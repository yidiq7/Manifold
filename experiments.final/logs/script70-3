+ RUN=3
+ export CUDA_VISIBLE_DEVICES=3
+ CUDA_VISIBLE_DEVICES=3
+ LAYERS='k4 k3 k2'
+ case $RUN in
+ PSI='2 3'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output70
+ for fn in f1 f2
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0
+ date
Tue Oct 27 14:42:53 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c191d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c19a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c1919d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c1bff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c1db730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c1db840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c0eaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c0eac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c112ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c0890d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c0bc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c052840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421c052a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4215643598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421569b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421561fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42155b3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42155b3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421558d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421554c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421554b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42154f1f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42154bd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42154b7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42154d6c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42154d67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4215431f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42154566a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4215456ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4215406378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4215456268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42153dd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421537f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42153acbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4215364a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42152eff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00233044475
Iter: 2 loss: 0.00231998088
Iter: 3 loss: 0.00227895356
Iter: 4 loss: 0.00209374703
Iter: 5 loss: 0.00167412788
Iter: 6 loss: 0.00167407235
Iter: 7 loss: 0.00131531223
Iter: 8 loss: 0.00515940366
Iter: 9 loss: 0.00130112283
Iter: 10 loss: 0.00110761472
Iter: 11 loss: 0.00142831
Iter: 12 loss: 0.00101917365
Iter: 13 loss: 0.000856153667
Iter: 14 loss: 0.00274288794
Iter: 15 loss: 0.00085418782
Iter: 16 loss: 0.000747537182
Iter: 17 loss: 0.000779167574
Iter: 18 loss: 0.000670294161
Iter: 19 loss: 0.000567935174
Iter: 20 loss: 0.000887474744
Iter: 21 loss: 0.000537778833
Iter: 22 loss: 0.000473404303
Iter: 23 loss: 0.000472663494
Iter: 24 loss: 0.000429061
Iter: 25 loss: 0.000399166602
Iter: 26 loss: 0.000383236504
Iter: 27 loss: 0.000334600627
Iter: 28 loss: 0.000463095406
Iter: 29 loss: 0.000318114704
Iter: 30 loss: 0.00028696534
Iter: 31 loss: 0.000776853238
Iter: 32 loss: 0.000286960625
Iter: 33 loss: 0.000261418492
Iter: 34 loss: 0.000319787388
Iter: 35 loss: 0.000251862
Iter: 36 loss: 0.000232679813
Iter: 37 loss: 0.000238564709
Iter: 38 loss: 0.000218968722
Iter: 39 loss: 0.000199618182
Iter: 40 loss: 0.000277305691
Iter: 41 loss: 0.000195243716
Iter: 42 loss: 0.000183102326
Iter: 43 loss: 0.000183090713
Iter: 44 loss: 0.000173187393
Iter: 45 loss: 0.000181020485
Iter: 46 loss: 0.000167207443
Iter: 47 loss: 0.000158215262
Iter: 48 loss: 0.000182890202
Iter: 49 loss: 0.000155263668
Iter: 50 loss: 0.000147074024
Iter: 51 loss: 0.000206518394
Iter: 52 loss: 0.000146406412
Iter: 53 loss: 0.000140981923
Iter: 54 loss: 0.000140017815
Iter: 55 loss: 0.000136336486
Iter: 56 loss: 0.000130946588
Iter: 57 loss: 0.000186010118
Iter: 58 loss: 0.000130787856
Iter: 59 loss: 0.000126401064
Iter: 60 loss: 0.000145146361
Iter: 61 loss: 0.000125493621
Iter: 62 loss: 0.000122351223
Iter: 63 loss: 0.000120924204
Iter: 64 loss: 0.000119352218
Iter: 65 loss: 0.00011616043
Iter: 66 loss: 0.000153596266
Iter: 67 loss: 0.000116113617
Iter: 68 loss: 0.000113362716
Iter: 69 loss: 0.000122676982
Iter: 70 loss: 0.000112622343
Iter: 71 loss: 0.000110657624
Iter: 72 loss: 0.000109264613
Iter: 73 loss: 0.00010857395
Iter: 74 loss: 0.000105972853
Iter: 75 loss: 0.000114730909
Iter: 76 loss: 0.000105267798
Iter: 77 loss: 0.000103092876
Iter: 78 loss: 0.00011202789
Iter: 79 loss: 0.000102618884
Iter: 80 loss: 0.000101149926
Iter: 81 loss: 0.000123729289
Iter: 82 loss: 0.000101149431
Iter: 83 loss: 9.99259792e-05
Iter: 84 loss: 0.000101319849
Iter: 85 loss: 9.92685455e-05
Iter: 86 loss: 9.81451885e-05
Iter: 87 loss: 9.87539242e-05
Iter: 88 loss: 9.7406526e-05
Iter: 89 loss: 9.62753693e-05
Iter: 90 loss: 0.000108428889
Iter: 91 loss: 9.62482882e-05
Iter: 92 loss: 9.52999908e-05
Iter: 93 loss: 9.67107189e-05
Iter: 94 loss: 9.48454544e-05
Iter: 95 loss: 9.39869642e-05
Iter: 96 loss: 9.61601909e-05
Iter: 97 loss: 9.36895522e-05
Iter: 98 loss: 9.27804722e-05
Iter: 99 loss: 9.78197786e-05
Iter: 100 loss: 9.26490175e-05
Iter: 101 loss: 9.19796439e-05
Iter: 102 loss: 9.19139493e-05
Iter: 103 loss: 9.142403e-05
Iter: 104 loss: 9.07046633e-05
Iter: 105 loss: 9.88635e-05
Iter: 106 loss: 9.06920468e-05
Iter: 107 loss: 9.00478335e-05
Iter: 108 loss: 9.05903726e-05
Iter: 109 loss: 8.96654674e-05
Iter: 110 loss: 8.90454103e-05
Iter: 111 loss: 8.9053734e-05
Iter: 112 loss: 8.85519403e-05
Iter: 113 loss: 8.79435684e-05
Iter: 114 loss: 9.70225956e-05
Iter: 115 loss: 8.79429863e-05
Iter: 116 loss: 8.73882236e-05
Iter: 117 loss: 8.79434665e-05
Iter: 118 loss: 8.70762597e-05
Iter: 119 loss: 8.65687762e-05
Iter: 120 loss: 8.64288595e-05
Iter: 121 loss: 8.61176959e-05
Iter: 122 loss: 8.54558311e-05
Iter: 123 loss: 8.77817365e-05
Iter: 124 loss: 8.52842059e-05
Iter: 125 loss: 8.47528718e-05
Iter: 126 loss: 8.87938368e-05
Iter: 127 loss: 8.47121701e-05
Iter: 128 loss: 8.42536e-05
Iter: 129 loss: 8.74490579e-05
Iter: 130 loss: 8.42113222e-05
Iter: 131 loss: 8.38936176e-05
Iter: 132 loss: 8.36718827e-05
Iter: 133 loss: 8.35583414e-05
Iter: 134 loss: 8.31471843e-05
Iter: 135 loss: 8.63260866e-05
Iter: 136 loss: 8.31169527e-05
Iter: 137 loss: 8.27549957e-05
Iter: 138 loss: 8.38818087e-05
Iter: 139 loss: 8.26493779e-05
Iter: 140 loss: 8.23533774e-05
Iter: 141 loss: 8.26150499e-05
Iter: 142 loss: 8.21803624e-05
Iter: 143 loss: 8.18455228e-05
Iter: 144 loss: 8.45949e-05
Iter: 145 loss: 8.18245171e-05
Iter: 146 loss: 8.15704e-05
Iter: 147 loss: 8.14948e-05
Iter: 148 loss: 8.13423685e-05
Iter: 149 loss: 8.10231e-05
Iter: 150 loss: 8.17982655e-05
Iter: 151 loss: 8.09089252e-05
Iter: 152 loss: 8.06563912e-05
Iter: 153 loss: 8.06563e-05
Iter: 154 loss: 8.04640877e-05
Iter: 155 loss: 8.03503935e-05
Iter: 156 loss: 8.02698341e-05
Iter: 157 loss: 8.00284761e-05
Iter: 158 loss: 8.06084136e-05
Iter: 159 loss: 7.99412956e-05
Iter: 160 loss: 7.97430694e-05
Iter: 161 loss: 8.28255143e-05
Iter: 162 loss: 7.97430112e-05
Iter: 163 loss: 7.96021632e-05
Iter: 164 loss: 7.94203661e-05
Iter: 165 loss: 7.94077205e-05
Iter: 166 loss: 7.91841885e-05
Iter: 167 loss: 7.96030654e-05
Iter: 168 loss: 7.90891936e-05
Iter: 169 loss: 7.88755278e-05
Iter: 170 loss: 7.98425608e-05
Iter: 171 loss: 7.88343314e-05
Iter: 172 loss: 7.86848614e-05
Iter: 173 loss: 7.86849e-05
Iter: 174 loss: 7.85670272e-05
Iter: 175 loss: 7.85362499e-05
Iter: 176 loss: 7.84627191e-05
Iter: 177 loss: 7.83304131e-05
Iter: 178 loss: 7.86821911e-05
Iter: 179 loss: 7.8286088e-05
Iter: 180 loss: 7.81633498e-05
Iter: 181 loss: 7.93123545e-05
Iter: 182 loss: 7.81583803e-05
Iter: 183 loss: 7.80690534e-05
Iter: 184 loss: 7.80710761e-05
Iter: 185 loss: 7.79979455e-05
Iter: 186 loss: 7.79003312e-05
Iter: 187 loss: 7.86756282e-05
Iter: 188 loss: 7.78935573e-05
Iter: 189 loss: 7.78071626e-05
Iter: 190 loss: 7.78996036e-05
Iter: 191 loss: 7.77595924e-05
Iter: 192 loss: 7.76802844e-05
Iter: 193 loss: 7.77297464e-05
Iter: 194 loss: 7.76296656e-05
Iter: 195 loss: 7.75591907e-05
Iter: 196 loss: 7.85940938e-05
Iter: 197 loss: 7.75591907e-05
Iter: 198 loss: 7.74969812e-05
Iter: 199 loss: 7.75920635e-05
Iter: 200 loss: 7.746763e-05
Iter: 201 loss: 7.74129439e-05
Iter: 202 loss: 7.74228101e-05
Iter: 203 loss: 7.73719803e-05
Iter: 204 loss: 7.7320452e-05
Iter: 205 loss: 7.80976043e-05
Iter: 206 loss: 7.73205466e-05
Iter: 207 loss: 7.72761414e-05
Iter: 208 loss: 7.73138163e-05
Iter: 209 loss: 7.72498315e-05
Iter: 210 loss: 7.72078638e-05
Iter: 211 loss: 7.72086496e-05
Iter: 212 loss: 7.71744526e-05
Iter: 213 loss: 7.71236446e-05
Iter: 214 loss: 7.73027132e-05
Iter: 215 loss: 7.71103514e-05
Iter: 216 loss: 7.70748e-05
Iter: 217 loss: 7.74478176e-05
Iter: 218 loss: 7.70738188e-05
Iter: 219 loss: 7.70427869e-05
Iter: 220 loss: 7.71803e-05
Iter: 221 loss: 7.70365805e-05
Iter: 222 loss: 7.70142942e-05
Iter: 223 loss: 7.70047845e-05
Iter: 224 loss: 7.69933104e-05
Iter: 225 loss: 7.69690669e-05
Iter: 226 loss: 7.72340645e-05
Iter: 227 loss: 7.69685867e-05
Iter: 228 loss: 7.69475737e-05
Iter: 229 loss: 7.69901235e-05
Iter: 230 loss: 7.69391336e-05
Iter: 231 loss: 7.69213802e-05
Iter: 232 loss: 7.69505568e-05
Iter: 233 loss: 7.69132457e-05
Iter: 234 loss: 7.68943719e-05
Iter: 235 loss: 7.70272818e-05
Iter: 236 loss: 7.68926402e-05
Iter: 237 loss: 7.68788741e-05
Iter: 238 loss: 7.68749451e-05
Iter: 239 loss: 7.6866374e-05
Iter: 240 loss: 7.68498721e-05
Iter: 241 loss: 7.69215694e-05
Iter: 242 loss: 7.6846547e-05
Iter: 243 loss: 7.68334794e-05
Iter: 244 loss: 7.69920662e-05
Iter: 245 loss: 7.68333557e-05
Iter: 246 loss: 7.68243626e-05
Iter: 247 loss: 7.68176687e-05
Iter: 248 loss: 7.68147875e-05
Iter: 249 loss: 7.68032842e-05
Iter: 250 loss: 7.68532045e-05
Iter: 251 loss: 7.68010941e-05
Iter: 252 loss: 7.67917081e-05
Iter: 253 loss: 7.68946484e-05
Iter: 254 loss: 7.67915044e-05
Iter: 255 loss: 7.67853271e-05
Iter: 256 loss: 7.67793754e-05
Iter: 257 loss: 7.67779e-05
Iter: 258 loss: 7.67691527e-05
Iter: 259 loss: 7.67858146e-05
Iter: 260 loss: 7.67655074e-05
Iter: 261 loss: 7.67573802e-05
Iter: 262 loss: 7.6795e-05
Iter: 263 loss: 7.67560123e-05
Iter: 264 loss: 7.67508e-05
Iter: 265 loss: 7.67507154e-05
Iter: 266 loss: 7.67466336e-05
Iter: 267 loss: 7.67452e-05
Iter: 268 loss: 7.67429e-05
Iter: 269 loss: 7.67380407e-05
Iter: 270 loss: 7.67460588e-05
Iter: 271 loss: 7.67358433e-05
Iter: 272 loss: 7.67321253e-05
Iter: 273 loss: 7.67321399e-05
Iter: 274 loss: 7.67292076e-05
Iter: 275 loss: 7.6727767e-05
Iter: 276 loss: 7.67263555e-05
Iter: 277 loss: 7.67230813e-05
Iter: 278 loss: 7.67362e-05
Iter: 279 loss: 7.67222082e-05
Iter: 280 loss: 7.67192396e-05
Iter: 281 loss: 7.67417077e-05
Iter: 282 loss: 7.67189122e-05
Iter: 283 loss: 7.67169404e-05
Iter: 284 loss: 7.67166057e-05
Iter: 285 loss: 7.67151141e-05
Iter: 286 loss: 7.67129823e-05
Iter: 287 loss: 7.67405e-05
Iter: 288 loss: 7.67130696e-05
Iter: 289 loss: 7.67112579e-05
Iter: 290 loss: 7.67127058e-05
Iter: 291 loss: 7.67102e-05
Iter: 292 loss: 7.67086312e-05
Iter: 293 loss: 7.67100573e-05
Iter: 294 loss: 7.67076272e-05
Iter: 295 loss: 7.67062447e-05
Iter: 296 loss: 7.67061938e-05
Iter: 297 loss: 7.67051242e-05
Iter: 298 loss: 7.67048405e-05
Iter: 299 loss: 7.67041347e-05
Iter: 300 loss: 7.67028396e-05
Iter: 301 loss: 7.67036909e-05
Iter: 302 loss: 7.67020319e-05
Iter: 303 loss: 7.6700635e-05
Iter: 304 loss: 7.67052188e-05
Iter: 305 loss: 7.67002639e-05
Iter: 306 loss: 7.66994e-05
Iter: 307 loss: 7.66994199e-05
Iter: 308 loss: 7.66986777e-05
Iter: 309 loss: 7.66987068e-05
Iter: 310 loss: 7.66981393e-05
Iter: 311 loss: 7.6697339e-05
Iter: 312 loss: 7.66981248e-05
Iter: 313 loss: 7.66968296e-05
Iter: 314 loss: 7.6696233e-05
Iter: 315 loss: 7.67064193e-05
Iter: 316 loss: 7.66962621e-05
Iter: 317 loss: 7.66956437e-05
Iter: 318 loss: 7.66961821e-05
Iter: 319 loss: 7.6695389e-05
Iter: 320 loss: 7.66947778e-05
Iter: 321 loss: 7.66952726e-05
Iter: 322 loss: 7.66945668e-05
Iter: 323 loss: 7.6694072e-05
Iter: 324 loss: 7.66974554e-05
Iter: 325 loss: 7.6694e-05
Iter: 326 loss: 7.66936e-05
Iter: 327 loss: 7.66962039e-05
Iter: 328 loss: 7.669349e-05
Iter: 329 loss: 7.66931917e-05
Iter: 330 loss: 7.66933954e-05
Iter: 331 loss: 7.66929879e-05
Iter: 332 loss: 7.66926823e-05
Iter: 333 loss: 7.66954618e-05
Iter: 334 loss: 7.66926169e-05
Iter: 335 loss: 7.66923185e-05
Iter: 336 loss: 7.66924277e-05
Iter: 337 loss: 7.66923113e-05
Iter: 338 loss: 7.6692013e-05
Iter: 339 loss: 7.66937592e-05
Iter: 340 loss: 7.66919838e-05
Iter: 341 loss: 7.66916783e-05
Iter: 342 loss: 7.66921657e-05
Iter: 343 loss: 7.66916201e-05
Iter: 344 loss: 7.66914236e-05
Iter: 345 loss: 7.6691409e-05
Iter: 346 loss: 7.66912417e-05
Iter: 347 loss: 7.66909725e-05
Iter: 348 loss: 7.6692013e-05
Iter: 349 loss: 7.66910234e-05
Iter: 350 loss: 7.66908051e-05
Iter: 351 loss: 7.66908051e-05
Iter: 352 loss: 7.6690696e-05
Iter: 353 loss: 7.66907397e-05
Iter: 354 loss: 7.66906305e-05
Iter: 355 loss: 7.6690485e-05
Iter: 356 loss: 7.66904268e-05
Iter: 357 loss: 7.66903904e-05
Iter: 358 loss: 7.66902667e-05
Iter: 359 loss: 7.66914673e-05
Iter: 360 loss: 7.66902376e-05
Iter: 361 loss: 7.66901867e-05
Iter: 362 loss: 7.66905723e-05
Iter: 363 loss: 7.6690194e-05
Iter: 364 loss: 7.66900048e-05
Iter: 365 loss: 7.66901067e-05
Iter: 366 loss: 7.66899248e-05
Iter: 367 loss: 7.66899393e-05
Iter: 368 loss: 7.66903249e-05
Iter: 369 loss: 7.66899175e-05
Iter: 370 loss: 7.66897574e-05
Iter: 371 loss: 7.66906596e-05
Iter: 372 loss: 7.66897865e-05
Iter: 373 loss: 7.6689852e-05
Iter: 374 loss: 7.66898156e-05
Iter: 375 loss: 7.66897356e-05
Iter: 376 loss: 7.66896555e-05
Iter: 377 loss: 7.66899611e-05
Iter: 378 loss: 7.66896192e-05
Iter: 379 loss: 7.668951e-05
Iter: 380 loss: 7.66898593e-05
Iter: 381 loss: 7.66895828e-05
Iter: 382 loss: 7.66895246e-05
Iter: 383 loss: 7.66895828e-05
Iter: 384 loss: 7.668951e-05
Iter: 385 loss: 7.66894809e-05
Iter: 386 loss: 7.6689983e-05
Iter: 387 loss: 7.66894809e-05
Iter: 388 loss: 7.66893791e-05
Iter: 389 loss: 7.66893791e-05
Iter: 390 loss: 7.66894591e-05
Iter: 391 loss: 7.66893791e-05
Iter: 392 loss: 7.66894736e-05
Iter: 393 loss: 7.66893791e-05
Iter: 394 loss: 7.66892845e-05
Iter: 395 loss: 7.66895246e-05
Iter: 396 loss: 7.66892408e-05
Iter: 397 loss: 7.66893136e-05
Iter: 398 loss: 7.66897647e-05
Iter: 399 loss: 7.66893208e-05
Iter: 400 loss: 7.66892408e-05
Iter: 401 loss: 7.66892554e-05
Iter: 402 loss: 7.66891681e-05
Iter: 403 loss: 7.66892044e-05
Iter: 404 loss: 7.66893354e-05
Iter: 405 loss: 7.66892408e-05
Iter: 406 loss: 7.66891608e-05
Iter: 407 loss: 7.66891899e-05
Iter: 408 loss: 7.66891462e-05
Iter: 409 loss: 7.66892e-05
Iter: 410 loss: 7.66891753e-05
Iter: 411 loss: 7.66891e-05
Iter: 412 loss: 7.66892335e-05
Iter: 413 loss: 7.66892044e-05
Iter: 414 loss: 7.66891462e-05
Iter: 415 loss: 7.66892917e-05
Iter: 416 loss: 7.66891e-05
Iter: 417 loss: 7.66891317e-05
Iter: 418 loss: 7.66891608e-05
Iter: 419 loss: 7.66891317e-05
Iter: 420 loss: 7.6689088e-05
Iter: 421 loss: 7.66891e-05
Iter: 422 loss: 7.66890444e-05
Iter: 423 loss: 7.66890516e-05
Iter: 424 loss: 7.66890444e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4
+ date
Tue Oct 27 14:48:48 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d2cf90730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d2cf90268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d6ed35e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d2cfa7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d2cf3dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d2cf517b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d2cf24f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d087b8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d087cd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d087cd158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d087cdae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d0874ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d086e5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d0869c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d0869cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d0869c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d08674a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d08686950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d085e07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d085e0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d08606598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d08606730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d08583950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d085588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d08528598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d0852ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d085079d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d08507bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d084b9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d084c32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d085076a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d0843a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d084521e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d083edd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d083a79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1d083a7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0254985746
Iter: 2 loss: 0.0250847153
Iter: 3 loss: 0.0234840401
Iter: 4 loss: 0.0167354066
Iter: 5 loss: 0.0115342299
Iter: 6 loss: 0.00788422674
Iter: 7 loss: 0.0040778555
Iter: 8 loss: 0.00394860236
Iter: 9 loss: 0.00232104631
Iter: 10 loss: 0.0134491734
Iter: 11 loss: 0.00202765851
Iter: 12 loss: 0.0013220231
Iter: 13 loss: 0.00499527715
Iter: 14 loss: 0.00118979299
Iter: 15 loss: 0.000824338524
Iter: 16 loss: 0.00544040883
Iter: 17 loss: 0.000820932677
Iter: 18 loss: 0.000618191261
Iter: 19 loss: 0.00367911113
Iter: 20 loss: 0.000618169783
Iter: 21 loss: 0.000523861439
Iter: 22 loss: 0.000581536
Iter: 23 loss: 0.000462977681
Iter: 24 loss: 0.000375348667
Iter: 25 loss: 0.000999975251
Iter: 26 loss: 0.000367093919
Iter: 27 loss: 0.000312994642
Iter: 28 loss: 0.000425228674
Iter: 29 loss: 0.000291392527
Iter: 30 loss: 0.000252074416
Iter: 31 loss: 0.000422566547
Iter: 32 loss: 0.000244257099
Iter: 33 loss: 0.000214633415
Iter: 34 loss: 0.000345284468
Iter: 35 loss: 0.00020856614
Iter: 36 loss: 0.000190089224
Iter: 37 loss: 0.000226335309
Iter: 38 loss: 0.000182387914
Iter: 39 loss: 0.000166946658
Iter: 40 loss: 0.000288587849
Iter: 41 loss: 0.000165891019
Iter: 42 loss: 0.000154493115
Iter: 43 loss: 0.000192966138
Iter: 44 loss: 0.000151388143
Iter: 45 loss: 0.000142813617
Iter: 46 loss: 0.000179610448
Iter: 47 loss: 0.000141057506
Iter: 48 loss: 0.000134157774
Iter: 49 loss: 0.000159782081
Iter: 50 loss: 0.00013244724
Iter: 51 loss: 0.000126747211
Iter: 52 loss: 0.00014667603
Iter: 53 loss: 0.000125265142
Iter: 54 loss: 0.000120821227
Iter: 55 loss: 0.000136599585
Iter: 56 loss: 0.000119672288
Iter: 57 loss: 0.000116094328
Iter: 58 loss: 0.000148116873
Iter: 59 loss: 0.000115917632
Iter: 60 loss: 0.000113488859
Iter: 61 loss: 0.000114948474
Iter: 62 loss: 0.000111925321
Iter: 63 loss: 0.00010934288
Iter: 64 loss: 0.00011721249
Iter: 65 loss: 0.000108571498
Iter: 66 loss: 0.000106290179
Iter: 67 loss: 0.000110573979
Iter: 68 loss: 0.000105321684
Iter: 69 loss: 0.000103209277
Iter: 70 loss: 0.000110012683
Iter: 71 loss: 0.00010261139
Iter: 72 loss: 0.00010078687
Iter: 73 loss: 0.000110213645
Iter: 74 loss: 0.000100494362
Iter: 75 loss: 9.9053e-05
Iter: 76 loss: 0.000103959916
Iter: 77 loss: 9.86672676e-05
Iter: 78 loss: 9.74578725e-05
Iter: 79 loss: 0.000101877857
Iter: 80 loss: 9.71550762e-05
Iter: 81 loss: 9.61246842e-05
Iter: 82 loss: 0.000101308819
Iter: 83 loss: 9.59546524e-05
Iter: 84 loss: 9.51158727e-05
Iter: 85 loss: 9.91021079e-05
Iter: 86 loss: 9.49626e-05
Iter: 87 loss: 9.42657643e-05
Iter: 88 loss: 9.50902468e-05
Iter: 89 loss: 9.38967351e-05
Iter: 90 loss: 9.32050243e-05
Iter: 91 loss: 9.52336559e-05
Iter: 92 loss: 9.2991686e-05
Iter: 93 loss: 9.24173291e-05
Iter: 94 loss: 9.65819345e-05
Iter: 95 loss: 9.23681946e-05
Iter: 96 loss: 9.1889553e-05
Iter: 97 loss: 9.32744297e-05
Iter: 98 loss: 9.17405e-05
Iter: 99 loss: 9.1324895e-05
Iter: 100 loss: 9.17172729e-05
Iter: 101 loss: 9.10862291e-05
Iter: 102 loss: 9.06505375e-05
Iter: 103 loss: 9.21949904e-05
Iter: 104 loss: 9.05386623e-05
Iter: 105 loss: 9.01661551e-05
Iter: 106 loss: 9.10759845e-05
Iter: 107 loss: 9.0033056e-05
Iter: 108 loss: 8.96940328e-05
Iter: 109 loss: 9.10092349e-05
Iter: 110 loss: 8.96148267e-05
Iter: 111 loss: 8.9310066e-05
Iter: 112 loss: 9.02065221e-05
Iter: 113 loss: 8.92167373e-05
Iter: 114 loss: 8.89528237e-05
Iter: 115 loss: 8.97831924e-05
Iter: 116 loss: 8.88763752e-05
Iter: 117 loss: 8.86428243e-05
Iter: 118 loss: 8.94537079e-05
Iter: 119 loss: 8.85816407e-05
Iter: 120 loss: 8.83849352e-05
Iter: 121 loss: 8.91906093e-05
Iter: 122 loss: 8.83418834e-05
Iter: 123 loss: 8.81723463e-05
Iter: 124 loss: 8.93258839e-05
Iter: 125 loss: 8.81558371e-05
Iter: 126 loss: 8.80220468e-05
Iter: 127 loss: 8.81152664e-05
Iter: 128 loss: 8.79386935e-05
Iter: 129 loss: 8.78021237e-05
Iter: 130 loss: 8.81708838e-05
Iter: 131 loss: 8.77569837e-05
Iter: 132 loss: 8.76367922e-05
Iter: 133 loss: 8.84672772e-05
Iter: 134 loss: 8.76254489e-05
Iter: 135 loss: 8.75316036e-05
Iter: 136 loss: 8.77901475e-05
Iter: 137 loss: 8.75011829e-05
Iter: 138 loss: 8.74102261e-05
Iter: 139 loss: 8.77718849e-05
Iter: 140 loss: 8.73896424e-05
Iter: 141 loss: 8.73152894e-05
Iter: 142 loss: 8.73259341e-05
Iter: 143 loss: 8.72589299e-05
Iter: 144 loss: 8.71738812e-05
Iter: 145 loss: 8.7436696e-05
Iter: 146 loss: 8.71490047e-05
Iter: 147 loss: 8.70713411e-05
Iter: 148 loss: 8.74987381e-05
Iter: 149 loss: 8.70601943e-05
Iter: 150 loss: 8.69987198e-05
Iter: 151 loss: 8.70973308e-05
Iter: 152 loss: 8.69702126e-05
Iter: 153 loss: 8.6910426e-05
Iter: 154 loss: 8.71275843e-05
Iter: 155 loss: 8.68955613e-05
Iter: 156 loss: 8.68424759e-05
Iter: 157 loss: 8.70745862e-05
Iter: 158 loss: 8.68316711e-05
Iter: 159 loss: 8.67882045e-05
Iter: 160 loss: 8.69111173e-05
Iter: 161 loss: 8.67743656e-05
Iter: 162 loss: 8.67356721e-05
Iter: 163 loss: 8.69403593e-05
Iter: 164 loss: 8.67297204e-05
Iter: 165 loss: 8.66963528e-05
Iter: 166 loss: 8.68274e-05
Iter: 167 loss: 8.66886548e-05
Iter: 168 loss: 8.66609043e-05
Iter: 169 loss: 8.6685417e-05
Iter: 170 loss: 8.66446353e-05
Iter: 171 loss: 8.66152695e-05
Iter: 172 loss: 8.6695567e-05
Iter: 173 loss: 8.66058108e-05
Iter: 174 loss: 8.65798429e-05
Iter: 175 loss: 8.67059571e-05
Iter: 176 loss: 8.65752882e-05
Iter: 177 loss: 8.65540205e-05
Iter: 178 loss: 8.67036506e-05
Iter: 179 loss: 8.65521e-05
Iter: 180 loss: 8.65358161e-05
Iter: 181 loss: 8.65523398e-05
Iter: 182 loss: 8.65265902e-05
Iter: 183 loss: 8.65088805e-05
Iter: 184 loss: 8.65705661e-05
Iter: 185 loss: 8.65041948e-05
Iter: 186 loss: 8.64890681e-05
Iter: 187 loss: 8.65002585e-05
Iter: 188 loss: 8.6479864e-05
Iter: 189 loss: 8.64635367e-05
Iter: 190 loss: 8.6531174e-05
Iter: 191 loss: 8.64599e-05
Iter: 192 loss: 8.6445827e-05
Iter: 193 loss: 8.65018956e-05
Iter: 194 loss: 8.64425529e-05
Iter: 195 loss: 8.64301182e-05
Iter: 196 loss: 8.64572503e-05
Iter: 197 loss: 8.64251269e-05
Iter: 198 loss: 8.64139074e-05
Iter: 199 loss: 8.64612957e-05
Iter: 200 loss: 8.64115864e-05
Iter: 201 loss: 8.6401822e-05
Iter: 202 loss: 8.64360554e-05
Iter: 203 loss: 8.63993919e-05
Iter: 204 loss: 8.63911118e-05
Iter: 205 loss: 8.64219328e-05
Iter: 206 loss: 8.63890891e-05
Iter: 207 loss: 8.63817259e-05
Iter: 208 loss: 8.64234753e-05
Iter: 209 loss: 8.63806272e-05
Iter: 210 loss: 8.63748428e-05
Iter: 211 loss: 8.63813475e-05
Iter: 212 loss: 8.63716414e-05
Iter: 213 loss: 8.63653404e-05
Iter: 214 loss: 8.63801251e-05
Iter: 215 loss: 8.63630412e-05
Iter: 216 loss: 8.63569367e-05
Iter: 217 loss: 8.63690657e-05
Iter: 218 loss: 8.63544192e-05
Iter: 219 loss: 8.63487076e-05
Iter: 220 loss: 8.63712703e-05
Iter: 221 loss: 8.63474852e-05
Iter: 222 loss: 8.63425084e-05
Iter: 223 loss: 8.63748282e-05
Iter: 224 loss: 8.6342e-05
Iter: 225 loss: 8.63383684e-05
Iter: 226 loss: 8.63514724e-05
Iter: 227 loss: 8.6337328e-05
Iter: 228 loss: 8.63338137e-05
Iter: 229 loss: 8.63449823e-05
Iter: 230 loss: 8.63329624e-05
Iter: 231 loss: 8.63297464e-05
Iter: 232 loss: 8.63306559e-05
Iter: 233 loss: 8.63274327e-05
Iter: 234 loss: 8.63240566e-05
Iter: 235 loss: 8.63345049e-05
Iter: 236 loss: 8.6323038e-05
Iter: 237 loss: 8.63198948e-05
Iter: 238 loss: 8.6336513e-05
Iter: 239 loss: 8.63194291e-05
Iter: 240 loss: 8.63169407e-05
Iter: 241 loss: 8.63214882e-05
Iter: 242 loss: 8.63158057e-05
Iter: 243 loss: 8.63133173e-05
Iter: 244 loss: 8.63226451e-05
Iter: 245 loss: 8.63128153e-05
Iter: 246 loss: 8.63105161e-05
Iter: 247 loss: 8.63169844e-05
Iter: 248 loss: 8.63099267e-05
Iter: 249 loss: 8.63079113e-05
Iter: 250 loss: 8.63162859e-05
Iter: 251 loss: 8.63074238e-05
Iter: 252 loss: 8.6305663e-05
Iter: 253 loss: 8.63136593e-05
Iter: 254 loss: 8.63055684e-05
Iter: 255 loss: 8.63038949e-05
Iter: 256 loss: 8.63087189e-05
Iter: 257 loss: 8.63033638e-05
Iter: 258 loss: 8.63022e-05
Iter: 259 loss: 8.63030655e-05
Iter: 260 loss: 8.6301392e-05
Iter: 261 loss: 8.6299915e-05
Iter: 262 loss: 8.63045716e-05
Iter: 263 loss: 8.62993911e-05
Iter: 264 loss: 8.62981396e-05
Iter: 265 loss: 8.63030291e-05
Iter: 266 loss: 8.6297805e-05
Iter: 267 loss: 8.62967e-05
Iter: 268 loss: 8.6301181e-05
Iter: 269 loss: 8.62963716e-05
Iter: 270 loss: 8.62954039e-05
Iter: 271 loss: 8.62987799e-05
Iter: 272 loss: 8.62951929e-05
Iter: 273 loss: 8.62943562e-05
Iter: 274 loss: 8.63002788e-05
Iter: 275 loss: 8.62941815e-05
Iter: 276 loss: 8.6293483e-05
Iter: 277 loss: 8.6293614e-05
Iter: 278 loss: 8.62929228e-05
Iter: 279 loss: 8.62920861e-05
Iter: 280 loss: 8.62938396e-05
Iter: 281 loss: 8.62916859e-05
Iter: 282 loss: 8.62910674e-05
Iter: 283 loss: 8.62948509e-05
Iter: 284 loss: 8.62908855e-05
Iter: 285 loss: 8.62902089e-05
Iter: 286 loss: 8.62916349e-05
Iter: 287 loss: 8.62899833e-05
Iter: 288 loss: 8.62893503e-05
Iter: 289 loss: 8.62910383e-05
Iter: 290 loss: 8.62892048e-05
Iter: 291 loss: 8.62885063e-05
Iter: 292 loss: 8.62910601e-05
Iter: 293 loss: 8.62884845e-05
Iter: 294 loss: 8.62878805e-05
Iter: 295 loss: 8.62890884e-05
Iter: 296 loss: 8.62878369e-05
Iter: 297 loss: 8.62874e-05
Iter: 298 loss: 8.62893794e-05
Iter: 299 loss: 8.62871457e-05
Iter: 300 loss: 8.62868328e-05
Iter: 301 loss: 8.62892484e-05
Iter: 302 loss: 8.62867746e-05
Iter: 303 loss: 8.62864254e-05
Iter: 304 loss: 8.62870365e-05
Iter: 305 loss: 8.62862653e-05
Iter: 306 loss: 8.62859888e-05
Iter: 307 loss: 8.62865709e-05
Iter: 308 loss: 8.62857851e-05
Iter: 309 loss: 8.62854795e-05
Iter: 310 loss: 8.62865709e-05
Iter: 311 loss: 8.62853849e-05
Iter: 312 loss: 8.62851448e-05
Iter: 313 loss: 8.62860252e-05
Iter: 314 loss: 8.62850575e-05
Iter: 315 loss: 8.62847155e-05
Iter: 316 loss: 8.62851593e-05
Iter: 317 loss: 8.62846064e-05
Iter: 318 loss: 8.62843299e-05
Iter: 319 loss: 8.62855231e-05
Iter: 320 loss: 8.62843663e-05
Iter: 321 loss: 8.62841262e-05
Iter: 322 loss: 8.62854286e-05
Iter: 323 loss: 8.62841844e-05
Iter: 324 loss: 8.62839588e-05
Iter: 325 loss: 8.62845482e-05
Iter: 326 loss: 8.62839e-05
Iter: 327 loss: 8.62838351e-05
Iter: 328 loss: 8.62839661e-05
Iter: 329 loss: 8.62836823e-05
Iter: 330 loss: 8.62835877e-05
Iter: 331 loss: 8.62841698e-05
Iter: 332 loss: 8.62834422e-05
Iter: 333 loss: 8.62833695e-05
Iter: 334 loss: 8.62834568e-05
Iter: 335 loss: 8.62833e-05
Iter: 336 loss: 8.62831948e-05
Iter: 337 loss: 8.62837696e-05
Iter: 338 loss: 8.6283093e-05
Iter: 339 loss: 8.62829838e-05
Iter: 340 loss: 8.62836241e-05
Iter: 341 loss: 8.62829693e-05
Iter: 342 loss: 8.62828165e-05
Iter: 343 loss: 8.62832094e-05
Iter: 344 loss: 8.62828165e-05
Iter: 345 loss: 8.62827874e-05
Iter: 346 loss: 8.62833767e-05
Iter: 347 loss: 8.62826491e-05
Iter: 348 loss: 8.62826e-05
Iter: 349 loss: 8.62827292e-05
Iter: 350 loss: 8.62825691e-05
Iter: 351 loss: 8.62824163e-05
Iter: 352 loss: 8.62827437e-05
Iter: 353 loss: 8.62824236e-05
Iter: 354 loss: 8.62823217e-05
Iter: 355 loss: 8.62826419e-05
Iter: 356 loss: 8.62823e-05
Iter: 357 loss: 8.62822053e-05
Iter: 358 loss: 8.62824381e-05
Iter: 359 loss: 8.62822e-05
Iter: 360 loss: 8.62820962e-05
Iter: 361 loss: 8.62823072e-05
Iter: 362 loss: 8.62821908e-05
Iter: 363 loss: 8.6282118e-05
Iter: 364 loss: 8.62823072e-05
Iter: 365 loss: 8.62819e-05
Iter: 366 loss: 8.62819434e-05
Iter: 367 loss: 8.62823945e-05
Iter: 368 loss: 8.62819288e-05
Iter: 369 loss: 8.62819361e-05
Iter: 370 loss: 8.62820161e-05
Iter: 371 loss: 8.62819361e-05
Iter: 372 loss: 8.62817833e-05
Iter: 373 loss: 8.62819288e-05
Iter: 374 loss: 8.6281776e-05
Iter: 375 loss: 8.6281776e-05
Iter: 376 loss: 8.62818852e-05
Iter: 377 loss: 8.62818488e-05
Iter: 378 loss: 8.62817833e-05
Iter: 379 loss: 8.62818e-05
Iter: 380 loss: 8.62818124e-05
Iter: 381 loss: 8.62818051e-05
Iter: 382 loss: 8.62819143e-05
Iter: 383 loss: 8.62817469e-05
Iter: 384 loss: 8.62816523e-05
Iter: 385 loss: 8.62818779e-05
Iter: 386 loss: 8.62816087e-05
Iter: 387 loss: 8.62817e-05
Iter: 388 loss: 8.62815796e-05
Iter: 389 loss: 8.62815796e-05
Iter: 390 loss: 8.62816378e-05
Iter: 391 loss: 8.62816159e-05
Iter: 392 loss: 8.62816305e-05
Iter: 393 loss: 8.62817324e-05
Iter: 394 loss: 8.62816814e-05
Iter: 395 loss: 8.62816087e-05
Iter: 396 loss: 8.62816378e-05
Iter: 397 loss: 8.62816523e-05
Iter: 398 loss: 8.62817178e-05
Iter: 399 loss: 8.62816669e-05
Iter: 400 loss: 8.62816742e-05
Iter: 401 loss: 8.62817178e-05
Iter: 402 loss: 8.62817105e-05
Iter: 403 loss: 8.62816887e-05
Iter: 404 loss: 8.62816887e-05
Iter: 405 loss: 8.62817105e-05
Iter: 406 loss: 8.6281696e-05
Iter: 407 loss: 8.62817105e-05
Iter: 408 loss: 8.62817e-05
Iter: 409 loss: 8.62817e-05
Iter: 410 loss: 8.6281696e-05
Iter: 411 loss: 8.6281696e-05
Iter: 412 loss: 8.62817e-05
Iter: 413 loss: 8.62816378e-05
Iter: 414 loss: 8.62818124e-05
Iter: 415 loss: 8.62815723e-05
Iter: 416 loss: 8.62815577e-05
Iter: 417 loss: 8.62816814e-05
Iter: 418 loss: 8.62815505e-05
Iter: 419 loss: 8.62815505e-05
Iter: 420 loss: 8.62817615e-05
Iter: 421 loss: 8.62815068e-05
Iter: 422 loss: 8.62814632e-05
Iter: 423 loss: 8.62814268e-05
Iter: 424 loss: 8.62814e-05
Iter: 425 loss: 8.62813322e-05
Iter: 426 loss: 8.62815723e-05
Iter: 427 loss: 8.62814777e-05
Iter: 428 loss: 8.62813831e-05
Iter: 429 loss: 8.62814777e-05
Iter: 430 loss: 8.62814268e-05
Iter: 431 loss: 8.62814e-05
Iter: 432 loss: 8.62815505e-05
Iter: 433 loss: 8.62814341e-05
Iter: 434 loss: 8.62813613e-05
Iter: 435 loss: 8.62815723e-05
Iter: 436 loss: 8.62814486e-05
Iter: 437 loss: 8.62814049e-05
Iter: 438 loss: 8.6281485e-05
Iter: 439 loss: 8.62813395e-05
Iter: 440 loss: 8.62813904e-05
Iter: 441 loss: 8.62814559e-05
Iter: 442 loss: 8.62813831e-05
Iter: 443 loss: 8.62814049e-05
Iter: 444 loss: 8.62814195e-05
Iter: 445 loss: 8.62814341e-05
Iter: 446 loss: 8.62813104e-05
Iter: 447 loss: 8.62812813e-05
Iter: 448 loss: 8.62813322e-05
Iter: 449 loss: 8.62813176e-05
Iter: 450 loss: 8.62813758e-05
Iter: 451 loss: 8.62812813e-05
Iter: 452 loss: 8.62814e-05
Iter: 453 loss: 8.62813686e-05
Iter: 454 loss: 8.62813758e-05
Iter: 455 loss: 8.62813e-05
Iter: 456 loss: 8.6281223e-05
Iter: 457 loss: 8.62813467e-05
Iter: 458 loss: 8.62813104e-05
Iter: 459 loss: 8.62812885e-05
Iter: 460 loss: 8.62813322e-05
Iter: 461 loss: 8.62812958e-05
Iter: 462 loss: 8.62813758e-05
Iter: 463 loss: 8.6281354e-05
Iter: 464 loss: 8.62813467e-05
Iter: 465 loss: 8.62813467e-05
Iter: 466 loss: 8.6281354e-05
Iter: 467 loss: 8.62813758e-05
Iter: 468 loss: 8.62813613e-05
Iter: 469 loss: 8.62813758e-05
Iter: 470 loss: 8.62813758e-05
Iter: 471 loss: 8.62813613e-05
Iter: 472 loss: 8.62813613e-05
Iter: 473 loss: 8.62813613e-05
Iter: 474 loss: 8.62813758e-05
Iter: 475 loss: 8.62813758e-05
Iter: 476 loss: 8.62813758e-05
Iter: 477 loss: 8.62813613e-05
Iter: 478 loss: 8.62813249e-05
Iter: 479 loss: 8.62814923e-05
Iter: 480 loss: 8.62812594e-05
Iter: 481 loss: 8.62812958e-05
Iter: 482 loss: 8.62812158e-05
Iter: 483 loss: 8.62813176e-05
Iter: 484 loss: 8.62813176e-05
Iter: 485 loss: 8.6281274e-05
Iter: 486 loss: 8.62813e-05
Iter: 487 loss: 8.62813322e-05
Iter: 488 loss: 8.62813e-05
Iter: 489 loss: 8.62814122e-05
Iter: 490 loss: 8.62813322e-05
Iter: 491 loss: 8.62813176e-05
Iter: 492 loss: 8.62812885e-05
Iter: 493 loss: 8.62812958e-05
Iter: 494 loss: 8.62812594e-05
Iter: 495 loss: 8.62812449e-05
Iter: 496 loss: 8.62812667e-05
Iter: 497 loss: 8.62812885e-05
Iter: 498 loss: 8.62813e-05
Iter: 499 loss: 8.62813104e-05
Iter: 500 loss: 8.62813104e-05
Iter: 501 loss: 8.62813e-05
Iter: 502 loss: 8.62813e-05
Iter: 503 loss: 8.62813176e-05
Iter: 504 loss: 8.62813e-05
Iter: 505 loss: 8.62813104e-05
Iter: 506 loss: 8.62813e-05
Iter: 507 loss: 8.62813e-05
Iter: 508 loss: 8.62813104e-05
Iter: 509 loss: 8.62813e-05
Iter: 510 loss: 8.62812594e-05
Iter: 511 loss: 8.62813904e-05
Iter: 512 loss: 8.62811939e-05
Iter: 513 loss: 8.62812449e-05
Iter: 514 loss: 8.62812449e-05
Iter: 515 loss: 8.62813758e-05
Iter: 516 loss: 8.6281223e-05
Iter: 517 loss: 8.62812303e-05
Iter: 518 loss: 8.6281274e-05
Iter: 519 loss: 8.62812158e-05
Iter: 520 loss: 8.62813322e-05
Iter: 521 loss: 8.62813e-05
Iter: 522 loss: 8.62812885e-05
Iter: 523 loss: 8.6281274e-05
Iter: 524 loss: 8.6281274e-05
Iter: 525 loss: 8.62812885e-05
Iter: 526 loss: 8.62812449e-05
Iter: 527 loss: 8.62812303e-05
Iter: 528 loss: 8.62812813e-05
Iter: 529 loss: 8.62812594e-05
Iter: 530 loss: 8.62812813e-05
Iter: 531 loss: 8.62812885e-05
Iter: 532 loss: 8.62812885e-05
Iter: 533 loss: 8.6281274e-05
Iter: 534 loss: 8.62812813e-05
Iter: 535 loss: 8.62812885e-05
Iter: 536 loss: 8.62812885e-05
Iter: 537 loss: 8.62812885e-05
Iter: 538 loss: 8.62812885e-05
Iter: 539 loss: 8.62812813e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8
+ date
Tue Oct 27 14:56:14 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddc616a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddc690d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f31041d1e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f310411d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddbfc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddbfcea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddb708c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddb9c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddb9cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30ddb47400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b83fa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b83a77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b83c1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b8368d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b83a7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b83d9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b8331598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b83577b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b82af8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b82af2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b82d78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b82d72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b824f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b81f6510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b81f6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b81a7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b81a7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b81862f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b818c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b812b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b8152bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b8110400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b8118268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b80b6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b80718c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f30b807a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0183548182
Iter: 2 loss: 0.0179898646
Iter: 3 loss: 0.0166027695
Iter: 4 loss: 0.0119424015
Iter: 5 loss: 5763.5918
Iter: 6 loss: 0.0119424015
Iter: 7 loss: 0.00772558199
Iter: 8 loss: 0.0956227481
Iter: 9 loss: 0.00753885694
Iter: 10 loss: 0.00403838465
Iter: 11 loss: 0.0820503458
Iter: 12 loss: 0.00403656485
Iter: 13 loss: 0.00258199545
Iter: 14 loss: 0.0149642155
Iter: 15 loss: 0.00240951614
Iter: 16 loss: 0.00170540763
Iter: 17 loss: 0.00713651
Iter: 18 loss: 0.00163172139
Iter: 19 loss: 0.00131349324
Iter: 20 loss: 0.00129428983
Iter: 21 loss: 0.00104711636
Iter: 22 loss: 0.0021132722
Iter: 23 loss: 0.000992057379
Iter: 24 loss: 0.000823257666
Iter: 25 loss: 0.000893068
Iter: 26 loss: 0.000705077546
Iter: 27 loss: 0.000569672033
Iter: 28 loss: 0.00171648047
Iter: 29 loss: 0.000560549379
Iter: 30 loss: 0.000467187434
Iter: 31 loss: 0.00102921634
Iter: 32 loss: 0.00045396568
Iter: 33 loss: 0.000390356756
Iter: 34 loss: 0.000571279088
Iter: 35 loss: 0.000370377209
Iter: 36 loss: 0.000324239867
Iter: 37 loss: 0.000667942455
Iter: 38 loss: 0.000320452207
Iter: 39 loss: 0.000288099487
Iter: 40 loss: 0.000402145699
Iter: 41 loss: 0.000279199157
Iter: 42 loss: 0.000257306092
Iter: 43 loss: 0.000396181946
Iter: 44 loss: 0.000255012274
Iter: 45 loss: 0.000235522399
Iter: 46 loss: 0.000407279207
Iter: 47 loss: 0.00023424362
Iter: 48 loss: 0.000223053881
Iter: 49 loss: 0.000215806824
Iter: 50 loss: 0.000211515551
Iter: 51 loss: 0.000197273184
Iter: 52 loss: 0.000267325027
Iter: 53 loss: 0.000194803084
Iter: 54 loss: 0.00018348411
Iter: 55 loss: 0.000225186377
Iter: 56 loss: 0.000180687668
Iter: 57 loss: 0.000172206288
Iter: 58 loss: 0.00021824539
Iter: 59 loss: 0.000170925574
Iter: 60 loss: 0.000164242898
Iter: 61 loss: 0.000221988987
Iter: 62 loss: 0.000163876495
Iter: 63 loss: 0.000159459334
Iter: 64 loss: 0.000156183596
Iter: 65 loss: 0.000154701018
Iter: 66 loss: 0.000148920284
Iter: 67 loss: 0.000164154044
Iter: 68 loss: 0.000146963721
Iter: 69 loss: 0.000142060962
Iter: 70 loss: 0.000165801583
Iter: 71 loss: 0.000141184617
Iter: 72 loss: 0.000137172319
Iter: 73 loss: 0.000152040622
Iter: 74 loss: 0.000136191331
Iter: 75 loss: 0.000133065318
Iter: 76 loss: 0.000150403066
Iter: 77 loss: 0.000132610381
Iter: 78 loss: 0.000130467379
Iter: 79 loss: 0.000150611362
Iter: 80 loss: 0.000130388304
Iter: 81 loss: 0.000128409592
Iter: 82 loss: 0.000133415015
Iter: 83 loss: 0.000127705862
Iter: 84 loss: 0.000126127037
Iter: 85 loss: 0.000126795698
Iter: 86 loss: 0.000125044695
Iter: 87 loss: 0.000123166174
Iter: 88 loss: 0.000127343781
Iter: 89 loss: 0.000122446072
Iter: 90 loss: 0.000120734985
Iter: 91 loss: 0.000128947213
Iter: 92 loss: 0.000120429875
Iter: 93 loss: 0.000119014861
Iter: 94 loss: 0.000124809536
Iter: 95 loss: 0.000118704513
Iter: 96 loss: 0.000117549032
Iter: 97 loss: 0.000125279708
Iter: 98 loss: 0.000117431497
Iter: 99 loss: 0.000116455667
Iter: 100 loss: 0.000117891082
Iter: 101 loss: 0.000115984338
Iter: 102 loss: 0.000115077608
Iter: 103 loss: 0.000115454124
Iter: 104 loss: 0.000114454655
Iter: 105 loss: 0.000113357681
Iter: 106 loss: 0.000117662101
Iter: 107 loss: 0.000113102789
Iter: 108 loss: 0.000112173031
Iter: 109 loss: 0.000115352093
Iter: 110 loss: 0.000111925183
Iter: 111 loss: 0.000111092711
Iter: 112 loss: 0.000113372727
Iter: 113 loss: 0.000110820314
Iter: 114 loss: 0.000110136629
Iter: 115 loss: 0.000113872891
Iter: 116 loss: 0.000110037821
Iter: 117 loss: 0.000109496461
Iter: 118 loss: 0.000116408351
Iter: 119 loss: 0.000109491593
Iter: 120 loss: 0.000109139975
Iter: 121 loss: 0.000108702399
Iter: 122 loss: 0.00010866567
Iter: 123 loss: 0.000108101674
Iter: 124 loss: 0.000109444336
Iter: 125 loss: 0.000107896776
Iter: 126 loss: 0.000107358428
Iter: 127 loss: 0.000109162094
Iter: 128 loss: 0.000107211934
Iter: 129 loss: 0.000106734689
Iter: 130 loss: 0.000108604159
Iter: 131 loss: 0.000106624779
Iter: 132 loss: 0.000106255924
Iter: 133 loss: 0.000109907443
Iter: 134 loss: 0.00010624346
Iter: 135 loss: 0.000105945699
Iter: 136 loss: 0.000106436491
Iter: 137 loss: 0.000105810206
Iter: 138 loss: 0.000105509404
Iter: 139 loss: 0.000105639207
Iter: 140 loss: 0.000105303756
Iter: 141 loss: 0.000104962128
Iter: 142 loss: 0.000106102707
Iter: 143 loss: 0.000104868835
Iter: 144 loss: 0.000104546416
Iter: 145 loss: 0.000105612831
Iter: 146 loss: 0.000104457591
Iter: 147 loss: 0.000104172621
Iter: 148 loss: 0.00010501733
Iter: 149 loss: 0.000104085491
Iter: 150 loss: 0.000103833612
Iter: 151 loss: 0.000104927691
Iter: 152 loss: 0.00010378263
Iter: 153 loss: 0.00010359718
Iter: 154 loss: 0.000105882253
Iter: 155 loss: 0.000103595055
Iter: 156 loss: 0.00010344683
Iter: 157 loss: 0.000103482489
Iter: 158 loss: 0.000103338447
Iter: 159 loss: 0.000103164399
Iter: 160 loss: 0.000103332961
Iter: 161 loss: 0.000103065191
Iter: 162 loss: 0.000102876991
Iter: 163 loss: 0.000103285725
Iter: 164 loss: 0.000102804013
Iter: 165 loss: 0.000102628532
Iter: 166 loss: 0.000103187871
Iter: 167 loss: 0.000102578357
Iter: 168 loss: 0.000102412494
Iter: 169 loss: 0.000103116559
Iter: 170 loss: 0.000102377729
Iter: 171 loss: 0.000102247737
Iter: 172 loss: 0.000103016995
Iter: 173 loss: 0.000102230952
Iter: 174 loss: 0.000102112026
Iter: 175 loss: 0.000102626043
Iter: 176 loss: 0.000102087564
Iter: 177 loss: 0.000101997532
Iter: 178 loss: 0.00010195675
Iter: 179 loss: 0.000101911559
Iter: 180 loss: 0.000101794831
Iter: 181 loss: 0.000102091282
Iter: 182 loss: 0.000101754311
Iter: 183 loss: 0.00010163671
Iter: 184 loss: 0.000102129197
Iter: 185 loss: 0.000101611608
Iter: 186 loss: 0.000101512313
Iter: 187 loss: 0.000101934143
Iter: 188 loss: 0.000101491678
Iter: 189 loss: 0.000101413942
Iter: 190 loss: 0.00010185899
Iter: 191 loss: 0.000101403399
Iter: 192 loss: 0.000101327256
Iter: 193 loss: 0.000101688507
Iter: 194 loss: 0.000101313657
Iter: 195 loss: 0.000101258083
Iter: 196 loss: 0.000101238831
Iter: 197 loss: 0.000101207377
Iter: 198 loss: 0.000101133111
Iter: 199 loss: 0.000101351296
Iter: 200 loss: 0.000101110192
Iter: 201 loss: 0.000101040059
Iter: 202 loss: 0.000101224898
Iter: 203 loss: 0.000101016602
Iter: 204 loss: 0.000100951918
Iter: 205 loss: 0.000101100537
Iter: 206 loss: 0.000100927718
Iter: 207 loss: 0.000100867968
Iter: 208 loss: 0.000101098616
Iter: 209 loss: 0.000100853809
Iter: 210 loss: 0.000100799109
Iter: 211 loss: 0.000101109908
Iter: 212 loss: 0.000100791483
Iter: 213 loss: 0.000100747086
Iter: 214 loss: 0.000100996011
Iter: 215 loss: 0.000100740755
Iter: 216 loss: 0.000100705292
Iter: 217 loss: 0.000100707432
Iter: 218 loss: 0.000100677498
Iter: 219 loss: 0.00010063457
Iter: 220 loss: 0.000100694429
Iter: 221 loss: 0.000100613237
Iter: 222 loss: 0.000100567428
Iter: 223 loss: 0.000100703473
Iter: 224 loss: 0.000100553531
Iter: 225 loss: 0.000100511941
Iter: 226 loss: 0.000100736564
Iter: 227 loss: 0.000100505757
Iter: 228 loss: 0.000100478494
Iter: 229 loss: 0.000100834091
Iter: 230 loss: 0.000100478479
Iter: 231 loss: 0.000100454577
Iter: 232 loss: 0.000100459583
Iter: 233 loss: 0.00010043662
Iter: 234 loss: 0.000100410296
Iter: 235 loss: 0.000100427686
Iter: 236 loss: 0.000100393423
Iter: 237 loss: 0.000100363235
Iter: 238 loss: 0.000100468038
Iter: 239 loss: 0.000100355319
Iter: 240 loss: 0.000100328682
Iter: 241 loss: 0.000100405567
Iter: 242 loss: 0.000100320292
Iter: 243 loss: 0.000100294586
Iter: 244 loss: 0.000100366189
Iter: 245 loss: 0.00010028627
Iter: 246 loss: 0.000100262099
Iter: 247 loss: 0.000100347301
Iter: 248 loss: 0.000100255871
Iter: 249 loss: 0.000100234742
Iter: 250 loss: 0.000100343408
Iter: 251 loss: 0.000100231468
Iter: 252 loss: 0.000100213772
Iter: 253 loss: 0.000100309975
Iter: 254 loss: 0.000100211211
Iter: 255 loss: 0.000100196048
Iter: 256 loss: 0.00010020128
Iter: 257 loss: 0.000100185454
Iter: 258 loss: 0.000100168138
Iter: 259 loss: 0.00010020005
Iter: 260 loss: 0.000100160658
Iter: 261 loss: 0.000100142206
Iter: 262 loss: 0.000100191493
Iter: 263 loss: 0.000100136196
Iter: 264 loss: 0.000100120458
Iter: 265 loss: 0.000100189645
Iter: 266 loss: 0.00010011749
Iter: 267 loss: 0.000100106619
Iter: 268 loss: 0.000100264457
Iter: 269 loss: 0.000100106561
Iter: 270 loss: 0.000100097088
Iter: 271 loss: 0.00010009457
Iter: 272 loss: 0.000100088801
Iter: 273 loss: 0.000100077828
Iter: 274 loss: 0.000100089106
Iter: 275 loss: 0.000100071753
Iter: 276 loss: 0.000100059064
Iter: 277 loss: 0.000100092511
Iter: 278 loss: 0.00010005472
Iter: 279 loss: 0.000100043049
Iter: 280 loss: 0.000100080812
Iter: 281 loss: 0.000100039702
Iter: 282 loss: 0.000100029225
Iter: 283 loss: 0.000100052668
Iter: 284 loss: 0.000100025136
Iter: 285 loss: 0.000100014942
Iter: 286 loss: 0.000100078047
Iter: 287 loss: 0.000100013654
Iter: 288 loss: 0.000100005331
Iter: 289 loss: 0.000100029822
Iter: 290 loss: 0.000100002828
Iter: 291 loss: 9.99957847e-05
Iter: 292 loss: 0.000100050958
Iter: 293 loss: 9.99951226e-05
Iter: 294 loss: 9.99887561e-05
Iter: 295 loss: 9.99873664e-05
Iter: 296 loss: 9.99832264e-05
Iter: 297 loss: 9.99759068e-05
Iter: 298 loss: 9.99973854e-05
Iter: 299 loss: 9.99736949e-05
Iter: 300 loss: 9.99665572e-05
Iter: 301 loss: 9.99919794e-05
Iter: 302 loss: 9.99648328e-05
Iter: 303 loss: 9.99587501e-05
Iter: 304 loss: 9.99707772e-05
Iter: 305 loss: 9.9956218e-05
Iter: 306 loss: 9.99514377e-05
Iter: 307 loss: 9.99515687e-05
Iter: 308 loss: 9.99478216e-05
Iter: 309 loss: 9.99430849e-05
Iter: 310 loss: 9.99426265e-05
Iter: 311 loss: 9.99370823e-05
Iter: 312 loss: 9.99508047e-05
Iter: 313 loss: 9.9935125e-05
Iter: 314 loss: 9.99294207e-05
Iter: 315 loss: 9.99450567e-05
Iter: 316 loss: 9.99275071e-05
Iter: 317 loss: 9.99221375e-05
Iter: 318 loss: 9.99354161e-05
Iter: 319 loss: 9.99201e-05
Iter: 320 loss: 9.99152107e-05
Iter: 321 loss: 9.99271797e-05
Iter: 322 loss: 9.99133263e-05
Iter: 323 loss: 9.99085241e-05
Iter: 324 loss: 9.99323529e-05
Iter: 325 loss: 9.99076656e-05
Iter: 326 loss: 9.99039476e-05
Iter: 327 loss: 9.99212498e-05
Iter: 328 loss: 9.99029653e-05
Iter: 329 loss: 9.98997057e-05
Iter: 330 loss: 9.99209224e-05
Iter: 331 loss: 9.98993637e-05
Iter: 332 loss: 9.98964824e-05
Iter: 333 loss: 9.99007607e-05
Iter: 334 loss: 9.98950854e-05
Iter: 335 loss: 9.98923206e-05
Iter: 336 loss: 9.98949108e-05
Iter: 337 loss: 9.98905816e-05
Iter: 338 loss: 9.98874311e-05
Iter: 339 loss: 9.98975593e-05
Iter: 340 loss: 9.98864271e-05
Iter: 341 loss: 9.98836622e-05
Iter: 342 loss: 9.98981704e-05
Iter: 343 loss: 9.98832402e-05
Iter: 344 loss: 9.9880941e-05
Iter: 345 loss: 9.99007607e-05
Iter: 346 loss: 9.98806645e-05
Iter: 347 loss: 9.9878831e-05
Iter: 348 loss: 9.98779142e-05
Iter: 349 loss: 9.98771e-05
Iter: 350 loss: 9.98746618e-05
Iter: 351 loss: 9.98776595e-05
Iter: 352 loss: 9.98733158e-05
Iter: 353 loss: 9.98706309e-05
Iter: 354 loss: 9.98806863e-05
Iter: 355 loss: 9.98699252e-05
Iter: 356 loss: 9.98674368e-05
Iter: 357 loss: 9.98713658e-05
Iter: 358 loss: 9.98662799e-05
Iter: 359 loss: 9.98637552e-05
Iter: 360 loss: 9.98719333e-05
Iter: 361 loss: 9.98630421e-05
Iter: 362 loss: 9.98608812e-05
Iter: 363 loss: 9.98695396e-05
Iter: 364 loss: 9.98603209e-05
Iter: 365 loss: 9.98582473e-05
Iter: 366 loss: 9.98630785e-05
Iter: 367 loss: 9.98575415e-05
Iter: 368 loss: 9.98558316e-05
Iter: 369 loss: 9.9870842e-05
Iter: 370 loss: 9.98556061e-05
Iter: 371 loss: 9.98541655e-05
Iter: 372 loss: 9.98595715e-05
Iter: 373 loss: 9.98538e-05
Iter: 374 loss: 9.98523537e-05
Iter: 375 loss: 9.98536e-05
Iter: 376 loss: 9.98515825e-05
Iter: 377 loss: 9.98501e-05
Iter: 378 loss: 9.98521209e-05
Iter: 379 loss: 9.98492906e-05
Iter: 380 loss: 9.98478572e-05
Iter: 381 loss: 9.98593e-05
Iter: 382 loss: 9.98477481e-05
Iter: 383 loss: 9.98465403e-05
Iter: 384 loss: 9.98532851e-05
Iter: 385 loss: 9.98464238e-05
Iter: 386 loss: 9.98454925e-05
Iter: 387 loss: 9.98455434e-05
Iter: 388 loss: 9.98445757e-05
Iter: 389 loss: 9.98434261e-05
Iter: 390 loss: 9.98449686e-05
Iter: 391 loss: 9.98428877e-05
Iter: 392 loss: 9.98414616e-05
Iter: 393 loss: 9.98442847e-05
Iter: 394 loss: 9.98409232e-05
Iter: 395 loss: 9.98395772e-05
Iter: 396 loss: 9.98444593e-05
Iter: 397 loss: 9.98392425e-05
Iter: 398 loss: 9.98380783e-05
Iter: 399 loss: 9.98414689e-05
Iter: 400 loss: 9.98377509e-05
Iter: 401 loss: 9.98365213e-05
Iter: 402 loss: 9.98391042e-05
Iter: 403 loss: 9.98360338e-05
Iter: 404 loss: 9.98350297e-05
Iter: 405 loss: 9.98378673e-05
Iter: 406 loss: 9.9834615e-05
Iter: 407 loss: 9.98335163e-05
Iter: 408 loss: 9.98369651e-05
Iter: 409 loss: 9.98331889e-05
Iter: 410 loss: 9.98322648e-05
Iter: 411 loss: 9.98409159e-05
Iter: 412 loss: 9.98322721e-05
Iter: 413 loss: 9.98314208e-05
Iter: 414 loss: 9.98334071e-05
Iter: 415 loss: 9.98311953e-05
Iter: 416 loss: 9.98303876e-05
Iter: 417 loss: 9.98312753e-05
Iter: 418 loss: 9.9830082e-05
Iter: 419 loss: 9.98292526e-05
Iter: 420 loss: 9.98313626e-05
Iter: 421 loss: 9.98291362e-05
Iter: 422 loss: 9.98285541e-05
Iter: 423 loss: 9.98353644e-05
Iter: 424 loss: 9.98284377e-05
Iter: 425 loss: 9.9827972e-05
Iter: 426 loss: 9.98280884e-05
Iter: 427 loss: 9.98276228e-05
Iter: 428 loss: 9.98269534e-05
Iter: 429 loss: 9.98272299e-05
Iter: 430 loss: 9.98266041e-05
Iter: 431 loss: 9.98258038e-05
Iter: 432 loss: 9.98287214e-05
Iter: 433 loss: 9.98255782e-05
Iter: 434 loss: 9.98251198e-05
Iter: 435 loss: 9.98259711e-05
Iter: 436 loss: 9.98246687e-05
Iter: 437 loss: 9.98239411e-05
Iter: 438 loss: 9.98265314e-05
Iter: 439 loss: 9.98237811e-05
Iter: 440 loss: 9.98232426e-05
Iter: 441 loss: 9.9824676e-05
Iter: 442 loss: 9.98229661e-05
Iter: 443 loss: 9.98223913e-05
Iter: 444 loss: 9.98244213e-05
Iter: 445 loss: 9.9822224e-05
Iter: 446 loss: 9.98216929e-05
Iter: 447 loss: 9.98231e-05
Iter: 448 loss: 9.98214164e-05
Iter: 449 loss: 9.98208561e-05
Iter: 450 loss: 9.98220785e-05
Iter: 451 loss: 9.98205651e-05
Iter: 452 loss: 9.98202377e-05
Iter: 453 loss: 9.98226678e-05
Iter: 454 loss: 9.98199102e-05
Iter: 455 loss: 9.98196047e-05
Iter: 456 loss: 9.98238611e-05
Iter: 457 loss: 9.98194955e-05
Iter: 458 loss: 9.98192118e-05
Iter: 459 loss: 9.98196774e-05
Iter: 460 loss: 9.98190371e-05
Iter: 461 loss: 9.98187e-05
Iter: 462 loss: 9.982e-05
Iter: 463 loss: 9.98185569e-05
Iter: 464 loss: 9.98182368e-05
Iter: 465 loss: 9.98200048e-05
Iter: 466 loss: 9.98181058e-05
Iter: 467 loss: 9.98179166e-05
Iter: 468 loss: 9.98177347e-05
Iter: 469 loss: 9.98175819e-05
Iter: 470 loss: 9.98173928e-05
Iter: 471 loss: 9.98184e-05
Iter: 472 loss: 9.98170581e-05
Iter: 473 loss: 9.98167234e-05
Iter: 474 loss: 9.98180039e-05
Iter: 475 loss: 9.98166506e-05
Iter: 476 loss: 9.9816345e-05
Iter: 477 loss: 9.98172e-05
Iter: 478 loss: 9.98162359e-05
Iter: 479 loss: 9.98157775e-05
Iter: 480 loss: 9.9816476e-05
Iter: 481 loss: 9.98157702e-05
Iter: 482 loss: 9.98154137e-05
Iter: 483 loss: 9.98170435e-05
Iter: 484 loss: 9.981537e-05
Iter: 485 loss: 9.98150426e-05
Iter: 486 loss: 9.98155447e-05
Iter: 487 loss: 9.98148462e-05
Iter: 488 loss: 9.98145333e-05
Iter: 489 loss: 9.98151809e-05
Iter: 490 loss: 9.98145e-05
Iter: 491 loss: 9.98142641e-05
Iter: 492 loss: 9.98152245e-05
Iter: 493 loss: 9.98140313e-05
Iter: 494 loss: 9.98138057e-05
Iter: 495 loss: 9.98151518e-05
Iter: 496 loss: 9.98139149e-05
Iter: 497 loss: 9.98135292e-05
Iter: 498 loss: 9.98156e-05
Iter: 499 loss: 9.98135365e-05
Iter: 500 loss: 9.98134637e-05
Iter: 501 loss: 9.98136093e-05
Iter: 502 loss: 9.98133473e-05
Iter: 503 loss: 9.98130345e-05
Iter: 504 loss: 9.981326e-05
Iter: 505 loss: 9.9812969e-05
Iter: 506 loss: 9.98129399e-05
Iter: 507 loss: 9.98146061e-05
Iter: 508 loss: 9.98127362e-05
Iter: 509 loss: 9.98127143e-05
Iter: 510 loss: 9.98128962e-05
Iter: 511 loss: 9.98125e-05
Iter: 512 loss: 9.98123869e-05
Iter: 513 loss: 9.98126634e-05
Iter: 514 loss: 9.98124306e-05
Iter: 515 loss: 9.98122632e-05
Iter: 516 loss: 9.98126779e-05
Iter: 517 loss: 9.9812125e-05
Iter: 518 loss: 9.9811863e-05
Iter: 519 loss: 9.98122e-05
Iter: 520 loss: 9.98118048e-05
Iter: 521 loss: 9.98118194e-05
Iter: 522 loss: 9.98125615e-05
Iter: 523 loss: 9.98116302e-05
Iter: 524 loss: 9.98114556e-05
Iter: 525 loss: 9.9811652e-05
Iter: 526 loss: 9.98114701e-05
Iter: 527 loss: 9.98113246e-05
Iter: 528 loss: 9.98120886e-05
Iter: 529 loss: 9.9811281e-05
Iter: 530 loss: 9.981115e-05
Iter: 531 loss: 9.98113828e-05
Iter: 532 loss: 9.98110627e-05
Iter: 533 loss: 9.98109172e-05
Iter: 534 loss: 9.98112446e-05
Iter: 535 loss: 9.98108735e-05
Iter: 536 loss: 9.98106916e-05
Iter: 537 loss: 9.98115065e-05
Iter: 538 loss: 9.98105679e-05
Iter: 539 loss: 9.98105534e-05
Iter: 540 loss: 9.98118121e-05
Iter: 541 loss: 9.98105461e-05
Iter: 542 loss: 9.98104442e-05
Iter: 543 loss: 9.98103424e-05
Iter: 544 loss: 9.98103787e-05
Iter: 545 loss: 9.98103642e-05
Iter: 546 loss: 9.98104e-05
Iter: 547 loss: 9.98103205e-05
Iter: 548 loss: 9.98101386e-05
Iter: 549 loss: 9.98103933e-05
Iter: 550 loss: 9.98101532e-05
Iter: 551 loss: 9.98100732e-05
Iter: 552 loss: 9.98105243e-05
Iter: 553 loss: 9.98100149e-05
Iter: 554 loss: 9.98099276e-05
Iter: 555 loss: 9.98104952e-05
Iter: 556 loss: 9.98100295e-05
Iter: 557 loss: 9.98098185e-05
Iter: 558 loss: 9.98099058e-05
Iter: 559 loss: 9.98097821e-05
Iter: 560 loss: 9.98096511e-05
Iter: 561 loss: 9.98098549e-05
Iter: 562 loss: 9.98096875e-05
Iter: 563 loss: 9.98097e-05
Iter: 564 loss: 9.98097239e-05
Iter: 565 loss: 9.98095929e-05
Iter: 566 loss: 9.98094183e-05
Iter: 567 loss: 9.98098258e-05
Iter: 568 loss: 9.98094329e-05
Iter: 569 loss: 9.98093601e-05
Iter: 570 loss: 9.98096948e-05
Iter: 571 loss: 9.98093092e-05
Iter: 572 loss: 9.98091273e-05
Iter: 573 loss: 9.98094256e-05
Iter: 574 loss: 9.98091709e-05
Iter: 575 loss: 9.98091418e-05
Iter: 576 loss: 9.98092728e-05
Iter: 577 loss: 9.98090545e-05
Iter: 578 loss: 9.98089963e-05
Iter: 579 loss: 9.98097094e-05
Iter: 580 loss: 9.98090181e-05
Iter: 581 loss: 9.98090836e-05
Iter: 582 loss: 9.98092291e-05
Iter: 583 loss: 9.98089745e-05
Iter: 584 loss: 9.9808909e-05
Iter: 585 loss: 9.9808909e-05
Iter: 586 loss: 9.98087853e-05
Iter: 587 loss: 9.98087635e-05
Iter: 588 loss: 9.98087489e-05
Iter: 589 loss: 9.98088217e-05
Iter: 590 loss: 9.98087562e-05
Iter: 591 loss: 9.98089599e-05
Iter: 592 loss: 9.9808618e-05
Iter: 593 loss: 9.98087489e-05
Iter: 594 loss: 9.98087053e-05
Iter: 595 loss: 9.98087198e-05
Iter: 596 loss: 9.98086e-05
Iter: 597 loss: 9.98088071e-05
Iter: 598 loss: 9.98087125e-05
Iter: 599 loss: 9.98087053e-05
Iter: 600 loss: 9.98087053e-05
Iter: 601 loss: 9.98086616e-05
Iter: 602 loss: 9.98087489e-05
Iter: 603 loss: 9.98087125e-05
Iter: 604 loss: 9.98087417e-05
Iter: 605 loss: 9.98087271e-05
Iter: 606 loss: 9.98087344e-05
Iter: 607 loss: 9.98087125e-05
Iter: 608 loss: 9.98087344e-05
Iter: 609 loss: 9.98087489e-05
Iter: 610 loss: 9.98087417e-05
Iter: 611 loss: 9.98087344e-05
Iter: 612 loss: 9.98087344e-05
Iter: 613 loss: 9.98087053e-05
Iter: 614 loss: 9.98087344e-05
Iter: 615 loss: 9.98087053e-05
Iter: 616 loss: 9.98087344e-05
Iter: 617 loss: 9.98087344e-05
Iter: 618 loss: 9.98087053e-05
Iter: 619 loss: 9.9808618e-05
Iter: 620 loss: 9.98090545e-05
Iter: 621 loss: 9.98085889e-05
Iter: 622 loss: 9.98086543e-05
Iter: 623 loss: 9.98085889e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2
+ date
Tue Oct 27 15:04:43 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421ddd70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421ddd7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dd6a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dd729d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dce4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dd72ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dce4e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dc78840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dc78158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dc160d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dbd5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421db8a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421db8a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421db8a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421db779d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421db06ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421db24400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421db24d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421da88840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421da886a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dab5510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421dab5d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421da28950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421da287b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421da28a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d97eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d9b6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d959268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d959840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d902488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d902510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d9028c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f421d8f1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41ff42b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41ff3eda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41ff411268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0192797538
Iter: 2 loss: 0.0180350058
Iter: 3 loss: 0.014102906
Iter: 4 loss: 6643.39893
Iter: 5 loss: 0.0141029041
Iter: 6 loss: 0.0116616832
Iter: 7 loss: 0.0110263284
Iter: 8 loss: 0.0083297072
Iter: 9 loss: 0.109618157
Iter: 10 loss: 0.00832626596
Iter: 11 loss: 0.00603878871
Iter: 12 loss: 0.0236465819
Iter: 13 loss: 0.00578230713
Iter: 14 loss: 0.00432697497
Iter: 15 loss: 0.0144470315
Iter: 16 loss: 0.00422486197
Iter: 17 loss: 0.00344682345
Iter: 18 loss: 0.00454772683
Iter: 19 loss: 0.002962003
Iter: 20 loss: 0.00234898739
Iter: 21 loss: 0.00234892638
Iter: 22 loss: 0.00198957021
Iter: 23 loss: 0.00296166446
Iter: 24 loss: 0.00189306459
Iter: 25 loss: 0.00171645149
Iter: 26 loss: 0.00188627327
Iter: 27 loss: 0.00160518149
Iter: 28 loss: 0.00140736345
Iter: 29 loss: 0.00176694524
Iter: 30 loss: 0.00131743704
Iter: 31 loss: 0.00113165355
Iter: 32 loss: 0.00210934225
Iter: 33 loss: 0.00109984551
Iter: 34 loss: 0.000963477651
Iter: 35 loss: 0.00161158957
Iter: 36 loss: 0.000936321099
Iter: 37 loss: 0.000829395547
Iter: 38 loss: 0.00126507715
Iter: 39 loss: 0.000803874398
Iter: 40 loss: 0.000728916901
Iter: 41 loss: 0.00105526485
Iter: 42 loss: 0.00071228249
Iter: 43 loss: 0.000650152448
Iter: 44 loss: 0.000772560772
Iter: 45 loss: 0.000623490196
Iter: 46 loss: 0.000559733075
Iter: 47 loss: 0.000916468096
Iter: 48 loss: 0.000550738943
Iter: 49 loss: 0.000506115321
Iter: 50 loss: 0.000628970563
Iter: 51 loss: 0.000491005369
Iter: 52 loss: 0.000448890496
Iter: 53 loss: 0.000583443441
Iter: 54 loss: 0.000436102739
Iter: 55 loss: 0.000406020205
Iter: 56 loss: 0.000780485
Iter: 57 loss: 0.000405838568
Iter: 58 loss: 0.000384750951
Iter: 59 loss: 0.000559522712
Iter: 60 loss: 0.000382937375
Iter: 61 loss: 0.00036585721
Iter: 62 loss: 0.000352051604
Iter: 63 loss: 0.00034702415
Iter: 64 loss: 0.00032174302
Iter: 65 loss: 0.000425535138
Iter: 66 loss: 0.000316065474
Iter: 67 loss: 0.000297058607
Iter: 68 loss: 0.000379533391
Iter: 69 loss: 0.000293082965
Iter: 70 loss: 0.000279167725
Iter: 71 loss: 0.000367960747
Iter: 72 loss: 0.000277612795
Iter: 73 loss: 0.000265314651
Iter: 74 loss: 0.000304358429
Iter: 75 loss: 0.000261755515
Iter: 76 loss: 0.000252133235
Iter: 77 loss: 0.00027637629
Iter: 78 loss: 0.000248825381
Iter: 79 loss: 0.00023967473
Iter: 80 loss: 0.000252098136
Iter: 81 loss: 0.000235049389
Iter: 82 loss: 0.000225563315
Iter: 83 loss: 0.000263410446
Iter: 84 loss: 0.000223375479
Iter: 85 loss: 0.000214850297
Iter: 86 loss: 0.000268427772
Iter: 87 loss: 0.000213857478
Iter: 88 loss: 0.00020707662
Iter: 89 loss: 0.00021492182
Iter: 90 loss: 0.000203441683
Iter: 91 loss: 0.000198689522
Iter: 92 loss: 0.000198606023
Iter: 93 loss: 0.000194585184
Iter: 94 loss: 0.000210117301
Iter: 95 loss: 0.000193590764
Iter: 96 loss: 0.000190071092
Iter: 97 loss: 0.000186342804
Iter: 98 loss: 0.000185715558
Iter: 99 loss: 0.000180264935
Iter: 100 loss: 0.000193225045
Iter: 101 loss: 0.000178254049
Iter: 102 loss: 0.000173270586
Iter: 103 loss: 0.000191525076
Iter: 104 loss: 0.000172022497
Iter: 105 loss: 0.000167540857
Iter: 106 loss: 0.00018204411
Iter: 107 loss: 0.00016626688
Iter: 108 loss: 0.000163009419
Iter: 109 loss: 0.000198360576
Iter: 110 loss: 0.000162931072
Iter: 111 loss: 0.000160132
Iter: 112 loss: 0.000162970304
Iter: 113 loss: 0.000158564901
Iter: 114 loss: 0.000155814691
Iter: 115 loss: 0.000164916652
Iter: 116 loss: 0.000155057351
Iter: 117 loss: 0.000152284978
Iter: 118 loss: 0.000155371585
Iter: 119 loss: 0.000150772219
Iter: 120 loss: 0.00014809618
Iter: 121 loss: 0.000158000767
Iter: 122 loss: 0.000147435028
Iter: 123 loss: 0.000145121157
Iter: 124 loss: 0.000155388319
Iter: 125 loss: 0.000144650025
Iter: 126 loss: 0.000143233949
Iter: 127 loss: 0.000143188459
Iter: 128 loss: 0.000141984739
Iter: 129 loss: 0.000141691969
Iter: 130 loss: 0.000140921271
Iter: 131 loss: 0.000139525015
Iter: 132 loss: 0.000138910807
Iter: 133 loss: 0.000138200834
Iter: 134 loss: 0.000136400457
Iter: 135 loss: 0.000144412916
Iter: 136 loss: 0.000136044386
Iter: 137 loss: 0.000134450529
Iter: 138 loss: 0.000139463285
Iter: 139 loss: 0.000133989219
Iter: 140 loss: 0.000132582281
Iter: 141 loss: 0.000135972266
Iter: 142 loss: 0.000132072426
Iter: 143 loss: 0.000130693021
Iter: 144 loss: 0.000140384436
Iter: 145 loss: 0.000130565735
Iter: 146 loss: 0.000129509775
Iter: 147 loss: 0.000130197426
Iter: 148 loss: 0.000128841319
Iter: 149 loss: 0.000127687177
Iter: 150 loss: 0.000134007336
Iter: 151 loss: 0.00012751724
Iter: 152 loss: 0.000126645115
Iter: 153 loss: 0.000133043679
Iter: 154 loss: 0.000126572268
Iter: 155 loss: 0.000125834529
Iter: 156 loss: 0.000126109022
Iter: 157 loss: 0.000125319741
Iter: 158 loss: 0.000124467828
Iter: 159 loss: 0.000126477215
Iter: 160 loss: 0.00012415307
Iter: 161 loss: 0.00012367325
Iter: 162 loss: 0.000123615435
Iter: 163 loss: 0.000123202728
Iter: 164 loss: 0.000122835132
Iter: 165 loss: 0.000122728583
Iter: 166 loss: 0.000122095254
Iter: 167 loss: 0.000122070327
Iter: 168 loss: 0.000121581594
Iter: 169 loss: 0.000120824523
Iter: 170 loss: 0.000121501347
Iter: 171 loss: 0.000120383876
Iter: 172 loss: 0.000119518751
Iter: 173 loss: 0.000124080776
Iter: 174 loss: 0.000119383221
Iter: 175 loss: 0.000118687982
Iter: 176 loss: 0.000121730889
Iter: 177 loss: 0.000118547745
Iter: 178 loss: 0.000117924428
Iter: 179 loss: 0.00011969106
Iter: 180 loss: 0.000117726784
Iter: 181 loss: 0.000117106771
Iter: 182 loss: 0.000119329699
Iter: 183 loss: 0.000116948882
Iter: 184 loss: 0.000116388561
Iter: 185 loss: 0.000117945019
Iter: 186 loss: 0.000116208015
Iter: 187 loss: 0.000115734227
Iter: 188 loss: 0.000119355558
Iter: 189 loss: 0.000115698436
Iter: 190 loss: 0.000115294293
Iter: 191 loss: 0.000115586648
Iter: 192 loss: 0.000115045048
Iter: 193 loss: 0.000114631359
Iter: 194 loss: 0.000116939344
Iter: 195 loss: 0.000114571179
Iter: 196 loss: 0.000114172697
Iter: 197 loss: 0.000116831579
Iter: 198 loss: 0.000114133094
Iter: 199 loss: 0.000113851806
Iter: 200 loss: 0.000113839662
Iter: 201 loss: 0.000113622533
Iter: 202 loss: 0.000113302427
Iter: 203 loss: 0.0001131381
Iter: 204 loss: 0.000112989277
Iter: 205 loss: 0.000112517024
Iter: 206 loss: 0.000114322298
Iter: 207 loss: 0.000112404916
Iter: 208 loss: 0.000111989058
Iter: 209 loss: 0.000113709364
Iter: 210 loss: 0.000111899011
Iter: 211 loss: 0.000111538255
Iter: 212 loss: 0.000112276262
Iter: 213 loss: 0.000111392961
Iter: 214 loss: 0.000111013156
Iter: 215 loss: 0.000112439157
Iter: 216 loss: 0.000110920941
Iter: 217 loss: 0.000110559711
Iter: 218 loss: 0.000111304529
Iter: 219 loss: 0.000110415174
Iter: 220 loss: 0.000110080313
Iter: 221 loss: 0.000111958609
Iter: 222 loss: 0.000110033368
Iter: 223 loss: 0.00010974102
Iter: 224 loss: 0.000111087385
Iter: 225 loss: 0.000109685614
Iter: 226 loss: 0.000109431021
Iter: 227 loss: 0.000109860914
Iter: 228 loss: 0.000109316592
Iter: 229 loss: 0.0001090886
Iter: 230 loss: 0.000111734786
Iter: 231 loss: 0.00010908478
Iter: 232 loss: 0.000108898959
Iter: 233 loss: 0.000109175489
Iter: 234 loss: 0.0001088102
Iter: 235 loss: 0.000108628941
Iter: 236 loss: 0.000108526496
Iter: 237 loss: 0.000108448017
Iter: 238 loss: 0.000108188135
Iter: 239 loss: 0.000108716697
Iter: 240 loss: 0.000108083375
Iter: 241 loss: 0.000107817425
Iter: 242 loss: 0.000108234206
Iter: 243 loss: 0.000107692962
Iter: 244 loss: 0.000107425665
Iter: 245 loss: 0.000108494671
Iter: 246 loss: 0.000107365908
Iter: 247 loss: 0.000107144937
Iter: 248 loss: 0.000108366898
Iter: 249 loss: 0.00010711317
Iter: 250 loss: 0.000106915519
Iter: 251 loss: 0.000107337677
Iter: 252 loss: 0.000106838408
Iter: 253 loss: 0.00010664649
Iter: 254 loss: 0.000106971442
Iter: 255 loss: 0.000106560401
Iter: 256 loss: 0.000106386142
Iter: 257 loss: 0.000108254397
Iter: 258 loss: 0.000106382126
Iter: 259 loss: 0.000106244494
Iter: 260 loss: 0.000106516236
Iter: 261 loss: 0.000106187756
Iter: 262 loss: 0.000106054416
Iter: 263 loss: 0.000106796302
Iter: 264 loss: 0.000106035754
Iter: 265 loss: 0.000105924526
Iter: 266 loss: 0.000106686632
Iter: 267 loss: 0.000105913619
Iter: 268 loss: 0.000105828418
Iter: 269 loss: 0.000105708175
Iter: 270 loss: 0.000105703846
Iter: 271 loss: 0.000105553299
Iter: 272 loss: 0.000106181782
Iter: 273 loss: 0.000105521052
Iter: 274 loss: 0.000105402083
Iter: 275 loss: 0.000105429557
Iter: 276 loss: 0.000105314852
Iter: 277 loss: 0.000105158033
Iter: 278 loss: 0.000105997693
Iter: 279 loss: 0.000105134422
Iter: 280 loss: 0.00010501509
Iter: 281 loss: 0.0001051789
Iter: 282 loss: 0.000104955747
Iter: 283 loss: 0.00010482475
Iter: 284 loss: 0.000105500207
Iter: 285 loss: 0.00010480365
Iter: 286 loss: 0.000104686755
Iter: 287 loss: 0.000104855993
Iter: 288 loss: 0.000104629871
Iter: 289 loss: 0.000104515508
Iter: 290 loss: 0.000104982464
Iter: 291 loss: 0.000104490166
Iter: 292 loss: 0.000104398736
Iter: 293 loss: 0.000105214764
Iter: 294 loss: 0.000104394407
Iter: 295 loss: 0.000104312487
Iter: 296 loss: 0.000104412677
Iter: 297 loss: 0.000104269515
Iter: 298 loss: 0.000104202598
Iter: 299 loss: 0.000104202678
Iter: 300 loss: 0.00010415008
Iter: 301 loss: 0.000104092236
Iter: 302 loss: 0.000104083891
Iter: 303 loss: 0.000104000443
Iter: 304 loss: 0.000104225037
Iter: 305 loss: 0.000103972881
Iter: 306 loss: 0.000103896964
Iter: 307 loss: 0.000103907456
Iter: 308 loss: 0.000103839287
Iter: 309 loss: 0.000103744103
Iter: 310 loss: 0.000104176412
Iter: 311 loss: 0.000103725579
Iter: 312 loss: 0.000103641971
Iter: 313 loss: 0.000103838291
Iter: 314 loss: 0.000103611019
Iter: 315 loss: 0.000103532926
Iter: 316 loss: 0.000103817933
Iter: 317 loss: 0.000103513259
Iter: 318 loss: 0.000103441256
Iter: 319 loss: 0.00010371708
Iter: 320 loss: 0.000103424187
Iter: 321 loss: 0.000103360937
Iter: 322 loss: 0.000103430961
Iter: 323 loss: 0.00010332658
Iter: 324 loss: 0.00010326373
Iter: 325 loss: 0.000103675033
Iter: 326 loss: 0.000103257131
Iter: 327 loss: 0.000103205384
Iter: 328 loss: 0.00010357071
Iter: 329 loss: 0.000103200691
Iter: 330 loss: 0.000103162354
Iter: 331 loss: 0.000103311351
Iter: 332 loss: 0.000103153427
Iter: 333 loss: 0.000103111241
Iter: 334 loss: 0.000103227809
Iter: 335 loss: 0.000103097664
Iter: 336 loss: 0.000103062674
Iter: 337 loss: 0.000103064849
Iter: 338 loss: 0.000103035309
Iter: 339 loss: 0.000102991893
Iter: 340 loss: 0.000103029481
Iter: 341 loss: 0.000102966442
Iter: 342 loss: 0.000102916754
Iter: 343 loss: 0.000103124432
Iter: 344 loss: 0.000102906328
Iter: 345 loss: 0.000102863596
Iter: 346 loss: 0.000102952181
Iter: 347 loss: 0.00010284657
Iter: 348 loss: 0.00010280429
Iter: 349 loss: 0.000102948688
Iter: 350 loss: 0.00010279307
Iter: 351 loss: 0.000102751146
Iter: 352 loss: 0.000102841361
Iter: 353 loss: 0.000102734964
Iter: 354 loss: 0.000102691942
Iter: 355 loss: 0.000102787468
Iter: 356 loss: 0.000102675658
Iter: 357 loss: 0.000102633858
Iter: 358 loss: 0.000102727274
Iter: 359 loss: 0.000102618156
Iter: 360 loss: 0.000102582155
Iter: 361 loss: 0.000102973645
Iter: 362 loss: 0.000102581398
Iter: 363 loss: 0.00010255236
Iter: 364 loss: 0.000102689446
Iter: 365 loss: 0.000102547318
Iter: 366 loss: 0.000102523394
Iter: 367 loss: 0.000102654732
Iter: 368 loss: 0.000102519698
Iter: 369 loss: 0.000102498627
Iter: 370 loss: 0.000102495396
Iter: 371 loss: 0.000102480793
Iter: 372 loss: 0.000102455408
Iter: 373 loss: 0.000102462669
Iter: 374 loss: 0.000102437138
Iter: 375 loss: 0.000102405102
Iter: 376 loss: 0.000102557955
Iter: 377 loss: 0.000102399426
Iter: 378 loss: 0.000102371894
Iter: 379 loss: 0.000102393606
Iter: 380 loss: 0.000102355072
Iter: 381 loss: 0.000102325481
Iter: 382 loss: 0.000102464866
Iter: 383 loss: 0.000102320017
Iter: 384 loss: 0.00010229295
Iter: 385 loss: 0.000102366459
Iter: 386 loss: 0.000102284233
Iter: 387 loss: 0.000102257596
Iter: 388 loss: 0.000102306214
Iter: 389 loss: 0.000102246115
Iter: 390 loss: 0.000102218641
Iter: 391 loss: 0.00010231544
Iter: 392 loss: 0.000102211379
Iter: 393 loss: 0.000102187638
Iter: 394 loss: 0.000102263279
Iter: 395 loss: 0.000102180624
Iter: 396 loss: 0.00010216111
Iter: 397 loss: 0.000102374848
Iter: 398 loss: 0.000102160739
Iter: 399 loss: 0.00010214527
Iter: 400 loss: 0.00010221784
Iter: 401 loss: 0.000102142556
Iter: 402 loss: 0.000102128412
Iter: 403 loss: 0.00010214826
Iter: 404 loss: 0.000102121456
Iter: 405 loss: 0.000102106962
Iter: 406 loss: 0.000102115315
Iter: 407 loss: 0.000102097569
Iter: 408 loss: 0.000102080783
Iter: 409 loss: 0.000102095823
Iter: 410 loss: 0.00010207099
Iter: 411 loss: 0.00010205021
Iter: 412 loss: 0.000102101112
Iter: 413 loss: 0.000102042541
Iter: 414 loss: 0.000102022561
Iter: 415 loss: 0.000102073172
Iter: 416 loss: 0.000102015663
Iter: 417 loss: 0.000101996869
Iter: 418 loss: 0.000102073638
Iter: 419 loss: 0.000101992569
Iter: 420 loss: 0.000101975093
Iter: 421 loss: 0.00010202796
Iter: 422 loss: 0.000101969803
Iter: 423 loss: 0.000101953439
Iter: 424 loss: 0.000102003629
Iter: 425 loss: 0.000101948426
Iter: 426 loss: 0.000101934
Iter: 427 loss: 0.00010193757
Iter: 428 loss: 0.000101923608
Iter: 429 loss: 0.000101909827
Iter: 430 loss: 0.000102120262
Iter: 431 loss: 0.000101909776
Iter: 432 loss: 0.000101899117
Iter: 433 loss: 0.000101972124
Iter: 434 loss: 0.000101897938
Iter: 435 loss: 0.000101889222
Iter: 436 loss: 0.000101912039
Iter: 437 loss: 0.000101886122
Iter: 438 loss: 0.000101877769
Iter: 439 loss: 0.000101879319
Iter: 440 loss: 0.000101871658
Iter: 441 loss: 0.000101859929
Iter: 442 loss: 0.000101867838
Iter: 443 loss: 0.000101852624
Iter: 444 loss: 0.000101840138
Iter: 445 loss: 0.000101866899
Iter: 446 loss: 0.000101835132
Iter: 447 loss: 0.000101822385
Iter: 448 loss: 0.000101870246
Iter: 449 loss: 0.000101819242
Iter: 450 loss: 0.000101807993
Iter: 451 loss: 0.000101829137
Iter: 452 loss: 0.000101803045
Iter: 453 loss: 0.000101791244
Iter: 454 loss: 0.000101846614
Iter: 455 loss: 0.000101789214
Iter: 456 loss: 0.000101779209
Iter: 457 loss: 0.000101811864
Iter: 458 loss: 0.000101776634
Iter: 459 loss: 0.000101767102
Iter: 460 loss: 0.00010177504
Iter: 461 loss: 0.000101761754
Iter: 462 loss: 0.000101752186
Iter: 463 loss: 0.000101796795
Iter: 464 loss: 0.000101750396
Iter: 465 loss: 0.000101742888
Iter: 466 loss: 0.000101842779
Iter: 467 loss: 0.000101742902
Iter: 468 loss: 0.000101736863
Iter: 469 loss: 0.000101756559
Iter: 470 loss: 0.000101735044
Iter: 471 loss: 0.000101729791
Iter: 472 loss: 0.000101732468
Iter: 473 loss: 0.000101726349
Iter: 474 loss: 0.000101719321
Iter: 475 loss: 0.000101726764
Iter: 476 loss: 0.000101715486
Iter: 477 loss: 0.000101708167
Iter: 478 loss: 0.000101719153
Iter: 479 loss: 0.000101704485
Iter: 480 loss: 0.000101696292
Iter: 481 loss: 0.000101718877
Iter: 482 loss: 0.00010169352
Iter: 483 loss: 0.000101685859
Iter: 484 loss: 0.000101701138
Iter: 485 loss: 0.000101682614
Iter: 486 loss: 0.000101674617
Iter: 487 loss: 0.000101694299
Iter: 488 loss: 0.000101671736
Iter: 489 loss: 0.000101664336
Iter: 490 loss: 0.000101713653
Iter: 491 loss: 0.000101663565
Iter: 492 loss: 0.000101656944
Iter: 493 loss: 0.000101661186
Iter: 494 loss: 0.000101652869
Iter: 495 loss: 0.000101645644
Iter: 496 loss: 0.000101682352
Iter: 497 loss: 0.000101644553
Iter: 498 loss: 0.000101638769
Iter: 499 loss: 0.000101660538
Iter: 500 loss: 0.000101637546
Iter: 501 loss: 0.000101632155
Iter: 502 loss: 0.000101695601
Iter: 503 loss: 0.000101632118
Iter: 504 loss: 0.000101628561
Iter: 505 loss: 0.000101629848
Iter: 506 loss: 0.000101625948
Iter: 507 loss: 0.00010162151
Iter: 508 loss: 0.000101625134
Iter: 509 loss: 0.000101618978
Iter: 510 loss: 0.000101613557
Iter: 511 loss: 0.000101630649
Iter: 512 loss: 0.000101612059
Iter: 513 loss: 0.000101607438
Iter: 514 loss: 0.000101609112
Iter: 515 loss: 0.00010160431
Iter: 516 loss: 0.000101598489
Iter: 517 loss: 0.000101614991
Iter: 518 loss: 0.000101596503
Iter: 519 loss: 0.000101591315
Iter: 520 loss: 0.000101603873
Iter: 521 loss: 0.000101589329
Iter: 522 loss: 0.000101583995
Iter: 523 loss: 0.000101609679
Iter: 524 loss: 0.00010158294
Iter: 525 loss: 0.000101578495
Iter: 526 loss: 0.00010158986
Iter: 527 loss: 0.00010157701
Iter: 528 loss: 0.000101572463
Iter: 529 loss: 0.000101592479
Iter: 530 loss: 0.00010157151
Iter: 531 loss: 0.000101567937
Iter: 532 loss: 0.000101572034
Iter: 533 loss: 0.000101565878
Iter: 534 loss: 0.00010156379
Iter: 535 loss: 0.000101563404
Iter: 536 loss: 0.000101561302
Iter: 537 loss: 0.000101561083
Iter: 538 loss: 0.000101559628
Iter: 539 loss: 0.000101556841
Iter: 540 loss: 0.00010156
Iter: 541 loss: 0.000101555241
Iter: 542 loss: 0.000101552258
Iter: 543 loss: 0.00010156184
Iter: 544 loss: 0.000101551093
Iter: 545 loss: 0.000101548219
Iter: 546 loss: 0.000101550468
Iter: 547 loss: 0.000101546328
Iter: 548 loss: 0.00010154277
Iter: 549 loss: 0.000101551341
Iter: 550 loss: 0.000101541453
Iter: 551 loss: 0.000101537946
Iter: 552 loss: 0.000101545462
Iter: 553 loss: 0.000101536658
Iter: 554 loss: 0.000101532918
Iter: 555 loss: 0.000101542057
Iter: 556 loss: 0.000101531878
Iter: 557 loss: 0.000101528618
Iter: 558 loss: 0.000101550038
Iter: 559 loss: 0.000101528276
Iter: 560 loss: 0.000101525438
Iter: 561 loss: 0.000101528145
Iter: 562 loss: 0.000101523881
Iter: 563 loss: 0.000101520782
Iter: 564 loss: 0.000101531448
Iter: 565 loss: 0.000101519945
Iter: 566 loss: 0.000101517857
Iter: 567 loss: 0.000101548125
Iter: 568 loss: 0.000101517886
Iter: 569 loss: 0.000101515849
Iter: 570 loss: 0.000101523008
Iter: 571 loss: 0.000101515529
Iter: 572 loss: 0.000101513768
Iter: 573 loss: 0.000101513026
Iter: 574 loss: 0.00010151224
Iter: 575 loss: 0.00010151
Iter: 576 loss: 0.000101518439
Iter: 577 loss: 0.000101509533
Iter: 578 loss: 0.000101507416
Iter: 579 loss: 0.000101510843
Iter: 580 loss: 0.000101506434
Iter: 581 loss: 0.000101504411
Iter: 582 loss: 0.000101507525
Iter: 583 loss: 0.000101503436
Iter: 584 loss: 0.000101501035
Iter: 585 loss: 0.000101505939
Iter: 586 loss: 0.000101500162
Iter: 587 loss: 0.000101497644
Iter: 588 loss: 0.000101501384
Iter: 589 loss: 0.00010149664
Iter: 590 loss: 0.000101494312
Iter: 591 loss: 0.000101506295
Iter: 592 loss: 0.000101493897
Iter: 593 loss: 0.000101491751
Iter: 594 loss: 0.000101498292
Iter: 595 loss: 0.000101491154
Iter: 596 loss: 0.000101489233
Iter: 597 loss: 0.000101493672
Iter: 598 loss: 0.000101488513
Iter: 599 loss: 0.000101486861
Iter: 600 loss: 0.000101497462
Iter: 601 loss: 0.000101486556
Iter: 602 loss: 0.000101485086
Iter: 603 loss: 0.000101503458
Iter: 604 loss: 0.000101485115
Iter: 605 loss: 0.000101484155
Iter: 606 loss: 0.00010148366
Iter: 607 loss: 0.000101483223
Iter: 608 loss: 0.000101481666
Iter: 609 loss: 0.000101484256
Iter: 610 loss: 0.000101481142
Iter: 611 loss: 0.000101479636
Iter: 612 loss: 0.000101483762
Iter: 613 loss: 0.00010147928
Iter: 614 loss: 0.000101477563
Iter: 615 loss: 0.000101480371
Iter: 616 loss: 0.000101477162
Iter: 617 loss: 0.000101475562
Iter: 618 loss: 0.000101477803
Iter: 619 loss: 0.00010147487
Iter: 620 loss: 0.000101473124
Iter: 621 loss: 0.000101475394
Iter: 622 loss: 0.000101472338
Iter: 623 loss: 0.000101470534
Iter: 624 loss: 0.000101478137
Iter: 625 loss: 0.000101470287
Iter: 626 loss: 0.000101468606
Iter: 627 loss: 0.000101473561
Iter: 628 loss: 0.000101468337
Iter: 629 loss: 0.000101466721
Iter: 630 loss: 0.000101472826
Iter: 631 loss: 0.000101466489
Iter: 632 loss: 0.000101465135
Iter: 633 loss: 0.000101467172
Iter: 634 loss: 0.000101464568
Iter: 635 loss: 0.000101463738
Iter: 636 loss: 0.000101463651
Iter: 637 loss: 0.000101462792
Iter: 638 loss: 0.000101463476
Iter: 639 loss: 0.000101462399
Iter: 640 loss: 0.000101461599
Iter: 641 loss: 0.000101461555
Iter: 642 loss: 0.000101460879
Iter: 643 loss: 0.000101459649
Iter: 644 loss: 0.000101464131
Iter: 645 loss: 0.000101459424
Iter: 646 loss: 0.00010145855
Iter: 647 loss: 0.000101460784
Iter: 648 loss: 0.000101458201
Iter: 649 loss: 0.000101457095
Iter: 650 loss: 0.000101458143
Iter: 651 loss: 0.000101456571
Iter: 652 loss: 0.000101455385
Iter: 653 loss: 0.000101458121
Iter: 654 loss: 0.000101455036
Iter: 655 loss: 0.000101453807
Iter: 656 loss: 0.000101457044
Iter: 657 loss: 0.00010145353
Iter: 658 loss: 0.000101452344
Iter: 659 loss: 0.00010145425
Iter: 660 loss: 0.000101451944
Iter: 661 loss: 0.000101450823
Iter: 662 loss: 0.000101458136
Iter: 663 loss: 0.000101450729
Iter: 664 loss: 0.000101449747
Iter: 665 loss: 0.000101449928
Iter: 666 loss: 0.000101449157
Iter: 667 loss: 0.00010144843
Iter: 668 loss: 0.000101459678
Iter: 669 loss: 0.000101448299
Iter: 670 loss: 0.000101447629
Iter: 671 loss: 0.00010145225
Iter: 672 loss: 0.000101447491
Iter: 673 loss: 0.000101447047
Iter: 674 loss: 0.00010144656
Iter: 675 loss: 0.000101446407
Iter: 676 loss: 0.000101445738
Iter: 677 loss: 0.000101449492
Iter: 678 loss: 0.000101445519
Iter: 679 loss: 0.000101444908
Iter: 680 loss: 0.000101445636
Iter: 681 loss: 0.000101444544
Iter: 682 loss: 0.000101443831
Iter: 683 loss: 0.000101446087
Iter: 684 loss: 0.000101443402
Iter: 685 loss: 0.000101442805
Iter: 686 loss: 0.0001014437
Iter: 687 loss: 0.000101442427
Iter: 688 loss: 0.000101441583
Iter: 689 loss: 0.000101444086
Iter: 690 loss: 0.00010144143
Iter: 691 loss: 0.000101440513
Iter: 692 loss: 0.000101441809
Iter: 693 loss: 0.000101440339
Iter: 694 loss: 0.000101439553
Iter: 695 loss: 0.000101443984
Iter: 696 loss: 0.000101439342
Iter: 697 loss: 0.000101438854
Iter: 698 loss: 0.000101439611
Iter: 699 loss: 0.000101438331
Iter: 700 loss: 0.000101437872
Iter: 701 loss: 0.000101440834
Iter: 702 loss: 0.000101437559
Iter: 703 loss: 0.000101437225
Iter: 704 loss: 0.000101437152
Iter: 705 loss: 0.000101436817
Iter: 706 loss: 0.000101436453
Iter: 707 loss: 0.000101436424
Iter: 708 loss: 0.000101436031
Iter: 709 loss: 0.000101436766
Iter: 710 loss: 0.000101435704
Iter: 711 loss: 0.000101435195
Iter: 712 loss: 0.000101437043
Iter: 713 loss: 0.000101435071
Iter: 714 loss: 0.000101434533
Iter: 715 loss: 0.000101435544
Iter: 716 loss: 0.00010143438
Iter: 717 loss: 0.000101433805
Iter: 718 loss: 0.000101434824
Iter: 719 loss: 0.00010143379
Iter: 720 loss: 0.000101433034
Iter: 721 loss: 0.000101434161
Iter: 722 loss: 0.000101432837
Iter: 723 loss: 0.000101432379
Iter: 724 loss: 0.000101433179
Iter: 725 loss: 0.000101432059
Iter: 726 loss: 0.000101431448
Iter: 727 loss: 0.000101434664
Iter: 728 loss: 0.00010143144
Iter: 729 loss: 0.000101430938
Iter: 730 loss: 0.000101432124
Iter: 731 loss: 0.000101430851
Iter: 732 loss: 0.000101430269
Iter: 733 loss: 0.000101431302
Iter: 734 loss: 0.000101430123
Iter: 735 loss: 0.000101429723
Iter: 736 loss: 0.00010142992
Iter: 737 loss: 0.000101429505
Iter: 738 loss: 0.000101429934
Iter: 739 loss: 0.000101429352
Iter: 740 loss: 0.00010142917
Iter: 741 loss: 0.000101428828
Iter: 742 loss: 0.000101428566
Iter: 743 loss: 0.000101428341
Iter: 744 loss: 0.000101430589
Iter: 745 loss: 0.000101428326
Iter: 746 loss: 0.000101427926
Iter: 747 loss: 0.000101428595
Iter: 748 loss: 0.000101427744
Iter: 749 loss: 0.000101427431
Iter: 750 loss: 0.000101428239
Iter: 751 loss: 0.000101427315
Iter: 752 loss: 0.000101426849
Iter: 753 loss: 0.000101427533
Iter: 754 loss: 0.000101426675
Iter: 755 loss: 0.000101426311
Iter: 756 loss: 0.000101427184
Iter: 757 loss: 0.000101426209
Iter: 758 loss: 0.000101425758
Iter: 759 loss: 0.000101426995
Iter: 760 loss: 0.000101425663
Iter: 761 loss: 0.00010142527
Iter: 762 loss: 0.000101426413
Iter: 763 loss: 0.000101425161
Iter: 764 loss: 0.000101424681
Iter: 765 loss: 0.000101425496
Iter: 766 loss: 0.00010142471
Iter: 767 loss: 0.000101424317
Iter: 768 loss: 0.000101425932
Iter: 769 loss: 0.00010142423
Iter: 770 loss: 0.000101423851
Iter: 771 loss: 0.000101423953
Iter: 772 loss: 0.000101423808
Iter: 773 loss: 0.000101423495
Iter: 774 loss: 0.000101429629
Iter: 775 loss: 0.000101423684
Iter: 776 loss: 0.000101423226
Iter: 777 loss: 0.000101424346
Iter: 778 loss: 0.000101423182
Iter: 779 loss: 0.000101422906
Iter: 780 loss: 0.000101424303
Iter: 781 loss: 0.000101422724
Iter: 782 loss: 0.000101422607
Iter: 783 loss: 0.000101422818
Iter: 784 loss: 0.000101422411
Iter: 785 loss: 0.000101422156
Iter: 786 loss: 0.000101422891
Iter: 787 loss: 0.000101422062
Iter: 788 loss: 0.000101421821
Iter: 789 loss: 0.000101422396
Iter: 790 loss: 0.000101421669
Iter: 791 loss: 0.000101421436
Iter: 792 loss: 0.000101421858
Iter: 793 loss: 0.000101421218
Iter: 794 loss: 0.000101420868
Iter: 795 loss: 0.000101421552
Iter: 796 loss: 0.000101420839
Iter: 797 loss: 0.00010142057
Iter: 798 loss: 0.000101421996
Iter: 799 loss: 0.000101420592
Iter: 800 loss: 0.000101420344
Iter: 801 loss: 0.000101420694
Iter: 802 loss: 0.000101420257
Iter: 803 loss: 0.000101420213
Iter: 804 loss: 0.000101420024
Iter: 805 loss: 0.000101419901
Iter: 806 loss: 0.000101419631
Iter: 807 loss: 0.000101419777
Iter: 808 loss: 0.000101419522
Iter: 809 loss: 0.000101419981
Iter: 810 loss: 0.000101419413
Iter: 811 loss: 0.000101419268
Iter: 812 loss: 0.000101419791
Iter: 813 loss: 0.000101419078
Iter: 814 loss: 0.000101418984
Iter: 815 loss: 0.000101420024
Iter: 816 loss: 0.000101418955
Iter: 817 loss: 0.000101418707
Iter: 818 loss: 0.000101418846
Iter: 819 loss: 0.000101418686
Iter: 820 loss: 0.000101418467
Iter: 821 loss: 0.000101418977
Iter: 822 loss: 0.000101418344
Iter: 823 loss: 0.000101418205
Iter: 824 loss: 0.000101418613
Iter: 825 loss: 0.000101418074
Iter: 826 loss: 0.000101417754
Iter: 827 loss: 0.000101418475
Iter: 828 loss: 0.000101417783
Iter: 829 loss: 0.000101417485
Iter: 830 loss: 0.000101418453
Iter: 831 loss: 0.000101417536
Iter: 832 loss: 0.000101417361
Iter: 833 loss: 0.000101417681
Iter: 834 loss: 0.000101417289
Iter: 835 loss: 0.000101417172
Iter: 836 loss: 0.00010141822
Iter: 837 loss: 0.000101417056
Iter: 838 loss: 0.000101416845
Iter: 839 loss: 0.000101417972
Iter: 840 loss: 0.000101417005
Iter: 841 loss: 0.000101416808
Iter: 842 loss: 0.000101416692
Iter: 843 loss: 0.000101416634
Iter: 844 loss: 0.00010141643
Iter: 845 loss: 0.000101416983
Iter: 846 loss: 0.000101416437
Iter: 847 loss: 0.000101416168
Iter: 848 loss: 0.000101417201
Iter: 849 loss: 0.000101416139
Iter: 850 loss: 0.000101416037
Iter: 851 loss: 0.00010141635
Iter: 852 loss: 0.000101416023
Iter: 853 loss: 0.000101415877
Iter: 854 loss: 0.000101416212
Iter: 855 loss: 0.000101415702
Iter: 856 loss: 0.000101415651
Iter: 857 loss: 0.000101415841
Iter: 858 loss: 0.000101415768
Iter: 859 loss: 0.00010141552
Iter: 860 loss: 0.000101415702
Iter: 861 loss: 0.00010141536
Iter: 862 loss: 0.000101415208
Iter: 863 loss: 0.000101416008
Iter: 864 loss: 0.000101415157
Iter: 865 loss: 0.000101414975
Iter: 866 loss: 0.000101415273
Iter: 867 loss: 0.000101415048
Iter: 868 loss: 0.000101414815
Iter: 869 loss: 0.000101415251
Iter: 870 loss: 0.000101414858
Iter: 871 loss: 0.000101414786
Iter: 872 loss: 0.000101414757
Iter: 873 loss: 0.000101414757
Iter: 874 loss: 0.000101414451
Iter: 875 loss: 0.000101414553
Iter: 876 loss: 0.0001014144
Iter: 877 loss: 0.000101414524
Iter: 878 loss: 0.000101414516
Iter: 879 loss: 0.00010141432
Iter: 880 loss: 0.000101415229
Iter: 881 loss: 0.000101414313
Iter: 882 loss: 0.000101414131
Iter: 883 loss: 0.000101414545
Iter: 884 loss: 0.000101413971
Iter: 885 loss: 0.000101413985
Iter: 886 loss: 0.000101414087
Iter: 887 loss: 0.000101413956
Iter: 888 loss: 0.000101413782
Iter: 889 loss: 0.000101414058
Iter: 890 loss: 0.000101413709
Iter: 891 loss: 0.0001014136
Iter: 892 loss: 0.000101413898
Iter: 893 loss: 0.000101413541
Iter: 894 loss: 0.00010141349
Iter: 895 loss: 0.000101413709
Iter: 896 loss: 0.000101413389
Iter: 897 loss: 0.000101413374
Iter: 898 loss: 0.000101413993
Iter: 899 loss: 0.000101413229
Iter: 900 loss: 0.00010141325
Iter: 901 loss: 0.000101413454
Iter: 902 loss: 0.00010141317
Iter: 903 loss: 0.00010141317
Iter: 904 loss: 0.000101413818
Iter: 905 loss: 0.000101413163
Iter: 906 loss: 0.00010141301
Iter: 907 loss: 0.000101413403
Iter: 908 loss: 0.00010141301
Iter: 909 loss: 0.000101413032
Iter: 910 loss: 0.000101412807
Iter: 911 loss: 0.00010141496
Iter: 912 loss: 0.000101412865
Iter: 913 loss: 0.000101412799
Iter: 914 loss: 0.000101413425
Iter: 915 loss: 0.000101412734
Iter: 916 loss: 0.000101412523
Iter: 917 loss: 0.000101412908
Iter: 918 loss: 0.000101412734
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6
+ date
Tue Oct 27 15:16:56 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8f1596730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb933319840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb933319158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb933319730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8f151c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8f15368c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc597620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc5c48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc553488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc553c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc5276a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc533f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc533e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc493c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc4cc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc45c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc45cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc410510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc3e28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc3e2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc40a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc3a99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc37a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc3196a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc3192f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc2d0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc30a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc30a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc2b7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc255488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc2b79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc2387b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc243268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc1e0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc19ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8cc19bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0267719626
Iter: 2 loss: 0.0194543842
Iter: 3 loss: 1726.5885
Iter: 4 loss: 6704.76318
Iter: 5 loss: 0.0267519541
Iter: 6 loss: 0.0193892159
Iter: 7 loss: 0.01985237
Iter: 8 loss: 0.0216682553
Iter: 9 loss: 0.0180755854
Iter: 10 loss: 0.0137776481
Iter: 11 loss: 0.0136565715
Iter: 12 loss: 0.0112369154
Iter: 13 loss: 0.022385437
Iter: 14 loss: 0.0107059991
Iter: 15 loss: 0.00913519785
Iter: 16 loss: 0.0155410916
Iter: 17 loss: 0.00896797
Iter: 18 loss: 0.00830617
Iter: 19 loss: 0.00813745521
Iter: 20 loss: 0.00764500536
Iter: 21 loss: 0.00661017653
Iter: 22 loss: 0.0115692131
Iter: 23 loss: 0.00630837958
Iter: 24 loss: 0.00499634305
Iter: 25 loss: 0.0370809548
Iter: 26 loss: 0.00498015434
Iter: 27 loss: 0.00411194
Iter: 28 loss: 0.00411051512
Iter: 29 loss: 0.0035710528
Iter: 30 loss: 0.00671086134
Iter: 31 loss: 0.00351291848
Iter: 32 loss: 0.00323767914
Iter: 33 loss: 0.00395837333
Iter: 34 loss: 0.00311739091
Iter: 35 loss: 0.00282253698
Iter: 36 loss: 0.00347077847
Iter: 37 loss: 0.00270921155
Iter: 38 loss: 0.00238918839
Iter: 39 loss: 0.0088297613
Iter: 40 loss: 0.00238545518
Iter: 41 loss: 0.00214677071
Iter: 42 loss: 0.00324498722
Iter: 43 loss: 0.00212023477
Iter: 44 loss: 0.00199911487
Iter: 45 loss: 0.00226230733
Iter: 46 loss: 0.00194281316
Iter: 47 loss: 0.00186181231
Iter: 48 loss: 0.00194094097
Iter: 49 loss: 0.0018110266
Iter: 50 loss: 0.00165799656
Iter: 51 loss: 0.00211793324
Iter: 52 loss: 0.00161014358
Iter: 53 loss: 0.00146668614
Iter: 54 loss: 0.00254606828
Iter: 55 loss: 0.00145748502
Iter: 56 loss: 0.00137435901
Iter: 57 loss: 0.00149704318
Iter: 58 loss: 0.00132972375
Iter: 59 loss: 0.00127585372
Iter: 60 loss: 0.00129026989
Iter: 61 loss: 0.00123688905
Iter: 62 loss: 0.00115121598
Iter: 63 loss: 0.00143211382
Iter: 64 loss: 0.00112687179
Iter: 65 loss: 0.00105694006
Iter: 66 loss: 0.00139513751
Iter: 67 loss: 0.0010445735
Iter: 68 loss: 0.000988388201
Iter: 69 loss: 0.00106288109
Iter: 70 loss: 0.000959104043
Iter: 71 loss: 0.000910535
Iter: 72 loss: 0.00162386103
Iter: 73 loss: 0.000910140516
Iter: 74 loss: 0.000874469231
Iter: 75 loss: 0.00102279964
Iter: 76 loss: 0.000867898751
Iter: 77 loss: 0.000835473067
Iter: 78 loss: 0.00106183207
Iter: 79 loss: 0.000831664773
Iter: 80 loss: 0.000812922895
Iter: 81 loss: 0.000789354905
Iter: 82 loss: 0.000787568861
Iter: 83 loss: 0.000741302385
Iter: 84 loss: 0.00117039238
Iter: 85 loss: 0.000739006
Iter: 86 loss: 0.000702288409
Iter: 87 loss: 0.000986772357
Iter: 88 loss: 0.000699738623
Iter: 89 loss: 0.000678737299
Iter: 90 loss: 0.000717989868
Iter: 91 loss: 0.000669170462
Iter: 92 loss: 0.000644775922
Iter: 93 loss: 0.00069648237
Iter: 94 loss: 0.000635030912
Iter: 95 loss: 0.000609930838
Iter: 96 loss: 0.000727633247
Iter: 97 loss: 0.000605032197
Iter: 98 loss: 0.000582692
Iter: 99 loss: 0.000619149883
Iter: 100 loss: 0.00057258294
Iter: 101 loss: 0.00055113656
Iter: 102 loss: 0.000620500767
Iter: 103 loss: 0.000544856419
Iter: 104 loss: 0.000527578813
Iter: 105 loss: 0.000548060285
Iter: 106 loss: 0.000518206565
Iter: 107 loss: 0.000498031848
Iter: 108 loss: 0.000541296438
Iter: 109 loss: 0.00049042108
Iter: 110 loss: 0.00047857684
Iter: 111 loss: 0.000609903247
Iter: 112 loss: 0.000478157279
Iter: 113 loss: 0.000466970727
Iter: 114 loss: 0.000460635289
Iter: 115 loss: 0.000455854577
Iter: 116 loss: 0.000441213982
Iter: 117 loss: 0.000464868208
Iter: 118 loss: 0.000434432644
Iter: 119 loss: 0.000420338649
Iter: 120 loss: 0.00044621728
Iter: 121 loss: 0.000414179289
Iter: 122 loss: 0.000401566736
Iter: 123 loss: 0.000533363898
Iter: 124 loss: 0.000401130877
Iter: 125 loss: 0.00039072457
Iter: 126 loss: 0.000452722132
Iter: 127 loss: 0.000389496272
Iter: 128 loss: 0.000380965881
Iter: 129 loss: 0.000378846598
Iter: 130 loss: 0.000373415824
Iter: 131 loss: 0.000361514656
Iter: 132 loss: 0.000391807553
Iter: 133 loss: 0.000357467972
Iter: 134 loss: 0.000346536748
Iter: 135 loss: 0.000380545884
Iter: 136 loss: 0.000343296269
Iter: 137 loss: 0.000334342098
Iter: 138 loss: 0.000387988955
Iter: 139 loss: 0.000333254109
Iter: 140 loss: 0.000325879839
Iter: 141 loss: 0.000348481175
Iter: 142 loss: 0.000323625485
Iter: 143 loss: 0.000318027713
Iter: 144 loss: 0.000343803898
Iter: 145 loss: 0.000317086087
Iter: 146 loss: 0.000310911797
Iter: 147 loss: 0.000325903296
Iter: 148 loss: 0.000308619929
Iter: 149 loss: 0.000303100649
Iter: 150 loss: 0.000302172848
Iter: 151 loss: 0.000298415485
Iter: 152 loss: 0.000290752039
Iter: 153 loss: 0.000304227928
Iter: 154 loss: 0.00028737777
Iter: 155 loss: 0.000279901724
Iter: 156 loss: 0.000316738558
Iter: 157 loss: 0.000278633728
Iter: 158 loss: 0.000273795857
Iter: 159 loss: 0.000299074338
Iter: 160 loss: 0.000272991281
Iter: 161 loss: 0.000267748
Iter: 162 loss: 0.000282863301
Iter: 163 loss: 0.000266144518
Iter: 164 loss: 0.000262189307
Iter: 165 loss: 0.000260187488
Iter: 166 loss: 0.000258322398
Iter: 167 loss: 0.000252847036
Iter: 168 loss: 0.000264944392
Iter: 169 loss: 0.000250735757
Iter: 170 loss: 0.000245357311
Iter: 171 loss: 0.000284073292
Iter: 172 loss: 0.000244861469
Iter: 173 loss: 0.000241164526
Iter: 174 loss: 0.000261531328
Iter: 175 loss: 0.000240646972
Iter: 176 loss: 0.000237611617
Iter: 177 loss: 0.000241023867
Iter: 178 loss: 0.000235945306
Iter: 179 loss: 0.00023263559
Iter: 180 loss: 0.000260606
Iter: 181 loss: 0.000232467602
Iter: 182 loss: 0.000229771074
Iter: 183 loss: 0.000228294579
Iter: 184 loss: 0.000227085329
Iter: 185 loss: 0.000223594252
Iter: 186 loss: 0.000229534679
Iter: 187 loss: 0.000222012226
Iter: 188 loss: 0.000217873196
Iter: 189 loss: 0.000228033212
Iter: 190 loss: 0.000216378045
Iter: 191 loss: 0.00021266102
Iter: 192 loss: 0.000222332077
Iter: 193 loss: 0.000211404433
Iter: 194 loss: 0.000208630605
Iter: 195 loss: 0.000208559883
Iter: 196 loss: 0.000206806886
Iter: 197 loss: 0.000203141986
Iter: 198 loss: 0.000265947107
Iter: 199 loss: 0.00020305191
Iter: 200 loss: 0.000199373113
Iter: 201 loss: 0.00021533636
Iter: 202 loss: 0.000198616326
Iter: 203 loss: 0.000195322689
Iter: 204 loss: 0.00021297764
Iter: 205 loss: 0.000194827298
Iter: 206 loss: 0.000192268926
Iter: 207 loss: 0.000211959676
Iter: 208 loss: 0.000192066786
Iter: 209 loss: 0.000189821862
Iter: 210 loss: 0.000198700669
Iter: 211 loss: 0.000189325379
Iter: 212 loss: 0.00018761617
Iter: 213 loss: 0.000194965352
Iter: 214 loss: 0.000187246158
Iter: 215 loss: 0.000185566285
Iter: 216 loss: 0.000187409387
Iter: 217 loss: 0.000184656135
Iter: 218 loss: 0.000182951364
Iter: 219 loss: 0.000184143428
Iter: 220 loss: 0.00018188676
Iter: 221 loss: 0.000179709561
Iter: 222 loss: 0.000187839905
Iter: 223 loss: 0.000179179711
Iter: 224 loss: 0.0001770909
Iter: 225 loss: 0.000179869225
Iter: 226 loss: 0.000176029353
Iter: 227 loss: 0.000174677451
Iter: 228 loss: 0.000174632471
Iter: 229 loss: 0.000173367545
Iter: 230 loss: 0.000172587432
Iter: 231 loss: 0.000172072294
Iter: 232 loss: 0.000170415704
Iter: 233 loss: 0.000170346815
Iter: 234 loss: 0.000169069463
Iter: 235 loss: 0.000166873215
Iter: 236 loss: 0.000178693648
Iter: 237 loss: 0.000166538972
Iter: 238 loss: 0.000164715544
Iter: 239 loss: 0.000169580569
Iter: 240 loss: 0.000164108758
Iter: 241 loss: 0.00016255735
Iter: 242 loss: 0.000183155178
Iter: 243 loss: 0.000162545577
Iter: 244 loss: 0.000161472824
Iter: 245 loss: 0.000162753655
Iter: 246 loss: 0.000160913303
Iter: 247 loss: 0.000159559597
Iter: 248 loss: 0.000162754121
Iter: 249 loss: 0.00015905856
Iter: 250 loss: 0.000157865405
Iter: 251 loss: 0.000157764734
Iter: 252 loss: 0.000156879833
Iter: 253 loss: 0.00015530322
Iter: 254 loss: 0.000162286145
Iter: 255 loss: 0.000154990252
Iter: 256 loss: 0.000153539324
Iter: 257 loss: 0.000156971248
Iter: 258 loss: 0.000153009853
Iter: 259 loss: 0.000151693413
Iter: 260 loss: 0.000160185358
Iter: 261 loss: 0.000151543558
Iter: 262 loss: 0.000150428619
Iter: 263 loss: 0.000158836629
Iter: 264 loss: 0.0001503448
Iter: 265 loss: 0.000149665837
Iter: 266 loss: 0.000148804887
Iter: 267 loss: 0.000148738982
Iter: 268 loss: 0.000147517479
Iter: 269 loss: 0.0001496771
Iter: 270 loss: 0.000146979
Iter: 271 loss: 0.000145645507
Iter: 272 loss: 0.000150941196
Iter: 273 loss: 0.000145339844
Iter: 274 loss: 0.000144557154
Iter: 275 loss: 0.000156593218
Iter: 276 loss: 0.000144556878
Iter: 277 loss: 0.000143863959
Iter: 278 loss: 0.00014539517
Iter: 279 loss: 0.000143595695
Iter: 280 loss: 0.000142934936
Iter: 281 loss: 0.000144574966
Iter: 282 loss: 0.000142703982
Iter: 283 loss: 0.000142036442
Iter: 284 loss: 0.000142046687
Iter: 285 loss: 0.000141503624
Iter: 286 loss: 0.00014060695
Iter: 287 loss: 0.000141862576
Iter: 288 loss: 0.000140163989
Iter: 289 loss: 0.000139214069
Iter: 290 loss: 0.000143663594
Iter: 291 loss: 0.000139036842
Iter: 292 loss: 0.000138167961
Iter: 293 loss: 0.000141188619
Iter: 294 loss: 0.000137941708
Iter: 295 loss: 0.000137289142
Iter: 296 loss: 0.00014528248
Iter: 297 loss: 0.000137281197
Iter: 298 loss: 0.000136771909
Iter: 299 loss: 0.000135980779
Iter: 300 loss: 0.000135970389
Iter: 301 loss: 0.000135127659
Iter: 302 loss: 0.00013746653
Iter: 303 loss: 0.000134854927
Iter: 304 loss: 0.000134021131
Iter: 305 loss: 0.000136753864
Iter: 306 loss: 0.000133788271
Iter: 307 loss: 0.000133125359
Iter: 308 loss: 0.00013812026
Iter: 309 loss: 0.00013307255
Iter: 310 loss: 0.000132543122
Iter: 311 loss: 0.000137652489
Iter: 312 loss: 0.000132524583
Iter: 313 loss: 0.000132156245
Iter: 314 loss: 0.000132364599
Iter: 315 loss: 0.000131914931
Iter: 316 loss: 0.000131443841
Iter: 317 loss: 0.000131939349
Iter: 318 loss: 0.000131183886
Iter: 319 loss: 0.000130624539
Iter: 320 loss: 0.000130828048
Iter: 321 loss: 0.000130232816
Iter: 322 loss: 0.000129593449
Iter: 323 loss: 0.000132344605
Iter: 324 loss: 0.000129461769
Iter: 325 loss: 0.000128859101
Iter: 326 loss: 0.000131896755
Iter: 327 loss: 0.000128757267
Iter: 328 loss: 0.000128335902
Iter: 329 loss: 0.000132159359
Iter: 330 loss: 0.000128317071
Iter: 331 loss: 0.000127907493
Iter: 332 loss: 0.000127497973
Iter: 333 loss: 0.000127413747
Iter: 334 loss: 0.000126855666
Iter: 335 loss: 0.000127472944
Iter: 336 loss: 0.000126552273
Iter: 337 loss: 0.000125943916
Iter: 338 loss: 0.000129216511
Iter: 339 loss: 0.000125851802
Iter: 340 loss: 0.000125364575
Iter: 341 loss: 0.000127117921
Iter: 342 loss: 0.000125241771
Iter: 343 loss: 0.000124829501
Iter: 344 loss: 0.000130345245
Iter: 345 loss: 0.00012482678
Iter: 346 loss: 0.000124523343
Iter: 347 loss: 0.00012454197
Iter: 348 loss: 0.0001242867
Iter: 349 loss: 0.000123870966
Iter: 350 loss: 0.000124514263
Iter: 351 loss: 0.000123674166
Iter: 352 loss: 0.000123230391
Iter: 353 loss: 0.000123628444
Iter: 354 loss: 0.000122971745
Iter: 355 loss: 0.000122489757
Iter: 356 loss: 0.000123568083
Iter: 357 loss: 0.000122306476
Iter: 358 loss: 0.000121810313
Iter: 359 loss: 0.000125368897
Iter: 360 loss: 0.000121767938
Iter: 361 loss: 0.000121408419
Iter: 362 loss: 0.000123335747
Iter: 363 loss: 0.000121353376
Iter: 364 loss: 0.000120974233
Iter: 365 loss: 0.000121415338
Iter: 366 loss: 0.000120772587
Iter: 367 loss: 0.000120445126
Iter: 368 loss: 0.000120198885
Iter: 369 loss: 0.000120091448
Iter: 370 loss: 0.000119604498
Iter: 371 loss: 0.000121917285
Iter: 372 loss: 0.0001195164
Iter: 373 loss: 0.00011909951
Iter: 374 loss: 0.000120666591
Iter: 375 loss: 0.000118998076
Iter: 376 loss: 0.000118714874
Iter: 377 loss: 0.000118713157
Iter: 378 loss: 0.000118491633
Iter: 379 loss: 0.000118441596
Iter: 380 loss: 0.000118297801
Iter: 381 loss: 0.00011796943
Iter: 382 loss: 0.000118493139
Iter: 383 loss: 0.000117817464
Iter: 384 loss: 0.000117476593
Iter: 385 loss: 0.000118050979
Iter: 386 loss: 0.000117323019
Iter: 387 loss: 0.000116978837
Iter: 388 loss: 0.000117357886
Iter: 389 loss: 0.000116791387
Iter: 390 loss: 0.000116434792
Iter: 391 loss: 0.000118960088
Iter: 392 loss: 0.000116402109
Iter: 393 loss: 0.000116105497
Iter: 394 loss: 0.000117487762
Iter: 395 loss: 0.00011605092
Iter: 396 loss: 0.000115756658
Iter: 397 loss: 0.000116687181
Iter: 398 loss: 0.000115671675
Iter: 399 loss: 0.000115435862
Iter: 400 loss: 0.000115218718
Iter: 401 loss: 0.00011516174
Iter: 402 loss: 0.000114803704
Iter: 403 loss: 0.000116070703
Iter: 404 loss: 0.000114711205
Iter: 405 loss: 0.000114385977
Iter: 406 loss: 0.000115283881
Iter: 407 loss: 0.000114280723
Iter: 408 loss: 0.000114072318
Iter: 409 loss: 0.000114062816
Iter: 410 loss: 0.00011388243
Iter: 411 loss: 0.000113919137
Iter: 412 loss: 0.000113748865
Iter: 413 loss: 0.00011350774
Iter: 414 loss: 0.000113779613
Iter: 415 loss: 0.000113377566
Iter: 416 loss: 0.00011313118
Iter: 417 loss: 0.000113696486
Iter: 418 loss: 0.000113039401
Iter: 419 loss: 0.000112781956
Iter: 420 loss: 0.000113006572
Iter: 421 loss: 0.000112630238
Iter: 422 loss: 0.000112347065
Iter: 423 loss: 0.000113593029
Iter: 424 loss: 0.000112290567
Iter: 425 loss: 0.000112031186
Iter: 426 loss: 0.000113787879
Iter: 427 loss: 0.000112005015
Iter: 428 loss: 0.000111788984
Iter: 429 loss: 0.000112761307
Iter: 430 loss: 0.000111747111
Iter: 431 loss: 0.000111565103
Iter: 432 loss: 0.000111403897
Iter: 433 loss: 0.000111356756
Iter: 434 loss: 0.000111087233
Iter: 435 loss: 0.00011156861
Iter: 436 loss: 0.00011096961
Iter: 437 loss: 0.000110689798
Iter: 438 loss: 0.000111303554
Iter: 439 loss: 0.000110581896
Iter: 440 loss: 0.000110401379
Iter: 441 loss: 0.000110393041
Iter: 442 loss: 0.000110218491
Iter: 443 loss: 0.000110354995
Iter: 444 loss: 0.00011011256
Iter: 445 loss: 0.000109916051
Iter: 446 loss: 0.000110170367
Iter: 447 loss: 0.000109815577
Iter: 448 loss: 0.000109608794
Iter: 449 loss: 0.000109836212
Iter: 450 loss: 0.000109495821
Iter: 451 loss: 0.00010923879
Iter: 452 loss: 0.000109679851
Iter: 453 loss: 0.000109124332
Iter: 454 loss: 0.000108873202
Iter: 455 loss: 0.000109592729
Iter: 456 loss: 0.000108794069
Iter: 457 loss: 0.000108557106
Iter: 458 loss: 0.000110547902
Iter: 459 loss: 0.000108543674
Iter: 460 loss: 0.000108356195
Iter: 461 loss: 0.000109147353
Iter: 462 loss: 0.000108316504
Iter: 463 loss: 0.000108148415
Iter: 464 loss: 0.000108106411
Iter: 465 loss: 0.000108000742
Iter: 466 loss: 0.000107786705
Iter: 467 loss: 0.000107976688
Iter: 468 loss: 0.000107661734
Iter: 469 loss: 0.000107399042
Iter: 470 loss: 0.000107998174
Iter: 471 loss: 0.000107300759
Iter: 472 loss: 0.000107144355
Iter: 473 loss: 0.000107139123
Iter: 474 loss: 0.000106984073
Iter: 475 loss: 0.000107230109
Iter: 476 loss: 0.00010691223
Iter: 477 loss: 0.000106761567
Iter: 478 loss: 0.000106973828
Iter: 479 loss: 0.000106687236
Iter: 480 loss: 0.000106522377
Iter: 481 loss: 0.000106600113
Iter: 482 loss: 0.000106411171
Iter: 483 loss: 0.000106203086
Iter: 484 loss: 0.000106886044
Iter: 485 loss: 0.000106145017
Iter: 486 loss: 0.000105963249
Iter: 487 loss: 0.000106172287
Iter: 488 loss: 0.000105865751
Iter: 489 loss: 0.000105669264
Iter: 490 loss: 0.000107612519
Iter: 491 loss: 0.00010566241
Iter: 492 loss: 0.000105506697
Iter: 493 loss: 0.000106221945
Iter: 494 loss: 0.000105477287
Iter: 495 loss: 0.000105337189
Iter: 496 loss: 0.000105345127
Iter: 497 loss: 0.000105227715
Iter: 498 loss: 0.000105063926
Iter: 499 loss: 0.000105152161
Iter: 500 loss: 0.000104956132
Iter: 501 loss: 0.000104737337
Iter: 502 loss: 0.000105125087
Iter: 503 loss: 0.000104641484
Iter: 504 loss: 0.000104474588
Iter: 505 loss: 0.000106842694
Iter: 506 loss: 0.000104474384
Iter: 507 loss: 0.000104314859
Iter: 508 loss: 0.000104994499
Iter: 509 loss: 0.000104281062
Iter: 510 loss: 0.000104167615
Iter: 511 loss: 0.00010422412
Iter: 512 loss: 0.0001040918
Iter: 513 loss: 0.000103941115
Iter: 514 loss: 0.000104034116
Iter: 515 loss: 0.000103844424
Iter: 516 loss: 0.000103664643
Iter: 517 loss: 0.000104253653
Iter: 518 loss: 0.00010361497
Iter: 519 loss: 0.000103450198
Iter: 520 loss: 0.000103666382
Iter: 521 loss: 0.000103366467
Iter: 522 loss: 0.000103201426
Iter: 523 loss: 0.000104690705
Iter: 524 loss: 0.000103193903
Iter: 525 loss: 0.000103065853
Iter: 526 loss: 0.000103742379
Iter: 527 loss: 0.000103045822
Iter: 528 loss: 0.000102929574
Iter: 529 loss: 0.000102936094
Iter: 530 loss: 0.000102838414
Iter: 531 loss: 0.000102699552
Iter: 532 loss: 0.000102844766
Iter: 533 loss: 0.000102622318
Iter: 534 loss: 0.000102456128
Iter: 535 loss: 0.00010269403
Iter: 536 loss: 0.000102374892
Iter: 537 loss: 0.000102214617
Iter: 538 loss: 0.000103315018
Iter: 539 loss: 0.000102199068
Iter: 540 loss: 0.000102061647
Iter: 541 loss: 0.000103666236
Iter: 542 loss: 0.00010205969
Iter: 543 loss: 0.000101982485
Iter: 544 loss: 0.000101946
Iter: 545 loss: 0.000101908146
Iter: 546 loss: 0.000101788566
Iter: 547 loss: 0.000101944606
Iter: 548 loss: 0.000101727506
Iter: 549 loss: 0.000101594429
Iter: 550 loss: 0.000101863683
Iter: 551 loss: 0.000101540543
Iter: 552 loss: 0.000101400758
Iter: 553 loss: 0.000101635298
Iter: 554 loss: 0.000101337719
Iter: 555 loss: 0.000101208032
Iter: 556 loss: 0.000102324033
Iter: 557 loss: 0.000101201076
Iter: 558 loss: 0.000101102836
Iter: 559 loss: 0.00010171326
Iter: 560 loss: 0.000101091806
Iter: 561 loss: 0.000101000616
Iter: 562 loss: 0.000100982055
Iter: 563 loss: 0.000100922
Iter: 564 loss: 0.000100801568
Iter: 565 loss: 0.000100920195
Iter: 566 loss: 0.000100733247
Iter: 567 loss: 0.000100588528
Iter: 568 loss: 0.000100903482
Iter: 569 loss: 0.000100532474
Iter: 570 loss: 0.000100402198
Iter: 571 loss: 0.00010082488
Iter: 572 loss: 0.000100365549
Iter: 573 loss: 0.000100263467
Iter: 574 loss: 0.000100261517
Iter: 575 loss: 0.000100196456
Iter: 576 loss: 0.000100121964
Iter: 577 loss: 0.000100112913
Iter: 578 loss: 9.99999e-05
Iter: 579 loss: 0.000100305
Iter: 580 loss: 9.99625336e-05
Iter: 581 loss: 9.9856421e-05
Iter: 582 loss: 0.000100014127
Iter: 583 loss: 9.98052856e-05
Iter: 584 loss: 9.96840608e-05
Iter: 585 loss: 9.98926844e-05
Iter: 586 loss: 9.96298913e-05
Iter: 587 loss: 9.95163e-05
Iter: 588 loss: 0.000100429679
Iter: 589 loss: 9.95089649e-05
Iter: 590 loss: 9.94217626e-05
Iter: 591 loss: 9.99279291e-05
Iter: 592 loss: 9.9409961e-05
Iter: 593 loss: 9.9324745e-05
Iter: 594 loss: 9.93631693e-05
Iter: 595 loss: 9.92670684e-05
Iter: 596 loss: 9.91730631e-05
Iter: 597 loss: 9.92458663e-05
Iter: 598 loss: 9.9116136e-05
Iter: 599 loss: 9.8997516e-05
Iter: 600 loss: 9.92460773e-05
Iter: 601 loss: 9.89506516e-05
Iter: 602 loss: 9.88405081e-05
Iter: 603 loss: 9.91213456e-05
Iter: 604 loss: 9.8802193e-05
Iter: 605 loss: 9.87490348e-05
Iter: 606 loss: 9.87352541e-05
Iter: 607 loss: 9.86889e-05
Iter: 608 loss: 9.86124942e-05
Iter: 609 loss: 9.86121886e-05
Iter: 610 loss: 9.85155202e-05
Iter: 611 loss: 9.88215616e-05
Iter: 612 loss: 9.8487857e-05
Iter: 613 loss: 9.8399687e-05
Iter: 614 loss: 9.85342776e-05
Iter: 615 loss: 9.83578211e-05
Iter: 616 loss: 9.82636411e-05
Iter: 617 loss: 9.84452927e-05
Iter: 618 loss: 9.82245037e-05
Iter: 619 loss: 9.81337653e-05
Iter: 620 loss: 9.86254308e-05
Iter: 621 loss: 9.81202902e-05
Iter: 622 loss: 9.80413606e-05
Iter: 623 loss: 9.85390361e-05
Iter: 624 loss: 9.80323093e-05
Iter: 625 loss: 9.79591e-05
Iter: 626 loss: 9.80514815e-05
Iter: 627 loss: 9.79209799e-05
Iter: 628 loss: 9.78503813e-05
Iter: 629 loss: 9.786788e-05
Iter: 630 loss: 9.77988166e-05
Iter: 631 loss: 9.77033706e-05
Iter: 632 loss: 9.79499164e-05
Iter: 633 loss: 9.76705051e-05
Iter: 634 loss: 9.7581411e-05
Iter: 635 loss: 9.77500677e-05
Iter: 636 loss: 9.75437724e-05
Iter: 637 loss: 9.75079e-05
Iter: 638 loss: 9.74933937e-05
Iter: 639 loss: 9.74531213e-05
Iter: 640 loss: 9.73861243e-05
Iter: 641 loss: 9.73858332e-05
Iter: 642 loss: 9.73063e-05
Iter: 643 loss: 9.76154406e-05
Iter: 644 loss: 9.72877751e-05
Iter: 645 loss: 9.72161288e-05
Iter: 646 loss: 9.73001879e-05
Iter: 647 loss: 9.71778572e-05
Iter: 648 loss: 9.70984693e-05
Iter: 649 loss: 9.72940325e-05
Iter: 650 loss: 9.70701658e-05
Iter: 651 loss: 9.69964312e-05
Iter: 652 loss: 9.73119531e-05
Iter: 653 loss: 9.69809553e-05
Iter: 654 loss: 9.69134e-05
Iter: 655 loss: 9.74007125e-05
Iter: 656 loss: 9.69075263e-05
Iter: 657 loss: 9.68465756e-05
Iter: 658 loss: 9.69559769e-05
Iter: 659 loss: 9.68199165e-05
Iter: 660 loss: 9.67623637e-05
Iter: 661 loss: 9.67526576e-05
Iter: 662 loss: 9.67132728e-05
Iter: 663 loss: 9.66351799e-05
Iter: 664 loss: 9.68834938e-05
Iter: 665 loss: 9.66128719e-05
Iter: 666 loss: 9.65406507e-05
Iter: 667 loss: 9.66374355e-05
Iter: 668 loss: 9.65042491e-05
Iter: 669 loss: 9.64739593e-05
Iter: 670 loss: 9.64625069e-05
Iter: 671 loss: 9.6423988e-05
Iter: 672 loss: 9.63703715e-05
Iter: 673 loss: 9.6368145e-05
Iter: 674 loss: 9.63063503e-05
Iter: 675 loss: 9.65350628e-05
Iter: 676 loss: 9.62910854e-05
Iter: 677 loss: 9.62326594e-05
Iter: 678 loss: 9.62822378e-05
Iter: 679 loss: 9.61978585e-05
Iter: 680 loss: 9.612945e-05
Iter: 681 loss: 9.63088678e-05
Iter: 682 loss: 9.61061e-05
Iter: 683 loss: 9.6043892e-05
Iter: 684 loss: 9.62848135e-05
Iter: 685 loss: 9.60294128e-05
Iter: 686 loss: 9.59745084e-05
Iter: 687 loss: 9.63986677e-05
Iter: 688 loss: 9.59706231e-05
Iter: 689 loss: 9.59233148e-05
Iter: 690 loss: 9.60287871e-05
Iter: 691 loss: 9.59052923e-05
Iter: 692 loss: 9.58597375e-05
Iter: 693 loss: 9.58369492e-05
Iter: 694 loss: 9.58154051e-05
Iter: 695 loss: 9.57521916e-05
Iter: 696 loss: 9.60095131e-05
Iter: 697 loss: 9.57383309e-05
Iter: 698 loss: 9.56836884e-05
Iter: 699 loss: 9.57467855e-05
Iter: 700 loss: 9.56544682e-05
Iter: 701 loss: 9.56241129e-05
Iter: 702 loss: 9.56198055e-05
Iter: 703 loss: 9.55847281e-05
Iter: 704 loss: 9.55493888e-05
Iter: 705 loss: 9.55422729e-05
Iter: 706 loss: 9.5493946e-05
Iter: 707 loss: 9.56543954e-05
Iter: 708 loss: 9.54807838e-05
Iter: 709 loss: 9.54348652e-05
Iter: 710 loss: 9.54897405e-05
Iter: 711 loss: 9.54106144e-05
Iter: 712 loss: 9.53586277e-05
Iter: 713 loss: 9.54660936e-05
Iter: 714 loss: 9.53377e-05
Iter: 715 loss: 9.52847477e-05
Iter: 716 loss: 9.54347634e-05
Iter: 717 loss: 9.5268013e-05
Iter: 718 loss: 9.52203409e-05
Iter: 719 loss: 9.56980803e-05
Iter: 720 loss: 9.52187111e-05
Iter: 721 loss: 9.51806e-05
Iter: 722 loss: 9.52925766e-05
Iter: 723 loss: 9.51687398e-05
Iter: 724 loss: 9.51334514e-05
Iter: 725 loss: 9.51112161e-05
Iter: 726 loss: 9.5097319e-05
Iter: 727 loss: 9.50466638e-05
Iter: 728 loss: 9.52027694e-05
Iter: 729 loss: 9.50316753e-05
Iter: 730 loss: 9.4981915e-05
Iter: 731 loss: 9.50619942e-05
Iter: 732 loss: 9.49588e-05
Iter: 733 loss: 9.4927469e-05
Iter: 734 loss: 9.49265377e-05
Iter: 735 loss: 9.48928719e-05
Iter: 736 loss: 9.48990273e-05
Iter: 737 loss: 9.48676752e-05
Iter: 738 loss: 9.48342931e-05
Iter: 739 loss: 9.48795496e-05
Iter: 740 loss: 9.48173256e-05
Iter: 741 loss: 9.47774461e-05
Iter: 742 loss: 9.48416709e-05
Iter: 743 loss: 9.47591e-05
Iter: 744 loss: 9.47152221e-05
Iter: 745 loss: 9.4806921e-05
Iter: 746 loss: 9.46978544e-05
Iter: 747 loss: 9.46548098e-05
Iter: 748 loss: 9.47642766e-05
Iter: 749 loss: 9.46398795e-05
Iter: 750 loss: 9.46005603e-05
Iter: 751 loss: 9.49903479e-05
Iter: 752 loss: 9.45991342e-05
Iter: 753 loss: 9.45672728e-05
Iter: 754 loss: 9.4657451e-05
Iter: 755 loss: 9.45570355e-05
Iter: 756 loss: 9.4525225e-05
Iter: 757 loss: 9.4515126e-05
Iter: 758 loss: 9.44965e-05
Iter: 759 loss: 9.44575e-05
Iter: 760 loss: 9.45662541e-05
Iter: 761 loss: 9.44448e-05
Iter: 762 loss: 9.44040294e-05
Iter: 763 loss: 9.44669737e-05
Iter: 764 loss: 9.438493e-05
Iter: 765 loss: 9.43530904e-05
Iter: 766 loss: 9.48239e-05
Iter: 767 loss: 9.43529521e-05
Iter: 768 loss: 9.43211489e-05
Iter: 769 loss: 9.43968043e-05
Iter: 770 loss: 9.43095947e-05
Iter: 771 loss: 9.42864281e-05
Iter: 772 loss: 9.4285e-05
Iter: 773 loss: 9.42676561e-05
Iter: 774 loss: 9.42341794e-05
Iter: 775 loss: 9.43036575e-05
Iter: 776 loss: 9.4220748e-05
Iter: 777 loss: 9.41838371e-05
Iter: 778 loss: 9.42528422e-05
Iter: 779 loss: 9.41680919e-05
Iter: 780 loss: 9.4131552e-05
Iter: 781 loss: 9.41976759e-05
Iter: 782 loss: 9.41155158e-05
Iter: 783 loss: 9.40820173e-05
Iter: 784 loss: 9.44999629e-05
Iter: 785 loss: 9.40816317e-05
Iter: 786 loss: 9.40551909e-05
Iter: 787 loss: 9.41338658e-05
Iter: 788 loss: 9.40473547e-05
Iter: 789 loss: 9.40206955e-05
Iter: 790 loss: 9.40173704e-05
Iter: 791 loss: 9.39983365e-05
Iter: 792 loss: 9.39672755e-05
Iter: 793 loss: 9.40210084e-05
Iter: 794 loss: 9.39531747e-05
Iter: 795 loss: 9.3917748e-05
Iter: 796 loss: 9.4016541e-05
Iter: 797 loss: 9.39062957e-05
Iter: 798 loss: 9.38789308e-05
Iter: 799 loss: 9.41196631e-05
Iter: 800 loss: 9.38774538e-05
Iter: 801 loss: 9.38501471e-05
Iter: 802 loss: 9.39762467e-05
Iter: 803 loss: 9.38447702e-05
Iter: 804 loss: 9.38270241e-05
Iter: 805 loss: 9.38117e-05
Iter: 806 loss: 9.38067242e-05
Iter: 807 loss: 9.37770892e-05
Iter: 808 loss: 9.38672092e-05
Iter: 809 loss: 9.37682707e-05
Iter: 810 loss: 9.37384611e-05
Iter: 811 loss: 9.37939767e-05
Iter: 812 loss: 9.37258519e-05
Iter: 813 loss: 9.36956349e-05
Iter: 814 loss: 9.3733368e-05
Iter: 815 loss: 9.36796132e-05
Iter: 816 loss: 9.36523938e-05
Iter: 817 loss: 9.40324098e-05
Iter: 818 loss: 9.3652241e-05
Iter: 819 loss: 9.36304859e-05
Iter: 820 loss: 9.36923607e-05
Iter: 821 loss: 9.36234e-05
Iter: 822 loss: 9.36010911e-05
Iter: 823 loss: 9.36103534e-05
Iter: 824 loss: 9.35855787e-05
Iter: 825 loss: 9.35614808e-05
Iter: 826 loss: 9.35817661e-05
Iter: 827 loss: 9.3547329e-05
Iter: 828 loss: 9.35174539e-05
Iter: 829 loss: 9.36155266e-05
Iter: 830 loss: 9.35091521e-05
Iter: 831 loss: 9.34849304e-05
Iter: 832 loss: 9.36424622e-05
Iter: 833 loss: 9.34823547e-05
Iter: 834 loss: 9.34598356e-05
Iter: 835 loss: 9.36459401e-05
Iter: 836 loss: 9.3458315e-05
Iter: 837 loss: 9.34450945e-05
Iter: 838 loss: 9.34275449e-05
Iter: 839 loss: 9.34265554e-05
Iter: 840 loss: 9.3402341e-05
Iter: 841 loss: 9.34860727e-05
Iter: 842 loss: 9.33961055e-05
Iter: 843 loss: 9.33726405e-05
Iter: 844 loss: 9.34175187e-05
Iter: 845 loss: 9.3362818e-05
Iter: 846 loss: 9.33379779e-05
Iter: 847 loss: 9.33583578e-05
Iter: 848 loss: 9.33232805e-05
Iter: 849 loss: 9.33008632e-05
Iter: 850 loss: 9.36382858e-05
Iter: 851 loss: 9.33009869e-05
Iter: 852 loss: 9.32833063e-05
Iter: 853 loss: 9.33400443e-05
Iter: 854 loss: 9.32781259e-05
Iter: 855 loss: 9.32604671e-05
Iter: 856 loss: 9.32714902e-05
Iter: 857 loss: 9.3249444e-05
Iter: 858 loss: 9.32300754e-05
Iter: 859 loss: 9.32324619e-05
Iter: 860 loss: 9.3215509e-05
Iter: 861 loss: 9.31907489e-05
Iter: 862 loss: 9.33171686e-05
Iter: 863 loss: 9.31867253e-05
Iter: 864 loss: 9.31680261e-05
Iter: 865 loss: 9.32499534e-05
Iter: 866 loss: 9.31643735e-05
Iter: 867 loss: 9.31469112e-05
Iter: 868 loss: 9.33390838e-05
Iter: 869 loss: 9.31466056e-05
Iter: 870 loss: 9.31361719e-05
Iter: 871 loss: 9.3119932e-05
Iter: 872 loss: 9.31196773e-05
Iter: 873 loss: 9.30996903e-05
Iter: 874 loss: 9.31798277e-05
Iter: 875 loss: 9.30952083e-05
Iter: 876 loss: 9.30765e-05
Iter: 877 loss: 9.3111943e-05
Iter: 878 loss: 9.30685201e-05
Iter: 879 loss: 9.30484384e-05
Iter: 880 loss: 9.30660608e-05
Iter: 881 loss: 9.3036404e-05
Iter: 882 loss: 9.30185779e-05
Iter: 883 loss: 9.32502444e-05
Iter: 884 loss: 9.30184397e-05
Iter: 885 loss: 9.30035749e-05
Iter: 886 loss: 9.30565e-05
Iter: 887 loss: 9.29997477e-05
Iter: 888 loss: 9.29856542e-05
Iter: 889 loss: 9.30003516e-05
Iter: 890 loss: 9.29777e-05
Iter: 891 loss: 9.29630187e-05
Iter: 892 loss: 9.29621e-05
Iter: 893 loss: 9.2950977e-05
Iter: 894 loss: 9.29316593e-05
Iter: 895 loss: 9.30222668e-05
Iter: 896 loss: 9.29283269e-05
Iter: 897 loss: 9.29124726e-05
Iter: 898 loss: 9.29714e-05
Iter: 899 loss: 9.29087182e-05
Iter: 900 loss: 9.28955415e-05
Iter: 901 loss: 9.28954178e-05
Iter: 902 loss: 9.28875525e-05
Iter: 903 loss: 9.28738154e-05
Iter: 904 loss: 9.28737427e-05
Iter: 905 loss: 9.28577938e-05
Iter: 906 loss: 9.29174275e-05
Iter: 907 loss: 9.28539739e-05
Iter: 908 loss: 9.28388e-05
Iter: 909 loss: 9.28704685e-05
Iter: 910 loss: 9.28328227e-05
Iter: 911 loss: 9.28169102e-05
Iter: 912 loss: 9.28359805e-05
Iter: 913 loss: 9.28086083e-05
Iter: 914 loss: 9.27943911e-05
Iter: 915 loss: 9.29230737e-05
Iter: 916 loss: 9.27935907e-05
Iter: 917 loss: 9.27808796e-05
Iter: 918 loss: 9.283502e-05
Iter: 919 loss: 9.27778383e-05
Iter: 920 loss: 9.27662404e-05
Iter: 921 loss: 9.27820147e-05
Iter: 922 loss: 9.27605142e-05
Iter: 923 loss: 9.27487417e-05
Iter: 924 loss: 9.27445581e-05
Iter: 925 loss: 9.27378642e-05
Iter: 926 loss: 9.27212677e-05
Iter: 927 loss: 9.27929214e-05
Iter: 928 loss: 9.27180226e-05
Iter: 929 loss: 9.27037181e-05
Iter: 930 loss: 9.27518849e-05
Iter: 931 loss: 9.26999637e-05
Iter: 932 loss: 9.26904759e-05
Iter: 933 loss: 9.26900466e-05
Iter: 934 loss: 9.26836146e-05
Iter: 935 loss: 9.26714492e-05
Iter: 936 loss: 9.29406e-05
Iter: 937 loss: 9.26714056e-05
Iter: 938 loss: 9.26573e-05
Iter: 939 loss: 9.27057263e-05
Iter: 940 loss: 9.26537614e-05
Iter: 941 loss: 9.26403154e-05
Iter: 942 loss: 9.26764333e-05
Iter: 943 loss: 9.26359498e-05
Iter: 944 loss: 9.26226785e-05
Iter: 945 loss: 9.2638671e-05
Iter: 946 loss: 9.26160137e-05
Iter: 947 loss: 9.260347e-05
Iter: 948 loss: 9.26823777e-05
Iter: 949 loss: 9.26019e-05
Iter: 950 loss: 9.25902059e-05
Iter: 951 loss: 9.26610301e-05
Iter: 952 loss: 9.2588707e-05
Iter: 953 loss: 9.25792556e-05
Iter: 954 loss: 9.25915374e-05
Iter: 955 loss: 9.25744389e-05
Iter: 956 loss: 9.25643326e-05
Iter: 957 loss: 9.25605e-05
Iter: 958 loss: 9.25547938e-05
Iter: 959 loss: 9.25406e-05
Iter: 960 loss: 9.25943168e-05
Iter: 961 loss: 9.25373e-05
Iter: 962 loss: 9.25249624e-05
Iter: 963 loss: 9.25666682e-05
Iter: 964 loss: 9.25214554e-05
Iter: 965 loss: 9.25139466e-05
Iter: 966 loss: 9.25134955e-05
Iter: 967 loss: 9.25076602e-05
Iter: 968 loss: 9.24975902e-05
Iter: 969 loss: 9.2497663e-05
Iter: 970 loss: 9.24861524e-05
Iter: 971 loss: 9.25205532e-05
Iter: 972 loss: 9.248282e-05
Iter: 973 loss: 9.24721608e-05
Iter: 974 loss: 9.25042041e-05
Iter: 975 loss: 9.24688866e-05
Iter: 976 loss: 9.24582055e-05
Iter: 977 loss: 9.24701162e-05
Iter: 978 loss: 9.24521228e-05
Iter: 979 loss: 9.24411215e-05
Iter: 980 loss: 9.24912529e-05
Iter: 981 loss: 9.24390333e-05
Iter: 982 loss: 9.24293272e-05
Iter: 983 loss: 9.25201603e-05
Iter: 984 loss: 9.24289488e-05
Iter: 985 loss: 9.24216365e-05
Iter: 986 loss: 9.24270134e-05
Iter: 987 loss: 9.24171545e-05
Iter: 988 loss: 9.24080668e-05
Iter: 989 loss: 9.24058404e-05
Iter: 990 loss: 9.23998741e-05
Iter: 991 loss: 9.23880289e-05
Iter: 992 loss: 9.24354099e-05
Iter: 993 loss: 9.23853659e-05
Iter: 994 loss: 9.23754124e-05
Iter: 995 loss: 9.24037813e-05
Iter: 996 loss: 9.23722837e-05
Iter: 997 loss: 9.23659682e-05
Iter: 998 loss: 9.23657208e-05
Iter: 999 loss: 9.2360191e-05
Iter: 1000 loss: 9.23517364e-05
Iter: 1001 loss: 9.23516636e-05
Iter: 1002 loss: 9.23422194e-05
Iter: 1003 loss: 9.23706102e-05
Iter: 1004 loss: 9.2339309e-05
Iter: 1005 loss: 9.2330949e-05
Iter: 1006 loss: 9.23566695e-05
Iter: 1007 loss: 9.23283369e-05
Iter: 1008 loss: 9.23194311e-05
Iter: 1009 loss: 9.23289917e-05
Iter: 1010 loss: 9.23145271e-05
Iter: 1011 loss: 9.23051e-05
Iter: 1012 loss: 9.23354237e-05
Iter: 1013 loss: 9.23022599e-05
Iter: 1014 loss: 9.2294249e-05
Iter: 1015 loss: 9.24036285e-05
Iter: 1016 loss: 9.22942272e-05
Iter: 1017 loss: 9.22885665e-05
Iter: 1018 loss: 9.22908803e-05
Iter: 1019 loss: 9.22845575e-05
Iter: 1020 loss: 9.22767358e-05
Iter: 1021 loss: 9.22780891e-05
Iter: 1022 loss: 9.2270915e-05
Iter: 1023 loss: 9.22614563e-05
Iter: 1024 loss: 9.22863837e-05
Iter: 1025 loss: 9.22582694e-05
Iter: 1026 loss: 9.2249189e-05
Iter: 1027 loss: 9.22756881e-05
Iter: 1028 loss: 9.22462932e-05
Iter: 1029 loss: 9.22413674e-05
Iter: 1030 loss: 9.2240909e-05
Iter: 1031 loss: 9.22361287e-05
Iter: 1032 loss: 9.22303152e-05
Iter: 1033 loss: 9.22298786e-05
Iter: 1034 loss: 9.22224644e-05
Iter: 1035 loss: 9.22364488e-05
Iter: 1036 loss: 9.22194595e-05
Iter: 1037 loss: 9.2211747e-05
Iter: 1038 loss: 9.22336912e-05
Iter: 1039 loss: 9.22097606e-05
Iter: 1040 loss: 9.22015606e-05
Iter: 1041 loss: 9.22183317e-05
Iter: 1042 loss: 9.21986793e-05
Iter: 1043 loss: 9.21913525e-05
Iter: 1044 loss: 9.2202732e-05
Iter: 1045 loss: 9.21879546e-05
Iter: 1046 loss: 9.2180795e-05
Iter: 1047 loss: 9.22865147e-05
Iter: 1048 loss: 9.2180635e-05
Iter: 1049 loss: 9.21752071e-05
Iter: 1050 loss: 9.21767787e-05
Iter: 1051 loss: 9.21713945e-05
Iter: 1052 loss: 9.21641113e-05
Iter: 1053 loss: 9.21724713e-05
Iter: 1054 loss: 9.2160335e-05
Iter: 1055 loss: 9.21532192e-05
Iter: 1056 loss: 9.21640167e-05
Iter: 1057 loss: 9.21497e-05
Iter: 1058 loss: 9.21413812e-05
Iter: 1059 loss: 9.21627361e-05
Iter: 1060 loss: 9.21384708e-05
Iter: 1061 loss: 9.21345345e-05
Iter: 1062 loss: 9.2133836e-05
Iter: 1063 loss: 9.21298051e-05
Iter: 1064 loss: 9.21260798e-05
Iter: 1065 loss: 9.2125214e-05
Iter: 1066 loss: 9.21194296e-05
Iter: 1067 loss: 9.21254177e-05
Iter: 1068 loss: 9.21161554e-05
Iter: 1069 loss: 9.21092869e-05
Iter: 1070 loss: 9.21282553e-05
Iter: 1071 loss: 9.21069732e-05
Iter: 1072 loss: 9.21000465e-05
Iter: 1073 loss: 9.21223618e-05
Iter: 1074 loss: 9.20982275e-05
Iter: 1075 loss: 9.20922e-05
Iter: 1076 loss: 9.2096263e-05
Iter: 1077 loss: 9.20885286e-05
Iter: 1078 loss: 9.20827297e-05
Iter: 1079 loss: 9.20825e-05
Iter: 1080 loss: 9.20779e-05
Iter: 1081 loss: 9.20792e-05
Iter: 1082 loss: 9.20745588e-05
Iter: 1083 loss: 9.20687307e-05
Iter: 1084 loss: 9.20776947e-05
Iter: 1085 loss: 9.20659731e-05
Iter: 1086 loss: 9.20603779e-05
Iter: 1087 loss: 9.20651873e-05
Iter: 1088 loss: 9.20569873e-05
Iter: 1089 loss: 9.20500461e-05
Iter: 1090 loss: 9.20698076e-05
Iter: 1091 loss: 9.20476305e-05
Iter: 1092 loss: 9.20441089e-05
Iter: 1093 loss: 9.20436796e-05
Iter: 1094 loss: 9.20399616e-05
Iter: 1095 loss: 9.20371676e-05
Iter: 1096 loss: 9.2035858e-05
Iter: 1097 loss: 9.20308084e-05
Iter: 1098 loss: 9.20352613e-05
Iter: 1099 loss: 9.20279854e-05
Iter: 1100 loss: 9.20220918e-05
Iter: 1101 loss: 9.20389866e-05
Iter: 1102 loss: 9.20201e-05
Iter: 1103 loss: 9.20143357e-05
Iter: 1104 loss: 9.20339e-05
Iter: 1105 loss: 9.20128659e-05
Iter: 1106 loss: 9.20077582e-05
Iter: 1107 loss: 9.20111124e-05
Iter: 1108 loss: 9.20045204e-05
Iter: 1109 loss: 9.1999842e-05
Iter: 1110 loss: 9.19998274e-05
Iter: 1111 loss: 9.19963059e-05
Iter: 1112 loss: 9.19969098e-05
Iter: 1113 loss: 9.19934828e-05
Iter: 1114 loss: 9.19886952e-05
Iter: 1115 loss: 9.19966697e-05
Iter: 1116 loss: 9.19864542e-05
Iter: 1117 loss: 9.19816957e-05
Iter: 1118 loss: 9.19854065e-05
Iter: 1119 loss: 9.19788145e-05
Iter: 1120 loss: 9.19729282e-05
Iter: 1121 loss: 9.1990747e-05
Iter: 1122 loss: 9.19712184e-05
Iter: 1123 loss: 9.19675877e-05
Iter: 1124 loss: 9.19676386e-05
Iter: 1125 loss: 9.19639715e-05
Iter: 1126 loss: 9.19628947e-05
Iter: 1127 loss: 9.19607846e-05
Iter: 1128 loss: 9.19565646e-05
Iter: 1129 loss: 9.19600861e-05
Iter: 1130 loss: 9.19541708e-05
Iter: 1131 loss: 9.19495506e-05
Iter: 1132 loss: 9.19639133e-05
Iter: 1133 loss: 9.19481317e-05
Iter: 1134 loss: 9.19438316e-05
Iter: 1135 loss: 9.1956812e-05
Iter: 1136 loss: 9.19424638e-05
Iter: 1137 loss: 9.19381928e-05
Iter: 1138 loss: 9.19410086e-05
Iter: 1139 loss: 9.19354352e-05
Iter: 1140 loss: 9.19318263e-05
Iter: 1141 loss: 9.19319209e-05
Iter: 1142 loss: 9.1928945e-05
Iter: 1143 loss: 9.19300292e-05
Iter: 1144 loss: 9.19269369e-05
Iter: 1145 loss: 9.1923037e-05
Iter: 1146 loss: 9.19287e-05
Iter: 1147 loss: 9.19211889e-05
Iter: 1148 loss: 9.1917027e-05
Iter: 1149 loss: 9.19203e-05
Iter: 1150 loss: 9.19148442e-05
Iter: 1151 loss: 9.19098165e-05
Iter: 1152 loss: 9.19264276e-05
Iter: 1153 loss: 9.19085e-05
Iter: 1154 loss: 9.19052763e-05
Iter: 1155 loss: 9.19526065e-05
Iter: 1156 loss: 9.19052691e-05
Iter: 1157 loss: 9.19020604e-05
Iter: 1158 loss: 9.19040103e-05
Iter: 1159 loss: 9.18998e-05
Iter: 1160 loss: 9.18967271e-05
Iter: 1161 loss: 9.18980732e-05
Iter: 1162 loss: 9.18944716e-05
Iter: 1163 loss: 9.18908481e-05
Iter: 1164 loss: 9.19017e-05
Iter: 1165 loss: 9.18896621e-05
Iter: 1166 loss: 9.1886e-05
Iter: 1167 loss: 9.18971e-05
Iter: 1168 loss: 9.18848455e-05
Iter: 1169 loss: 9.18812875e-05
Iter: 1170 loss: 9.18844526e-05
Iter: 1171 loss: 9.18792648e-05
Iter: 1172 loss: 9.1876107e-05
Iter: 1173 loss: 9.18760779e-05
Iter: 1174 loss: 9.18732621e-05
Iter: 1175 loss: 9.18751903e-05
Iter: 1176 loss: 9.18714068e-05
Iter: 1177 loss: 9.18681471e-05
Iter: 1178 loss: 9.18732476e-05
Iter: 1179 loss: 9.18666774e-05
Iter: 1180 loss: 9.18632577e-05
Iter: 1181 loss: 9.18670921e-05
Iter: 1182 loss: 9.18614824e-05
Iter: 1183 loss: 9.18573787e-05
Iter: 1184 loss: 9.18681762e-05
Iter: 1185 loss: 9.18563e-05
Iter: 1186 loss: 9.18533769e-05
Iter: 1187 loss: 9.1887181e-05
Iter: 1188 loss: 9.18533333e-05
Iter: 1189 loss: 9.18501828e-05
Iter: 1190 loss: 9.18562728e-05
Iter: 1191 loss: 9.18490696e-05
Iter: 1192 loss: 9.18468795e-05
Iter: 1193 loss: 9.18466103e-05
Iter: 1194 loss: 9.18448786e-05
Iter: 1195 loss: 9.18418882e-05
Iter: 1196 loss: 9.18488731e-05
Iter: 1197 loss: 9.18406658e-05
Iter: 1198 loss: 9.18374499e-05
Iter: 1199 loss: 9.18480437e-05
Iter: 1200 loss: 9.18367441e-05
Iter: 1201 loss: 9.18335718e-05
Iter: 1202 loss: 9.18369187e-05
Iter: 1203 loss: 9.18318838e-05
Iter: 1204 loss: 9.18289879e-05
Iter: 1205 loss: 9.18613514e-05
Iter: 1206 loss: 9.18289225e-05
Iter: 1207 loss: 9.18263395e-05
Iter: 1208 loss: 9.18301157e-05
Iter: 1209 loss: 9.18251244e-05
Iter: 1210 loss: 9.18223377e-05
Iter: 1211 loss: 9.18256555e-05
Iter: 1212 loss: 9.18209771e-05
Iter: 1213 loss: 9.18180885e-05
Iter: 1214 loss: 9.18221267e-05
Iter: 1215 loss: 9.18167352e-05
Iter: 1216 loss: 9.18134756e-05
Iter: 1217 loss: 9.18214e-05
Iter: 1218 loss: 9.18122096e-05
Iter: 1219 loss: 9.18098813e-05
Iter: 1220 loss: 9.18342266e-05
Iter: 1221 loss: 9.18096484e-05
Iter: 1222 loss: 9.1807e-05
Iter: 1223 loss: 9.18158185e-05
Iter: 1224 loss: 9.18062506e-05
Iter: 1225 loss: 9.18045262e-05
Iter: 1226 loss: 9.18037549e-05
Iter: 1227 loss: 9.18027217e-05
Iter: 1228 loss: 9.17998696e-05
Iter: 1229 loss: 9.1805734e-05
Iter: 1230 loss: 9.17987927e-05
Iter: 1231 loss: 9.17960569e-05
Iter: 1232 loss: 9.18059595e-05
Iter: 1233 loss: 9.17953e-05
Iter: 1234 loss: 9.179263e-05
Iter: 1235 loss: 9.17955185e-05
Iter: 1236 loss: 9.17909783e-05
Iter: 1237 loss: 9.17884e-05
Iter: 1238 loss: 9.18144506e-05
Iter: 1239 loss: 9.17883372e-05
Iter: 1240 loss: 9.17858561e-05
Iter: 1241 loss: 9.17915e-05
Iter: 1242 loss: 9.1785012e-05
Iter: 1243 loss: 9.17829311e-05
Iter: 1244 loss: 9.17846482e-05
Iter: 1245 loss: 9.17816578e-05
Iter: 1246 loss: 9.17792786e-05
Iter: 1247 loss: 9.17828147e-05
Iter: 1248 loss: 9.17780417e-05
Iter: 1249 loss: 9.17752477e-05
Iter: 1250 loss: 9.17817524e-05
Iter: 1251 loss: 9.177436e-05
Iter: 1252 loss: 9.17723082e-05
Iter: 1253 loss: 9.17894868e-05
Iter: 1254 loss: 9.17719153e-05
Iter: 1255 loss: 9.17696307e-05
Iter: 1256 loss: 9.17803263e-05
Iter: 1257 loss: 9.17692087e-05
Iter: 1258 loss: 9.17678262e-05
Iter: 1259 loss: 9.17664293e-05
Iter: 1260 loss: 9.17658326e-05
Iter: 1261 loss: 9.17634e-05
Iter: 1262 loss: 9.17696307e-05
Iter: 1263 loss: 9.17624857e-05
Iter: 1264 loss: 9.17600119e-05
Iter: 1265 loss: 9.17687721e-05
Iter: 1266 loss: 9.17592697e-05
Iter: 1267 loss: 9.17567813e-05
Iter: 1268 loss: 9.17598882e-05
Iter: 1269 loss: 9.1755559e-05
Iter: 1270 loss: 9.17534126e-05
Iter: 1271 loss: 9.1772119e-05
Iter: 1272 loss: 9.17532598e-05
Iter: 1273 loss: 9.17513607e-05
Iter: 1274 loss: 9.17582802e-05
Iter: 1275 loss: 9.17505895e-05
Iter: 1276 loss: 9.17488796e-05
Iter: 1277 loss: 9.17495927e-05
Iter: 1278 loss: 9.17477373e-05
Iter: 1279 loss: 9.17455909e-05
Iter: 1280 loss: 9.17485595e-05
Iter: 1281 loss: 9.17444122e-05
Iter: 1282 loss: 9.17418802e-05
Iter: 1283 loss: 9.17484431e-05
Iter: 1284 loss: 9.17410798e-05
Iter: 1285 loss: 9.17389698e-05
Iter: 1286 loss: 9.17526413e-05
Iter: 1287 loss: 9.17387879e-05
Iter: 1288 loss: 9.17367361e-05
Iter: 1289 loss: 9.1750655e-05
Iter: 1290 loss: 9.17365833e-05
Iter: 1291 loss: 9.17351572e-05
Iter: 1292 loss: 9.17337238e-05
Iter: 1293 loss: 9.17334692e-05
Iter: 1294 loss: 9.17312136e-05
Iter: 1295 loss: 9.17386569e-05
Iter: 1296 loss: 9.1730486e-05
Iter: 1297 loss: 9.17284196e-05
Iter: 1298 loss: 9.17348516e-05
Iter: 1299 loss: 9.17279176e-05
Iter: 1300 loss: 9.17257566e-05
Iter: 1301 loss: 9.17287398e-05
Iter: 1302 loss: 9.17246798e-05
Iter: 1303 loss: 9.17226353e-05
Iter: 1304 loss: 9.17352154e-05
Iter: 1305 loss: 9.17225e-05
Iter: 1306 loss: 9.17205616e-05
Iter: 1307 loss: 9.17305661e-05
Iter: 1308 loss: 9.17202196e-05
Iter: 1309 loss: 9.17187e-05
Iter: 1310 loss: 9.17186553e-05
Iter: 1311 loss: 9.17176367e-05
Iter: 1312 loss: 9.17153957e-05
Iter: 1313 loss: 9.17183861e-05
Iter: 1314 loss: 9.17144353e-05
Iter: 1315 loss: 9.17122088e-05
Iter: 1316 loss: 9.17185243e-05
Iter: 1317 loss: 9.17114667e-05
Iter: 1318 loss: 9.17095749e-05
Iter: 1319 loss: 9.17189245e-05
Iter: 1320 loss: 9.17092766e-05
Iter: 1321 loss: 9.17073339e-05
Iter: 1322 loss: 9.17288417e-05
Iter: 1323 loss: 9.17072321e-05
Iter: 1324 loss: 9.17063589e-05
Iter: 1325 loss: 9.17045254e-05
Iter: 1326 loss: 9.17045254e-05
Iter: 1327 loss: 9.1702459e-05
Iter: 1328 loss: 9.17101352e-05
Iter: 1329 loss: 9.17019497e-05
Iter: 1330 loss: 9.1700058e-05
Iter: 1331 loss: 9.17049183e-05
Iter: 1332 loss: 9.16993304e-05
Iter: 1333 loss: 9.1697555e-05
Iter: 1334 loss: 9.17012803e-05
Iter: 1335 loss: 9.16966819e-05
Iter: 1336 loss: 9.16948775e-05
Iter: 1337 loss: 9.17038415e-05
Iter: 1338 loss: 9.16946374e-05
Iter: 1339 loss: 9.16928839e-05
Iter: 1340 loss: 9.1703725e-05
Iter: 1341 loss: 9.16926074e-05
Iter: 1342 loss: 9.16914796e-05
Iter: 1343 loss: 9.1690963e-05
Iter: 1344 loss: 9.16903155e-05
Iter: 1345 loss: 9.16883e-05
Iter: 1346 loss: 9.16917415e-05
Iter: 1347 loss: 9.16875651e-05
Iter: 1348 loss: 9.16854478e-05
Iter: 1349 loss: 9.16908612e-05
Iter: 1350 loss: 9.16848294e-05
Iter: 1351 loss: 9.16828722e-05
Iter: 1352 loss: 9.16884455e-05
Iter: 1353 loss: 9.16823046e-05
Iter: 1354 loss: 9.16807694e-05
Iter: 1355 loss: 9.16807039e-05
Iter: 1356 loss: 9.16798308e-05
Iter: 1357 loss: 9.16780846e-05
Iter: 1358 loss: 9.17134821e-05
Iter: 1359 loss: 9.16782301e-05
Iter: 1360 loss: 9.16762801e-05
Iter: 1361 loss: 9.16841454e-05
Iter: 1362 loss: 9.16758072e-05
Iter: 1363 loss: 9.1674061e-05
Iter: 1364 loss: 9.16783756e-05
Iter: 1365 loss: 9.16734716e-05
Iter: 1366 loss: 9.1671609e-05
Iter: 1367 loss: 9.16761273e-05
Iter: 1368 loss: 9.16711506e-05
Iter: 1369 loss: 9.16696226e-05
Iter: 1370 loss: 9.16752106e-05
Iter: 1371 loss: 9.16689314e-05
Iter: 1372 loss: 9.16675635e-05
Iter: 1373 loss: 9.16803547e-05
Iter: 1374 loss: 9.16674617e-05
Iter: 1375 loss: 9.16663266e-05
Iter: 1376 loss: 9.1665941e-05
Iter: 1377 loss: 9.16652061e-05
Iter: 1378 loss: 9.16636563e-05
Iter: 1379 loss: 9.16663776e-05
Iter: 1380 loss: 9.1662936e-05
Iter: 1381 loss: 9.1661117e-05
Iter: 1382 loss: 9.16664721e-05
Iter: 1383 loss: 9.16604404e-05
Iter: 1384 loss: 9.16588833e-05
Iter: 1385 loss: 9.16617719e-05
Iter: 1386 loss: 9.16581339e-05
Iter: 1387 loss: 9.16570862e-05
Iter: 1388 loss: 9.16569843e-05
Iter: 1389 loss: 9.16562567e-05
Iter: 1390 loss: 9.16547433e-05
Iter: 1391 loss: 9.16788049e-05
Iter: 1392 loss: 9.16548088e-05
Iter: 1393 loss: 9.1653128e-05
Iter: 1394 loss: 9.16590652e-05
Iter: 1395 loss: 9.16526624e-05
Iter: 1396 loss: 9.16513236e-05
Iter: 1397 loss: 9.16549543e-05
Iter: 1398 loss: 9.16505815e-05
Iter: 1399 loss: 9.16491845e-05
Iter: 1400 loss: 9.16536e-05
Iter: 1401 loss: 9.16486315e-05
Iter: 1402 loss: 9.16472491e-05
Iter: 1403 loss: 9.16513891e-05
Iter: 1404 loss: 9.1646958e-05
Iter: 1405 loss: 9.1645612e-05
Iter: 1406 loss: 9.16568824e-05
Iter: 1407 loss: 9.16454883e-05
Iter: 1408 loss: 9.16443823e-05
Iter: 1409 loss: 9.16443314e-05
Iter: 1410 loss: 9.16435238e-05
Iter: 1411 loss: 9.16420104e-05
Iter: 1412 loss: 9.16442223e-05
Iter: 1413 loss: 9.16414574e-05
Iter: 1414 loss: 9.16399949e-05
Iter: 1415 loss: 9.16457939e-05
Iter: 1416 loss: 9.16394638e-05
Iter: 1417 loss: 9.16381687e-05
Iter: 1418 loss: 9.16394783e-05
Iter: 1419 loss: 9.16375138e-05
Iter: 1420 loss: 9.16366334e-05
Iter: 1421 loss: 9.16365389e-05
Iter: 1422 loss: 9.16358113e-05
Iter: 1423 loss: 9.16346326e-05
Iter: 1424 loss: 9.16559657e-05
Iter: 1425 loss: 9.16344143e-05
Iter: 1426 loss: 9.16328354e-05
Iter: 1427 loss: 9.16386416e-05
Iter: 1428 loss: 9.16325516e-05
Iter: 1429 loss: 9.16311328e-05
Iter: 1430 loss: 9.16352437e-05
Iter: 1431 loss: 9.16308345e-05
Iter: 1432 loss: 9.16293211e-05
Iter: 1433 loss: 9.16326098e-05
Iter: 1434 loss: 9.1629e-05
Iter: 1435 loss: 9.16277204e-05
Iter: 1436 loss: 9.16302815e-05
Iter: 1437 loss: 9.16272184e-05
Iter: 1438 loss: 9.16259305e-05
Iter: 1439 loss: 9.16406716e-05
Iter: 1440 loss: 9.16258723e-05
Iter: 1441 loss: 9.16249337e-05
Iter: 1442 loss: 9.16250574e-05
Iter: 1443 loss: 9.16241261e-05
Iter: 1444 loss: 9.16231438e-05
Iter: 1445 loss: 9.16246427e-05
Iter: 1446 loss: 9.16225545e-05
Iter: 1447 loss: 9.16211138e-05
Iter: 1448 loss: 9.16253412e-05
Iter: 1449 loss: 9.16206482e-05
Iter: 1450 loss: 9.16194113e-05
Iter: 1451 loss: 9.16216959e-05
Iter: 1452 loss: 9.16187128e-05
Iter: 1453 loss: 9.16180288e-05
Iter: 1454 loss: 9.16180725e-05
Iter: 1455 loss: 9.16173522e-05
Iter: 1456 loss: 9.16163044e-05
Iter: 1457 loss: 9.16363933e-05
Iter: 1458 loss: 9.16162826e-05
Iter: 1459 loss: 9.16147837e-05
Iter: 1460 loss: 9.16191784e-05
Iter: 1461 loss: 9.16146091e-05
Iter: 1462 loss: 9.16133e-05
Iter: 1463 loss: 9.16164863e-05
Iter: 1464 loss: 9.1612892e-05
Iter: 1465 loss: 9.16116551e-05
Iter: 1466 loss: 9.16143617e-05
Iter: 1467 loss: 9.16111167e-05
Iter: 1468 loss: 9.16098943e-05
Iter: 1469 loss: 9.16126155e-05
Iter: 1470 loss: 9.16093704e-05
Iter: 1471 loss: 9.16083809e-05
Iter: 1472 loss: 9.16232311e-05
Iter: 1473 loss: 9.16083081e-05
Iter: 1474 loss: 9.16074641e-05
Iter: 1475 loss: 9.16071876e-05
Iter: 1476 loss: 9.16068675e-05
Iter: 1477 loss: 9.16056e-05
Iter: 1478 loss: 9.16071149e-05
Iter: 1479 loss: 9.16049758e-05
Iter: 1480 loss: 9.16039135e-05
Iter: 1481 loss: 9.16088902e-05
Iter: 1482 loss: 9.16034332e-05
Iter: 1483 loss: 9.16022109e-05
Iter: 1484 loss: 9.16046265e-05
Iter: 1485 loss: 9.16016725e-05
Iter: 1486 loss: 9.16012359e-05
Iter: 1487 loss: 9.16011923e-05
Iter: 1488 loss: 9.16006175e-05
Iter: 1489 loss: 9.15995333e-05
Iter: 1490 loss: 9.1622016e-05
Iter: 1491 loss: 9.15994315e-05
Iter: 1492 loss: 9.15984128e-05
Iter: 1493 loss: 9.16023564e-05
Iter: 1494 loss: 9.15982091e-05
Iter: 1495 loss: 9.15970886e-05
Iter: 1496 loss: 9.15996061e-05
Iter: 1497 loss: 9.15966593e-05
Iter: 1498 loss: 9.15956189e-05
Iter: 1499 loss: 9.15983837e-05
Iter: 1500 loss: 9.15953715e-05
Iter: 1501 loss: 9.15941782e-05
Iter: 1502 loss: 9.15965356e-05
Iter: 1503 loss: 9.15937417e-05
Iter: 1504 loss: 9.1592854e-05
Iter: 1505 loss: 9.1605958e-05
Iter: 1506 loss: 9.15927667e-05
Iter: 1507 loss: 9.15921701e-05
Iter: 1508 loss: 9.15916316e-05
Iter: 1509 loss: 9.15914279e-05
Iter: 1510 loss: 9.15902492e-05
Iter: 1511 loss: 9.15919081e-05
Iter: 1512 loss: 9.15898272e-05
Iter: 1513 loss: 9.15887722e-05
Iter: 1514 loss: 9.15936107e-05
Iter: 1515 loss: 9.15884593e-05
Iter: 1516 loss: 9.15875135e-05
Iter: 1517 loss: 9.15893834e-05
Iter: 1518 loss: 9.15870696e-05
Iter: 1519 loss: 9.15866112e-05
Iter: 1520 loss: 9.15866913e-05
Iter: 1521 loss: 9.15860146e-05
Iter: 1522 loss: 9.15851706e-05
Iter: 1523 loss: 9.15850469e-05
Iter: 1524 loss: 9.15842829e-05
Iter: 1525 loss: 9.15865676e-05
Iter: 1526 loss: 9.15839046e-05
Iter: 1527 loss: 9.15830315e-05
Iter: 1528 loss: 9.15850251e-05
Iter: 1529 loss: 9.15824057e-05
Iter: 1530 loss: 9.15815253e-05
Iter: 1531 loss: 9.15843848e-05
Iter: 1532 loss: 9.15813e-05
Iter: 1533 loss: 9.15803539e-05
Iter: 1534 loss: 9.15825076e-05
Iter: 1535 loss: 9.15799e-05
Iter: 1536 loss: 9.15790806e-05
Iter: 1537 loss: 9.15896526e-05
Iter: 1538 loss: 9.15790879e-05
Iter: 1539 loss: 9.15783457e-05
Iter: 1540 loss: 9.15781493e-05
Iter: 1541 loss: 9.15778728e-05
Iter: 1542 loss: 9.1577e-05
Iter: 1543 loss: 9.15781638e-05
Iter: 1544 loss: 9.15764904e-05
Iter: 1545 loss: 9.15754208e-05
Iter: 1546 loss: 9.15795463e-05
Iter: 1547 loss: 9.15753189e-05
Iter: 1548 loss: 9.15743731e-05
Iter: 1549 loss: 9.15759447e-05
Iter: 1550 loss: 9.15741184e-05
Iter: 1551 loss: 9.15734709e-05
Iter: 1552 loss: 9.15735145e-05
Iter: 1553 loss: 9.15730052e-05
Iter: 1554 loss: 9.15721612e-05
Iter: 1555 loss: 9.15723e-05
Iter: 1556 loss: 9.15713608e-05
Iter: 1557 loss: 9.15728451e-05
Iter: 1558 loss: 9.1571128e-05
Iter: 1559 loss: 9.15702694e-05
Iter: 1560 loss: 9.15726705e-05
Iter: 1561 loss: 9.15700221e-05
Iter: 1562 loss: 9.15692217e-05
Iter: 1563 loss: 9.15709388e-05
Iter: 1564 loss: 9.15688724e-05
Iter: 1565 loss: 9.15679557e-05
Iter: 1566 loss: 9.15700948e-05
Iter: 1567 loss: 9.15676646e-05
Iter: 1568 loss: 9.1567068e-05
Iter: 1569 loss: 9.1577167e-05
Iter: 1570 loss: 9.15671262e-05
Iter: 1571 loss: 9.15664132e-05
Iter: 1572 loss: 9.15663477e-05
Iter: 1573 loss: 9.15660057e-05
Iter: 1574 loss: 9.15654091e-05
Iter: 1575 loss: 9.15663e-05
Iter: 1576 loss: 9.15649e-05
Iter: 1577 loss: 9.15640703e-05
Iter: 1578 loss: 9.1566646e-05
Iter: 1579 loss: 9.15639539e-05
Iter: 1580 loss: 9.1563139e-05
Iter: 1581 loss: 9.15655255e-05
Iter: 1582 loss: 9.15627606e-05
Iter: 1583 loss: 9.15624e-05
Iter: 1584 loss: 9.15624e-05
Iter: 1585 loss: 9.15618366e-05
Iter: 1586 loss: 9.15614364e-05
Iter: 1587 loss: 9.15612181e-05
Iter: 1588 loss: 9.15606652e-05
Iter: 1589 loss: 9.15613928e-05
Iter: 1590 loss: 9.1560396e-05
Iter: 1591 loss: 9.15595592e-05
Iter: 1592 loss: 9.15626588e-05
Iter: 1593 loss: 9.15594574e-05
Iter: 1594 loss: 9.15586788e-05
Iter: 1595 loss: 9.15602868e-05
Iter: 1596 loss: 9.15584897e-05
Iter: 1597 loss: 9.15577111e-05
Iter: 1598 loss: 9.15591081e-05
Iter: 1599 loss: 9.15575365e-05
Iter: 1600 loss: 9.15569763e-05
Iter: 1601 loss: 9.15644487e-05
Iter: 1602 loss: 9.15568962e-05
Iter: 1603 loss: 9.15563432e-05
Iter: 1604 loss: 9.15565761e-05
Iter: 1605 loss: 9.15558776e-05
Iter: 1606 loss: 9.15552882e-05
Iter: 1607 loss: 9.15559e-05
Iter: 1608 loss: 9.15548953e-05
Iter: 1609 loss: 9.15543351e-05
Iter: 1610 loss: 9.15558194e-05
Iter: 1611 loss: 9.15541677e-05
Iter: 1612 loss: 9.15533528e-05
Iter: 1613 loss: 9.15566779e-05
Iter: 1614 loss: 9.15532291e-05
Iter: 1615 loss: 9.15527344e-05
Iter: 1616 loss: 9.15581913e-05
Iter: 1617 loss: 9.1552909e-05
Iter: 1618 loss: 9.15522396e-05
Iter: 1619 loss: 9.15522542e-05
Iter: 1620 loss: 9.15518467e-05
Iter: 1621 loss: 9.15514247e-05
Iter: 1622 loss: 9.15513592e-05
Iter: 1623 loss: 9.15509736e-05
Iter: 1624 loss: 9.15502824e-05
Iter: 1625 loss: 9.15534183e-05
Iter: 1626 loss: 9.15499841e-05
Iter: 1627 loss: 9.15496057e-05
Iter: 1628 loss: 9.15507699e-05
Iter: 1629 loss: 9.15493147e-05
Iter: 1630 loss: 9.15486744e-05
Iter: 1631 loss: 9.15498676e-05
Iter: 1632 loss: 9.15485361e-05
Iter: 1633 loss: 9.15479104e-05
Iter: 1634 loss: 9.15548735e-05
Iter: 1635 loss: 9.15479e-05
Iter: 1636 loss: 9.15474666e-05
Iter: 1637 loss: 9.1547925e-05
Iter: 1638 loss: 9.15473065e-05
Iter: 1639 loss: 9.15468e-05
Iter: 1640 loss: 9.15469e-05
Iter: 1641 loss: 9.15462442e-05
Iter: 1642 loss: 9.15457276e-05
Iter: 1643 loss: 9.15470155e-05
Iter: 1644 loss: 9.15454366e-05
Iter: 1645 loss: 9.15450146e-05
Iter: 1646 loss: 9.15483397e-05
Iter: 1647 loss: 9.15447672e-05
Iter: 1648 loss: 9.15445053e-05
Iter: 1649 loss: 9.15482378e-05
Iter: 1650 loss: 9.15445e-05
Iter: 1651 loss: 9.15441924e-05
Iter: 1652 loss: 9.15441924e-05
Iter: 1653 loss: 9.15436685e-05
Iter: 1654 loss: 9.15433047e-05
Iter: 1655 loss: 9.15431301e-05
Iter: 1656 loss: 9.15427227e-05
Iter: 1657 loss: 9.15423661e-05
Iter: 1658 loss: 9.15454148e-05
Iter: 1659 loss: 9.15423e-05
Iter: 1660 loss: 9.15417477e-05
Iter: 1661 loss: 9.15425626e-05
Iter: 1662 loss: 9.15414e-05
Iter: 1663 loss: 9.15408891e-05
Iter: 1664 loss: 9.1541966e-05
Iter: 1665 loss: 9.15407e-05
Iter: 1666 loss: 9.15403507e-05
Iter: 1667 loss: 9.15456621e-05
Iter: 1668 loss: 9.15402488e-05
Iter: 1669 loss: 9.15398923e-05
Iter: 1670 loss: 9.15401251e-05
Iter: 1671 loss: 9.15396085e-05
Iter: 1672 loss: 9.15392e-05
Iter: 1673 loss: 9.15393102e-05
Iter: 1674 loss: 9.15387645e-05
Iter: 1675 loss: 9.15383571e-05
Iter: 1676 loss: 9.15396158e-05
Iter: 1677 loss: 9.15381097e-05
Iter: 1678 loss: 9.15376877e-05
Iter: 1679 loss: 9.15406563e-05
Iter: 1680 loss: 9.15375858e-05
Iter: 1681 loss: 9.15371784e-05
Iter: 1682 loss: 9.15395067e-05
Iter: 1683 loss: 9.15371565e-05
Iter: 1684 loss: 9.15368291e-05
Iter: 1685 loss: 9.15375131e-05
Iter: 1686 loss: 9.15365e-05
Iter: 1687 loss: 9.15363489e-05
Iter: 1688 loss: 9.15359706e-05
Iter: 1689 loss: 9.15358105e-05
Iter: 1690 loss: 9.15354321e-05
Iter: 1691 loss: 9.15380078e-05
Iter: 1692 loss: 9.15352866e-05
Iter: 1693 loss: 9.1534821e-05
Iter: 1694 loss: 9.1535614e-05
Iter: 1695 loss: 9.15346682e-05
Iter: 1696 loss: 9.15341225e-05
Iter: 1697 loss: 9.15352502e-05
Iter: 1698 loss: 9.15340715e-05
Iter: 1699 loss: 9.1533635e-05
Iter: 1700 loss: 9.15376149e-05
Iter: 1701 loss: 9.15334822e-05
Iter: 1702 loss: 9.15331038e-05
Iter: 1703 loss: 9.15336859e-05
Iter: 1704 loss: 9.15329219e-05
Iter: 1705 loss: 9.15327109e-05
Iter: 1706 loss: 9.15326527e-05
Iter: 1707 loss: 9.15323617e-05
Iter: 1708 loss: 9.15318087e-05
Iter: 1709 loss: 9.15328274e-05
Iter: 1710 loss: 9.15316705e-05
Iter: 1711 loss: 9.15312412e-05
Iter: 1712 loss: 9.15334676e-05
Iter: 1713 loss: 9.15310811e-05
Iter: 1714 loss: 9.15306591e-05
Iter: 1715 loss: 9.15329583e-05
Iter: 1716 loss: 9.15306882e-05
Iter: 1717 loss: 9.15303608e-05
Iter: 1718 loss: 9.15315e-05
Iter: 1719 loss: 9.15302589e-05
Iter: 1720 loss: 9.15300188e-05
Iter: 1721 loss: 9.15296696e-05
Iter: 1722 loss: 9.1529575e-05
Iter: 1723 loss: 9.15292112e-05
Iter: 1724 loss: 9.15313722e-05
Iter: 1725 loss: 9.15291894e-05
Iter: 1726 loss: 9.15285782e-05
Iter: 1727 loss: 9.15295604e-05
Iter: 1728 loss: 9.15285127e-05
Iter: 1729 loss: 9.15281125e-05
Iter: 1730 loss: 9.15291603e-05
Iter: 1731 loss: 9.15279306e-05
Iter: 1732 loss: 9.15276e-05
Iter: 1733 loss: 9.15306737e-05
Iter: 1734 loss: 9.15275741e-05
Iter: 1735 loss: 9.15272394e-05
Iter: 1736 loss: 9.15278215e-05
Iter: 1737 loss: 9.15271667e-05
Iter: 1738 loss: 9.15269629e-05
Iter: 1739 loss: 9.15269848e-05
Iter: 1740 loss: 9.15266064e-05
Iter: 1741 loss: 9.15262863e-05
Iter: 1742 loss: 9.15268174e-05
Iter: 1743 loss: 9.15260171e-05
Iter: 1744 loss: 9.15256678e-05
Iter: 1745 loss: 9.1527545e-05
Iter: 1746 loss: 9.15254859e-05
Iter: 1747 loss: 9.15252167e-05
Iter: 1748 loss: 9.15271085e-05
Iter: 1749 loss: 9.1525173e-05
Iter: 1750 loss: 9.15248092e-05
Iter: 1751 loss: 9.15266792e-05
Iter: 1752 loss: 9.15249111e-05
Iter: 1753 loss: 9.15247874e-05
Iter: 1754 loss: 9.15242563e-05
Iter: 1755 loss: 9.15321216e-05
Iter: 1756 loss: 9.15243072e-05
Iter: 1757 loss: 9.15239652e-05
Iter: 1758 loss: 9.1525857e-05
Iter: 1759 loss: 9.15238779e-05
Iter: 1760 loss: 9.15233541e-05
Iter: 1761 loss: 9.15244163e-05
Iter: 1762 loss: 9.15231212e-05
Iter: 1763 loss: 9.15229e-05
Iter: 1764 loss: 9.15236e-05
Iter: 1765 loss: 9.15228738e-05
Iter: 1766 loss: 9.15225392e-05
Iter: 1767 loss: 9.15250857e-05
Iter: 1768 loss: 9.152251e-05
Iter: 1769 loss: 9.15221244e-05
Iter: 1770 loss: 9.15228447e-05
Iter: 1771 loss: 9.15220662e-05
Iter: 1772 loss: 9.15218188e-05
Iter: 1773 loss: 9.15218261e-05
Iter: 1774 loss: 9.15215642e-05
Iter: 1775 loss: 9.15212586e-05
Iter: 1776 loss: 9.15217097e-05
Iter: 1777 loss: 9.15209821e-05
Iter: 1778 loss: 9.15207056e-05
Iter: 1779 loss: 9.15225683e-05
Iter: 1780 loss: 9.15206401e-05
Iter: 1781 loss: 9.15203564e-05
Iter: 1782 loss: 9.15221317e-05
Iter: 1783 loss: 9.15202909e-05
Iter: 1784 loss: 9.15200726e-05
Iter: 1785 loss: 9.15220153e-05
Iter: 1786 loss: 9.15200071e-05
Iter: 1787 loss: 9.15198398e-05
Iter: 1788 loss: 9.15195633e-05
Iter: 1789 loss: 9.15264e-05
Iter: 1790 loss: 9.15195924e-05
Iter: 1791 loss: 9.1519345e-05
Iter: 1792 loss: 9.15209239e-05
Iter: 1793 loss: 9.15192068e-05
Iter: 1794 loss: 9.1518843e-05
Iter: 1795 loss: 9.15195269e-05
Iter: 1796 loss: 9.15187848e-05
Iter: 1797 loss: 9.15185083e-05
Iter: 1798 loss: 9.15187484e-05
Iter: 1799 loss: 9.15183555e-05
Iter: 1800 loss: 9.15179262e-05
Iter: 1801 loss: 9.15206692e-05
Iter: 1802 loss: 9.15179698e-05
Iter: 1803 loss: 9.15175042e-05
Iter: 1804 loss: 9.15182e-05
Iter: 1805 loss: 9.15176497e-05
Iter: 1806 loss: 9.15173587e-05
Iter: 1807 loss: 9.15175769e-05
Iter: 1808 loss: 9.15171258e-05
Iter: 1809 loss: 9.15168e-05
Iter: 1810 loss: 9.15176279e-05
Iter: 1811 loss: 9.1516682e-05
Iter: 1812 loss: 9.15165292e-05
Iter: 1813 loss: 9.15180572e-05
Iter: 1814 loss: 9.15164128e-05
Iter: 1815 loss: 9.15161654e-05
Iter: 1816 loss: 9.15172277e-05
Iter: 1817 loss: 9.15160781e-05
Iter: 1818 loss: 9.15157871e-05
Iter: 1819 loss: 9.15177516e-05
Iter: 1820 loss: 9.15157943e-05
Iter: 1821 loss: 9.15155542e-05
Iter: 1822 loss: 9.15154378e-05
Iter: 1823 loss: 9.15212e-05
Iter: 1824 loss: 9.15153942e-05
Iter: 1825 loss: 9.15151104e-05
Iter: 1826 loss: 9.15165074e-05
Iter: 1827 loss: 9.15152e-05
Iter: 1828 loss: 9.15149e-05
Iter: 1829 loss: 9.15155179e-05
Iter: 1830 loss: 9.15148121e-05
Iter: 1831 loss: 9.15146156e-05
Iter: 1832 loss: 9.15149139e-05
Iter: 1833 loss: 9.15142155e-05
Iter: 1834 loss: 9.15140117e-05
Iter: 1835 loss: 9.15159617e-05
Iter: 1836 loss: 9.15139826e-05
Iter: 1837 loss: 9.15137207e-05
Iter: 1838 loss: 9.15143173e-05
Iter: 1839 loss: 9.15137e-05
Iter: 1840 loss: 9.15134733e-05
Iter: 1841 loss: 9.15134588e-05
Iter: 1842 loss: 9.15134442e-05
Iter: 1843 loss: 9.15131e-05
Iter: 1844 loss: 9.15138517e-05
Iter: 1845 loss: 9.15128767e-05
Iter: 1846 loss: 9.1512622e-05
Iter: 1847 loss: 9.15136188e-05
Iter: 1848 loss: 9.15126584e-05
Iter: 1849 loss: 9.15124256e-05
Iter: 1850 loss: 9.15133e-05
Iter: 1851 loss: 9.15122946e-05
Iter: 1852 loss: 9.151212e-05
Iter: 1853 loss: 9.15140117e-05
Iter: 1854 loss: 9.15120909e-05
Iter: 1855 loss: 9.15120327e-05
Iter: 1856 loss: 9.15119e-05
Iter: 1857 loss: 9.15167038e-05
Iter: 1858 loss: 9.15118071e-05
Iter: 1859 loss: 9.1511567e-05
Iter: 1860 loss: 9.15125347e-05
Iter: 1861 loss: 9.15115888e-05
Iter: 1862 loss: 9.15111596e-05
Iter: 1863 loss: 9.15122146e-05
Iter: 1864 loss: 9.15110795e-05
Iter: 1865 loss: 9.15107084e-05
Iter: 1866 loss: 9.15114215e-05
Iter: 1867 loss: 9.15108103e-05
Iter: 1868 loss: 9.15104392e-05
Iter: 1869 loss: 9.15116325e-05
Iter: 1870 loss: 9.15104611e-05
Iter: 1871 loss: 9.15102282e-05
Iter: 1872 loss: 9.15113633e-05
Iter: 1873 loss: 9.15102137e-05
Iter: 1874 loss: 9.15100682e-05
Iter: 1875 loss: 9.1509959e-05
Iter: 1876 loss: 9.15098644e-05
Iter: 1877 loss: 9.15096e-05
Iter: 1878 loss: 9.15103083e-05
Iter: 1879 loss: 9.15096316e-05
Iter: 1880 loss: 9.15092533e-05
Iter: 1881 loss: 9.15099881e-05
Iter: 1882 loss: 9.15093115e-05
Iter: 1883 loss: 9.15090059e-05
Iter: 1884 loss: 9.1510221e-05
Iter: 1885 loss: 9.15088895e-05
Iter: 1886 loss: 9.1508773e-05
Iter: 1887 loss: 9.15110431e-05
Iter: 1888 loss: 9.15088604e-05
Iter: 1889 loss: 9.15088604e-05
Iter: 1890 loss: 9.15083656e-05
Iter: 1891 loss: 9.15126438e-05
Iter: 1892 loss: 9.15084092e-05
Iter: 1893 loss: 9.15081764e-05
Iter: 1894 loss: 9.15088385e-05
Iter: 1895 loss: 9.15081182e-05
Iter: 1896 loss: 9.15079145e-05
Iter: 1897 loss: 9.1508773e-05
Iter: 1898 loss: 9.15078126e-05
Iter: 1899 loss: 9.1507638e-05
Iter: 1900 loss: 9.15080745e-05
Iter: 1901 loss: 9.15075216e-05
Iter: 1902 loss: 9.15072451e-05
Iter: 1903 loss: 9.15080163e-05
Iter: 1904 loss: 9.15071432e-05
Iter: 1905 loss: 9.15070414e-05
Iter: 1906 loss: 9.15081182e-05
Iter: 1907 loss: 9.15069395e-05
Iter: 1908 loss: 9.1506794e-05
Iter: 1909 loss: 9.15066485e-05
Iter: 1910 loss: 9.15066266e-05
Iter: 1911 loss: 9.15064156e-05
Iter: 1912 loss: 9.1507085e-05
Iter: 1913 loss: 9.15063283e-05
Iter: 1914 loss: 9.15060809e-05
Iter: 1915 loss: 9.15068376e-05
Iter: 1916 loss: 9.15059718e-05
Iter: 1917 loss: 9.15058044e-05
Iter: 1918 loss: 9.15065684e-05
Iter: 1919 loss: 9.15057171e-05
Iter: 1920 loss: 9.15054261e-05
Iter: 1921 loss: 9.15071141e-05
Iter: 1922 loss: 9.15055061e-05
Iter: 1923 loss: 9.15054843e-05
Iter: 1924 loss: 9.15053679e-05
Iter: 1925 loss: 9.1505266e-05
Iter: 1926 loss: 9.15051e-05
Iter: 1927 loss: 9.15058263e-05
Iter: 1928 loss: 9.1505e-05
Iter: 1929 loss: 9.15048658e-05
Iter: 1930 loss: 9.15054188e-05
Iter: 1931 loss: 9.15047131e-05
Iter: 1932 loss: 9.15045093e-05
Iter: 1933 loss: 9.15051351e-05
Iter: 1934 loss: 9.15045093e-05
Iter: 1935 loss: 9.1504291e-05
Iter: 1936 loss: 9.15050696e-05
Iter: 1937 loss: 9.15040946e-05
Iter: 1938 loss: 9.15040728e-05
Iter: 1939 loss: 9.15057317e-05
Iter: 1940 loss: 9.15039855e-05
Iter: 1941 loss: 9.15038763e-05
Iter: 1942 loss: 9.15037817e-05
Iter: 1943 loss: 9.1503869e-05
Iter: 1944 loss: 9.15035198e-05
Iter: 1945 loss: 9.15042692e-05
Iter: 1946 loss: 9.15035052e-05
Iter: 1947 loss: 9.15033306e-05
Iter: 1948 loss: 9.15037526e-05
Iter: 1949 loss: 9.15031706e-05
Iter: 1950 loss: 9.15031e-05
Iter: 1951 loss: 9.15045093e-05
Iter: 1952 loss: 9.15029377e-05
Iter: 1953 loss: 9.15028286e-05
Iter: 1954 loss: 9.15040873e-05
Iter: 1955 loss: 9.1502865e-05
Iter: 1956 loss: 9.15026831e-05
Iter: 1957 loss: 9.15025448e-05
Iter: 1958 loss: 9.15026467e-05
Iter: 1959 loss: 9.15023e-05
Iter: 1960 loss: 9.15029304e-05
Iter: 1961 loss: 9.1502443e-05
Iter: 1962 loss: 9.15022247e-05
Iter: 1963 loss: 9.15028359e-05
Iter: 1964 loss: 9.15022538e-05
Iter: 1965 loss: 9.15020282e-05
Iter: 1966 loss: 9.15023629e-05
Iter: 1967 loss: 9.15018172e-05
Iter: 1968 loss: 9.15017663e-05
Iter: 1969 loss: 9.15021956e-05
Iter: 1970 loss: 9.15016135e-05
Iter: 1971 loss: 9.1501468e-05
Iter: 1972 loss: 9.15041164e-05
Iter: 1973 loss: 9.15015844e-05
Iter: 1974 loss: 9.15014607e-05
Iter: 1975 loss: 9.1501337e-05
Iter: 1976 loss: 9.1501337e-05
Iter: 1977 loss: 9.15011115e-05
Iter: 1978 loss: 9.15015771e-05
Iter: 1979 loss: 9.15010605e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2
+ date
Tue Oct 27 15:42:40 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a546d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a546510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a55f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a584b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a4d5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a4f3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a458840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a47e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a47ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a432730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a3f56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a3986a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a398ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a3bd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a398840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a377e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a32b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a32b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a2d8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a2cc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a2cc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a27be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a22b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a1e0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a1d5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a1fa1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a1c77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a173400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a1732f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a11fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a0d2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a0db840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a0dbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a0a06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a0c9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f772a07b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0474546775
Iter: 2 loss: 693.098511
Iter: 3 loss: 1147.08362
Iter: 4 loss: 0.0474542864
Iter: 5 loss: 1906.30579
Iter: 6 loss: 0.0391369686
Iter: 7 loss: 0.0422268808
Iter: 8 loss: 0.0365340188
Iter: 9 loss: 0.035835579
Iter: 10 loss: 0.0424466804
Iter: 11 loss: 0.0348896533
Iter: 12 loss: 0.0341570526
Iter: 13 loss: 0.0285842977
Iter: 14 loss: 1549.49133
Iter: 15 loss: 0.0285839345
Iter: 16 loss: 0.0240038298
Iter: 17 loss: 0.187960267
Iter: 18 loss: 0.023973573
Iter: 19 loss: 0.0211242046
Iter: 20 loss: 0.0232387409
Iter: 21 loss: 0.0200724956
Iter: 22 loss: 0.0188885275
Iter: 23 loss: 0.0307634808
Iter: 24 loss: 0.0187353231
Iter: 25 loss: 0.0173027646
Iter: 26 loss: 0.0490005799
Iter: 27 loss: 0.0172372572
Iter: 28 loss: 0.0158066563
Iter: 29 loss: 0.0283287577
Iter: 30 loss: 0.0156184128
Iter: 31 loss: 0.0144694429
Iter: 32 loss: 0.0234304741
Iter: 33 loss: 0.0143973641
Iter: 34 loss: 0.0136169773
Iter: 35 loss: 0.0148265194
Iter: 36 loss: 0.0131632881
Iter: 37 loss: 0.0120715126
Iter: 38 loss: 0.0239381976
Iter: 39 loss: 0.011921932
Iter: 40 loss: 0.0107253101
Iter: 41 loss: 0.0187730491
Iter: 42 loss: 0.0105407536
Iter: 43 loss: 0.00959940534
Iter: 44 loss: 0.0256425217
Iter: 45 loss: 0.00959859602
Iter: 46 loss: 0.00891863368
Iter: 47 loss: 0.0113157257
Iter: 48 loss: 0.00869493
Iter: 49 loss: 0.00816804264
Iter: 50 loss: 0.012130213
Iter: 51 loss: 0.00813403726
Iter: 52 loss: 0.00781665742
Iter: 53 loss: 0.00781431422
Iter: 54 loss: 0.00758762239
Iter: 55 loss: 0.00830047764
Iter: 56 loss: 0.00753222872
Iter: 57 loss: 0.00730539579
Iter: 58 loss: 0.00786830299
Iter: 59 loss: 0.00722329179
Iter: 60 loss: 0.00691609271
Iter: 61 loss: 0.00838640332
Iter: 62 loss: 0.00684161764
Iter: 63 loss: 0.00654476229
Iter: 64 loss: 0.00968168862
Iter: 65 loss: 0.00653624814
Iter: 66 loss: 0.00623190403
Iter: 67 loss: 0.00650947168
Iter: 68 loss: 0.0060340981
Iter: 69 loss: 0.00575777795
Iter: 70 loss: 0.00707693025
Iter: 71 loss: 0.00572373811
Iter: 72 loss: 0.00553063536
Iter: 73 loss: 0.00567536522
Iter: 74 loss: 0.00540846586
Iter: 75 loss: 0.00515994662
Iter: 76 loss: 0.00589369796
Iter: 77 loss: 0.00508371
Iter: 78 loss: 0.00489215
Iter: 79 loss: 0.00529548619
Iter: 80 loss: 0.00481451303
Iter: 81 loss: 0.00457751937
Iter: 82 loss: 0.00463182107
Iter: 83 loss: 0.0043935026
Iter: 84 loss: 0.00428555533
Iter: 85 loss: 0.0042493213
Iter: 86 loss: 0.00409413
Iter: 87 loss: 0.00429250719
Iter: 88 loss: 0.00400546659
Iter: 89 loss: 0.00388888223
Iter: 90 loss: 0.00416701753
Iter: 91 loss: 0.00384349772
Iter: 92 loss: 0.00371282478
Iter: 93 loss: 0.00371253514
Iter: 94 loss: 0.00357408775
Iter: 95 loss: 0.00403160369
Iter: 96 loss: 0.00354142
Iter: 97 loss: 0.0034160018
Iter: 98 loss: 0.0035760554
Iter: 99 loss: 0.00334418798
Iter: 100 loss: 0.00323699228
Iter: 101 loss: 0.00348487403
Iter: 102 loss: 0.00319957035
Iter: 103 loss: 0.00309615908
Iter: 104 loss: 0.00338221109
Iter: 105 loss: 0.00305914832
Iter: 106 loss: 0.00296117412
Iter: 107 loss: 0.00355123263
Iter: 108 loss: 0.00294975517
Iter: 109 loss: 0.00286059082
Iter: 110 loss: 0.00306199444
Iter: 111 loss: 0.00282622827
Iter: 112 loss: 0.00273332652
Iter: 113 loss: 0.0030517038
Iter: 114 loss: 0.002707551
Iter: 115 loss: 0.00263595954
Iter: 116 loss: 0.00307581527
Iter: 117 loss: 0.00262500648
Iter: 118 loss: 0.00255749328
Iter: 119 loss: 0.00318658166
Iter: 120 loss: 0.00255655
Iter: 121 loss: 0.00252014492
Iter: 122 loss: 0.00246970379
Iter: 123 loss: 0.00246734149
Iter: 124 loss: 0.00241207145
Iter: 125 loss: 0.00241315644
Iter: 126 loss: 0.0023680022
Iter: 127 loss: 0.00229989318
Iter: 128 loss: 0.00283611193
Iter: 129 loss: 0.00229431363
Iter: 130 loss: 0.00223714556
Iter: 131 loss: 0.00246689073
Iter: 132 loss: 0.0022246039
Iter: 133 loss: 0.00216674758
Iter: 134 loss: 0.00261777081
Iter: 135 loss: 0.00216124952
Iter: 136 loss: 0.00211441168
Iter: 137 loss: 0.0021061122
Iter: 138 loss: 0.0020753087
Iter: 139 loss: 0.00202803197
Iter: 140 loss: 0.00207559718
Iter: 141 loss: 0.00200018939
Iter: 142 loss: 0.00195980165
Iter: 143 loss: 0.00203153258
Iter: 144 loss: 0.00194221467
Iter: 145 loss: 0.00189644517
Iter: 146 loss: 0.00197181
Iter: 147 loss: 0.00187507167
Iter: 148 loss: 0.00183098693
Iter: 149 loss: 0.00193644653
Iter: 150 loss: 0.00181522046
Iter: 151 loss: 0.00181267702
Iter: 152 loss: 0.00179281237
Iter: 153 loss: 0.00177451642
Iter: 154 loss: 0.00177810364
Iter: 155 loss: 0.00176089595
Iter: 156 loss: 0.00173642102
Iter: 157 loss: 0.00171879027
Iter: 158 loss: 0.00171041931
Iter: 159 loss: 0.0016696821
Iter: 160 loss: 0.00170791592
Iter: 161 loss: 0.0016459435
Iter: 162 loss: 0.00161370635
Iter: 163 loss: 0.00161343
Iter: 164 loss: 0.00158102065
Iter: 165 loss: 0.00164976763
Iter: 166 loss: 0.0015671514
Iter: 167 loss: 0.00154891959
Iter: 168 loss: 0.00157289614
Iter: 169 loss: 0.0015400683
Iter: 170 loss: 0.00152564712
Iter: 171 loss: 0.00151498779
Iter: 172 loss: 0.00150993245
Iter: 173 loss: 0.00149379089
Iter: 174 loss: 0.00149298459
Iter: 175 loss: 0.00148056156
Iter: 176 loss: 0.0014603996
Iter: 177 loss: 0.00158079388
Iter: 178 loss: 0.00145758688
Iter: 179 loss: 0.00143733714
Iter: 180 loss: 0.00146060844
Iter: 181 loss: 0.00142638269
Iter: 182 loss: 0.0013975224
Iter: 183 loss: 0.00151993241
Iter: 184 loss: 0.00139094261
Iter: 185 loss: 0.00136737316
Iter: 186 loss: 0.00154662272
Iter: 187 loss: 0.00136601471
Iter: 188 loss: 0.00134943193
Iter: 189 loss: 0.00133804325
Iter: 190 loss: 0.00133175193
Iter: 191 loss: 0.00131237693
Iter: 192 loss: 0.00132622663
Iter: 193 loss: 0.00130047265
Iter: 194 loss: 0.00127391214
Iter: 195 loss: 0.00134813844
Iter: 196 loss: 0.00126544666
Iter: 197 loss: 0.00124060991
Iter: 198 loss: 0.00139882532
Iter: 199 loss: 0.00123838568
Iter: 200 loss: 0.00122048252
Iter: 201 loss: 0.00135201914
Iter: 202 loss: 0.00121874129
Iter: 203 loss: 0.00120568299
Iter: 204 loss: 0.0012177336
Iter: 205 loss: 0.00119856698
Iter: 206 loss: 0.00118425617
Iter: 207 loss: 0.00120118121
Iter: 208 loss: 0.0011764915
Iter: 209 loss: 0.00115952804
Iter: 210 loss: 0.00114587229
Iter: 211 loss: 0.00114090741
Iter: 212 loss: 0.00111780781
Iter: 213 loss: 0.00124804804
Iter: 214 loss: 0.00111452362
Iter: 215 loss: 0.0010923713
Iter: 216 loss: 0.00110657234
Iter: 217 loss: 0.00107841252
Iter: 218 loss: 0.00106396503
Iter: 219 loss: 0.00106292008
Iter: 220 loss: 0.00105081429
Iter: 221 loss: 0.00106109551
Iter: 222 loss: 0.00104367442
Iter: 223 loss: 0.0010295962
Iter: 224 loss: 0.00103627983
Iter: 225 loss: 0.00101998565
Iter: 226 loss: 0.00100434711
Iter: 227 loss: 0.00104027078
Iter: 228 loss: 0.000998581061
Iter: 229 loss: 0.0009837416
Iter: 230 loss: 0.00117237808
Iter: 231 loss: 0.000983513426
Iter: 232 loss: 0.00097347406
Iter: 233 loss: 0.00105541945
Iter: 234 loss: 0.000972959097
Iter: 235 loss: 0.000965829066
Iter: 236 loss: 0.0009828076
Iter: 237 loss: 0.000963127124
Iter: 238 loss: 0.000956839707
Iter: 239 loss: 0.000960490433
Iter: 240 loss: 0.000952826696
Iter: 241 loss: 0.000944461848
Iter: 242 loss: 0.000939005404
Iter: 243 loss: 0.000935751712
Iter: 244 loss: 0.000921810861
Iter: 245 loss: 0.000957893266
Iter: 246 loss: 0.000917017809
Iter: 247 loss: 0.000901919906
Iter: 248 loss: 0.000928949332
Iter: 249 loss: 0.000895158
Iter: 250 loss: 0.00088565913
Iter: 251 loss: 0.00100701349
Iter: 252 loss: 0.000885624497
Iter: 253 loss: 0.00087742554
Iter: 254 loss: 0.000870684336
Iter: 255 loss: 0.000868289033
Iter: 256 loss: 0.000850714801
Iter: 257 loss: 0.000910608796
Iter: 258 loss: 0.000846149167
Iter: 259 loss: 0.000832021469
Iter: 260 loss: 0.00084276835
Iter: 261 loss: 0.000823333103
Iter: 262 loss: 0.000811985694
Iter: 263 loss: 0.000882037915
Iter: 264 loss: 0.00081067346
Iter: 265 loss: 0.000800890848
Iter: 266 loss: 0.000827751064
Iter: 267 loss: 0.00079751981
Iter: 268 loss: 0.000788497389
Iter: 269 loss: 0.000819062348
Iter: 270 loss: 0.000786221586
Iter: 271 loss: 0.000778262387
Iter: 272 loss: 0.000775684719
Iter: 273 loss: 0.000770967628
Iter: 274 loss: 0.000761402072
Iter: 275 loss: 0.000779368682
Iter: 276 loss: 0.000757404
Iter: 277 loss: 0.000748335966
Iter: 278 loss: 0.000770260638
Iter: 279 loss: 0.000745050493
Iter: 280 loss: 0.000735438545
Iter: 281 loss: 0.000775723252
Iter: 282 loss: 0.000733369088
Iter: 283 loss: 0.00072596164
Iter: 284 loss: 0.000742656295
Iter: 285 loss: 0.000723080884
Iter: 286 loss: 0.000714408583
Iter: 287 loss: 0.000741467346
Iter: 288 loss: 0.000711986213
Iter: 289 loss: 0.000705797342
Iter: 290 loss: 0.000705786166
Iter: 291 loss: 0.000700828852
Iter: 292 loss: 0.000692729722
Iter: 293 loss: 0.000708020525
Iter: 294 loss: 0.000689339126
Iter: 295 loss: 0.000682254613
Iter: 296 loss: 0.000711132423
Iter: 297 loss: 0.000680620316
Iter: 298 loss: 0.000674659677
Iter: 299 loss: 0.000726799131
Iter: 300 loss: 0.000674396346
Iter: 301 loss: 0.000669915637
Iter: 302 loss: 0.000707383442
Iter: 303 loss: 0.000669605564
Iter: 304 loss: 0.000665917527
Iter: 305 loss: 0.000661472906
Iter: 306 loss: 0.000661041413
Iter: 307 loss: 0.000653696596
Iter: 308 loss: 0.000658627832
Iter: 309 loss: 0.00064905
Iter: 310 loss: 0.000639884383
Iter: 311 loss: 0.000652912888
Iter: 312 loss: 0.000635423581
Iter: 313 loss: 0.000625104061
Iter: 314 loss: 0.000675993273
Iter: 315 loss: 0.000623364176
Iter: 316 loss: 0.000614632561
Iter: 317 loss: 0.000627411297
Iter: 318 loss: 0.000610441668
Iter: 319 loss: 0.000603289925
Iter: 320 loss: 0.000603019842
Iter: 321 loss: 0.000598014798
Iter: 322 loss: 0.000594884739
Iter: 323 loss: 0.00059291895
Iter: 324 loss: 0.000587023795
Iter: 325 loss: 0.000591466727
Iter: 326 loss: 0.000583341287
Iter: 327 loss: 0.000578037463
Iter: 328 loss: 0.000581946806
Iter: 329 loss: 0.000574808917
Iter: 330 loss: 0.000569519354
Iter: 331 loss: 0.000609109644
Iter: 332 loss: 0.000569066731
Iter: 333 loss: 0.000564729446
Iter: 334 loss: 0.000595230958
Iter: 335 loss: 0.000564383401
Iter: 336 loss: 0.000559624052
Iter: 337 loss: 0.000559113338
Iter: 338 loss: 0.000555618841
Iter: 339 loss: 0.000549570716
Iter: 340 loss: 0.000546562951
Iter: 341 loss: 0.000543684931
Iter: 342 loss: 0.000536979584
Iter: 343 loss: 0.000577202416
Iter: 344 loss: 0.000536087435
Iter: 345 loss: 0.000530717312
Iter: 346 loss: 0.00054027047
Iter: 347 loss: 0.000528344477
Iter: 348 loss: 0.000523227965
Iter: 349 loss: 0.000549668213
Iter: 350 loss: 0.000522399321
Iter: 351 loss: 0.000518136367
Iter: 352 loss: 0.000546939787
Iter: 353 loss: 0.000517742243
Iter: 354 loss: 0.000514357525
Iter: 355 loss: 0.000537412241
Iter: 356 loss: 0.000514007057
Iter: 357 loss: 0.000511522172
Iter: 358 loss: 0.00051497086
Iter: 359 loss: 0.000510303362
Iter: 360 loss: 0.000507009565
Iter: 361 loss: 0.000516895554
Iter: 362 loss: 0.000505989301
Iter: 363 loss: 0.000503173331
Iter: 364 loss: 0.00051651604
Iter: 365 loss: 0.000502675772
Iter: 366 loss: 0.000500250317
Iter: 367 loss: 0.000511972117
Iter: 368 loss: 0.000499793154
Iter: 369 loss: 0.000497117057
Iter: 370 loss: 0.000499305432
Iter: 371 loss: 0.000495526183
Iter: 372 loss: 0.000492462364
Iter: 373 loss: 0.000494030188
Iter: 374 loss: 0.000490420207
Iter: 375 loss: 0.000487164623
Iter: 376 loss: 0.000494038337
Iter: 377 loss: 0.000485883036
Iter: 378 loss: 0.000482096308
Iter: 379 loss: 0.000490659964
Iter: 380 loss: 0.000480654067
Iter: 381 loss: 0.00047672572
Iter: 382 loss: 0.000488543417
Iter: 383 loss: 0.000475523178
Iter: 384 loss: 0.000472118438
Iter: 385 loss: 0.000496581779
Iter: 386 loss: 0.00047178613
Iter: 387 loss: 0.000468927203
Iter: 388 loss: 0.000486414239
Iter: 389 loss: 0.00046859344
Iter: 390 loss: 0.000466050813
Iter: 391 loss: 0.000466013735
Iter: 392 loss: 0.000463988341
Iter: 393 loss: 0.00046051442
Iter: 394 loss: 0.000468184066
Iter: 395 loss: 0.000459208619
Iter: 396 loss: 0.000456151145
Iter: 397 loss: 0.000465410587
Iter: 398 loss: 0.000455222791
Iter: 399 loss: 0.000452372798
Iter: 400 loss: 0.000472226355
Iter: 401 loss: 0.000452133681
Iter: 402 loss: 0.000449270476
Iter: 403 loss: 0.000453936373
Iter: 404 loss: 0.000447937404
Iter: 405 loss: 0.000445418438
Iter: 406 loss: 0.000443298137
Iter: 407 loss: 0.00044258713
Iter: 408 loss: 0.000439052092
Iter: 409 loss: 0.000446869
Iter: 410 loss: 0.000437693234
Iter: 411 loss: 0.000433714944
Iter: 412 loss: 0.000444270321
Iter: 413 loss: 0.000432387256
Iter: 414 loss: 0.000428130588
Iter: 415 loss: 0.000440702075
Iter: 416 loss: 0.000426824467
Iter: 417 loss: 0.000423209567
Iter: 418 loss: 0.000440046715
Iter: 419 loss: 0.000422555633
Iter: 420 loss: 0.000419630029
Iter: 421 loss: 0.000444765756
Iter: 422 loss: 0.000419456046
Iter: 423 loss: 0.000417156582
Iter: 424 loss: 0.000417939737
Iter: 425 loss: 0.0004155442
Iter: 426 loss: 0.000412450609
Iter: 427 loss: 0.000429164618
Iter: 428 loss: 0.000411969726
Iter: 429 loss: 0.000409801054
Iter: 430 loss: 0.0004145852
Iter: 431 loss: 0.000408973312
Iter: 432 loss: 0.000406892214
Iter: 433 loss: 0.000420824857
Iter: 434 loss: 0.000406662
Iter: 435 loss: 0.000404741731
Iter: 436 loss: 0.000409343804
Iter: 437 loss: 0.000404057151
Iter: 438 loss: 0.00040192579
Iter: 439 loss: 0.000399983255
Iter: 440 loss: 0.000399459474
Iter: 441 loss: 0.000396592251
Iter: 442 loss: 0.000402757782
Iter: 443 loss: 0.000395480747
Iter: 444 loss: 0.000391979062
Iter: 445 loss: 0.000397119904
Iter: 446 loss: 0.000390281464
Iter: 447 loss: 0.000386518543
Iter: 448 loss: 0.00040690173
Iter: 449 loss: 0.00038595908
Iter: 450 loss: 0.000383149047
Iter: 451 loss: 0.000394007191
Iter: 452 loss: 0.000382479979
Iter: 453 loss: 0.000380232232
Iter: 454 loss: 0.000404655817
Iter: 455 loss: 0.000380188285
Iter: 456 loss: 0.000378404802
Iter: 457 loss: 0.000377609045
Iter: 458 loss: 0.000376697746
Iter: 459 loss: 0.000374244351
Iter: 460 loss: 0.000386376341
Iter: 461 loss: 0.000373834104
Iter: 462 loss: 0.000371855567
Iter: 463 loss: 0.000377305376
Iter: 464 loss: 0.00037120434
Iter: 465 loss: 0.000369410613
Iter: 466 loss: 0.000380571291
Iter: 467 loss: 0.00036921259
Iter: 468 loss: 0.0003674443
Iter: 469 loss: 0.000371101429
Iter: 470 loss: 0.000366721506
Iter: 471 loss: 0.000364931417
Iter: 472 loss: 0.000363357278
Iter: 473 loss: 0.000362884923
Iter: 474 loss: 0.000360335747
Iter: 475 loss: 0.000362273655
Iter: 476 loss: 0.000358768739
Iter: 477 loss: 0.000355389289
Iter: 478 loss: 0.000368636654
Iter: 479 loss: 0.000354612188
Iter: 480 loss: 0.000351783761
Iter: 481 loss: 0.000363346015
Iter: 482 loss: 0.00035115931
Iter: 483 loss: 0.000348501024
Iter: 484 loss: 0.000354764226
Iter: 485 loss: 0.000347527268
Iter: 486 loss: 0.00034518959
Iter: 487 loss: 0.000371549977
Iter: 488 loss: 0.000345138775
Iter: 489 loss: 0.000343166146
Iter: 490 loss: 0.000345196691
Iter: 491 loss: 0.000342076382
Iter: 492 loss: 0.000340171187
Iter: 493 loss: 0.00034739307
Iter: 494 loss: 0.000339701248
Iter: 495 loss: 0.000337951176
Iter: 496 loss: 0.000341065839
Iter: 497 loss: 0.000337191334
Iter: 498 loss: 0.000335443881
Iter: 499 loss: 0.00034688611
Iter: 500 loss: 0.000335248711
Iter: 501 loss: 0.000333642762
Iter: 502 loss: 0.000341837935
Iter: 503 loss: 0.000333391392
Iter: 504 loss: 0.000332119293
Iter: 505 loss: 0.000330452342
Iter: 506 loss: 0.00033034748
Iter: 507 loss: 0.000328249793
Iter: 508 loss: 0.000329399831
Iter: 509 loss: 0.000326875423
Iter: 510 loss: 0.000324071239
Iter: 511 loss: 0.000334039883
Iter: 512 loss: 0.000323336397
Iter: 513 loss: 0.000320932595
Iter: 514 loss: 0.000331069779
Iter: 515 loss: 0.000320420862
Iter: 516 loss: 0.000318246661
Iter: 517 loss: 0.000326748966
Iter: 518 loss: 0.000317738566
Iter: 519 loss: 0.000316073914
Iter: 520 loss: 0.000331741525
Iter: 521 loss: 0.000316011661
Iter: 522 loss: 0.000314580277
Iter: 523 loss: 0.000316078891
Iter: 524 loss: 0.000313777768
Iter: 525 loss: 0.000312267453
Iter: 526 loss: 0.000317758153
Iter: 527 loss: 0.000311899232
Iter: 528 loss: 0.000310364499
Iter: 529 loss: 0.000313993951
Iter: 530 loss: 0.000309796829
Iter: 531 loss: 0.000308419898
Iter: 532 loss: 0.000314842822
Iter: 533 loss: 0.000308173
Iter: 534 loss: 0.000306889502
Iter: 535 loss: 0.000310931558
Iter: 536 loss: 0.000306511531
Iter: 537 loss: 0.000305304
Iter: 538 loss: 0.000304962596
Iter: 539 loss: 0.00030422851
Iter: 540 loss: 0.000302765
Iter: 541 loss: 0.000302985893
Iter: 542 loss: 0.000301657361
Iter: 543 loss: 0.000299656298
Iter: 544 loss: 0.000309800729
Iter: 545 loss: 0.000299335574
Iter: 546 loss: 0.000297616178
Iter: 547 loss: 0.000302073138
Iter: 548 loss: 0.000297026767
Iter: 549 loss: 0.000295357779
Iter: 550 loss: 0.000300759741
Iter: 551 loss: 0.000294889091
Iter: 552 loss: 0.000293456949
Iter: 553 loss: 0.000306883128
Iter: 554 loss: 0.000293391553
Iter: 555 loss: 0.000292115612
Iter: 556 loss: 0.000294298457
Iter: 557 loss: 0.000291550503
Iter: 558 loss: 0.000290410942
Iter: 559 loss: 0.000292715558
Iter: 560 loss: 0.000289938966
Iter: 561 loss: 0.000288807583
Iter: 562 loss: 0.000291646575
Iter: 563 loss: 0.000288414973
Iter: 564 loss: 0.000287419069
Iter: 565 loss: 0.000291899662
Iter: 566 loss: 0.000287220173
Iter: 567 loss: 0.000286247523
Iter: 568 loss: 0.00029194128
Iter: 569 loss: 0.000286124938
Iter: 570 loss: 0.000285292481
Iter: 571 loss: 0.00028475828
Iter: 572 loss: 0.000284432899
Iter: 573 loss: 0.000283323461
Iter: 574 loss: 0.000282737106
Iter: 575 loss: 0.000282230845
Iter: 576 loss: 0.000280498876
Iter: 577 loss: 0.000288232259
Iter: 578 loss: 0.000280149456
Iter: 579 loss: 0.000278546766
Iter: 580 loss: 0.000281977
Iter: 581 loss: 0.000277921354
Iter: 582 loss: 0.000276253733
Iter: 583 loss: 0.000285508
Iter: 584 loss: 0.000276013539
Iter: 585 loss: 0.000274774618
Iter: 586 loss: 0.000282485
Iter: 587 loss: 0.000274636026
Iter: 588 loss: 0.000273472077
Iter: 589 loss: 0.000276514096
Iter: 590 loss: 0.000273071026
Iter: 591 loss: 0.000272130244
Iter: 592 loss: 0.000273885438
Iter: 593 loss: 0.000271733879
Iter: 594 loss: 0.000270600169
Iter: 595 loss: 0.000277251645
Iter: 596 loss: 0.000270448509
Iter: 597 loss: 0.000269631768
Iter: 598 loss: 0.000271886238
Iter: 599 loss: 0.000269371172
Iter: 600 loss: 0.000268494798
Iter: 601 loss: 0.000271413242
Iter: 602 loss: 0.000268248754
Iter: 603 loss: 0.0002674071
Iter: 604 loss: 0.000266960706
Iter: 605 loss: 0.000266579154
Iter: 606 loss: 0.000265299692
Iter: 607 loss: 0.00026513933
Iter: 608 loss: 0.000264226634
Iter: 609 loss: 0.000262574846
Iter: 610 loss: 0.000271724595
Iter: 611 loss: 0.00026234152
Iter: 612 loss: 0.000260818313
Iter: 613 loss: 0.000263905938
Iter: 614 loss: 0.00026019878
Iter: 615 loss: 0.000258696324
Iter: 616 loss: 0.000264425325
Iter: 617 loss: 0.000258339045
Iter: 618 loss: 0.000257027161
Iter: 619 loss: 0.000267756579
Iter: 620 loss: 0.000256937463
Iter: 621 loss: 0.000255784
Iter: 622 loss: 0.000259923778
Iter: 623 loss: 0.000255495863
Iter: 624 loss: 0.000254554092
Iter: 625 loss: 0.000255275285
Iter: 626 loss: 0.000253975129
Iter: 627 loss: 0.000252991944
Iter: 628 loss: 0.000257138745
Iter: 629 loss: 0.000252787257
Iter: 630 loss: 0.000251998397
Iter: 631 loss: 0.000253939768
Iter: 632 loss: 0.000251715741
Iter: 633 loss: 0.000250783487
Iter: 634 loss: 0.00025472205
Iter: 635 loss: 0.000250591664
Iter: 636 loss: 0.000249586708
Iter: 637 loss: 0.000250058132
Iter: 638 loss: 0.000248905
Iter: 639 loss: 0.000247971329
Iter: 640 loss: 0.000247164338
Iter: 641 loss: 0.00024691227
Iter: 642 loss: 0.000245302886
Iter: 643 loss: 0.000250449
Iter: 644 loss: 0.000244836527
Iter: 645 loss: 0.000243135
Iter: 646 loss: 0.0002478674
Iter: 647 loss: 0.000242585607
Iter: 648 loss: 0.000241079309
Iter: 649 loss: 0.000250222249
Iter: 650 loss: 0.000240891924
Iter: 651 loss: 0.000239622852
Iter: 652 loss: 0.000243007846
Iter: 653 loss: 0.000239207293
Iter: 654 loss: 0.000237761182
Iter: 655 loss: 0.00024673692
Iter: 656 loss: 0.000237583008
Iter: 657 loss: 0.000236687512
Iter: 658 loss: 0.000237946166
Iter: 659 loss: 0.000236249733
Iter: 660 loss: 0.000235297368
Iter: 661 loss: 0.000243107119
Iter: 662 loss: 0.000235235188
Iter: 663 loss: 0.000234555904
Iter: 664 loss: 0.000235096464
Iter: 665 loss: 0.000234148756
Iter: 666 loss: 0.000233241444
Iter: 667 loss: 0.000236899126
Iter: 668 loss: 0.000233032988
Iter: 669 loss: 0.000232236285
Iter: 670 loss: 0.000232873979
Iter: 671 loss: 0.000231757964
Iter: 672 loss: 0.000230816979
Iter: 673 loss: 0.000230091726
Iter: 674 loss: 0.000229792393
Iter: 675 loss: 0.000228278222
Iter: 676 loss: 0.000234901032
Iter: 677 loss: 0.000227974073
Iter: 678 loss: 0.000226476972
Iter: 679 loss: 0.000231923274
Iter: 680 loss: 0.000226096774
Iter: 681 loss: 0.000224809599
Iter: 682 loss: 0.000227155586
Iter: 683 loss: 0.000224253541
Iter: 684 loss: 0.000222793111
Iter: 685 loss: 0.000233144383
Iter: 686 loss: 0.000222652496
Iter: 687 loss: 0.000221575232
Iter: 688 loss: 0.000229919242
Iter: 689 loss: 0.000221500391
Iter: 690 loss: 0.000220823975
Iter: 691 loss: 0.00022081178
Iter: 692 loss: 0.000220275979
Iter: 693 loss: 0.000219447669
Iter: 694 loss: 0.000224133022
Iter: 695 loss: 0.000219334121
Iter: 696 loss: 0.000218683082
Iter: 697 loss: 0.000220022062
Iter: 698 loss: 0.0002184193
Iter: 699 loss: 0.000217659428
Iter: 700 loss: 0.000221045775
Iter: 701 loss: 0.000217513254
Iter: 702 loss: 0.000216734217
Iter: 703 loss: 0.000217112669
Iter: 704 loss: 0.000216209868
Iter: 705 loss: 0.000215399225
Iter: 706 loss: 0.00021424811
Iter: 707 loss: 0.000214206812
Iter: 708 loss: 0.000212664891
Iter: 709 loss: 0.00021916462
Iter: 710 loss: 0.000212334475
Iter: 711 loss: 0.000210782673
Iter: 712 loss: 0.000215137319
Iter: 713 loss: 0.000210287282
Iter: 714 loss: 0.000208850921
Iter: 715 loss: 0.000217089953
Iter: 716 loss: 0.000208654674
Iter: 717 loss: 0.000207566045
Iter: 718 loss: 0.000212374289
Iter: 719 loss: 0.000207354111
Iter: 720 loss: 0.000206351193
Iter: 721 loss: 0.000213533494
Iter: 722 loss: 0.000206259108
Iter: 723 loss: 0.000205525721
Iter: 724 loss: 0.000205723074
Iter: 725 loss: 0.000204996715
Iter: 726 loss: 0.000204178883
Iter: 727 loss: 0.000213594336
Iter: 728 loss: 0.000204164447
Iter: 729 loss: 0.000203591713
Iter: 730 loss: 0.000204205251
Iter: 731 loss: 0.000203278614
Iter: 732 loss: 0.000202556897
Iter: 733 loss: 0.000205458462
Iter: 734 loss: 0.000202391
Iter: 735 loss: 0.000201727438
Iter: 736 loss: 0.000202092371
Iter: 737 loss: 0.000201293296
Iter: 738 loss: 0.000200418581
Iter: 739 loss: 0.000200093375
Iter: 740 loss: 0.000199612085
Iter: 741 loss: 0.00019848271
Iter: 742 loss: 0.000202096824
Iter: 743 loss: 0.000198161317
Iter: 744 loss: 0.000196931956
Iter: 745 loss: 0.000202318857
Iter: 746 loss: 0.000196679975
Iter: 747 loss: 0.000195758083
Iter: 748 loss: 0.00019813978
Iter: 749 loss: 0.000195441011
Iter: 750 loss: 0.000194440479
Iter: 751 loss: 0.000199765753
Iter: 752 loss: 0.000194281369
Iter: 753 loss: 0.000193479529
Iter: 754 loss: 0.000201351068
Iter: 755 loss: 0.000193453539
Iter: 756 loss: 0.000192903186
Iter: 757 loss: 0.000192700507
Iter: 758 loss: 0.000192393374
Iter: 759 loss: 0.000191752886
Iter: 760 loss: 0.000196475768
Iter: 761 loss: 0.000191701343
Iter: 762 loss: 0.000191195169
Iter: 763 loss: 0.000192076186
Iter: 764 loss: 0.000190969236
Iter: 765 loss: 0.000190373525
Iter: 766 loss: 0.000192561245
Iter: 767 loss: 0.000190229242
Iter: 768 loss: 0.00018959961
Iter: 769 loss: 0.000190279301
Iter: 770 loss: 0.000189252372
Iter: 771 loss: 0.000188684819
Iter: 772 loss: 0.000188079401
Iter: 773 loss: 0.000187979225
Iter: 774 loss: 0.00018704847
Iter: 775 loss: 0.000189632323
Iter: 776 loss: 0.000186746591
Iter: 777 loss: 0.000185744168
Iter: 778 loss: 0.000189868209
Iter: 779 loss: 0.000185527519
Iter: 780 loss: 0.000184637684
Iter: 781 loss: 0.000187879108
Iter: 782 loss: 0.000184415025
Iter: 783 loss: 0.000183577387
Iter: 784 loss: 0.000186700607
Iter: 785 loss: 0.000183376338
Iter: 786 loss: 0.00018263841
Iter: 787 loss: 0.00018944715
Iter: 788 loss: 0.000182603922
Iter: 789 loss: 0.00018206719
Iter: 790 loss: 0.000181965705
Iter: 791 loss: 0.000181608091
Iter: 792 loss: 0.000180970863
Iter: 793 loss: 0.000188039732
Iter: 794 loss: 0.000180957199
Iter: 795 loss: 0.000180482733
Iter: 796 loss: 0.000181032767
Iter: 797 loss: 0.000180230127
Iter: 798 loss: 0.000179653682
Iter: 799 loss: 0.000182119053
Iter: 800 loss: 0.000179530223
Iter: 801 loss: 0.00017906088
Iter: 802 loss: 0.000179493611
Iter: 803 loss: 0.000178790549
Iter: 804 loss: 0.000178193557
Iter: 805 loss: 0.000178005852
Iter: 806 loss: 0.000177655194
Iter: 807 loss: 0.000176882168
Iter: 808 loss: 0.000178078481
Iter: 809 loss: 0.000176516711
Iter: 810 loss: 0.000175582449
Iter: 811 loss: 0.000181982425
Iter: 812 loss: 0.000175489709
Iter: 813 loss: 0.000174778805
Iter: 814 loss: 0.000175535984
Iter: 815 loss: 0.00017438698
Iter: 816 loss: 0.000173538196
Iter: 817 loss: 0.000180082017
Iter: 818 loss: 0.000173472858
Iter: 819 loss: 0.00017292166
Iter: 820 loss: 0.000178884758
Iter: 821 loss: 0.000172910572
Iter: 822 loss: 0.000172505737
Iter: 823 loss: 0.000172257976
Iter: 824 loss: 0.000172092579
Iter: 825 loss: 0.000171582346
Iter: 826 loss: 0.000174412489
Iter: 827 loss: 0.000171509892
Iter: 828 loss: 0.000171067193
Iter: 829 loss: 0.000173079461
Iter: 830 loss: 0.000170980493
Iter: 831 loss: 0.000170626561
Iter: 832 loss: 0.000171874912
Iter: 833 loss: 0.000170536936
Iter: 834 loss: 0.000170159619
Iter: 835 loss: 0.000170370709
Iter: 836 loss: 0.000169911567
Iter: 837 loss: 0.000169472594
Iter: 838 loss: 0.000169082865
Iter: 839 loss: 0.000168969404
Iter: 840 loss: 0.000168314233
Iter: 841 loss: 0.000169599036
Iter: 842 loss: 0.000168043247
Iter: 843 loss: 0.000167326769
Iter: 844 loss: 0.000171117761
Iter: 845 loss: 0.000167217193
Iter: 846 loss: 0.000166581071
Iter: 847 loss: 0.000168220315
Iter: 848 loss: 0.000166361249
Iter: 849 loss: 0.000165781792
Iter: 850 loss: 0.000168989864
Iter: 851 loss: 0.000165700068
Iter: 852 loss: 0.000165270947
Iter: 853 loss: 0.00016967213
Iter: 854 loss: 0.00016525705
Iter: 855 loss: 0.000164910278
Iter: 856 loss: 0.000164808676
Iter: 857 loss: 0.000164600497
Iter: 858 loss: 0.000164220837
Iter: 859 loss: 0.000168529063
Iter: 860 loss: 0.000164213969
Iter: 861 loss: 0.000163925622
Iter: 862 loss: 0.000164534373
Iter: 863 loss: 0.000163812278
Iter: 864 loss: 0.000163499353
Iter: 865 loss: 0.000164498808
Iter: 866 loss: 0.000163408171
Iter: 867 loss: 0.000163103075
Iter: 868 loss: 0.000163276287
Iter: 869 loss: 0.000162904355
Iter: 870 loss: 0.00016247842
Iter: 871 loss: 0.000162487413
Iter: 872 loss: 0.000162140685
Iter: 873 loss: 0.000161647666
Iter: 874 loss: 0.000162245662
Iter: 875 loss: 0.000161389122
Iter: 876 loss: 0.000160833792
Iter: 877 loss: 0.000165132689
Iter: 878 loss: 0.000160792551
Iter: 879 loss: 0.000160353055
Iter: 880 loss: 0.000160827767
Iter: 881 loss: 0.000160111842
Iter: 882 loss: 0.000159622025
Iter: 883 loss: 0.000163459816
Iter: 884 loss: 0.000159585921
Iter: 885 loss: 0.000159268093
Iter: 886 loss: 0.000162797922
Iter: 887 loss: 0.000159262228
Iter: 888 loss: 0.000159009127
Iter: 889 loss: 0.000158831099
Iter: 890 loss: 0.000158740964
Iter: 891 loss: 0.000158401119
Iter: 892 loss: 0.00015984854
Iter: 893 loss: 0.000158330717
Iter: 894 loss: 0.000157990944
Iter: 895 loss: 0.00015981702
Iter: 896 loss: 0.000157938397
Iter: 897 loss: 0.000157674978
Iter: 898 loss: 0.000158429873
Iter: 899 loss: 0.00015759276
Iter: 900 loss: 0.000157313072
Iter: 901 loss: 0.000157402508
Iter: 902 loss: 0.000157113667
Iter: 903 loss: 0.000156756461
Iter: 904 loss: 0.000156719107
Iter: 905 loss: 0.000156458787
Iter: 906 loss: 0.000156032271
Iter: 907 loss: 0.000156358466
Iter: 908 loss: 0.000155772461
Iter: 909 loss: 0.000155300877
Iter: 910 loss: 0.000159172356
Iter: 911 loss: 0.000155272457
Iter: 912 loss: 0.000154864509
Iter: 913 loss: 0.000155341739
Iter: 914 loss: 0.000154647059
Iter: 915 loss: 0.000154214766
Iter: 916 loss: 0.000156928058
Iter: 917 loss: 0.000154165988
Iter: 918 loss: 0.000153855421
Iter: 919 loss: 0.000157072223
Iter: 920 loss: 0.000153846049
Iter: 921 loss: 0.000153576286
Iter: 922 loss: 0.000153489702
Iter: 923 loss: 0.000153332803
Iter: 924 loss: 0.000153004439
Iter: 925 loss: 0.000154848633
Iter: 926 loss: 0.000152957393
Iter: 927 loss: 0.000152672204
Iter: 928 loss: 0.00015394084
Iter: 929 loss: 0.000152616762
Iter: 930 loss: 0.000152380497
Iter: 931 loss: 0.000153275483
Iter: 932 loss: 0.00015232322
Iter: 933 loss: 0.00015210548
Iter: 934 loss: 0.000152324414
Iter: 935 loss: 0.000151983841
Iter: 936 loss: 0.000151730608
Iter: 937 loss: 0.000151701111
Iter: 938 loss: 0.000151518499
Iter: 939 loss: 0.000151190223
Iter: 940 loss: 0.000151370448
Iter: 941 loss: 0.00015097452
Iter: 942 loss: 0.000150617911
Iter: 943 loss: 0.000153632907
Iter: 944 loss: 0.000150596767
Iter: 945 loss: 0.00015027565
Iter: 946 loss: 0.000150417589
Iter: 947 loss: 0.000150057342
Iter: 948 loss: 0.000149655913
Iter: 949 loss: 0.00015236625
Iter: 950 loss: 0.000149615371
Iter: 951 loss: 0.000149347325
Iter: 952 loss: 0.0001523643
Iter: 953 loss: 0.000149343512
Iter: 954 loss: 0.000149124215
Iter: 955 loss: 0.000149118234
Iter: 956 loss: 0.000148946987
Iter: 957 loss: 0.000148707113
Iter: 958 loss: 0.0001495131
Iter: 959 loss: 0.000148642313
Iter: 960 loss: 0.000148396415
Iter: 961 loss: 0.000150019507
Iter: 962 loss: 0.000148370382
Iter: 963 loss: 0.000148195904
Iter: 964 loss: 0.000148760882
Iter: 965 loss: 0.00014814717
Iter: 966 loss: 0.000147971834
Iter: 967 loss: 0.000148028616
Iter: 968 loss: 0.000147847313
Iter: 969 loss: 0.000147614846
Iter: 970 loss: 0.000147574261
Iter: 971 loss: 0.00014741646
Iter: 972 loss: 0.000147102561
Iter: 973 loss: 0.000147246785
Iter: 974 loss: 0.000146890729
Iter: 975 loss: 0.000146521634
Iter: 976 loss: 0.000148947496
Iter: 977 loss: 0.000146482693
Iter: 978 loss: 0.000146123144
Iter: 979 loss: 0.000146554201
Iter: 980 loss: 0.000145932863
Iter: 981 loss: 0.000145562604
Iter: 982 loss: 0.000148058767
Iter: 983 loss: 0.000145525482
Iter: 984 loss: 0.00014527145
Iter: 985 loss: 0.000148122635
Iter: 986 loss: 0.000145265978
Iter: 987 loss: 0.000145051017
Iter: 988 loss: 0.000145051992
Iter: 989 loss: 0.00014487977
Iter: 990 loss: 0.000144633173
Iter: 991 loss: 0.000145504397
Iter: 992 loss: 0.000144568752
Iter: 993 loss: 0.00014433515
Iter: 994 loss: 0.000145755825
Iter: 995 loss: 0.000144306978
Iter: 996 loss: 0.000144127494
Iter: 997 loss: 0.000144609818
Iter: 998 loss: 0.000144067497
Iter: 999 loss: 0.000143869634
Iter: 1000 loss: 0.000143982979
Iter: 1001 loss: 0.000143741199
Iter: 1002 loss: 0.000143486526
Iter: 1003 loss: 0.000143600919
Iter: 1004 loss: 0.000143313635
Iter: 1005 loss: 0.000143010635
Iter: 1006 loss: 0.000142943536
Iter: 1007 loss: 0.000142746037
Iter: 1008 loss: 0.000142363453
Iter: 1009 loss: 0.000145369049
Iter: 1010 loss: 0.000142336226
Iter: 1011 loss: 0.000141990109
Iter: 1012 loss: 0.000142587
Iter: 1013 loss: 0.000141837081
Iter: 1014 loss: 0.000141496
Iter: 1015 loss: 0.000143358149
Iter: 1016 loss: 0.000141445707
Iter: 1017 loss: 0.000141201337
Iter: 1018 loss: 0.000143815152
Iter: 1019 loss: 0.000141196128
Iter: 1020 loss: 0.000140985692
Iter: 1021 loss: 0.000141142955
Iter: 1022 loss: 0.000140856224
Iter: 1023 loss: 0.000140652483
Iter: 1024 loss: 0.000141021024
Iter: 1025 loss: 0.000140565026
Iter: 1026 loss: 0.000140332209
Iter: 1027 loss: 0.000142116391
Iter: 1028 loss: 0.000140314703
Iter: 1029 loss: 0.000140148
Iter: 1030 loss: 0.000140592805
Iter: 1031 loss: 0.000140092656
Iter: 1032 loss: 0.000139911426
Iter: 1033 loss: 0.00014002157
Iter: 1034 loss: 0.000139794778
Iter: 1035 loss: 0.000139574899
Iter: 1036 loss: 0.000139571988
Iter: 1037 loss: 0.000139398617
Iter: 1038 loss: 0.000139100899
Iter: 1039 loss: 0.000139110751
Iter: 1040 loss: 0.000138865493
Iter: 1041 loss: 0.000138528543
Iter: 1042 loss: 0.000141011958
Iter: 1043 loss: 0.000138501317
Iter: 1044 loss: 0.000138190138
Iter: 1045 loss: 0.000138746924
Iter: 1046 loss: 0.000138054049
Iter: 1047 loss: 0.000137746858
Iter: 1048 loss: 0.000139327109
Iter: 1049 loss: 0.000137697396
Iter: 1050 loss: 0.000137481256
Iter: 1051 loss: 0.000140108
Iter: 1052 loss: 0.000137478724
Iter: 1053 loss: 0.000137299983
Iter: 1054 loss: 0.000137400231
Iter: 1055 loss: 0.000137183408
Iter: 1056 loss: 0.00013698866
Iter: 1057 loss: 0.000137287891
Iter: 1058 loss: 0.000136896517
Iter: 1059 loss: 0.000136686343
Iter: 1060 loss: 0.000138552045
Iter: 1061 loss: 0.000136676143
Iter: 1062 loss: 0.000136529823
Iter: 1063 loss: 0.000136880757
Iter: 1064 loss: 0.000136476272
Iter: 1065 loss: 0.000136311748
Iter: 1066 loss: 0.000136403716
Iter: 1067 loss: 0.000136204122
Iter: 1068 loss: 0.000135989598
Iter: 1069 loss: 0.000136097384
Iter: 1070 loss: 0.000135845912
Iter: 1071 loss: 0.000135589857
Iter: 1072 loss: 0.000135680646
Iter: 1073 loss: 0.000135409646
Iter: 1074 loss: 0.000135131835
Iter: 1075 loss: 0.000136602
Iter: 1076 loss: 0.000135088645
Iter: 1077 loss: 0.000134801812
Iter: 1078 loss: 0.000135424343
Iter: 1079 loss: 0.000134691276
Iter: 1080 loss: 0.000134423521
Iter: 1081 loss: 0.000135868788
Iter: 1082 loss: 0.000134383474
Iter: 1083 loss: 0.000134195056
Iter: 1084 loss: 0.000136259754
Iter: 1085 loss: 0.00013419133
Iter: 1086 loss: 0.000134025031
Iter: 1087 loss: 0.000134178641
Iter: 1088 loss: 0.000133929047
Iter: 1089 loss: 0.000133760492
Iter: 1090 loss: 0.00013390425
Iter: 1091 loss: 0.00013366068
Iter: 1092 loss: 0.000133473208
Iter: 1093 loss: 0.00013558552
Iter: 1094 loss: 0.000133469235
Iter: 1095 loss: 0.000133342954
Iter: 1096 loss: 0.000133600144
Iter: 1097 loss: 0.000133291964
Iter: 1098 loss: 0.000133141089
Iter: 1099 loss: 0.00013323137
Iter: 1100 loss: 0.000133043563
Iter: 1101 loss: 0.00013286373
Iter: 1102 loss: 0.000132968184
Iter: 1103 loss: 0.000132746572
Iter: 1104 loss: 0.000132537141
Iter: 1105 loss: 0.000132573361
Iter: 1106 loss: 0.000132379195
Iter: 1107 loss: 0.000132127796
Iter: 1108 loss: 0.000133245863
Iter: 1109 loss: 0.000132078101
Iter: 1110 loss: 0.000131812762
Iter: 1111 loss: 0.00013261252
Iter: 1112 loss: 0.000131732522
Iter: 1113 loss: 0.000131501933
Iter: 1114 loss: 0.000132431247
Iter: 1115 loss: 0.000131450463
Iter: 1116 loss: 0.000131268331
Iter: 1117 loss: 0.000133225039
Iter: 1118 loss: 0.000131263805
Iter: 1119 loss: 0.000131101959
Iter: 1120 loss: 0.000131295892
Iter: 1121 loss: 0.000131016888
Iter: 1122 loss: 0.000130859669
Iter: 1123 loss: 0.00013096258
Iter: 1124 loss: 0.000130759392
Iter: 1125 loss: 0.000130588538
Iter: 1126 loss: 0.000132676156
Iter: 1127 loss: 0.000130586443
Iter: 1128 loss: 0.000130472603
Iter: 1129 loss: 0.000130669127
Iter: 1130 loss: 0.000130421744
Iter: 1131 loss: 0.000130281813
Iter: 1132 loss: 0.000130424844
Iter: 1133 loss: 0.000130204338
Iter: 1134 loss: 0.000130047119
Iter: 1135 loss: 0.00013012893
Iter: 1136 loss: 0.000129942913
Iter: 1137 loss: 0.000129748805
Iter: 1138 loss: 0.000129774038
Iter: 1139 loss: 0.000129600696
Iter: 1140 loss: 0.000129366264
Iter: 1141 loss: 0.000130268134
Iter: 1142 loss: 0.000129310181
Iter: 1143 loss: 0.000129059321
Iter: 1144 loss: 0.000129853579
Iter: 1145 loss: 0.000128987595
Iter: 1146 loss: 0.00012875734
Iter: 1147 loss: 0.000129553868
Iter: 1148 loss: 0.000128696905
Iter: 1149 loss: 0.000128519619
Iter: 1150 loss: 0.000130755565
Iter: 1151 loss: 0.000128518557
Iter: 1152 loss: 0.00012836972
Iter: 1153 loss: 0.000128563523
Iter: 1154 loss: 0.000128293759
Iter: 1155 loss: 0.000128150103
Iter: 1156 loss: 0.000128186977
Iter: 1157 loss: 0.000128046246
Iter: 1158 loss: 0.000127890205
Iter: 1159 loss: 0.000130214728
Iter: 1160 loss: 0.000127890089
Iter: 1161 loss: 0.000127784384
Iter: 1162 loss: 0.000127991269
Iter: 1163 loss: 0.000127740888
Iter: 1164 loss: 0.000127618623
Iter: 1165 loss: 0.000127712847
Iter: 1166 loss: 0.000127543841
Iter: 1167 loss: 0.000127399602
Iter: 1168 loss: 0.000127434367
Iter: 1169 loss: 0.000127293752
Iter: 1170 loss: 0.0001271
Iter: 1171 loss: 0.000127151114
Iter: 1172 loss: 0.000126959261
Iter: 1173 loss: 0.000126733765
Iter: 1174 loss: 0.000127706589
Iter: 1175 loss: 0.000126687868
Iter: 1176 loss: 0.000126449
Iter: 1177 loss: 0.000127216597
Iter: 1178 loss: 0.000126380706
Iter: 1179 loss: 0.000126168423
Iter: 1180 loss: 0.000126925515
Iter: 1181 loss: 0.00012611394
Iter: 1182 loss: 0.000125956489
Iter: 1183 loss: 0.000127900828
Iter: 1184 loss: 0.000125954772
Iter: 1185 loss: 0.000125814666
Iter: 1186 loss: 0.000126049679
Iter: 1187 loss: 0.000125751278
Iter: 1188 loss: 0.000125616833
Iter: 1189 loss: 0.000125616731
Iter: 1190 loss: 0.000125508785
Iter: 1191 loss: 0.00012536587
Iter: 1192 loss: 0.000127545762
Iter: 1193 loss: 0.000125365972
Iter: 1194 loss: 0.000125273364
Iter: 1195 loss: 0.000125389066
Iter: 1196 loss: 0.000125225357
Iter: 1197 loss: 0.000125100574
Iter: 1198 loss: 0.000125244347
Iter: 1199 loss: 0.000125034159
Iter: 1200 loss: 0.000124890692
Iter: 1201 loss: 0.000124895392
Iter: 1202 loss: 0.000124776969
Iter: 1203 loss: 0.000124590559
Iter: 1204 loss: 0.000124696729
Iter: 1205 loss: 0.000124469079
Iter: 1206 loss: 0.000124263985
Iter: 1207 loss: 0.000124786631
Iter: 1208 loss: 0.000124193408
Iter: 1209 loss: 0.000123945705
Iter: 1210 loss: 0.000124883416
Iter: 1211 loss: 0.000123887265
Iter: 1212 loss: 0.000123673468
Iter: 1213 loss: 0.000124485116
Iter: 1214 loss: 0.000123622201
Iter: 1215 loss: 0.000123462742
Iter: 1216 loss: 0.000125143852
Iter: 1217 loss: 0.000123458522
Iter: 1218 loss: 0.000123316146
Iter: 1219 loss: 0.000123583275
Iter: 1220 loss: 0.000123255071
Iter: 1221 loss: 0.000123122736
Iter: 1222 loss: 0.000123128208
Iter: 1223 loss: 0.000123018952
Iter: 1224 loss: 0.000122882484
Iter: 1225 loss: 0.000122882499
Iter: 1226 loss: 0.000122787969
Iter: 1227 loss: 0.000122898811
Iter: 1228 loss: 0.000122738405
Iter: 1229 loss: 0.000122615063
Iter: 1230 loss: 0.000122783182
Iter: 1231 loss: 0.000122553407
Iter: 1232 loss: 0.000122423429
Iter: 1233 loss: 0.000122456084
Iter: 1234 loss: 0.000122328725
Iter: 1235 loss: 0.000122150901
Iter: 1236 loss: 0.000122205412
Iter: 1237 loss: 0.000122024074
Iter: 1238 loss: 0.000121809317
Iter: 1239 loss: 0.000122448051
Iter: 1240 loss: 0.000121743746
Iter: 1241 loss: 0.000121508921
Iter: 1242 loss: 0.000122594734
Iter: 1243 loss: 0.000121464247
Iter: 1244 loss: 0.000121271696
Iter: 1245 loss: 0.000121801117
Iter: 1246 loss: 0.00012120905
Iter: 1247 loss: 0.00012105221
Iter: 1248 loss: 0.000122908605
Iter: 1249 loss: 0.000121050092
Iter: 1250 loss: 0.000120915458
Iter: 1251 loss: 0.000121276491
Iter: 1252 loss: 0.000120871242
Iter: 1253 loss: 0.000120761033
Iter: 1254 loss: 0.000120730983
Iter: 1255 loss: 0.000120663266
Iter: 1256 loss: 0.000120545126
Iter: 1257 loss: 0.000120544799
Iter: 1258 loss: 0.00012046429
Iter: 1259 loss: 0.000120578981
Iter: 1260 loss: 0.000120424695
Iter: 1261 loss: 0.000120323486
Iter: 1262 loss: 0.000120477685
Iter: 1263 loss: 0.000120275508
Iter: 1264 loss: 0.000120165365
Iter: 1265 loss: 0.000120175762
Iter: 1266 loss: 0.000120080309
Iter: 1267 loss: 0.000119930395
Iter: 1268 loss: 0.000119948607
Iter: 1269 loss: 0.000119815842
Iter: 1270 loss: 0.000119634657
Iter: 1271 loss: 0.00012013856
Iter: 1272 loss: 0.000119576202
Iter: 1273 loss: 0.000119378863
Iter: 1274 loss: 0.000120306009
Iter: 1275 loss: 0.000119342636
Iter: 1276 loss: 0.000119171542
Iter: 1277 loss: 0.000119646109
Iter: 1278 loss: 0.000119116252
Iter: 1279 loss: 0.000118985598
Iter: 1280 loss: 0.000120568446
Iter: 1281 loss: 0.000118984244
Iter: 1282 loss: 0.000118873111
Iter: 1283 loss: 0.000119171644
Iter: 1284 loss: 0.000118836237
Iter: 1285 loss: 0.000118741329
Iter: 1286 loss: 0.000118711701
Iter: 1287 loss: 0.000118655298
Iter: 1288 loss: 0.000118558906
Iter: 1289 loss: 0.000118558077
Iter: 1290 loss: 0.000118489428
Iter: 1291 loss: 0.000118568671
Iter: 1292 loss: 0.000118452808
Iter: 1293 loss: 0.000118366115
Iter: 1294 loss: 0.000118502649
Iter: 1295 loss: 0.000118325552
Iter: 1296 loss: 0.000118236305
Iter: 1297 loss: 0.000118218479
Iter: 1298 loss: 0.000118159238
Iter: 1299 loss: 0.000118019903
Iter: 1300 loss: 0.000118089942
Iter: 1301 loss: 0.000117927375
Iter: 1302 loss: 0.000117768061
Iter: 1303 loss: 0.000118208751
Iter: 1304 loss: 0.000117715856
Iter: 1305 loss: 0.000117543626
Iter: 1306 loss: 0.000118463533
Iter: 1307 loss: 0.000117517229
Iter: 1308 loss: 0.000117374329
Iter: 1309 loss: 0.000117663985
Iter: 1310 loss: 0.000117316638
Iter: 1311 loss: 0.00011719008
Iter: 1312 loss: 0.000118593205
Iter: 1313 loss: 0.00011718693
Iter: 1314 loss: 0.000117076139
Iter: 1315 loss: 0.000117447271
Iter: 1316 loss: 0.00011704582
Iter: 1317 loss: 0.000116960029
Iter: 1318 loss: 0.000116917741
Iter: 1319 loss: 0.000116876865
Iter: 1320 loss: 0.000116786265
Iter: 1321 loss: 0.000116785821
Iter: 1322 loss: 0.000116719435
Iter: 1323 loss: 0.000116815885
Iter: 1324 loss: 0.000116687086
Iter: 1325 loss: 0.000116606185
Iter: 1326 loss: 0.000116738272
Iter: 1327 loss: 0.000116568975
Iter: 1328 loss: 0.000116479088
Iter: 1329 loss: 0.000116471194
Iter: 1330 loss: 0.000116405128
Iter: 1331 loss: 0.00011628314
Iter: 1332 loss: 0.000116327923
Iter: 1333 loss: 0.000116197945
Iter: 1334 loss: 0.000116049319
Iter: 1335 loss: 0.000116324489
Iter: 1336 loss: 0.000115985968
Iter: 1337 loss: 0.000115819203
Iter: 1338 loss: 0.000116861906
Iter: 1339 loss: 0.000115800278
Iter: 1340 loss: 0.000115660325
Iter: 1341 loss: 0.000115922274
Iter: 1342 loss: 0.000115601324
Iter: 1343 loss: 0.000115471579
Iter: 1344 loss: 0.000116673968
Iter: 1345 loss: 0.000115466333
Iter: 1346 loss: 0.000115350769
Iter: 1347 loss: 0.000115763192
Iter: 1348 loss: 0.000115321178
Iter: 1349 loss: 0.000115229195
Iter: 1350 loss: 0.000115201503
Iter: 1351 loss: 0.000115146773
Iter: 1352 loss: 0.000115057672
Iter: 1353 loss: 0.000115056886
Iter: 1354 loss: 0.000114990311
Iter: 1355 loss: 0.000115060138
Iter: 1356 loss: 0.000114953284
Iter: 1357 loss: 0.00011486985
Iter: 1358 loss: 0.00011503385
Iter: 1359 loss: 0.000114835209
Iter: 1360 loss: 0.000114754715
Iter: 1361 loss: 0.000114739683
Iter: 1362 loss: 0.000114685638
Iter: 1363 loss: 0.000114561568
Iter: 1364 loss: 0.000114637034
Iter: 1365 loss: 0.00011448186
Iter: 1366 loss: 0.000114329174
Iter: 1367 loss: 0.000114574934
Iter: 1368 loss: 0.000114258772
Iter: 1369 loss: 0.000114096925
Iter: 1370 loss: 0.000115391784
Iter: 1371 loss: 0.00011408607
Iter: 1372 loss: 0.000113958165
Iter: 1373 loss: 0.000114066199
Iter: 1374 loss: 0.000113882226
Iter: 1375 loss: 0.000113740556
Iter: 1376 loss: 0.000115214207
Iter: 1377 loss: 0.000113736824
Iter: 1378 loss: 0.00011361167
Iter: 1379 loss: 0.000114146853
Iter: 1380 loss: 0.000113585622
Iter: 1381 loss: 0.000113498536
Iter: 1382 loss: 0.000113456699
Iter: 1383 loss: 0.000113414542
Iter: 1384 loss: 0.000113327078
Iter: 1385 loss: 0.000113326969
Iter: 1386 loss: 0.000113259121
Iter: 1387 loss: 0.000113375754
Iter: 1388 loss: 0.000113228918
Iter: 1389 loss: 0.000113151982
Iter: 1390 loss: 0.000113297909
Iter: 1391 loss: 0.000113119386
Iter: 1392 loss: 0.000113036614
Iter: 1393 loss: 0.000113030095
Iter: 1394 loss: 0.000112967871
Iter: 1395 loss: 0.000112854563
Iter: 1396 loss: 0.000112873466
Iter: 1397 loss: 0.000112769689
Iter: 1398 loss: 0.000112619062
Iter: 1399 loss: 0.000112890601
Iter: 1400 loss: 0.000112553906
Iter: 1401 loss: 0.000112397756
Iter: 1402 loss: 0.000113522663
Iter: 1403 loss: 0.000112384136
Iter: 1404 loss: 0.000112251597
Iter: 1405 loss: 0.000112454953
Iter: 1406 loss: 0.000112188871
Iter: 1407 loss: 0.000112057518
Iter: 1408 loss: 0.00011309822
Iter: 1409 loss: 0.000112048903
Iter: 1410 loss: 0.000111927926
Iter: 1411 loss: 0.000112533169
Iter: 1412 loss: 0.000111907386
Iter: 1413 loss: 0.000111821231
Iter: 1414 loss: 0.000111763962
Iter: 1415 loss: 0.000111731308
Iter: 1416 loss: 0.000111646579
Iter: 1417 loss: 0.000111645553
Iter: 1418 loss: 0.000111581161
Iter: 1419 loss: 0.000111650777
Iter: 1420 loss: 0.000111546135
Iter: 1421 loss: 0.000111466274
Iter: 1422 loss: 0.000111639449
Iter: 1423 loss: 0.000111434943
Iter: 1424 loss: 0.000111358546
Iter: 1425 loss: 0.000111313428
Iter: 1426 loss: 0.00011128129
Iter: 1427 loss: 0.000111155765
Iter: 1428 loss: 0.000111312183
Iter: 1429 loss: 0.00011109066
Iter: 1430 loss: 0.000110953399
Iter: 1431 loss: 0.000111103313
Iter: 1432 loss: 0.000110878558
Iter: 1433 loss: 0.000110729845
Iter: 1434 loss: 0.000112085181
Iter: 1435 loss: 0.000110723151
Iter: 1436 loss: 0.000110607012
Iter: 1437 loss: 0.000110709661
Iter: 1438 loss: 0.000110539346
Iter: 1439 loss: 0.000110404704
Iter: 1440 loss: 0.000111467743
Iter: 1441 loss: 0.000110395194
Iter: 1442 loss: 0.000110272158
Iter: 1443 loss: 0.000110952264
Iter: 1444 loss: 0.00011025498
Iter: 1445 loss: 0.000110171022
Iter: 1446 loss: 0.00011014034
Iter: 1447 loss: 0.000110093111
Iter: 1448 loss: 0.000110012894
Iter: 1449 loss: 0.000111247355
Iter: 1450 loss: 0.00011001317
Iter: 1451 loss: 0.00010994987
Iter: 1452 loss: 0.000110065128
Iter: 1453 loss: 0.000109922083
Iter: 1454 loss: 0.000109851972
Iter: 1455 loss: 0.000109991306
Iter: 1456 loss: 0.000109823581
Iter: 1457 loss: 0.000109747518
Iter: 1458 loss: 0.000109744724
Iter: 1459 loss: 0.000109685927
Iter: 1460 loss: 0.0001095888
Iter: 1461 loss: 0.000109654837
Iter: 1462 loss: 0.000109527959
Iter: 1463 loss: 0.000109409666
Iter: 1464 loss: 0.000109535133
Iter: 1465 loss: 0.000109344895
Iter: 1466 loss: 0.000109216504
Iter: 1467 loss: 0.000110203284
Iter: 1468 loss: 0.000109207125
Iter: 1469 loss: 0.000109092514
Iter: 1470 loss: 0.000109249275
Iter: 1471 loss: 0.000109035514
Iter: 1472 loss: 0.000108918022
Iter: 1473 loss: 0.000109724766
Iter: 1474 loss: 0.000108906941
Iter: 1475 loss: 0.000108801862
Iter: 1476 loss: 0.000109493551
Iter: 1477 loss: 0.0001087907
Iter: 1478 loss: 0.00010872056
Iter: 1479 loss: 0.00010867395
Iter: 1480 loss: 0.000108647837
Iter: 1481 loss: 0.000108575587
Iter: 1482 loss: 0.000108575216
Iter: 1483 loss: 0.000108519926
Iter: 1484 loss: 0.000108614862
Iter: 1485 loss: 0.00010849494
Iter: 1486 loss: 0.000108434986
Iter: 1487 loss: 0.000108577311
Iter: 1488 loss: 0.000108413282
Iter: 1489 loss: 0.000108357075
Iter: 1490 loss: 0.000108323744
Iter: 1491 loss: 0.000108300839
Iter: 1492 loss: 0.000108208536
Iter: 1493 loss: 0.000108295397
Iter: 1494 loss: 0.000108155495
Iter: 1495 loss: 0.000108049266
Iter: 1496 loss: 0.000108161235
Iter: 1497 loss: 0.000107990199
Iter: 1498 loss: 0.000107876884
Iter: 1499 loss: 0.000108896827
Iter: 1500 loss: 0.00010787163
Iter: 1501 loss: 0.000107777974
Iter: 1502 loss: 0.000107836415
Iter: 1503 loss: 0.000107718181
Iter: 1504 loss: 0.000107606509
Iter: 1505 loss: 0.000108473541
Iter: 1506 loss: 0.000107598265
Iter: 1507 loss: 0.000107501335
Iter: 1508 loss: 0.000108143206
Iter: 1509 loss: 0.000107491069
Iter: 1510 loss: 0.000107423475
Iter: 1511 loss: 0.000107391774
Iter: 1512 loss: 0.000107358566
Iter: 1513 loss: 0.000107291533
Iter: 1514 loss: 0.000108212742
Iter: 1515 loss: 0.0001072913
Iter: 1516 loss: 0.000107237502
Iter: 1517 loss: 0.000107367916
Iter: 1518 loss: 0.000107218497
Iter: 1519 loss: 0.000107165812
Iter: 1520 loss: 0.000107271801
Iter: 1521 loss: 0.000107144406
Iter: 1522 loss: 0.000107086227
Iter: 1523 loss: 0.000107063635
Iter: 1524 loss: 0.000107032392
Iter: 1525 loss: 0.000106948522
Iter: 1526 loss: 0.000107014144
Iter: 1527 loss: 0.000106897656
Iter: 1528 loss: 0.000106797401
Iter: 1529 loss: 0.000106941305
Iter: 1530 loss: 0.00010674879
Iter: 1531 loss: 0.000106646214
Iter: 1532 loss: 0.00010733294
Iter: 1533 loss: 0.000106636013
Iter: 1534 loss: 0.000106537991
Iter: 1535 loss: 0.000106686675
Iter: 1536 loss: 0.000106491381
Iter: 1537 loss: 0.000106391701
Iter: 1538 loss: 0.000106999832
Iter: 1539 loss: 0.000106379775
Iter: 1540 loss: 0.00010629031
Iter: 1541 loss: 0.000106948879
Iter: 1542 loss: 0.00010628278
Iter: 1543 loss: 0.000106220832
Iter: 1544 loss: 0.000106188148
Iter: 1545 loss: 0.00010615967
Iter: 1546 loss: 0.00010609733
Iter: 1547 loss: 0.000106097257
Iter: 1548 loss: 0.000106047
Iter: 1549 loss: 0.000106148575
Iter: 1550 loss: 0.00010602671
Iter: 1551 loss: 0.000105974919
Iter: 1552 loss: 0.000106078893
Iter: 1553 loss: 0.000105953957
Iter: 1554 loss: 0.000105901723
Iter: 1555 loss: 0.000105875231
Iter: 1556 loss: 0.000105850515
Iter: 1557 loss: 0.000105768784
Iter: 1558 loss: 0.00010586789
Iter: 1559 loss: 0.00010572614
Iter: 1560 loss: 0.000105633073
Iter: 1561 loss: 0.000105713763
Iter: 1562 loss: 0.000105578445
Iter: 1563 loss: 0.000105480183
Iter: 1564 loss: 0.000106374879
Iter: 1565 loss: 0.000105475716
Iter: 1566 loss: 0.000105391911
Iter: 1567 loss: 0.000105452156
Iter: 1568 loss: 0.00010534039
Iter: 1569 loss: 0.00010524167
Iter: 1570 loss: 0.000105907995
Iter: 1571 loss: 0.000105231506
Iter: 1572 loss: 0.000105144674
Iter: 1573 loss: 0.000105858569
Iter: 1574 loss: 0.000105139217
Iter: 1575 loss: 0.000105081905
Iter: 1576 loss: 0.000105039253
Iter: 1577 loss: 0.000105020401
Iter: 1578 loss: 0.000104956373
Iter: 1579 loss: 0.000105665909
Iter: 1580 loss: 0.000104955303
Iter: 1581 loss: 0.000104900959
Iter: 1582 loss: 0.000105057014
Iter: 1583 loss: 0.000104884268
Iter: 1584 loss: 0.000104832725
Iter: 1585 loss: 0.000104955878
Iter: 1586 loss: 0.000104814651
Iter: 1587 loss: 0.000104760889
Iter: 1588 loss: 0.000104738734
Iter: 1589 loss: 0.000104710438
Iter: 1590 loss: 0.000104635095
Iter: 1591 loss: 0.000104658218
Iter: 1592 loss: 0.000104581304
Iter: 1593 loss: 0.000104480525
Iter: 1594 loss: 0.000104649298
Iter: 1595 loss: 0.000104434555
Iter: 1596 loss: 0.000104338513
Iter: 1597 loss: 0.000104968058
Iter: 1598 loss: 0.000104327934
Iter: 1599 loss: 0.000104232524
Iter: 1600 loss: 0.000104362523
Iter: 1601 loss: 0.000104184837
Iter: 1602 loss: 0.000104084473
Iter: 1603 loss: 0.000104613428
Iter: 1604 loss: 0.000104068669
Iter: 1605 loss: 0.000103979342
Iter: 1606 loss: 0.000104767139
Iter: 1607 loss: 0.000103974759
Iter: 1608 loss: 0.000103913117
Iter: 1609 loss: 0.000103866703
Iter: 1610 loss: 0.00010384612
Iter: 1611 loss: 0.000103776089
Iter: 1612 loss: 0.000104676437
Iter: 1613 loss: 0.000103775455
Iter: 1614 loss: 0.000103717714
Iter: 1615 loss: 0.000103892417
Iter: 1616 loss: 0.000103700775
Iter: 1617 loss: 0.00010364785
Iter: 1618 loss: 0.000103761777
Iter: 1619 loss: 0.000103627281
Iter: 1620 loss: 0.000103573031
Iter: 1621 loss: 0.000103538958
Iter: 1622 loss: 0.000103517625
Iter: 1623 loss: 0.0001034292
Iter: 1624 loss: 0.000103522085
Iter: 1625 loss: 0.000103380356
Iter: 1626 loss: 0.000103279934
Iter: 1627 loss: 0.00010340946
Iter: 1628 loss: 0.000103228856
Iter: 1629 loss: 0.000103130515
Iter: 1630 loss: 0.000103849205
Iter: 1631 loss: 0.000103121965
Iter: 1632 loss: 0.000103029903
Iter: 1633 loss: 0.000103138118
Iter: 1634 loss: 0.000102981066
Iter: 1635 loss: 0.000102880149
Iter: 1636 loss: 0.000103518913
Iter: 1637 loss: 0.000102868435
Iter: 1638 loss: 0.000102787621
Iter: 1639 loss: 0.000103598941
Iter: 1640 loss: 0.00010278487
Iter: 1641 loss: 0.000102732607
Iter: 1642 loss: 0.000102700367
Iter: 1643 loss: 0.000102679187
Iter: 1644 loss: 0.000102620965
Iter: 1645 loss: 0.000103144281
Iter: 1646 loss: 0.000102617683
Iter: 1647 loss: 0.000102565464
Iter: 1648 loss: 0.000102741978
Iter: 1649 loss: 0.000102551479
Iter: 1650 loss: 0.000102504418
Iter: 1651 loss: 0.000102589263
Iter: 1652 loss: 0.000102484148
Iter: 1653 loss: 0.000102430873
Iter: 1654 loss: 0.000102418322
Iter: 1655 loss: 0.000102384234
Iter: 1656 loss: 0.000102313395
Iter: 1657 loss: 0.000102368918
Iter: 1658 loss: 0.000102270431
Iter: 1659 loss: 0.00010218336
Iter: 1660 loss: 0.000102308652
Iter: 1661 loss: 0.000102140941
Iter: 1662 loss: 0.000102057864
Iter: 1663 loss: 0.000102582599
Iter: 1664 loss: 0.000102048267
Iter: 1665 loss: 0.000101966296
Iter: 1666 loss: 0.00010212537
Iter: 1667 loss: 0.000101932186
Iter: 1668 loss: 0.000101857528
Iter: 1669 loss: 0.000102301186
Iter: 1670 loss: 0.000101848083
Iter: 1671 loss: 0.000101789206
Iter: 1672 loss: 0.000102468141
Iter: 1673 loss: 0.000101788457
Iter: 1674 loss: 0.000101749029
Iter: 1675 loss: 0.000101716651
Iter: 1676 loss: 0.000101705009
Iter: 1677 loss: 0.000101654696
Iter: 1678 loss: 0.00010206888
Iter: 1679 loss: 0.000101651538
Iter: 1680 loss: 0.000101604557
Iter: 1681 loss: 0.000101763122
Iter: 1682 loss: 0.000101592203
Iter: 1683 loss: 0.000101549595
Iter: 1684 loss: 0.000101646408
Iter: 1685 loss: 0.00010153318
Iter: 1686 loss: 0.000101490717
Iter: 1687 loss: 0.00010146937
Iter: 1688 loss: 0.000101449456
Iter: 1689 loss: 0.000101387399
Iter: 1690 loss: 0.00010143753
Iter: 1691 loss: 0.000101350037
Iter: 1692 loss: 0.000101273959
Iter: 1693 loss: 0.000101372854
Iter: 1694 loss: 0.000101235
Iter: 1695 loss: 0.000101160738
Iter: 1696 loss: 0.000101689249
Iter: 1697 loss: 0.000101154044
Iter: 1698 loss: 0.000101085127
Iter: 1699 loss: 0.000101206475
Iter: 1700 loss: 0.000101054808
Iter: 1701 loss: 0.000100986901
Iter: 1702 loss: 0.000101328449
Iter: 1703 loss: 0.000100975507
Iter: 1704 loss: 0.000100919911
Iter: 1705 loss: 0.000101552396
Iter: 1706 loss: 0.000100918871
Iter: 1707 loss: 0.000100879966
Iter: 1708 loss: 0.000100848025
Iter: 1709 loss: 0.000100836733
Iter: 1710 loss: 0.000100785495
Iter: 1711 loss: 0.000101110214
Iter: 1712 loss: 0.00010077974
Iter: 1713 loss: 0.000100730336
Iter: 1714 loss: 0.00010094016
Iter: 1715 loss: 0.000100719946
Iter: 1716 loss: 0.00010067907
Iter: 1717 loss: 0.000100759418
Iter: 1718 loss: 0.00010066219
Iter: 1719 loss: 0.000100616657
Iter: 1720 loss: 0.000100595236
Iter: 1721 loss: 0.00010057247
Iter: 1722 loss: 0.000100507292
Iter: 1723 loss: 0.000100558907
Iter: 1724 loss: 0.000100467892
Iter: 1725 loss: 0.000100387369
Iter: 1726 loss: 0.000100504622
Iter: 1727 loss: 0.000100348778
Iter: 1728 loss: 0.000100270416
Iter: 1729 loss: 0.000100693796
Iter: 1730 loss: 0.000100258956
Iter: 1731 loss: 0.000100179423
Iter: 1732 loss: 0.000100360601
Iter: 1733 loss: 0.000100149598
Iter: 1734 loss: 0.000100074489
Iter: 1735 loss: 0.000100430021
Iter: 1736 loss: 0.000100061283
Iter: 1737 loss: 0.000100000361
Iter: 1738 loss: 0.000100721343
Iter: 1739 loss: 9.99994081e-05
Iter: 1740 loss: 9.99555923e-05
Iter: 1741 loss: 9.99275217e-05
Iter: 1742 loss: 9.9910656e-05
Iter: 1743 loss: 9.98565811e-05
Iter: 1744 loss: 0.000100229052
Iter: 1745 loss: 9.98518e-05
Iter: 1746 loss: 9.98011674e-05
Iter: 1747 loss: 9.99859403e-05
Iter: 1748 loss: 9.97886382e-05
Iter: 1749 loss: 9.9744313e-05
Iter: 1750 loss: 9.98377363e-05
Iter: 1751 loss: 9.97271854e-05
Iter: 1752 loss: 9.96777671e-05
Iter: 1753 loss: 9.96707822e-05
Iter: 1754 loss: 9.96362069e-05
Iter: 1755 loss: 9.956961e-05
Iter: 1756 loss: 9.96417511e-05
Iter: 1757 loss: 9.95331648e-05
Iter: 1758 loss: 9.945489e-05
Iter: 1759 loss: 9.95255104e-05
Iter: 1760 loss: 9.94094225e-05
Iter: 1761 loss: 9.93256253e-05
Iter: 1762 loss: 9.97608877e-05
Iter: 1763 loss: 9.93120775e-05
Iter: 1764 loss: 9.92258356e-05
Iter: 1765 loss: 9.94680886e-05
Iter: 1766 loss: 9.91987472e-05
Iter: 1767 loss: 9.91235283e-05
Iter: 1768 loss: 9.94928414e-05
Iter: 1769 loss: 9.91105626e-05
Iter: 1770 loss: 9.90517437e-05
Iter: 1771 loss: 9.9777506e-05
Iter: 1772 loss: 9.90511762e-05
Iter: 1773 loss: 9.90106128e-05
Iter: 1774 loss: 9.89889813e-05
Iter: 1775 loss: 9.89712062e-05
Iter: 1776 loss: 9.89221662e-05
Iter: 1777 loss: 9.91938068e-05
Iter: 1778 loss: 9.89156906e-05
Iter: 1779 loss: 9.88658721e-05
Iter: 1780 loss: 9.90933913e-05
Iter: 1781 loss: 9.88565153e-05
Iter: 1782 loss: 9.88178508e-05
Iter: 1783 loss: 9.88800675e-05
Iter: 1784 loss: 9.88001e-05
Iter: 1785 loss: 9.87540188e-05
Iter: 1786 loss: 9.87462e-05
Iter: 1787 loss: 9.87146632e-05
Iter: 1788 loss: 9.86545347e-05
Iter: 1789 loss: 9.86973319e-05
Iter: 1790 loss: 9.86173472e-05
Iter: 1791 loss: 9.85411098e-05
Iter: 1792 loss: 9.86374653e-05
Iter: 1793 loss: 9.85019651e-05
Iter: 1794 loss: 9.84178623e-05
Iter: 1795 loss: 9.8758981e-05
Iter: 1796 loss: 9.8399265e-05
Iter: 1797 loss: 9.83114733e-05
Iter: 1798 loss: 9.86478699e-05
Iter: 1799 loss: 9.82906422e-05
Iter: 1800 loss: 9.82232305e-05
Iter: 1801 loss: 9.85354854e-05
Iter: 1802 loss: 9.82108904e-05
Iter: 1803 loss: 9.81591e-05
Iter: 1804 loss: 9.88441752e-05
Iter: 1805 loss: 9.81589328e-05
Iter: 1806 loss: 9.812192e-05
Iter: 1807 loss: 9.80952827e-05
Iter: 1808 loss: 9.80828845e-05
Iter: 1809 loss: 9.80361729e-05
Iter: 1810 loss: 9.83456775e-05
Iter: 1811 loss: 9.80314944e-05
Iter: 1812 loss: 9.79864562e-05
Iter: 1813 loss: 9.81856356e-05
Iter: 1814 loss: 9.79776669e-05
Iter: 1815 loss: 9.79401375e-05
Iter: 1816 loss: 9.80008699e-05
Iter: 1817 loss: 9.79220931e-05
Iter: 1818 loss: 9.78791359e-05
Iter: 1819 loss: 9.78653698e-05
Iter: 1820 loss: 9.78398e-05
Iter: 1821 loss: 9.77782256e-05
Iter: 1822 loss: 9.78291937e-05
Iter: 1823 loss: 9.77412e-05
Iter: 1824 loss: 9.76631709e-05
Iter: 1825 loss: 9.77424934e-05
Iter: 1826 loss: 9.76190931e-05
Iter: 1827 loss: 9.75306393e-05
Iter: 1828 loss: 9.78855096e-05
Iter: 1829 loss: 9.7510645e-05
Iter: 1830 loss: 9.7422555e-05
Iter: 1831 loss: 9.78494791e-05
Iter: 1832 loss: 9.74072173e-05
Iter: 1833 loss: 9.73434071e-05
Iter: 1834 loss: 9.75955045e-05
Iter: 1835 loss: 9.73284768e-05
Iter: 1836 loss: 9.7276672e-05
Iter: 1837 loss: 9.79635661e-05
Iter: 1838 loss: 9.72764392e-05
Iter: 1839 loss: 9.72391354e-05
Iter: 1840 loss: 9.72103153e-05
Iter: 1841 loss: 9.71986519e-05
Iter: 1842 loss: 9.71496484e-05
Iter: 1843 loss: 9.73497517e-05
Iter: 1844 loss: 9.71389818e-05
Iter: 1845 loss: 9.70867404e-05
Iter: 1846 loss: 9.74065333e-05
Iter: 1847 loss: 9.70803667e-05
Iter: 1848 loss: 9.70420369e-05
Iter: 1849 loss: 9.7086071e-05
Iter: 1850 loss: 9.70212423e-05
Iter: 1851 loss: 9.69710527e-05
Iter: 1852 loss: 9.69564862e-05
Iter: 1853 loss: 9.69255343e-05
Iter: 1854 loss: 9.68561726e-05
Iter: 1855 loss: 9.69175308e-05
Iter: 1856 loss: 9.681542e-05
Iter: 1857 loss: 9.67320375e-05
Iter: 1858 loss: 9.68385e-05
Iter: 1859 loss: 9.6689022e-05
Iter: 1860 loss: 9.65980435e-05
Iter: 1861 loss: 9.69318426e-05
Iter: 1862 loss: 9.65755244e-05
Iter: 1863 loss: 9.64837236e-05
Iter: 1864 loss: 9.69690736e-05
Iter: 1865 loss: 9.64695064e-05
Iter: 1866 loss: 9.64024512e-05
Iter: 1867 loss: 9.66121806e-05
Iter: 1868 loss: 9.63830389e-05
Iter: 1869 loss: 9.63261409e-05
Iter: 1870 loss: 9.71259869e-05
Iter: 1871 loss: 9.63259445e-05
Iter: 1872 loss: 9.62826234e-05
Iter: 1873 loss: 9.62468839e-05
Iter: 1874 loss: 9.62343329e-05
Iter: 1875 loss: 9.61755868e-05
Iter: 1876 loss: 9.65071813e-05
Iter: 1877 loss: 9.61673431e-05
Iter: 1878 loss: 9.61112164e-05
Iter: 1879 loss: 9.6485368e-05
Iter: 1880 loss: 9.61056721e-05
Iter: 1881 loss: 9.60639591e-05
Iter: 1882 loss: 9.61085752e-05
Iter: 1883 loss: 9.60405596e-05
Iter: 1884 loss: 9.59899626e-05
Iter: 1885 loss: 9.59855315e-05
Iter: 1886 loss: 9.59481404e-05
Iter: 1887 loss: 9.58839082e-05
Iter: 1888 loss: 9.59414174e-05
Iter: 1889 loss: 9.58462115e-05
Iter: 1890 loss: 9.57679e-05
Iter: 1891 loss: 9.58831515e-05
Iter: 1892 loss: 9.57296725e-05
Iter: 1893 loss: 9.56456643e-05
Iter: 1894 loss: 9.58985038e-05
Iter: 1895 loss: 9.56205768e-05
Iter: 1896 loss: 9.55325377e-05
Iter: 1897 loss: 9.60207108e-05
Iter: 1898 loss: 9.55197611e-05
Iter: 1899 loss: 9.54543866e-05
Iter: 1900 loss: 9.56422227e-05
Iter: 1901 loss: 9.5433672e-05
Iter: 1902 loss: 9.53764102e-05
Iter: 1903 loss: 9.6233256e-05
Iter: 1904 loss: 9.53762938e-05
Iter: 1905 loss: 9.53320778e-05
Iter: 1906 loss: 9.53007475e-05
Iter: 1907 loss: 9.52853807e-05
Iter: 1908 loss: 9.52303817e-05
Iter: 1909 loss: 9.5380281e-05
Iter: 1910 loss: 9.52121773e-05
Iter: 1911 loss: 9.51521579e-05
Iter: 1912 loss: 9.56276635e-05
Iter: 1913 loss: 9.51482943e-05
Iter: 1914 loss: 9.51090042e-05
Iter: 1915 loss: 9.51406619e-05
Iter: 1916 loss: 9.50855174e-05
Iter: 1917 loss: 9.50330068e-05
Iter: 1918 loss: 9.50272879e-05
Iter: 1919 loss: 9.49893074e-05
Iter: 1920 loss: 9.49228706e-05
Iter: 1921 loss: 9.49955938e-05
Iter: 1922 loss: 9.48870293e-05
Iter: 1923 loss: 9.48096567e-05
Iter: 1924 loss: 9.49048481e-05
Iter: 1925 loss: 9.47692461e-05
Iter: 1926 loss: 9.46790678e-05
Iter: 1927 loss: 9.49257665e-05
Iter: 1928 loss: 9.46494547e-05
Iter: 1929 loss: 9.4556046e-05
Iter: 1930 loss: 9.51649854e-05
Iter: 1931 loss: 9.4546027e-05
Iter: 1932 loss: 9.44773492e-05
Iter: 1933 loss: 9.4611125e-05
Iter: 1934 loss: 9.44491767e-05
Iter: 1935 loss: 9.43881823e-05
Iter: 1936 loss: 9.43882333e-05
Iter: 1937 loss: 9.43393388e-05
Iter: 1938 loss: 9.43056802e-05
Iter: 1939 loss: 9.42883053e-05
Iter: 1940 loss: 9.42252082e-05
Iter: 1941 loss: 9.44915519e-05
Iter: 1942 loss: 9.42123588e-05
Iter: 1943 loss: 9.41535109e-05
Iter: 1944 loss: 9.45816137e-05
Iter: 1945 loss: 9.41485196e-05
Iter: 1946 loss: 9.41046164e-05
Iter: 1947 loss: 9.41612234e-05
Iter: 1948 loss: 9.40821337e-05
Iter: 1949 loss: 9.402859e-05
Iter: 1950 loss: 9.40520695e-05
Iter: 1951 loss: 9.39928577e-05
Iter: 1952 loss: 9.39334568e-05
Iter: 1953 loss: 9.39664387e-05
Iter: 1954 loss: 9.38945086e-05
Iter: 1955 loss: 9.38156445e-05
Iter: 1956 loss: 9.39110905e-05
Iter: 1957 loss: 9.37747172e-05
Iter: 1958 loss: 9.36877477e-05
Iter: 1959 loss: 9.39424499e-05
Iter: 1960 loss: 9.36609e-05
Iter: 1961 loss: 9.35772114e-05
Iter: 1962 loss: 9.41805338e-05
Iter: 1963 loss: 9.35700955e-05
Iter: 1964 loss: 9.35071221e-05
Iter: 1965 loss: 9.35982171e-05
Iter: 1966 loss: 9.34766576e-05
Iter: 1967 loss: 9.34158597e-05
Iter: 1968 loss: 9.42944316e-05
Iter: 1969 loss: 9.34157506e-05
Iter: 1970 loss: 9.33663177e-05
Iter: 1971 loss: 9.33704941e-05
Iter: 1972 loss: 9.33282e-05
Iter: 1973 loss: 9.32790281e-05
Iter: 1974 loss: 9.33940901e-05
Iter: 1975 loss: 9.32611729e-05
Iter: 1976 loss: 9.32086114e-05
Iter: 1977 loss: 9.37831792e-05
Iter: 1978 loss: 9.32074327e-05
Iter: 1979 loss: 9.31751e-05
Iter: 1980 loss: 9.31991308e-05
Iter: 1981 loss: 9.31552349e-05
Iter: 1982 loss: 9.31124086e-05
Iter: 1983 loss: 9.31199756e-05
Iter: 1984 loss: 9.30803944e-05
Iter: 1985 loss: 9.30290553e-05
Iter: 1986 loss: 9.30640163e-05
Iter: 1987 loss: 9.29968737e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4
+ date
Tue Oct 27 16:08:30 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d82fa840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d8403d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d84037b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d8296950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d82960d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d82a77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d820a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d820a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d81c9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d81c9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d819a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d81548c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d81671e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d8109ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d8154378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d8109a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d80d1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d80f2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d80578c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d80571e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d80719d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76d80716a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfd20730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfcc5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfcc5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfc79598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfcb48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfcb49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfc56510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfbff378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfc56950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfbd9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfbeb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfb90d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfb47a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f76cfb471e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.132429898
Iter: 2 loss: 5987.56201
Iter: 3 loss: 0.132424444
Iter: 4 loss: 2460.77344
Iter: 5 loss: 0.132416964
Iter: 6 loss: 6540.98877
Iter: 7 loss: 0.132406846
Iter: 8 loss: 1678.72339
Iter: 9 loss: 1162.82251
Iter: 10 loss: 949.9198
Iter: 11 loss: 0.132403836
Iter: 12 loss: 232.071243
Iter: 13 loss: 0.132403687
Iter: 14 loss: 239.196564
Iter: 15 loss: 0.0907029212
Iter: 16 loss: 0.122326985
Iter: 17 loss: 0.10185422
Iter: 18 loss: 0.0938229
Iter: 19 loss: 0.0871048
Iter: 20 loss: 0.0864591822
Iter: 21 loss: 114.424706
Iter: 22 loss: 0.086455062
Iter: 23 loss: 0.0860054493
Iter: 24 loss: 0.0812466592
Iter: 25 loss: 0.0788494945
Iter: 26 loss: 0.0779637247
Iter: 27 loss: 0.074295789
Iter: 28 loss: 0.0838415474
Iter: 29 loss: 0.0746235102
Iter: 30 loss: 0.0708965883
Iter: 31 loss: 0.0760655627
Iter: 32 loss: 0.0688617826
Iter: 33 loss: 0.0710768178
Iter: 34 loss: 0.0676853359
Iter: 35 loss: 0.0716976374
Iter: 36 loss: 0.0667248517
Iter: 37 loss: 0.0645050406
Iter: 38 loss: 0.0637690648
Iter: 39 loss: 0.0593866
Iter: 40 loss: 0.0593729801
Iter: 41 loss: 0.0548815951
Iter: 42 loss: 0.100256532
Iter: 43 loss: 0.0547502637
Iter: 44 loss: 0.0567337796
Iter: 45 loss: 0.0525000207
Iter: 46 loss: 0.0501935855
Iter: 47 loss: 0.0575947
Iter: 48 loss: 0.0499122739
Iter: 49 loss: 0.0480210893
Iter: 50 loss: 0.0683053955
Iter: 51 loss: 0.047887627
Iter: 52 loss: 0.0461673364
Iter: 53 loss: 0.0461581126
Iter: 54 loss: 0.0444864258
Iter: 55 loss: 0.050887011
Iter: 56 loss: 0.0441893749
Iter: 57 loss: 0.0504626259
Iter: 58 loss: 0.0439246371
Iter: 59 loss: 0.0431307331
Iter: 60 loss: 0.0524594188
Iter: 61 loss: 0.0430645049
Iter: 62 loss: 0.0418884791
Iter: 63 loss: 0.0412494205
Iter: 64 loss: 0.0406431034
Iter: 65 loss: 0.0393534899
Iter: 66 loss: 0.0393532924
Iter: 67 loss: 0.0380745195
Iter: 68 loss: 0.0492418259
Iter: 69 loss: 0.0379005745
Iter: 70 loss: 0.0373715498
Iter: 71 loss: 0.0370239466
Iter: 72 loss: 0.0360270478
Iter: 73 loss: 0.0480797738
Iter: 74 loss: 0.0359366499
Iter: 75 loss: 0.0354793109
Iter: 76 loss: 0.0354790054
Iter: 77 loss: 0.0351615436
Iter: 78 loss: 0.0352019891
Iter: 79 loss: 0.0349224359
Iter: 80 loss: 0.0347974151
Iter: 81 loss: 0.0347543471
Iter: 82 loss: 0.0346859209
Iter: 83 loss: 0.034191221
Iter: 84 loss: 0.0329780318
Iter: 85 loss: 0.0486478806
Iter: 86 loss: 0.0328535326
Iter: 87 loss: 0.0320068337
Iter: 88 loss: 0.031935472
Iter: 89 loss: 0.030909488
Iter: 90 loss: 0.0469553806
Iter: 91 loss: 0.0308589321
Iter: 92 loss: 0.0307181496
Iter: 93 loss: 0.0307177715
Iter: 94 loss: 0.0306817852
Iter: 95 loss: 0.0310893971
Iter: 96 loss: 0.0306812264
Iter: 97 loss: 0.0306403749
Iter: 98 loss: 0.0305190608
Iter: 99 loss: 0.0307903141
Iter: 100 loss: 0.0304565541
Iter: 101 loss: 0.0301748663
Iter: 102 loss: 0.0298391543
Iter: 103 loss: 0.0297860764
Iter: 104 loss: 0.0293142777
Iter: 105 loss: 0.0303543247
Iter: 106 loss: 0.0290869623
Iter: 107 loss: 0.0286516566
Iter: 108 loss: 0.0302477442
Iter: 109 loss: 0.0285527557
Iter: 110 loss: 0.0290380381
Iter: 111 loss: 0.0283792429
Iter: 112 loss: 0.0280097201
Iter: 113 loss: 0.0292537026
Iter: 114 loss: 0.0279356465
Iter: 115 loss: 0.0278400555
Iter: 116 loss: 0.0288696662
Iter: 117 loss: 0.0278388094
Iter: 118 loss: 0.0278153829
Iter: 119 loss: 0.0278326645
Iter: 120 loss: 0.0278010573
Iter: 121 loss: 0.027536016
Iter: 122 loss: 0.0270222332
Iter: 123 loss: 0.0443658568
Iter: 124 loss: 0.0270211436
Iter: 125 loss: 0.0288333837
Iter: 126 loss: 0.0268673897
Iter: 127 loss: 0.0266337581
Iter: 128 loss: 0.0269870423
Iter: 129 loss: 0.026509691
Iter: 130 loss: 0.0262994412
Iter: 131 loss: 0.0261827465
Iter: 132 loss: 0.0260925293
Iter: 133 loss: 0.0262378138
Iter: 134 loss: 0.0259832069
Iter: 135 loss: 0.0257220212
Iter: 136 loss: 0.0265614279
Iter: 137 loss: 0.0256458297
Iter: 138 loss: 0.0253302418
Iter: 139 loss: 0.0254232921
Iter: 140 loss: 0.0250800811
Iter: 141 loss: 0.0246557351
Iter: 142 loss: 0.0246331394
Iter: 143 loss: 0.0243196767
Iter: 144 loss: 0.024836868
Iter: 145 loss: 0.0241693482
Iter: 146 loss: 0.0238506235
Iter: 147 loss: 0.0247572977
Iter: 148 loss: 0.0237327963
Iter: 149 loss: 0.0235760584
Iter: 150 loss: 0.0238056853
Iter: 151 loss: 0.0235009
Iter: 152 loss: 0.0231919326
Iter: 153 loss: 0.0230852049
Iter: 154 loss: 0.0229179934
Iter: 155 loss: 0.0233389586
Iter: 156 loss: 0.0226492099
Iter: 157 loss: 0.0224965438
Iter: 158 loss: 0.0229749084
Iter: 159 loss: 0.0224484801
Iter: 160 loss: 0.0223629232
Iter: 161 loss: 0.0221402179
Iter: 162 loss: 0.0237379484
Iter: 163 loss: 0.0220942609
Iter: 164 loss: 0.021849364
Iter: 165 loss: 0.0214529373
Iter: 166 loss: 0.0214458182
Iter: 167 loss: 0.0212106593
Iter: 168 loss: 0.0223315395
Iter: 169 loss: 0.0211729482
Iter: 170 loss: 0.021030128
Iter: 171 loss: 0.0211060829
Iter: 172 loss: 0.0209345296
Iter: 173 loss: 0.0206665602
Iter: 174 loss: 0.0204848759
Iter: 175 loss: 0.0203963853
Iter: 176 loss: 0.0201115608
Iter: 177 loss: 0.0201110225
Iter: 178 loss: 0.0197233409
Iter: 179 loss: 0.0236634314
Iter: 180 loss: 0.0197052173
Iter: 181 loss: 0.0196200758
Iter: 182 loss: 0.019626718
Iter: 183 loss: 0.0195538271
Iter: 184 loss: 0.01942119
Iter: 185 loss: 0.0194155499
Iter: 186 loss: 0.0193135124
Iter: 187 loss: 0.0191822089
Iter: 188 loss: 0.01927476
Iter: 189 loss: 0.0191039499
Iter: 190 loss: 0.0188475586
Iter: 191 loss: 0.0185379535
Iter: 192 loss: 0.0185111687
Iter: 193 loss: 0.0183101073
Iter: 194 loss: 0.0197341964
Iter: 195 loss: 0.018283695
Iter: 196 loss: 0.0181763135
Iter: 197 loss: 0.0191121828
Iter: 198 loss: 0.0181714594
Iter: 199 loss: 0.0181095861
Iter: 200 loss: 0.0180494972
Iter: 201 loss: 0.0179313794
Iter: 202 loss: 0.0178063251
Iter: 203 loss: 0.017787151
Iter: 204 loss: 0.0176618863
Iter: 205 loss: 0.0177808814
Iter: 206 loss: 0.0175946243
Iter: 207 loss: 0.0175139084
Iter: 208 loss: 0.0174981523
Iter: 209 loss: 0.0174394976
Iter: 210 loss: 0.0176873412
Iter: 211 loss: 0.0174265318
Iter: 212 loss: 0.0173616484
Iter: 213 loss: 0.0173040107
Iter: 214 loss: 0.0171604641
Iter: 215 loss: 0.0171245337
Iter: 216 loss: 0.0170323104
Iter: 217 loss: 0.016825052
Iter: 218 loss: 0.0169404894
Iter: 219 loss: 0.0166869108
Iter: 220 loss: 0.0165082794
Iter: 221 loss: 0.016642198
Iter: 222 loss: 0.016405398
Iter: 223 loss: 0.0161194839
Iter: 224 loss: 0.0164265558
Iter: 225 loss: 0.0159504
Iter: 226 loss: 0.0157153383
Iter: 227 loss: 0.0157111287
Iter: 228 loss: 0.0156715363
Iter: 229 loss: 0.0156991687
Iter: 230 loss: 0.0156462509
Iter: 231 loss: 0.0154307522
Iter: 232 loss: 0.0158701427
Iter: 233 loss: 0.0153441783
Iter: 234 loss: 0.0151909143
Iter: 235 loss: 0.0151649835
Iter: 236 loss: 0.0150684416
Iter: 237 loss: 0.0150052747
Iter: 238 loss: 0.0149705764
Iter: 239 loss: 0.0148621788
Iter: 240 loss: 0.0148977078
Iter: 241 loss: 0.0147828748
Iter: 242 loss: 0.0147212949
Iter: 243 loss: 0.0147114974
Iter: 244 loss: 0.0146685652
Iter: 245 loss: 0.0145711955
Iter: 246 loss: 0.0147022773
Iter: 247 loss: 0.0145211732
Iter: 248 loss: 0.0145096295
Iter: 249 loss: 0.0144449156
Iter: 250 loss: 0.0143545428
Iter: 251 loss: 0.0142970933
Iter: 252 loss: 0.0142581789
Iter: 253 loss: 0.0141084921
Iter: 254 loss: 0.0141511671
Iter: 255 loss: 0.0140057616
Iter: 256 loss: 0.0139496475
Iter: 257 loss: 0.0139459912
Iter: 258 loss: 0.0138768479
Iter: 259 loss: 0.0139006749
Iter: 260 loss: 0.0138275754
Iter: 261 loss: 0.0137659647
Iter: 262 loss: 0.0138831446
Iter: 263 loss: 0.0137391444
Iter: 264 loss: 0.0135537861
Iter: 265 loss: 0.0136991553
Iter: 266 loss: 0.0134396646
Iter: 267 loss: 0.0133459764
Iter: 268 loss: 0.0133247785
Iter: 269 loss: 0.0132527547
Iter: 270 loss: 0.0131355058
Iter: 271 loss: 0.0131343482
Iter: 272 loss: 0.0129544185
Iter: 273 loss: 0.0126862
Iter: 274 loss: 0.012680009
Iter: 275 loss: 0.0125361821
Iter: 276 loss: 0.013268155
Iter: 277 loss: 0.0125098629
Iter: 278 loss: 0.0124743348
Iter: 279 loss: 0.0129373381
Iter: 280 loss: 0.0124741085
Iter: 281 loss: 0.0124424761
Iter: 282 loss: 0.0124463355
Iter: 283 loss: 0.0124182086
Iter: 284 loss: 0.012337273
Iter: 285 loss: 0.0124928392
Iter: 286 loss: 0.0123065412
Iter: 287 loss: 0.0123330569
Iter: 288 loss: 0.012275327
Iter: 289 loss: 0.0122511312
Iter: 290 loss: 0.0122428918
Iter: 291 loss: 0.0122288372
Iter: 292 loss: 0.0121333897
Iter: 293 loss: 0.0121136978
Iter: 294 loss: 0.0120523889
Iter: 295 loss: 0.0119622955
Iter: 296 loss: 0.0119682932
Iter: 297 loss: 0.0118971691
Iter: 298 loss: 0.0117953345
Iter: 299 loss: 0.0116168819
Iter: 300 loss: 0.0116168661
Iter: 301 loss: 0.0114372168
Iter: 302 loss: 0.0133847287
Iter: 303 loss: 0.0114342123
Iter: 304 loss: 0.0113301342
Iter: 305 loss: 0.0114009948
Iter: 306 loss: 0.0112683773
Iter: 307 loss: 0.0111920657
Iter: 308 loss: 0.0111919902
Iter: 309 loss: 0.0111302873
Iter: 310 loss: 0.0111249601
Iter: 311 loss: 0.011099631
Iter: 312 loss: 0.0111128446
Iter: 313 loss: 0.0110825114
Iter: 314 loss: 0.0110474899
Iter: 315 loss: 0.011010699
Iter: 316 loss: 0.0110041397
Iter: 317 loss: 0.0108731408
Iter: 318 loss: 0.0113830091
Iter: 319 loss: 0.0108406991
Iter: 320 loss: 0.0106957015
Iter: 321 loss: 0.0116414428
Iter: 322 loss: 0.0106769139
Iter: 323 loss: 0.0107742185
Iter: 324 loss: 0.0105717396
Iter: 325 loss: 0.010480728
Iter: 326 loss: 0.0104508679
Iter: 327 loss: 0.0103959944
Iter: 328 loss: 0.0102631766
Iter: 329 loss: 0.0107364198
Iter: 330 loss: 0.0102311876
Iter: 331 loss: 0.0102246096
Iter: 332 loss: 0.0101181818
Iter: 333 loss: 0.0100926813
Iter: 334 loss: 0.0101582399
Iter: 335 loss: 0.0100836512
Iter: 336 loss: 0.0100703742
Iter: 337 loss: 0.0100409705
Iter: 338 loss: 0.0104296915
Iter: 339 loss: 0.0100393649
Iter: 340 loss: 0.010027878
Iter: 341 loss: 0.00999956392
Iter: 342 loss: 0.00991491415
Iter: 343 loss: 0.00998048298
Iter: 344 loss: 0.0098626595
Iter: 345 loss: 0.00976639707
Iter: 346 loss: 0.0109574804
Iter: 347 loss: 0.00976553652
Iter: 348 loss: 0.00969225913
Iter: 349 loss: 0.0102036353
Iter: 350 loss: 0.00968385767
Iter: 351 loss: 0.00962039363
Iter: 352 loss: 0.00969304051
Iter: 353 loss: 0.00958587602
Iter: 354 loss: 0.00950847287
Iter: 355 loss: 0.00966995
Iter: 356 loss: 0.00947926845
Iter: 357 loss: 0.00940210465
Iter: 358 loss: 0.010205132
Iter: 359 loss: 0.00940003432
Iter: 360 loss: 0.00936145708
Iter: 361 loss: 0.00946160592
Iter: 362 loss: 0.00934782065
Iter: 363 loss: 0.00933624897
Iter: 364 loss: 0.00931677222
Iter: 365 loss: 0.00931672566
Iter: 366 loss: 0.00934735
Iter: 367 loss: 0.00929174479
Iter: 368 loss: 0.00923478883
Iter: 369 loss: 0.00924397819
Iter: 370 loss: 0.00919152796
Iter: 371 loss: 0.00915526412
Iter: 372 loss: 0.00917235762
Iter: 373 loss: 0.00913080946
Iter: 374 loss: 0.00909065455
Iter: 375 loss: 0.00958072394
Iter: 376 loss: 0.00908983313
Iter: 377 loss: 0.00904220529
Iter: 378 loss: 0.00904582348
Iter: 379 loss: 0.00900495425
Iter: 380 loss: 0.00892170332
Iter: 381 loss: 0.0088773733
Iter: 382 loss: 0.00883979909
Iter: 383 loss: 0.00875490345
Iter: 384 loss: 0.00875349902
Iter: 385 loss: 0.00869744644
Iter: 386 loss: 0.00873724371
Iter: 387 loss: 0.00866081286
Iter: 388 loss: 0.00865933392
Iter: 389 loss: 0.00861816201
Iter: 390 loss: 0.00858873874
Iter: 391 loss: 0.00872535817
Iter: 392 loss: 0.00858244672
Iter: 393 loss: 0.0085692443
Iter: 394 loss: 0.00853402447
Iter: 395 loss: 0.00879829377
Iter: 396 loss: 0.00852634758
Iter: 397 loss: 0.0084056817
Iter: 398 loss: 0.00840934552
Iter: 399 loss: 0.00831186399
Iter: 400 loss: 0.00840742327
Iter: 401 loss: 0.00827817153
Iter: 402 loss: 0.00825385377
Iter: 403 loss: 0.0082273148
Iter: 404 loss: 0.0082231788
Iter: 405 loss: 0.00817515142
Iter: 406 loss: 0.00843490101
Iter: 407 loss: 0.00816765521
Iter: 408 loss: 0.00811379
Iter: 409 loss: 0.00826037303
Iter: 410 loss: 0.0080949273
Iter: 411 loss: 0.00807217881
Iter: 412 loss: 0.00806131586
Iter: 413 loss: 0.00805028249
Iter: 414 loss: 0.00800192077
Iter: 415 loss: 0.00862081908
Iter: 416 loss: 0.0080012735
Iter: 417 loss: 0.00793546066
Iter: 418 loss: 0.00792772882
Iter: 419 loss: 0.00787971728
Iter: 420 loss: 0.00782167539
Iter: 421 loss: 0.0079316292
Iter: 422 loss: 0.00779618463
Iter: 423 loss: 0.00780000631
Iter: 424 loss: 0.00778094586
Iter: 425 loss: 0.00775705837
Iter: 426 loss: 0.00771249272
Iter: 427 loss: 0.00865010265
Iter: 428 loss: 0.00771236466
Iter: 429 loss: 0.00767071685
Iter: 430 loss: 0.007617909
Iter: 431 loss: 0.00761456694
Iter: 432 loss: 0.00752449
Iter: 433 loss: 0.0078562079
Iter: 434 loss: 0.00750152534
Iter: 435 loss: 0.00753206
Iter: 436 loss: 0.00747076329
Iter: 437 loss: 0.00745127629
Iter: 438 loss: 0.00745378248
Iter: 439 loss: 0.00743669551
Iter: 440 loss: 0.00740816537
Iter: 441 loss: 0.0074076
Iter: 442 loss: 0.00738525763
Iter: 443 loss: 0.00736084674
Iter: 444 loss: 0.00737941638
Iter: 445 loss: 0.00734561356
Iter: 446 loss: 0.00733161485
Iter: 447 loss: 0.00730811339
Iter: 448 loss: 0.00730808172
Iter: 449 loss: 0.00725715095
Iter: 450 loss: 0.00720176147
Iter: 451 loss: 0.00719327619
Iter: 452 loss: 0.0071429
Iter: 453 loss: 0.00707101449
Iter: 454 loss: 0.00706862658
Iter: 455 loss: 0.00760060688
Iter: 456 loss: 0.00703758374
Iter: 457 loss: 0.00698601408
Iter: 458 loss: 0.00707252696
Iter: 459 loss: 0.0069631706
Iter: 460 loss: 0.00694680819
Iter: 461 loss: 0.00698460825
Iter: 462 loss: 0.00694044773
Iter: 463 loss: 0.00687678531
Iter: 464 loss: 0.00731777772
Iter: 465 loss: 0.00687149446
Iter: 466 loss: 0.0067855604
Iter: 467 loss: 0.00678555202
Iter: 468 loss: 0.00678514084
Iter: 469 loss: 0.00676729437
Iter: 470 loss: 0.00675540371
Iter: 471 loss: 0.00679704268
Iter: 472 loss: 0.00675223395
Iter: 473 loss: 0.00674370583
Iter: 474 loss: 0.00674193865
Iter: 475 loss: 0.00673637725
Iter: 476 loss: 0.00671939645
Iter: 477 loss: 0.00667737145
Iter: 478 loss: 0.00711798202
Iter: 479 loss: 0.00667209737
Iter: 480 loss: 0.00663773669
Iter: 481 loss: 0.00689876731
Iter: 482 loss: 0.00663485425
Iter: 483 loss: 0.00659802323
Iter: 484 loss: 0.00690280832
Iter: 485 loss: 0.00659607816
Iter: 486 loss: 0.00664226711
Iter: 487 loss: 0.0065844534
Iter: 488 loss: 0.00657571945
Iter: 489 loss: 0.00658837333
Iter: 490 loss: 0.00657139253
Iter: 491 loss: 0.00656329
Iter: 492 loss: 0.00654218346
Iter: 493 loss: 0.00671423413
Iter: 494 loss: 0.00653823139
Iter: 495 loss: 0.00651416881
Iter: 496 loss: 0.0065134
Iter: 497 loss: 0.00649955869
Iter: 498 loss: 0.00651016
Iter: 499 loss: 0.00649112742
Iter: 500 loss: 0.00646198634
Iter: 501 loss: 0.00641467841
Iter: 502 loss: 0.00641436968
Iter: 503 loss: 0.00639189221
Iter: 504 loss: 0.00638901256
Iter: 505 loss: 0.00637030415
Iter: 506 loss: 0.00644771196
Iter: 507 loss: 0.00636639446
Iter: 508 loss: 0.00634215958
Iter: 509 loss: 0.00633717701
Iter: 510 loss: 0.00631486299
Iter: 511 loss: 0.00632682908
Iter: 512 loss: 0.00630054437
Iter: 513 loss: 0.00629091635
Iter: 514 loss: 0.00630731788
Iter: 515 loss: 0.00628653914
Iter: 516 loss: 0.00627903175
Iter: 517 loss: 0.00625704089
Iter: 518 loss: 0.00634078123
Iter: 519 loss: 0.00624779938
Iter: 520 loss: 0.00649005454
Iter: 521 loss: 0.00623992831
Iter: 522 loss: 0.00623175688
Iter: 523 loss: 0.00624936819
Iter: 524 loss: 0.00622850563
Iter: 525 loss: 0.00622003572
Iter: 526 loss: 0.00621608272
Iter: 527 loss: 0.00621194625
Iter: 528 loss: 0.00619017193
Iter: 529 loss: 0.00618955074
Iter: 530 loss: 0.00616575871
Iter: 531 loss: 0.00611894578
Iter: 532 loss: 0.00710547715
Iter: 533 loss: 0.00611854531
Iter: 534 loss: 0.00612182822
Iter: 535 loss: 0.00610613218
Iter: 536 loss: 0.00607662834
Iter: 537 loss: 0.00610904954
Iter: 538 loss: 0.00605997164
Iter: 539 loss: 0.00603094883
Iter: 540 loss: 0.00605188962
Iter: 541 loss: 0.00601303484
Iter: 542 loss: 0.00599523541
Iter: 543 loss: 0.005993044
Iter: 544 loss: 0.00596686639
Iter: 545 loss: 0.00612977846
Iter: 546 loss: 0.0059639411
Iter: 547 loss: 0.00594499893
Iter: 548 loss: 0.00596983358
Iter: 549 loss: 0.00593494345
Iter: 550 loss: 0.00592270959
Iter: 551 loss: 0.00603520218
Iter: 552 loss: 0.00592212239
Iter: 553 loss: 0.00591408927
Iter: 554 loss: 0.00591032952
Iter: 555 loss: 0.00590653578
Iter: 556 loss: 0.00589322485
Iter: 557 loss: 0.00587117486
Iter: 558 loss: 0.00586959627
Iter: 559 loss: 0.00582721
Iter: 560 loss: 0.00581990974
Iter: 561 loss: 0.00575176347
Iter: 562 loss: 0.00598877948
Iter: 563 loss: 0.00573267415
Iter: 564 loss: 0.00570411049
Iter: 565 loss: 0.00565526541
Iter: 566 loss: 0.00565518
Iter: 567 loss: 0.00562681071
Iter: 568 loss: 0.00562529173
Iter: 569 loss: 0.00561627932
Iter: 570 loss: 0.00561952824
Iter: 571 loss: 0.00560995471
Iter: 572 loss: 0.00559234712
Iter: 573 loss: 0.00557315489
Iter: 574 loss: 0.00557007035
Iter: 575 loss: 0.0055582365
Iter: 576 loss: 0.00569536863
Iter: 577 loss: 0.00555806793
Iter: 578 loss: 0.00555197615
Iter: 579 loss: 0.00554103591
Iter: 580 loss: 0.00582439359
Iter: 581 loss: 0.00554102939
Iter: 582 loss: 0.00553046027
Iter: 583 loss: 0.00567493122
Iter: 584 loss: 0.00553046446
Iter: 585 loss: 0.00551776355
Iter: 586 loss: 0.00550087634
Iter: 587 loss: 0.00549990358
Iter: 588 loss: 0.00549166277
Iter: 589 loss: 0.00551665667
Iter: 590 loss: 0.00548918452
Iter: 591 loss: 0.00548202591
Iter: 592 loss: 0.00547958445
Iter: 593 loss: 0.00547545496
Iter: 594 loss: 0.00546380086
Iter: 595 loss: 0.00545263197
Iter: 596 loss: 0.00545012858
Iter: 597 loss: 0.00541757606
Iter: 598 loss: 0.005495633
Iter: 599 loss: 0.00540549308
Iter: 600 loss: 0.00537231471
Iter: 601 loss: 0.00577785913
Iter: 602 loss: 0.00537193846
Iter: 603 loss: 0.00535365101
Iter: 604 loss: 0.00553837419
Iter: 605 loss: 0.00535321143
Iter: 606 loss: 0.00534543255
Iter: 607 loss: 0.00532862032
Iter: 608 loss: 0.00562474318
Iter: 609 loss: 0.00532809505
Iter: 610 loss: 0.00530835707
Iter: 611 loss: 0.00538860727
Iter: 612 loss: 0.00530411163
Iter: 613 loss: 0.00529098278
Iter: 614 loss: 0.00537427375
Iter: 615 loss: 0.00528934598
Iter: 616 loss: 0.00528316107
Iter: 617 loss: 0.00527465623
Iter: 618 loss: 0.0052742688
Iter: 619 loss: 0.00537061412
Iter: 620 loss: 0.00526761264
Iter: 621 loss: 0.00526257697
Iter: 622 loss: 0.00527130533
Iter: 623 loss: 0.00526041817
Iter: 624 loss: 0.00525665283
Iter: 625 loss: 0.00524977967
Iter: 626 loss: 0.00541689526
Iter: 627 loss: 0.00524977362
Iter: 628 loss: 0.00518338615
Iter: 629 loss: 0.00583595736
Iter: 630 loss: 0.00518083759
Iter: 631 loss: 0.00512557849
Iter: 632 loss: 0.00518274866
Iter: 633 loss: 0.00509612868
Iter: 634 loss: 0.00506188627
Iter: 635 loss: 0.00534896925
Iter: 636 loss: 0.00506021827
Iter: 637 loss: 0.00502761919
Iter: 638 loss: 0.00508289365
Iter: 639 loss: 0.00501215365
Iter: 640 loss: 0.00499752443
Iter: 641 loss: 0.00514389854
Iter: 642 loss: 0.00499704294
Iter: 643 loss: 0.0051403977
Iter: 644 loss: 0.00499186711
Iter: 645 loss: 0.00498819072
Iter: 646 loss: 0.00497995224
Iter: 647 loss: 0.00509749399
Iter: 648 loss: 0.00497948751
Iter: 649 loss: 0.00497604115
Iter: 650 loss: 0.0049835369
Iter: 651 loss: 0.00497472472
Iter: 652 loss: 0.00497252773
Iter: 653 loss: 0.00496565318
Iter: 654 loss: 0.00497489888
Iter: 655 loss: 0.00496065151
Iter: 656 loss: 0.00529068615
Iter: 657 loss: 0.00495419279
Iter: 658 loss: 0.00494845584
Iter: 659 loss: 0.00493626762
Iter: 660 loss: 0.00512839947
Iter: 661 loss: 0.00493586063
Iter: 662 loss: 0.00489686662
Iter: 663 loss: 0.00496321591
Iter: 664 loss: 0.00487907976
Iter: 665 loss: 0.00484702084
Iter: 666 loss: 0.0048094755
Iter: 667 loss: 0.00480506569
Iter: 668 loss: 0.00478040799
Iter: 669 loss: 0.00472926581
Iter: 670 loss: 0.00560450507
Iter: 671 loss: 0.00472809747
Iter: 672 loss: 0.00469049253
Iter: 673 loss: 0.00498180604
Iter: 674 loss: 0.00468845945
Iter: 675 loss: 0.00466097705
Iter: 676 loss: 0.00481402595
Iter: 677 loss: 0.00465662917
Iter: 678 loss: 0.00463871704
Iter: 679 loss: 0.00460620364
Iter: 680 loss: 0.00534333382
Iter: 681 loss: 0.00460626185
Iter: 682 loss: 0.00460117357
Iter: 683 loss: 0.004594584
Iter: 684 loss: 0.00458449312
Iter: 685 loss: 0.00459518703
Iter: 686 loss: 0.00457901834
Iter: 687 loss: 0.0045677172
Iter: 688 loss: 0.00456782244
Iter: 689 loss: 0.00455878302
Iter: 690 loss: 0.00454836432
Iter: 691 loss: 0.00454833545
Iter: 692 loss: 0.00454556663
Iter: 693 loss: 0.00455105258
Iter: 694 loss: 0.00454440759
Iter: 695 loss: 0.00453855144
Iter: 696 loss: 0.00452721911
Iter: 697 loss: 0.00477037719
Iter: 698 loss: 0.00452716369
Iter: 699 loss: 0.00450788578
Iter: 700 loss: 0.00450995611
Iter: 701 loss: 0.00449276
Iter: 702 loss: 0.00446878513
Iter: 703 loss: 0.00448516477
Iter: 704 loss: 0.00445334567
Iter: 705 loss: 0.00444282312
Iter: 706 loss: 0.00441597868
Iter: 707 loss: 0.00464261603
Iter: 708 loss: 0.00441150181
Iter: 709 loss: 0.00439062668
Iter: 710 loss: 0.00441413652
Iter: 711 loss: 0.0043798741
Iter: 712 loss: 0.00436894922
Iter: 713 loss: 0.00436190749
Iter: 714 loss: 0.00435762759
Iter: 715 loss: 0.00437007472
Iter: 716 loss: 0.00434982637
Iter: 717 loss: 0.0043449509
Iter: 718 loss: 0.00435174769
Iter: 719 loss: 0.00434254156
Iter: 720 loss: 0.00440811459
Iter: 721 loss: 0.00433808425
Iter: 722 loss: 0.00433359761
Iter: 723 loss: 0.00435144547
Iter: 724 loss: 0.00433257408
Iter: 725 loss: 0.00432914589
Iter: 726 loss: 0.00432364503
Iter: 727 loss: 0.00432360312
Iter: 728 loss: 0.00430531148
Iter: 729 loss: 0.00428069336
Iter: 730 loss: 0.00427941605
Iter: 731 loss: 0.0042651454
Iter: 732 loss: 0.00429054536
Iter: 733 loss: 0.00425901962
Iter: 734 loss: 0.00424960209
Iter: 735 loss: 0.00422631484
Iter: 736 loss: 0.0044484688
Iter: 737 loss: 0.00422323914
Iter: 738 loss: 0.00419592392
Iter: 739 loss: 0.00423302
Iter: 740 loss: 0.00418271776
Iter: 741 loss: 0.00415733922
Iter: 742 loss: 0.00426720828
Iter: 743 loss: 0.00415216386
Iter: 744 loss: 0.0041689272
Iter: 745 loss: 0.00413259352
Iter: 746 loss: 0.00412213895
Iter: 747 loss: 0.00418161415
Iter: 748 loss: 0.00412079878
Iter: 749 loss: 0.0041149389
Iter: 750 loss: 0.00411094539
Iter: 751 loss: 0.00410878705
Iter: 752 loss: 0.00409291964
Iter: 753 loss: 0.0041390555
Iter: 754 loss: 0.00408791099
Iter: 755 loss: 0.00407290645
Iter: 756 loss: 0.00414982624
Iter: 757 loss: 0.00407041889
Iter: 758 loss: 0.00405493099
Iter: 759 loss: 0.00405433169
Iter: 760 loss: 0.00404880708
Iter: 761 loss: 0.00404209737
Iter: 762 loss: 0.00404149201
Iter: 763 loss: 0.00402936805
Iter: 764 loss: 0.0040767272
Iter: 765 loss: 0.00402671518
Iter: 766 loss: 0.00401854794
Iter: 767 loss: 0.0040200334
Iter: 768 loss: 0.00401252881
Iter: 769 loss: 0.00400477
Iter: 770 loss: 0.00399694638
Iter: 771 loss: 0.00399537664
Iter: 772 loss: 0.00397760887
Iter: 773 loss: 0.00399888307
Iter: 774 loss: 0.00396842603
Iter: 775 loss: 0.00396102108
Iter: 776 loss: 0.00395532092
Iter: 777 loss: 0.00395298935
Iter: 778 loss: 0.00395158073
Iter: 779 loss: 0.00394835882
Iter: 780 loss: 0.00394567568
Iter: 781 loss: 0.00395020563
Iter: 782 loss: 0.00394444354
Iter: 783 loss: 0.00393811893
Iter: 784 loss: 0.00392898824
Iter: 785 loss: 0.00392871816
Iter: 786 loss: 0.0039119
Iter: 787 loss: 0.00390072423
Iter: 788 loss: 0.00389429182
Iter: 789 loss: 0.0038868594
Iter: 790 loss: 0.00388684636
Iter: 791 loss: 0.00387791451
Iter: 792 loss: 0.00386657752
Iter: 793 loss: 0.00386568392
Iter: 794 loss: 0.00385528849
Iter: 795 loss: 0.00384077453
Iter: 796 loss: 0.00384019013
Iter: 797 loss: 0.00381965889
Iter: 798 loss: 0.00385549478
Iter: 799 loss: 0.00381047558
Iter: 800 loss: 0.00379365147
Iter: 801 loss: 0.00377532234
Iter: 802 loss: 0.00377247436
Iter: 803 loss: 0.00373931252
Iter: 804 loss: 0.00373923825
Iter: 805 loss: 0.00372194406
Iter: 806 loss: 0.00382694928
Iter: 807 loss: 0.00371992844
Iter: 808 loss: 0.00371197378
Iter: 809 loss: 0.00371192303
Iter: 810 loss: 0.00370493298
Iter: 811 loss: 0.00371141289
Iter: 812 loss: 0.00370093528
Iter: 813 loss: 0.00368952239
Iter: 814 loss: 0.0036769
Iter: 815 loss: 0.00367499981
Iter: 816 loss: 0.00365556125
Iter: 817 loss: 0.00371719827
Iter: 818 loss: 0.00364989601
Iter: 819 loss: 0.00364793651
Iter: 820 loss: 0.00364610134
Iter: 821 loss: 0.00364315533
Iter: 822 loss: 0.00364930648
Iter: 823 loss: 0.00364198163
Iter: 824 loss: 0.00363921025
Iter: 825 loss: 0.00363212847
Iter: 826 loss: 0.00369179831
Iter: 827 loss: 0.0036309706
Iter: 828 loss: 0.00362057751
Iter: 829 loss: 0.00361107499
Iter: 830 loss: 0.00360858091
Iter: 831 loss: 0.00368421408
Iter: 832 loss: 0.00359698106
Iter: 833 loss: 0.0035864776
Iter: 834 loss: 0.00363303348
Iter: 835 loss: 0.00358432531
Iter: 836 loss: 0.00357985566
Iter: 837 loss: 0.00357959955
Iter: 838 loss: 0.0035765646
Iter: 839 loss: 0.00359778805
Iter: 840 loss: 0.00357626425
Iter: 841 loss: 0.00357261556
Iter: 842 loss: 0.00356644089
Iter: 843 loss: 0.00356642809
Iter: 844 loss: 0.0035583768
Iter: 845 loss: 0.00354785146
Iter: 846 loss: 0.003547217
Iter: 847 loss: 0.00354096945
Iter: 848 loss: 0.00355658471
Iter: 849 loss: 0.00353884511
Iter: 850 loss: 0.00353548652
Iter: 851 loss: 0.00352630438
Iter: 852 loss: 0.00358134648
Iter: 853 loss: 0.00352377957
Iter: 854 loss: 0.00351506332
Iter: 855 loss: 0.00351393013
Iter: 856 loss: 0.00350081641
Iter: 857 loss: 0.00356366439
Iter: 858 loss: 0.00349846319
Iter: 859 loss: 0.00349490345
Iter: 860 loss: 0.00348680164
Iter: 861 loss: 0.00359247741
Iter: 862 loss: 0.00348629174
Iter: 863 loss: 0.0034692015
Iter: 864 loss: 0.00353000686
Iter: 865 loss: 0.00346459611
Iter: 866 loss: 0.00344295753
Iter: 867 loss: 0.00352441613
Iter: 868 loss: 0.00343768392
Iter: 869 loss: 0.00342541235
Iter: 870 loss: 0.00361602241
Iter: 871 loss: 0.00342542212
Iter: 872 loss: 0.00341930147
Iter: 873 loss: 0.00347476709
Iter: 874 loss: 0.00341904932
Iter: 875 loss: 0.00341705466
Iter: 876 loss: 0.00341312424
Iter: 877 loss: 0.00349538773
Iter: 878 loss: 0.00341312494
Iter: 879 loss: 0.0034089468
Iter: 880 loss: 0.00339593715
Iter: 881 loss: 0.00342299906
Iter: 882 loss: 0.00338755455
Iter: 883 loss: 0.00336920773
Iter: 884 loss: 0.00361986412
Iter: 885 loss: 0.00336913788
Iter: 886 loss: 0.00335588609
Iter: 887 loss: 0.00335469609
Iter: 888 loss: 0.00334930373
Iter: 889 loss: 0.00334041519
Iter: 890 loss: 0.00334036024
Iter: 891 loss: 0.00340299169
Iter: 892 loss: 0.00333806616
Iter: 893 loss: 0.00333676348
Iter: 894 loss: 0.00333823706
Iter: 895 loss: 0.00333605194
Iter: 896 loss: 0.0033314731
Iter: 897 loss: 0.00332705164
Iter: 898 loss: 0.00332602393
Iter: 899 loss: 0.00331739313
Iter: 900 loss: 0.00330193969
Iter: 901 loss: 0.00369741255
Iter: 902 loss: 0.00330195623
Iter: 903 loss: 0.00328724738
Iter: 904 loss: 0.00336627383
Iter: 905 loss: 0.00328509603
Iter: 906 loss: 0.00340433465
Iter: 907 loss: 0.00328287645
Iter: 908 loss: 0.00328130717
Iter: 909 loss: 0.00327813509
Iter: 910 loss: 0.00334064639
Iter: 911 loss: 0.00327809784
Iter: 912 loss: 0.00327426288
Iter: 913 loss: 0.00327321072
Iter: 914 loss: 0.00327087985
Iter: 915 loss: 0.00326740067
Iter: 916 loss: 0.00325902575
Iter: 917 loss: 0.00335907517
Iter: 918 loss: 0.00325818872
Iter: 919 loss: 0.00325292861
Iter: 920 loss: 0.00325248134
Iter: 921 loss: 0.00324813323
Iter: 922 loss: 0.00325719663
Iter: 923 loss: 0.00324642938
Iter: 924 loss: 0.00324412086
Iter: 925 loss: 0.00325646275
Iter: 926 loss: 0.00324378186
Iter: 927 loss: 0.00323819602
Iter: 928 loss: 0.00325233978
Iter: 929 loss: 0.0032362123
Iter: 930 loss: 0.00322689814
Iter: 931 loss: 0.00321990647
Iter: 932 loss: 0.00321686803
Iter: 933 loss: 0.0032073406
Iter: 934 loss: 0.00319682318
Iter: 935 loss: 0.00319532678
Iter: 936 loss: 0.0031915328
Iter: 937 loss: 0.0031875167
Iter: 938 loss: 0.00318681216
Iter: 939 loss: 0.00318134157
Iter: 940 loss: 0.00317287631
Iter: 941 loss: 0.00317274593
Iter: 942 loss: 0.00316806301
Iter: 943 loss: 0.0031907137
Iter: 944 loss: 0.00316721038
Iter: 945 loss: 0.00316404924
Iter: 946 loss: 0.00319101708
Iter: 947 loss: 0.0031638972
Iter: 948 loss: 0.00316055235
Iter: 949 loss: 0.00315750972
Iter: 950 loss: 0.00315666338
Iter: 951 loss: 0.00315026566
Iter: 952 loss: 0.00314507866
Iter: 953 loss: 0.00314319134
Iter: 954 loss: 0.00312927505
Iter: 955 loss: 0.00322440779
Iter: 956 loss: 0.00312794
Iter: 957 loss: 0.0031121762
Iter: 958 loss: 0.00313952449
Iter: 959 loss: 0.00310525019
Iter: 960 loss: 0.00309638213
Iter: 961 loss: 0.00307932636
Iter: 962 loss: 0.00344186695
Iter: 963 loss: 0.00307921087
Iter: 964 loss: 0.00306688715
Iter: 965 loss: 0.00322211441
Iter: 966 loss: 0.00306673674
Iter: 967 loss: 0.00306020956
Iter: 968 loss: 0.00308142323
Iter: 969 loss: 0.00305836555
Iter: 970 loss: 0.00304798409
Iter: 971 loss: 0.00320159225
Iter: 972 loss: 0.00304796593
Iter: 973 loss: 0.00304008531
Iter: 974 loss: 0.00303972792
Iter: 975 loss: 0.00303741824
Iter: 976 loss: 0.0030331458
Iter: 977 loss: 0.00313103292
Iter: 978 loss: 0.00303314603
Iter: 979 loss: 0.00302674412
Iter: 980 loss: 0.00305911433
Iter: 981 loss: 0.00302570127
Iter: 982 loss: 0.00301969331
Iter: 983 loss: 0.00305751571
Iter: 984 loss: 0.00301896804
Iter: 985 loss: 0.00301629258
Iter: 986 loss: 0.00301037286
Iter: 987 loss: 0.00309311366
Iter: 988 loss: 0.0030100483
Iter: 989 loss: 0.00300104823
Iter: 990 loss: 0.00310449814
Iter: 991 loss: 0.00300088525
Iter: 992 loss: 0.00298942393
Iter: 993 loss: 0.0030029926
Iter: 994 loss: 0.00298327883
Iter: 995 loss: 0.00297440588
Iter: 996 loss: 0.00296905148
Iter: 997 loss: 0.00296536693
Iter: 998 loss: 0.00294266199
Iter: 999 loss: 0.00314102788
Iter: 1000 loss: 0.00294146943
Iter: 1001 loss: 0.00294834282
Iter: 1002 loss: 0.0029397551
Iter: 1003 loss: 0.00293889455
Iter: 1004 loss: 0.00293753762
Iter: 1005 loss: 0.00293753669
Iter: 1006 loss: 0.00293486612
Iter: 1007 loss: 0.00292740809
Iter: 1008 loss: 0.00296684587
Iter: 1009 loss: 0.00292502902
Iter: 1010 loss: 0.00292180572
Iter: 1011 loss: 0.0029501277
Iter: 1012 loss: 0.00292162923
Iter: 1013 loss: 0.00291929254
Iter: 1014 loss: 0.00291823735
Iter: 1015 loss: 0.0029170583
Iter: 1016 loss: 0.00290366821
Iter: 1017 loss: 0.00293081859
Iter: 1018 loss: 0.00289819483
Iter: 1019 loss: 0.00289248093
Iter: 1020 loss: 0.00288874
Iter: 1021 loss: 0.00288135
Iter: 1022 loss: 0.00287243864
Iter: 1023 loss: 0.0028715306
Iter: 1024 loss: 0.00286217616
Iter: 1025 loss: 0.00291695306
Iter: 1026 loss: 0.0028609531
Iter: 1027 loss: 0.00285126828
Iter: 1028 loss: 0.00285081565
Iter: 1029 loss: 0.00284092
Iter: 1030 loss: 0.00285359332
Iter: 1031 loss: 0.00283580902
Iter: 1032 loss: 0.00284002838
Iter: 1033 loss: 0.00283232913
Iter: 1034 loss: 0.00283087557
Iter: 1035 loss: 0.00282683875
Iter: 1036 loss: 0.00284981215
Iter: 1037 loss: 0.00282566668
Iter: 1038 loss: 0.00292116543
Iter: 1039 loss: 0.00282125967
Iter: 1040 loss: 0.00281474344
Iter: 1041 loss: 0.00283998391
Iter: 1042 loss: 0.00281325751
Iter: 1043 loss: 0.00281135086
Iter: 1044 loss: 0.00280446629
Iter: 1045 loss: 0.00278908829
Iter: 1046 loss: 0.00278908154
Iter: 1047 loss: 0.00278387032
Iter: 1048 loss: 0.00277712382
Iter: 1049 loss: 0.00276733749
Iter: 1050 loss: 0.00282293279
Iter: 1051 loss: 0.00276598847
Iter: 1052 loss: 0.00276230136
Iter: 1053 loss: 0.00275535369
Iter: 1054 loss: 0.00290000066
Iter: 1055 loss: 0.00275532808
Iter: 1056 loss: 0.00274480879
Iter: 1057 loss: 0.00274887821
Iter: 1058 loss: 0.00273740664
Iter: 1059 loss: 0.00272632111
Iter: 1060 loss: 0.00280303461
Iter: 1061 loss: 0.00272533903
Iter: 1062 loss: 0.00272076856
Iter: 1063 loss: 0.0027144677
Iter: 1064 loss: 0.0027141613
Iter: 1065 loss: 0.00270207133
Iter: 1066 loss: 0.0026848237
Iter: 1067 loss: 0.00268424046
Iter: 1068 loss: 0.00273785135
Iter: 1069 loss: 0.00267888559
Iter: 1070 loss: 0.00267684553
Iter: 1071 loss: 0.00267201709
Iter: 1072 loss: 0.00273034978
Iter: 1073 loss: 0.00267157657
Iter: 1074 loss: 0.00269387872
Iter: 1075 loss: 0.00266795326
Iter: 1076 loss: 0.00266398839
Iter: 1077 loss: 0.00268429471
Iter: 1078 loss: 0.00266337255
Iter: 1079 loss: 0.0026607872
Iter: 1080 loss: 0.00265447632
Iter: 1081 loss: 0.00271683931
Iter: 1082 loss: 0.00265371799
Iter: 1083 loss: 0.00264761131
Iter: 1084 loss: 0.00265441556
Iter: 1085 loss: 0.00264427951
Iter: 1086 loss: 0.00263923174
Iter: 1087 loss: 0.00262969825
Iter: 1088 loss: 0.00283755874
Iter: 1089 loss: 0.00262965355
Iter: 1090 loss: 0.00262818113
Iter: 1091 loss: 0.00262511359
Iter: 1092 loss: 0.00267734239
Iter: 1093 loss: 0.0026250463
Iter: 1094 loss: 0.00262204278
Iter: 1095 loss: 0.00262423791
Iter: 1096 loss: 0.00262021786
Iter: 1097 loss: 0.00261840038
Iter: 1098 loss: 0.00261336751
Iter: 1099 loss: 0.00264310557
Iter: 1100 loss: 0.00261199661
Iter: 1101 loss: 0.00260629132
Iter: 1102 loss: 0.00261230697
Iter: 1103 loss: 0.00260313461
Iter: 1104 loss: 0.00259307353
Iter: 1105 loss: 0.00262260903
Iter: 1106 loss: 0.00258997362
Iter: 1107 loss: 0.00258239452
Iter: 1108 loss: 0.00258726534
Iter: 1109 loss: 0.00257759541
Iter: 1110 loss: 0.00257171877
Iter: 1111 loss: 0.00256990176
Iter: 1112 loss: 0.00256641954
Iter: 1113 loss: 0.00256777043
Iter: 1114 loss: 0.00255863531
Iter: 1115 loss: 0.00255532144
Iter: 1116 loss: 0.00258320197
Iter: 1117 loss: 0.002555107
Iter: 1118 loss: 0.00255367346
Iter: 1119 loss: 0.00255412376
Iter: 1120 loss: 0.00255264947
Iter: 1121 loss: 0.0025497023
Iter: 1122 loss: 0.00257839123
Iter: 1123 loss: 0.00254960498
Iter: 1124 loss: 0.00254697702
Iter: 1125 loss: 0.00255260058
Iter: 1126 loss: 0.00254592299
Iter: 1127 loss: 0.00254374533
Iter: 1128 loss: 0.00254543172
Iter: 1129 loss: 0.00254241517
Iter: 1130 loss: 0.00253958022
Iter: 1131 loss: 0.00253371126
Iter: 1132 loss: 0.00263725594
Iter: 1133 loss: 0.00253356434
Iter: 1134 loss: 0.00252860738
Iter: 1135 loss: 0.00252591446
Iter: 1136 loss: 0.00251814863
Iter: 1137 loss: 0.0025193668
Iter: 1138 loss: 0.00251235394
Iter: 1139 loss: 0.00250634574
Iter: 1140 loss: 0.00251246942
Iter: 1141 loss: 0.00250301324
Iter: 1142 loss: 0.00249706209
Iter: 1143 loss: 0.00254292833
Iter: 1144 loss: 0.0024966402
Iter: 1145 loss: 0.00249170698
Iter: 1146 loss: 0.00250931
Iter: 1147 loss: 0.00249039568
Iter: 1148 loss: 0.00248705712
Iter: 1149 loss: 0.00248771347
Iter: 1150 loss: 0.00248458586
Iter: 1151 loss: 0.00248026499
Iter: 1152 loss: 0.00250960863
Iter: 1153 loss: 0.00247982
Iter: 1154 loss: 0.0024751334
Iter: 1155 loss: 0.00254084263
Iter: 1156 loss: 0.0024751178
Iter: 1157 loss: 0.00247398484
Iter: 1158 loss: 0.00247225538
Iter: 1159 loss: 0.00247103884
Iter: 1160 loss: 0.00247038715
Iter: 1161 loss: 0.00246983673
Iter: 1162 loss: 0.00246776803
Iter: 1163 loss: 0.00246095657
Iter: 1164 loss: 0.00246409117
Iter: 1165 loss: 0.00245465501
Iter: 1166 loss: 0.00245128479
Iter: 1167 loss: 0.00247329427
Iter: 1168 loss: 0.00245093647
Iter: 1169 loss: 0.00245017326
Iter: 1170 loss: 0.00244756
Iter: 1171 loss: 0.00244454062
Iter: 1172 loss: 0.00244367821
Iter: 1173 loss: 0.00243930612
Iter: 1174 loss: 0.00243928074
Iter: 1175 loss: 0.00243351306
Iter: 1176 loss: 0.00243343716
Iter: 1177 loss: 0.002430222
Iter: 1178 loss: 0.00243012165
Iter: 1179 loss: 0.0024257258
Iter: 1180 loss: 0.00242051086
Iter: 1181 loss: 0.00241996069
Iter: 1182 loss: 0.00241431803
Iter: 1183 loss: 0.00240156753
Iter: 1184 loss: 0.00257218536
Iter: 1185 loss: 0.00240078475
Iter: 1186 loss: 0.00239110366
Iter: 1187 loss: 0.00245100656
Iter: 1188 loss: 0.00238994276
Iter: 1189 loss: 0.00239126198
Iter: 1190 loss: 0.00238871155
Iter: 1191 loss: 0.00238774158
Iter: 1192 loss: 0.00239005685
Iter: 1193 loss: 0.00238740398
Iter: 1194 loss: 0.002385956
Iter: 1195 loss: 0.00238256692
Iter: 1196 loss: 0.00242434675
Iter: 1197 loss: 0.00238230987
Iter: 1198 loss: 0.00238057319
Iter: 1199 loss: 0.00238037901
Iter: 1200 loss: 0.00237925607
Iter: 1201 loss: 0.00237613358
Iter: 1202 loss: 0.00239321776
Iter: 1203 loss: 0.00237516291
Iter: 1204 loss: 0.00236851606
Iter: 1205 loss: 0.00236079865
Iter: 1206 loss: 0.00235990528
Iter: 1207 loss: 0.00234478177
Iter: 1208 loss: 0.00235379837
Iter: 1209 loss: 0.00233498588
Iter: 1210 loss: 0.0023331733
Iter: 1211 loss: 0.00232777558
Iter: 1212 loss: 0.00232614297
Iter: 1213 loss: 0.00232388964
Iter: 1214 loss: 0.00232270174
Iter: 1215 loss: 0.00231922115
Iter: 1216 loss: 0.00233176677
Iter: 1217 loss: 0.00231766072
Iter: 1218 loss: 0.0023129771
Iter: 1219 loss: 0.00231256965
Iter: 1220 loss: 0.00230748346
Iter: 1221 loss: 0.00233701756
Iter: 1222 loss: 0.00230676192
Iter: 1223 loss: 0.00236141542
Iter: 1224 loss: 0.00230566738
Iter: 1225 loss: 0.00230528973
Iter: 1226 loss: 0.00230414188
Iter: 1227 loss: 0.00230627
Iter: 1228 loss: 0.00230339449
Iter: 1229 loss: 0.00230081752
Iter: 1230 loss: 0.00229690783
Iter: 1231 loss: 0.00229684589
Iter: 1232 loss: 0.00229471177
Iter: 1233 loss: 0.00231455732
Iter: 1234 loss: 0.00229462236
Iter: 1235 loss: 0.00228836481
Iter: 1236 loss: 0.00227898196
Iter: 1237 loss: 0.00227877731
Iter: 1238 loss: 0.00227158121
Iter: 1239 loss: 0.00227680802
Iter: 1240 loss: 0.00226714648
Iter: 1241 loss: 0.00225450518
Iter: 1242 loss: 0.00224488834
Iter: 1243 loss: 0.00224079378
Iter: 1244 loss: 0.00222984352
Iter: 1245 loss: 0.00222906168
Iter: 1246 loss: 0.00222912268
Iter: 1247 loss: 0.00222278899
Iter: 1248 loss: 0.0022181985
Iter: 1249 loss: 0.00221352978
Iter: 1250 loss: 0.00221262826
Iter: 1251 loss: 0.00220561866
Iter: 1252 loss: 0.00224232208
Iter: 1253 loss: 0.0022045623
Iter: 1254 loss: 0.00220153714
Iter: 1255 loss: 0.00219903886
Iter: 1256 loss: 0.00219815364
Iter: 1257 loss: 0.00220359163
Iter: 1258 loss: 0.00219692825
Iter: 1259 loss: 0.00219551288
Iter: 1260 loss: 0.00219337
Iter: 1261 loss: 0.0021933245
Iter: 1262 loss: 0.00219058106
Iter: 1263 loss: 0.00218693959
Iter: 1264 loss: 0.0021867021
Iter: 1265 loss: 0.0021807868
Iter: 1266 loss: 0.00218027225
Iter: 1267 loss: 0.00217585918
Iter: 1268 loss: 0.00217146403
Iter: 1269 loss: 0.00220800075
Iter: 1270 loss: 0.00217120373
Iter: 1271 loss: 0.00216857879
Iter: 1272 loss: 0.00216339901
Iter: 1273 loss: 0.00226804102
Iter: 1274 loss: 0.00216333522
Iter: 1275 loss: 0.00215884624
Iter: 1276 loss: 0.00215448812
Iter: 1277 loss: 0.00215351162
Iter: 1278 loss: 0.00215062848
Iter: 1279 loss: 0.0021477025
Iter: 1280 loss: 0.0021471295
Iter: 1281 loss: 0.00214268547
Iter: 1282 loss: 0.00214020442
Iter: 1283 loss: 0.00213824795
Iter: 1284 loss: 0.00213396223
Iter: 1285 loss: 0.00212389394
Iter: 1286 loss: 0.00224825111
Iter: 1287 loss: 0.00212308811
Iter: 1288 loss: 0.00211846712
Iter: 1289 loss: 0.00211841566
Iter: 1290 loss: 0.00211575045
Iter: 1291 loss: 0.00211761682
Iter: 1292 loss: 0.00211410969
Iter: 1293 loss: 0.00211074506
Iter: 1294 loss: 0.00211062329
Iter: 1295 loss: 0.00210957369
Iter: 1296 loss: 0.00211426103
Iter: 1297 loss: 0.0021093681
Iter: 1298 loss: 0.0021078384
Iter: 1299 loss: 0.00210691756
Iter: 1300 loss: 0.00210374733
Iter: 1301 loss: 0.00210355222
Iter: 1302 loss: 0.00210113218
Iter: 1303 loss: 0.00209691934
Iter: 1304 loss: 0.00212039892
Iter: 1305 loss: 0.00209634984
Iter: 1306 loss: 0.00209433143
Iter: 1307 loss: 0.00209910213
Iter: 1308 loss: 0.00209360733
Iter: 1309 loss: 0.00209184014
Iter: 1310 loss: 0.00212014234
Iter: 1311 loss: 0.00209184457
Iter: 1312 loss: 0.00209013815
Iter: 1313 loss: 0.00208714837
Iter: 1314 loss: 0.00208714721
Iter: 1315 loss: 0.00208579306
Iter: 1316 loss: 0.00208295858
Iter: 1317 loss: 0.00213275757
Iter: 1318 loss: 0.00208289223
Iter: 1319 loss: 0.00208041328
Iter: 1320 loss: 0.00208175392
Iter: 1321 loss: 0.00207879697
Iter: 1322 loss: 0.00207654294
Iter: 1323 loss: 0.00207359297
Iter: 1324 loss: 0.00207342533
Iter: 1325 loss: 0.00208045822
Iter: 1326 loss: 0.00207176851
Iter: 1327 loss: 0.00206969492
Iter: 1328 loss: 0.00206607534
Iter: 1329 loss: 0.00206607394
Iter: 1330 loss: 0.00205736398
Iter: 1331 loss: 0.00204064231
Iter: 1332 loss: 0.00239440287
Iter: 1333 loss: 0.00204057759
Iter: 1334 loss: 0.00203054631
Iter: 1335 loss: 0.00210526912
Iter: 1336 loss: 0.00202971837
Iter: 1337 loss: 0.00202395581
Iter: 1338 loss: 0.00202444708
Iter: 1339 loss: 0.00201949733
Iter: 1340 loss: 0.00201178156
Iter: 1341 loss: 0.00203351653
Iter: 1342 loss: 0.00200934615
Iter: 1343 loss: 0.00200844463
Iter: 1344 loss: 0.00200690748
Iter: 1345 loss: 0.0020069133
Iter: 1346 loss: 0.00200351956
Iter: 1347 loss: 0.00202526059
Iter: 1348 loss: 0.00200316682
Iter: 1349 loss: 0.00200241525
Iter: 1350 loss: 0.00200217613
Iter: 1351 loss: 0.00200169533
Iter: 1352 loss: 0.00200171163
Iter: 1353 loss: 0.00200131768
Iter: 1354 loss: 0.00199662615
Iter: 1355 loss: 0.00205882359
Iter: 1356 loss: 0.00199659541
Iter: 1357 loss: 0.00199475419
Iter: 1358 loss: 0.00199422
Iter: 1359 loss: 0.00199138047
Iter: 1360 loss: 0.00199145917
Iter: 1361 loss: 0.0019891155
Iter: 1362 loss: 0.00198115292
Iter: 1363 loss: 0.00198117038
Iter: 1364 loss: 0.00197472889
Iter: 1365 loss: 0.00196733931
Iter: 1366 loss: 0.0020489255
Iter: 1367 loss: 0.00196720939
Iter: 1368 loss: 0.00196398213
Iter: 1369 loss: 0.00199604686
Iter: 1370 loss: 0.00196386827
Iter: 1371 loss: 0.0019612764
Iter: 1372 loss: 0.00196756842
Iter: 1373 loss: 0.00196032901
Iter: 1374 loss: 0.00195806101
Iter: 1375 loss: 0.00195185351
Iter: 1376 loss: 0.00199057534
Iter: 1377 loss: 0.00195025676
Iter: 1378 loss: 0.00194685161
Iter: 1379 loss: 0.00194456766
Iter: 1380 loss: 0.00194549595
Iter: 1381 loss: 0.00194306101
Iter: 1382 loss: 0.00194182666
Iter: 1383 loss: 0.00193963828
Iter: 1384 loss: 0.00193965132
Iter: 1385 loss: 0.00193700031
Iter: 1386 loss: 0.00193533499
Iter: 1387 loss: 0.0019342734
Iter: 1388 loss: 0.00192947104
Iter: 1389 loss: 0.00193051551
Iter: 1390 loss: 0.00192589976
Iter: 1391 loss: 0.0019240512
Iter: 1392 loss: 0.00192140392
Iter: 1393 loss: 0.00192131312
Iter: 1394 loss: 0.00191753975
Iter: 1395 loss: 0.00191775127
Iter: 1396 loss: 0.00191458501
Iter: 1397 loss: 0.00191224483
Iter: 1398 loss: 0.00190552801
Iter: 1399 loss: 0.00193584152
Iter: 1400 loss: 0.00190304662
Iter: 1401 loss: 0.00191079825
Iter: 1402 loss: 0.00189717487
Iter: 1403 loss: 0.00189225562
Iter: 1404 loss: 0.00190708425
Iter: 1405 loss: 0.00189073954
Iter: 1406 loss: 0.00188730913
Iter: 1407 loss: 0.00189493806
Iter: 1408 loss: 0.00188601913
Iter: 1409 loss: 0.00188272248
Iter: 1410 loss: 0.00188050442
Iter: 1411 loss: 0.00187929277
Iter: 1412 loss: 0.0018764165
Iter: 1413 loss: 0.00189198554
Iter: 1414 loss: 0.00187596434
Iter: 1415 loss: 0.00187289692
Iter: 1416 loss: 0.00187909964
Iter: 1417 loss: 0.00187164615
Iter: 1418 loss: 0.0018698154
Iter: 1419 loss: 0.00186609779
Iter: 1420 loss: 0.00193617423
Iter: 1421 loss: 0.00186605006
Iter: 1422 loss: 0.00186261628
Iter: 1423 loss: 0.0018546636
Iter: 1424 loss: 0.00195504236
Iter: 1425 loss: 0.00185407768
Iter: 1426 loss: 0.00185371772
Iter: 1427 loss: 0.00185117871
Iter: 1428 loss: 0.00184996857
Iter: 1429 loss: 0.00185648061
Iter: 1430 loss: 0.00184978987
Iter: 1431 loss: 0.00184599694
Iter: 1432 loss: 0.00185381609
Iter: 1433 loss: 0.00184447994
Iter: 1434 loss: 0.0018416401
Iter: 1435 loss: 0.00183773879
Iter: 1436 loss: 0.00183756067
Iter: 1437 loss: 0.00183718593
Iter: 1438 loss: 0.00183571852
Iter: 1439 loss: 0.00183380186
Iter: 1440 loss: 0.00182999915
Iter: 1441 loss: 0.00190529577
Iter: 1442 loss: 0.00182995177
Iter: 1443 loss: 0.00182635174
Iter: 1444 loss: 0.00184061646
Iter: 1445 loss: 0.00182554917
Iter: 1446 loss: 0.0018245331
Iter: 1447 loss: 0.00182449503
Iter: 1448 loss: 0.00182302
Iter: 1449 loss: 0.00181887136
Iter: 1450 loss: 0.00184100412
Iter: 1451 loss: 0.00181756727
Iter: 1452 loss: 0.00181426713
Iter: 1453 loss: 0.00182324788
Iter: 1454 loss: 0.00181315676
Iter: 1455 loss: 0.00181002938
Iter: 1456 loss: 0.00182705023
Iter: 1457 loss: 0.00180953089
Iter: 1458 loss: 0.00181039155
Iter: 1459 loss: 0.00180842448
Iter: 1460 loss: 0.00180800224
Iter: 1461 loss: 0.00180824567
Iter: 1462 loss: 0.00180772785
Iter: 1463 loss: 0.00180596113
Iter: 1464 loss: 0.00180191454
Iter: 1465 loss: 0.0018550735
Iter: 1466 loss: 0.00180163863
Iter: 1467 loss: 0.00179779297
Iter: 1468 loss: 0.00181526481
Iter: 1469 loss: 0.0017970372
Iter: 1470 loss: 0.00179341272
Iter: 1471 loss: 0.00179267407
Iter: 1472 loss: 0.00179028721
Iter: 1473 loss: 0.00178804249
Iter: 1474 loss: 0.00181794073
Iter: 1475 loss: 0.00178802304
Iter: 1476 loss: 0.00178653281
Iter: 1477 loss: 0.0017828648
Iter: 1478 loss: 0.00181973714
Iter: 1479 loss: 0.00178242242
Iter: 1480 loss: 0.00177953078
Iter: 1481 loss: 0.00181040319
Iter: 1482 loss: 0.00177944952
Iter: 1483 loss: 0.00177881878
Iter: 1484 loss: 0.00178509695
Iter: 1485 loss: 0.0017788026
Iter: 1486 loss: 0.00177751924
Iter: 1487 loss: 0.00177457673
Iter: 1488 loss: 0.00181199773
Iter: 1489 loss: 0.00177434681
Iter: 1490 loss: 0.00177046773
Iter: 1491 loss: 0.00177744846
Iter: 1492 loss: 0.00176879868
Iter: 1493 loss: 0.00176685583
Iter: 1494 loss: 0.00178431324
Iter: 1495 loss: 0.00176676211
Iter: 1496 loss: 0.00176554301
Iter: 1497 loss: 0.00176443509
Iter: 1498 loss: 0.00176413241
Iter: 1499 loss: 0.0017590567
Iter: 1500 loss: 0.0017591794
Iter: 1501 loss: 0.00175505551
Iter: 1502 loss: 0.00175703154
Iter: 1503 loss: 0.00175311707
Iter: 1504 loss: 0.00175154721
Iter: 1505 loss: 0.00174748991
Iter: 1506 loss: 0.00177965546
Iter: 1507 loss: 0.00174671714
Iter: 1508 loss: 0.00174463587
Iter: 1509 loss: 0.00175136817
Iter: 1510 loss: 0.00174402923
Iter: 1511 loss: 0.00174348464
Iter: 1512 loss: 0.00174155785
Iter: 1513 loss: 0.00173912081
Iter: 1514 loss: 0.00173860393
Iter: 1515 loss: 0.00173894351
Iter: 1516 loss: 0.00173718971
Iter: 1517 loss: 0.00173551682
Iter: 1518 loss: 0.00175784389
Iter: 1519 loss: 0.00173551613
Iter: 1520 loss: 0.00173497561
Iter: 1521 loss: 0.00173432904
Iter: 1522 loss: 0.00173427432
Iter: 1523 loss: 0.00173316733
Iter: 1524 loss: 0.00173249596
Iter: 1525 loss: 0.00172968872
Iter: 1526 loss: 0.00175582885
Iter: 1527 loss: 0.00172957266
Iter: 1528 loss: 0.00172542536
Iter: 1529 loss: 0.00177106168
Iter: 1530 loss: 0.00172534282
Iter: 1531 loss: 0.0017227151
Iter: 1532 loss: 0.00172441383
Iter: 1533 loss: 0.00172103476
Iter: 1534 loss: 0.00172027072
Iter: 1535 loss: 0.00171799574
Iter: 1536 loss: 0.00172539393
Iter: 1537 loss: 0.0017169154
Iter: 1538 loss: 0.00171298976
Iter: 1539 loss: 0.00173914887
Iter: 1540 loss: 0.00171258557
Iter: 1541 loss: 0.0017114717
Iter: 1542 loss: 0.00171099673
Iter: 1543 loss: 0.00171049975
Iter: 1544 loss: 0.00170891511
Iter: 1545 loss: 0.00171118591
Iter: 1546 loss: 0.00170776877
Iter: 1547 loss: 0.00170597329
Iter: 1548 loss: 0.0017071506
Iter: 1549 loss: 0.00170483254
Iter: 1550 loss: 0.00170266756
Iter: 1551 loss: 0.00171156425
Iter: 1552 loss: 0.00170220505
Iter: 1553 loss: 0.0016987687
Iter: 1554 loss: 0.001704289
Iter: 1555 loss: 0.00169714657
Iter: 1556 loss: 0.00169648277
Iter: 1557 loss: 0.0016963738
Iter: 1558 loss: 0.00169591536
Iter: 1559 loss: 0.00169178157
Iter: 1560 loss: 0.00168681832
Iter: 1561 loss: 0.00168632227
Iter: 1562 loss: 0.00167983945
Iter: 1563 loss: 0.00170402229
Iter: 1564 loss: 0.00167824305
Iter: 1565 loss: 0.00167445769
Iter: 1566 loss: 0.00167432381
Iter: 1567 loss: 0.00167134567
Iter: 1568 loss: 0.00167124742
Iter: 1569 loss: 0.00166891923
Iter: 1570 loss: 0.00166233652
Iter: 1571 loss: 0.00166127714
Iter: 1572 loss: 0.00165675802
Iter: 1573 loss: 0.00169595412
Iter: 1574 loss: 0.00165527419
Iter: 1575 loss: 0.00165364833
Iter: 1576 loss: 0.00165095949
Iter: 1577 loss: 0.00165096065
Iter: 1578 loss: 0.00164594769
Iter: 1579 loss: 0.00166768511
Iter: 1580 loss: 0.00164493301
Iter: 1581 loss: 0.00164224778
Iter: 1582 loss: 0.00164222205
Iter: 1583 loss: 0.00164206291
Iter: 1584 loss: 0.00164060027
Iter: 1585 loss: 0.00164020155
Iter: 1586 loss: 0.00164031051
Iter: 1587 loss: 0.0016399083
Iter: 1588 loss: 0.00163917476
Iter: 1589 loss: 0.001637629
Iter: 1590 loss: 0.00166396168
Iter: 1591 loss: 0.00163757335
Iter: 1592 loss: 0.00163501606
Iter: 1593 loss: 0.00163343642
Iter: 1594 loss: 0.00163240964
Iter: 1595 loss: 0.00162925886
Iter: 1596 loss: 0.00162506208
Iter: 1597 loss: 0.00162483868
Iter: 1598 loss: 0.00162337744
Iter: 1599 loss: 0.00162264938
Iter: 1600 loss: 0.00161857414
Iter: 1601 loss: 0.00162148848
Iter: 1602 loss: 0.00161608565
Iter: 1603 loss: 0.00161414803
Iter: 1604 loss: 0.00162975816
Iter: 1605 loss: 0.00161401532
Iter: 1606 loss: 0.0016127713
Iter: 1607 loss: 0.00160955428
Iter: 1608 loss: 0.00163629453
Iter: 1609 loss: 0.00160898408
Iter: 1610 loss: 0.00160473038
Iter: 1611 loss: 0.00160681037
Iter: 1612 loss: 0.00160189928
Iter: 1613 loss: 0.00160064013
Iter: 1614 loss: 0.00159698457
Iter: 1615 loss: 0.00161367911
Iter: 1616 loss: 0.00159565546
Iter: 1617 loss: 0.00159433729
Iter: 1618 loss: 0.00159432436
Iter: 1619 loss: 0.00159294
Iter: 1620 loss: 0.00159455638
Iter: 1621 loss: 0.00159220793
Iter: 1622 loss: 0.00159054832
Iter: 1623 loss: 0.00159026647
Iter: 1624 loss: 0.00158895808
Iter: 1625 loss: 0.0015900298
Iter: 1626 loss: 0.00158816529
Iter: 1627 loss: 0.00158665911
Iter: 1628 loss: 0.00158358994
Iter: 1629 loss: 0.00163808884
Iter: 1630 loss: 0.00158353825
Iter: 1631 loss: 0.0015790374
Iter: 1632 loss: 0.00158936251
Iter: 1633 loss: 0.00157733774
Iter: 1634 loss: 0.00157380546
Iter: 1635 loss: 0.00156995654
Iter: 1636 loss: 0.00156936119
Iter: 1637 loss: 0.0015678826
Iter: 1638 loss: 0.00156777
Iter: 1639 loss: 0.00156615616
Iter: 1640 loss: 0.00156967156
Iter: 1641 loss: 0.00156554068
Iter: 1642 loss: 0.00157092582
Iter: 1643 loss: 0.00156424777
Iter: 1644 loss: 0.00156306033
Iter: 1645 loss: 0.00156305369
Iter: 1646 loss: 0.00156212423
Iter: 1647 loss: 0.00156002957
Iter: 1648 loss: 0.00156326569
Iter: 1649 loss: 0.00155905215
Iter: 1650 loss: 0.00155672012
Iter: 1651 loss: 0.00158171356
Iter: 1652 loss: 0.00155666471
Iter: 1653 loss: 0.00155540986
Iter: 1654 loss: 0.00155280624
Iter: 1655 loss: 0.00159542891
Iter: 1656 loss: 0.00155274384
Iter: 1657 loss: 0.00154651108
Iter: 1658 loss: 0.00157072349
Iter: 1659 loss: 0.00154502771
Iter: 1660 loss: 0.00154141022
Iter: 1661 loss: 0.00155978254
Iter: 1662 loss: 0.00154081336
Iter: 1663 loss: 0.00153890229
Iter: 1664 loss: 0.00153889216
Iter: 1665 loss: 0.00153681159
Iter: 1666 loss: 0.00153813302
Iter: 1667 loss: 0.00153549935
Iter: 1668 loss: 0.00153340329
Iter: 1669 loss: 0.00153156021
Iter: 1670 loss: 0.0015309907
Iter: 1671 loss: 0.00152649474
Iter: 1672 loss: 0.00152936403
Iter: 1673 loss: 0.0015235953
Iter: 1674 loss: 0.00152270752
Iter: 1675 loss: 0.00152226107
Iter: 1676 loss: 0.00152184477
Iter: 1677 loss: 0.00152037898
Iter: 1678 loss: 0.00151838316
Iter: 1679 loss: 0.00151825789
Iter: 1680 loss: 0.00153183891
Iter: 1681 loss: 0.00151609583
Iter: 1682 loss: 0.00151540979
Iter: 1683 loss: 0.0015139631
Iter: 1684 loss: 0.00153841893
Iter: 1685 loss: 0.00151391863
Iter: 1686 loss: 0.00151229324
Iter: 1687 loss: 0.00151177123
Iter: 1688 loss: 0.00151082291
Iter: 1689 loss: 0.00151003734
Iter: 1690 loss: 0.0015085889
Iter: 1691 loss: 0.00153954467
Iter: 1692 loss: 0.00150858145
Iter: 1693 loss: 0.00150500238
Iter: 1694 loss: 0.00151845661
Iter: 1695 loss: 0.00150414626
Iter: 1696 loss: 0.00150070572
Iter: 1697 loss: 0.00150016323
Iter: 1698 loss: 0.00149795716
Iter: 1699 loss: 0.00150284567
Iter: 1700 loss: 0.00149711105
Iter: 1701 loss: 0.00149598904
Iter: 1702 loss: 0.00149483187
Iter: 1703 loss: 0.00149462675
Iter: 1704 loss: 0.00149214175
Iter: 1705 loss: 0.00149677531
Iter: 1706 loss: 0.00149107515
Iter: 1707 loss: 0.00148832751
Iter: 1708 loss: 0.00151246577
Iter: 1709 loss: 0.00148816616
Iter: 1710 loss: 0.00148583786
Iter: 1711 loss: 0.00149574131
Iter: 1712 loss: 0.00148535974
Iter: 1713 loss: 0.00148298498
Iter: 1714 loss: 0.00150981732
Iter: 1715 loss: 0.00148293958
Iter: 1716 loss: 0.00148176262
Iter: 1717 loss: 0.00148120057
Iter: 1718 loss: 0.00148049893
Iter: 1719 loss: 0.00147919613
Iter: 1720 loss: 0.00150738598
Iter: 1721 loss: 0.00147918053
Iter: 1722 loss: 0.00147720415
Iter: 1723 loss: 0.00148903695
Iter: 1724 loss: 0.00147694733
Iter: 1725 loss: 0.0014757074
Iter: 1726 loss: 0.00147703139
Iter: 1727 loss: 0.00147504313
Iter: 1728 loss: 0.00147243519
Iter: 1729 loss: 0.00147242239
Iter: 1730 loss: 0.00147403323
Iter: 1731 loss: 0.00147148408
Iter: 1732 loss: 0.00147115695
Iter: 1733 loss: 0.00147070654
Iter: 1734 loss: 0.00147068151
Iter: 1735 loss: 0.00146994437
Iter: 1736 loss: 0.00147077232
Iter: 1737 loss: 0.00146955031
Iter: 1738 loss: 0.00146879582
Iter: 1739 loss: 0.00146821467
Iter: 1740 loss: 0.00146797718
Iter: 1741 loss: 0.00146587077
Iter: 1742 loss: 0.00147237943
Iter: 1743 loss: 0.0014652377
Iter: 1744 loss: 0.00146380858
Iter: 1745 loss: 0.00146413804
Iter: 1746 loss: 0.00146276841
Iter: 1747 loss: 0.00150591403
Iter: 1748 loss: 0.00146238739
Iter: 1749 loss: 0.00146201241
Iter: 1750 loss: 0.00146258529
Iter: 1751 loss: 0.00146183337
Iter: 1752 loss: 0.00146107725
Iter: 1753 loss: 0.00145842938
Iter: 1754 loss: 0.00145456556
Iter: 1755 loss: 0.0014540758
Iter: 1756 loss: 0.00145096553
Iter: 1757 loss: 0.00145081757
Iter: 1758 loss: 0.00144952198
Iter: 1759 loss: 0.00145727163
Iter: 1760 loss: 0.00144934934
Iter: 1761 loss: 0.00144873071
Iter: 1762 loss: 0.00144777191
Iter: 1763 loss: 0.001447747
Iter: 1764 loss: 0.00144675677
Iter: 1765 loss: 0.00145536801
Iter: 1766 loss: 0.00144669716
Iter: 1767 loss: 0.0014447195
Iter: 1768 loss: 0.00144987588
Iter: 1769 loss: 0.00144405325
Iter: 1770 loss: 0.00144248735
Iter: 1771 loss: 0.00144154031
Iter: 1772 loss: 0.00144089409
Iter: 1773 loss: 0.00143916951
Iter: 1774 loss: 0.00143756275
Iter: 1775 loss: 0.00143713853
Iter: 1776 loss: 0.0014353639
Iter: 1777 loss: 0.00145172235
Iter: 1778 loss: 0.0014352916
Iter: 1779 loss: 0.0014346072
Iter: 1780 loss: 0.00143324328
Iter: 1781 loss: 0.00146063825
Iter: 1782 loss: 0.00143322779
Iter: 1783 loss: 0.00143204501
Iter: 1784 loss: 0.00143383932
Iter: 1785 loss: 0.00143149635
Iter: 1786 loss: 0.00143090216
Iter: 1787 loss: 0.0014296422
Iter: 1788 loss: 0.0014499
Iter: 1789 loss: 0.00142960518
Iter: 1790 loss: 0.00142857851
Iter: 1791 loss: 0.00143261207
Iter: 1792 loss: 0.00142834627
Iter: 1793 loss: 0.00142706581
Iter: 1794 loss: 0.00142634404
Iter: 1795 loss: 0.00142577873
Iter: 1796 loss: 0.0014240325
Iter: 1797 loss: 0.00142523681
Iter: 1798 loss: 0.00142293586
Iter: 1799 loss: 0.00142189325
Iter: 1800 loss: 0.00142422854
Iter: 1801 loss: 0.00142150559
Iter: 1802 loss: 0.0014198455
Iter: 1803 loss: 0.00141894608
Iter: 1804 loss: 0.00141822523
Iter: 1805 loss: 0.00141652627
Iter: 1806 loss: 0.00144196814
Iter: 1807 loss: 0.00141652976
Iter: 1808 loss: 0.00141515327
Iter: 1809 loss: 0.00141212298
Iter: 1810 loss: 0.00145636778
Iter: 1811 loss: 0.0014119827
Iter: 1812 loss: 0.00143520138
Iter: 1813 loss: 0.00141117279
Iter: 1814 loss: 0.00141062867
Iter: 1815 loss: 0.00141255348
Iter: 1816 loss: 0.00141048897
Iter: 1817 loss: 0.0014099729
Iter: 1818 loss: 0.00140996836
Iter: 1819 loss: 0.0014092573
Iter: 1820 loss: 0.00140808616
Iter: 1821 loss: 0.00140808523
Iter: 1822 loss: 0.00140575226
Iter: 1823 loss: 0.0014024016
Iter: 1824 loss: 0.00140230369
Iter: 1825 loss: 0.0013965494
Iter: 1826 loss: 0.0013964551
Iter: 1827 loss: 0.00139553403
Iter: 1828 loss: 0.00139525114
Iter: 1829 loss: 0.0013943438
Iter: 1830 loss: 0.00139214355
Iter: 1831 loss: 0.00141682755
Iter: 1832 loss: 0.00139192166
Iter: 1833 loss: 0.00138887041
Iter: 1834 loss: 0.00138865295
Iter: 1835 loss: 0.00138635247
Iter: 1836 loss: 0.00138511043
Iter: 1837 loss: 0.00138559565
Iter: 1838 loss: 0.0013842436
Iter: 1839 loss: 0.00138203637
Iter: 1840 loss: 0.00138785783
Iter: 1841 loss: 0.00138129457
Iter: 1842 loss: 0.00137899455
Iter: 1843 loss: 0.00137794763
Iter: 1844 loss: 0.0013768
Iter: 1845 loss: 0.00137479254
Iter: 1846 loss: 0.00138284429
Iter: 1847 loss: 0.00137433643
Iter: 1848 loss: 0.00137361977
Iter: 1849 loss: 0.00137180462
Iter: 1850 loss: 0.00138934969
Iter: 1851 loss: 0.00137156516
Iter: 1852 loss: 0.0013678273
Iter: 1853 loss: 0.00138322008
Iter: 1854 loss: 0.00136702333
Iter: 1855 loss: 0.00136595371
Iter: 1856 loss: 0.00136572495
Iter: 1857 loss: 0.00136503857
Iter: 1858 loss: 0.00135973
Iter: 1859 loss: 0.00136549701
Iter: 1860 loss: 0.00135685923
Iter: 1861 loss: 0.00135363685
Iter: 1862 loss: 0.00135332509
Iter: 1863 loss: 0.00135062134
Iter: 1864 loss: 0.00135052262
Iter: 1865 loss: 0.00134919817
Iter: 1866 loss: 0.00134884939
Iter: 1867 loss: 0.0013480176
Iter: 1868 loss: 0.00134699186
Iter: 1869 loss: 0.00134615775
Iter: 1870 loss: 0.00134585286
Iter: 1871 loss: 0.00134439557
Iter: 1872 loss: 0.00134329218
Iter: 1873 loss: 0.00134283
Iter: 1874 loss: 0.0013403995
Iter: 1875 loss: 0.00136692647
Iter: 1876 loss: 0.00134036492
Iter: 1877 loss: 0.00133832044
Iter: 1878 loss: 0.00136299478
Iter: 1879 loss: 0.00133829343
Iter: 1880 loss: 0.0013357331
Iter: 1881 loss: 0.00133193249
Iter: 1882 loss: 0.00133183924
Iter: 1883 loss: 0.00134503772
Iter: 1884 loss: 0.00133069395
Iter: 1885 loss: 0.00133051164
Iter: 1886 loss: 0.00133017753
Iter: 1887 loss: 0.00133822602
Iter: 1888 loss: 0.00133016543
Iter: 1889 loss: 0.00132752059
Iter: 1890 loss: 0.00132433581
Iter: 1891 loss: 0.00132401031
Iter: 1892 loss: 0.00131733809
Iter: 1893 loss: 0.00133499666
Iter: 1894 loss: 0.00131504983
Iter: 1895 loss: 0.00133123645
Iter: 1896 loss: 0.0013142816
Iter: 1897 loss: 0.00131324632
Iter: 1898 loss: 0.00131649571
Iter: 1899 loss: 0.001312932
Iter: 1900 loss: 0.00131229614
Iter: 1901 loss: 0.00131037447
Iter: 1902 loss: 0.00131604844
Iter: 1903 loss: 0.00130939623
Iter: 1904 loss: 0.00130809052
Iter: 1905 loss: 0.00130706502
Iter: 1906 loss: 0.00130667479
Iter: 1907 loss: 0.00130448036
Iter: 1908 loss: 0.00131215632
Iter: 1909 loss: 0.0013039
Iter: 1910 loss: 0.00130300224
Iter: 1911 loss: 0.00130259455
Iter: 1912 loss: 0.00130156486
Iter: 1913 loss: 0.0013009836
Iter: 1914 loss: 0.00130054727
Iter: 1915 loss: 0.00130570959
Iter: 1916 loss: 0.00130015821
Iter: 1917 loss: 0.00129960035
Iter: 1918 loss: 0.00129834702
Iter: 1919 loss: 0.00131439022
Iter: 1920 loss: 0.00129826984
Iter: 1921 loss: 0.00129684492
Iter: 1922 loss: 0.00129726296
Iter: 1923 loss: 0.00129582372
Iter: 1924 loss: 0.00129262975
Iter: 1925 loss: 0.00130977726
Iter: 1926 loss: 0.00129214441
Iter: 1927 loss: 0.00129207491
Iter: 1928 loss: 0.00129100913
Iter: 1929 loss: 0.00128984265
Iter: 1930 loss: 0.00128962006
Iter: 1931 loss: 0.00128935825
Iter: 1932 loss: 0.00128883752
Iter: 1933 loss: 0.00129885308
Iter: 1934 loss: 0.00128883542
Iter: 1935 loss: 0.00128743495
Iter: 1936 loss: 0.00128839188
Iter: 1937 loss: 0.00128655974
Iter: 1938 loss: 0.00128444866
Iter: 1939 loss: 0.00128859957
Iter: 1940 loss: 0.00128358928
Iter: 1941 loss: 0.00128153176
Iter: 1942 loss: 0.0012996851
Iter: 1943 loss: 0.00128143711
Iter: 1944 loss: 0.00127954758
Iter: 1945 loss: 0.00128460932
Iter: 1946 loss: 0.00127892068
Iter: 1947 loss: 0.00127691822
Iter: 1948 loss: 0.00127474591
Iter: 1949 loss: 0.00127441541
Iter: 1950 loss: 0.00127367477
Iter: 1951 loss: 0.00127198466
Iter: 1952 loss: 0.00127159408
Iter: 1953 loss: 0.00127085473
Iter: 1954 loss: 0.00128688919
Iter: 1955 loss: 0.00127085135
Iter: 1956 loss: 0.00126992
Iter: 1957 loss: 0.0012687617
Iter: 1958 loss: 0.0012686376
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8
+ date
Tue Oct 27 16:33:56 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1182ca0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1182c9dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1182d0b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1182cf91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c3c2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c37aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c395d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c3508c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c36a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c36a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c2c8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c2d5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c2d5e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c231bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c2699d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c269158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c1fa6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c269268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c17c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c17c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c1a5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c1a5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c150bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c0bd0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c0bd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c0736a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c0a5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c0391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c039268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f115c057730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11400ce9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f114008b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11400ce268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1140031f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10cc7ce950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10cc7ce6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.103690714
Iter: 2 loss: 4.87335968
Iter: 3 loss: 4.8716526
Iter: 4 loss: 3.34154725
Iter: 5 loss: 3.34023046
Iter: 6 loss: 2.36365271
Iter: 7 loss: 2.36250305
Iter: 8 loss: 1.7005887
Iter: 9 loss: 1.69948435
Iter: 10 loss: 1.23914957
Iter: 11 loss: 1.23807979
Iter: 12 loss: 0.914853454
Iter: 13 loss: 0.913745522
Iter: 14 loss: 0.672946
Iter: 15 loss: 0.671622515
Iter: 16 loss: 0.483005464
Iter: 17 loss: 0.481364042
Iter: 18 loss: 0.336364806
Iter: 19 loss: 0.334549963
Iter: 20 loss: 0.230129302
Iter: 21 loss: 0.228289083
Iter: 22 loss: 0.15398702
Iter: 23 loss: 0.152105227
Iter: 24 loss: 0.100770973
Iter: 25 loss: 0.0991071761
Iter: 26 loss: 0.0971666947
Iter: 27 loss: 0.0892202258
Iter: 28 loss: 0.049307283
Iter: 29 loss: 1002.8551
Iter: 30 loss: 0.0493072122
Iter: 31 loss: 1854.27173
Iter: 32 loss: 668.238708
Iter: 33 loss: 0.0493072122
Iter: 34 loss: 564.228088
Iter: 35 loss: 3.65806
Iter: 36 loss: 0.0493067652
Iter: 37 loss: 0.0825362653
Iter: 38 loss: 0.0461583696
Iter: 39 loss: 0.0459017381
Iter: 40 loss: 0.0418230668
Iter: 41 loss: 0.0415545925
Iter: 42 loss: 0.0416100249
Iter: 43 loss: 0.0389862135
Iter: 44 loss: 0.0349510834
Iter: 45 loss: 0.0345988423
Iter: 46 loss: 0.0342123136
Iter: 47 loss: 0.033509396
Iter: 48 loss: 0.0317152888
Iter: 49 loss: 0.137029767
Iter: 50 loss: 0.0316790268
Iter: 51 loss: 0.0306958817
Iter: 52 loss: 0.0306292474
Iter: 53 loss: 0.0293276757
Iter: 54 loss: 0.0322285444
Iter: 55 loss: 0.0287498273
Iter: 56 loss: 0.0271859765
Iter: 57 loss: 0.0263762083
Iter: 58 loss: 0.0258613825
Iter: 59 loss: 0.0250464603
Iter: 60 loss: 0.0240162201
Iter: 61 loss: 0.0238906853
Iter: 62 loss: 0.0229931623
Iter: 63 loss: 0.0237686187
Iter: 64 loss: 0.02242814
Iter: 65 loss: 0.0214413833
Iter: 66 loss: 0.0237304121
Iter: 67 loss: 0.0212161094
Iter: 68 loss: 0.0207809508
Iter: 69 loss: 0.020566443
Iter: 70 loss: 0.0203337707
Iter: 71 loss: 0.0193836149
Iter: 72 loss: 0.0189430863
Iter: 73 loss: 0.0184689853
Iter: 74 loss: 0.017391026
Iter: 75 loss: 0.0236364789
Iter: 76 loss: 0.0172776505
Iter: 77 loss: 0.0166869331
Iter: 78 loss: 0.0157830827
Iter: 79 loss: 0.015757449
Iter: 80 loss: 0.0150579205
Iter: 81 loss: 0.0371656269
Iter: 82 loss: 0.0150574837
Iter: 83 loss: 0.0146767758
Iter: 84 loss: 0.0164682418
Iter: 85 loss: 0.0146303102
Iter: 86 loss: 0.0140627306
Iter: 87 loss: 0.0176838543
Iter: 88 loss: 0.0139692686
Iter: 89 loss: 0.0134735797
Iter: 90 loss: 0.0145365726
Iter: 91 loss: 0.0132549535
Iter: 92 loss: 0.0124591934
Iter: 93 loss: 0.0143750627
Iter: 94 loss: 0.0122507736
Iter: 95 loss: 0.0118454099
Iter: 96 loss: 0.0134590119
Iter: 97 loss: 0.011723645
Iter: 98 loss: 0.0113247801
Iter: 99 loss: 0.013519072
Iter: 100 loss: 0.0112756789
Iter: 101 loss: 0.0109318774
Iter: 102 loss: 0.0135703031
Iter: 103 loss: 0.0108686322
Iter: 104 loss: 0.0105599239
Iter: 105 loss: 0.0107096061
Iter: 106 loss: 0.0103493826
Iter: 107 loss: 0.00985622
Iter: 108 loss: 0.0128424466
Iter: 109 loss: 0.00977850519
Iter: 110 loss: 0.00967949629
Iter: 111 loss: 0.00946994778
Iter: 112 loss: 0.00932010077
Iter: 113 loss: 0.00956996065
Iter: 114 loss: 0.00924145896
Iter: 115 loss: 0.00911656208
Iter: 116 loss: 0.00911706779
Iter: 117 loss: 0.00901419483
Iter: 118 loss: 0.00874778721
Iter: 119 loss: 0.00908210501
Iter: 120 loss: 0.0086002592
Iter: 121 loss: 0.0084711723
Iter: 122 loss: 0.00844815746
Iter: 123 loss: 0.00832185894
Iter: 124 loss: 0.00819651596
Iter: 125 loss: 0.00816661865
Iter: 126 loss: 0.00799452327
Iter: 127 loss: 0.00804445706
Iter: 128 loss: 0.00788107608
Iter: 129 loss: 0.0076995967
Iter: 130 loss: 0.00822721049
Iter: 131 loss: 0.00764448568
Iter: 132 loss: 0.00745453592
Iter: 133 loss: 0.00733126607
Iter: 134 loss: 0.00725654
Iter: 135 loss: 0.00701929163
Iter: 136 loss: 0.00701928837
Iter: 137 loss: 0.00677253958
Iter: 138 loss: 0.0112620518
Iter: 139 loss: 0.00677146856
Iter: 140 loss: 0.00657631829
Iter: 141 loss: 0.00804804452
Iter: 142 loss: 0.0065689357
Iter: 143 loss: 0.00648616347
Iter: 144 loss: 0.00648407079
Iter: 145 loss: 0.0063971146
Iter: 146 loss: 0.00634744484
Iter: 147 loss: 0.00631129602
Iter: 148 loss: 0.00615214789
Iter: 149 loss: 0.00614676159
Iter: 150 loss: 0.00602200162
Iter: 151 loss: 0.00589771662
Iter: 152 loss: 0.00589769194
Iter: 153 loss: 0.00581928715
Iter: 154 loss: 0.00648857281
Iter: 155 loss: 0.00581257511
Iter: 156 loss: 0.00576492399
Iter: 157 loss: 0.00567050744
Iter: 158 loss: 0.00744854938
Iter: 159 loss: 0.00566941127
Iter: 160 loss: 0.00549810752
Iter: 161 loss: 0.00549806375
Iter: 162 loss: 0.00537894387
Iter: 163 loss: 0.00573499128
Iter: 164 loss: 0.00534373522
Iter: 165 loss: 0.00526168104
Iter: 166 loss: 0.00517127
Iter: 167 loss: 0.00515822694
Iter: 168 loss: 0.00505718309
Iter: 169 loss: 0.005776281
Iter: 170 loss: 0.00504573062
Iter: 171 loss: 0.00494350865
Iter: 172 loss: 0.00568581512
Iter: 173 loss: 0.0049369554
Iter: 174 loss: 0.00487675192
Iter: 175 loss: 0.00518736476
Iter: 176 loss: 0.00486475229
Iter: 177 loss: 0.00483322423
Iter: 178 loss: 0.00479284348
Iter: 179 loss: 0.00478989165
Iter: 180 loss: 0.00466710329
Iter: 181 loss: 0.00473420322
Iter: 182 loss: 0.00458696578
Iter: 183 loss: 0.00450135721
Iter: 184 loss: 0.00502803037
Iter: 185 loss: 0.00449360255
Iter: 186 loss: 0.00445079571
Iter: 187 loss: 0.00444784481
Iter: 188 loss: 0.0044314866
Iter: 189 loss: 0.00441255653
Iter: 190 loss: 0.00441045314
Iter: 191 loss: 0.00436742604
Iter: 192 loss: 0.00431022607
Iter: 193 loss: 0.00430720951
Iter: 194 loss: 0.00421940256
Iter: 195 loss: 0.00447978964
Iter: 196 loss: 0.00419324357
Iter: 197 loss: 0.00413244031
Iter: 198 loss: 0.00413722359
Iter: 199 loss: 0.00408571213
Iter: 200 loss: 0.0040223971
Iter: 201 loss: 0.00470806658
Iter: 202 loss: 0.00402093865
Iter: 203 loss: 0.0039864853
Iter: 204 loss: 0.00433402602
Iter: 205 loss: 0.00398514327
Iter: 206 loss: 0.00396750448
Iter: 207 loss: 0.00396432821
Iter: 208 loss: 0.00394474668
Iter: 209 loss: 0.00390970195
Iter: 210 loss: 0.00390969776
Iter: 211 loss: 0.00388112012
Iter: 212 loss: 0.00390631892
Iter: 213 loss: 0.00386485783
Iter: 214 loss: 0.0038376865
Iter: 215 loss: 0.00384825235
Iter: 216 loss: 0.00381845236
Iter: 217 loss: 0.00377456
Iter: 218 loss: 0.00379100279
Iter: 219 loss: 0.00374494586
Iter: 220 loss: 0.00372473337
Iter: 221 loss: 0.0037085549
Iter: 222 loss: 0.00370131666
Iter: 223 loss: 0.0036958484
Iter: 224 loss: 0.00369346887
Iter: 225 loss: 0.00367279607
Iter: 226 loss: 0.00365748606
Iter: 227 loss: 0.00365054142
Iter: 228 loss: 0.00361980149
Iter: 229 loss: 0.00358493347
Iter: 230 loss: 0.00358031713
Iter: 231 loss: 0.00354424701
Iter: 232 loss: 0.00369673548
Iter: 233 loss: 0.00353608513
Iter: 234 loss: 0.0034952485
Iter: 235 loss: 0.00355835631
Iter: 236 loss: 0.00347642391
Iter: 237 loss: 0.00343669718
Iter: 238 loss: 0.00356105831
Iter: 239 loss: 0.00342511293
Iter: 240 loss: 0.00354638812
Iter: 241 loss: 0.00341078592
Iter: 242 loss: 0.00340062
Iter: 243 loss: 0.00343188317
Iter: 244 loss: 0.00339742051
Iter: 245 loss: 0.0033922689
Iter: 246 loss: 0.00338388886
Iter: 247 loss: 0.0033838416
Iter: 248 loss: 0.00336772739
Iter: 249 loss: 0.00333643798
Iter: 250 loss: 0.0039816238
Iter: 251 loss: 0.00333622377
Iter: 252 loss: 0.00330531341
Iter: 253 loss: 0.00342920376
Iter: 254 loss: 0.00329791289
Iter: 255 loss: 0.00326797576
Iter: 256 loss: 0.00326797459
Iter: 257 loss: 0.00325088343
Iter: 258 loss: 0.00324954931
Iter: 259 loss: 0.00323040294
Iter: 260 loss: 0.00322948489
Iter: 261 loss: 0.00321476324
Iter: 262 loss: 0.00319037866
Iter: 263 loss: 0.00324394717
Iter: 264 loss: 0.00318127102
Iter: 265 loss: 0.00315685291
Iter: 266 loss: 0.00320677226
Iter: 267 loss: 0.00314712734
Iter: 268 loss: 0.00312607596
Iter: 269 loss: 0.00316841435
Iter: 270 loss: 0.00311740395
Iter: 271 loss: 0.00309720077
Iter: 272 loss: 0.00315465545
Iter: 273 loss: 0.00309092691
Iter: 274 loss: 0.00317646284
Iter: 275 loss: 0.00308595155
Iter: 276 loss: 0.00308341696
Iter: 277 loss: 0.00307949376
Iter: 278 loss: 0.00307943043
Iter: 279 loss: 0.00306596514
Iter: 280 loss: 0.00303942664
Iter: 281 loss: 0.003551987
Iter: 282 loss: 0.00303915539
Iter: 283 loss: 0.00302325143
Iter: 284 loss: 0.00315445429
Iter: 285 loss: 0.0030221031
Iter: 286 loss: 0.00301060872
Iter: 287 loss: 0.00299597136
Iter: 288 loss: 0.00299480511
Iter: 289 loss: 0.00297107548
Iter: 290 loss: 0.00299510779
Iter: 291 loss: 0.00295792194
Iter: 292 loss: 0.00294479798
Iter: 293 loss: 0.00301441643
Iter: 294 loss: 0.00294261263
Iter: 295 loss: 0.00292569213
Iter: 296 loss: 0.00291966088
Iter: 297 loss: 0.00291020353
Iter: 298 loss: 0.00289017754
Iter: 299 loss: 0.00296126911
Iter: 300 loss: 0.00288460311
Iter: 301 loss: 0.00287068868
Iter: 302 loss: 0.00290483842
Iter: 303 loss: 0.00286569656
Iter: 304 loss: 0.00284926174
Iter: 305 loss: 0.00284282817
Iter: 306 loss: 0.00283405278
Iter: 307 loss: 0.0028237931
Iter: 308 loss: 0.00282346876
Iter: 309 loss: 0.00282046827
Iter: 310 loss: 0.00281839259
Iter: 311 loss: 0.00281455833
Iter: 312 loss: 0.00280360784
Iter: 313 loss: 0.00285924133
Iter: 314 loss: 0.00279979222
Iter: 315 loss: 0.00278866151
Iter: 316 loss: 0.0028262753
Iter: 317 loss: 0.00278578745
Iter: 318 loss: 0.00277757039
Iter: 319 loss: 0.00277240248
Iter: 320 loss: 0.00276911957
Iter: 321 loss: 0.00275453
Iter: 322 loss: 0.0027628066
Iter: 323 loss: 0.00274479
Iter: 324 loss: 0.0027293202
Iter: 325 loss: 0.00282072229
Iter: 326 loss: 0.00272720354
Iter: 327 loss: 0.00271302368
Iter: 328 loss: 0.00279523758
Iter: 329 loss: 0.00271130959
Iter: 330 loss: 0.00270488905
Iter: 331 loss: 0.00269414019
Iter: 332 loss: 0.00269409968
Iter: 333 loss: 0.00268412288
Iter: 334 loss: 0.00269738771
Iter: 335 loss: 0.00267912657
Iter: 336 loss: 0.002669062
Iter: 337 loss: 0.00267055538
Iter: 338 loss: 0.00266148662
Iter: 339 loss: 0.00264772307
Iter: 340 loss: 0.00264786882
Iter: 341 loss: 0.0026367195
Iter: 342 loss: 0.00263084029
Iter: 343 loss: 0.0026302794
Iter: 344 loss: 0.00262206746
Iter: 345 loss: 0.00263957027
Iter: 346 loss: 0.0026187445
Iter: 347 loss: 0.00260811974
Iter: 348 loss: 0.0026082918
Iter: 349 loss: 0.00259959861
Iter: 350 loss: 0.00258817896
Iter: 351 loss: 0.00258801598
Iter: 352 loss: 0.00258058729
Iter: 353 loss: 0.00256710942
Iter: 354 loss: 0.0028726696
Iter: 355 loss: 0.0025671008
Iter: 356 loss: 0.00255131163
Iter: 357 loss: 0.00255576428
Iter: 358 loss: 0.00253988337
Iter: 359 loss: 0.00253133476
Iter: 360 loss: 0.00254739402
Iter: 361 loss: 0.00252777431
Iter: 362 loss: 0.00251500425
Iter: 363 loss: 0.0025335534
Iter: 364 loss: 0.00250857696
Iter: 365 loss: 0.00249220734
Iter: 366 loss: 0.00256400299
Iter: 367 loss: 0.00248914352
Iter: 368 loss: 0.0024699166
Iter: 369 loss: 0.00247402792
Iter: 370 loss: 0.00245581986
Iter: 371 loss: 0.00244050613
Iter: 372 loss: 0.00253193267
Iter: 373 loss: 0.00243844651
Iter: 374 loss: 0.002437633
Iter: 375 loss: 0.00243379339
Iter: 376 loss: 0.00242902967
Iter: 377 loss: 0.00243091583
Iter: 378 loss: 0.00242569926
Iter: 379 loss: 0.00242132135
Iter: 380 loss: 0.00241342047
Iter: 381 loss: 0.00260449573
Iter: 382 loss: 0.00241341721
Iter: 383 loss: 0.00240299245
Iter: 384 loss: 0.00247670198
Iter: 385 loss: 0.00240197219
Iter: 386 loss: 0.00239298446
Iter: 387 loss: 0.00247782888
Iter: 388 loss: 0.00239268877
Iter: 389 loss: 0.00238493364
Iter: 390 loss: 0.00239009317
Iter: 391 loss: 0.00238001
Iter: 392 loss: 0.00236957287
Iter: 393 loss: 0.00235641166
Iter: 394 loss: 0.00235542422
Iter: 395 loss: 0.0023360108
Iter: 396 loss: 0.0023995731
Iter: 397 loss: 0.00233030459
Iter: 398 loss: 0.0023152756
Iter: 399 loss: 0.00231941603
Iter: 400 loss: 0.00230441662
Iter: 401 loss: 0.00229519513
Iter: 402 loss: 0.00229379232
Iter: 403 loss: 0.0022853238
Iter: 404 loss: 0.00227462337
Iter: 405 loss: 0.00227386
Iter: 406 loss: 0.00226405123
Iter: 407 loss: 0.00226395554
Iter: 408 loss: 0.00225900067
Iter: 409 loss: 0.00226467662
Iter: 410 loss: 0.00225635106
Iter: 411 loss: 0.00224685855
Iter: 412 loss: 0.00228119572
Iter: 413 loss: 0.00224438077
Iter: 414 loss: 0.00223586615
Iter: 415 loss: 0.00231653079
Iter: 416 loss: 0.00223559886
Iter: 417 loss: 0.00222993479
Iter: 418 loss: 0.00223126612
Iter: 419 loss: 0.00222569797
Iter: 420 loss: 0.00221803947
Iter: 421 loss: 0.00221596356
Iter: 422 loss: 0.00221125735
Iter: 423 loss: 0.0022003206
Iter: 424 loss: 0.00222366583
Iter: 425 loss: 0.00219591288
Iter: 426 loss: 0.00218299218
Iter: 427 loss: 0.00218482479
Iter: 428 loss: 0.00217327615
Iter: 429 loss: 0.002162138
Iter: 430 loss: 0.00217234809
Iter: 431 loss: 0.00215559802
Iter: 432 loss: 0.00214289618
Iter: 433 loss: 0.00214574719
Iter: 434 loss: 0.00213344512
Iter: 435 loss: 0.00212233118
Iter: 436 loss: 0.00212230184
Iter: 437 loss: 0.00211285427
Iter: 438 loss: 0.00222048769
Iter: 439 loss: 0.00211260142
Iter: 440 loss: 0.00210088887
Iter: 441 loss: 0.00210089982
Iter: 442 loss: 0.00209162314
Iter: 443 loss: 0.00208114972
Iter: 444 loss: 0.00208809553
Iter: 445 loss: 0.002074535
Iter: 446 loss: 0.00206733518
Iter: 447 loss: 0.0020669729
Iter: 448 loss: 0.00206091511
Iter: 449 loss: 0.00207048655
Iter: 450 loss: 0.00205803267
Iter: 451 loss: 0.00205211807
Iter: 452 loss: 0.00204506982
Iter: 453 loss: 0.00204437319
Iter: 454 loss: 0.00203520316
Iter: 455 loss: 0.00207851268
Iter: 456 loss: 0.00203346414
Iter: 457 loss: 0.00202482566
Iter: 458 loss: 0.00202919729
Iter: 459 loss: 0.0020190787
Iter: 460 loss: 0.00200861646
Iter: 461 loss: 0.00202437583
Iter: 462 loss: 0.00200355309
Iter: 463 loss: 0.0019924168
Iter: 464 loss: 0.00198479253
Iter: 465 loss: 0.00198065257
Iter: 466 loss: 0.00196037069
Iter: 467 loss: 0.00201690616
Iter: 468 loss: 0.0019537441
Iter: 469 loss: 0.00193868694
Iter: 470 loss: 0.00193852151
Iter: 471 loss: 0.00193641218
Iter: 472 loss: 0.00193423673
Iter: 473 loss: 0.00193021051
Iter: 474 loss: 0.00192190439
Iter: 475 loss: 0.00208241236
Iter: 476 loss: 0.0019217513
Iter: 477 loss: 0.00191559608
Iter: 478 loss: 0.00191972533
Iter: 479 loss: 0.00191182666
Iter: 480 loss: 0.00190662674
Iter: 481 loss: 0.00189472747
Iter: 482 loss: 0.00205702055
Iter: 483 loss: 0.00189396809
Iter: 484 loss: 0.00188765302
Iter: 485 loss: 0.00188898342
Iter: 486 loss: 0.00188302272
Iter: 487 loss: 0.00187290297
Iter: 488 loss: 0.00188329606
Iter: 489 loss: 0.00186721131
Iter: 490 loss: 0.00185898785
Iter: 491 loss: 0.00185893779
Iter: 492 loss: 0.00185148208
Iter: 493 loss: 0.00191817852
Iter: 494 loss: 0.00185109
Iter: 495 loss: 0.00184572663
Iter: 496 loss: 0.00184673397
Iter: 497 loss: 0.00184174418
Iter: 498 loss: 0.00183494715
Iter: 499 loss: 0.00183489919
Iter: 500 loss: 0.00182946702
Iter: 501 loss: 0.00182009558
Iter: 502 loss: 0.00184739649
Iter: 503 loss: 0.00181718578
Iter: 504 loss: 0.00180769514
Iter: 505 loss: 0.00184678962
Iter: 506 loss: 0.00180572446
Iter: 507 loss: 0.00180159148
Iter: 508 loss: 0.00180060742
Iter: 509 loss: 0.00179644139
Iter: 510 loss: 0.00179725979
Iter: 511 loss: 0.00179339398
Iter: 512 loss: 0.00178581872
Iter: 513 loss: 0.00178481662
Iter: 514 loss: 0.00177938351
Iter: 515 loss: 0.00177223515
Iter: 516 loss: 0.00177376927
Iter: 517 loss: 0.00176698912
Iter: 518 loss: 0.00175667903
Iter: 519 loss: 0.00177187589
Iter: 520 loss: 0.00175156363
Iter: 521 loss: 0.00174128369
Iter: 522 loss: 0.00173789077
Iter: 523 loss: 0.00173196406
Iter: 524 loss: 0.00172253279
Iter: 525 loss: 0.00172252231
Iter: 526 loss: 0.00171520107
Iter: 527 loss: 0.00172126223
Iter: 528 loss: 0.0017108355
Iter: 529 loss: 0.00170082692
Iter: 530 loss: 0.00170021656
Iter: 531 loss: 0.00169256935
Iter: 532 loss: 0.00168150128
Iter: 533 loss: 0.00175114011
Iter: 534 loss: 0.00168030208
Iter: 535 loss: 0.00167155464
Iter: 536 loss: 0.0017328742
Iter: 537 loss: 0.00167079258
Iter: 538 loss: 0.00167144951
Iter: 539 loss: 0.001667595
Iter: 540 loss: 0.00166524609
Iter: 541 loss: 0.00166380242
Iter: 542 loss: 0.00166285993
Iter: 543 loss: 0.00165826688
Iter: 544 loss: 0.00166911772
Iter: 545 loss: 0.00165654556
Iter: 546 loss: 0.00165173342
Iter: 547 loss: 0.00164135965
Iter: 548 loss: 0.00181395351
Iter: 549 loss: 0.00164100761
Iter: 550 loss: 0.001632903
Iter: 551 loss: 0.00165158603
Iter: 552 loss: 0.0016298308
Iter: 553 loss: 0.00162560935
Iter: 554 loss: 0.0016203844
Iter: 555 loss: 0.00161994901
Iter: 556 loss: 0.00161387608
Iter: 557 loss: 0.00161798764
Iter: 558 loss: 0.00161005836
Iter: 559 loss: 0.00160264247
Iter: 560 loss: 0.00163067912
Iter: 561 loss: 0.00160092884
Iter: 562 loss: 0.00159463263
Iter: 563 loss: 0.00159714615
Iter: 564 loss: 0.00159022305
Iter: 565 loss: 0.00158399716
Iter: 566 loss: 0.0015841159
Iter: 567 loss: 0.00157905661
Iter: 568 loss: 0.00157114363
Iter: 569 loss: 0.00161706912
Iter: 570 loss: 0.00157005223
Iter: 571 loss: 0.00156360411
Iter: 572 loss: 0.00157781853
Iter: 573 loss: 0.00156104402
Iter: 574 loss: 0.00155994203
Iter: 575 loss: 0.00155729591
Iter: 576 loss: 0.00155478716
Iter: 577 loss: 0.00155253452
Iter: 578 loss: 0.00155189866
Iter: 579 loss: 0.00154696777
Iter: 580 loss: 0.00155403977
Iter: 581 loss: 0.00154459185
Iter: 582 loss: 0.00154018751
Iter: 583 loss: 0.00156687
Iter: 584 loss: 0.00153962639
Iter: 585 loss: 0.00153588702
Iter: 586 loss: 0.00158045779
Iter: 587 loss: 0.00153584604
Iter: 588 loss: 0.00153325382
Iter: 589 loss: 0.00152940443
Iter: 590 loss: 0.00152931246
Iter: 591 loss: 0.001525086
Iter: 592 loss: 0.00155062485
Iter: 593 loss: 0.00152458344
Iter: 594 loss: 0.0015199522
Iter: 595 loss: 0.00151137658
Iter: 596 loss: 0.001716353
Iter: 597 loss: 0.00151136727
Iter: 598 loss: 0.00150052761
Iter: 599 loss: 0.00151208171
Iter: 600 loss: 0.00149457366
Iter: 601 loss: 0.00148803089
Iter: 602 loss: 0.00158961513
Iter: 603 loss: 0.00148802833
Iter: 604 loss: 0.00148221524
Iter: 605 loss: 0.00147801824
Iter: 606 loss: 0.00147600588
Iter: 607 loss: 0.00147543964
Iter: 608 loss: 0.00147294148
Iter: 609 loss: 0.00146946893
Iter: 610 loss: 0.00148079405
Iter: 611 loss: 0.0014684737
Iter: 612 loss: 0.00146578811
Iter: 613 loss: 0.00145908713
Iter: 614 loss: 0.00152121368
Iter: 615 loss: 0.00145814184
Iter: 616 loss: 0.00145376264
Iter: 617 loss: 0.00145339756
Iter: 618 loss: 0.00144975539
Iter: 619 loss: 0.00144975609
Iter: 620 loss: 0.00144748797
Iter: 621 loss: 0.00144262775
Iter: 622 loss: 0.00151840178
Iter: 623 loss: 0.00144246407
Iter: 624 loss: 0.00143689429
Iter: 625 loss: 0.00144144008
Iter: 626 loss: 0.001433586
Iter: 627 loss: 0.0014301776
Iter: 628 loss: 0.00143006467
Iter: 629 loss: 0.00142676127
Iter: 630 loss: 0.00141719403
Iter: 631 loss: 0.00145912403
Iter: 632 loss: 0.0014134706
Iter: 633 loss: 0.00140332791
Iter: 634 loss: 0.00147658389
Iter: 635 loss: 0.00140255888
Iter: 636 loss: 0.00139413495
Iter: 637 loss: 0.00142266217
Iter: 638 loss: 0.00139187719
Iter: 639 loss: 0.00139064575
Iter: 640 loss: 0.00138871651
Iter: 641 loss: 0.00138484361
Iter: 642 loss: 0.00139526499
Iter: 643 loss: 0.00138358597
Iter: 644 loss: 0.00137944729
Iter: 645 loss: 0.00136916339
Iter: 646 loss: 0.00146659056
Iter: 647 loss: 0.00136775826
Iter: 648 loss: 0.0013619992
Iter: 649 loss: 0.00136197824
Iter: 650 loss: 0.00135871104
Iter: 651 loss: 0.00135867158
Iter: 652 loss: 0.00135625352
Iter: 653 loss: 0.00135248026
Iter: 654 loss: 0.00135242846
Iter: 655 loss: 0.00134854752
Iter: 656 loss: 0.00135259214
Iter: 657 loss: 0.00134639372
Iter: 658 loss: 0.00134244631
Iter: 659 loss: 0.00134479627
Iter: 660 loss: 0.00133988075
Iter: 661 loss: 0.00133223576
Iter: 662 loss: 0.00133533718
Iter: 663 loss: 0.00132699544
Iter: 664 loss: 0.00132116186
Iter: 665 loss: 0.00132267
Iter: 666 loss: 0.00131683389
Iter: 667 loss: 0.00130917621
Iter: 668 loss: 0.00137590361
Iter: 669 loss: 0.0013088017
Iter: 670 loss: 0.0013030218
Iter: 671 loss: 0.00130649307
Iter: 672 loss: 0.00129931525
Iter: 673 loss: 0.00130057475
Iter: 674 loss: 0.00129729835
Iter: 675 loss: 0.00129455957
Iter: 676 loss: 0.00129135035
Iter: 677 loss: 0.00129097397
Iter: 678 loss: 0.00128905079
Iter: 679 loss: 0.00128836161
Iter: 680 loss: 0.00128728687
Iter: 681 loss: 0.00128449383
Iter: 682 loss: 0.00128289312
Iter: 683 loss: 0.00128170347
Iter: 684 loss: 0.001278223
Iter: 685 loss: 0.00128093094
Iter: 686 loss: 0.00127612357
Iter: 687 loss: 0.00126891513
Iter: 688 loss: 0.00130731589
Iter: 689 loss: 0.00126775645
Iter: 690 loss: 0.00126309472
Iter: 691 loss: 0.00126306352
Iter: 692 loss: 0.0012593834
Iter: 693 loss: 0.00126510346
Iter: 694 loss: 0.00125762145
Iter: 695 loss: 0.00125322386
Iter: 696 loss: 0.00126822758
Iter: 697 loss: 0.00125205936
Iter: 698 loss: 0.00124674244
Iter: 699 loss: 0.00124905084
Iter: 700 loss: 0.00124309782
Iter: 701 loss: 0.00123884808
Iter: 702 loss: 0.00124338549
Iter: 703 loss: 0.00123651349
Iter: 704 loss: 0.00123413932
Iter: 705 loss: 0.0012337605
Iter: 706 loss: 0.00123213534
Iter: 707 loss: 0.00123210624
Iter: 708 loss: 0.00123137049
Iter: 709 loss: 0.00122930028
Iter: 710 loss: 0.00123975542
Iter: 711 loss: 0.00122862798
Iter: 712 loss: 0.00122493284
Iter: 713 loss: 0.00124979799
Iter: 714 loss: 0.00122454367
Iter: 715 loss: 0.00122197054
Iter: 716 loss: 0.00121507479
Iter: 717 loss: 0.00126228726
Iter: 718 loss: 0.00121346372
Iter: 719 loss: 0.00120805087
Iter: 720 loss: 0.00123625726
Iter: 721 loss: 0.00120711746
Iter: 722 loss: 0.00120498124
Iter: 723 loss: 0.0012004578
Iter: 724 loss: 0.00127119711
Iter: 725 loss: 0.0012003195
Iter: 726 loss: 0.00119416264
Iter: 727 loss: 0.00124409
Iter: 728 loss: 0.00119373389
Iter: 729 loss: 0.00118895958
Iter: 730 loss: 0.00119127415
Iter: 731 loss: 0.00118577597
Iter: 732 loss: 0.00117949338
Iter: 733 loss: 0.00119067286
Iter: 734 loss: 0.00117670302
Iter: 735 loss: 0.00117342151
Iter: 736 loss: 0.00118241622
Iter: 737 loss: 0.00117235014
Iter: 738 loss: 0.00116791856
Iter: 739 loss: 0.0011689777
Iter: 740 loss: 0.00116467522
Iter: 741 loss: 0.00116120628
Iter: 742 loss: 0.00116096169
Iter: 743 loss: 0.00115770311
Iter: 744 loss: 0.00117829419
Iter: 745 loss: 0.00115736667
Iter: 746 loss: 0.00115596107
Iter: 747 loss: 0.00115260272
Iter: 748 loss: 0.00119210011
Iter: 749 loss: 0.00115228479
Iter: 750 loss: 0.00114942831
Iter: 751 loss: 0.00115845143
Iter: 752 loss: 0.00114860258
Iter: 753 loss: 0.00114697358
Iter: 754 loss: 0.00114266423
Iter: 755 loss: 0.00117527763
Iter: 756 loss: 0.00114176481
Iter: 757 loss: 0.00113747
Iter: 758 loss: 0.00113745499
Iter: 759 loss: 0.00113486685
Iter: 760 loss: 0.00113375578
Iter: 761 loss: 0.00113240455
Iter: 762 loss: 0.0011283739
Iter: 763 loss: 0.00115451263
Iter: 764 loss: 0.00112791557
Iter: 765 loss: 0.00112475466
Iter: 766 loss: 0.00115265849
Iter: 767 loss: 0.00112460763
Iter: 768 loss: 0.0011227373
Iter: 769 loss: 0.00111931399
Iter: 770 loss: 0.0011974955
Iter: 771 loss: 0.00111930771
Iter: 772 loss: 0.00111609616
Iter: 773 loss: 0.00115497154
Iter: 774 loss: 0.00111605239
Iter: 775 loss: 0.00111384317
Iter: 776 loss: 0.0011182701
Iter: 777 loss: 0.0011129831
Iter: 778 loss: 0.00111061661
Iter: 779 loss: 0.00110875058
Iter: 780 loss: 0.00110801647
Iter: 781 loss: 0.00110490841
Iter: 782 loss: 0.00109904108
Iter: 783 loss: 0.00122536568
Iter: 784 loss: 0.00109901954
Iter: 785 loss: 0.00109273719
Iter: 786 loss: 0.00115317362
Iter: 787 loss: 0.00109247374
Iter: 788 loss: 0.0010851135
Iter: 789 loss: 0.00110384799
Iter: 790 loss: 0.00108260452
Iter: 791 loss: 0.00107942335
Iter: 792 loss: 0.00107990764
Iter: 793 loss: 0.00107700529
Iter: 794 loss: 0.00107283855
Iter: 795 loss: 0.00108700094
Iter: 796 loss: 0.0010717269
Iter: 797 loss: 0.0010682526
Iter: 798 loss: 0.00107447593
Iter: 799 loss: 0.0010667172
Iter: 800 loss: 0.00106441253
Iter: 801 loss: 0.00106146897
Iter: 802 loss: 0.0010612586
Iter: 803 loss: 0.00105862052
Iter: 804 loss: 0.00108578242
Iter: 805 loss: 0.00105852541
Iter: 806 loss: 0.00105630094
Iter: 807 loss: 0.00106646726
Iter: 808 loss: 0.00105588313
Iter: 809 loss: 0.00105407531
Iter: 810 loss: 0.00105399569
Iter: 811 loss: 0.00105225563
Iter: 812 loss: 0.0010574304
Iter: 813 loss: 0.00105173769
Iter: 814 loss: 0.00105030672
Iter: 815 loss: 0.0010463607
Iter: 816 loss: 0.00107021793
Iter: 817 loss: 0.00104524964
Iter: 818 loss: 0.00104103272
Iter: 819 loss: 0.00108719943
Iter: 820 loss: 0.00104094599
Iter: 821 loss: 0.00103918719
Iter: 822 loss: 0.00103916891
Iter: 823 loss: 0.00103727903
Iter: 824 loss: 0.00103432918
Iter: 825 loss: 0.00103429391
Iter: 826 loss: 0.00103143952
Iter: 827 loss: 0.00102824531
Iter: 828 loss: 0.0010278133
Iter: 829 loss: 0.00102424866
Iter: 830 loss: 0.00104636385
Iter: 831 loss: 0.0010238114
Iter: 832 loss: 0.0010200321
Iter: 833 loss: 0.00103217375
Iter: 834 loss: 0.00101897458
Iter: 835 loss: 0.00101776479
Iter: 836 loss: 0.00101733743
Iter: 837 loss: 0.00101600506
Iter: 838 loss: 0.00101362227
Iter: 839 loss: 0.00107246859
Iter: 840 loss: 0.00101362495
Iter: 841 loss: 0.00101219444
Iter: 842 loss: 0.0010116999
Iter: 843 loss: 0.00100880652
Iter: 844 loss: 0.00104132807
Iter: 845 loss: 0.00100875553
Iter: 846 loss: 0.001008027
Iter: 847 loss: 0.0010058881
Iter: 848 loss: 0.00101428956
Iter: 849 loss: 0.00100498088
Iter: 850 loss: 0.0010018294
Iter: 851 loss: 0.000996130519
Iter: 852 loss: 0.00112745818
Iter: 853 loss: 0.000996127259
Iter: 854 loss: 0.000988663291
Iter: 855 loss: 0.00102813751
Iter: 856 loss: 0.000987540116
Iter: 857 loss: 0.000982897822
Iter: 858 loss: 0.00105086667
Iter: 859 loss: 0.000982897705
Iter: 860 loss: 0.000981945
Iter: 861 loss: 0.000980872894
Iter: 862 loss: 0.000979952281
Iter: 863 loss: 0.000976920594
Iter: 864 loss: 0.000977508724
Iter: 865 loss: 0.000973938382
Iter: 866 loss: 0.000968194567
Iter: 867 loss: 0.00100695121
Iter: 868 loss: 0.000967654749
Iter: 869 loss: 0.000970373105
Iter: 870 loss: 0.000965814746
Iter: 871 loss: 0.000963922124
Iter: 872 loss: 0.000960129255
Iter: 873 loss: 0.00102813472
Iter: 874 loss: 0.000960075879
Iter: 875 loss: 0.000956959324
Iter: 876 loss: 0.000956909673
Iter: 877 loss: 0.000955393421
Iter: 878 loss: 0.000955076132
Iter: 879 loss: 0.000954227871
Iter: 880 loss: 0.000952344737
Iter: 881 loss: 0.000979764853
Iter: 882 loss: 0.00095225
Iter: 883 loss: 0.000950014393
Iter: 884 loss: 0.000948760775
Iter: 885 loss: 0.000947792432
Iter: 886 loss: 0.000945652719
Iter: 887 loss: 0.000944343337
Iter: 888 loss: 0.000943475694
Iter: 889 loss: 0.000940459198
Iter: 890 loss: 0.000938552839
Iter: 891 loss: 0.000937364879
Iter: 892 loss: 0.00093443814
Iter: 893 loss: 0.000955860538
Iter: 894 loss: 0.000934182201
Iter: 895 loss: 0.000931915711
Iter: 896 loss: 0.000944204337
Iter: 897 loss: 0.000931591727
Iter: 898 loss: 0.000929455506
Iter: 899 loss: 0.000935533084
Iter: 900 loss: 0.000928778725
Iter: 901 loss: 0.000927026791
Iter: 902 loss: 0.000923490152
Iter: 903 loss: 0.00098888576
Iter: 904 loss: 0.000923439744
Iter: 905 loss: 0.000930238515
Iter: 906 loss: 0.000922859763
Iter: 907 loss: 0.000922253181
Iter: 908 loss: 0.000921802595
Iter: 909 loss: 0.000921600556
Iter: 910 loss: 0.000920357765
Iter: 911 loss: 0.00091993867
Iter: 912 loss: 0.000919223763
Iter: 913 loss: 0.000917588943
Iter: 914 loss: 0.000918909791
Iter: 915 loss: 0.000916615827
Iter: 916 loss: 0.000915442
Iter: 917 loss: 0.000916485209
Iter: 918 loss: 0.00091475423
Iter: 919 loss: 0.000913250376
Iter: 920 loss: 0.000911959214
Iter: 921 loss: 0.000911549549
Iter: 922 loss: 0.000908717571
Iter: 923 loss: 0.000914359116
Iter: 924 loss: 0.000907565467
Iter: 925 loss: 0.000904420274
Iter: 926 loss: 0.000906290428
Iter: 927 loss: 0.000902375032
Iter: 928 loss: 0.000899867155
Iter: 929 loss: 0.000899829378
Iter: 930 loss: 0.000897905091
Iter: 931 loss: 0.00090322888
Iter: 932 loss: 0.000897297286
Iter: 933 loss: 0.000894897676
Iter: 934 loss: 0.000894275727
Iter: 935 loss: 0.000892778276
Iter: 936 loss: 0.000891106785
Iter: 937 loss: 0.000899740204
Iter: 938 loss: 0.000890831463
Iter: 939 loss: 0.000889933
Iter: 940 loss: 0.000889815332
Iter: 941 loss: 0.000889137562
Iter: 942 loss: 0.000891264062
Iter: 943 loss: 0.00088893855
Iter: 944 loss: 0.000888398848
Iter: 945 loss: 0.000888640643
Iter: 946 loss: 0.000888033304
Iter: 947 loss: 0.000887220318
Iter: 948 loss: 0.00088554027
Iter: 949 loss: 0.000915614539
Iter: 950 loss: 0.000885503
Iter: 951 loss: 0.000883004512
Iter: 952 loss: 0.000896133075
Iter: 953 loss: 0.000882618
Iter: 954 loss: 0.000880575739
Iter: 955 loss: 0.000878777355
Iter: 956 loss: 0.000878243707
Iter: 957 loss: 0.000874707242
Iter: 958 loss: 0.000879949366
Iter: 959 loss: 0.0008729822
Iter: 960 loss: 0.000869408366
Iter: 961 loss: 0.000871331897
Iter: 962 loss: 0.000867052819
Iter: 963 loss: 0.000863911817
Iter: 964 loss: 0.000863658381
Iter: 965 loss: 0.000861114706
Iter: 966 loss: 0.000865477661
Iter: 967 loss: 0.000859973778
Iter: 968 loss: 0.000857712585
Iter: 969 loss: 0.000854508
Iter: 970 loss: 0.000854396261
Iter: 971 loss: 0.000857019506
Iter: 972 loss: 0.000852931174
Iter: 973 loss: 0.000851842167
Iter: 974 loss: 0.000854941667
Iter: 975 loss: 0.000851492689
Iter: 976 loss: 0.00085059338
Iter: 977 loss: 0.00084870815
Iter: 978 loss: 0.000878905237
Iter: 979 loss: 0.000848658034
Iter: 980 loss: 0.000846071169
Iter: 981 loss: 0.000852283381
Iter: 982 loss: 0.000845118
Iter: 983 loss: 0.000843744
Iter: 984 loss: 0.000849068863
Iter: 985 loss: 0.000843424117
Iter: 986 loss: 0.000841738191
Iter: 987 loss: 0.000844496826
Iter: 988 loss: 0.000840965076
Iter: 989 loss: 0.000839079032
Iter: 990 loss: 0.000836349849
Iter: 991 loss: 0.000836267078
Iter: 992 loss: 0.000832831778
Iter: 993 loss: 0.00085756043
Iter: 994 loss: 0.000832536141
Iter: 995 loss: 0.000830464764
Iter: 996 loss: 0.000840489112
Iter: 997 loss: 0.000830111327
Iter: 998 loss: 0.000827890704
Iter: 999 loss: 0.000843578542
Iter: 1000 loss: 0.000827672658
Iter: 1001 loss: 0.000825935917
Iter: 1002 loss: 0.000822822913
Iter: 1003 loss: 0.000899367384
Iter: 1004 loss: 0.000822823087
Iter: 1005 loss: 0.000826116593
Iter: 1006 loss: 0.000821903581
Iter: 1007 loss: 0.000821070222
Iter: 1008 loss: 0.000826364092
Iter: 1009 loss: 0.000820973888
Iter: 1010 loss: 0.000820440357
Iter: 1011 loss: 0.000819039182
Iter: 1012 loss: 0.000829429366
Iter: 1013 loss: 0.000818753
Iter: 1014 loss: 0.000817166641
Iter: 1015 loss: 0.000825446215
Iter: 1016 loss: 0.00081690948
Iter: 1017 loss: 0.000815217616
Iter: 1018 loss: 0.000813468883
Iter: 1019 loss: 0.000813152
Iter: 1020 loss: 0.000810559
Iter: 1021 loss: 0.000821594731
Iter: 1022 loss: 0.000810004771
Iter: 1023 loss: 0.000808150857
Iter: 1024 loss: 0.000808789569
Iter: 1025 loss: 0.00080683839
Iter: 1026 loss: 0.000804454205
Iter: 1027 loss: 0.000808052835
Iter: 1028 loss: 0.000803328818
Iter: 1029 loss: 0.00080095575
Iter: 1030 loss: 0.000810786849
Iter: 1031 loss: 0.00080044
Iter: 1032 loss: 0.000798555906
Iter: 1033 loss: 0.000814024708
Iter: 1034 loss: 0.000798430352
Iter: 1035 loss: 0.000796884648
Iter: 1036 loss: 0.00080602
Iter: 1037 loss: 0.000796697452
Iter: 1038 loss: 0.000795753265
Iter: 1039 loss: 0.000795522181
Iter: 1040 loss: 0.000794925261
Iter: 1041 loss: 0.000795891683
Iter: 1042 loss: 0.000794559484
Iter: 1043 loss: 0.000794325722
Iter: 1044 loss: 0.000793646148
Iter: 1045 loss: 0.000796369452
Iter: 1046 loss: 0.000793366635
Iter: 1047 loss: 0.000792239909
Iter: 1048 loss: 0.000792346895
Iter: 1049 loss: 0.000791364524
Iter: 1050 loss: 0.000789853861
Iter: 1051 loss: 0.000790227437
Iter: 1052 loss: 0.000788749428
Iter: 1053 loss: 0.000786957564
Iter: 1054 loss: 0.000802375434
Iter: 1055 loss: 0.000786861754
Iter: 1056 loss: 0.00078512344
Iter: 1057 loss: 0.000787339523
Iter: 1058 loss: 0.000784226053
Iter: 1059 loss: 0.000782096176
Iter: 1060 loss: 0.000801641261
Iter: 1061 loss: 0.000782006304
Iter: 1062 loss: 0.000780092843
Iter: 1063 loss: 0.000779694063
Iter: 1064 loss: 0.000778426358
Iter: 1065 loss: 0.000776419824
Iter: 1066 loss: 0.000780651695
Iter: 1067 loss: 0.000775630644
Iter: 1068 loss: 0.000773311
Iter: 1069 loss: 0.000780146045
Iter: 1070 loss: 0.000772583066
Iter: 1071 loss: 0.000771236
Iter: 1072 loss: 0.000773964741
Iter: 1073 loss: 0.000770694693
Iter: 1074 loss: 0.000770038634
Iter: 1075 loss: 0.000770019484
Iter: 1076 loss: 0.000769456849
Iter: 1077 loss: 0.000767820864
Iter: 1078 loss: 0.00077437557
Iter: 1079 loss: 0.000767145655
Iter: 1080 loss: 0.00076514692
Iter: 1081 loss: 0.000764967815
Iter: 1082 loss: 0.000763494405
Iter: 1083 loss: 0.000761013711
Iter: 1084 loss: 0.0007754736
Iter: 1085 loss: 0.000760681578
Iter: 1086 loss: 0.000758577371
Iter: 1087 loss: 0.000762761687
Iter: 1088 loss: 0.000757704489
Iter: 1089 loss: 0.000755438756
Iter: 1090 loss: 0.000751805492
Iter: 1091 loss: 0.000751770218
Iter: 1092 loss: 0.000753398344
Iter: 1093 loss: 0.000750265783
Iter: 1094 loss: 0.00074932928
Iter: 1095 loss: 0.000750014
Iter: 1096 loss: 0.000748753257
Iter: 1097 loss: 0.000746992067
Iter: 1098 loss: 0.000747955695
Iter: 1099 loss: 0.000745827681
Iter: 1100 loss: 0.000744642806
Iter: 1101 loss: 0.000755095447
Iter: 1102 loss: 0.000744586287
Iter: 1103 loss: 0.000743801589
Iter: 1104 loss: 0.000747128739
Iter: 1105 loss: 0.000743633893
Iter: 1106 loss: 0.000743059441
Iter: 1107 loss: 0.000749233528
Iter: 1108 loss: 0.000743049197
Iter: 1109 loss: 0.000742381846
Iter: 1110 loss: 0.000741017458
Iter: 1111 loss: 0.000765337492
Iter: 1112 loss: 0.000740989344
Iter: 1113 loss: 0.000739860523
Iter: 1114 loss: 0.000738971401
Iter: 1115 loss: 0.000738624949
Iter: 1116 loss: 0.000737395545
Iter: 1117 loss: 0.000739158
Iter: 1118 loss: 0.000736800139
Iter: 1119 loss: 0.000735174515
Iter: 1120 loss: 0.000738953357
Iter: 1121 loss: 0.000734568341
Iter: 1122 loss: 0.000732625835
Iter: 1123 loss: 0.000732380664
Iter: 1124 loss: 0.00073098857
Iter: 1125 loss: 0.000728478772
Iter: 1126 loss: 0.000736130751
Iter: 1127 loss: 0.000727715495
Iter: 1128 loss: 0.000724854646
Iter: 1129 loss: 0.000756586553
Iter: 1130 loss: 0.000724790269
Iter: 1131 loss: 0.000723198522
Iter: 1132 loss: 0.000731041597
Iter: 1133 loss: 0.000722929544
Iter: 1134 loss: 0.000721592
Iter: 1135 loss: 0.000724299112
Iter: 1136 loss: 0.000721038901
Iter: 1137 loss: 0.00071963243
Iter: 1138 loss: 0.000729169929
Iter: 1139 loss: 0.000719497155
Iter: 1140 loss: 0.000718751573
Iter: 1141 loss: 0.00072778383
Iter: 1142 loss: 0.000718739058
Iter: 1143 loss: 0.000718015537
Iter: 1144 loss: 0.000717306859
Iter: 1145 loss: 0.000717152085
Iter: 1146 loss: 0.000716273
Iter: 1147 loss: 0.000714822381
Iter: 1148 loss: 0.000714816502
Iter: 1149 loss: 0.00071331847
Iter: 1150 loss: 0.000718019553
Iter: 1151 loss: 0.000712873705
Iter: 1152 loss: 0.000710988883
Iter: 1153 loss: 0.000713243324
Iter: 1154 loss: 0.000709993765
Iter: 1155 loss: 0.000707699568
Iter: 1156 loss: 0.00071032159
Iter: 1157 loss: 0.000706466904
Iter: 1158 loss: 0.000704007572
Iter: 1159 loss: 0.000703964732
Iter: 1160 loss: 0.000702023855
Iter: 1161 loss: 0.000700041535
Iter: 1162 loss: 0.000699769589
Iter: 1163 loss: 0.000698589662
Iter: 1164 loss: 0.000699160388
Iter: 1165 loss: 0.000697790529
Iter: 1166 loss: 0.000696316827
Iter: 1167 loss: 0.000696474104
Iter: 1168 loss: 0.000695197203
Iter: 1169 loss: 0.000693155802
Iter: 1170 loss: 0.00070601562
Iter: 1171 loss: 0.00069291715
Iter: 1172 loss: 0.000691682799
Iter: 1173 loss: 0.000688895583
Iter: 1174 loss: 0.000725522055
Iter: 1175 loss: 0.000688729808
Iter: 1176 loss: 0.000686299521
Iter: 1177 loss: 0.000686160871
Iter: 1178 loss: 0.000685577223
Iter: 1179 loss: 0.000684753933
Iter: 1180 loss: 0.000684726285
Iter: 1181 loss: 0.0006830325
Iter: 1182 loss: 0.000682169921
Iter: 1183 loss: 0.000681380217
Iter: 1184 loss: 0.000679684
Iter: 1185 loss: 0.000685889041
Iter: 1186 loss: 0.000679257093
Iter: 1187 loss: 0.000678011
Iter: 1188 loss: 0.00067995151
Iter: 1189 loss: 0.000677418138
Iter: 1190 loss: 0.000675729942
Iter: 1191 loss: 0.000676522497
Iter: 1192 loss: 0.00067459204
Iter: 1193 loss: 0.00067298772
Iter: 1194 loss: 0.000686877465
Iter: 1195 loss: 0.000672904658
Iter: 1196 loss: 0.000672143418
Iter: 1197 loss: 0.000681537786
Iter: 1198 loss: 0.000672133639
Iter: 1199 loss: 0.000671361
Iter: 1200 loss: 0.000674032664
Iter: 1201 loss: 0.000671160698
Iter: 1202 loss: 0.000670309644
Iter: 1203 loss: 0.000674795825
Iter: 1204 loss: 0.000670174
Iter: 1205 loss: 0.000669783796
Iter: 1206 loss: 0.000670039037
Iter: 1207 loss: 0.00066953816
Iter: 1208 loss: 0.000669172034
Iter: 1209 loss: 0.000669157598
Iter: 1210 loss: 0.000668860739
Iter: 1211 loss: 0.000667966786
Iter: 1212 loss: 0.000670688227
Iter: 1213 loss: 0.000667527085
Iter: 1214 loss: 0.000665813452
Iter: 1215 loss: 0.000664382474
Iter: 1216 loss: 0.000663885497
Iter: 1217 loss: 0.000661462836
Iter: 1218 loss: 0.000669587753
Iter: 1219 loss: 0.000660807942
Iter: 1220 loss: 0.000657918281
Iter: 1221 loss: 0.000667040469
Iter: 1222 loss: 0.000657079043
Iter: 1223 loss: 0.00065493834
Iter: 1224 loss: 0.000665410305
Iter: 1225 loss: 0.000654576055
Iter: 1226 loss: 0.000652844552
Iter: 1227 loss: 0.000652002112
Iter: 1228 loss: 0.000651174167
Iter: 1229 loss: 0.000648860354
Iter: 1230 loss: 0.00067626033
Iter: 1231 loss: 0.000648822112
Iter: 1232 loss: 0.000647691311
Iter: 1233 loss: 0.000653987867
Iter: 1234 loss: 0.000647530891
Iter: 1235 loss: 0.000646623317
Iter: 1236 loss: 0.000646586355
Iter: 1237 loss: 0.000646197237
Iter: 1238 loss: 0.000645890133
Iter: 1239 loss: 0.000645774533
Iter: 1240 loss: 0.000645348104
Iter: 1241 loss: 0.000645331573
Iter: 1242 loss: 0.000644916377
Iter: 1243 loss: 0.000644272834
Iter: 1244 loss: 0.000644265674
Iter: 1245 loss: 0.000643615145
Iter: 1246 loss: 0.000642731902
Iter: 1247 loss: 0.000642687548
Iter: 1248 loss: 0.000641491264
Iter: 1249 loss: 0.000650763861
Iter: 1250 loss: 0.000641403894
Iter: 1251 loss: 0.000640568091
Iter: 1252 loss: 0.000640462327
Iter: 1253 loss: 0.000639863778
Iter: 1254 loss: 0.000638783677
Iter: 1255 loss: 0.000641283696
Iter: 1256 loss: 0.000638383732
Iter: 1257 loss: 0.00063710066
Iter: 1258 loss: 0.000636679935
Iter: 1259 loss: 0.000635935809
Iter: 1260 loss: 0.000634150812
Iter: 1261 loss: 0.00064928981
Iter: 1262 loss: 0.000634045864
Iter: 1263 loss: 0.000632646377
Iter: 1264 loss: 0.000634456403
Iter: 1265 loss: 0.000631928036
Iter: 1266 loss: 0.000630174764
Iter: 1267 loss: 0.000643757638
Iter: 1268 loss: 0.000630048162
Iter: 1269 loss: 0.000628521841
Iter: 1270 loss: 0.00064525858
Iter: 1271 loss: 0.000628484297
Iter: 1272 loss: 0.000628096226
Iter: 1273 loss: 0.000629347749
Iter: 1274 loss: 0.000627988833
Iter: 1275 loss: 0.000627551111
Iter: 1276 loss: 0.00062894891
Iter: 1277 loss: 0.00062742841
Iter: 1278 loss: 0.000627103436
Iter: 1279 loss: 0.000626054301
Iter: 1280 loss: 0.000626875379
Iter: 1281 loss: 0.000625167042
Iter: 1282 loss: 0.000623772
Iter: 1283 loss: 0.000624397944
Iter: 1284 loss: 0.000622823951
Iter: 1285 loss: 0.00062191789
Iter: 1286 loss: 0.000621919171
Iter: 1287 loss: 0.000621112529
Iter: 1288 loss: 0.000621274929
Iter: 1289 loss: 0.000620519335
Iter: 1290 loss: 0.000619662576
Iter: 1291 loss: 0.000618960126
Iter: 1292 loss: 0.000618706748
Iter: 1293 loss: 0.00061772787
Iter: 1294 loss: 0.000616239093
Iter: 1295 loss: 0.000616212492
Iter: 1296 loss: 0.000614881865
Iter: 1297 loss: 0.000619367347
Iter: 1298 loss: 0.00061452121
Iter: 1299 loss: 0.000613066426
Iter: 1300 loss: 0.000616355217
Iter: 1301 loss: 0.000612517586
Iter: 1302 loss: 0.000614069402
Iter: 1303 loss: 0.000612127071
Iter: 1304 loss: 0.000611951
Iter: 1305 loss: 0.000611626077
Iter: 1306 loss: 0.000618922524
Iter: 1307 loss: 0.000611627067
Iter: 1308 loss: 0.000611118216
Iter: 1309 loss: 0.00061458617
Iter: 1310 loss: 0.00061106612
Iter: 1311 loss: 0.000610731367
Iter: 1312 loss: 0.000610334449
Iter: 1313 loss: 0.000610292424
Iter: 1314 loss: 0.000609445386
Iter: 1315 loss: 0.000609104405
Iter: 1316 loss: 0.000608654052
Iter: 1317 loss: 0.000607748283
Iter: 1318 loss: 0.000611046
Iter: 1319 loss: 0.000607518945
Iter: 1320 loss: 0.000606476
Iter: 1321 loss: 0.000608978502
Iter: 1322 loss: 0.000606098154
Iter: 1323 loss: 0.000604631146
Iter: 1324 loss: 0.000603843946
Iter: 1325 loss: 0.000603180553
Iter: 1326 loss: 0.000601464417
Iter: 1327 loss: 0.000611580326
Iter: 1328 loss: 0.000601248059
Iter: 1329 loss: 0.000600524829
Iter: 1330 loss: 0.000600174244
Iter: 1331 loss: 0.000599825522
Iter: 1332 loss: 0.000598578423
Iter: 1333 loss: 0.000606920687
Iter: 1334 loss: 0.000598451239
Iter: 1335 loss: 0.000598502054
Iter: 1336 loss: 0.000598025
Iter: 1337 loss: 0.000597618171
Iter: 1338 loss: 0.000599101651
Iter: 1339 loss: 0.000597519334
Iter: 1340 loss: 0.000597203849
Iter: 1341 loss: 0.000597165606
Iter: 1342 loss: 0.000596938888
Iter: 1343 loss: 0.000596347556
Iter: 1344 loss: 0.000595765247
Iter: 1345 loss: 0.000595641322
Iter: 1346 loss: 0.000594557379
Iter: 1347 loss: 0.000593900681
Iter: 1348 loss: 0.000593450386
Iter: 1349 loss: 0.000592337048
Iter: 1350 loss: 0.000591375807
Iter: 1351 loss: 0.000591074408
Iter: 1352 loss: 0.000589578
Iter: 1353 loss: 0.000589571428
Iter: 1354 loss: 0.000588332245
Iter: 1355 loss: 0.000589124509
Iter: 1356 loss: 0.00058754324
Iter: 1357 loss: 0.000586453127
Iter: 1358 loss: 0.000597384875
Iter: 1359 loss: 0.000586424081
Iter: 1360 loss: 0.000585214351
Iter: 1361 loss: 0.000584110327
Iter: 1362 loss: 0.000583814108
Iter: 1363 loss: 0.00058237277
Iter: 1364 loss: 0.000593524775
Iter: 1365 loss: 0.000582266948
Iter: 1366 loss: 0.000581358327
Iter: 1367 loss: 0.000591700547
Iter: 1368 loss: 0.000581345
Iter: 1369 loss: 0.000580833293
Iter: 1370 loss: 0.000580817868
Iter: 1371 loss: 0.000580521184
Iter: 1372 loss: 0.000580040389
Iter: 1373 loss: 0.000580036838
Iter: 1374 loss: 0.000579358661
Iter: 1375 loss: 0.000581699307
Iter: 1376 loss: 0.00057917909
Iter: 1377 loss: 0.000578517909
Iter: 1378 loss: 0.000577919185
Iter: 1379 loss: 0.000577754807
Iter: 1380 loss: 0.000576721155
Iter: 1381 loss: 0.000575661543
Iter: 1382 loss: 0.000575460377
Iter: 1383 loss: 0.000573584111
Iter: 1384 loss: 0.00057934667
Iter: 1385 loss: 0.000573029218
Iter: 1386 loss: 0.000571666285
Iter: 1387 loss: 0.000571654469
Iter: 1388 loss: 0.00057062757
Iter: 1389 loss: 0.0005688
Iter: 1390 loss: 0.00061402272
Iter: 1391 loss: 0.000568798278
Iter: 1392 loss: 0.000567863
Iter: 1393 loss: 0.000567497802
Iter: 1394 loss: 0.00056698604
Iter: 1395 loss: 0.00056570489
Iter: 1396 loss: 0.000577814819
Iter: 1397 loss: 0.000565522816
Iter: 1398 loss: 0.000563996146
Iter: 1399 loss: 0.000571318378
Iter: 1400 loss: 0.000563716865
Iter: 1401 loss: 0.000564171467
Iter: 1402 loss: 0.000563426933
Iter: 1403 loss: 0.00056306005
Iter: 1404 loss: 0.00056315877
Iter: 1405 loss: 0.000562786881
Iter: 1406 loss: 0.000562303059
Iter: 1407 loss: 0.000561222841
Iter: 1408 loss: 0.000576480525
Iter: 1409 loss: 0.000561164692
Iter: 1410 loss: 0.000560318411
Iter: 1411 loss: 0.000572640158
Iter: 1412 loss: 0.000560318236
Iter: 1413 loss: 0.000559632084
Iter: 1414 loss: 0.000560212415
Iter: 1415 loss: 0.000559226959
Iter: 1416 loss: 0.000558440806
Iter: 1417 loss: 0.000557259074
Iter: 1418 loss: 0.000557234453
Iter: 1419 loss: 0.000556234096
Iter: 1420 loss: 0.000554898637
Iter: 1421 loss: 0.000554824946
Iter: 1422 loss: 0.000553120568
Iter: 1423 loss: 0.000552478712
Iter: 1424 loss: 0.000551544654
Iter: 1425 loss: 0.000550133758
Iter: 1426 loss: 0.000568684074
Iter: 1427 loss: 0.000550122757
Iter: 1428 loss: 0.00054918509
Iter: 1429 loss: 0.000555793755
Iter: 1430 loss: 0.000549099059
Iter: 1431 loss: 0.000548289216
Iter: 1432 loss: 0.000546982919
Iter: 1433 loss: 0.000546972966
Iter: 1434 loss: 0.000546683
Iter: 1435 loss: 0.000546353171
Iter: 1436 loss: 0.000546291412
Iter: 1437 loss: 0.000546163297
Iter: 1438 loss: 0.000545995077
Iter: 1439 loss: 0.000545574701
Iter: 1440 loss: 0.000549682532
Iter: 1441 loss: 0.000545518182
Iter: 1442 loss: 0.000545140938
Iter: 1443 loss: 0.000544406823
Iter: 1444 loss: 0.000559679931
Iter: 1445 loss: 0.000544402516
Iter: 1446 loss: 0.000543308211
Iter: 1447 loss: 0.000546070689
Iter: 1448 loss: 0.000542928814
Iter: 1449 loss: 0.000542302092
Iter: 1450 loss: 0.000542247668
Iter: 1451 loss: 0.000541853369
Iter: 1452 loss: 0.000542288937
Iter: 1453 loss: 0.000541642366
Iter: 1454 loss: 0.000541000685
Iter: 1455 loss: 0.000540365581
Iter: 1456 loss: 0.000540231122
Iter: 1457 loss: 0.000539430475
Iter: 1458 loss: 0.000544648385
Iter: 1459 loss: 0.000539347122
Iter: 1460 loss: 0.000538388
Iter: 1461 loss: 0.000538347231
Iter: 1462 loss: 0.000537610555
Iter: 1463 loss: 0.000536288775
Iter: 1464 loss: 0.000538623717
Iter: 1465 loss: 0.000535705
Iter: 1466 loss: 0.000534583349
Iter: 1467 loss: 0.000548421405
Iter: 1468 loss: 0.000534571416
Iter: 1469 loss: 0.000533760234
Iter: 1470 loss: 0.00053647114
Iter: 1471 loss: 0.000533533399
Iter: 1472 loss: 0.000534509309
Iter: 1473 loss: 0.000533335144
Iter: 1474 loss: 0.000533184
Iter: 1475 loss: 0.000532674254
Iter: 1476 loss: 0.000532228732
Iter: 1477 loss: 0.000531982572
Iter: 1478 loss: 0.000531135476
Iter: 1479 loss: 0.000530270569
Iter: 1480 loss: 0.000530104153
Iter: 1481 loss: 0.00052895
Iter: 1482 loss: 0.000535485393
Iter: 1483 loss: 0.000528794
Iter: 1484 loss: 0.000527779
Iter: 1485 loss: 0.000534310413
Iter: 1486 loss: 0.000527663738
Iter: 1487 loss: 0.000527031254
Iter: 1488 loss: 0.000525900046
Iter: 1489 loss: 0.000553355203
Iter: 1490 loss: 0.000525899814
Iter: 1491 loss: 0.000525000622
Iter: 1492 loss: 0.000527246797
Iter: 1493 loss: 0.000524684903
Iter: 1494 loss: 0.000523836876
Iter: 1495 loss: 0.000524709292
Iter: 1496 loss: 0.000523362425
Iter: 1497 loss: 0.000522316084
Iter: 1498 loss: 0.000522226386
Iter: 1499 loss: 0.000521448674
Iter: 1500 loss: 0.000519893249
Iter: 1501 loss: 0.00052991946
Iter: 1502 loss: 0.000519723224
Iter: 1503 loss: 0.000518906105
Iter: 1504 loss: 0.000520239118
Iter: 1505 loss: 0.000518534798
Iter: 1506 loss: 0.000518487534
Iter: 1507 loss: 0.000518149289
Iter: 1508 loss: 0.000517801673
Iter: 1509 loss: 0.000517340726
Iter: 1510 loss: 0.000517314591
Iter: 1511 loss: 0.000516780594
Iter: 1512 loss: 0.000516974484
Iter: 1513 loss: 0.000516406843
Iter: 1514 loss: 0.000515717082
Iter: 1515 loss: 0.000517347478
Iter: 1516 loss: 0.000515468651
Iter: 1517 loss: 0.000514801592
Iter: 1518 loss: 0.000520147
Iter: 1519 loss: 0.000514758693
Iter: 1520 loss: 0.000514175626
Iter: 1521 loss: 0.000520760543
Iter: 1522 loss: 0.000514166779
Iter: 1523 loss: 0.000513960491
Iter: 1524 loss: 0.000513547566
Iter: 1525 loss: 0.000521179638
Iter: 1526 loss: 0.000513540639
Iter: 1527 loss: 0.000512947969
Iter: 1528 loss: 0.000513496227
Iter: 1529 loss: 0.000512607512
Iter: 1530 loss: 0.000511950697
Iter: 1531 loss: 0.000513787265
Iter: 1532 loss: 0.000511740334
Iter: 1533 loss: 0.000511008431
Iter: 1534 loss: 0.000511910359
Iter: 1535 loss: 0.000510628452
Iter: 1536 loss: 0.000509769947
Iter: 1537 loss: 0.000514781801
Iter: 1538 loss: 0.000509659527
Iter: 1539 loss: 0.000509775069
Iter: 1540 loss: 0.000509407313
Iter: 1541 loss: 0.000509169
Iter: 1542 loss: 0.00050859456
Iter: 1543 loss: 0.000514524756
Iter: 1544 loss: 0.00050852797
Iter: 1545 loss: 0.00050786318
Iter: 1546 loss: 0.000507030112
Iter: 1547 loss: 0.000506964338
Iter: 1548 loss: 0.000505844888
Iter: 1549 loss: 0.000508319179
Iter: 1550 loss: 0.000505412638
Iter: 1551 loss: 0.000504321768
Iter: 1552 loss: 0.000509057078
Iter: 1553 loss: 0.000504098192
Iter: 1554 loss: 0.000503885967
Iter: 1555 loss: 0.00050364784
Iter: 1556 loss: 0.000503307
Iter: 1557 loss: 0.000502545154
Iter: 1558 loss: 0.000513020088
Iter: 1559 loss: 0.000502499403
Iter: 1560 loss: 0.000501568778
Iter: 1561 loss: 0.000501732051
Iter: 1562 loss: 0.000500871509
Iter: 1563 loss: 0.000500072609
Iter: 1564 loss: 0.000502933573
Iter: 1565 loss: 0.000499865797
Iter: 1566 loss: 0.00049901352
Iter: 1567 loss: 0.00050296355
Iter: 1568 loss: 0.000498857116
Iter: 1569 loss: 0.000498240464
Iter: 1570 loss: 0.000497952045
Iter: 1571 loss: 0.000497650239
Iter: 1572 loss: 0.000497030036
Iter: 1573 loss: 0.000497008
Iter: 1574 loss: 0.000496490858
Iter: 1575 loss: 0.000502378796
Iter: 1576 loss: 0.000496483641
Iter: 1577 loss: 0.00049632194
Iter: 1578 loss: 0.000495793938
Iter: 1579 loss: 0.000496040564
Iter: 1580 loss: 0.000495308894
Iter: 1581 loss: 0.000494773732
Iter: 1582 loss: 0.000494772918
Iter: 1583 loss: 0.000494389678
Iter: 1584 loss: 0.000493749802
Iter: 1585 loss: 0.000493748754
Iter: 1586 loss: 0.000493593107
Iter: 1587 loss: 0.000493381696
Iter: 1588 loss: 0.000493022788
Iter: 1589 loss: 0.000492857769
Iter: 1590 loss: 0.000492677442
Iter: 1591 loss: 0.00049197
Iter: 1592 loss: 0.000491751358
Iter: 1593 loss: 0.000491330633
Iter: 1594 loss: 0.000490075501
Iter: 1595 loss: 0.000491248
Iter: 1596 loss: 0.000489347673
Iter: 1597 loss: 0.000488899706
Iter: 1598 loss: 0.000488826074
Iter: 1599 loss: 0.000488338643
Iter: 1600 loss: 0.000488533406
Iter: 1601 loss: 0.000487999176
Iter: 1602 loss: 0.000487455138
Iter: 1603 loss: 0.000487297017
Iter: 1604 loss: 0.000486969861
Iter: 1605 loss: 0.000486315315
Iter: 1606 loss: 0.000486681936
Iter: 1607 loss: 0.000485891243
Iter: 1608 loss: 0.000486728502
Iter: 1609 loss: 0.000485671015
Iter: 1610 loss: 0.000485460274
Iter: 1611 loss: 0.000484823482
Iter: 1612 loss: 0.000486700417
Iter: 1613 loss: 0.00048449717
Iter: 1614 loss: 0.000483629527
Iter: 1615 loss: 0.000484549964
Iter: 1616 loss: 0.000483154581
Iter: 1617 loss: 0.000482832198
Iter: 1618 loss: 0.000482716423
Iter: 1619 loss: 0.000482321164
Iter: 1620 loss: 0.00048290196
Iter: 1621 loss: 0.000482133
Iter: 1622 loss: 0.000481901574
Iter: 1623 loss: 0.000481194147
Iter: 1624 loss: 0.000482957286
Iter: 1625 loss: 0.000480797898
Iter: 1626 loss: 0.000480057468
Iter: 1627 loss: 0.000480979099
Iter: 1628 loss: 0.000479672715
Iter: 1629 loss: 0.000479087
Iter: 1630 loss: 0.000480285846
Iter: 1631 loss: 0.00047885222
Iter: 1632 loss: 0.000478083326
Iter: 1633 loss: 0.0004800077
Iter: 1634 loss: 0.000477816153
Iter: 1635 loss: 0.000477276451
Iter: 1636 loss: 0.000480634626
Iter: 1637 loss: 0.000477213878
Iter: 1638 loss: 0.000476680521
Iter: 1639 loss: 0.000476538145
Iter: 1640 loss: 0.000476207817
Iter: 1641 loss: 0.000475251378
Iter: 1642 loss: 0.000478359842
Iter: 1643 loss: 0.000474986446
Iter: 1644 loss: 0.000475568115
Iter: 1645 loss: 0.000474731583
Iter: 1646 loss: 0.000474526489
Iter: 1647 loss: 0.000473862659
Iter: 1648 loss: 0.00047454235
Iter: 1649 loss: 0.000473336491
Iter: 1650 loss: 0.000487549609
Iter: 1651 loss: 0.00047286498
Iter: 1652 loss: 0.000472474174
Iter: 1653 loss: 0.000472197164
Iter: 1654 loss: 0.000472058338
Iter: 1655 loss: 0.000471627194
Iter: 1656 loss: 0.000471042702
Iter: 1657 loss: 0.000471013191
Iter: 1658 loss: 0.000470418483
Iter: 1659 loss: 0.00047009936
Iter: 1660 loss: 0.000469829421
Iter: 1661 loss: 0.000469036342
Iter: 1662 loss: 0.00046998894
Iter: 1663 loss: 0.000468615821
Iter: 1664 loss: 0.000467668753
Iter: 1665 loss: 0.000468425278
Iter: 1666 loss: 0.00046709564
Iter: 1667 loss: 0.000465934834
Iter: 1668 loss: 0.000477666152
Iter: 1669 loss: 0.000465900084
Iter: 1670 loss: 0.000465290621
Iter: 1671 loss: 0.000466876372
Iter: 1672 loss: 0.000465083285
Iter: 1673 loss: 0.000464254204
Iter: 1674 loss: 0.000464357116
Iter: 1675 loss: 0.000463619042
Iter: 1676 loss: 0.000463523087
Iter: 1677 loss: 0.000463204487
Iter: 1678 loss: 0.000462823373
Iter: 1679 loss: 0.000463335309
Iter: 1680 loss: 0.000462636235
Iter: 1681 loss: 0.000462510798
Iter: 1682 loss: 0.000462129654
Iter: 1683 loss: 0.000462945784
Iter: 1684 loss: 0.000461897056
Iter: 1685 loss: 0.000461177638
Iter: 1686 loss: 0.000462236116
Iter: 1687 loss: 0.000460830284
Iter: 1688 loss: 0.000460850424
Iter: 1689 loss: 0.000460444222
Iter: 1690 loss: 0.000460163224
Iter: 1691 loss: 0.000459297444
Iter: 1692 loss: 0.000461199495
Iter: 1693 loss: 0.000458776165
Iter: 1694 loss: 0.000457850489
Iter: 1695 loss: 0.000465794583
Iter: 1696 loss: 0.000457800867
Iter: 1697 loss: 0.000457304937
Iter: 1698 loss: 0.000458125083
Iter: 1699 loss: 0.00045707979
Iter: 1700 loss: 0.000456614449
Iter: 1701 loss: 0.000457679795
Iter: 1702 loss: 0.000456439506
Iter: 1703 loss: 0.00045597693
Iter: 1704 loss: 0.000455849833
Iter: 1705 loss: 0.000455564907
Iter: 1706 loss: 0.000454950699
Iter: 1707 loss: 0.000455682923
Iter: 1708 loss: 0.000454629655
Iter: 1709 loss: 0.000454144902
Iter: 1710 loss: 0.000457678223
Iter: 1711 loss: 0.000454102934
Iter: 1712 loss: 0.000454369583
Iter: 1713 loss: 0.000453944871
Iter: 1714 loss: 0.000453821704
Iter: 1715 loss: 0.000453488756
Iter: 1716 loss: 0.000455597445
Iter: 1717 loss: 0.000453402754
Iter: 1718 loss: 0.000453183107
Iter: 1719 loss: 0.000453112472
Iter: 1720 loss: 0.000452986103
Iter: 1721 loss: 0.000452752
Iter: 1722 loss: 0.000453293382
Iter: 1723 loss: 0.000452664681
Iter: 1724 loss: 0.000452279928
Iter: 1725 loss: 0.000452090055
Iter: 1726 loss: 0.000451907166
Iter: 1727 loss: 0.000451279106
Iter: 1728 loss: 0.000453529821
Iter: 1729 loss: 0.000451116182
Iter: 1730 loss: 0.000450759311
Iter: 1731 loss: 0.000456289155
Iter: 1732 loss: 0.000450759195
Iter: 1733 loss: 0.00045046123
Iter: 1734 loss: 0.000449785206
Iter: 1735 loss: 0.000458665134
Iter: 1736 loss: 0.000449740503
Iter: 1737 loss: 0.000448934181
Iter: 1738 loss: 0.000454536959
Iter: 1739 loss: 0.000448858045
Iter: 1740 loss: 0.000448149658
Iter: 1741 loss: 0.000449148909
Iter: 1742 loss: 0.00044779983
Iter: 1743 loss: 0.000446898368
Iter: 1744 loss: 0.000451067754
Iter: 1745 loss: 0.000446731137
Iter: 1746 loss: 0.000446979015
Iter: 1747 loss: 0.000446503225
Iter: 1748 loss: 0.000446280639
Iter: 1749 loss: 0.000446119288
Iter: 1750 loss: 0.000446044171
Iter: 1751 loss: 0.00044579251
Iter: 1752 loss: 0.000445269805
Iter: 1753 loss: 0.000453922141
Iter: 1754 loss: 0.000445254962
Iter: 1755 loss: 0.000444791483
Iter: 1756 loss: 0.000449184357
Iter: 1757 loss: 0.000444772304
Iter: 1758 loss: 0.000444330915
Iter: 1759 loss: 0.000445075741
Iter: 1760 loss: 0.000444132369
Iter: 1761 loss: 0.000443573837
Iter: 1762 loss: 0.000443827215
Iter: 1763 loss: 0.000443195342
Iter: 1764 loss: 0.000442500226
Iter: 1765 loss: 0.000443516823
Iter: 1766 loss: 0.000442167366
Iter: 1767 loss: 0.00044125953
Iter: 1768 loss: 0.000446438848
Iter: 1769 loss: 0.000441135984
Iter: 1770 loss: 0.000440548902
Iter: 1771 loss: 0.000440185366
Iter: 1772 loss: 0.000439949188
Iter: 1773 loss: 0.000439050142
Iter: 1774 loss: 0.000441120821
Iter: 1775 loss: 0.000438714167
Iter: 1776 loss: 0.000437959912
Iter: 1777 loss: 0.000439149415
Iter: 1778 loss: 0.000437609589
Iter: 1779 loss: 0.000436814531
Iter: 1780 loss: 0.000439638156
Iter: 1781 loss: 0.000436614413
Iter: 1782 loss: 0.000435846538
Iter: 1783 loss: 0.000435845199
Iter: 1784 loss: 0.000435609021
Iter: 1785 loss: 0.000434909132
Iter: 1786 loss: 0.000437307492
Iter: 1787 loss: 0.000434586371
Iter: 1788 loss: 0.000433596317
Iter: 1789 loss: 0.000440805423
Iter: 1790 loss: 0.000433513924
Iter: 1791 loss: 0.000432941015
Iter: 1792 loss: 0.000434873073
Iter: 1793 loss: 0.000432785164
Iter: 1794 loss: 0.000432205969
Iter: 1795 loss: 0.000431537454
Iter: 1796 loss: 0.000431455788
Iter: 1797 loss: 0.000430551707
Iter: 1798 loss: 0.000429513428
Iter: 1799 loss: 0.000429385458
Iter: 1800 loss: 0.000428502797
Iter: 1801 loss: 0.000428428699
Iter: 1802 loss: 0.00042793178
Iter: 1803 loss: 0.000429075153
Iter: 1804 loss: 0.000427746738
Iter: 1805 loss: 0.000427088147
Iter: 1806 loss: 0.000428512198
Iter: 1807 loss: 0.000426833343
Iter: 1808 loss: 0.00042650968
Iter: 1809 loss: 0.00042859884
Iter: 1810 loss: 0.000426475832
Iter: 1811 loss: 0.00042620863
Iter: 1812 loss: 0.000429799198
Iter: 1813 loss: 0.000426207785
Iter: 1814 loss: 0.00042605144
Iter: 1815 loss: 0.00042800745
Iter: 1816 loss: 0.000426049
Iter: 1817 loss: 0.000425937673
Iter: 1818 loss: 0.000425640639
Iter: 1819 loss: 0.000427769468
Iter: 1820 loss: 0.000425575417
Iter: 1821 loss: 0.000425238453
Iter: 1822 loss: 0.000425868493
Iter: 1823 loss: 0.00042509276
Iter: 1824 loss: 0.000424567144
Iter: 1825 loss: 0.000426748942
Iter: 1826 loss: 0.000424455851
Iter: 1827 loss: 0.000424028054
Iter: 1828 loss: 0.00042477707
Iter: 1829 loss: 0.000423837657
Iter: 1830 loss: 0.000423407968
Iter: 1831 loss: 0.000422809535
Iter: 1832 loss: 0.000422785175
Iter: 1833 loss: 0.000422293815
Iter: 1834 loss: 0.00042289577
Iter: 1835 loss: 0.000422039127
Iter: 1836 loss: 0.000421538891
Iter: 1837 loss: 0.000428707863
Iter: 1838 loss: 0.000421538018
Iter: 1839 loss: 0.000421218341
Iter: 1840 loss: 0.000422155019
Iter: 1841 loss: 0.000421119476
Iter: 1842 loss: 0.000420873286
Iter: 1843 loss: 0.000422279583
Iter: 1844 loss: 0.000420838391
Iter: 1845 loss: 0.000420750584
Iter: 1846 loss: 0.000420730095
Iter: 1847 loss: 0.000420647062
Iter: 1848 loss: 0.000420818978
Iter: 1849 loss: 0.000420614815
Iter: 1850 loss: 0.000420481927
Iter: 1851 loss: 0.00042017136
Iter: 1852 loss: 0.000423851307
Iter: 1853 loss: 0.000420143682
Iter: 1854 loss: 0.000419908669
Iter: 1855 loss: 0.000419734803
Iter: 1856 loss: 0.000419656077
Iter: 1857 loss: 0.000419353601
Iter: 1858 loss: 0.000419353077
Iter: 1859 loss: 0.000419136079
Iter: 1860 loss: 0.000419783348
Iter: 1861 loss: 0.000419070566
Iter: 1862 loss: 0.000418777228
Iter: 1863 loss: 0.000418717042
Iter: 1864 loss: 0.000418524665
Iter: 1865 loss: 0.00041824652
Iter: 1866 loss: 0.000418258162
Iter: 1867 loss: 0.000418026175
Iter: 1868 loss: 0.000417771
Iter: 1869 loss: 0.000418484793
Iter: 1870 loss: 0.00041768857
Iter: 1871 loss: 0.000417458912
Iter: 1872 loss: 0.000418050506
Iter: 1873 loss: 0.000417378935
Iter: 1874 loss: 0.000417123403
Iter: 1875 loss: 0.000417415
Iter: 1876 loss: 0.000416985131
Iter: 1877 loss: 0.000416870927
Iter: 1878 loss: 0.000416860887
Iter: 1879 loss: 0.000416766619
Iter: 1880 loss: 0.00041800848
Iter: 1881 loss: 0.000416766648
Iter: 1882 loss: 0.000416699739
Iter: 1883 loss: 0.000416559633
Iter: 1884 loss: 0.000418929267
Iter: 1885 loss: 0.0004165555
Iter: 1886 loss: 0.000416444207
Iter: 1887 loss: 0.000416295195
Iter: 1888 loss: 0.000416287337
Iter: 1889 loss: 0.00041614176
Iter: 1890 loss: 0.000417906151
Iter: 1891 loss: 0.000416139868
Iter: 1892 loss: 0.000416025432
Iter: 1893 loss: 0.000416022725
Iter: 1894 loss: 0.000415932474
Iter: 1895 loss: 0.000415726041
Iter: 1896 loss: 0.000416538795
Iter: 1897 loss: 0.000415678485
Iter: 1898 loss: 0.000415503688
Iter: 1899 loss: 0.00041572738
Iter: 1900 loss: 0.000415413
Iter: 1901 loss: 0.000415293849
Iter: 1902 loss: 0.000415429182
Iter: 1903 loss: 0.00041523017
Iter: 1904 loss: 0.000415137445
Iter: 1905 loss: 0.000414974522
Iter: 1906 loss: 0.000414974696
Iter: 1907 loss: 0.000414804817
Iter: 1908 loss: 0.000416404306
Iter: 1909 loss: 0.000414798327
Iter: 1910 loss: 0.000414693262
Iter: 1911 loss: 0.000414999551
Iter: 1912 loss: 0.000414660375
Iter: 1913 loss: 0.000414701586
Iter: 1914 loss: 0.000414596318
Iter: 1915 loss: 0.000414537382
Iter: 1916 loss: 0.000414439
Iter: 1917 loss: 0.000414438429
Iter: 1918 loss: 0.000414345937
Iter: 1919 loss: 0.000414201699
Iter: 1920 loss: 0.000414200214
Iter: 1921 loss: 0.000414079055
Iter: 1922 loss: 0.000415723247
Iter: 1923 loss: 0.000414077949
Iter: 1924 loss: 0.000413983536
Iter: 1925 loss: 0.00041394314
Iter: 1926 loss: 0.000413893635
Iter: 1927 loss: 0.000413716713
Iter: 1928 loss: 0.000413635775
Iter: 1929 loss: 0.000413547881
Iter: 1930 loss: 0.000413377886
Iter: 1931 loss: 0.000413375587
Iter: 1932 loss: 0.000413248141
Iter: 1933 loss: 0.000413988309
Iter: 1934 loss: 0.000413231464
Iter: 1935 loss: 0.000413136964
Iter: 1936 loss: 0.000412930618
Iter: 1937 loss: 0.000416048861
Iter: 1938 loss: 0.000412922353
Iter: 1939 loss: 0.000412744528
Iter: 1940 loss: 0.000413246686
Iter: 1941 loss: 0.000412689464
Iter: 1942 loss: 0.000412498252
Iter: 1943 loss: 0.000413680158
Iter: 1944 loss: 0.00041247491
Iter: 1945 loss: 0.000412363239
Iter: 1946 loss: 0.000412358408
Iter: 1947 loss: 0.00041231676
Iter: 1948 loss: 0.000412253954
Iter: 1949 loss: 0.000412253081
Iter: 1950 loss: 0.000412152789
Iter: 1951 loss: 0.000411964313
Iter: 1952 loss: 0.000416260387
Iter: 1953 loss: 0.000411964953
Iter: 1954 loss: 0.000411795452
Iter: 1955 loss: 0.000412811904
Iter: 1956 loss: 0.000411776069
Iter: 1957 loss: 0.000411596266
Iter: 1958 loss: 0.000411883491
Iter: 1959 loss: 0.000411514193
Iter: 1960 loss: 0.000411320798
Iter: 1961 loss: 0.000411640678
Iter: 1962 loss: 0.000411230489
Iter: 1963 loss: 0.000411095156
Iter: 1964 loss: 0.00041231286
Iter: 1965 loss: 0.000411089393
Iter: 1966 loss: 0.000410981826
Iter: 1967 loss: 0.000411907386
Iter: 1968 loss: 0.000410977489
Iter: 1969 loss: 0.000410902256
Iter: 1970 loss: 0.000410941313
Iter: 1971 loss: 0.000410851848
Iter: 1972 loss: 0.000410760636
Iter: 1973 loss: 0.000410774606
Iter: 1974 loss: 0.000410691835
Iter: 1975 loss: 0.000410558307
Iter: 1976 loss: 0.000411040965
Iter: 1977 loss: 0.00041052571
Iter: 1978 loss: 0.000410505716
Iter: 1979 loss: 0.000410462846
Iter: 1980 loss: 0.000410430366
Iter: 1981 loss: 0.000410352775
Iter: 1982 loss: 0.000411119865
Iter: 1983 loss: 0.000410341978
Iter: 1984 loss: 0.00041014771
Iter: 1985 loss: 0.000410817214
Iter: 1986 loss: 0.000410096545
Iter: 1987 loss: 0.00040997169
Iter: 1988 loss: 0.000410577137
Iter: 1989 loss: 0.000409949163
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3
+ date
Tue Oct 27 16:59:47 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 2 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97d0c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97da7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97d0c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97cd61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97c35620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97befe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97ba98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97bdb6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97b706a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97b822f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97b38bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97af4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97afd510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97afd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97ac99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97ac9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97ac92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97a3c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97a5cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97a6f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b97a12840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b979af510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b979857b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b9792e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b9793d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b9795f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b979189d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b978c5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b978c5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b978e3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b978c5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b9784a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b9784a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b977f1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b977f1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b977df268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0252579898
Iter: 2 loss: 1.69714725
Iter: 3 loss: 1.68849432
Iter: 4 loss: 1.19750214
Iter: 5 loss: 1.18926513
Iter: 6 loss: 0.84691155
Iter: 7 loss: 0.838602543
Iter: 8 loss: 0.593278527
Iter: 9 loss: 0.584241807
Iter: 10 loss: 0.401140511
Iter: 11 loss: 0.39044714
Iter: 12 loss: 0.252191931
Iter: 13 loss: 0.240241215
Iter: 14 loss: 0.143918365
Iter: 15 loss: 0.132717609
Iter: 16 loss: 0.0715889707
Iter: 17 loss: 0.0628032684
Iter: 18 loss: 0.0300281532
Iter: 19 loss: 0.0256693028
Iter: 20 loss: 0.0135444859
Iter: 21 loss: 0.0128512606
Iter: 22 loss: 0.0122432867
Iter: 23 loss: 0.0107686222
Iter: 24 loss: 1917.04749
Iter: 25 loss: 0.0107686147
Iter: 26 loss: 0.00992897898
Iter: 27 loss: 0.0423097387
Iter: 28 loss: 0.00990466401
Iter: 29 loss: 0.00828930549
Iter: 30 loss: 0.00828922726
Iter: 31 loss: 0.00689492468
Iter: 32 loss: 0.0118085621
Iter: 33 loss: 0.00685923966
Iter: 34 loss: 0.00641107839
Iter: 35 loss: 0.00865268707
Iter: 36 loss: 0.00626198435
Iter: 37 loss: 0.00592405349
Iter: 38 loss: 0.0106088929
Iter: 39 loss: 0.00590647571
Iter: 40 loss: 0.00558049232
Iter: 41 loss: 0.00608482584
Iter: 42 loss: 0.00544831576
Iter: 43 loss: 0.00514320098
Iter: 44 loss: 0.00513936114
Iter: 45 loss: 0.00492658
Iter: 46 loss: 0.00468647853
Iter: 47 loss: 0.00446524378
Iter: 48 loss: 0.00439797947
Iter: 49 loss: 0.00415287307
Iter: 50 loss: 0.00392358052
Iter: 51 loss: 0.00388213387
Iter: 52 loss: 0.00354451244
Iter: 53 loss: 0.0036842227
Iter: 54 loss: 0.00329786399
Iter: 55 loss: 0.00301823439
Iter: 56 loss: 0.00473922398
Iter: 57 loss: 0.00298435753
Iter: 58 loss: 0.00280319387
Iter: 59 loss: 0.00371229858
Iter: 60 loss: 0.00277794804
Iter: 61 loss: 0.00262410054
Iter: 62 loss: 0.00269664079
Iter: 63 loss: 0.00252126553
Iter: 64 loss: 0.00235033943
Iter: 65 loss: 0.00265669497
Iter: 66 loss: 0.00228551589
Iter: 67 loss: 0.00214233249
Iter: 68 loss: 0.0027601351
Iter: 69 loss: 0.00211048056
Iter: 70 loss: 0.00202265126
Iter: 71 loss: 0.0020798943
Iter: 72 loss: 0.00196508178
Iter: 73 loss: 0.00190939673
Iter: 74 loss: 0.00188713172
Iter: 75 loss: 0.00183197495
Iter: 76 loss: 0.00181503035
Iter: 77 loss: 0.00178183569
Iter: 78 loss: 0.00169109728
Iter: 79 loss: 0.00174772809
Iter: 80 loss: 0.00163479149
Iter: 81 loss: 0.00169500592
Iter: 82 loss: 0.00159324217
Iter: 83 loss: 0.00156284915
Iter: 84 loss: 0.00152276829
Iter: 85 loss: 0.00152031356
Iter: 86 loss: 0.00143833307
Iter: 87 loss: 0.00150054775
Iter: 88 loss: 0.00138971617
Iter: 89 loss: 0.00133047323
Iter: 90 loss: 0.00147986878
Iter: 91 loss: 0.00130859413
Iter: 92 loss: 0.00124601834
Iter: 93 loss: 0.0015706952
Iter: 94 loss: 0.00123675936
Iter: 95 loss: 0.00119014841
Iter: 96 loss: 0.00113642775
Iter: 97 loss: 0.00113042863
Iter: 98 loss: 0.00109071261
Iter: 99 loss: 0.00126393035
Iter: 100 loss: 0.00108360581
Iter: 101 loss: 0.00104927074
Iter: 102 loss: 0.0015969302
Iter: 103 loss: 0.00104912429
Iter: 104 loss: 0.00103187189
Iter: 105 loss: 0.00115522509
Iter: 106 loss: 0.00103069388
Iter: 107 loss: 0.00102104386
Iter: 108 loss: 0.00100434979
Iter: 109 loss: 0.00100432755
Iter: 110 loss: 0.000983054284
Iter: 111 loss: 0.000972030743
Iter: 112 loss: 0.000962225837
Iter: 113 loss: 0.000932191
Iter: 114 loss: 0.000926544191
Iter: 115 loss: 0.000905984838
Iter: 116 loss: 0.000893458375
Iter: 117 loss: 0.00088558509
Iter: 118 loss: 0.000869525131
Iter: 119 loss: 0.000894952
Iter: 120 loss: 0.000861624372
Iter: 121 loss: 0.000844381168
Iter: 122 loss: 0.000864950707
Iter: 123 loss: 0.000835239189
Iter: 124 loss: 0.000817547319
Iter: 125 loss: 0.00105693203
Iter: 126 loss: 0.000817424036
Iter: 127 loss: 0.000806249795
Iter: 128 loss: 0.000788772828
Iter: 129 loss: 0.000788571488
Iter: 130 loss: 0.000769467733
Iter: 131 loss: 0.000894246274
Iter: 132 loss: 0.000767524121
Iter: 133 loss: 0.000752111548
Iter: 134 loss: 0.000800957787
Iter: 135 loss: 0.000747524668
Iter: 136 loss: 0.000743160374
Iter: 137 loss: 0.000742282311
Iter: 138 loss: 0.000735687616
Iter: 139 loss: 0.000753664644
Iter: 140 loss: 0.000733619207
Iter: 141 loss: 0.000730447238
Iter: 142 loss: 0.000726598722
Iter: 143 loss: 0.00072622241
Iter: 144 loss: 0.000719005882
Iter: 145 loss: 0.000742626376
Iter: 146 loss: 0.000716961222
Iter: 147 loss: 0.000706678955
Iter: 148 loss: 0.000774245884
Iter: 149 loss: 0.000705710147
Iter: 150 loss: 0.000694843882
Iter: 151 loss: 0.000736713118
Iter: 152 loss: 0.00069214229
Iter: 153 loss: 0.000685249455
Iter: 154 loss: 0.000672408147
Iter: 155 loss: 0.000941515784
Iter: 156 loss: 0.000672376482
Iter: 157 loss: 0.000657321361
Iter: 158 loss: 0.000752949622
Iter: 159 loss: 0.000655703712
Iter: 160 loss: 0.000647227
Iter: 161 loss: 0.000676140189
Iter: 162 loss: 0.000644947169
Iter: 163 loss: 0.000639123842
Iter: 164 loss: 0.000639125123
Iter: 165 loss: 0.000635523233
Iter: 166 loss: 0.000629955146
Iter: 167 loss: 0.000629876624
Iter: 168 loss: 0.000632034964
Iter: 169 loss: 0.000627141
Iter: 170 loss: 0.000623737928
Iter: 171 loss: 0.000649499823
Iter: 172 loss: 0.000623506843
Iter: 173 loss: 0.000622147694
Iter: 174 loss: 0.000618606457
Iter: 175 loss: 0.000646164175
Iter: 176 loss: 0.000617929501
Iter: 177 loss: 0.000613746699
Iter: 178 loss: 0.000611550699
Iter: 179 loss: 0.000609635
Iter: 180 loss: 0.000604808447
Iter: 181 loss: 0.000657929922
Iter: 182 loss: 0.000604712055
Iter: 183 loss: 0.000601262262
Iter: 184 loss: 0.000638649
Iter: 185 loss: 0.00060119672
Iter: 186 loss: 0.000598452869
Iter: 187 loss: 0.000612468808
Iter: 188 loss: 0.000598003156
Iter: 189 loss: 0.000595663674
Iter: 190 loss: 0.00059201062
Iter: 191 loss: 0.000591968303
Iter: 192 loss: 0.000587342074
Iter: 193 loss: 0.000609668903
Iter: 194 loss: 0.000586519542
Iter: 195 loss: 0.000582911773
Iter: 196 loss: 0.000584513298
Iter: 197 loss: 0.000580457039
Iter: 198 loss: 0.000576221384
Iter: 199 loss: 0.000609595
Iter: 200 loss: 0.000575926038
Iter: 201 loss: 0.000572640216
Iter: 202 loss: 0.000581663451
Iter: 203 loss: 0.000571578392
Iter: 204 loss: 0.000568552641
Iter: 205 loss: 0.000570894
Iter: 206 loss: 0.000566715724
Iter: 207 loss: 0.000570639037
Iter: 208 loss: 0.000565737544
Iter: 209 loss: 0.000565038
Iter: 210 loss: 0.000562787172
Iter: 211 loss: 0.000564833288
Iter: 212 loss: 0.000560939603
Iter: 213 loss: 0.000557902327
Iter: 214 loss: 0.000557487074
Iter: 215 loss: 0.000555358944
Iter: 216 loss: 0.000553346821
Iter: 217 loss: 0.000550955243
Iter: 218 loss: 0.000550697325
Iter: 219 loss: 0.00054891035
Iter: 220 loss: 0.000549792137
Iter: 221 loss: 0.000547726406
Iter: 222 loss: 0.000546438619
Iter: 223 loss: 0.00054645515
Iter: 224 loss: 0.000545409566
Iter: 225 loss: 0.000543260539
Iter: 226 loss: 0.000542151625
Iter: 227 loss: 0.000541152549
Iter: 228 loss: 0.00053791859
Iter: 229 loss: 0.000541228685
Iter: 230 loss: 0.000536130043
Iter: 231 loss: 0.000533829
Iter: 232 loss: 0.000545689138
Iter: 233 loss: 0.000533452956
Iter: 234 loss: 0.000531817554
Iter: 235 loss: 0.000532006728
Iter: 236 loss: 0.000530558173
Iter: 237 loss: 0.00052837457
Iter: 238 loss: 0.000531219412
Iter: 239 loss: 0.000527271302
Iter: 240 loss: 0.000525530602
Iter: 241 loss: 0.000525359297
Iter: 242 loss: 0.000524086936
Iter: 243 loss: 0.000522527902
Iter: 244 loss: 0.000522504561
Iter: 245 loss: 0.000521250884
Iter: 246 loss: 0.00052784459
Iter: 247 loss: 0.000521061767
Iter: 248 loss: 0.000520151749
Iter: 249 loss: 0.00052083272
Iter: 250 loss: 0.000519591966
Iter: 251 loss: 0.000518827175
Iter: 252 loss: 0.000518828048
Iter: 253 loss: 0.000518194109
Iter: 254 loss: 0.000516875705
Iter: 255 loss: 0.000539679429
Iter: 256 loss: 0.00051684503
Iter: 257 loss: 0.000515002408
Iter: 258 loss: 0.000514040818
Iter: 259 loss: 0.000513193896
Iter: 260 loss: 0.000511020888
Iter: 261 loss: 0.000533163897
Iter: 262 loss: 0.000510962447
Iter: 263 loss: 0.000509470818
Iter: 264 loss: 0.000516362
Iter: 265 loss: 0.000509187172
Iter: 266 loss: 0.000507622783
Iter: 267 loss: 0.000507919642
Iter: 268 loss: 0.000506458222
Iter: 269 loss: 0.000504806812
Iter: 270 loss: 0.000508854282
Iter: 271 loss: 0.000504222757
Iter: 272 loss: 0.000502564129
Iter: 273 loss: 0.00051640626
Iter: 274 loss: 0.000502459938
Iter: 275 loss: 0.000501212664
Iter: 276 loss: 0.00050113257
Iter: 277 loss: 0.000500191352
Iter: 278 loss: 0.000499603106
Iter: 279 loss: 0.000499265327
Iter: 280 loss: 0.000498523121
Iter: 281 loss: 0.000498244073
Iter: 282 loss: 0.000497836445
Iter: 283 loss: 0.000497116824
Iter: 284 loss: 0.000502816052
Iter: 285 loss: 0.000497065717
Iter: 286 loss: 0.00049655186
Iter: 287 loss: 0.000496611348
Iter: 288 loss: 0.000496158958
Iter: 289 loss: 0.000495379383
Iter: 290 loss: 0.000494925422
Iter: 291 loss: 0.000494594045
Iter: 292 loss: 0.000493568776
Iter: 293 loss: 0.00049684383
Iter: 294 loss: 0.000493277097
Iter: 295 loss: 0.000492449675
Iter: 296 loss: 0.000497140107
Iter: 297 loss: 0.000492337917
Iter: 298 loss: 0.000491367595
Iter: 299 loss: 0.000493179075
Iter: 300 loss: 0.000490952632
Iter: 301 loss: 0.000489982136
Iter: 302 loss: 0.000490352861
Iter: 303 loss: 0.000489310478
Iter: 304 loss: 0.000488324091
Iter: 305 loss: 0.000490026083
Iter: 306 loss: 0.000487886311
Iter: 307 loss: 0.000486614037
Iter: 308 loss: 0.000492728082
Iter: 309 loss: 0.000486385921
Iter: 310 loss: 0.000485511264
Iter: 311 loss: 0.000495827175
Iter: 312 loss: 0.000485500845
Iter: 313 loss: 0.0004848229
Iter: 314 loss: 0.00048758529
Iter: 315 loss: 0.000484670774
Iter: 316 loss: 0.000484236109
Iter: 317 loss: 0.000485151
Iter: 318 loss: 0.000484066462
Iter: 319 loss: 0.000483454147
Iter: 320 loss: 0.000483190321
Iter: 321 loss: 0.000482872943
Iter: 322 loss: 0.000481996598
Iter: 323 loss: 0.000482366187
Iter: 324 loss: 0.000481393
Iter: 325 loss: 0.000480214832
Iter: 326 loss: 0.000480332266
Iter: 327 loss: 0.000479310052
Iter: 328 loss: 0.00047779482
Iter: 329 loss: 0.000480610179
Iter: 330 loss: 0.000477146677
Iter: 331 loss: 0.000476066751
Iter: 332 loss: 0.000489707803
Iter: 333 loss: 0.000476057758
Iter: 334 loss: 0.000474879897
Iter: 335 loss: 0.000476780726
Iter: 336 loss: 0.000474332715
Iter: 337 loss: 0.000473175838
Iter: 338 loss: 0.000472769752
Iter: 339 loss: 0.000472115469
Iter: 340 loss: 0.000470565632
Iter: 341 loss: 0.000475352455
Iter: 342 loss: 0.000470111379
Iter: 343 loss: 0.000468436221
Iter: 344 loss: 0.000473150983
Iter: 345 loss: 0.000467895297
Iter: 346 loss: 0.000467277132
Iter: 347 loss: 0.000466878526
Iter: 348 loss: 0.000466259778
Iter: 349 loss: 0.00046583786
Iter: 350 loss: 0.000465607911
Iter: 351 loss: 0.000464668236
Iter: 352 loss: 0.00046682934
Iter: 353 loss: 0.000464325916
Iter: 354 loss: 0.000463243137
Iter: 355 loss: 0.00046185439
Iter: 356 loss: 0.000461756543
Iter: 357 loss: 0.000460320618
Iter: 358 loss: 0.000464409357
Iter: 359 loss: 0.000459868927
Iter: 360 loss: 0.000458334427
Iter: 361 loss: 0.000463243196
Iter: 362 loss: 0.000457896793
Iter: 363 loss: 0.000456750859
Iter: 364 loss: 0.000456746086
Iter: 365 loss: 0.000455833302
Iter: 366 loss: 0.000453967892
Iter: 367 loss: 0.000457520422
Iter: 368 loss: 0.000453193585
Iter: 369 loss: 0.000451568631
Iter: 370 loss: 0.000466358295
Iter: 371 loss: 0.000451496075
Iter: 372 loss: 0.000449927349
Iter: 373 loss: 0.00045783128
Iter: 374 loss: 0.000449659972
Iter: 375 loss: 0.000448482693
Iter: 376 loss: 0.000447649742
Iter: 377 loss: 0.000447237195
Iter: 378 loss: 0.000449383166
Iter: 379 loss: 0.000446822087
Iter: 380 loss: 0.000446422782
Iter: 381 loss: 0.000446865277
Iter: 382 loss: 0.000446208811
Iter: 383 loss: 0.000445826736
Iter: 384 loss: 0.000445645128
Iter: 385 loss: 0.000445459678
Iter: 386 loss: 0.000444952835
Iter: 387 loss: 0.000446310267
Iter: 388 loss: 0.00044478738
Iter: 389 loss: 0.000444265315
Iter: 390 loss: 0.000443924975
Iter: 391 loss: 0.000443725119
Iter: 392 loss: 0.000442988385
Iter: 393 loss: 0.00044408234
Iter: 394 loss: 0.000442636199
Iter: 395 loss: 0.000441830431
Iter: 396 loss: 0.000443615892
Iter: 397 loss: 0.000441522017
Iter: 398 loss: 0.000440349104
Iter: 399 loss: 0.000439655705
Iter: 400 loss: 0.000439164636
Iter: 401 loss: 0.000437699608
Iter: 402 loss: 0.000447450322
Iter: 403 loss: 0.000437549228
Iter: 404 loss: 0.000436300645
Iter: 405 loss: 0.000437952956
Iter: 406 loss: 0.000435673603
Iter: 407 loss: 0.000434721936
Iter: 408 loss: 0.000434711314
Iter: 409 loss: 0.000434177811
Iter: 410 loss: 0.000436720875
Iter: 411 loss: 0.000434085901
Iter: 412 loss: 0.00043354131
Iter: 413 loss: 0.000437422743
Iter: 414 loss: 0.000433491659
Iter: 415 loss: 0.00043318703
Iter: 416 loss: 0.000432691275
Iter: 417 loss: 0.000432688452
Iter: 418 loss: 0.00043198897
Iter: 419 loss: 0.000433192938
Iter: 420 loss: 0.000431676337
Iter: 421 loss: 0.000430915068
Iter: 422 loss: 0.000433264824
Iter: 423 loss: 0.000430693064
Iter: 424 loss: 0.000430117449
Iter: 425 loss: 0.000429769629
Iter: 426 loss: 0.000429532636
Iter: 427 loss: 0.000428608415
Iter: 428 loss: 0.000431029039
Iter: 429 loss: 0.000428296509
Iter: 430 loss: 0.000427147141
Iter: 431 loss: 0.000430362445
Iter: 432 loss: 0.000426781
Iter: 433 loss: 0.000425893842
Iter: 434 loss: 0.000428223168
Iter: 435 loss: 0.000425593404
Iter: 436 loss: 0.000424646016
Iter: 437 loss: 0.000425653241
Iter: 438 loss: 0.000424123806
Iter: 439 loss: 0.000423368299
Iter: 440 loss: 0.000423366728
Iter: 441 loss: 0.000422958168
Iter: 442 loss: 0.000426663435
Iter: 443 loss: 0.000422938581
Iter: 444 loss: 0.000422633253
Iter: 445 loss: 0.000425911538
Iter: 446 loss: 0.000422625948
Iter: 447 loss: 0.000422433484
Iter: 448 loss: 0.000422070618
Iter: 449 loss: 0.000430061249
Iter: 450 loss: 0.000422068144
Iter: 451 loss: 0.000421641977
Iter: 452 loss: 0.000422357291
Iter: 453 loss: 0.000421451
Iter: 454 loss: 0.000420980854
Iter: 455 loss: 0.000422155048
Iter: 456 loss: 0.000420816039
Iter: 457 loss: 0.000420389813
Iter: 458 loss: 0.000420420023
Iter: 459 loss: 0.000420057506
Iter: 460 loss: 0.000419370655
Iter: 461 loss: 0.000420062046
Iter: 462 loss: 0.000418984448
Iter: 463 loss: 0.000418174313
Iter: 464 loss: 0.000422203157
Iter: 465 loss: 0.000418036245
Iter: 466 loss: 0.00041727096
Iter: 467 loss: 0.000420072756
Iter: 468 loss: 0.000417078787
Iter: 469 loss: 0.000416409166
Iter: 470 loss: 0.000415797229
Iter: 471 loss: 0.000415631512
Iter: 472 loss: 0.000414887851
Iter: 473 loss: 0.000414850598
Iter: 474 loss: 0.000414371549
Iter: 475 loss: 0.000417740899
Iter: 476 loss: 0.000414327951
Iter: 477 loss: 0.000413925125
Iter: 478 loss: 0.000416845898
Iter: 479 loss: 0.000413889589
Iter: 480 loss: 0.000413597649
Iter: 481 loss: 0.000413207395
Iter: 482 loss: 0.000413186412
Iter: 483 loss: 0.000412707246
Iter: 484 loss: 0.000413671543
Iter: 485 loss: 0.000412511639
Iter: 486 loss: 0.00041194
Iter: 487 loss: 0.00041267596
Iter: 488 loss: 0.000411649351
Iter: 489 loss: 0.000410986191
Iter: 490 loss: 0.000411184243
Iter: 491 loss: 0.000410508772
Iter: 492 loss: 0.000409550266
Iter: 493 loss: 0.000410313194
Iter: 494 loss: 0.000408973923
Iter: 495 loss: 0.000407837884
Iter: 496 loss: 0.000412029156
Iter: 497 loss: 0.00040755645
Iter: 498 loss: 0.000406370033
Iter: 499 loss: 0.000411212561
Iter: 500 loss: 0.000406110659
Iter: 501 loss: 0.000405086321
Iter: 502 loss: 0.000405905768
Iter: 503 loss: 0.000404469785
Iter: 504 loss: 0.000403367914
Iter: 505 loss: 0.000408828666
Iter: 506 loss: 0.00040318229
Iter: 507 loss: 0.000402515259
Iter: 508 loss: 0.000402503589
Iter: 509 loss: 0.000402027421
Iter: 510 loss: 0.000407138257
Iter: 511 loss: 0.000402018079
Iter: 512 loss: 0.000401691534
Iter: 513 loss: 0.00040124575
Iter: 514 loss: 0.000401224534
Iter: 515 loss: 0.000400736462
Iter: 516 loss: 0.000400835968
Iter: 517 loss: 0.00040037412
Iter: 518 loss: 0.000399602432
Iter: 519 loss: 0.00039984897
Iter: 520 loss: 0.000399050245
Iter: 521 loss: 0.000397821626
Iter: 522 loss: 0.000400480116
Iter: 523 loss: 0.000397346361
Iter: 524 loss: 0.000396362622
Iter: 525 loss: 0.000399493583
Iter: 526 loss: 0.000396078
Iter: 527 loss: 0.000395140611
Iter: 528 loss: 0.000396070536
Iter: 529 loss: 0.000394613191
Iter: 530 loss: 0.000393642928
Iter: 531 loss: 0.000403005688
Iter: 532 loss: 0.00039360582
Iter: 533 loss: 0.000392820104
Iter: 534 loss: 0.000393015333
Iter: 535 loss: 0.000392246031
Iter: 536 loss: 0.000391236041
Iter: 537 loss: 0.000395111565
Iter: 538 loss: 0.000390994537
Iter: 539 loss: 0.000390421192
Iter: 540 loss: 0.000390374189
Iter: 541 loss: 0.000390019413
Iter: 542 loss: 0.000394199393
Iter: 543 loss: 0.000390013243
Iter: 544 loss: 0.000389769033
Iter: 545 loss: 0.000389298308
Iter: 546 loss: 0.000399007113
Iter: 547 loss: 0.000389296416
Iter: 548 loss: 0.000388635788
Iter: 549 loss: 0.000388766581
Iter: 550 loss: 0.000388144166
Iter: 551 loss: 0.000387167296
Iter: 552 loss: 0.000390216243
Iter: 553 loss: 0.000386885
Iter: 554 loss: 0.000386026455
Iter: 555 loss: 0.000387341192
Iter: 556 loss: 0.000385618885
Iter: 557 loss: 0.000384813698
Iter: 558 loss: 0.000386916829
Iter: 559 loss: 0.000384542043
Iter: 560 loss: 0.000383694918
Iter: 561 loss: 0.000383776933
Iter: 562 loss: 0.000383040169
Iter: 563 loss: 0.000381921302
Iter: 564 loss: 0.000390306202
Iter: 565 loss: 0.000381834
Iter: 566 loss: 0.000380931742
Iter: 567 loss: 0.000382840866
Iter: 568 loss: 0.000380577636
Iter: 569 loss: 0.000379664183
Iter: 570 loss: 0.00038066128
Iter: 571 loss: 0.000379168428
Iter: 572 loss: 0.000378675875
Iter: 573 loss: 0.000378577213
Iter: 574 loss: 0.00037819444
Iter: 575 loss: 0.000382576021
Iter: 576 loss: 0.000378188095
Iter: 577 loss: 0.000377903081
Iter: 578 loss: 0.00037728966
Iter: 579 loss: 0.000387169188
Iter: 580 loss: 0.000377268763
Iter: 581 loss: 0.00037657225
Iter: 582 loss: 0.000378030818
Iter: 583 loss: 0.000376295706
Iter: 584 loss: 0.000375626143
Iter: 585 loss: 0.000376855693
Iter: 586 loss: 0.0003753372
Iter: 587 loss: 0.000374606694
Iter: 588 loss: 0.000376227894
Iter: 589 loss: 0.000374328403
Iter: 590 loss: 0.000373706047
Iter: 591 loss: 0.000374731404
Iter: 592 loss: 0.000373421411
Iter: 593 loss: 0.000372605
Iter: 594 loss: 0.000372557668
Iter: 595 loss: 0.000371939241
Iter: 596 loss: 0.000370864174
Iter: 597 loss: 0.00037898455
Iter: 598 loss: 0.000370779366
Iter: 599 loss: 0.000369902875
Iter: 600 loss: 0.000372674258
Iter: 601 loss: 0.000369648595
Iter: 602 loss: 0.000368903129
Iter: 603 loss: 0.000369965797
Iter: 604 loss: 0.000368536741
Iter: 605 loss: 0.000368082081
Iter: 606 loss: 0.000368040171
Iter: 607 loss: 0.00036774468
Iter: 608 loss: 0.000372232404
Iter: 609 loss: 0.000367744244
Iter: 610 loss: 0.000367538829
Iter: 611 loss: 0.000367150118
Iter: 612 loss: 0.000375416828
Iter: 613 loss: 0.000367148838
Iter: 614 loss: 0.000366708962
Iter: 615 loss: 0.000367867062
Iter: 616 loss: 0.000366561173
Iter: 617 loss: 0.000366132124
Iter: 618 loss: 0.000366672321
Iter: 619 loss: 0.00036591012
Iter: 620 loss: 0.000365363201
Iter: 621 loss: 0.000366302
Iter: 622 loss: 0.000365117419
Iter: 623 loss: 0.000364531123
Iter: 624 loss: 0.000365043146
Iter: 625 loss: 0.000364187756
Iter: 626 loss: 0.000363400031
Iter: 627 loss: 0.000364080712
Iter: 628 loss: 0.000362935651
Iter: 629 loss: 0.000361928047
Iter: 630 loss: 0.000366253109
Iter: 631 loss: 0.000361721148
Iter: 632 loss: 0.000360971433
Iter: 633 loss: 0.000367107743
Iter: 634 loss: 0.000360924227
Iter: 635 loss: 0.000360371545
Iter: 636 loss: 0.000360258593
Iter: 637 loss: 0.000359893544
Iter: 638 loss: 0.000359547761
Iter: 639 loss: 0.000359485217
Iter: 640 loss: 0.000359229482
Iter: 641 loss: 0.000362530234
Iter: 642 loss: 0.000359228085
Iter: 643 loss: 0.00035902916
Iter: 644 loss: 0.000358631776
Iter: 645 loss: 0.000366267253
Iter: 646 loss: 0.000358626305
Iter: 647 loss: 0.000358195
Iter: 648 loss: 0.000359227357
Iter: 649 loss: 0.000358039804
Iter: 650 loss: 0.000357605662
Iter: 651 loss: 0.000357954588
Iter: 652 loss: 0.000357343
Iter: 653 loss: 0.000356766803
Iter: 654 loss: 0.000357769546
Iter: 655 loss: 0.000356512348
Iter: 656 loss: 0.000355895783
Iter: 657 loss: 0.000356729463
Iter: 658 loss: 0.000355584285
Iter: 659 loss: 0.000354788208
Iter: 660 loss: 0.000355147175
Iter: 661 loss: 0.000354247866
Iter: 662 loss: 0.000353200157
Iter: 663 loss: 0.000358347024
Iter: 664 loss: 0.000353017531
Iter: 665 loss: 0.0003521943
Iter: 666 loss: 0.000357130688
Iter: 667 loss: 0.000352089846
Iter: 668 loss: 0.000351419323
Iter: 669 loss: 0.000352076662
Iter: 670 loss: 0.000351038907
Iter: 671 loss: 0.000350540562
Iter: 672 loss: 0.000350539107
Iter: 673 loss: 0.000350215792
Iter: 674 loss: 0.000350215647
Iter: 675 loss: 0.000349984912
Iter: 676 loss: 0.00034953194
Iter: 677 loss: 0.00035838387
Iter: 678 loss: 0.000349527865
Iter: 679 loss: 0.000349034643
Iter: 680 loss: 0.000350638467
Iter: 681 loss: 0.000348894624
Iter: 682 loss: 0.000348434522
Iter: 683 loss: 0.000348648726
Iter: 684 loss: 0.000348125293
Iter: 685 loss: 0.000347452791
Iter: 686 loss: 0.00034889282
Iter: 687 loss: 0.000347188761
Iter: 688 loss: 0.000346486748
Iter: 689 loss: 0.000346684421
Iter: 690 loss: 0.000345980981
Iter: 691 loss: 0.000345064735
Iter: 692 loss: 0.000347503228
Iter: 693 loss: 0.000344758213
Iter: 694 loss: 0.000343763444
Iter: 695 loss: 0.000345292065
Iter: 696 loss: 0.000343294
Iter: 697 loss: 0.000342405081
Iter: 698 loss: 0.00035246191
Iter: 699 loss: 0.000342388637
Iter: 700 loss: 0.000341764826
Iter: 701 loss: 0.000342008745
Iter: 702 loss: 0.000341330684
Iter: 703 loss: 0.000340809871
Iter: 704 loss: 0.000340807659
Iter: 705 loss: 0.000340485771
Iter: 706 loss: 0.000340484548
Iter: 707 loss: 0.000340244442
Iter: 708 loss: 0.000339717546
Iter: 709 loss: 0.000347657478
Iter: 710 loss: 0.00033969534
Iter: 711 loss: 0.000339165446
Iter: 712 loss: 0.000341136241
Iter: 713 loss: 0.000339036284
Iter: 714 loss: 0.000338568876
Iter: 715 loss: 0.000339093385
Iter: 716 loss: 0.00033831512
Iter: 717 loss: 0.000337742676
Iter: 718 loss: 0.000338592072
Iter: 719 loss: 0.000337468053
Iter: 720 loss: 0.000336777943
Iter: 721 loss: 0.000337854144
Iter: 722 loss: 0.000336451514
Iter: 723 loss: 0.000335710094
Iter: 724 loss: 0.000336727826
Iter: 725 loss: 0.000335340068
Iter: 726 loss: 0.000334363693
Iter: 727 loss: 0.000336871308
Iter: 728 loss: 0.000334025535
Iter: 729 loss: 0.000333257922
Iter: 730 loss: 0.000340503233
Iter: 731 loss: 0.000333226
Iter: 732 loss: 0.000332634198
Iter: 733 loss: 0.000333409465
Iter: 734 loss: 0.000332333031
Iter: 735 loss: 0.000331856485
Iter: 736 loss: 0.000336424797
Iter: 737 loss: 0.000331839052
Iter: 738 loss: 0.00033153221
Iter: 739 loss: 0.000331529474
Iter: 740 loss: 0.00033129027
Iter: 741 loss: 0.000330846611
Iter: 742 loss: 0.000340946601
Iter: 743 loss: 0.000330846698
Iter: 744 loss: 0.000330408395
Iter: 745 loss: 0.000332135882
Iter: 746 loss: 0.000330306066
Iter: 747 loss: 0.00032994154
Iter: 748 loss: 0.000330015027
Iter: 749 loss: 0.000329670846
Iter: 750 loss: 0.000329120056
Iter: 751 loss: 0.000330293726
Iter: 752 loss: 0.000328902912
Iter: 753 loss: 0.000328319526
Iter: 754 loss: 0.000329063798
Iter: 755 loss: 0.000328021735
Iter: 756 loss: 0.000327364774
Iter: 757 loss: 0.000328113092
Iter: 758 loss: 0.000327010872
Iter: 759 loss: 0.000326165871
Iter: 760 loss: 0.000328349881
Iter: 761 loss: 0.000325878558
Iter: 762 loss: 0.000325202942
Iter: 763 loss: 0.00033141661
Iter: 764 loss: 0.000325173081
Iter: 765 loss: 0.000324648223
Iter: 766 loss: 0.000325159926
Iter: 767 loss: 0.000324351364
Iter: 768 loss: 0.000323879765
Iter: 769 loss: 0.000329109142
Iter: 770 loss: 0.000323869754
Iter: 771 loss: 0.000323616812
Iter: 772 loss: 0.00032360293
Iter: 773 loss: 0.000323408924
Iter: 774 loss: 0.000323048036
Iter: 775 loss: 0.000331292598
Iter: 776 loss: 0.000323047687
Iter: 777 loss: 0.000322704291
Iter: 778 loss: 0.000323453947
Iter: 779 loss: 0.00032257245
Iter: 780 loss: 0.000322205306
Iter: 781 loss: 0.000322450389
Iter: 782 loss: 0.000321972679
Iter: 783 loss: 0.000321505
Iter: 784 loss: 0.000322785723
Iter: 785 loss: 0.000321353436
Iter: 786 loss: 0.000320846681
Iter: 787 loss: 0.000321189116
Iter: 788 loss: 0.000320528809
Iter: 789 loss: 0.000319904939
Iter: 790 loss: 0.000321030704
Iter: 791 loss: 0.000319635612
Iter: 792 loss: 0.000318895909
Iter: 793 loss: 0.000320856459
Iter: 794 loss: 0.000318648061
Iter: 795 loss: 0.000318010483
Iter: 796 loss: 0.000322127278
Iter: 797 loss: 0.000317940779
Iter: 798 loss: 0.000317389815
Iter: 799 loss: 0.000318737235
Iter: 800 loss: 0.000317192695
Iter: 801 loss: 0.00031680247
Iter: 802 loss: 0.000320125604
Iter: 803 loss: 0.000316781341
Iter: 804 loss: 0.00031657418
Iter: 805 loss: 0.000316563383
Iter: 806 loss: 0.000316403311
Iter: 807 loss: 0.000316097634
Iter: 808 loss: 0.000322592561
Iter: 809 loss: 0.000316096062
Iter: 810 loss: 0.000315774232
Iter: 811 loss: 0.000316847116
Iter: 812 loss: 0.000315684854
Iter: 813 loss: 0.00031538069
Iter: 814 loss: 0.000315672631
Iter: 815 loss: 0.000315207464
Iter: 816 loss: 0.000314835575
Iter: 817 loss: 0.00031540927
Iter: 818 loss: 0.000314659759
Iter: 819 loss: 0.000314211968
Iter: 820 loss: 0.000314695179
Iter: 821 loss: 0.000313966884
Iter: 822 loss: 0.000313460478
Iter: 823 loss: 0.00031393714
Iter: 824 loss: 0.000313169148
Iter: 825 loss: 0.000312498596
Iter: 826 loss: 0.000314299541
Iter: 827 loss: 0.000312276214
Iter: 828 loss: 0.000311697077
Iter: 829 loss: 0.000315656274
Iter: 830 loss: 0.000311639393
Iter: 831 loss: 0.000311158132
Iter: 832 loss: 0.0003124
Iter: 833 loss: 0.000310992822
Iter: 834 loss: 0.000310651463
Iter: 835 loss: 0.000313642493
Iter: 836 loss: 0.00031063176
Iter: 837 loss: 0.000310474687
Iter: 838 loss: 0.000310450559
Iter: 839 loss: 0.000310311676
Iter: 840 loss: 0.00031005597
Iter: 841 loss: 0.000315989659
Iter: 842 loss: 0.000310055213
Iter: 843 loss: 0.00030980361
Iter: 844 loss: 0.000310150615
Iter: 845 loss: 0.000309678435
Iter: 846 loss: 0.000309388037
Iter: 847 loss: 0.000309492927
Iter: 848 loss: 0.00030918367
Iter: 849 loss: 0.000308808347
Iter: 850 loss: 0.000309975876
Iter: 851 loss: 0.000308699266
Iter: 852 loss: 0.000308305782
Iter: 853 loss: 0.000308656425
Iter: 854 loss: 0.000308076094
Iter: 855 loss: 0.000307554379
Iter: 856 loss: 0.00030787359
Iter: 857 loss: 0.000307220442
Iter: 858 loss: 0.000306556758
Iter: 859 loss: 0.000309792871
Iter: 860 loss: 0.000306439062
Iter: 861 loss: 0.000305944704
Iter: 862 loss: 0.000308256072
Iter: 863 loss: 0.000305852736
Iter: 864 loss: 0.00030538789
Iter: 865 loss: 0.000306914328
Iter: 866 loss: 0.000305258
Iter: 867 loss: 0.00030492607
Iter: 868 loss: 0.000307149225
Iter: 869 loss: 0.000304892863
Iter: 870 loss: 0.000304748391
Iter: 871 loss: 0.000304725952
Iter: 872 loss: 0.000304597896
Iter: 873 loss: 0.000304385729
Iter: 874 loss: 0.000304385059
Iter: 875 loss: 0.000304154586
Iter: 876 loss: 0.000304467801
Iter: 877 loss: 0.000304038404
Iter: 878 loss: 0.000303737557
Iter: 879 loss: 0.000304091373
Iter: 880 loss: 0.000303579174
Iter: 881 loss: 0.000303255307
Iter: 882 loss: 0.000304114365
Iter: 883 loss: 0.000303147302
Iter: 884 loss: 0.000302807253
Iter: 885 loss: 0.000303009932
Iter: 886 loss: 0.000302588742
Iter: 887 loss: 0.000302117551
Iter: 888 loss: 0.000302553148
Iter: 889 loss: 0.000301846041
Iter: 890 loss: 0.000301341235
Iter: 891 loss: 0.000303964189
Iter: 892 loss: 0.000301261491
Iter: 893 loss: 0.000300848915
Iter: 894 loss: 0.000302056229
Iter: 895 loss: 0.000300721556
Iter: 896 loss: 0.0003002827
Iter: 897 loss: 0.000302095024
Iter: 898 loss: 0.000300187734
Iter: 899 loss: 0.000299892679
Iter: 900 loss: 0.000301961147
Iter: 901 loss: 0.000299864652
Iter: 902 loss: 0.000299762964
Iter: 903 loss: 0.00029972833
Iter: 904 loss: 0.000299622887
Iter: 905 loss: 0.000299436
Iter: 906 loss: 0.000299435895
Iter: 907 loss: 0.000299232081
Iter: 908 loss: 0.000299329404
Iter: 909 loss: 0.000299095875
Iter: 910 loss: 0.000298819214
Iter: 911 loss: 0.000299215433
Iter: 912 loss: 0.000298683153
Iter: 913 loss: 0.000298411469
Iter: 914 loss: 0.000299066131
Iter: 915 loss: 0.000298314088
Iter: 916 loss: 0.000297999475
Iter: 917 loss: 0.00029826822
Iter: 918 loss: 0.00029781292
Iter: 919 loss: 0.000297391845
Iter: 920 loss: 0.000297795195
Iter: 921 loss: 0.00029715136
Iter: 922 loss: 0.000296665967
Iter: 923 loss: 0.000298408588
Iter: 924 loss: 0.000296541548
Iter: 925 loss: 0.000296065351
Iter: 926 loss: 0.000297314778
Iter: 927 loss: 0.000295904494
Iter: 928 loss: 0.000295402861
Iter: 929 loss: 0.000298034371
Iter: 930 loss: 0.00029532495
Iter: 931 loss: 0.000294984959
Iter: 932 loss: 0.000296871265
Iter: 933 loss: 0.000294936559
Iter: 934 loss: 0.000294797705
Iter: 935 loss: 0.000294771802
Iter: 936 loss: 0.000294639962
Iter: 937 loss: 0.000294461235
Iter: 938 loss: 0.000294451631
Iter: 939 loss: 0.000294240628
Iter: 940 loss: 0.000294481521
Iter: 941 loss: 0.000294126221
Iter: 942 loss: 0.000293845776
Iter: 943 loss: 0.00029424089
Iter: 944 loss: 0.000293708523
Iter: 945 loss: 0.00029341015
Iter: 946 loss: 0.000293855672
Iter: 947 loss: 0.000293268356
Iter: 948 loss: 0.000292921293
Iter: 949 loss: 0.00029346376
Iter: 950 loss: 0.000292759418
Iter: 951 loss: 0.000292326236
Iter: 952 loss: 0.000292391633
Iter: 953 loss: 0.000291998207
Iter: 954 loss: 0.000291376375
Iter: 955 loss: 0.000293258345
Iter: 956 loss: 0.000291190547
Iter: 957 loss: 0.000290585187
Iter: 958 loss: 0.000292905519
Iter: 959 loss: 0.000290441443
Iter: 960 loss: 0.000289876247
Iter: 961 loss: 0.000292399607
Iter: 962 loss: 0.000289765158
Iter: 963 loss: 0.0002893497
Iter: 964 loss: 0.000291663106
Iter: 965 loss: 0.000289289746
Iter: 966 loss: 0.000289192452
Iter: 967 loss: 0.000289108459
Iter: 968 loss: 0.000288973592
Iter: 969 loss: 0.000288787967
Iter: 970 loss: 0.000288779323
Iter: 971 loss: 0.000288577517
Iter: 972 loss: 0.000288529845
Iter: 973 loss: 0.00028839978
Iter: 974 loss: 0.000288067618
Iter: 975 loss: 0.0002884118
Iter: 976 loss: 0.000287882111
Iter: 977 loss: 0.000287509523
Iter: 978 loss: 0.000288448267
Iter: 979 loss: 0.000287379808
Iter: 980 loss: 0.00028698807
Iter: 981 loss: 0.000287779316
Iter: 982 loss: 0.000286828668
Iter: 983 loss: 0.00028636615
Iter: 984 loss: 0.000286406081
Iter: 985 loss: 0.000286009
Iter: 986 loss: 0.000285382295
Iter: 987 loss: 0.000287827657
Iter: 988 loss: 0.00028523567
Iter: 989 loss: 0.000284643611
Iter: 990 loss: 0.000286701485
Iter: 991 loss: 0.000284488866
Iter: 992 loss: 0.000283947447
Iter: 993 loss: 0.000286893337
Iter: 994 loss: 0.00028386747
Iter: 995 loss: 0.000283467
Iter: 996 loss: 0.000285336573
Iter: 997 loss: 0.0002833943
Iter: 998 loss: 0.000283289613
Iter: 999 loss: 0.000283223839
Iter: 1000 loss: 0.00028309552
Iter: 1001 loss: 0.00028289709
Iter: 1002 loss: 0.000282894413
Iter: 1003 loss: 0.000282647263
Iter: 1004 loss: 0.00028295943
Iter: 1005 loss: 0.000282520021
Iter: 1006 loss: 0.000282212917
Iter: 1007 loss: 0.000282954279
Iter: 1008 loss: 0.000282103312
Iter: 1009 loss: 0.000281832065
Iter: 1010 loss: 0.000282000809
Iter: 1011 loss: 0.000281657733
Iter: 1012 loss: 0.000281301822
Iter: 1013 loss: 0.000282115972
Iter: 1014 loss: 0.000281169545
Iter: 1015 loss: 0.000280781765
Iter: 1016 loss: 0.000280988344
Iter: 1017 loss: 0.000280526176
Iter: 1018 loss: 0.000280018052
Iter: 1019 loss: 0.000281204295
Iter: 1020 loss: 0.000279831351
Iter: 1021 loss: 0.000279275875
Iter: 1022 loss: 0.000281504064
Iter: 1023 loss: 0.000279149535
Iter: 1024 loss: 0.000278681284
Iter: 1025 loss: 0.000281073968
Iter: 1026 loss: 0.000278605206
Iter: 1027 loss: 0.000278234133
Iter: 1028 loss: 0.000279597181
Iter: 1029 loss: 0.000278140185
Iter: 1030 loss: 0.000278057618
Iter: 1031 loss: 0.00027796076
Iter: 1032 loss: 0.000277813466
Iter: 1033 loss: 0.000277641171
Iter: 1034 loss: 0.000277621701
Iter: 1035 loss: 0.000277438
Iter: 1036 loss: 0.000277450948
Iter: 1037 loss: 0.000277294777
Iter: 1038 loss: 0.000277026498
Iter: 1039 loss: 0.000277323124
Iter: 1040 loss: 0.000276879611
Iter: 1041 loss: 0.000276554638
Iter: 1042 loss: 0.000276907347
Iter: 1043 loss: 0.000276377075
Iter: 1044 loss: 0.000275975879
Iter: 1045 loss: 0.000277593615
Iter: 1046 loss: 0.000275885686
Iter: 1047 loss: 0.000275533472
Iter: 1048 loss: 0.000275583472
Iter: 1049 loss: 0.000275266357
Iter: 1050 loss: 0.000274734164
Iter: 1051 loss: 0.000275583647
Iter: 1052 loss: 0.000274484511
Iter: 1053 loss: 0.000273869431
Iter: 1054 loss: 0.00027670915
Iter: 1055 loss: 0.000273753132
Iter: 1056 loss: 0.000273250509
Iter: 1057 loss: 0.000276078499
Iter: 1058 loss: 0.000273179816
Iter: 1059 loss: 0.000272732461
Iter: 1060 loss: 0.000273695623
Iter: 1061 loss: 0.000272559118
Iter: 1062 loss: 0.000272496633
Iter: 1063 loss: 0.000272348436
Iter: 1064 loss: 0.000272202364
Iter: 1065 loss: 0.000271997182
Iter: 1066 loss: 0.000271989789
Iter: 1067 loss: 0.000271722529
Iter: 1068 loss: 0.000272075966
Iter: 1069 loss: 0.000271586381
Iter: 1070 loss: 0.00027124607
Iter: 1071 loss: 0.000272071949
Iter: 1072 loss: 0.000271124794
Iter: 1073 loss: 0.000270801916
Iter: 1074 loss: 0.000270964723
Iter: 1075 loss: 0.000270585413
Iter: 1076 loss: 0.000270200719
Iter: 1077 loss: 0.000271232188
Iter: 1078 loss: 0.000270073302
Iter: 1079 loss: 0.000269674638
Iter: 1080 loss: 0.000269872398
Iter: 1081 loss: 0.000269407
Iter: 1082 loss: 0.000268865057
Iter: 1083 loss: 0.000269814773
Iter: 1084 loss: 0.0002686269
Iter: 1085 loss: 0.000267964642
Iter: 1086 loss: 0.000271381519
Iter: 1087 loss: 0.000267856172
Iter: 1088 loss: 0.000267327618
Iter: 1089 loss: 0.000268764095
Iter: 1090 loss: 0.00026715413
Iter: 1091 loss: 0.000266621559
Iter: 1092 loss: 0.000269267941
Iter: 1093 loss: 0.00026652962
Iter: 1094 loss: 0.00026647895
Iter: 1095 loss: 0.000266332121
Iter: 1096 loss: 0.000266167539
Iter: 1097 loss: 0.000265959708
Iter: 1098 loss: 0.000265942974
Iter: 1099 loss: 0.0002657164
Iter: 1100 loss: 0.000265560462
Iter: 1101 loss: 0.000265478651
Iter: 1102 loss: 0.000265083363
Iter: 1103 loss: 0.000265894632
Iter: 1104 loss: 0.000264922361
Iter: 1105 loss: 0.000264554285
Iter: 1106 loss: 0.00026477786
Iter: 1107 loss: 0.00026431703
Iter: 1108 loss: 0.000263813126
Iter: 1109 loss: 0.000265911804
Iter: 1110 loss: 0.000263703871
Iter: 1111 loss: 0.000263218972
Iter: 1112 loss: 0.000263350375
Iter: 1113 loss: 0.000262869813
Iter: 1114 loss: 0.00026223794
Iter: 1115 loss: 0.000263485301
Iter: 1116 loss: 0.000261975
Iter: 1117 loss: 0.000261285197
Iter: 1118 loss: 0.000263871101
Iter: 1119 loss: 0.000261118606
Iter: 1120 loss: 0.000260484347
Iter: 1121 loss: 0.000263751834
Iter: 1122 loss: 0.000260380853
Iter: 1123 loss: 0.000259836321
Iter: 1124 loss: 0.000261998
Iter: 1125 loss: 0.000259712804
Iter: 1126 loss: 0.000259608612
Iter: 1127 loss: 0.00025949569
Iter: 1128 loss: 0.000259332883
Iter: 1129 loss: 0.000259147171
Iter: 1130 loss: 0.000259123161
Iter: 1131 loss: 0.00025884388
Iter: 1132 loss: 0.000258973916
Iter: 1133 loss: 0.000258654356
Iter: 1134 loss: 0.000258248358
Iter: 1135 loss: 0.000259780849
Iter: 1136 loss: 0.000258150743
Iter: 1137 loss: 0.000257812266
Iter: 1138 loss: 0.000257881242
Iter: 1139 loss: 0.000257560052
Iter: 1140 loss: 0.000257152278
Iter: 1141 loss: 0.00025828465
Iter: 1142 loss: 0.000257021049
Iter: 1143 loss: 0.000256572
Iter: 1144 loss: 0.000256849162
Iter: 1145 loss: 0.000256282976
Iter: 1146 loss: 0.000255731051
Iter: 1147 loss: 0.000257018313
Iter: 1148 loss: 0.000255527761
Iter: 1149 loss: 0.000254898216
Iter: 1150 loss: 0.000257935957
Iter: 1151 loss: 0.000254786341
Iter: 1152 loss: 0.000254260143
Iter: 1153 loss: 0.000255185907
Iter: 1154 loss: 0.000254028593
Iter: 1155 loss: 0.000253429374
Iter: 1156 loss: 0.00025731558
Iter: 1157 loss: 0.000253364706
Iter: 1158 loss: 0.000253300415
Iter: 1159 loss: 0.000253166218
Iter: 1160 loss: 0.000253002043
Iter: 1161 loss: 0.000252782425
Iter: 1162 loss: 0.000252770522
Iter: 1163 loss: 0.000252514088
Iter: 1164 loss: 0.000252268277
Iter: 1165 loss: 0.000252211845
Iter: 1166 loss: 0.000251754071
Iter: 1167 loss: 0.00025309046
Iter: 1168 loss: 0.000251611142
Iter: 1169 loss: 0.000251240039
Iter: 1170 loss: 0.00025098183
Iter: 1171 loss: 0.000250848243
Iter: 1172 loss: 0.000250222249
Iter: 1173 loss: 0.00025499874
Iter: 1174 loss: 0.000250174402
Iter: 1175 loss: 0.000249688484
Iter: 1176 loss: 0.000250190933
Iter: 1177 loss: 0.000249418837
Iter: 1178 loss: 0.000248913
Iter: 1179 loss: 0.000249302131
Iter: 1180 loss: 0.000248604571
Iter: 1181 loss: 0.00024808076
Iter: 1182 loss: 0.00025092368
Iter: 1183 loss: 0.000248002703
Iter: 1184 loss: 0.000247578835
Iter: 1185 loss: 0.000248492201
Iter: 1186 loss: 0.000247412972
Iter: 1187 loss: 0.000246949086
Iter: 1188 loss: 0.000249033619
Iter: 1189 loss: 0.000246857846
Iter: 1190 loss: 0.000246810901
Iter: 1191 loss: 0.000246667769
Iter: 1192 loss: 0.000246550597
Iter: 1193 loss: 0.000246449752
Iter: 1194 loss: 0.000246418
Iter: 1195 loss: 0.000246209733
Iter: 1196 loss: 0.000246526266
Iter: 1197 loss: 0.00024611043
Iter: 1198 loss: 0.00024588377
Iter: 1199 loss: 0.000246965268
Iter: 1200 loss: 0.000245843665
Iter: 1201 loss: 0.000245654781
Iter: 1202 loss: 0.000245370553
Iter: 1203 loss: 0.000245364907
Iter: 1204 loss: 0.000245044444
Iter: 1205 loss: 0.000246932614
Iter: 1206 loss: 0.000245003437
Iter: 1207 loss: 0.000244718423
Iter: 1208 loss: 0.000245399511
Iter: 1209 loss: 0.000244613911
Iter: 1210 loss: 0.000244352326
Iter: 1211 loss: 0.000245085597
Iter: 1212 loss: 0.000244268216
Iter: 1213 loss: 0.000243988237
Iter: 1214 loss: 0.000245605188
Iter: 1215 loss: 0.000243950635
Iter: 1216 loss: 0.000243734
Iter: 1217 loss: 0.000243865
Iter: 1218 loss: 0.000243593648
Iter: 1219 loss: 0.000243253904
Iter: 1220 loss: 0.000244243187
Iter: 1221 loss: 0.000243148737
Iter: 1222 loss: 0.00024320079
Iter: 1223 loss: 0.000243029062
Iter: 1224 loss: 0.000242930371
Iter: 1225 loss: 0.000242849303
Iter: 1226 loss: 0.000242820417
Iter: 1227 loss: 0.000242682436
Iter: 1228 loss: 0.000242534064
Iter: 1229 loss: 0.000242511131
Iter: 1230 loss: 0.000242289505
Iter: 1231 loss: 0.000243642717
Iter: 1232 loss: 0.000242261493
Iter: 1233 loss: 0.000242111084
Iter: 1234 loss: 0.000242015842
Iter: 1235 loss: 0.0002419558
Iter: 1236 loss: 0.000241754242
Iter: 1237 loss: 0.000242894035
Iter: 1238 loss: 0.000241726491
Iter: 1239 loss: 0.000241521746
Iter: 1240 loss: 0.000242188849
Iter: 1241 loss: 0.000241465881
Iter: 1242 loss: 0.000241278933
Iter: 1243 loss: 0.000241431553
Iter: 1244 loss: 0.000241167509
Iter: 1245 loss: 0.000240980924
Iter: 1246 loss: 0.000242701033
Iter: 1247 loss: 0.000240972528
Iter: 1248 loss: 0.000240837573
Iter: 1249 loss: 0.000240822133
Iter: 1250 loss: 0.000240723952
Iter: 1251 loss: 0.000240517533
Iter: 1252 loss: 0.000241355738
Iter: 1253 loss: 0.000240470967
Iter: 1254 loss: 0.000240447116
Iter: 1255 loss: 0.000240386231
Iter: 1256 loss: 0.000240305599
Iter: 1257 loss: 0.000240332331
Iter: 1258 loss: 0.000240248875
Iter: 1259 loss: 0.00024015778
Iter: 1260 loss: 0.000240073976
Iter: 1261 loss: 0.00024005209
Iter: 1262 loss: 0.000239915156
Iter: 1263 loss: 0.000241050438
Iter: 1264 loss: 0.00023990772
Iter: 1265 loss: 0.000239797475
Iter: 1266 loss: 0.000239619723
Iter: 1267 loss: 0.000239618064
Iter: 1268 loss: 0.000239382192
Iter: 1269 loss: 0.000239608809
Iter: 1270 loss: 0.000239247034
Iter: 1271 loss: 0.000238950714
Iter: 1272 loss: 0.000240661044
Iter: 1273 loss: 0.000238910463
Iter: 1274 loss: 0.000238660461
Iter: 1275 loss: 0.000238722714
Iter: 1276 loss: 0.000238477645
Iter: 1277 loss: 0.000238182765
Iter: 1278 loss: 0.000241087328
Iter: 1279 loss: 0.000238172535
Iter: 1280 loss: 0.000237953602
Iter: 1281 loss: 0.000238146502
Iter: 1282 loss: 0.000237824846
Iter: 1283 loss: 0.00023756623
Iter: 1284 loss: 0.000238724926
Iter: 1285 loss: 0.000237515196
Iter: 1286 loss: 0.000237329543
Iter: 1287 loss: 0.000239158369
Iter: 1288 loss: 0.000237322529
Iter: 1289 loss: 0.000237128144
Iter: 1290 loss: 0.000238421751
Iter: 1291 loss: 0.000237108034
Iter: 1292 loss: 0.000237024316
Iter: 1293 loss: 0.000236870561
Iter: 1294 loss: 0.000240425594
Iter: 1295 loss: 0.000236870299
Iter: 1296 loss: 0.00023675643
Iter: 1297 loss: 0.000236756168
Iter: 1298 loss: 0.000236664782
Iter: 1299 loss: 0.000236753447
Iter: 1300 loss: 0.000236612963
Iter: 1301 loss: 0.000236536624
Iter: 1302 loss: 0.000236561202
Iter: 1303 loss: 0.000236481981
Iter: 1304 loss: 0.00023639368
Iter: 1305 loss: 0.000236818174
Iter: 1306 loss: 0.000236377236
Iter: 1307 loss: 0.000236271895
Iter: 1308 loss: 0.000236220061
Iter: 1309 loss: 0.000236169479
Iter: 1310 loss: 0.000236025022
Iter: 1311 loss: 0.000236585867
Iter: 1312 loss: 0.000235991116
Iter: 1313 loss: 0.000235824918
Iter: 1314 loss: 0.000236431981
Iter: 1315 loss: 0.000235782732
Iter: 1316 loss: 0.000235671832
Iter: 1317 loss: 0.000235966843
Iter: 1318 loss: 0.000235635089
Iter: 1319 loss: 0.000235489642
Iter: 1320 loss: 0.000235535874
Iter: 1321 loss: 0.000235385669
Iter: 1322 loss: 0.000235424435
Iter: 1323 loss: 0.000235301821
Iter: 1324 loss: 0.000235232073
Iter: 1325 loss: 0.000235033265
Iter: 1326 loss: 0.000235989486
Iter: 1327 loss: 0.000234963314
Iter: 1328 loss: 0.000234760009
Iter: 1329 loss: 0.000235377767
Iter: 1330 loss: 0.00023469975
Iter: 1331 loss: 0.000234511448
Iter: 1332 loss: 0.000235976884
Iter: 1333 loss: 0.000234497333
Iter: 1334 loss: 0.000234314037
Iter: 1335 loss: 0.00023402879
Iter: 1336 loss: 0.000234024468
Iter: 1337 loss: 0.000233750121
Iter: 1338 loss: 0.000236981767
Iter: 1339 loss: 0.000233746221
Iter: 1340 loss: 0.000233516315
Iter: 1341 loss: 0.000233924613
Iter: 1342 loss: 0.000233415878
Iter: 1343 loss: 0.000233188402
Iter: 1344 loss: 0.000233072031
Iter: 1345 loss: 0.000232965744
Iter: 1346 loss: 0.000232603808
Iter: 1347 loss: 0.000233264436
Iter: 1348 loss: 0.00023244691
Iter: 1349 loss: 0.000232189966
Iter: 1350 loss: 0.000235596759
Iter: 1351 loss: 0.000232188948
Iter: 1352 loss: 0.000231991376
Iter: 1353 loss: 0.000232192891
Iter: 1354 loss: 0.000231881335
Iter: 1355 loss: 0.000231767975
Iter: 1356 loss: 0.000231746701
Iter: 1357 loss: 0.000231604659
Iter: 1358 loss: 0.000231520404
Iter: 1359 loss: 0.000231461716
Iter: 1360 loss: 0.000231255064
Iter: 1361 loss: 0.000230713122
Iter: 1362 loss: 0.000234831648
Iter: 1363 loss: 0.000230604579
Iter: 1364 loss: 0.000229970159
Iter: 1365 loss: 0.000238490175
Iter: 1366 loss: 0.000229966943
Iter: 1367 loss: 0.000229284429
Iter: 1368 loss: 0.000230498539
Iter: 1369 loss: 0.000228981487
Iter: 1370 loss: 0.000228547142
Iter: 1371 loss: 0.000228629462
Iter: 1372 loss: 0.000228223245
Iter: 1373 loss: 0.000227804121
Iter: 1374 loss: 0.000228937759
Iter: 1375 loss: 0.000227665179
Iter: 1376 loss: 0.000227236349
Iter: 1377 loss: 0.000230619495
Iter: 1378 loss: 0.000227206838
Iter: 1379 loss: 0.000226942648
Iter: 1380 loss: 0.000226774457
Iter: 1381 loss: 0.000226671196
Iter: 1382 loss: 0.000226298114
Iter: 1383 loss: 0.000227991055
Iter: 1384 loss: 0.00022622713
Iter: 1385 loss: 0.000225887445
Iter: 1386 loss: 0.00022888089
Iter: 1387 loss: 0.000225870506
Iter: 1388 loss: 0.000225767915
Iter: 1389 loss: 0.000225760712
Iter: 1390 loss: 0.00022564648
Iter: 1391 loss: 0.000225700496
Iter: 1392 loss: 0.000225569267
Iter: 1393 loss: 0.000225452313
Iter: 1394 loss: 0.000225242373
Iter: 1395 loss: 0.000230404723
Iter: 1396 loss: 0.00022524246
Iter: 1397 loss: 0.0002250291
Iter: 1398 loss: 0.000225457028
Iter: 1399 loss: 0.000224942429
Iter: 1400 loss: 0.000224801348
Iter: 1401 loss: 0.000224797579
Iter: 1402 loss: 0.000224670322
Iter: 1403 loss: 0.000224560237
Iter: 1404 loss: 0.000224526651
Iter: 1405 loss: 0.000224360236
Iter: 1406 loss: 0.000224240794
Iter: 1407 loss: 0.000224183241
Iter: 1408 loss: 0.000223963405
Iter: 1409 loss: 0.000226177217
Iter: 1410 loss: 0.000223956071
Iter: 1411 loss: 0.000223727839
Iter: 1412 loss: 0.000223794224
Iter: 1413 loss: 0.000223563198
Iter: 1414 loss: 0.000223318246
Iter: 1415 loss: 0.000223532101
Iter: 1416 loss: 0.000223174487
Iter: 1417 loss: 0.00022293361
Iter: 1418 loss: 0.000226567936
Iter: 1419 loss: 0.000222933886
Iter: 1420 loss: 0.000222819945
Iter: 1421 loss: 0.000222820119
Iter: 1422 loss: 0.000222712013
Iter: 1423 loss: 0.000223070412
Iter: 1424 loss: 0.000222682545
Iter: 1425 loss: 0.000222589064
Iter: 1426 loss: 0.000222390314
Iter: 1427 loss: 0.000225599011
Iter: 1428 loss: 0.000222384508
Iter: 1429 loss: 0.000222214396
Iter: 1430 loss: 0.000222500137
Iter: 1431 loss: 0.000222138406
Iter: 1432 loss: 0.000221982089
Iter: 1433 loss: 0.000222960138
Iter: 1434 loss: 0.000221963826
Iter: 1435 loss: 0.000221810042
Iter: 1436 loss: 0.000222669551
Iter: 1437 loss: 0.000221788272
Iter: 1438 loss: 0.000221687136
Iter: 1439 loss: 0.000221527895
Iter: 1440 loss: 0.000221525886
Iter: 1441 loss: 0.00022137136
Iter: 1442 loss: 0.000221951428
Iter: 1443 loss: 0.000221334369
Iter: 1444 loss: 0.000221178285
Iter: 1445 loss: 0.00022224705
Iter: 1446 loss: 0.000221163165
Iter: 1447 loss: 0.000221052789
Iter: 1448 loss: 0.000221107417
Iter: 1449 loss: 0.000220979186
Iter: 1450 loss: 0.00022086245
Iter: 1451 loss: 0.00022115506
Iter: 1452 loss: 0.000220822898
Iter: 1453 loss: 0.000220737187
Iter: 1454 loss: 0.000220735368
Iter: 1455 loss: 0.000220662128
Iter: 1456 loss: 0.000221340757
Iter: 1457 loss: 0.00022065916
Iter: 1458 loss: 0.000220606817
Iter: 1459 loss: 0.000220527319
Iter: 1460 loss: 0.000220526214
Iter: 1461 loss: 0.000220449801
Iter: 1462 loss: 0.00022038084
Iter: 1463 loss: 0.000220361428
Iter: 1464 loss: 0.000220212183
Iter: 1465 loss: 0.000220444475
Iter: 1466 loss: 0.00022014213
Iter: 1467 loss: 0.000220056914
Iter: 1468 loss: 0.000220049231
Iter: 1469 loss: 0.0002199632
Iter: 1470 loss: 0.000219830225
Iter: 1471 loss: 0.000219828406
Iter: 1472 loss: 0.000219706155
Iter: 1473 loss: 0.000219657217
Iter: 1474 loss: 0.000219591981
Iter: 1475 loss: 0.000219468289
Iter: 1476 loss: 0.000219467562
Iter: 1477 loss: 0.000219355672
Iter: 1478 loss: 0.000219401103
Iter: 1479 loss: 0.000219277921
Iter: 1480 loss: 0.00021912466
Iter: 1481 loss: 0.000219261623
Iter: 1482 loss: 0.000219035224
Iter: 1483 loss: 0.000218886402
Iter: 1484 loss: 0.00021988267
Iter: 1485 loss: 0.000218870642
Iter: 1486 loss: 0.000218941917
Iter: 1487 loss: 0.000218830988
Iter: 1488 loss: 0.000218805624
Iter: 1489 loss: 0.00021875769
Iter: 1490 loss: 0.00021989466
Iter: 1491 loss: 0.000218757574
Iter: 1492 loss: 0.000218699613
Iter: 1493 loss: 0.000218639543
Iter: 1494 loss: 0.000218629008
Iter: 1495 loss: 0.000218561516
Iter: 1496 loss: 0.000218766858
Iter: 1497 loss: 0.00021854139
Iter: 1498 loss: 0.000218468573
Iter: 1499 loss: 0.000218620844
Iter: 1500 loss: 0.00021844024
Iter: 1501 loss: 0.000218375586
Iter: 1502 loss: 0.00021837544
Iter: 1503 loss: 0.000218338217
Iter: 1504 loss: 0.000218273504
Iter: 1505 loss: 0.000218273519
Iter: 1506 loss: 0.000218196132
Iter: 1507 loss: 0.000218309462
Iter: 1508 loss: 0.000218158442
Iter: 1509 loss: 0.0002180749
Iter: 1510 loss: 0.000218365836
Iter: 1511 loss: 0.000218052504
Iter: 1512 loss: 0.000217966939
Iter: 1513 loss: 0.000218451067
Iter: 1514 loss: 0.000217954788
Iter: 1515 loss: 0.000217879075
Iter: 1516 loss: 0.000217834313
Iter: 1517 loss: 0.000217802808
Iter: 1518 loss: 0.000217901936
Iter: 1519 loss: 0.000217779379
Iter: 1520 loss: 0.000217751658
Iter: 1521 loss: 0.000217698689
Iter: 1522 loss: 0.000218777452
Iter: 1523 loss: 0.000217697932
Iter: 1524 loss: 0.000217643712
Iter: 1525 loss: 0.000217757159
Iter: 1526 loss: 0.000217621535
Iter: 1527 loss: 0.000217575958
Iter: 1528 loss: 0.000217528141
Iter: 1529 loss: 0.000217519686
Iter: 1530 loss: 0.000217445573
Iter: 1531 loss: 0.000217756373
Iter: 1532 loss: 0.000217430104
Iter: 1533 loss: 0.000217382621
Iter: 1534 loss: 0.000217382316
Iter: 1535 loss: 0.00021734192
Iter: 1536 loss: 0.000217319321
Iter: 1537 loss: 0.000217301771
Iter: 1538 loss: 0.000217249442
Iter: 1539 loss: 0.000217301626
Iter: 1540 loss: 0.000217220891
Iter: 1541 loss: 0.000217153531
Iter: 1542 loss: 0.000217184555
Iter: 1543 loss: 0.000217108231
Iter: 1544 loss: 0.000217047898
Iter: 1545 loss: 0.000217865891
Iter: 1546 loss: 0.000217047549
Iter: 1547 loss: 0.000216998262
Iter: 1548 loss: 0.000217069377
Iter: 1549 loss: 0.000216973975
Iter: 1550 loss: 0.000216932211
Iter: 1551 loss: 0.000217145309
Iter: 1552 loss: 0.000216925881
Iter: 1553 loss: 0.000216870205
Iter: 1554 loss: 0.000217227818
Iter: 1555 loss: 0.000216863875
Iter: 1556 loss: 0.000216843211
Iter: 1557 loss: 0.000216814471
Iter: 1558 loss: 0.000216812638
Iter: 1559 loss: 0.00021676824
Iter: 1560 loss: 0.000216748347
Iter: 1561 loss: 0.000216726316
Iter: 1562 loss: 0.000216659
Iter: 1563 loss: 0.000216721353
Iter: 1564 loss: 0.000216620465
Iter: 1565 loss: 0.000216560555
Iter: 1566 loss: 0.000217148074
Iter: 1567 loss: 0.000216558547
Iter: 1568 loss: 0.000216499
Iter: 1569 loss: 0.000216725821
Iter: 1570 loss: 0.000216484681
Iter: 1571 loss: 0.000216443746
Iter: 1572 loss: 0.000216414483
Iter: 1573 loss: 0.000216400513
Iter: 1574 loss: 0.000216332701
Iter: 1575 loss: 0.000216500164
Iter: 1576 loss: 0.000216308312
Iter: 1577 loss: 0.000216247165
Iter: 1578 loss: 0.000216307613
Iter: 1579 loss: 0.000216212837
Iter: 1580 loss: 0.000216133645
Iter: 1581 loss: 0.000216730536
Iter: 1582 loss: 0.000216127344
Iter: 1583 loss: 0.000216073167
Iter: 1584 loss: 0.000216184562
Iter: 1585 loss: 0.000216051063
Iter: 1586 loss: 0.000216073357
Iter: 1587 loss: 0.000216026761
Iter: 1588 loss: 0.000216014654
Iter: 1589 loss: 0.000215980224
Iter: 1590 loss: 0.000216100671
Iter: 1591 loss: 0.000215964465
Iter: 1592 loss: 0.000215903579
Iter: 1593 loss: 0.000215976936
Iter: 1594 loss: 0.0002158719
Iter: 1595 loss: 0.000215810389
Iter: 1596 loss: 0.000215818538
Iter: 1597 loss: 0.000215763939
Iter: 1598 loss: 0.000215684267
Iter: 1599 loss: 0.000215843917
Iter: 1600 loss: 0.000215652195
Iter: 1601 loss: 0.000215595559
Iter: 1602 loss: 0.000215592314
Iter: 1603 loss: 0.000215553548
Iter: 1604 loss: 0.000215477165
Iter: 1605 loss: 0.00021699084
Iter: 1606 loss: 0.000215476495
Iter: 1607 loss: 0.000215399225
Iter: 1608 loss: 0.000215867825
Iter: 1609 loss: 0.000215389853
Iter: 1610 loss: 0.000215326363
Iter: 1611 loss: 0.000215326494
Iter: 1612 loss: 0.000215276275
Iter: 1613 loss: 0.000215216787
Iter: 1614 loss: 0.000216012399
Iter: 1615 loss: 0.000215216423
Iter: 1616 loss: 0.000215166772
Iter: 1617 loss: 0.000215177162
Iter: 1618 loss: 0.000215130247
Iter: 1619 loss: 0.000215152759
Iter: 1620 loss: 0.000215108157
Iter: 1621 loss: 0.000215083361
Iter: 1622 loss: 0.000215027423
Iter: 1623 loss: 0.000215688589
Iter: 1624 loss: 0.000215022417
Iter: 1625 loss: 0.000214963628
Iter: 1626 loss: 0.000215125794
Iter: 1627 loss: 0.000214943793
Iter: 1628 loss: 0.000214879692
Iter: 1629 loss: 0.00021484532
Iter: 1630 loss: 0.000214816217
Iter: 1631 loss: 0.000214727814
Iter: 1632 loss: 0.000214832282
Iter: 1633 loss: 0.000214680695
Iter: 1634 loss: 0.000214617598
Iter: 1635 loss: 0.000215598731
Iter: 1636 loss: 0.000214617467
Iter: 1637 loss: 0.000214547472
Iter: 1638 loss: 0.000214561442
Iter: 1639 loss: 0.000214495914
Iter: 1640 loss: 0.000214419721
Iter: 1641 loss: 0.000214386513
Iter: 1642 loss: 0.000214347616
Iter: 1643 loss: 0.000214231433
Iter: 1644 loss: 0.000214874861
Iter: 1645 loss: 0.000214215455
Iter: 1646 loss: 0.000214134372
Iter: 1647 loss: 0.000214331289
Iter: 1648 loss: 0.00021410585
Iter: 1649 loss: 0.000214017768
Iter: 1650 loss: 0.000214494707
Iter: 1651 loss: 0.000214004933
Iter: 1652 loss: 0.000213990294
Iter: 1653 loss: 0.000213971973
Iter: 1654 loss: 0.000213937732
Iter: 1655 loss: 0.000213919338
Iter: 1656 loss: 0.000213903564
Iter: 1657 loss: 0.000213867
Iter: 1658 loss: 0.000213797961
Iter: 1659 loss: 0.000215302658
Iter: 1660 loss: 0.000213798281
Iter: 1661 loss: 0.000213709689
Iter: 1662 loss: 0.000214160027
Iter: 1663 loss: 0.000213695399
Iter: 1664 loss: 0.000213620529
Iter: 1665 loss: 0.000213606108
Iter: 1666 loss: 0.000213555701
Iter: 1667 loss: 0.000213478081
Iter: 1668 loss: 0.000213925727
Iter: 1669 loss: 0.000213467982
Iter: 1670 loss: 0.000213374791
Iter: 1671 loss: 0.000213966792
Iter: 1672 loss: 0.000213364488
Iter: 1673 loss: 0.000213312116
Iter: 1674 loss: 0.000213231571
Iter: 1675 loss: 0.00021323
Iter: 1676 loss: 0.00021313371
Iter: 1677 loss: 0.000213446096
Iter: 1678 loss: 0.000213106367
Iter: 1679 loss: 0.000213006366
Iter: 1680 loss: 0.000213105537
Iter: 1681 loss: 0.000212949817
Iter: 1682 loss: 0.000212856801
Iter: 1683 loss: 0.000213689986
Iter: 1684 loss: 0.000212852858
Iter: 1685 loss: 0.000212833562
Iter: 1686 loss: 0.000212819956
Iter: 1687 loss: 0.000212785963
Iter: 1688 loss: 0.000212801882
Iter: 1689 loss: 0.000212762883
Iter: 1690 loss: 0.000212726
Iter: 1691 loss: 0.000212650964
Iter: 1692 loss: 0.000213978259
Iter: 1693 loss: 0.000212649786
Iter: 1694 loss: 0.000212577113
Iter: 1695 loss: 0.00021312818
Iter: 1696 loss: 0.000212571482
Iter: 1697 loss: 0.000212509593
Iter: 1698 loss: 0.000212526618
Iter: 1699 loss: 0.000212465311
Iter: 1700 loss: 0.000212397223
Iter: 1701 loss: 0.000212428873
Iter: 1702 loss: 0.000212350686
Iter: 1703 loss: 0.000212301384
Iter: 1704 loss: 0.000212297178
Iter: 1705 loss: 0.000212255691
Iter: 1706 loss: 0.000212204744
Iter: 1707 loss: 0.000212200364
Iter: 1708 loss: 0.000212129438
Iter: 1709 loss: 0.000212196508
Iter: 1710 loss: 0.000212088533
Iter: 1711 loss: 0.000212014696
Iter: 1712 loss: 0.000212344894
Iter: 1713 loss: 0.000212000014
Iter: 1714 loss: 0.00021193079
Iter: 1715 loss: 0.000212209066
Iter: 1716 loss: 0.000211915991
Iter: 1717 loss: 0.000211869992
Iter: 1718 loss: 0.000212347237
Iter: 1719 loss: 0.000211868377
Iter: 1720 loss: 0.000211821
Iter: 1721 loss: 0.000212185929
Iter: 1722 loss: 0.000211817649
Iter: 1723 loss: 0.000211789418
Iter: 1724 loss: 0.000211721665
Iter: 1725 loss: 0.000212466606
Iter: 1726 loss: 0.000211714359
Iter: 1727 loss: 0.000211637758
Iter: 1728 loss: 0.000211760576
Iter: 1729 loss: 0.00021160247
Iter: 1730 loss: 0.000211504259
Iter: 1731 loss: 0.00021197
Iter: 1732 loss: 0.000211486331
Iter: 1733 loss: 0.000211426115
Iter: 1734 loss: 0.000211414299
Iter: 1735 loss: 0.000211374136
Iter: 1736 loss: 0.000211302759
Iter: 1737 loss: 0.00021215374
Iter: 1738 loss: 0.000211302104
Iter: 1739 loss: 0.000211235631
Iter: 1740 loss: 0.000211319639
Iter: 1741 loss: 0.000211201754
Iter: 1742 loss: 0.000211134451
Iter: 1743 loss: 0.000211061284
Iter: 1744 loss: 0.000211050428
Iter: 1745 loss: 0.000210928934
Iter: 1746 loss: 0.000211094142
Iter: 1747 loss: 0.000210868282
Iter: 1748 loss: 0.000210763712
Iter: 1749 loss: 0.000212290295
Iter: 1750 loss: 0.000210763697
Iter: 1751 loss: 0.000210684753
Iter: 1752 loss: 0.000210727041
Iter: 1753 loss: 0.000210634229
Iter: 1754 loss: 0.000210665778
Iter: 1755 loss: 0.000210589293
Iter: 1756 loss: 0.000210566024
Iter: 1757 loss: 0.000210505154
Iter: 1758 loss: 0.000210974933
Iter: 1759 loss: 0.000210493221
Iter: 1760 loss: 0.000210430459
Iter: 1761 loss: 0.0002104382
Iter: 1762 loss: 0.000210382044
Iter: 1763 loss: 0.000210322352
Iter: 1764 loss: 0.000211078979
Iter: 1765 loss: 0.000210321465
Iter: 1766 loss: 0.000210273822
Iter: 1767 loss: 0.000210210259
Iter: 1768 loss: 0.000210206636
Iter: 1769 loss: 0.000210138271
Iter: 1770 loss: 0.000210702157
Iter: 1771 loss: 0.000210133803
Iter: 1772 loss: 0.000210058308
Iter: 1773 loss: 0.000210442435
Iter: 1774 loss: 0.000210045953
Iter: 1775 loss: 0.000209991878
Iter: 1776 loss: 0.000209933467
Iter: 1777 loss: 0.000209923979
Iter: 1778 loss: 0.000209850317
Iter: 1779 loss: 0.000209932798
Iter: 1780 loss: 0.00020981027
Iter: 1781 loss: 0.000209719947
Iter: 1782 loss: 0.0002099587
Iter: 1783 loss: 0.000209690174
Iter: 1784 loss: 0.000209590857
Iter: 1785 loss: 0.000210094964
Iter: 1786 loss: 0.000209575679
Iter: 1787 loss: 0.000209599282
Iter: 1788 loss: 0.000209549413
Iter: 1789 loss: 0.000209521691
Iter: 1790 loss: 0.000209454854
Iter: 1791 loss: 0.000210213795
Iter: 1792 loss: 0.000209448262
Iter: 1793 loss: 0.000209376478
Iter: 1794 loss: 0.00020943032
Iter: 1795 loss: 0.000209331789
Iter: 1796 loss: 0.000209263104
Iter: 1797 loss: 0.000209623162
Iter: 1798 loss: 0.000209251622
Iter: 1799 loss: 0.000209184363
Iter: 1800 loss: 0.000209338876
Iter: 1801 loss: 0.000209159407
Iter: 1802 loss: 0.00020909452
Iter: 1803 loss: 0.000209097387
Iter: 1804 loss: 0.000209043239
Iter: 1805 loss: 0.000208974219
Iter: 1806 loss: 0.000209591963
Iter: 1807 loss: 0.000208970145
Iter: 1808 loss: 0.000208904894
Iter: 1809 loss: 0.000209302903
Iter: 1810 loss: 0.000208896614
Iter: 1811 loss: 0.000208856247
Iter: 1812 loss: 0.000208750644
Iter: 1813 loss: 0.000209600286
Iter: 1814 loss: 0.000208731188
Iter: 1815 loss: 0.000208631376
Iter: 1816 loss: 0.000209055215
Iter: 1817 loss: 0.000208610873
Iter: 1818 loss: 0.000208496305
Iter: 1819 loss: 0.000208792539
Iter: 1820 loss: 0.000208457277
Iter: 1821 loss: 0.000208332523
Iter: 1822 loss: 0.000208513724
Iter: 1823 loss: 0.000208271769
Iter: 1824 loss: 0.000208539772
Iter: 1825 loss: 0.000208248835
Iter: 1826 loss: 0.000208231242
Iter: 1827 loss: 0.000208176876
Iter: 1828 loss: 0.000208248341
Iter: 1829 loss: 0.000208136509
Iter: 1830 loss: 0.000208069599
Iter: 1831 loss: 0.000208091442
Iter: 1832 loss: 0.000208022306
Iter: 1833 loss: 0.000207946345
Iter: 1834 loss: 0.000208053127
Iter: 1835 loss: 0.000207909368
Iter: 1836 loss: 0.000207813835
Iter: 1837 loss: 0.000208246085
Iter: 1838 loss: 0.000207795383
Iter: 1839 loss: 0.000207726553
Iter: 1840 loss: 0.000207967081
Iter: 1841 loss: 0.000207708406
Iter: 1842 loss: 0.000207629346
Iter: 1843 loss: 0.000207790363
Iter: 1844 loss: 0.000207597594
Iter: 1845 loss: 0.00020752367
Iter: 1846 loss: 0.000208010446
Iter: 1847 loss: 0.000207515375
Iter: 1848 loss: 0.000207469551
Iter: 1849 loss: 0.000207398378
Iter: 1850 loss: 0.000207397854
Iter: 1851 loss: 0.00020730494
Iter: 1852 loss: 0.000207234378
Iter: 1853 loss: 0.000207204721
Iter: 1854 loss: 0.000207097182
Iter: 1855 loss: 0.00020698861
Iter: 1856 loss: 0.000206966914
Iter: 1857 loss: 0.000206848053
Iter: 1858 loss: 0.000206848141
Iter: 1859 loss: 0.000206812023
Iter: 1860 loss: 0.000206796074
Iter: 1861 loss: 0.000206750265
Iter: 1862 loss: 0.000206636076
Iter: 1863 loss: 0.0002077346
Iter: 1864 loss: 0.000206620665
Iter: 1865 loss: 0.000206507626
Iter: 1866 loss: 0.000206793848
Iter: 1867 loss: 0.000206468598
Iter: 1868 loss: 0.000206369543
Iter: 1869 loss: 0.000206619414
Iter: 1870 loss: 0.000206335477
Iter: 1871 loss: 0.000206220167
Iter: 1872 loss: 0.000206442579
Iter: 1873 loss: 0.000206171244
Iter: 1874 loss: 0.000206071112
Iter: 1875 loss: 0.000206724959
Iter: 1876 loss: 0.000206060708
Iter: 1877 loss: 0.000205993812
Iter: 1878 loss: 0.000206608864
Iter: 1879 loss: 0.000205990349
Iter: 1880 loss: 0.000205935183
Iter: 1881 loss: 0.00020589288
Iter: 1882 loss: 0.000205874705
Iter: 1883 loss: 0.000205789678
Iter: 1884 loss: 0.000205864504
Iter: 1885 loss: 0.000205739809
Iter: 1886 loss: 0.000205652526
Iter: 1887 loss: 0.000205750039
Iter: 1888 loss: 0.000205605436
Iter: 1889 loss: 0.000205548888
Iter: 1890 loss: 0.000205541059
Iter: 1891 loss: 0.000205522068
Iter: 1892 loss: 0.000205520191
Iter: 1893 loss: 0.000205498945
Iter: 1894 loss: 0.000205459539
Iter: 1895 loss: 0.000205459626
Iter: 1896 loss: 0.000205416785
Iter: 1897 loss: 0.000205421355
Iter: 1898 loss: 0.000205383083
Iter: 1899 loss: 0.000205337739
Iter: 1900 loss: 0.000205385833
Iter: 1901 loss: 0.000205312623
Iter: 1902 loss: 0.000205247736
Iter: 1903 loss: 0.000205502933
Iter: 1904 loss: 0.000205232791
Iter: 1905 loss: 0.000205182121
Iter: 1906 loss: 0.000205295088
Iter: 1907 loss: 0.000205162869
Iter: 1908 loss: 0.000205105345
Iter: 1909 loss: 0.000205369128
Iter: 1910 loss: 0.00020509382
Iter: 1911 loss: 0.000205034972
Iter: 1912 loss: 0.000205215387
Iter: 1913 loss: 0.000205017335
Iter: 1914 loss: 0.000204956828
Iter: 1915 loss: 0.00020484718
Iter: 1916 loss: 0.000207493707
Iter: 1917 loss: 0.00020484718
Iter: 1918 loss: 0.000204741795
Iter: 1919 loss: 0.000205513817
Iter: 1920 loss: 0.000204733602
Iter: 1921 loss: 0.000204636774
Iter: 1922 loss: 0.000204869008
Iter: 1923 loss: 0.00020460182
Iter: 1924 loss: 0.000204619573
Iter: 1925 loss: 0.00020456643
Iter: 1926 loss: 0.000204536918
Iter: 1927 loss: 0.000204495504
Iter: 1928 loss: 0.000204494339
Iter: 1929 loss: 0.000204448967
Iter: 1930 loss: 0.000204437936
Iter: 1931 loss: 0.000204409298
Iter: 1932 loss: 0.000204336393
Iter: 1933 loss: 0.000204360666
Iter: 1934 loss: 0.000204284937
Iter: 1935 loss: 0.000204198062
Iter: 1936 loss: 0.000204861775
Iter: 1937 loss: 0.000204192038
Iter: 1938 loss: 0.000204117416
Iter: 1939 loss: 0.00020418287
Iter: 1940 loss: 0.000204074255
Iter: 1941 loss: 0.000203994365
Iter: 1942 loss: 0.000204466429
Iter: 1943 loss: 0.000203984906
Iter: 1944 loss: 0.000203895703
Iter: 1945 loss: 0.000203989708
Iter: 1946 loss: 0.00020384675
Iter: 1947 loss: 0.000203752817
Iter: 1948 loss: 0.000204069365
Iter: 1949 loss: 0.000203727875
Iter: 1950 loss: 0.000203644653
Iter: 1951 loss: 0.000203560106
Iter: 1952 loss: 0.000203543779
Iter: 1953 loss: 0.000203417047
Iter: 1954 loss: 0.000203859774
Iter: 1955 loss: 0.000203384028
Iter: 1956 loss: 0.000203456424
Iter: 1957 loss: 0.000203345611
Iter: 1958 loss: 0.000203305244
Iter: 1959 loss: 0.000203268137
Iter: 1960 loss: 0.000203258533
Iter: 1961 loss: 0.00020320552
Iter: 1962 loss: 0.000203128584
Iter: 1963 loss: 0.000203126343
Iter: 1964 loss: 0.000203036267
Iter: 1965 loss: 0.000203304691
Iter: 1966 loss: 0.000203009316
Iter: 1967 loss: 0.000202915457
Iter: 1968 loss: 0.000203021162
Iter: 1969 loss: 0.000202865704
Iter: 1970 loss: 0.00020273868
Iter: 1971 loss: 0.000203278818
Iter: 1972 loss: 0.000202711613
Iter: 1973 loss: 0.000202624229
Iter: 1974 loss: 0.000202911411
Iter: 1975 loss: 0.000202600088
Iter: 1976 loss: 0.000202502037
Iter: 1977 loss: 0.000202792886
Iter: 1978 loss: 0.000202472555
Iter: 1979 loss: 0.000202392956
Iter: 1980 loss: 0.000202611031
Iter: 1981 loss: 0.000202366704
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/k4
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0
+ date
Tue Oct 27 17:25:32 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8c812bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8c812bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8c808b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8c80b1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd94c62a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8c8045268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd94c62aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8a00eea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd94c62ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8c8020f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8a00bbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8a0089c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8a00892f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd89825f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8a0089bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd89820cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8981ca620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8981ca8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8981a97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd898165a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd898165510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd89810bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8980c9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8980dbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8980f2c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8980a7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd898067378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8980721e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd898072950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd89802e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8980a71e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd880139620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd880139400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8800a5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd8800d9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd880063f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00448169047
Iter: 2 loss: 0.00446442794
Iter: 3 loss: 0.00439876784
Iter: 4 loss: 0.00415241346
Iter: 5 loss: 0.00503807422
Iter: 6 loss: 0.00403895089
Iter: 7 loss: 0.00391503144
Iter: 8 loss: 0.00565103441
Iter: 9 loss: 0.00391476182
Iter: 10 loss: 0.00383680174
Iter: 11 loss: 0.00427873479
Iter: 12 loss: 0.00382612948
Iter: 13 loss: 0.00378934457
Iter: 14 loss: 0.00383161847
Iter: 15 loss: 0.00376962172
Iter: 16 loss: 0.0037490041
Iter: 17 loss: 0.0040156953
Iter: 18 loss: 0.00374885905
Iter: 19 loss: 0.00373607315
Iter: 20 loss: 0.00381815038
Iter: 21 loss: 0.00373467896
Iter: 22 loss: 0.0037284086
Iter: 23 loss: 0.00373320887
Iter: 24 loss: 0.0037245932
Iter: 25 loss: 0.00372097082
Iter: 26 loss: 0.00377442036
Iter: 27 loss: 0.0037209664
Iter: 28 loss: 0.00371846254
Iter: 29 loss: 0.00372983981
Iter: 30 loss: 0.00371798431
Iter: 31 loss: 0.00371685601
Iter: 32 loss: 0.00371741317
Iter: 33 loss: 0.00371610257
Iter: 34 loss: 0.00371537521
Iter: 35 loss: 0.00372261647
Iter: 36 loss: 0.00371535099
Iter: 37 loss: 0.00371499918
Iter: 38 loss: 0.00371499639
Iter: 39 loss: 0.00371483248
Iter: 40 loss: 0.0037147915
Iter: 41 loss: 0.00371468882
Iter: 42 loss: 0.00371456263
Iter: 43 loss: 0.00371503015
Iter: 44 loss: 0.00371453166
Iter: 45 loss: 0.00371446321
Iter: 46 loss: 0.00371487299
Iter: 47 loss: 0.00371445389
Iter: 48 loss: 0.00371443201
Iter: 49 loss: 0.00371443178
Iter: 50 loss: 0.00371441548
Iter: 51 loss: 0.00371450209
Iter: 52 loss: 0.00371441245
Iter: 53 loss: 0.0037144064
Iter: 54 loss: 0.00371441059
Iter: 55 loss: 0.00371440221
Iter: 56 loss: 0.00371439662
Iter: 57 loss: 0.00371439662
Iter: 58 loss: 0.00371439452
Iter: 59 loss: 0.00371440593
Iter: 60 loss: 0.00371439359
Iter: 61 loss: 0.00371439289
Iter: 62 loss: 0.00371439382
Iter: 63 loss: 0.00371439196
Iter: 64 loss: 0.0037143908
Iter: 65 loss: 0.00371439056
Iter: 66 loss: 0.0037143908
Iter: 67 loss: 0.00371439126
Iter: 68 loss: 0.00371438987
Iter: 69 loss: 0.00371439
Iter: 70 loss: 0.00371439
Iter: 71 loss: 0.00371438963
Iter: 72 loss: 0.0037143894
Iter: 73 loss: 0.0037143908
Iter: 74 loss: 0.00371439
Iter: 75 loss: 0.00371438987
Iter: 76 loss: 0.00371439
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4
+ date
Tue Oct 27 17:26:17 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aac17730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aad0d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aad0dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aac61598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aabae510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aabc6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aab28620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aab5a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aab5a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aab28488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aab5a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aaa738c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aab5a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aaa26d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aaa5e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa9efd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aaa08730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aaa5e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa9dd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aaa13730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa992620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa992510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa90d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa8b4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa8b4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa865598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa89e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa844620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa89ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa7e4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa816ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa7d0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa7d0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa7736a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa72a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f85aa743ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0297812298
Iter: 2 loss: 0.0286576822
Iter: 3 loss: 0.0245110448
Iter: 4 loss: 0.0112343086
Iter: 5 loss: 0.172798455
Iter: 6 loss: 0.00957298279
Iter: 7 loss: 0.00523680914
Iter: 8 loss: 0.0772826374
Iter: 9 loss: 0.0052271653
Iter: 10 loss: 0.00484260265
Iter: 11 loss: 0.00446857559
Iter: 12 loss: 0.00421422068
Iter: 13 loss: 0.00477124145
Iter: 14 loss: 0.00411637919
Iter: 15 loss: 0.0039975
Iter: 16 loss: 0.0047909175
Iter: 17 loss: 0.00398475491
Iter: 18 loss: 0.00393530261
Iter: 19 loss: 0.00468384102
Iter: 20 loss: 0.00393528119
Iter: 21 loss: 0.00391052291
Iter: 22 loss: 0.00394971948
Iter: 23 loss: 0.00389893912
Iter: 24 loss: 0.00388463354
Iter: 25 loss: 0.00402992778
Iter: 26 loss: 0.00388420653
Iter: 27 loss: 0.00387453591
Iter: 28 loss: 0.0038993319
Iter: 29 loss: 0.00387120503
Iter: 30 loss: 0.00386606436
Iter: 31 loss: 0.00387246162
Iter: 32 loss: 0.00386339147
Iter: 33 loss: 0.00385984
Iter: 34 loss: 0.00388867734
Iter: 35 loss: 0.00385961332
Iter: 36 loss: 0.00385720399
Iter: 37 loss: 0.00387253333
Iter: 38 loss: 0.00385693554
Iter: 39 loss: 0.00385561748
Iter: 40 loss: 0.0038583877
Iter: 41 loss: 0.00385509524
Iter: 42 loss: 0.0038542843
Iter: 43 loss: 0.00385886128
Iter: 44 loss: 0.00385417114
Iter: 45 loss: 0.00385372899
Iter: 46 loss: 0.00385982287
Iter: 47 loss: 0.00385372853
Iter: 48 loss: 0.00385348732
Iter: 49 loss: 0.00385371363
Iter: 50 loss: 0.00385334971
Iter: 51 loss: 0.00385316508
Iter: 52 loss: 0.00385395484
Iter: 53 loss: 0.00385312806
Iter: 54 loss: 0.00385303
Iter: 55 loss: 0.00385303
Iter: 56 loss: 0.00385296647
Iter: 57 loss: 0.00385308871
Iter: 58 loss: 0.00385293877
Iter: 59 loss: 0.00385290198
Iter: 60 loss: 0.00385318603
Iter: 61 loss: 0.00385289825
Iter: 62 loss: 0.00385286985
Iter: 63 loss: 0.00385295623
Iter: 64 loss: 0.0038528617
Iter: 65 loss: 0.00385284331
Iter: 66 loss: 0.00385290082
Iter: 67 loss: 0.00385283679
Iter: 68 loss: 0.00385282584
Iter: 69 loss: 0.0038528773
Iter: 70 loss: 0.00385282282
Iter: 71 loss: 0.00385281607
Iter: 72 loss: 0.0038528759
Iter: 73 loss: 0.0038528156
Iter: 74 loss: 0.00385281071
Iter: 75 loss: 0.00385282864
Iter: 76 loss: 0.00385280978
Iter: 77 loss: 0.00385280699
Iter: 78 loss: 0.00385281374
Iter: 79 loss: 0.00385280605
Iter: 80 loss: 0.00385280442
Iter: 81 loss: 0.00385282235
Iter: 82 loss: 0.00385280396
Iter: 83 loss: 0.00385280326
Iter: 84 loss: 0.00385280862
Iter: 85 loss: 0.00385280256
Iter: 86 loss: 0.0038528021
Iter: 87 loss: 0.00385280326
Iter: 88 loss: 0.00385280233
Iter: 89 loss: 0.00385280093
Iter: 90 loss: 0.0038528021
Iter: 91 loss: 0.0038528014
Iter: 92 loss: 0.00385280163
Iter: 93 loss: 0.00385280093
Iter: 94 loss: 0.00385280093
Iter: 95 loss: 0.0038528014
Iter: 96 loss: 0.0038528007
Iter: 97 loss: 0.00385280093
Iter: 98 loss: 0.00385280186
Iter: 99 loss: 0.00385280047
Iter: 100 loss: 0.00385280047
Iter: 101 loss: 0.00385280047
Iter: 102 loss: 0.0038528
Iter: 103 loss: 0.0038528
Iter: 104 loss: 0.0038528
Iter: 105 loss: 0.00385280023
Iter: 106 loss: 0.00385280116
Iter: 107 loss: 0.0038528014
Iter: 108 loss: 0.0038528
Iter: 109 loss: 0.0038528007
Iter: 110 loss: 0.00385280047
Iter: 111 loss: 0.00385279977
Iter: 112 loss: 0.0038528
Iter: 113 loss: 0.00385280047
Iter: 114 loss: 0.00385280023
Iter: 115 loss: 0.0038528007
Iter: 116 loss: 0.0038528
Iter: 117 loss: 0.00385280047
Iter: 118 loss: 0.00385280023
Iter: 119 loss: 0.00385280023
Iter: 120 loss: 0.00385280093
Iter: 121 loss: 0.0038528
Iter: 122 loss: 0.00385279977
Iter: 123 loss: 0.0038528
Iter: 124 loss: 0.0038528
Iter: 125 loss: 0.00385280116
Iter: 126 loss: 0.00385280047
Iter: 127 loss: 0.00385280023
Iter: 128 loss: 0.0038527993
Iter: 129 loss: 0.00385279977
Iter: 130 loss: 0.00385280047
Iter: 131 loss: 0.00385279953
Iter: 132 loss: 0.00385279953
Iter: 133 loss: 0.0038528007
Iter: 134 loss: 0.00385280047
Iter: 135 loss: 0.00385279977
Iter: 136 loss: 0.0038527993
Iter: 137 loss: 0.0038528
Iter: 138 loss: 0.0038528
Iter: 139 loss: 0.0038528
Iter: 140 loss: 0.00385280047
Iter: 141 loss: 0.0038528
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8
+ date
Tue Oct 27 17:27:19 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d125b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d1267d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d12cf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d120c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d11650d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d117fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d117f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d111b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d111b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d10a4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d1075b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d10310d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d10318c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0fdc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d10189d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0fa7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0fc3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d1018d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0f956a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0fcda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0f4d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0f95d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0ec86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0e70950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0e70378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0e1f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0e5b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae96f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5d0e5b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae914378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae944ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae8fc2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae8fc488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae8a16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae85ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd5ae86ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0225935169
Iter: 2 loss: 0.0216996558
Iter: 3 loss: 0.0184870511
Iter: 4 loss: 0.0156135438
Iter: 5 loss: 0.0135863032
Iter: 6 loss: 0.00877048541
Iter: 7 loss: 0.0689437538
Iter: 8 loss: 0.00835108105
Iter: 9 loss: 0.0056063435
Iter: 10 loss: 0.00550340582
Iter: 11 loss: 0.0049599167
Iter: 12 loss: 0.00889949594
Iter: 13 loss: 0.00488831196
Iter: 14 loss: 0.0046355552
Iter: 15 loss: 0.00857560616
Iter: 16 loss: 0.00463417359
Iter: 17 loss: 0.0045023
Iter: 18 loss: 0.00465662777
Iter: 19 loss: 0.00443404
Iter: 20 loss: 0.004327
Iter: 21 loss: 0.00465323636
Iter: 22 loss: 0.00429307763
Iter: 23 loss: 0.00423704274
Iter: 24 loss: 0.00449178414
Iter: 25 loss: 0.00422602845
Iter: 26 loss: 0.00419362495
Iter: 27 loss: 0.00451931637
Iter: 28 loss: 0.00419258326
Iter: 29 loss: 0.00417453237
Iter: 30 loss: 0.00424573198
Iter: 31 loss: 0.00417038612
Iter: 32 loss: 0.00416003
Iter: 33 loss: 0.00419675
Iter: 34 loss: 0.004157349
Iter: 35 loss: 0.00415081624
Iter: 36 loss: 0.00418807659
Iter: 37 loss: 0.00414992031
Iter: 38 loss: 0.00414558407
Iter: 39 loss: 0.00416544266
Iter: 40 loss: 0.00414475333
Iter: 41 loss: 0.00414192164
Iter: 42 loss: 0.00415729079
Iter: 43 loss: 0.00414150301
Iter: 44 loss: 0.00413965527
Iter: 45 loss: 0.00415406609
Iter: 46 loss: 0.00413952162
Iter: 47 loss: 0.00413822848
Iter: 48 loss: 0.00414236356
Iter: 49 loss: 0.00413786154
Iter: 50 loss: 0.00413673278
Iter: 51 loss: 0.00413809251
Iter: 52 loss: 0.00413614046
Iter: 53 loss: 0.00413506432
Iter: 54 loss: 0.00414254423
Iter: 55 loss: 0.00413496327
Iter: 56 loss: 0.00413426897
Iter: 57 loss: 0.00413941452
Iter: 58 loss: 0.00413421309
Iter: 59 loss: 0.00413369481
Iter: 60 loss: 0.0041342862
Iter: 61 loss: 0.00413341587
Iter: 62 loss: 0.00413297536
Iter: 63 loss: 0.00413363753
Iter: 64 loss: 0.00413276302
Iter: 65 loss: 0.00413234159
Iter: 66 loss: 0.00413381401
Iter: 67 loss: 0.00413223077
Iter: 68 loss: 0.00413192529
Iter: 69 loss: 0.00413364824
Iter: 70 loss: 0.00413188338
Iter: 71 loss: 0.00413165707
Iter: 72 loss: 0.00413238676
Iter: 73 loss: 0.00413159328
Iter: 74 loss: 0.00413143355
Iter: 75 loss: 0.00413217396
Iter: 76 loss: 0.00413140375
Iter: 77 loss: 0.00413129
Iter: 78 loss: 0.00413195044
Iter: 79 loss: 0.00413127337
Iter: 80 loss: 0.00413120259
Iter: 81 loss: 0.00413162727
Iter: 82 loss: 0.00413119327
Iter: 83 loss: 0.00413114
Iter: 84 loss: 0.00413150061
Iter: 85 loss: 0.00413113413
Iter: 86 loss: 0.00413110061
Iter: 87 loss: 0.00413112435
Iter: 88 loss: 0.00413107965
Iter: 89 loss: 0.00413105497
Iter: 90 loss: 0.00413132366
Iter: 91 loss: 0.00413105497
Iter: 92 loss: 0.00413103867
Iter: 93 loss: 0.00413111644
Iter: 94 loss: 0.00413103495
Iter: 95 loss: 0.00413102331
Iter: 96 loss: 0.00413104519
Iter: 97 loss: 0.00413101865
Iter: 98 loss: 0.00413100887
Iter: 99 loss: 0.00413102936
Iter: 100 loss: 0.00413100561
Iter: 101 loss: 0.00413099676
Iter: 102 loss: 0.00413102098
Iter: 103 loss: 0.00413099537
Iter: 104 loss: 0.00413098931
Iter: 105 loss: 0.00413101912
Iter: 106 loss: 0.00413098931
Iter: 107 loss: 0.00413098559
Iter: 108 loss: 0.00413100095
Iter: 109 loss: 0.00413098466
Iter: 110 loss: 0.00413098233
Iter: 111 loss: 0.00413099397
Iter: 112 loss: 0.0041309814
Iter: 113 loss: 0.00413098093
Iter: 114 loss: 0.00413098605
Iter: 115 loss: 0.00413098
Iter: 116 loss: 0.00413097907
Iter: 117 loss: 0.00413098838
Iter: 118 loss: 0.00413097907
Iter: 119 loss: 0.00413097907
Iter: 120 loss: 0.00413098233
Iter: 121 loss: 0.00413097814
Iter: 122 loss: 0.00413097814
Iter: 123 loss: 0.00413097907
Iter: 124 loss: 0.00413097814
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2
+ date
Tue Oct 27 17:28:16 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95b8c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95c88ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95c88840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95c88620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95b23378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95b23a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95aa2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95ad5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95aa28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95a71488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95a30950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f959ec8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f959f71e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f9599aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f959ec378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f9599aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f959646a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95987950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f958e0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f958e0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f959059d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f958bad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95886730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f9581d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f9581d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f957da378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f958159d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f95815840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f957c1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f9575b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f9578ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f957451e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f9574b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f956ea8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f7b23fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2f7b23f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0238065943
Iter: 2 loss: 0.0215467699
Iter: 3 loss: 0.0153040718
Iter: 4 loss: 5629.48877
Iter: 5 loss: 0.0496946
Iter: 6 loss: 0.0212050304
Iter: 7 loss: 0.0381224714
Iter: 8 loss: 0.0179351475
Iter: 9 loss: 0.0250841565
Iter: 10 loss: 0.0135613922
Iter: 11 loss: 0.0111005008
Iter: 12 loss: 0.00919986
Iter: 13 loss: 0.0074122618
Iter: 14 loss: 0.0428887308
Iter: 15 loss: 0.00737911742
Iter: 16 loss: 0.0060085142
Iter: 17 loss: 0.012149266
Iter: 18 loss: 0.00571126956
Iter: 19 loss: 0.00535274297
Iter: 20 loss: 0.00655685924
Iter: 21 loss: 0.00525095779
Iter: 22 loss: 0.00504662283
Iter: 23 loss: 0.00664087432
Iter: 24 loss: 0.005024096
Iter: 25 loss: 0.00490263104
Iter: 26 loss: 0.00583394105
Iter: 27 loss: 0.00489144539
Iter: 28 loss: 0.00481447112
Iter: 29 loss: 0.00497118756
Iter: 30 loss: 0.00478411838
Iter: 31 loss: 0.00472421106
Iter: 32 loss: 0.00481151184
Iter: 33 loss: 0.00469506579
Iter: 34 loss: 0.00463486835
Iter: 35 loss: 0.00477045029
Iter: 36 loss: 0.00461083092
Iter: 37 loss: 0.00456829788
Iter: 38 loss: 0.00480153272
Iter: 39 loss: 0.00456198677
Iter: 40 loss: 0.00453295186
Iter: 41 loss: 0.0047284835
Iter: 42 loss: 0.00452989247
Iter: 43 loss: 0.00450948253
Iter: 44 loss: 0.00455942564
Iter: 45 loss: 0.00450214744
Iter: 46 loss: 0.00448661158
Iter: 47 loss: 0.00456640124
Iter: 48 loss: 0.00448398665
Iter: 49 loss: 0.00447711116
Iter: 50 loss: 0.00447707856
Iter: 51 loss: 0.00447147293
Iter: 52 loss: 0.00447370484
Iter: 53 loss: 0.00446758373
Iter: 54 loss: 0.0044633
Iter: 55 loss: 0.00448190421
Iter: 56 loss: 0.00446243491
Iter: 57 loss: 0.00445942115
Iter: 58 loss: 0.00446686707
Iter: 59 loss: 0.00445835944
Iter: 60 loss: 0.00445558969
Iter: 61 loss: 0.00446463656
Iter: 62 loss: 0.00445481436
Iter: 63 loss: 0.00445276545
Iter: 64 loss: 0.00446668826
Iter: 65 loss: 0.00445255823
Iter: 66 loss: 0.00445089536
Iter: 67 loss: 0.00446030218
Iter: 68 loss: 0.00445066346
Iter: 69 loss: 0.00444937218
Iter: 70 loss: 0.00445389
Iter: 71 loss: 0.00444903504
Iter: 72 loss: 0.00444793515
Iter: 73 loss: 0.00444772234
Iter: 74 loss: 0.00444699
Iter: 75 loss: 0.00444577634
Iter: 76 loss: 0.00445491821
Iter: 77 loss: 0.00444568
Iter: 78 loss: 0.00444471929
Iter: 79 loss: 0.00445137033
Iter: 80 loss: 0.00444463082
Iter: 81 loss: 0.00444396958
Iter: 82 loss: 0.0044448548
Iter: 83 loss: 0.00444363616
Iter: 84 loss: 0.00444299774
Iter: 85 loss: 0.00444655633
Iter: 86 loss: 0.00444290787
Iter: 87 loss: 0.00444236351
Iter: 88 loss: 0.00444307411
Iter: 89 loss: 0.00444208551
Iter: 90 loss: 0.00444152
Iter: 91 loss: 0.0044424
Iter: 92 loss: 0.00444125663
Iter: 93 loss: 0.00444065034
Iter: 94 loss: 0.00444288366
Iter: 95 loss: 0.0044405004
Iter: 96 loss: 0.00443999795
Iter: 97 loss: 0.00444086641
Iter: 98 loss: 0.00443977537
Iter: 99 loss: 0.00443930645
Iter: 100 loss: 0.00444189599
Iter: 101 loss: 0.00443923753
Iter: 102 loss: 0.00443892367
Iter: 103 loss: 0.00444178516
Iter: 104 loss: 0.00443890877
Iter: 105 loss: 0.00443862565
Iter: 106 loss: 0.00443895813
Iter: 107 loss: 0.00443847757
Iter: 108 loss: 0.004438214
Iter: 109 loss: 0.00443819398
Iter: 110 loss: 0.00443799747
Iter: 111 loss: 0.00443775672
Iter: 112 loss: 0.00444131624
Iter: 113 loss: 0.0044377544
Iter: 114 loss: 0.0044375658
Iter: 115 loss: 0.00443846
Iter: 116 loss: 0.00443753228
Iter: 117 loss: 0.00443740562
Iter: 118 loss: 0.00443768315
Iter: 119 loss: 0.00443735812
Iter: 120 loss: 0.00443723425
Iter: 121 loss: 0.00443761609
Iter: 122 loss: 0.00443719793
Iter: 123 loss: 0.0044370871
Iter: 124 loss: 0.00443734229
Iter: 125 loss: 0.00443704613
Iter: 126 loss: 0.00443695066
Iter: 127 loss: 0.00443713414
Iter: 128 loss: 0.00443691
Iter: 129 loss: 0.0044368254
Iter: 130 loss: 0.00443735
Iter: 131 loss: 0.00443681516
Iter: 132 loss: 0.00443675648
Iter: 133 loss: 0.00443687104
Iter: 134 loss: 0.00443673087
Iter: 135 loss: 0.00443667686
Iter: 136 loss: 0.00443690643
Iter: 137 loss: 0.00443666428
Iter: 138 loss: 0.00443662377
Iter: 139 loss: 0.00443713367
Iter: 140 loss: 0.00443662331
Iter: 141 loss: 0.00443659537
Iter: 142 loss: 0.00443660142
Iter: 143 loss: 0.00443657534
Iter: 144 loss: 0.0044365488
Iter: 145 loss: 0.00443663914
Iter: 146 loss: 0.00443654135
Iter: 147 loss: 0.00443652
Iter: 148 loss: 0.00443665311
Iter: 149 loss: 0.00443651713
Iter: 150 loss: 0.00443650223
Iter: 151 loss: 0.0044366424
Iter: 152 loss: 0.00443650177
Iter: 153 loss: 0.00443649
Iter: 154 loss: 0.00443649758
Iter: 155 loss: 0.00443648314
Iter: 156 loss: 0.00443647336
Iter: 157 loss: 0.00443650177
Iter: 158 loss: 0.00443646964
Iter: 159 loss: 0.00443645893
Iter: 160 loss: 0.00443649897
Iter: 161 loss: 0.00443645567
Iter: 162 loss: 0.00443644915
Iter: 163 loss: 0.00443645613
Iter: 164 loss: 0.00443644356
Iter: 165 loss: 0.00443643704
Iter: 166 loss: 0.00443649106
Iter: 167 loss: 0.00443643844
Iter: 168 loss: 0.00443643192
Iter: 169 loss: 0.00443644263
Iter: 170 loss: 0.00443642912
Iter: 171 loss: 0.0044364254
Iter: 172 loss: 0.00443645474
Iter: 173 loss: 0.00443642493
Iter: 174 loss: 0.00443642261
Iter: 175 loss: 0.00443644356
Iter: 176 loss: 0.00443642214
Iter: 177 loss: 0.00443641935
Iter: 178 loss: 0.00443642028
Iter: 179 loss: 0.00443641841
Iter: 180 loss: 0.00443641655
Iter: 181 loss: 0.00443642261
Iter: 182 loss: 0.00443641422
Iter: 183 loss: 0.00443641422
Iter: 184 loss: 0.00443642959
Iter: 185 loss: 0.00443641283
Iter: 186 loss: 0.00443641376
Iter: 187 loss: 0.00443641841
Iter: 188 loss: 0.00443641236
Iter: 189 loss: 0.0044364105
Iter: 190 loss: 0.00443641189
Iter: 191 loss: 0.00443641096
Iter: 192 loss: 0.0044364091
Iter: 193 loss: 0.00443641702
Iter: 194 loss: 0.0044364091
Iter: 195 loss: 0.00443640864
Iter: 196 loss: 0.00443641
Iter: 197 loss: 0.00443640817
Iter: 198 loss: 0.00443640631
Iter: 199 loss: 0.00443641189
Iter: 200 loss: 0.00443640631
Iter: 201 loss: 0.00443640584
Iter: 202 loss: 0.00443640817
Iter: 203 loss: 0.00443640631
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6
+ date
Tue Oct 27 17:29:31 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c37f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c37f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05b4638e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c3a60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c308ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c338400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c2e5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c299048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c2b7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c2b7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c2991e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c1ce510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c1cec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c230b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c1bd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c1bd268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c14e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c171620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c0ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c0ce1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c0ee9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c0fcea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c06d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c0eef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c00d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f058c01be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f057021f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f057021f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05701c4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0570164488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05701c49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05701527b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0570159268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05700f6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f05700f6598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0570152400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0318808854
Iter: 2 loss: 0.0219429526
Iter: 3 loss: 3557.87378
Iter: 4 loss: 0.0219429471
Iter: 5 loss: 0.0429240391
Iter: 6 loss: 0.0205227509
Iter: 7 loss: 0.016907325
Iter: 8 loss: 0.0157861374
Iter: 9 loss: 0.0130682187
Iter: 10 loss: 0.0810388848
Iter: 11 loss: 0.0130076595
Iter: 12 loss: 0.0107512614
Iter: 13 loss: 0.0227794964
Iter: 14 loss: 0.0104040131
Iter: 15 loss: 0.00944377482
Iter: 16 loss: 0.0102888802
Iter: 17 loss: 0.00895413663
Iter: 18 loss: 0.00807452
Iter: 19 loss: 0.00860359799
Iter: 20 loss: 0.00741432142
Iter: 21 loss: 0.00661701895
Iter: 22 loss: 0.0197073072
Iter: 23 loss: 0.00658809859
Iter: 24 loss: 0.00618013367
Iter: 25 loss: 0.00961244106
Iter: 26 loss: 0.00615333067
Iter: 27 loss: 0.00589898042
Iter: 28 loss: 0.00666271895
Iter: 29 loss: 0.0058271545
Iter: 30 loss: 0.00564598758
Iter: 31 loss: 0.00628499314
Iter: 32 loss: 0.00558920763
Iter: 33 loss: 0.00548048224
Iter: 34 loss: 0.00569062633
Iter: 35 loss: 0.005434772
Iter: 36 loss: 0.00533120893
Iter: 37 loss: 0.00621265173
Iter: 38 loss: 0.00532535557
Iter: 39 loss: 0.0052684024
Iter: 40 loss: 0.00574515853
Iter: 41 loss: 0.00526439399
Iter: 42 loss: 0.00522386469
Iter: 43 loss: 0.00520968903
Iter: 44 loss: 0.0051866686
Iter: 45 loss: 0.00512920367
Iter: 46 loss: 0.00539997639
Iter: 47 loss: 0.00511796912
Iter: 48 loss: 0.00508131273
Iter: 49 loss: 0.00536208414
Iter: 50 loss: 0.00507865567
Iter: 51 loss: 0.00506058615
Iter: 52 loss: 0.00505277701
Iter: 53 loss: 0.00504326774
Iter: 54 loss: 0.00502286153
Iter: 55 loss: 0.00506606931
Iter: 56 loss: 0.00501509104
Iter: 57 loss: 0.00499789743
Iter: 58 loss: 0.00499341404
Iter: 59 loss: 0.00498255529
Iter: 60 loss: 0.00495827757
Iter: 61 loss: 0.00507788127
Iter: 62 loss: 0.00495424401
Iter: 63 loss: 0.00493598217
Iter: 64 loss: 0.00494839298
Iter: 65 loss: 0.00492438115
Iter: 66 loss: 0.00490551349
Iter: 67 loss: 0.00500830263
Iter: 68 loss: 0.00490274839
Iter: 69 loss: 0.00488815969
Iter: 70 loss: 0.00503755081
Iter: 71 loss: 0.00488761906
Iter: 72 loss: 0.0048775943
Iter: 73 loss: 0.00488669239
Iter: 74 loss: 0.00487176888
Iter: 75 loss: 0.00486157835
Iter: 76 loss: 0.00489313621
Iter: 77 loss: 0.00485852361
Iter: 78 loss: 0.00485093612
Iter: 79 loss: 0.00489102164
Iter: 80 loss: 0.00484974589
Iter: 81 loss: 0.00484360568
Iter: 82 loss: 0.00485987077
Iter: 83 loss: 0.00484152371
Iter: 84 loss: 0.0048371288
Iter: 85 loss: 0.00488880416
Iter: 86 loss: 0.00483707292
Iter: 87 loss: 0.0048338105
Iter: 88 loss: 0.00484281313
Iter: 89 loss: 0.00483273203
Iter: 90 loss: 0.00482951943
Iter: 91 loss: 0.00484968163
Iter: 92 loss: 0.0048291632
Iter: 93 loss: 0.0048273
Iter: 94 loss: 0.00482457876
Iter: 95 loss: 0.00482450332
Iter: 96 loss: 0.00482164603
Iter: 97 loss: 0.00484611746
Iter: 98 loss: 0.00482149189
Iter: 99 loss: 0.00481971446
Iter: 100 loss: 0.00482145231
Iter: 101 loss: 0.00481870305
Iter: 102 loss: 0.00481688743
Iter: 103 loss: 0.00482341088
Iter: 104 loss: 0.00481642876
Iter: 105 loss: 0.00481508067
Iter: 106 loss: 0.00483489409
Iter: 107 loss: 0.00481507648
Iter: 108 loss: 0.00481409952
Iter: 109 loss: 0.0048132576
Iter: 110 loss: 0.00481299311
Iter: 111 loss: 0.00481176423
Iter: 112 loss: 0.00481797848
Iter: 113 loss: 0.00481156074
Iter: 114 loss: 0.00481041148
Iter: 115 loss: 0.00481256
Iter: 116 loss: 0.004809923
Iter: 117 loss: 0.00480903545
Iter: 118 loss: 0.00481664483
Iter: 119 loss: 0.00480898749
Iter: 120 loss: 0.00480831228
Iter: 121 loss: 0.00481206784
Iter: 122 loss: 0.00480821589
Iter: 123 loss: 0.00480766129
Iter: 124 loss: 0.00481061125
Iter: 125 loss: 0.00480757561
Iter: 126 loss: 0.00480707595
Iter: 127 loss: 0.00480716303
Iter: 128 loss: 0.00480670249
Iter: 129 loss: 0.0048061572
Iter: 130 loss: 0.00480723102
Iter: 131 loss: 0.00480593322
Iter: 132 loss: 0.00480535813
Iter: 133 loss: 0.00480563752
Iter: 134 loss: 0.00480497442
Iter: 135 loss: 0.00480437186
Iter: 136 loss: 0.00480879331
Iter: 137 loss: 0.0048043225
Iter: 138 loss: 0.00480384566
Iter: 139 loss: 0.00480498746
Iter: 140 loss: 0.0048036715
Iter: 141 loss: 0.00480317743
Iter: 142 loss: 0.00480592344
Iter: 143 loss: 0.00480310712
Iter: 144 loss: 0.00480270106
Iter: 145 loss: 0.00480368687
Iter: 146 loss: 0.00480255485
Iter: 147 loss: 0.00480216
Iter: 148 loss: 0.00480241422
Iter: 149 loss: 0.00480190944
Iter: 150 loss: 0.00480145961
Iter: 151 loss: 0.00480237883
Iter: 152 loss: 0.00480127893
Iter: 153 loss: 0.00480091106
Iter: 154 loss: 0.00480457
Iter: 155 loss: 0.00480089895
Iter: 156 loss: 0.00480060838
Iter: 157 loss: 0.00480259769
Iter: 158 loss: 0.00480058091
Iter: 159 loss: 0.00480032898
Iter: 160 loss: 0.00480084727
Iter: 161 loss: 0.00480022933
Iter: 162 loss: 0.00480000209
Iter: 163 loss: 0.00480032805
Iter: 164 loss: 0.00479989219
Iter: 165 loss: 0.00479965098
Iter: 166 loss: 0.00479965657
Iter: 167 loss: 0.0047994582
Iter: 168 loss: 0.00479917135
Iter: 169 loss: 0.00479987683
Iter: 170 loss: 0.00479906891
Iter: 171 loss: 0.00479877088
Iter: 172 loss: 0.00480032153
Iter: 173 loss: 0.00479872525
Iter: 174 loss: 0.0047984859
Iter: 175 loss: 0.00479913317
Iter: 176 loss: 0.0047984058
Iter: 177 loss: 0.00479819532
Iter: 178 loss: 0.00480006682
Iter: 179 loss: 0.00479818508
Iter: 180 loss: 0.00479802396
Iter: 181 loss: 0.00479807891
Iter: 182 loss: 0.00479791127
Iter: 183 loss: 0.00479771104
Iter: 184 loss: 0.00479813851
Iter: 185 loss: 0.00479763374
Iter: 186 loss: 0.00479742372
Iter: 187 loss: 0.00479817297
Iter: 188 loss: 0.00479737204
Iter: 189 loss: 0.0047972044
Iter: 190 loss: 0.0047976952
Iter: 191 loss: 0.00479715224
Iter: 192 loss: 0.0047970158
Iter: 193 loss: 0.00479701534
Iter: 194 loss: 0.004796925
Iter: 195 loss: 0.0047967881
Iter: 196 loss: 0.00479678437
Iter: 197 loss: 0.00479660276
Iter: 198 loss: 0.00479743257
Iter: 199 loss: 0.00479656644
Iter: 200 loss: 0.00479642721
Iter: 201 loss: 0.00479640905
Iter: 202 loss: 0.00479630847
Iter: 203 loss: 0.00479612499
Iter: 204 loss: 0.00479693245
Iter: 205 loss: 0.00479608867
Iter: 206 loss: 0.00479592662
Iter: 207 loss: 0.00479611522
Iter: 208 loss: 0.00479584
Iter: 209 loss: 0.0047957059
Iter: 210 loss: 0.00479736784
Iter: 211 loss: 0.00479570311
Iter: 212 loss: 0.00479559228
Iter: 213 loss: 0.00479579624
Iter: 214 loss: 0.00479554059
Iter: 215 loss: 0.00479541905
Iter: 216 loss: 0.00479575898
Iter: 217 loss: 0.00479537901
Iter: 218 loss: 0.00479527377
Iter: 219 loss: 0.00479544885
Iter: 220 loss: 0.00479522534
Iter: 221 loss: 0.00479510799
Iter: 222 loss: 0.00479540322
Iter: 223 loss: 0.00479506701
Iter: 224 loss: 0.00479497388
Iter: 225 loss: 0.00479583908
Iter: 226 loss: 0.00479497109
Iter: 227 loss: 0.00479489658
Iter: 228 loss: 0.00479543582
Iter: 229 loss: 0.0047948896
Iter: 230 loss: 0.00479483744
Iter: 231 loss: 0.00479478
Iter: 232 loss: 0.00479477
Iter: 233 loss: 0.00479468703
Iter: 234 loss: 0.0047949492
Iter: 235 loss: 0.00479466282
Iter: 236 loss: 0.00479458785
Iter: 237 loss: 0.00479492545
Iter: 238 loss: 0.00479457295
Iter: 239 loss: 0.00479451474
Iter: 240 loss: 0.00479462184
Iter: 241 loss: 0.00479449
Iter: 242 loss: 0.00479443371
Iter: 243 loss: 0.00479453523
Iter: 244 loss: 0.0047944095
Iter: 245 loss: 0.00479435083
Iter: 246 loss: 0.00479458179
Iter: 247 loss: 0.00479433779
Iter: 248 loss: 0.00479429
Iter: 249 loss: 0.00479444442
Iter: 250 loss: 0.00479427492
Iter: 251 loss: 0.00479423394
Iter: 252 loss: 0.0047947308
Iter: 253 loss: 0.00479423488
Iter: 254 loss: 0.00479420926
Iter: 255 loss: 0.00479419157
Iter: 256 loss: 0.00479418226
Iter: 257 loss: 0.0047941478
Iter: 258 loss: 0.00479425443
Iter: 259 loss: 0.00479413709
Iter: 260 loss: 0.00479412125
Iter: 261 loss: 0.00479411939
Iter: 262 loss: 0.00479410216
Iter: 263 loss: 0.00479409564
Iter: 264 loss: 0.00479409
Iter: 265 loss: 0.0047940705
Iter: 266 loss: 0.0047941003
Iter: 267 loss: 0.00479406212
Iter: 268 loss: 0.00479404163
Iter: 269 loss: 0.00479407795
Iter: 270 loss: 0.00479403418
Iter: 271 loss: 0.00479401648
Iter: 272 loss: 0.0047941329
Iter: 273 loss: 0.00479401555
Iter: 274 loss: 0.00479400065
Iter: 275 loss: 0.00479401555
Iter: 276 loss: 0.00479399133
Iter: 277 loss: 0.0047939755
Iter: 278 loss: 0.00479403138
Iter: 279 loss: 0.00479397178
Iter: 280 loss: 0.00479395874
Iter: 281 loss: 0.00479398575
Iter: 282 loss: 0.00479395501
Iter: 283 loss: 0.00479394477
Iter: 284 loss: 0.00479404069
Iter: 285 loss: 0.00479394663
Iter: 286 loss: 0.00479393639
Iter: 287 loss: 0.00479395315
Iter: 288 loss: 0.00479393126
Iter: 289 loss: 0.00479392335
Iter: 290 loss: 0.00479393033
Iter: 291 loss: 0.00479392102
Iter: 292 loss: 0.00479391497
Iter: 293 loss: 0.00479399506
Iter: 294 loss: 0.00479391264
Iter: 295 loss: 0.00479390845
Iter: 296 loss: 0.00479393499
Iter: 297 loss: 0.00479390752
Iter: 298 loss: 0.00479390519
Iter: 299 loss: 0.00479389913
Iter: 300 loss: 0.0047938996
Iter: 301 loss: 0.00479389261
Iter: 302 loss: 0.00479391078
Iter: 303 loss: 0.00479389075
Iter: 304 loss: 0.00479388749
Iter: 305 loss: 0.00479390379
Iter: 306 loss: 0.0047938833
Iter: 307 loss: 0.00479388051
Iter: 308 loss: 0.00479390938
Iter: 309 loss: 0.00479387958
Iter: 310 loss: 0.00479387771
Iter: 311 loss: 0.00479387958
Iter: 312 loss: 0.00479387352
Iter: 313 loss: 0.00479387119
Iter: 314 loss: 0.00479388144
Iter: 315 loss: 0.00479387026
Iter: 316 loss: 0.00479386467
Iter: 317 loss: 0.00479387864
Iter: 318 loss: 0.00479386514
Iter: 319 loss: 0.00479386188
Iter: 320 loss: 0.00479389215
Iter: 321 loss: 0.00479386142
Iter: 322 loss: 0.00479385909
Iter: 323 loss: 0.00479385909
Iter: 324 loss: 0.00479385816
Iter: 325 loss: 0.00479385443
Iter: 326 loss: 0.00479387213
Iter: 327 loss: 0.00479385396
Iter: 328 loss: 0.0047938521
Iter: 329 loss: 0.00479387632
Iter: 330 loss: 0.00479385303
Iter: 331 loss: 0.00479385071
Iter: 332 loss: 0.00479385024
Iter: 333 loss: 0.00479385164
Iter: 334 loss: 0.00479384838
Iter: 335 loss: 0.00479385257
Iter: 336 loss: 0.00479384745
Iter: 337 loss: 0.00479384651
Iter: 338 loss: 0.00479385164
Iter: 339 loss: 0.00479384465
Iter: 340 loss: 0.00479384232
Iter: 341 loss: 0.00479385071
Iter: 342 loss: 0.00479384419
Iter: 343 loss: 0.00479384186
Iter: 344 loss: 0.00479384325
Iter: 345 loss: 0.00479384046
Iter: 346 loss: 0.00479384046
Iter: 347 loss: 0.00479384698
Iter: 348 loss: 0.00479383906
Iter: 349 loss: 0.00479383767
Iter: 350 loss: 0.0047938386
Iter: 351 loss: 0.00479383674
Iter: 352 loss: 0.0047938358
Iter: 353 loss: 0.00479384791
Iter: 354 loss: 0.00479383627
Iter: 355 loss: 0.00479383487
Iter: 356 loss: 0.00479383767
Iter: 357 loss: 0.00479383487
Iter: 358 loss: 0.00479383394
Iter: 359 loss: 0.0047938358
Iter: 360 loss: 0.00479383348
Iter: 361 loss: 0.00479383348
Iter: 362 loss: 0.00479384325
Iter: 363 loss: 0.00479383441
Iter: 364 loss: 0.00479383301
Iter: 365 loss: 0.00479383208
Iter: 366 loss: 0.00479383301
Iter: 367 loss: 0.00479383254
Iter: 368 loss: 0.00479383301
Iter: 369 loss: 0.00479383208
Iter: 370 loss: 0.00479383161
Iter: 371 loss: 0.00479383301
Iter: 372 loss: 0.00479383115
Iter: 373 loss: 0.00479383115
Iter: 374 loss: 0.00479383254
Iter: 375 loss: 0.00479382928
Iter: 376 loss: 0.00479382975
Iter: 377 loss: 0.00479383161
Iter: 378 loss: 0.00479383
Iter: 379 loss: 0.00479382835
Iter: 380 loss: 0.00479382975
Iter: 381 loss: 0.00479382835
Iter: 382 loss: 0.00479382835
Iter: 383 loss: 0.00479382928
Iter: 384 loss: 0.00479382742
Iter: 385 loss: 0.00479382789
Iter: 386 loss: 0.00479383115
Iter: 387 loss: 0.00479382649
Iter: 388 loss: 0.00479382742
Iter: 389 loss: 0.00479382835
Iter: 390 loss: 0.00479382835
Iter: 391 loss: 0.00479382742
Iter: 392 loss: 0.00479382789
Iter: 393 loss: 0.00479382696
Iter: 394 loss: 0.00479382556
Iter: 395 loss: 0.00479382975
Iter: 396 loss: 0.00479382742
Iter: 397 loss: 0.00479382696
Iter: 398 loss: 0.00479382649
Iter: 399 loss: 0.00479382602
Iter: 400 loss: 0.00479382649
Iter: 401 loss: 0.00479382696
Iter: 402 loss: 0.00479382742
Iter: 403 loss: 0.00479382556
Iter: 404 loss: 0.00479382742
Iter: 405 loss: 0.00479382556
Iter: 406 loss: 0.00479382463
Iter: 407 loss: 0.00479382556
Iter: 408 loss: 0.00479382556
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2
+ date
Tue Oct 27 17:31:30 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4ad9cd1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4f3765158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4ad9fdae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4ada04c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4ad95b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4ad974840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4ad94b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd48808d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd48809c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd48809cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4701169d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4700c16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4700c19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd470078598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd47008b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd47008b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4700497b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd470049510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd424768b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42475d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42475d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42470b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4246c3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42466b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42466b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42468b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd424644ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd424605620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42460b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4245af6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4245e2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd42460b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd424571950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd424529c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd424559510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd424559f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0531722419
Iter: 2 loss: 791.452576
Iter: 3 loss: 2324.01123
Iter: 4 loss: 0.0321463868
Iter: 5 loss: 0.0721877217
Iter: 6 loss: 0.032114204
Iter: 7 loss: 0.0297190286
Iter: 8 loss: 0.0296801217
Iter: 9 loss: 0.0239694603
Iter: 10 loss: 0.0233846214
Iter: 11 loss: 0.0188495293
Iter: 12 loss: 0.101980656
Iter: 13 loss: 0.0188177377
Iter: 14 loss: 0.0175930634
Iter: 15 loss: 0.0190563258
Iter: 16 loss: 0.0170906689
Iter: 17 loss: 0.0162020121
Iter: 18 loss: 0.0180771854
Iter: 19 loss: 0.0157418698
Iter: 20 loss: 0.0146086607
Iter: 21 loss: 0.0214764327
Iter: 22 loss: 0.0143739823
Iter: 23 loss: 0.0130050881
Iter: 24 loss: 0.0173880383
Iter: 25 loss: 0.0125420634
Iter: 26 loss: 0.0112166014
Iter: 27 loss: 0.0183090419
Iter: 28 loss: 0.0109703606
Iter: 29 loss: 0.00977011584
Iter: 30 loss: 0.0298209824
Iter: 31 loss: 0.00972631201
Iter: 32 loss: 0.00910657831
Iter: 33 loss: 0.0136477649
Iter: 34 loss: 0.00901659
Iter: 35 loss: 0.00846921466
Iter: 36 loss: 0.00990446657
Iter: 37 loss: 0.00827011093
Iter: 38 loss: 0.0078073442
Iter: 39 loss: 0.0103486516
Iter: 40 loss: 0.00771810766
Iter: 41 loss: 0.00761490688
Iter: 42 loss: 0.00752200792
Iter: 43 loss: 0.00738114258
Iter: 44 loss: 0.00823997706
Iter: 45 loss: 0.00735709816
Iter: 46 loss: 0.00727413595
Iter: 47 loss: 0.00722101517
Iter: 48 loss: 0.00718781492
Iter: 49 loss: 0.00698429858
Iter: 50 loss: 0.00720564742
Iter: 51 loss: 0.00686900737
Iter: 52 loss: 0.00667080609
Iter: 53 loss: 0.00723859807
Iter: 54 loss: 0.0066120089
Iter: 55 loss: 0.00644575246
Iter: 56 loss: 0.00738764787
Iter: 57 loss: 0.0064165676
Iter: 58 loss: 0.00632671081
Iter: 59 loss: 0.00668420084
Iter: 60 loss: 0.00630421424
Iter: 61 loss: 0.00619522808
Iter: 62 loss: 0.00636050757
Iter: 63 loss: 0.0061419555
Iter: 64 loss: 0.006045477
Iter: 65 loss: 0.00702761905
Iter: 66 loss: 0.00604242366
Iter: 67 loss: 0.00595263764
Iter: 68 loss: 0.00624753255
Iter: 69 loss: 0.00592593849
Iter: 70 loss: 0.00587701378
Iter: 71 loss: 0.00600468321
Iter: 72 loss: 0.0058600381
Iter: 73 loss: 0.00580671895
Iter: 74 loss: 0.00584490644
Iter: 75 loss: 0.00577336084
Iter: 76 loss: 0.00572992582
Iter: 77 loss: 0.00610619271
Iter: 78 loss: 0.00572818331
Iter: 79 loss: 0.00571351126
Iter: 80 loss: 0.00570802204
Iter: 81 loss: 0.00569677632
Iter: 82 loss: 0.00568189286
Iter: 83 loss: 0.00568097597
Iter: 84 loss: 0.00565068563
Iter: 85 loss: 0.0056861937
Iter: 86 loss: 0.00563447643
Iter: 87 loss: 0.00561410049
Iter: 88 loss: 0.00565632293
Iter: 89 loss: 0.00560576282
Iter: 90 loss: 0.00558572821
Iter: 91 loss: 0.00569402054
Iter: 92 loss: 0.0055826325
Iter: 93 loss: 0.00556534529
Iter: 94 loss: 0.00574474549
Iter: 95 loss: 0.00556481443
Iter: 96 loss: 0.00555287767
Iter: 97 loss: 0.00555226952
Iter: 98 loss: 0.00554312
Iter: 99 loss: 0.00552882534
Iter: 100 loss: 0.00557994284
Iter: 101 loss: 0.00552514056
Iter: 102 loss: 0.00551188504
Iter: 103 loss: 0.00556901097
Iter: 104 loss: 0.00550915115
Iter: 105 loss: 0.00549713802
Iter: 106 loss: 0.00553919561
Iter: 107 loss: 0.00549388165
Iter: 108 loss: 0.00548214372
Iter: 109 loss: 0.00550249871
Iter: 110 loss: 0.00547694135
Iter: 111 loss: 0.00547289569
Iter: 112 loss: 0.00547137391
Iter: 113 loss: 0.00546460692
Iter: 114 loss: 0.00545187294
Iter: 115 loss: 0.00573434122
Iter: 116 loss: 0.00545184035
Iter: 117 loss: 0.00544157252
Iter: 118 loss: 0.00544585707
Iter: 119 loss: 0.00543456851
Iter: 120 loss: 0.00542339729
Iter: 121 loss: 0.00545910187
Iter: 122 loss: 0.00542015908
Iter: 123 loss: 0.00540747913
Iter: 124 loss: 0.00543390308
Iter: 125 loss: 0.00540239
Iter: 126 loss: 0.00539056445
Iter: 127 loss: 0.00541945687
Iter: 128 loss: 0.00538637117
Iter: 129 loss: 0.00537515571
Iter: 130 loss: 0.00542340893
Iter: 131 loss: 0.00537280831
Iter: 132 loss: 0.00536375958
Iter: 133 loss: 0.00543192727
Iter: 134 loss: 0.00536308298
Iter: 135 loss: 0.00535481749
Iter: 136 loss: 0.00537719531
Iter: 137 loss: 0.00535203144
Iter: 138 loss: 0.00534399087
Iter: 139 loss: 0.00534779672
Iter: 140 loss: 0.00533860363
Iter: 141 loss: 0.00532971043
Iter: 142 loss: 0.00536384713
Iter: 143 loss: 0.00532759726
Iter: 144 loss: 0.00532050617
Iter: 145 loss: 0.00536323432
Iter: 146 loss: 0.00531968568
Iter: 147 loss: 0.00531624211
Iter: 148 loss: 0.00531576388
Iter: 149 loss: 0.00531333219
Iter: 150 loss: 0.00530698849
Iter: 151 loss: 0.0053555062
Iter: 152 loss: 0.00530575449
Iter: 153 loss: 0.00529702753
Iter: 154 loss: 0.00530170416
Iter: 155 loss: 0.00529125845
Iter: 156 loss: 0.00528227631
Iter: 157 loss: 0.00530138053
Iter: 158 loss: 0.0052787764
Iter: 159 loss: 0.00527127646
Iter: 160 loss: 0.00537981465
Iter: 161 loss: 0.00527125923
Iter: 162 loss: 0.00526670832
Iter: 163 loss: 0.00526392926
Iter: 164 loss: 0.00526206102
Iter: 165 loss: 0.00525610801
Iter: 166 loss: 0.00526832882
Iter: 167 loss: 0.00525371
Iter: 168 loss: 0.00524873659
Iter: 169 loss: 0.00524873845
Iter: 170 loss: 0.00524515053
Iter: 171 loss: 0.00526525
Iter: 172 loss: 0.00524462
Iter: 173 loss: 0.0052416157
Iter: 174 loss: 0.00524017587
Iter: 175 loss: 0.00523871509
Iter: 176 loss: 0.00523390621
Iter: 177 loss: 0.00524229649
Iter: 178 loss: 0.00523175625
Iter: 179 loss: 0.00523361843
Iter: 180 loss: 0.00522988848
Iter: 181 loss: 0.00522825262
Iter: 182 loss: 0.00522443373
Iter: 183 loss: 0.00527327601
Iter: 184 loss: 0.00522414036
Iter: 185 loss: 0.00522089796
Iter: 186 loss: 0.00522547588
Iter: 187 loss: 0.00521929655
Iter: 188 loss: 0.00521556288
Iter: 189 loss: 0.00522056455
Iter: 190 loss: 0.00521367509
Iter: 191 loss: 0.0052097505
Iter: 192 loss: 0.00522665819
Iter: 193 loss: 0.00520892907
Iter: 194 loss: 0.00520530762
Iter: 195 loss: 0.00521225203
Iter: 196 loss: 0.00520378025
Iter: 197 loss: 0.00520102913
Iter: 198 loss: 0.00520934165
Iter: 199 loss: 0.00520020677
Iter: 200 loss: 0.00519771408
Iter: 201 loss: 0.00520969648
Iter: 202 loss: 0.00519726332
Iter: 203 loss: 0.00519541
Iter: 204 loss: 0.00521056447
Iter: 205 loss: 0.00519529684
Iter: 206 loss: 0.00519352779
Iter: 207 loss: 0.00520346314
Iter: 208 loss: 0.00519327028
Iter: 209 loss: 0.00519219926
Iter: 210 loss: 0.00519136526
Iter: 211 loss: 0.00519102952
Iter: 212 loss: 0.00518967
Iter: 213 loss: 0.00520668132
Iter: 214 loss: 0.00518965349
Iter: 215 loss: 0.00518846791
Iter: 216 loss: 0.00519563677
Iter: 217 loss: 0.00518832728
Iter: 218 loss: 0.0051877941
Iter: 219 loss: 0.0051865261
Iter: 220 loss: 0.00520109944
Iter: 221 loss: 0.00518640643
Iter: 222 loss: 0.00518522412
Iter: 223 loss: 0.00519322185
Iter: 224 loss: 0.00518510584
Iter: 225 loss: 0.00518398266
Iter: 226 loss: 0.00518375728
Iter: 227 loss: 0.00518301129
Iter: 228 loss: 0.00518177263
Iter: 229 loss: 0.00518928096
Iter: 230 loss: 0.0051816171
Iter: 231 loss: 0.00518048462
Iter: 232 loss: 0.00518093444
Iter: 233 loss: 0.00517969811
Iter: 234 loss: 0.0051785768
Iter: 235 loss: 0.00518234074
Iter: 236 loss: 0.0051782704
Iter: 237 loss: 0.00517723337
Iter: 238 loss: 0.00518241432
Iter: 239 loss: 0.00517705735
Iter: 240 loss: 0.00517634209
Iter: 241 loss: 0.00518173445
Iter: 242 loss: 0.00517628901
Iter: 243 loss: 0.00517564267
Iter: 244 loss: 0.00517857354
Iter: 245 loss: 0.00517551415
Iter: 246 loss: 0.0051750429
Iter: 247 loss: 0.00517565617
Iter: 248 loss: 0.00517480541
Iter: 249 loss: 0.00517429598
Iter: 250 loss: 0.005181049
Iter: 251 loss: 0.00517429132
Iter: 252 loss: 0.00517401332
Iter: 253 loss: 0.00517348479
Iter: 254 loss: 0.0051850751
Iter: 255 loss: 0.00517348154
Iter: 256 loss: 0.0051729558
Iter: 257 loss: 0.00517409947
Iter: 258 loss: 0.00517275464
Iter: 259 loss: 0.00517229456
Iter: 260 loss: 0.00517403474
Iter: 261 loss: 0.00517218467
Iter: 262 loss: 0.00517175626
Iter: 263 loss: 0.00517306756
Iter: 264 loss: 0.00517162774
Iter: 265 loss: 0.00517122075
Iter: 266 loss: 0.00517129153
Iter: 267 loss: 0.00517091714
Iter: 268 loss: 0.00517045055
Iter: 269 loss: 0.0051723416
Iter: 270 loss: 0.00517034438
Iter: 271 loss: 0.00516981352
Iter: 272 loss: 0.00517120631
Iter: 273 loss: 0.00516963284
Iter: 274 loss: 0.00516931154
Iter: 275 loss: 0.00517129246
Iter: 276 loss: 0.00516927335
Iter: 277 loss: 0.00516897952
Iter: 278 loss: 0.00517150527
Iter: 279 loss: 0.00516896229
Iter: 280 loss: 0.005168756
Iter: 281 loss: 0.00516950106
Iter: 282 loss: 0.00516870338
Iter: 283 loss: 0.00516854227
Iter: 284 loss: 0.00517031271
Iter: 285 loss: 0.00516853761
Iter: 286 loss: 0.00516840164
Iter: 287 loss: 0.00516812364
Iter: 288 loss: 0.00517308665
Iter: 289 loss: 0.00516811665
Iter: 290 loss: 0.00516787823
Iter: 291 loss: 0.0051687411
Iter: 292 loss: 0.00516781677
Iter: 293 loss: 0.00516759139
Iter: 294 loss: 0.00516766449
Iter: 295 loss: 0.00516743306
Iter: 296 loss: 0.00516713317
Iter: 297 loss: 0.00516876951
Iter: 298 loss: 0.00516709
Iter: 299 loss: 0.00516684446
Iter: 300 loss: 0.00516710524
Iter: 301 loss: 0.00516671129
Iter: 302 loss: 0.00516646
Iter: 303 loss: 0.00516676577
Iter: 304 loss: 0.00516633
Iter: 305 loss: 0.00516605191
Iter: 306 loss: 0.00516824704
Iter: 307 loss: 0.00516603142
Iter: 308 loss: 0.0051658419
Iter: 309 loss: 0.00516614597
Iter: 310 loss: 0.00516575668
Iter: 311 loss: 0.00516558206
Iter: 312 loss: 0.00516558113
Iter: 313 loss: 0.00516546704
Iter: 314 loss: 0.00516586192
Iter: 315 loss: 0.00516543351
Iter: 316 loss: 0.00516534038
Iter: 317 loss: 0.00516603235
Iter: 318 loss: 0.00516533246
Iter: 319 loss: 0.00516524026
Iter: 320 loss: 0.00516515691
Iter: 321 loss: 0.00516513363
Iter: 322 loss: 0.00516502373
Iter: 323 loss: 0.00516510848
Iter: 324 loss: 0.00516495435
Iter: 325 loss: 0.00516481884
Iter: 326 loss: 0.00516492687
Iter: 327 loss: 0.00516473642
Iter: 328 loss: 0.00516456179
Iter: 329 loss: 0.00516524725
Iter: 330 loss: 0.00516452268
Iter: 331 loss: 0.00516436435
Iter: 332 loss: 0.00516481325
Iter: 333 loss: 0.00516431779
Iter: 334 loss: 0.00516416412
Iter: 335 loss: 0.00516436528
Iter: 336 loss: 0.00516408635
Iter: 337 loss: 0.00516391685
Iter: 338 loss: 0.00516412314
Iter: 339 loss: 0.0051638307
Iter: 340 loss: 0.00516365794
Iter: 341 loss: 0.00516513083
Iter: 342 loss: 0.00516364817
Iter: 343 loss: 0.00516352709
Iter: 344 loss: 0.00516455155
Iter: 345 loss: 0.00516351778
Iter: 346 loss: 0.00516343303
Iter: 347 loss: 0.00516410451
Iter: 348 loss: 0.0051634307
Iter: 349 loss: 0.00516337901
Iter: 350 loss: 0.00516368914
Iter: 351 loss: 0.00516337436
Iter: 352 loss: 0.00516331941
Iter: 353 loss: 0.00516326167
Iter: 354 loss: 0.00516325282
Iter: 355 loss: 0.00516316388
Iter: 356 loss: 0.00516320299
Iter: 357 loss: 0.00516310707
Iter: 358 loss: 0.00516300555
Iter: 359 loss: 0.00516304886
Iter: 360 loss: 0.00516293617
Iter: 361 loss: 0.00516281463
Iter: 362 loss: 0.00516366214
Iter: 363 loss: 0.00516280532
Iter: 364 loss: 0.00516270753
Iter: 365 loss: 0.00516282534
Iter: 366 loss: 0.00516265724
Iter: 367 loss: 0.00516255386
Iter: 368 loss: 0.00516293803
Iter: 369 loss: 0.00516252825
Iter: 370 loss: 0.00516242348
Iter: 371 loss: 0.00516240532
Iter: 372 loss: 0.00516233547
Iter: 373 loss: 0.00516220788
Iter: 374 loss: 0.00516302045
Iter: 375 loss: 0.00516218971
Iter: 376 loss: 0.00516209938
Iter: 377 loss: 0.00516318763
Iter: 378 loss: 0.00516209844
Iter: 379 loss: 0.0051620435
Iter: 380 loss: 0.00516262511
Iter: 381 loss: 0.00516204163
Iter: 382 loss: 0.00516200904
Iter: 383 loss: 0.00516211707
Iter: 384 loss: 0.00516199879
Iter: 385 loss: 0.00516195595
Iter: 386 loss: 0.00516195362
Iter: 387 loss: 0.00516192
Iter: 388 loss: 0.0051618712
Iter: 389 loss: 0.00516186
Iter: 390 loss: 0.0051618279
Iter: 391 loss: 0.00516175292
Iter: 392 loss: 0.00516179297
Iter: 393 loss: 0.00516170729
Iter: 394 loss: 0.00516162347
Iter: 395 loss: 0.00516206492
Iter: 396 loss: 0.00516161183
Iter: 397 loss: 0.00516154058
Iter: 398 loss: 0.00516167656
Iter: 399 loss: 0.00516151031
Iter: 400 loss: 0.00516142789
Iter: 401 loss: 0.00516161416
Iter: 402 loss: 0.00516139716
Iter: 403 loss: 0.00516131334
Iter: 404 loss: 0.00516147679
Iter: 405 loss: 0.00516128074
Iter: 406 loss: 0.00516119832
Iter: 407 loss: 0.00516143674
Iter: 408 loss: 0.00516117364
Iter: 409 loss: 0.00516110798
Iter: 410 loss: 0.00516164023
Iter: 411 loss: 0.00516110333
Iter: 412 loss: 0.00516105816
Iter: 413 loss: 0.00516173709
Iter: 414 loss: 0.00516105816
Iter: 415 loss: 0.00516103208
Iter: 416 loss: 0.00516113266
Iter: 417 loss: 0.00516102556
Iter: 418 loss: 0.00516099576
Iter: 419 loss: 0.00516100693
Iter: 420 loss: 0.0051609762
Iter: 421 loss: 0.00516093709
Iter: 422 loss: 0.00516088866
Iter: 423 loss: 0.005160884
Iter: 424 loss: 0.0051608244
Iter: 425 loss: 0.00516099
Iter: 426 loss: 0.00516080437
Iter: 427 loss: 0.00516074058
Iter: 428 loss: 0.00516088773
Iter: 429 loss: 0.00516071636
Iter: 430 loss: 0.00516066
Iter: 431 loss: 0.00516082253
Iter: 432 loss: 0.00516064186
Iter: 433 loss: 0.00516057154
Iter: 434 loss: 0.0051607294
Iter: 435 loss: 0.00516054593
Iter: 436 loss: 0.00516048446
Iter: 437 loss: 0.00516055571
Iter: 438 loss: 0.00516045233
Iter: 439 loss: 0.00516038202
Iter: 440 loss: 0.0051606996
Iter: 441 loss: 0.00516037084
Iter: 442 loss: 0.00516031031
Iter: 443 loss: 0.00516046304
Iter: 444 loss: 0.00516028935
Iter: 445 loss: 0.00516026374
Iter: 446 loss: 0.00516025489
Iter: 447 loss: 0.00516023394
Iter: 448 loss: 0.00516025536
Iter: 449 loss: 0.0051602223
Iter: 450 loss: 0.00516018504
Iter: 451 loss: 0.00516021345
Iter: 452 loss: 0.00516016548
Iter: 453 loss: 0.00516012311
Iter: 454 loss: 0.00516011659
Iter: 455 loss: 0.00516009051
Iter: 456 loss: 0.00516004302
Iter: 457 loss: 0.00516008725
Iter: 458 loss: 0.00516001508
Iter: 459 loss: 0.00515996106
Iter: 460 loss: 0.00516015524
Iter: 461 loss: 0.00515994616
Iter: 462 loss: 0.00515990052
Iter: 463 loss: 0.0051600188
Iter: 464 loss: 0.0051598819
Iter: 465 loss: 0.00515983161
Iter: 466 loss: 0.00515996199
Iter: 467 loss: 0.00515981112
Iter: 468 loss: 0.0051597557
Iter: 469 loss: 0.00515983719
Iter: 470 loss: 0.00515972823
Iter: 471 loss: 0.00515967235
Iter: 472 loss: 0.00515982416
Iter: 473 loss: 0.00515965046
Iter: 474 loss: 0.00515959784
Iter: 475 loss: 0.00515979715
Iter: 476 loss: 0.00515958387
Iter: 477 loss: 0.00515955593
Iter: 478 loss: 0.00515955267
Iter: 479 loss: 0.00515952846
Iter: 480 loss: 0.00515959831
Iter: 481 loss: 0.00515952427
Iter: 482 loss: 0.00515949773
Iter: 483 loss: 0.00515956152
Iter: 484 loss: 0.00515949
Iter: 485 loss: 0.00515946653
Iter: 486 loss: 0.00515943579
Iter: 487 loss: 0.00515943393
Iter: 488 loss: 0.00515939295
Iter: 489 loss: 0.00515946653
Iter: 490 loss: 0.00515937526
Iter: 491 loss: 0.00515932869
Iter: 492 loss: 0.00515936594
Iter: 493 loss: 0.00515929936
Iter: 494 loss: 0.00515925372
Iter: 495 loss: 0.00515958667
Iter: 496 loss: 0.00515924906
Iter: 497 loss: 0.00515920669
Iter: 498 loss: 0.00515920762
Iter: 499 loss: 0.00515917037
Iter: 500 loss: 0.00515911588
Iter: 501 loss: 0.00515943393
Iter: 502 loss: 0.00515911076
Iter: 503 loss: 0.00515906326
Iter: 504 loss: 0.00515910098
Iter: 505 loss: 0.00515903486
Iter: 506 loss: 0.00515898
Iter: 507 loss: 0.00515905861
Iter: 508 loss: 0.00515895337
Iter: 509 loss: 0.0051589408
Iter: 510 loss: 0.00515892264
Iter: 511 loss: 0.00515890401
Iter: 512 loss: 0.00515896268
Iter: 513 loss: 0.00515889656
Iter: 514 loss: 0.0051588756
Iter: 515 loss: 0.0051589245
Iter: 516 loss: 0.00515886769
Iter: 517 loss: 0.00515884347
Iter: 518 loss: 0.00515881926
Iter: 519 loss: 0.00515881553
Iter: 520 loss: 0.00515878107
Iter: 521 loss: 0.00515883323
Iter: 522 loss: 0.00515876338
Iter: 523 loss: 0.00515872054
Iter: 524 loss: 0.00515879085
Iter: 525 loss: 0.00515870051
Iter: 526 loss: 0.0051586628
Iter: 527 loss: 0.0051588132
Iter: 528 loss: 0.00515865348
Iter: 529 loss: 0.00515861157
Iter: 530 loss: 0.00515870564
Iter: 531 loss: 0.00515859621
Iter: 532 loss: 0.00515855569
Iter: 533 loss: 0.00515866
Iter: 534 loss: 0.00515854266
Iter: 535 loss: 0.00515850168
Iter: 536 loss: 0.00515857525
Iter: 537 loss: 0.00515848491
Iter: 538 loss: 0.005158443
Iter: 539 loss: 0.00515857618
Iter: 540 loss: 0.00515843183
Iter: 541 loss: 0.00515840296
Iter: 542 loss: 0.00515883975
Iter: 543 loss: 0.00515840063
Iter: 544 loss: 0.00515837781
Iter: 545 loss: 0.00515854452
Iter: 546 loss: 0.00515837781
Iter: 547 loss: 0.00515836
Iter: 548 loss: 0.00515840529
Iter: 549 loss: 0.00515835453
Iter: 550 loss: 0.00515833683
Iter: 551 loss: 0.00515831821
Iter: 552 loss: 0.00515831728
Iter: 553 loss: 0.00515828747
Iter: 554 loss: 0.00515833544
Iter: 555 loss: 0.0051582763
Iter: 556 loss: 0.00515824324
Iter: 557 loss: 0.00515825115
Iter: 558 loss: 0.00515822135
Iter: 559 loss: 0.00515818596
Iter: 560 loss: 0.00515848119
Iter: 561 loss: 0.0051581813
Iter: 562 loss: 0.00515815569
Iter: 563 loss: 0.00515816407
Iter: 564 loss: 0.00515813287
Iter: 565 loss: 0.00515809795
Iter: 566 loss: 0.00515829772
Iter: 567 loss: 0.00515808957
Iter: 568 loss: 0.0051580593
Iter: 569 loss: 0.00515805976
Iter: 570 loss: 0.00515803322
Iter: 571 loss: 0.00515799783
Iter: 572 loss: 0.00515820645
Iter: 573 loss: 0.00515799504
Iter: 574 loss: 0.0051579643
Iter: 575 loss: 0.00515818782
Iter: 576 loss: 0.00515796337
Iter: 577 loss: 0.00515794381
Iter: 578 loss: 0.00515794381
Iter: 579 loss: 0.00515793264
Iter: 580 loss: 0.00515795127
Iter: 581 loss: 0.00515792705
Iter: 582 loss: 0.00515791122
Iter: 583 loss: 0.00515788933
Iter: 584 loss: 0.00515789073
Iter: 585 loss: 0.00515786512
Iter: 586 loss: 0.00515793078
Iter: 587 loss: 0.00515785767
Iter: 588 loss: 0.00515783066
Iter: 589 loss: 0.00515783392
Iter: 590 loss: 0.00515780877
Iter: 591 loss: 0.00515777851
Iter: 592 loss: 0.00515799038
Iter: 593 loss: 0.00515777711
Iter: 594 loss: 0.00515774917
Iter: 595 loss: 0.0051577678
Iter: 596 loss: 0.00515773473
Iter: 597 loss: 0.005157704
Iter: 598 loss: 0.00515788747
Iter: 599 loss: 0.00515770074
Iter: 600 loss: 0.00515767653
Iter: 601 loss: 0.00515767559
Iter: 602 loss: 0.00515765324
Iter: 603 loss: 0.00515762297
Iter: 604 loss: 0.00515776919
Iter: 605 loss: 0.00515761925
Iter: 606 loss: 0.00515759457
Iter: 607 loss: 0.00515778968
Iter: 608 loss: 0.00515759457
Iter: 609 loss: 0.00515757874
Iter: 610 loss: 0.005157582
Iter: 611 loss: 0.00515756896
Iter: 612 loss: 0.00515757687
Iter: 613 loss: 0.00515756244
Iter: 614 loss: 0.00515754893
Iter: 615 loss: 0.00515753683
Iter: 616 loss: 0.00515753403
Iter: 617 loss: 0.00515751448
Iter: 618 loss: 0.00515754335
Iter: 619 loss: 0.00515750516
Iter: 620 loss: 0.0051574856
Iter: 621 loss: 0.00515752938
Iter: 622 loss: 0.00515747955
Iter: 623 loss: 0.00515745766
Iter: 624 loss: 0.005157487
Iter: 625 loss: 0.00515744556
Iter: 626 loss: 0.00515742507
Iter: 627 loss: 0.00515752938
Iter: 628 loss: 0.00515742134
Iter: 629 loss: 0.00515739946
Iter: 630 loss: 0.00515746698
Iter: 631 loss: 0.0051573948
Iter: 632 loss: 0.00515737571
Iter: 633 loss: 0.00515738968
Iter: 634 loss: 0.00515736779
Iter: 635 loss: 0.00515734497
Iter: 636 loss: 0.00515744556
Iter: 637 loss: 0.00515733799
Iter: 638 loss: 0.00515732262
Iter: 639 loss: 0.00515736919
Iter: 640 loss: 0.0051573161
Iter: 641 loss: 0.00515730819
Iter: 642 loss: 0.0051573026
Iter: 643 loss: 0.00515729794
Iter: 644 loss: 0.0051573012
Iter: 645 loss: 0.00515729282
Iter: 646 loss: 0.00515728537
Iter: 647 loss: 0.00515727792
Iter: 648 loss: 0.00515727606
Iter: 649 loss: 0.00515725836
Iter: 650 loss: 0.00515727699
Iter: 651 loss: 0.00515725464
Iter: 652 loss: 0.00515724067
Iter: 653 loss: 0.00515727093
Iter: 654 loss: 0.00515723368
Iter: 655 loss: 0.00515721878
Iter: 656 loss: 0.00515723787
Iter: 657 loss: 0.00515721086
Iter: 658 loss: 0.0051571941
Iter: 659 loss: 0.00515723508
Iter: 660 loss: 0.00515718572
Iter: 661 loss: 0.00515716942
Iter: 662 loss: 0.00515730027
Iter: 663 loss: 0.00515717035
Iter: 664 loss: 0.00515715778
Iter: 665 loss: 0.00515715
Iter: 666 loss: 0.00515714474
Iter: 667 loss: 0.00515712518
Iter: 668 loss: 0.00515724905
Iter: 669 loss: 0.00515712425
Iter: 670 loss: 0.00515711
Iter: 671 loss: 0.0051571494
Iter: 672 loss: 0.00515710469
Iter: 673 loss: 0.00515710376
Iter: 674 loss: 0.00515709724
Iter: 675 loss: 0.00515709398
Iter: 676 loss: 0.00515709491
Iter: 677 loss: 0.00515709165
Iter: 678 loss: 0.00515708327
Iter: 679 loss: 0.00515708234
Iter: 680 loss: 0.00515707955
Iter: 681 loss: 0.0051570721
Iter: 682 loss: 0.00515707536
Iter: 683 loss: 0.00515706651
Iter: 684 loss: 0.00515705626
Iter: 685 loss: 0.00515707955
Iter: 686 loss: 0.00515705161
Iter: 687 loss: 0.00515704183
Iter: 688 loss: 0.00515704835
Iter: 689 loss: 0.00515703531
Iter: 690 loss: 0.00515702274
Iter: 691 loss: 0.00515708188
Iter: 692 loss: 0.00515702
Iter: 693 loss: 0.0051570083
Iter: 694 loss: 0.00515704602
Iter: 695 loss: 0.00515700597
Iter: 696 loss: 0.0051569948
Iter: 697 loss: 0.00515702087
Iter: 698 loss: 0.00515699433
Iter: 699 loss: 0.00515698176
Iter: 700 loss: 0.0051569934
Iter: 701 loss: 0.0051569771
Iter: 702 loss: 0.00515696686
Iter: 703 loss: 0.00515701622
Iter: 704 loss: 0.00515696406
Iter: 705 loss: 0.0051569622
Iter: 706 loss: 0.00515696
Iter: 707 loss: 0.00515695428
Iter: 708 loss: 0.00515696127
Iter: 709 loss: 0.00515695382
Iter: 710 loss: 0.00515694916
Iter: 711 loss: 0.00515695242
Iter: 712 loss: 0.00515694637
Iter: 713 loss: 0.00515694404
Iter: 714 loss: 0.00515693799
Iter: 715 loss: 0.00515693473
Iter: 716 loss: 0.0051569296
Iter: 717 loss: 0.00515697245
Iter: 718 loss: 0.00515692681
Iter: 719 loss: 0.00515692169
Iter: 720 loss: 0.00515692215
Iter: 721 loss: 0.0051569147
Iter: 722 loss: 0.00515690492
Iter: 723 loss: 0.0051569473
Iter: 724 loss: 0.00515690353
Iter: 725 loss: 0.00515689701
Iter: 726 loss: 0.00515691843
Iter: 727 loss: 0.00515689328
Iter: 728 loss: 0.0051568863
Iter: 729 loss: 0.00515691284
Iter: 730 loss: 0.00515688397
Iter: 731 loss: 0.00515687745
Iter: 732 loss: 0.00515689049
Iter: 733 loss: 0.00515687373
Iter: 734 loss: 0.00515686814
Iter: 735 loss: 0.0051568835
Iter: 736 loss: 0.00515686441
Iter: 737 loss: 0.00515686534
Iter: 738 loss: 0.00515686069
Iter: 739 loss: 0.00515685929
Iter: 740 loss: 0.00515686441
Iter: 741 loss: 0.00515685976
Iter: 742 loss: 0.00515685882
Iter: 743 loss: 0.0051568565
Iter: 744 loss: 0.00515685463
Iter: 745 loss: 0.0051568523
Iter: 746 loss: 0.00515684625
Iter: 747 loss: 0.00515684765
Iter: 748 loss: 0.00515684159
Iter: 749 loss: 0.00515686534
Iter: 750 loss: 0.00515684159
Iter: 751 loss: 0.00515683601
Iter: 752 loss: 0.00515684485
Iter: 753 loss: 0.00515683461
Iter: 754 loss: 0.00515682902
Iter: 755 loss: 0.0051568388
Iter: 756 loss: 0.00515682623
Iter: 757 loss: 0.00515682064
Iter: 758 loss: 0.00515683927
Iter: 759 loss: 0.00515681878
Iter: 760 loss: 0.00515681691
Iter: 761 loss: 0.00515684206
Iter: 762 loss: 0.00515681505
Iter: 763 loss: 0.0051568104
Iter: 764 loss: 0.00515681133
Iter: 765 loss: 0.00515680667
Iter: 766 loss: 0.00515680248
Iter: 767 loss: 0.00515683368
Iter: 768 loss: 0.00515680108
Iter: 769 loss: 0.0051568
Iter: 770 loss: 0.00515679922
Iter: 771 loss: 0.00515679829
Iter: 772 loss: 0.00515680388
Iter: 773 loss: 0.00515679643
Iter: 774 loss: 0.00515679736
Iter: 775 loss: 0.00515679456
Iter: 776 loss: 0.00515679549
Iter: 777 loss: 0.00515679177
Iter: 778 loss: 0.00515678851
Iter: 779 loss: 0.00515678804
Iter: 780 loss: 0.00515678618
Iter: 781 loss: 0.00515681412
Iter: 782 loss: 0.00515678385
Iter: 783 loss: 0.00515678339
Iter: 784 loss: 0.00515678246
Iter: 785 loss: 0.00515677966
Iter: 786 loss: 0.00515677733
Iter: 787 loss: 0.00515679363
Iter: 788 loss: 0.0051567764
Iter: 789 loss: 0.00515677407
Iter: 790 loss: 0.00515677407
Iter: 791 loss: 0.00515677221
Iter: 792 loss: 0.00515676849
Iter: 793 loss: 0.00515680201
Iter: 794 loss: 0.00515676755
Iter: 795 loss: 0.00515676429
Iter: 796 loss: 0.00515676383
Iter: 797 loss: 0.00515676336
Iter: 798 loss: 0.00515676104
Iter: 799 loss: 0.00515677221
Iter: 800 loss: 0.00515675917
Iter: 801 loss: 0.00515675917
Iter: 802 loss: 0.00515675778
Iter: 803 loss: 0.00515675824
Iter: 804 loss: 0.0051567629
Iter: 805 loss: 0.00515675731
Iter: 806 loss: 0.00515675591
Iter: 807 loss: 0.00515675684
Iter: 808 loss: 0.00515675265
Iter: 809 loss: 0.00515675498
Iter: 810 loss: 0.00515675219
Iter: 811 loss: 0.00515675172
Iter: 812 loss: 0.00515675079
Iter: 813 loss: 0.00515675731
Iter: 814 loss: 0.00515674893
Iter: 815 loss: 0.00515674707
Iter: 816 loss: 0.00515675
Iter: 817 loss: 0.00515674613
Iter: 818 loss: 0.0051567452
Iter: 819 loss: 0.00515674939
Iter: 820 loss: 0.00515674334
Iter: 821 loss: 0.00515674241
Iter: 822 loss: 0.00515674567
Iter: 823 loss: 0.00515674055
Iter: 824 loss: 0.00515673961
Iter: 825 loss: 0.00515675172
Iter: 826 loss: 0.00515673961
Iter: 827 loss: 0.00515673682
Iter: 828 loss: 0.00515673961
Iter: 829 loss: 0.00515673729
Iter: 830 loss: 0.00515673356
Iter: 831 loss: 0.00515673822
Iter: 832 loss: 0.00515673403
Iter: 833 loss: 0.0051567331
Iter: 834 loss: 0.00515673216
Iter: 835 loss: 0.00515673263
Iter: 836 loss: 0.00515674055
Iter: 837 loss: 0.00515673077
Iter: 838 loss: 0.00515673216
Iter: 839 loss: 0.0051567289
Iter: 840 loss: 0.00515672937
Iter: 841 loss: 0.0051567289
Iter: 842 loss: 0.00515672704
Iter: 843 loss: 0.00515672751
Iter: 844 loss: 0.00515672844
Iter: 845 loss: 0.00515673123
Iter: 846 loss: 0.00515672797
Iter: 847 loss: 0.00515672471
Iter: 848 loss: 0.00515672518
Iter: 849 loss: 0.00515672378
Iter: 850 loss: 0.00515672378
Iter: 851 loss: 0.0051567303
Iter: 852 loss: 0.00515672658
Iter: 853 loss: 0.00515672425
Iter: 854 loss: 0.00515672285
Iter: 855 loss: 0.00515672192
Iter: 856 loss: 0.00515671819
Iter: 857 loss: 0.00515673123
Iter: 858 loss: 0.00515671819
Iter: 859 loss: 0.00515671819
Iter: 860 loss: 0.00515671913
Iter: 861 loss: 0.00515671819
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4
+ date
Tue Oct 27 17:35:10 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea4327268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbecb48ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbecb48cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbecb3e8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea42c2c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea427cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea427c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea4252b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea42686a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea4268620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea4210510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea41c9ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea417b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea4134a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea416d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea416d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea40fb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea411ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea40e4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea40fbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea409d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbea409df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe907e7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe9078ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe90799b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe9073dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe90774048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe906feea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe9071e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe9071eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe9071eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe9069d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe906b1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe906b1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe905fd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbe905fd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.136990547
Iter: 2 loss: 2792.52832
Iter: 3 loss: 3207.19922
Iter: 4 loss: 0.136989683
Iter: 5 loss: 1693.27771
Iter: 6 loss: 0.136989206
Iter: 7 loss: 303.852814
Iter: 8 loss: 0.136982
Iter: 9 loss: 524.276489
Iter: 10 loss: 0.135491788
Iter: 11 loss: 65.2291
Iter: 12 loss: 0.0866528302
Iter: 13 loss: 0.0756468922
Iter: 14 loss: 0.0767395422
Iter: 15 loss: 0.299248189
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8
+ date
Tue Oct 27 17:35:43 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6950bed378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6950bed158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6950b0dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c388048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c39c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c35ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c3148c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c340730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c314730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c340620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c2d09d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c2548c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c29fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c20c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c1c89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c1d4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c1fbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c1fbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c1b7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c1e7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c17a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c17a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c0ee950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c09b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c09b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c04a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c04a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c024730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f692c024488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f691077d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f69107b36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f69107701e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6910778268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6910719f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f69106d28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f69106f68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0958184227
Iter: 2 loss: 1.09978688
Iter: 3 loss: 1.080019
Iter: 4 loss: 0.735954046
Iter: 5 loss: 0.719993532
Iter: 6 loss: 0.497107416
Iter: 7 loss: 0.482117474
Iter: 8 loss: 0.329963088
Iter: 9 loss: 0.315514266
Iter: 10 loss: 0.216299742
Iter: 11 loss: 0.204169542
Iter: 12 loss: 0.144887775
Iter: 13 loss: 0.136200011
Iter: 14 loss: 0.105075486
Iter: 15 loss: 0.100561023
Iter: 16 loss: 0.087696366
Iter: 17 loss: 0.0864362866
Iter: 18 loss: 0.0851511955
Iter: 19 loss: 0.0821134374
Iter: 20 loss: 672.209595
Iter: 21 loss: 0.153620884
Iter: 22 loss: 0.0858195275
Iter: 23 loss: 0.137079954
Iter: 24 loss: 0.0826010257
Iter: 25 loss: 0.0824609548
Iter: 26 loss: 0.0813582093
Iter: 27 loss: 0.0811436102
Iter: 28 loss: 0.0786163807
Iter: 29 loss: 0.0763413683
Iter: 30 loss: 0.0753113329
Iter: 31 loss: 0.0653567165
Iter: 32 loss: 0.0653515086
Iter: 33 loss: 0.0555399582
Iter: 34 loss: 0.0554557294
Iter: 35 loss: 0.049725581
Iter: 36 loss: 0.0439906
Iter: 37 loss: 0.0570461042
Iter: 38 loss: 0.0426522046
Iter: 39 loss: 0.0397726372
Iter: 40 loss: 0.0509127341
Iter: 41 loss: 0.0386960655
Iter: 42 loss: 0.035675928
Iter: 43 loss: 0.37539494
Iter: 44 loss: 0.0356729068
Iter: 45 loss: 0.0339065567
Iter: 46 loss: 0.0361648872
Iter: 47 loss: 0.033218421
Iter: 48 loss: 0.0317967311
Iter: 49 loss: 0.0303479768
Iter: 50 loss: 0.0300264582
Iter: 51 loss: 0.0275541693
Iter: 52 loss: 0.0572698191
Iter: 53 loss: 0.0272969343
Iter: 54 loss: 0.0259342436
Iter: 55 loss: 0.032598339
Iter: 56 loss: 0.025631329
Iter: 57 loss: 0.0235331096
Iter: 58 loss: 0.0285464264
Iter: 59 loss: 0.0227537155
Iter: 60 loss: 0.0211762507
Iter: 61 loss: 0.0252831895
Iter: 62 loss: 0.0208511595
Iter: 63 loss: 0.0199582577
Iter: 64 loss: 0.0356472097
Iter: 65 loss: 0.0198922977
Iter: 66 loss: 0.0192302316
Iter: 67 loss: 0.0242805611
Iter: 68 loss: 0.0191290863
Iter: 69 loss: 0.0184706524
Iter: 70 loss: 0.020371139
Iter: 71 loss: 0.0182932448
Iter: 72 loss: 0.0176739749
Iter: 73 loss: 0.0176322106
Iter: 74 loss: 0.017181132
Iter: 75 loss: 0.0161083676
Iter: 76 loss: 0.0162264109
Iter: 77 loss: 0.015201007
Iter: 78 loss: 0.0141613344
Iter: 79 loss: 0.0397724696
Iter: 80 loss: 0.0141601488
Iter: 81 loss: 0.0135827251
Iter: 82 loss: 0.0149052553
Iter: 83 loss: 0.0133761121
Iter: 84 loss: 0.0129317082
Iter: 85 loss: 0.0129339807
Iter: 86 loss: 0.0125611462
Iter: 87 loss: 0.012000937
Iter: 88 loss: 0.0133632896
Iter: 89 loss: 0.0117593668
Iter: 90 loss: 0.01161459
Iter: 91 loss: 0.0115104914
Iter: 92 loss: 0.0112361657
Iter: 93 loss: 0.0113571491
Iter: 94 loss: 0.0110451067
Iter: 95 loss: 0.0106363259
Iter: 96 loss: 0.0117499903
Iter: 97 loss: 0.0105006695
Iter: 98 loss: 0.0101142144
Iter: 99 loss: 0.0111857057
Iter: 100 loss: 0.00997759774
Iter: 101 loss: 0.0114996657
Iter: 102 loss: 0.00984790362
Iter: 103 loss: 0.00965789147
Iter: 104 loss: 0.0111873141
Iter: 105 loss: 0.00964133628
Iter: 106 loss: 0.00940781
Iter: 107 loss: 0.00961412117
Iter: 108 loss: 0.00928404275
Iter: 109 loss: 0.0091073662
Iter: 110 loss: 0.00923800562
Iter: 111 loss: 0.00898626074
Iter: 112 loss: 0.00886357855
Iter: 113 loss: 0.00922232401
Iter: 114 loss: 0.00882715639
Iter: 115 loss: 0.00871570408
Iter: 116 loss: 0.00857954659
Iter: 117 loss: 0.00856730808
Iter: 118 loss: 0.0083602909
Iter: 119 loss: 0.00876873
Iter: 120 loss: 0.00826857612
Iter: 121 loss: 0.00809955783
Iter: 122 loss: 0.0106100254
Iter: 123 loss: 0.00809893385
Iter: 124 loss: 0.0079062786
Iter: 125 loss: 0.00869362708
Iter: 126 loss: 0.0078574447
Iter: 127 loss: 0.00769919669
Iter: 128 loss: 0.00808325224
Iter: 129 loss: 0.00763693172
Iter: 130 loss: 0.00749058
Iter: 131 loss: 0.0080250008
Iter: 132 loss: 0.00745680975
Iter: 133 loss: 0.00734617189
Iter: 134 loss: 0.00727627426
Iter: 135 loss: 0.0072275931
Iter: 136 loss: 0.00711549073
Iter: 137 loss: 0.00734145613
Iter: 138 loss: 0.00707415678
Iter: 139 loss: 0.00700950809
Iter: 140 loss: 0.00692626368
Iter: 141 loss: 0.00691973511
Iter: 142 loss: 0.00685430504
Iter: 143 loss: 0.00712155923
Iter: 144 loss: 0.0068418216
Iter: 145 loss: 0.00677132793
Iter: 146 loss: 0.00707072252
Iter: 147 loss: 0.00675471453
Iter: 148 loss: 0.00664828066
Iter: 149 loss: 0.0069047017
Iter: 150 loss: 0.00660899514
Iter: 151 loss: 0.00652875658
Iter: 152 loss: 0.00663758069
Iter: 153 loss: 0.00648946129
Iter: 154 loss: 0.00637177471
Iter: 155 loss: 0.0067265043
Iter: 156 loss: 0.0063324254
Iter: 157 loss: 0.00625376264
Iter: 158 loss: 0.00644418504
Iter: 159 loss: 0.00622386765
Iter: 160 loss: 0.00613828236
Iter: 161 loss: 0.00651775859
Iter: 162 loss: 0.00612080749
Iter: 163 loss: 0.00606480241
Iter: 164 loss: 0.00661748
Iter: 165 loss: 0.00606158189
Iter: 166 loss: 0.00603350671
Iter: 167 loss: 0.00603973307
Iter: 168 loss: 0.00601311075
Iter: 169 loss: 0.00597535959
Iter: 170 loss: 0.00595533615
Iter: 171 loss: 0.0059377728
Iter: 172 loss: 0.00588423293
Iter: 173 loss: 0.00628311932
Iter: 174 loss: 0.00588014163
Iter: 175 loss: 0.00584977912
Iter: 176 loss: 0.00607486814
Iter: 177 loss: 0.00584667502
Iter: 178 loss: 0.00582016353
Iter: 179 loss: 0.00577079412
Iter: 180 loss: 0.00689507648
Iter: 181 loss: 0.00577070192
Iter: 182 loss: 0.00573154818
Iter: 183 loss: 0.00573076401
Iter: 184 loss: 0.0057023596
Iter: 185 loss: 0.00584592298
Iter: 186 loss: 0.00569775561
Iter: 187 loss: 0.00567561109
Iter: 188 loss: 0.00564829353
Iter: 189 loss: 0.00564582739
Iter: 190 loss: 0.00560989697
Iter: 191 loss: 0.00563376024
Iter: 192 loss: 0.00558686489
Iter: 193 loss: 0.00554496236
Iter: 194 loss: 0.00567987841
Iter: 195 loss: 0.00553227495
Iter: 196 loss: 0.00549986633
Iter: 197 loss: 0.00553739537
Iter: 198 loss: 0.00548276491
Iter: 199 loss: 0.00547117833
Iter: 200 loss: 0.00546650123
Iter: 201 loss: 0.00545756239
Iter: 202 loss: 0.00544869434
Iter: 203 loss: 0.00544691551
Iter: 204 loss: 0.00542991515
Iter: 205 loss: 0.00539235584
Iter: 206 loss: 0.00597193558
Iter: 207 loss: 0.00539067294
Iter: 208 loss: 0.00535658468
Iter: 209 loss: 0.00585419964
Iter: 210 loss: 0.00535639282
Iter: 211 loss: 0.00532889925
Iter: 212 loss: 0.00549069047
Iter: 213 loss: 0.00532574253
Iter: 214 loss: 0.00530801341
Iter: 215 loss: 0.00528245419
Iter: 216 loss: 0.00528163137
Iter: 217 loss: 0.00524926465
Iter: 218 loss: 0.00541755045
Iter: 219 loss: 0.0052442085
Iter: 220 loss: 0.00522497622
Iter: 221 loss: 0.005221623
Iter: 222 loss: 0.00520854443
Iter: 223 loss: 0.00518782856
Iter: 224 loss: 0.00523547409
Iter: 225 loss: 0.00518013816
Iter: 226 loss: 0.00515732
Iter: 227 loss: 0.0052132085
Iter: 228 loss: 0.00514917402
Iter: 229 loss: 0.00513329729
Iter: 230 loss: 0.00514217606
Iter: 231 loss: 0.00512294285
Iter: 232 loss: 0.00510688359
Iter: 233 loss: 0.00510094129
Iter: 234 loss: 0.00509224
Iter: 235 loss: 0.00509097893
Iter: 236 loss: 0.00507886801
Iter: 237 loss: 0.00507381838
Iter: 238 loss: 0.00507001532
Iter: 239 loss: 0.00506836455
Iter: 240 loss: 0.00505428715
Iter: 241 loss: 0.00512493774
Iter: 242 loss: 0.00505210739
Iter: 243 loss: 0.00503749028
Iter: 244 loss: 0.00521537941
Iter: 245 loss: 0.00503721088
Iter: 246 loss: 0.00502696214
Iter: 247 loss: 0.00502281357
Iter: 248 loss: 0.00501735229
Iter: 249 loss: 0.00500346115
Iter: 250 loss: 0.0050378954
Iter: 251 loss: 0.00499839149
Iter: 252 loss: 0.0049794903
Iter: 253 loss: 0.0049812817
Iter: 254 loss: 0.0049648406
Iter: 255 loss: 0.00494571403
Iter: 256 loss: 0.00501276134
Iter: 257 loss: 0.00494069187
Iter: 258 loss: 0.0049228929
Iter: 259 loss: 0.00491207931
Iter: 260 loss: 0.00490464782
Iter: 261 loss: 0.00489098858
Iter: 262 loss: 0.00489041256
Iter: 263 loss: 0.0048785517
Iter: 264 loss: 0.0048907483
Iter: 265 loss: 0.00487188296
Iter: 266 loss: 0.00488095
Iter: 267 loss: 0.00486634905
Iter: 268 loss: 0.00486233272
Iter: 269 loss: 0.00486127753
Iter: 270 loss: 0.00485873502
Iter: 271 loss: 0.00484914891
Iter: 272 loss: 0.00483881496
Iter: 273 loss: 0.00483713858
Iter: 274 loss: 0.00482854806
Iter: 275 loss: 0.00482643768
Iter: 276 loss: 0.0048163617
Iter: 277 loss: 0.0048120576
Iter: 278 loss: 0.00480678072
Iter: 279 loss: 0.0047898218
Iter: 280 loss: 0.00483343424
Iter: 281 loss: 0.00478394795
Iter: 282 loss: 0.00477209641
Iter: 283 loss: 0.0047853915
Iter: 284 loss: 0.00476556551
Iter: 285 loss: 0.00475481618
Iter: 286 loss: 0.00474865688
Iter: 287 loss: 0.00474407058
Iter: 288 loss: 0.00473058736
Iter: 289 loss: 0.0048776106
Iter: 290 loss: 0.00473028421
Iter: 291 loss: 0.00471942499
Iter: 292 loss: 0.0047124424
Iter: 293 loss: 0.00470817741
Iter: 294 loss: 0.00469140802
Iter: 295 loss: 0.00479454966
Iter: 296 loss: 0.00468921941
Iter: 297 loss: 0.00468248408
Iter: 298 loss: 0.00470828451
Iter: 299 loss: 0.00468095578
Iter: 300 loss: 0.00467185024
Iter: 301 loss: 0.00471868692
Iter: 302 loss: 0.00467027724
Iter: 303 loss: 0.0046672076
Iter: 304 loss: 0.00466577662
Iter: 305 loss: 0.0046642716
Iter: 306 loss: 0.00465478
Iter: 307 loss: 0.00464759301
Iter: 308 loss: 0.00464444235
Iter: 309 loss: 0.0046298597
Iter: 310 loss: 0.00462949462
Iter: 311 loss: 0.0046205828
Iter: 312 loss: 0.00462269317
Iter: 313 loss: 0.00461404305
Iter: 314 loss: 0.00460634753
Iter: 315 loss: 0.0046382607
Iter: 316 loss: 0.00460471213
Iter: 317 loss: 0.00459794141
Iter: 318 loss: 0.00460128393
Iter: 319 loss: 0.0045934068
Iter: 320 loss: 0.00458283164
Iter: 321 loss: 0.00461185072
Iter: 322 loss: 0.00457937922
Iter: 323 loss: 0.00457305554
Iter: 324 loss: 0.00462756352
Iter: 325 loss: 0.00457270024
Iter: 326 loss: 0.00456745178
Iter: 327 loss: 0.00456997845
Iter: 328 loss: 0.00456395373
Iter: 329 loss: 0.00455969572
Iter: 330 loss: 0.00460632332
Iter: 331 loss: 0.00455958117
Iter: 332 loss: 0.00455662701
Iter: 333 loss: 0.00455662236
Iter: 334 loss: 0.00455494598
Iter: 335 loss: 0.00455077
Iter: 336 loss: 0.0045920196
Iter: 337 loss: 0.00455021486
Iter: 338 loss: 0.00454557873
Iter: 339 loss: 0.00455099717
Iter: 340 loss: 0.00454314891
Iter: 341 loss: 0.00453958148
Iter: 342 loss: 0.00453958102
Iter: 343 loss: 0.00453685131
Iter: 344 loss: 0.00453641359
Iter: 345 loss: 0.00453453418
Iter: 346 loss: 0.00453041634
Iter: 347 loss: 0.00453118933
Iter: 348 loss: 0.00452734157
Iter: 349 loss: 0.00452196
Iter: 350 loss: 0.00455563702
Iter: 351 loss: 0.00452135783
Iter: 352 loss: 0.00451741
Iter: 353 loss: 0.00452642841
Iter: 354 loss: 0.00451593054
Iter: 355 loss: 0.00451189559
Iter: 356 loss: 0.00451083947
Iter: 357 loss: 0.00450833375
Iter: 358 loss: 0.00450251112
Iter: 359 loss: 0.00457111653
Iter: 360 loss: 0.00450242963
Iter: 361 loss: 0.00450020516
Iter: 362 loss: 0.00451585464
Iter: 363 loss: 0.0045000175
Iter: 364 loss: 0.00449796859
Iter: 365 loss: 0.00451383181
Iter: 366 loss: 0.00449781166
Iter: 367 loss: 0.00449573435
Iter: 368 loss: 0.00449218601
Iter: 369 loss: 0.00449218
Iter: 370 loss: 0.00448939344
Iter: 371 loss: 0.00448947772
Iter: 372 loss: 0.00448717549
Iter: 373 loss: 0.00448372774
Iter: 374 loss: 0.00452094758
Iter: 375 loss: 0.0044836523
Iter: 376 loss: 0.00448077172
Iter: 377 loss: 0.00448109396
Iter: 378 loss: 0.00447855238
Iter: 379 loss: 0.00447494304
Iter: 380 loss: 0.0044744988
Iter: 381 loss: 0.00447191903
Iter: 382 loss: 0.00446787663
Iter: 383 loss: 0.00447643828
Iter: 384 loss: 0.00446626218
Iter: 385 loss: 0.0044615753
Iter: 386 loss: 0.00448089838
Iter: 387 loss: 0.00446056528
Iter: 388 loss: 0.00445559062
Iter: 389 loss: 0.00446331594
Iter: 390 loss: 0.00445325533
Iter: 391 loss: 0.00444819685
Iter: 392 loss: 0.00450573815
Iter: 393 loss: 0.00444811862
Iter: 394 loss: 0.00444525294
Iter: 395 loss: 0.00444546156
Iter: 396 loss: 0.00444299448
Iter: 397 loss: 0.00444043707
Iter: 398 loss: 0.00444032904
Iter: 399 loss: 0.00443807151
Iter: 400 loss: 0.00443482865
Iter: 401 loss: 0.00443472387
Iter: 402 loss: 0.00443034805
Iter: 403 loss: 0.00442991685
Iter: 404 loss: 0.00442670379
Iter: 405 loss: 0.004425616
Iter: 406 loss: 0.0044239331
Iter: 407 loss: 0.0044217892
Iter: 408 loss: 0.00442083552
Iter: 409 loss: 0.00441975
Iter: 410 loss: 0.00441554748
Iter: 411 loss: 0.00441813748
Iter: 412 loss: 0.00441284385
Iter: 413 loss: 0.00440836046
Iter: 414 loss: 0.00443752855
Iter: 415 loss: 0.0044078948
Iter: 416 loss: 0.00440478604
Iter: 417 loss: 0.00440695276
Iter: 418 loss: 0.00440284424
Iter: 419 loss: 0.00439910963
Iter: 420 loss: 0.00439538714
Iter: 421 loss: 0.00439462066
Iter: 422 loss: 0.0043897396
Iter: 423 loss: 0.00445308443
Iter: 424 loss: 0.00438969955
Iter: 425 loss: 0.00438650139
Iter: 426 loss: 0.00439666584
Iter: 427 loss: 0.00438561
Iter: 428 loss: 0.00438401382
Iter: 429 loss: 0.00438386481
Iter: 430 loss: 0.0043821088
Iter: 431 loss: 0.00437862147
Iter: 432 loss: 0.00444491
Iter: 433 loss: 0.00437858049
Iter: 434 loss: 0.00437511271
Iter: 435 loss: 0.00437273737
Iter: 436 loss: 0.00437147962
Iter: 437 loss: 0.00436755549
Iter: 438 loss: 0.00442201
Iter: 439 loss: 0.00436754664
Iter: 440 loss: 0.00436358526
Iter: 441 loss: 0.0043674442
Iter: 442 loss: 0.00436132634
Iter: 443 loss: 0.00435786741
Iter: 444 loss: 0.00435860641
Iter: 445 loss: 0.00435531605
Iter: 446 loss: 0.00435160287
Iter: 447 loss: 0.00435410533
Iter: 448 loss: 0.00434925128
Iter: 449 loss: 0.00434364565
Iter: 450 loss: 0.00436269213
Iter: 451 loss: 0.00434214389
Iter: 452 loss: 0.00433663838
Iter: 453 loss: 0.00435541058
Iter: 454 loss: 0.00433515664
Iter: 455 loss: 0.00433183555
Iter: 456 loss: 0.00433182903
Iter: 457 loss: 0.00432932237
Iter: 458 loss: 0.00432666438
Iter: 459 loss: 0.00432621129
Iter: 460 loss: 0.00432370137
Iter: 461 loss: 0.00432357425
Iter: 462 loss: 0.00432073465
Iter: 463 loss: 0.00431803195
Iter: 464 loss: 0.00431738375
Iter: 465 loss: 0.00431400817
Iter: 466 loss: 0.00431200536
Iter: 467 loss: 0.00431058928
Iter: 468 loss: 0.00430664793
Iter: 469 loss: 0.00432531442
Iter: 470 loss: 0.00430591591
Iter: 471 loss: 0.00430190517
Iter: 472 loss: 0.00431487849
Iter: 473 loss: 0.00430078525
Iter: 474 loss: 0.00429724203
Iter: 475 loss: 0.00430195872
Iter: 476 loss: 0.00429545343
Iter: 477 loss: 0.00429173838
Iter: 478 loss: 0.00431459537
Iter: 479 loss: 0.00429130346
Iter: 480 loss: 0.00428794697
Iter: 481 loss: 0.0042909258
Iter: 482 loss: 0.00428598048
Iter: 483 loss: 0.00428272411
Iter: 484 loss: 0.00428360794
Iter: 485 loss: 0.00428037252
Iter: 486 loss: 0.00427708216
Iter: 487 loss: 0.00429245969
Iter: 488 loss: 0.00427646656
Iter: 489 loss: 0.00427276129
Iter: 490 loss: 0.00428658444
Iter: 491 loss: 0.0042718593
Iter: 492 loss: 0.00426910399
Iter: 493 loss: 0.00428385334
Iter: 494 loss: 0.00426865881
Iter: 495 loss: 0.00426465366
Iter: 496 loss: 0.0042692218
Iter: 497 loss: 0.00426252652
Iter: 498 loss: 0.00425964501
Iter: 499 loss: 0.00425754907
Iter: 500 loss: 0.00425657071
Iter: 501 loss: 0.0042534261
Iter: 502 loss: 0.00429247227
Iter: 503 loss: 0.0042533977
Iter: 504 loss: 0.00425068475
Iter: 505 loss: 0.00425870903
Iter: 506 loss: 0.00424984
Iter: 507 loss: 0.00424775574
Iter: 508 loss: 0.00424716808
Iter: 509 loss: 0.00424589869
Iter: 510 loss: 0.00424316153
Iter: 511 loss: 0.00424560718
Iter: 512 loss: 0.00424155407
Iter: 513 loss: 0.0042377254
Iter: 514 loss: 0.00425398443
Iter: 515 loss: 0.00423691794
Iter: 516 loss: 0.00423350558
Iter: 517 loss: 0.00423957501
Iter: 518 loss: 0.00423200475
Iter: 519 loss: 0.00422879821
Iter: 520 loss: 0.00425561331
Iter: 521 loss: 0.00422860868
Iter: 522 loss: 0.00422553
Iter: 523 loss: 0.0042283223
Iter: 524 loss: 0.004223736
Iter: 525 loss: 0.00422113668
Iter: 526 loss: 0.00423936918
Iter: 527 loss: 0.00422091223
Iter: 528 loss: 0.00421809405
Iter: 529 loss: 0.00422600517
Iter: 530 loss: 0.00421717204
Iter: 531 loss: 0.00421572104
Iter: 532 loss: 0.00421453267
Iter: 533 loss: 0.0042141038
Iter: 534 loss: 0.00421183882
Iter: 535 loss: 0.00421294942
Iter: 536 loss: 0.00421030819
Iter: 537 loss: 0.0042074034
Iter: 538 loss: 0.00424838904
Iter: 539 loss: 0.00420739455
Iter: 540 loss: 0.00420591468
Iter: 541 loss: 0.00420506764
Iter: 542 loss: 0.00420443
Iter: 543 loss: 0.00420183782
Iter: 544 loss: 0.00421078596
Iter: 545 loss: 0.00420116074
Iter: 546 loss: 0.00419844
Iter: 547 loss: 0.00420393376
Iter: 548 loss: 0.00419732695
Iter: 549 loss: 0.00419488456
Iter: 550 loss: 0.00419636816
Iter: 551 loss: 0.00419330131
Iter: 552 loss: 0.00419039
Iter: 553 loss: 0.00419562822
Iter: 554 loss: 0.00418911502
Iter: 555 loss: 0.0041855108
Iter: 556 loss: 0.00420941692
Iter: 557 loss: 0.00418513641
Iter: 558 loss: 0.00418281322
Iter: 559 loss: 0.00419208035
Iter: 560 loss: 0.00418226747
Iter: 561 loss: 0.0041798288
Iter: 562 loss: 0.00420012139
Iter: 563 loss: 0.00417969143
Iter: 564 loss: 0.00417857571
Iter: 565 loss: 0.00417622924
Iter: 566 loss: 0.00421464443
Iter: 567 loss: 0.00417615846
Iter: 568 loss: 0.00417329231
Iter: 569 loss: 0.00418277085
Iter: 570 loss: 0.00417249789
Iter: 571 loss: 0.00417041965
Iter: 572 loss: 0.00417039823
Iter: 573 loss: 0.0041691931
Iter: 574 loss: 0.00416784082
Iter: 575 loss: 0.00416765921
Iter: 576 loss: 0.00416549388
Iter: 577 loss: 0.00417156704
Iter: 578 loss: 0.00416479353
Iter: 579 loss: 0.00416268874
Iter: 580 loss: 0.00417554751
Iter: 581 loss: 0.00416243635
Iter: 582 loss: 0.00416085683
Iter: 583 loss: 0.00416107476
Iter: 584 loss: 0.00415965309
Iter: 585 loss: 0.00415785424
Iter: 586 loss: 0.00416683313
Iter: 587 loss: 0.00415755156
Iter: 588 loss: 0.00415606098
Iter: 589 loss: 0.00416441681
Iter: 590 loss: 0.00415585143
Iter: 591 loss: 0.00415483769
Iter: 592 loss: 0.00416009221
Iter: 593 loss: 0.00415467937
Iter: 594 loss: 0.00415366655
Iter: 595 loss: 0.00416115206
Iter: 596 loss: 0.00415358366
Iter: 597 loss: 0.00415297877
Iter: 598 loss: 0.00415196503
Iter: 599 loss: 0.00415196177
Iter: 600 loss: 0.00415073335
Iter: 601 loss: 0.00415001903
Iter: 602 loss: 0.00414949609
Iter: 603 loss: 0.00414818106
Iter: 604 loss: 0.00414809911
Iter: 605 loss: 0.00414726976
Iter: 606 loss: 0.00414616941
Iter: 607 loss: 0.00414610188
Iter: 608 loss: 0.00414473144
Iter: 609 loss: 0.00415165443
Iter: 610 loss: 0.00414450467
Iter: 611 loss: 0.0041433638
Iter: 612 loss: 0.00414855918
Iter: 613 loss: 0.00414314354
Iter: 614 loss: 0.00414211769
Iter: 615 loss: 0.00414280593
Iter: 616 loss: 0.00414147228
Iter: 617 loss: 0.00414040592
Iter: 618 loss: 0.00414672773
Iter: 619 loss: 0.00414026901
Iter: 620 loss: 0.00413936097
Iter: 621 loss: 0.00414236169
Iter: 622 loss: 0.00413911138
Iter: 623 loss: 0.0041382676
Iter: 624 loss: 0.00414042408
Iter: 625 loss: 0.00413796632
Iter: 626 loss: 0.00413719099
Iter: 627 loss: 0.00414350163
Iter: 628 loss: 0.00413714442
Iter: 629 loss: 0.00413663546
Iter: 630 loss: 0.00413554674
Iter: 631 loss: 0.00415256
Iter: 632 loss: 0.00413550716
Iter: 633 loss: 0.00413401891
Iter: 634 loss: 0.00413709134
Iter: 635 loss: 0.00413342239
Iter: 636 loss: 0.00413277466
Iter: 637 loss: 0.00413257396
Iter: 638 loss: 0.00413206592
Iter: 639 loss: 0.00413134
Iter: 640 loss: 0.0041313176
Iter: 641 loss: 0.00413050968
Iter: 642 loss: 0.00413479656
Iter: 643 loss: 0.00413038209
Iter: 644 loss: 0.00412969291
Iter: 645 loss: 0.00413243752
Iter: 646 loss: 0.00412954064
Iter: 647 loss: 0.00412893
Iter: 648 loss: 0.00412902329
Iter: 649 loss: 0.00412846543
Iter: 650 loss: 0.00412782934
Iter: 651 loss: 0.00413052598
Iter: 652 loss: 0.00412769383
Iter: 653 loss: 0.00412709918
Iter: 654 loss: 0.00413100421
Iter: 655 loss: 0.00412703352
Iter: 656 loss: 0.0041266121
Iter: 657 loss: 0.00412976649
Iter: 658 loss: 0.00412657904
Iter: 659 loss: 0.00412627123
Iter: 660 loss: 0.00412898324
Iter: 661 loss: 0.0041262568
Iter: 662 loss: 0.0041260561
Iter: 663 loss: 0.00412569847
Iter: 664 loss: 0.00412569754
Iter: 665 loss: 0.00412529
Iter: 666 loss: 0.00412531
Iter: 667 loss: 0.00412496971
Iter: 668 loss: 0.00412474526
Iter: 669 loss: 0.0041246796
Iter: 670 loss: 0.00412448449
Iter: 671 loss: 0.00412426423
Iter: 672 loss: 0.00412423257
Iter: 673 loss: 0.0041239243
Iter: 674 loss: 0.00412442721
Iter: 675 loss: 0.00412378553
Iter: 676 loss: 0.00412336085
Iter: 677 loss: 0.00412494689
Iter: 678 loss: 0.00412325747
Iter: 679 loss: 0.00412281603
Iter: 680 loss: 0.00412321743
Iter: 681 loss: 0.00412255758
Iter: 682 loss: 0.00412208773
Iter: 683 loss: 0.00412359927
Iter: 684 loss: 0.00412195921
Iter: 685 loss: 0.00412149169
Iter: 686 loss: 0.00412373478
Iter: 687 loss: 0.00412141159
Iter: 688 loss: 0.00412108423
Iter: 689 loss: 0.00412345119
Iter: 690 loss: 0.00412105722
Iter: 691 loss: 0.00412084116
Iter: 692 loss: 0.00412232848
Iter: 693 loss: 0.00412082393
Iter: 694 loss: 0.00412064139
Iter: 695 loss: 0.00412020832
Iter: 696 loss: 0.00412531057
Iter: 697 loss: 0.00412017573
Iter: 698 loss: 0.00411959179
Iter: 699 loss: 0.00412105815
Iter: 700 loss: 0.00411939202
Iter: 701 loss: 0.00411917269
Iter: 702 loss: 0.00411911961
Iter: 703 loss: 0.00411891378
Iter: 704 loss: 0.004118538
Iter: 705 loss: 0.00412757928
Iter: 706 loss: 0.00411853567
Iter: 707 loss: 0.00411807094
Iter: 708 loss: 0.00411894545
Iter: 709 loss: 0.0041178735
Iter: 710 loss: 0.00411732
Iter: 711 loss: 0.00412118575
Iter: 712 loss: 0.00411726907
Iter: 713 loss: 0.00411686487
Iter: 714 loss: 0.00411711633
Iter: 715 loss: 0.00411660224
Iter: 716 loss: 0.00411620829
Iter: 717 loss: 0.00411719689
Iter: 718 loss: 0.00411607558
Iter: 719 loss: 0.00411570119
Iter: 720 loss: 0.00411861949
Iter: 721 loss: 0.00411567511
Iter: 722 loss: 0.00411543436
Iter: 723 loss: 0.0041175005
Iter: 724 loss: 0.00411542086
Iter: 725 loss: 0.00411523785
Iter: 726 loss: 0.00411624555
Iter: 727 loss: 0.00411521364
Iter: 728 loss: 0.00411504041
Iter: 729 loss: 0.00411472842
Iter: 730 loss: 0.00412228936
Iter: 731 loss: 0.00411473
Iter: 732 loss: 0.00411440153
Iter: 733 loss: 0.00411509443
Iter: 734 loss: 0.00411427161
Iter: 735 loss: 0.00411408581
Iter: 736 loss: 0.00411407743
Iter: 737 loss: 0.00411390141
Iter: 738 loss: 0.0041136425
Iter: 739 loss: 0.00411363784
Iter: 740 loss: 0.00411335
Iter: 741 loss: 0.00411382876
Iter: 742 loss: 0.00411321875
Iter: 743 loss: 0.00411289278
Iter: 744 loss: 0.00411529373
Iter: 745 loss: 0.00411286671
Iter: 746 loss: 0.0041126
Iter: 747 loss: 0.00411285926
Iter: 748 loss: 0.00411244482
Iter: 749 loss: 0.00411218219
Iter: 750 loss: 0.0041132
Iter: 751 loss: 0.00411212072
Iter: 752 loss: 0.00411188183
Iter: 753 loss: 0.00411310652
Iter: 754 loss: 0.00411184318
Iter: 755 loss: 0.00411165413
Iter: 756 loss: 0.00411269162
Iter: 757 loss: 0.00411162758
Iter: 758 loss: 0.00411146833
Iter: 759 loss: 0.00411221199
Iter: 760 loss: 0.00411144132
Iter: 761 loss: 0.00411127601
Iter: 762 loss: 0.00411101757
Iter: 763 loss: 0.00411101617
Iter: 764 loss: 0.00411071396
Iter: 765 loss: 0.0041111256
Iter: 766 loss: 0.00411056168
Iter: 767 loss: 0.00411032885
Iter: 768 loss: 0.00411033025
Iter: 769 loss: 0.0041101072
Iter: 770 loss: 0.00410995912
Iter: 771 loss: 0.0041098753
Iter: 772 loss: 0.0041095959
Iter: 773 loss: 0.00410973793
Iter: 774 loss: 0.00410941243
Iter: 775 loss: 0.00410898402
Iter: 776 loss: 0.00411155121
Iter: 777 loss: 0.00410893513
Iter: 778 loss: 0.00410857331
Iter: 779 loss: 0.00410897611
Iter: 780 loss: 0.00410837727
Iter: 781 loss: 0.00410808576
Iter: 782 loss: 0.00410865806
Iter: 783 loss: 0.00410796469
Iter: 784 loss: 0.00410763174
Iter: 785 loss: 0.00410948228
Iter: 786 loss: 0.00410758471
Iter: 787 loss: 0.00410731509
Iter: 788 loss: 0.00410921779
Iter: 789 loss: 0.00410729274
Iter: 790 loss: 0.00410707295
Iter: 791 loss: 0.00410819
Iter: 792 loss: 0.00410704408
Iter: 793 loss: 0.00410682801
Iter: 794 loss: 0.00410659
Iter: 795 loss: 0.00410655607
Iter: 796 loss: 0.00410624407
Iter: 797 loss: 0.00410663243
Iter: 798 loss: 0.00410608
Iter: 799 loss: 0.00410584267
Iter: 800 loss: 0.00410584128
Iter: 801 loss: 0.00410562055
Iter: 802 loss: 0.00410554325
Iter: 803 loss: 0.00410541799
Iter: 804 loss: 0.00410517678
Iter: 805 loss: 0.00410496
Iter: 806 loss: 0.00410489924
Iter: 807 loss: 0.00410445733
Iter: 808 loss: 0.00410767365
Iter: 809 loss: 0.00410441868
Iter: 810 loss: 0.00410407409
Iter: 811 loss: 0.00410528388
Iter: 812 loss: 0.00410398282
Iter: 813 loss: 0.00410373416
Iter: 814 loss: 0.00410417607
Iter: 815 loss: 0.00410362519
Iter: 816 loss: 0.00410334719
Iter: 817 loss: 0.00410530902
Iter: 818 loss: 0.00410332065
Iter: 819 loss: 0.00410313066
Iter: 820 loss: 0.00410419749
Iter: 821 loss: 0.00410310552
Iter: 822 loss: 0.00410295045
Iter: 823 loss: 0.00410370156
Iter: 824 loss: 0.00410292484
Iter: 825 loss: 0.00410277769
Iter: 826 loss: 0.0041026054
Iter: 827 loss: 0.00410258677
Iter: 828 loss: 0.00410237629
Iter: 829 loss: 0.00410262262
Iter: 830 loss: 0.00410226686
Iter: 831 loss: 0.00410210062
Iter: 832 loss: 0.00410422031
Iter: 833 loss: 0.00410209829
Iter: 834 loss: 0.00410193391
Iter: 835 loss: 0.0041019721
Iter: 836 loss: 0.00410181284
Iter: 837 loss: 0.00410163403
Iter: 838 loss: 0.00410151109
Iter: 839 loss: 0.0041014459
Iter: 840 loss: 0.00410116278
Iter: 841 loss: 0.00410444802
Iter: 842 loss: 0.00410115905
Iter: 843 loss: 0.00410097
Iter: 844 loss: 0.0041013
Iter: 845 loss: 0.0041008871
Iter: 846 loss: 0.00410073344
Iter: 847 loss: 0.00410078093
Iter: 848 loss: 0.00410062494
Iter: 849 loss: 0.00410043914
Iter: 850 loss: 0.00410210434
Iter: 851 loss: 0.00410043076
Iter: 852 loss: 0.00410029851
Iter: 853 loss: 0.00410117721
Iter: 854 loss: 0.004100285
Iter: 855 loss: 0.0041001779
Iter: 856 loss: 0.00410065427
Iter: 857 loss: 0.00410015788
Iter: 858 loss: 0.00410004333
Iter: 859 loss: 0.004099946
Iter: 860 loss: 0.00409991248
Iter: 861 loss: 0.00409976672
Iter: 862 loss: 0.00409993762
Iter: 863 loss: 0.00409968896
Iter: 864 loss: 0.0040995609
Iter: 865 loss: 0.00410116091
Iter: 866 loss: 0.00409955578
Iter: 867 loss: 0.00409942772
Iter: 868 loss: 0.00409945613
Iter: 869 loss: 0.00409933
Iter: 870 loss: 0.0040992084
Iter: 871 loss: 0.00409906404
Iter: 872 loss: 0.00409904681
Iter: 873 loss: 0.0040988382
Iter: 874 loss: 0.00410127081
Iter: 875 loss: 0.004098834
Iter: 876 loss: 0.00409868173
Iter: 877 loss: 0.0040990347
Iter: 878 loss: 0.00409862492
Iter: 879 loss: 0.00409849081
Iter: 880 loss: 0.00409861468
Iter: 881 loss: 0.00409841351
Iter: 882 loss: 0.004098278
Iter: 883 loss: 0.00409981702
Iter: 884 loss: 0.00409827661
Iter: 885 loss: 0.00409818
Iter: 886 loss: 0.00409846427
Iter: 887 loss: 0.0040981546
Iter: 888 loss: 0.00409805123
Iter: 889 loss: 0.00409853924
Iter: 890 loss: 0.0040980354
Iter: 891 loss: 0.00409793435
Iter: 892 loss: 0.0040978929
Iter: 893 loss: 0.00409784727
Iter: 894 loss: 0.00409773411
Iter: 895 loss: 0.00409782352
Iter: 896 loss: 0.00409766845
Iter: 897 loss: 0.00409755716
Iter: 898 loss: 0.00409830455
Iter: 899 loss: 0.00409754738
Iter: 900 loss: 0.00409742165
Iter: 901 loss: 0.00409761164
Iter: 902 loss: 0.00409736065
Iter: 903 loss: 0.00409725914
Iter: 904 loss: 0.00409713853
Iter: 905 loss: 0.00409712177
Iter: 906 loss: 0.00409695
Iter: 907 loss: 0.00409919489
Iter: 908 loss: 0.00409694761
Iter: 909 loss: 0.00409682374
Iter: 910 loss: 0.00409707753
Iter: 911 loss: 0.00409677532
Iter: 912 loss: 0.00409667892
Iter: 913 loss: 0.00409674365
Iter: 914 loss: 0.00409662025
Iter: 915 loss: 0.00409651175
Iter: 916 loss: 0.00409731222
Iter: 917 loss: 0.00409650244
Iter: 918 loss: 0.00409641769
Iter: 919 loss: 0.00409682095
Iter: 920 loss: 0.0040963972
Iter: 921 loss: 0.00409631617
Iter: 922 loss: 0.00409679906
Iter: 923 loss: 0.00409630826
Iter: 924 loss: 0.00409623282
Iter: 925 loss: 0.00409624306
Iter: 926 loss: 0.00409617228
Iter: 927 loss: 0.0040961029
Iter: 928 loss: 0.00409608195
Iter: 929 loss: 0.0040960405
Iter: 930 loss: 0.00409594458
Iter: 931 loss: 0.00409686938
Iter: 932 loss: 0.00409594039
Iter: 933 loss: 0.00409584586
Iter: 934 loss: 0.00409601768
Iter: 935 loss: 0.00409580534
Iter: 936 loss: 0.00409573968
Iter: 937 loss: 0.00409561489
Iter: 938 loss: 0.00409838511
Iter: 939 loss: 0.00409561396
Iter: 940 loss: 0.00409548543
Iter: 941 loss: 0.00409706868
Iter: 942 loss: 0.00409548357
Iter: 943 loss: 0.0040953923
Iter: 944 loss: 0.00409569871
Iter: 945 loss: 0.00409536716
Iter: 946 loss: 0.00409529265
Iter: 947 loss: 0.00409534853
Iter: 948 loss: 0.00409524655
Iter: 949 loss: 0.00409516366
Iter: 950 loss: 0.00409621
Iter: 951 loss: 0.0040951618
Iter: 952 loss: 0.00409510452
Iter: 953 loss: 0.00409520464
Iter: 954 loss: 0.00409508
Iter: 955 loss: 0.00409501512
Iter: 956 loss: 0.0040953327
Iter: 957 loss: 0.0040950072
Iter: 958 loss: 0.00409494806
Iter: 959 loss: 0.00409494434
Iter: 960 loss: 0.00409490475
Iter: 961 loss: 0.00409483444
Iter: 962 loss: 0.00409486052
Iter: 963 loss: 0.00409478741
Iter: 964 loss: 0.00409471104
Iter: 965 loss: 0.00409517111
Iter: 966 loss: 0.00409470545
Iter: 967 loss: 0.00409461418
Iter: 968 loss: 0.00409484049
Iter: 969 loss: 0.00409458391
Iter: 970 loss: 0.00409451872
Iter: 971 loss: 0.00409441069
Iter: 972 loss: 0.00409440883
Iter: 973 loss: 0.00409430731
Iter: 974 loss: 0.00409430498
Iter: 975 loss: 0.00409423932
Iter: 976 loss: 0.00409429
Iter: 977 loss: 0.00409419928
Iter: 978 loss: 0.00409411918
Iter: 979 loss: 0.0040942356
Iter: 980 loss: 0.00409408286
Iter: 981 loss: 0.00409401301
Iter: 982 loss: 0.00409490149
Iter: 983 loss: 0.00409401348
Iter: 984 loss: 0.00409395294
Iter: 985 loss: 0.0040942207
Iter: 986 loss: 0.00409393851
Iter: 987 loss: 0.00409388589
Iter: 988 loss: 0.0040940512
Iter: 989 loss: 0.00409387331
Iter: 990 loss: 0.00409381464
Iter: 991 loss: 0.00409384817
Iter: 992 loss: 0.00409377832
Iter: 993 loss: 0.00409372244
Iter: 994 loss: 0.00409369124
Iter: 995 loss: 0.00409366749
Iter: 996 loss: 0.00409358274
Iter: 997 loss: 0.00409417041
Iter: 998 loss: 0.00409357622
Iter: 999 loss: 0.00409348449
Iter: 1000 loss: 0.00409379276
Iter: 1001 loss: 0.00409346074
Iter: 1002 loss: 0.00409340393
Iter: 1003 loss: 0.00409331359
Iter: 1004 loss: 0.00409331452
Iter: 1005 loss: 0.00409321953
Iter: 1006 loss: 0.00409431569
Iter: 1007 loss: 0.00409321627
Iter: 1008 loss: 0.00409314036
Iter: 1009 loss: 0.00409324281
Iter: 1010 loss: 0.00409310451
Iter: 1011 loss: 0.0040930286
Iter: 1012 loss: 0.00409305934
Iter: 1013 loss: 0.00409297599
Iter: 1014 loss: 0.00409290614
Iter: 1015 loss: 0.00409290753
Iter: 1016 loss: 0.00409285398
Iter: 1017 loss: 0.00409301883
Iter: 1018 loss: 0.00409283955
Iter: 1019 loss: 0.00409278832
Iter: 1020 loss: 0.00409299461
Iter: 1021 loss: 0.00409277808
Iter: 1022 loss: 0.00409272779
Iter: 1023 loss: 0.00409273338
Iter: 1024 loss: 0.00409269147
Iter: 1025 loss: 0.00409262814
Iter: 1026 loss: 0.00409259461
Iter: 1027 loss: 0.00409256853
Iter: 1028 loss: 0.00409249
Iter: 1029 loss: 0.00409304909
Iter: 1030 loss: 0.00409248238
Iter: 1031 loss: 0.0040924
Iter: 1032 loss: 0.00409282185
Iter: 1033 loss: 0.00409238692
Iter: 1034 loss: 0.00409233803
Iter: 1035 loss: 0.00409225
Iter: 1036 loss: 0.00409440277
Iter: 1037 loss: 0.00409225
Iter: 1038 loss: 0.0040921662
Iter: 1039 loss: 0.00409216806
Iter: 1040 loss: 0.00409210613
Iter: 1041 loss: 0.00409209076
Iter: 1042 loss: 0.00409205444
Iter: 1043 loss: 0.00409196783
Iter: 1044 loss: 0.00409204373
Iter: 1045 loss: 0.00409191754
Iter: 1046 loss: 0.00409184396
Iter: 1047 loss: 0.0040918435
Iter: 1048 loss: 0.00409179181
Iter: 1049 loss: 0.00409207679
Iter: 1050 loss: 0.00409177924
Iter: 1051 loss: 0.00409173267
Iter: 1052 loss: 0.00409188028
Iter: 1053 loss: 0.00409171823
Iter: 1054 loss: 0.00409166515
Iter: 1055 loss: 0.00409169635
Iter: 1056 loss: 0.00409163162
Iter: 1057 loss: 0.00409157854
Iter: 1058 loss: 0.0040915492
Iter: 1059 loss: 0.00409152359
Iter: 1060 loss: 0.00409145
Iter: 1061 loss: 0.00409199111
Iter: 1062 loss: 0.00409144349
Iter: 1063 loss: 0.00409137271
Iter: 1064 loss: 0.00409172382
Iter: 1065 loss: 0.00409136247
Iter: 1066 loss: 0.00409132056
Iter: 1067 loss: 0.0040912549
Iter: 1068 loss: 0.00409125164
Iter: 1069 loss: 0.00409118086
Iter: 1070 loss: 0.00409202836
Iter: 1071 loss: 0.00409118179
Iter: 1072 loss: 0.00409112452
Iter: 1073 loss: 0.00409114547
Iter: 1074 loss: 0.00409108028
Iter: 1075 loss: 0.00409100763
Iter: 1076 loss: 0.00409099367
Iter: 1077 loss: 0.00409094524
Iter: 1078 loss: 0.00409087352
Iter: 1079 loss: 0.00409087
Iter: 1080 loss: 0.00409081345
Iter: 1081 loss: 0.00409104442
Iter: 1082 loss: 0.00409080135
Iter: 1083 loss: 0.00409075338
Iter: 1084 loss: 0.0040909322
Iter: 1085 loss: 0.00409074128
Iter: 1086 loss: 0.00409069285
Iter: 1087 loss: 0.00409072358
Iter: 1088 loss: 0.00409066491
Iter: 1089 loss: 0.00409061648
Iter: 1090 loss: 0.00409058481
Iter: 1091 loss: 0.00409056433
Iter: 1092 loss: 0.00409049354
Iter: 1093 loss: 0.00409093546
Iter: 1094 loss: 0.00409048796
Iter: 1095 loss: 0.00409041904
Iter: 1096 loss: 0.00409088656
Iter: 1097 loss: 0.00409041438
Iter: 1098 loss: 0.00409037713
Iter: 1099 loss: 0.00409030681
Iter: 1100 loss: 0.00409185514
Iter: 1101 loss: 0.00409030821
Iter: 1102 loss: 0.00409024162
Iter: 1103 loss: 0.00409118086
Iter: 1104 loss: 0.00409024209
Iter: 1105 loss: 0.00409019133
Iter: 1106 loss: 0.0040901727
Iter: 1107 loss: 0.00409014337
Iter: 1108 loss: 0.00409006141
Iter: 1109 loss: 0.00409015268
Iter: 1110 loss: 0.00409001671
Iter: 1111 loss: 0.00408994732
Iter: 1112 loss: 0.00409103837
Iter: 1113 loss: 0.004089945
Iter: 1114 loss: 0.00408989191
Iter: 1115 loss: 0.00409025606
Iter: 1116 loss: 0.00408988632
Iter: 1117 loss: 0.00408984721
Iter: 1118 loss: 0.00408995803
Iter: 1119 loss: 0.00408983603
Iter: 1120 loss: 0.00408979598
Iter: 1121 loss: 0.00408983883
Iter: 1122 loss: 0.00408977317
Iter: 1123 loss: 0.00408973265
Iter: 1124 loss: 0.00408969121
Iter: 1125 loss: 0.00408967957
Iter: 1126 loss: 0.00408961903
Iter: 1127 loss: 0.00409013405
Iter: 1128 loss: 0.00408961345
Iter: 1129 loss: 0.00408955617
Iter: 1130 loss: 0.00408998225
Iter: 1131 loss: 0.00408955198
Iter: 1132 loss: 0.00408951845
Iter: 1133 loss: 0.00408946769
Iter: 1134 loss: 0.00408946769
Iter: 1135 loss: 0.0040894188
Iter: 1136 loss: 0.00408995384
Iter: 1137 loss: 0.00408941833
Iter: 1138 loss: 0.00408937549
Iter: 1139 loss: 0.00408935966
Iter: 1140 loss: 0.00408933032
Iter: 1141 loss: 0.00408926141
Iter: 1142 loss: 0.00408926047
Iter: 1143 loss: 0.00408920646
Iter: 1144 loss: 0.00408915244
Iter: 1145 loss: 0.00408914592
Iter: 1146 loss: 0.00408910308
Iter: 1147 loss: 0.00408940576
Iter: 1148 loss: 0.00408909749
Iter: 1149 loss: 0.00408906629
Iter: 1150 loss: 0.0040891543
Iter: 1151 loss: 0.00408905651
Iter: 1152 loss: 0.00408902299
Iter: 1153 loss: 0.00408903975
Iter: 1154 loss: 0.00408899924
Iter: 1155 loss: 0.00408895826
Iter: 1156 loss: 0.00408891402
Iter: 1157 loss: 0.0040889075
Iter: 1158 loss: 0.00408884371
Iter: 1159 loss: 0.00408921856
Iter: 1160 loss: 0.00408883765
Iter: 1161 loss: 0.00408877898
Iter: 1162 loss: 0.0040892968
Iter: 1163 loss: 0.00408877572
Iter: 1164 loss: 0.00408874592
Iter: 1165 loss: 0.00408869423
Iter: 1166 loss: 0.00408995291
Iter: 1167 loss: 0.00408869144
Iter: 1168 loss: 0.00408863975
Iter: 1169 loss: 0.00408941507
Iter: 1170 loss: 0.00408863742
Iter: 1171 loss: 0.00408858946
Iter: 1172 loss: 0.00408855
Iter: 1173 loss: 0.00408853963
Iter: 1174 loss: 0.0040884614
Iter: 1175 loss: 0.00408848748
Iter: 1176 loss: 0.00408840179
Iter: 1177 loss: 0.00408833055
Iter: 1178 loss: 0.00408918131
Iter: 1179 loss: 0.00408832915
Iter: 1180 loss: 0.00408827141
Iter: 1181 loss: 0.00408883858
Iter: 1182 loss: 0.00408826955
Iter: 1183 loss: 0.00408823416
Iter: 1184 loss: 0.00408834545
Iter: 1185 loss: 0.00408822251
Iter: 1186 loss: 0.00408818061
Iter: 1187 loss: 0.004088216
Iter: 1188 loss: 0.00408816105
Iter: 1189 loss: 0.00408811169
Iter: 1190 loss: 0.00408806698
Iter: 1191 loss: 0.00408805441
Iter: 1192 loss: 0.00408798689
Iter: 1193 loss: 0.00408851635
Iter: 1194 loss: 0.00408798363
Iter: 1195 loss: 0.00408792822
Iter: 1196 loss: 0.00408840133
Iter: 1197 loss: 0.00408792635
Iter: 1198 loss: 0.00408789515
Iter: 1199 loss: 0.00408784
Iter: 1200 loss: 0.00408784114
Iter: 1201 loss: 0.00408778619
Iter: 1202 loss: 0.00408828119
Iter: 1203 loss: 0.00408778433
Iter: 1204 loss: 0.0040877331
Iter: 1205 loss: 0.00408775685
Iter: 1206 loss: 0.00408769818
Iter: 1207 loss: 0.00408763438
Iter: 1208 loss: 0.00408763438
Iter: 1209 loss: 0.00408758409
Iter: 1210 loss: 0.00408751937
Iter: 1211 loss: 0.00408836547
Iter: 1212 loss: 0.00408752
Iter: 1213 loss: 0.00408747606
Iter: 1214 loss: 0.00408787746
Iter: 1215 loss: 0.00408747513
Iter: 1216 loss: 0.00408744672
Iter: 1217 loss: 0.00408755057
Iter: 1218 loss: 0.00408743788
Iter: 1219 loss: 0.004087409
Iter: 1220 loss: 0.00408741273
Iter: 1221 loss: 0.00408738945
Iter: 1222 loss: 0.00408735033
Iter: 1223 loss: 0.00408732519
Iter: 1224 loss: 0.00408731122
Iter: 1225 loss: 0.00408726279
Iter: 1226 loss: 0.00408752449
Iter: 1227 loss: 0.0040872572
Iter: 1228 loss: 0.00408721063
Iter: 1229 loss: 0.00408771215
Iter: 1230 loss: 0.0040872125
Iter: 1231 loss: 0.00408718782
Iter: 1232 loss: 0.00408714497
Iter: 1233 loss: 0.00408798
Iter: 1234 loss: 0.00408714218
Iter: 1235 loss: 0.00408710167
Iter: 1236 loss: 0.00408758642
Iter: 1237 loss: 0.0040871012
Iter: 1238 loss: 0.00408706395
Iter: 1239 loss: 0.00408707932
Iter: 1240 loss: 0.00408703834
Iter: 1241 loss: 0.00408699177
Iter: 1242 loss: 0.00408703601
Iter: 1243 loss: 0.00408696942
Iter: 1244 loss: 0.0040869303
Iter: 1245 loss: 0.00408738619
Iter: 1246 loss: 0.00408692565
Iter: 1247 loss: 0.00408689771
Iter: 1248 loss: 0.00408720784
Iter: 1249 loss: 0.00408689678
Iter: 1250 loss: 0.00408687862
Iter: 1251 loss: 0.00408694148
Iter: 1252 loss: 0.00408687256
Iter: 1253 loss: 0.004086853
Iter: 1254 loss: 0.00408685859
Iter: 1255 loss: 0.00408683717
Iter: 1256 loss: 0.00408681203
Iter: 1257 loss: 0.00408677524
Iter: 1258 loss: 0.00408677431
Iter: 1259 loss: 0.00408672728
Iter: 1260 loss: 0.00408703322
Iter: 1261 loss: 0.00408672402
Iter: 1262 loss: 0.00408668211
Iter: 1263 loss: 0.00408710912
Iter: 1264 loss: 0.00408668164
Iter: 1265 loss: 0.00408665929
Iter: 1266 loss: 0.00408661691
Iter: 1267 loss: 0.00408661831
Iter: 1268 loss: 0.00408658199
Iter: 1269 loss: 0.00408695033
Iter: 1270 loss: 0.00408658
Iter: 1271 loss: 0.00408654287
Iter: 1272 loss: 0.00408659875
Iter: 1273 loss: 0.00408652239
Iter: 1274 loss: 0.00408649258
Iter: 1275 loss: 0.00408646557
Iter: 1276 loss: 0.00408645533
Iter: 1277 loss: 0.00408641063
Iter: 1278 loss: 0.00408679945
Iter: 1279 loss: 0.0040864055
Iter: 1280 loss: 0.00408637384
Iter: 1281 loss: 0.00408665976
Iter: 1282 loss: 0.00408637477
Iter: 1283 loss: 0.00408634963
Iter: 1284 loss: 0.00408646977
Iter: 1285 loss: 0.0040863445
Iter: 1286 loss: 0.00408632169
Iter: 1287 loss: 0.00408630632
Iter: 1288 loss: 0.00408629887
Iter: 1289 loss: 0.00408626208
Iter: 1290 loss: 0.00408621226
Iter: 1291 loss: 0.00408620713
Iter: 1292 loss: 0.00408614101
Iter: 1293 loss: 0.00408637244
Iter: 1294 loss: 0.00408612564
Iter: 1295 loss: 0.00408606743
Iter: 1296 loss: 0.00408692844
Iter: 1297 loss: 0.00408607069
Iter: 1298 loss: 0.0040860381
Iter: 1299 loss: 0.00408596825
Iter: 1300 loss: 0.00408715
Iter: 1301 loss: 0.00408596918
Iter: 1302 loss: 0.00408590678
Iter: 1303 loss: 0.00408640131
Iter: 1304 loss: 0.00408590026
Iter: 1305 loss: 0.00408584159
Iter: 1306 loss: 0.00408592494
Iter: 1307 loss: 0.00408581551
Iter: 1308 loss: 0.00408574101
Iter: 1309 loss: 0.00408584718
Iter: 1310 loss: 0.00408570655
Iter: 1311 loss: 0.00408564508
Iter: 1312 loss: 0.00408636359
Iter: 1313 loss: 0.00408564135
Iter: 1314 loss: 0.00408559386
Iter: 1315 loss: 0.00408587605
Iter: 1316 loss: 0.00408559
Iter: 1317 loss: 0.00408555334
Iter: 1318 loss: 0.00408568559
Iter: 1319 loss: 0.00408554776
Iter: 1320 loss: 0.0040855133
Iter: 1321 loss: 0.00408551376
Iter: 1322 loss: 0.00408548303
Iter: 1323 loss: 0.00408542342
Iter: 1324 loss: 0.00408537034
Iter: 1325 loss: 0.0040853573
Iter: 1326 loss: 0.00408527162
Iter: 1327 loss: 0.00408575078
Iter: 1328 loss: 0.00408525765
Iter: 1329 loss: 0.00408519339
Iter: 1330 loss: 0.00408600364
Iter: 1331 loss: 0.00408519339
Iter: 1332 loss: 0.00408514962
Iter: 1333 loss: 0.00408508163
Iter: 1334 loss: 0.00408508303
Iter: 1335 loss: 0.00408501597
Iter: 1336 loss: 0.00408552
Iter: 1337 loss: 0.00408501085
Iter: 1338 loss: 0.00408495078
Iter: 1339 loss: 0.00408506254
Iter: 1340 loss: 0.00408491679
Iter: 1341 loss: 0.00408485811
Iter: 1342 loss: 0.00408488326
Iter: 1343 loss: 0.00408481481
Iter: 1344 loss: 0.00408475567
Iter: 1345 loss: 0.00408568326
Iter: 1346 loss: 0.00408475567
Iter: 1347 loss: 0.0040847091
Iter: 1348 loss: 0.00408499781
Iter: 1349 loss: 0.00408470538
Iter: 1350 loss: 0.00408467604
Iter: 1351 loss: 0.00408481807
Iter: 1352 loss: 0.00408466905
Iter: 1353 loss: 0.00408464
Iter: 1354 loss: 0.00408462714
Iter: 1355 loss: 0.00408461783
Iter: 1356 loss: 0.00408456288
Iter: 1357 loss: 0.00408454752
Iter: 1358 loss: 0.00408451864
Iter: 1359 loss: 0.00408445578
Iter: 1360 loss: 0.00408467
Iter: 1361 loss: 0.00408444181
Iter: 1362 loss: 0.00408439711
Iter: 1363 loss: 0.00408439711
Iter: 1364 loss: 0.00408436963
Iter: 1365 loss: 0.00408432074
Iter: 1366 loss: 0.00408534147
Iter: 1367 loss: 0.00408431934
Iter: 1368 loss: 0.00408426952
Iter: 1369 loss: 0.00408458756
Iter: 1370 loss: 0.00408426439
Iter: 1371 loss: 0.00408421364
Iter: 1372 loss: 0.00408424623
Iter: 1373 loss: 0.00408418477
Iter: 1374 loss: 0.00408412423
Iter: 1375 loss: 0.00408422807
Iter: 1376 loss: 0.00408409676
Iter: 1377 loss: 0.00408405066
Iter: 1378 loss: 0.0040846467
Iter: 1379 loss: 0.00408405159
Iter: 1380 loss: 0.00408401387
Iter: 1381 loss: 0.00408432912
Iter: 1382 loss: 0.0040840148
Iter: 1383 loss: 0.00408399198
Iter: 1384 loss: 0.004084046
Iter: 1385 loss: 0.004083985
Iter: 1386 loss: 0.00408395752
Iter: 1387 loss: 0.00408396125
Iter: 1388 loss: 0.0040839375
Iter: 1389 loss: 0.00408390444
Iter: 1390 loss: 0.0040838779
Iter: 1391 loss: 0.0040838616
Iter: 1392 loss: 0.00408381224
Iter: 1393 loss: 0.00408409629
Iter: 1394 loss: 0.00408380572
Iter: 1395 loss: 0.00408377312
Iter: 1396 loss: 0.00408426765
Iter: 1397 loss: 0.00408377405
Iter: 1398 loss: 0.00408374937
Iter: 1399 loss: 0.00408371631
Iter: 1400 loss: 0.00408371771
Iter: 1401 loss: 0.00408367487
Iter: 1402 loss: 0.0040838453
Iter: 1403 loss: 0.00408367068
Iter: 1404 loss: 0.00408361619
Iter: 1405 loss: 0.0040836744
Iter: 1406 loss: 0.00408358686
Iter: 1407 loss: 0.00408353563
Iter: 1408 loss: 0.00408354
Iter: 1409 loss: 0.0040834914
Iter: 1410 loss: 0.00408344157
Iter: 1411 loss: 0.00408415869
Iter: 1412 loss: 0.00408344343
Iter: 1413 loss: 0.00408340804
Iter: 1414 loss: 0.00408372562
Iter: 1415 loss: 0.00408340804
Iter: 1416 loss: 0.0040833829
Iter: 1417 loss: 0.00408346625
Iter: 1418 loss: 0.00408337591
Iter: 1419 loss: 0.00408335542
Iter: 1420 loss: 0.00408334
Iter: 1421 loss: 0.00408332841
Iter: 1422 loss: 0.00408328511
Iter: 1423 loss: 0.00408328976
Iter: 1424 loss: 0.00408324972
Iter: 1425 loss: 0.00408320501
Iter: 1426 loss: 0.00408337265
Iter: 1427 loss: 0.00408319291
Iter: 1428 loss: 0.00408316404
Iter: 1429 loss: 0.0040831631
Iter: 1430 loss: 0.00408314262
Iter: 1431 loss: 0.00408309419
Iter: 1432 loss: 0.00408364926
Iter: 1433 loss: 0.00408309279
Iter: 1434 loss: 0.00408303458
Iter: 1435 loss: 0.00408327766
Iter: 1436 loss: 0.00408302061
Iter: 1437 loss: 0.00408295356
Iter: 1438 loss: 0.00408303132
Iter: 1439 loss: 0.00408291724
Iter: 1440 loss: 0.0040828418
Iter: 1441 loss: 0.00408298848
Iter: 1442 loss: 0.00408280967
Iter: 1443 loss: 0.00408275751
Iter: 1444 loss: 0.00408344669
Iter: 1445 loss: 0.00408275612
Iter: 1446 loss: 0.00408271421
Iter: 1447 loss: 0.00408311235
Iter: 1448 loss: 0.00408271328
Iter: 1449 loss: 0.00408268906
Iter: 1450 loss: 0.00408273935
Iter: 1451 loss: 0.00408267742
Iter: 1452 loss: 0.00408264808
Iter: 1453 loss: 0.00408266
Iter: 1454 loss: 0.00408262527
Iter: 1455 loss: 0.00408257963
Iter: 1456 loss: 0.00408257451
Iter: 1457 loss: 0.00408254284
Iter: 1458 loss: 0.00408249488
Iter: 1459 loss: 0.00408271607
Iter: 1460 loss: 0.00408248464
Iter: 1461 loss: 0.00408244878
Iter: 1462 loss: 0.00408297125
Iter: 1463 loss: 0.00408244692
Iter: 1464 loss: 0.00408242457
Iter: 1465 loss: 0.00408236869
Iter: 1466 loss: 0.00408349605
Iter: 1467 loss: 0.00408236915
Iter: 1468 loss: 0.00408231048
Iter: 1469 loss: 0.00408250233
Iter: 1470 loss: 0.00408229418
Iter: 1471 loss: 0.00408221688
Iter: 1472 loss: 0.00408236962
Iter: 1473 loss: 0.00408218894
Iter: 1474 loss: 0.00408212235
Iter: 1475 loss: 0.00408217683
Iter: 1476 loss: 0.00408208836
Iter: 1477 loss: 0.00408203714
Iter: 1478 loss: 0.00408278732
Iter: 1479 loss: 0.0040820376
Iter: 1480 loss: 0.00408200035
Iter: 1481 loss: 0.0040823645
Iter: 1482 loss: 0.00408200081
Iter: 1483 loss: 0.00408197846
Iter: 1484 loss: 0.00408203295
Iter: 1485 loss: 0.00408196962
Iter: 1486 loss: 0.00408194726
Iter: 1487 loss: 0.00408193655
Iter: 1488 loss: 0.00408192305
Iter: 1489 loss: 0.00408187788
Iter: 1490 loss: 0.00408189837
Iter: 1491 loss: 0.00408185134
Iter: 1492 loss: 0.00408181
Iter: 1493 loss: 0.00408196822
Iter: 1494 loss: 0.00408179965
Iter: 1495 loss: 0.00408177171
Iter: 1496 loss: 0.00408177171
Iter: 1497 loss: 0.00408174936
Iter: 1498 loss: 0.00408171257
Iter: 1499 loss: 0.0040822858
Iter: 1500 loss: 0.00408170745
Iter: 1501 loss: 0.00408165716
Iter: 1502 loss: 0.00408183597
Iter: 1503 loss: 0.00408164505
Iter: 1504 loss: 0.00408159103
Iter: 1505 loss: 0.00408167858
Iter: 1506 loss: 0.00408156263
Iter: 1507 loss: 0.00408151094
Iter: 1508 loss: 0.00408161338
Iter: 1509 loss: 0.00408149045
Iter: 1510 loss: 0.00408145133
Iter: 1511 loss: 0.00408189744
Iter: 1512 loss: 0.0040814504
Iter: 1513 loss: 0.00408142246
Iter: 1514 loss: 0.00408176659
Iter: 1515 loss: 0.00408142246
Iter: 1516 loss: 0.00408140849
Iter: 1517 loss: 0.00408142153
Iter: 1518 loss: 0.00408139918
Iter: 1519 loss: 0.0040813759
Iter: 1520 loss: 0.00408137403
Iter: 1521 loss: 0.0040813568
Iter: 1522 loss: 0.00408131909
Iter: 1523 loss: 0.00408133
Iter: 1524 loss: 0.0040812958
Iter: 1525 loss: 0.00408126041
Iter: 1526 loss: 0.00408143457
Iter: 1527 loss: 0.00408125669
Iter: 1528 loss: 0.00408123294
Iter: 1529 loss: 0.00408123294
Iter: 1530 loss: 0.00408121757
Iter: 1531 loss: 0.00408118777
Iter: 1532 loss: 0.00408118963
Iter: 1533 loss: 0.00408115704
Iter: 1534 loss: 0.0040812511
Iter: 1535 loss: 0.00408114633
Iter: 1536 loss: 0.00408110674
Iter: 1537 loss: 0.00408117659
Iter: 1538 loss: 0.00408108858
Iter: 1539 loss: 0.00408105273
Iter: 1540 loss: 0.00408108486
Iter: 1541 loss: 0.00408102851
Iter: 1542 loss: 0.00408099871
Iter: 1543 loss: 0.00408140291
Iter: 1544 loss: 0.00408099592
Iter: 1545 loss: 0.00408097
Iter: 1546 loss: 0.00408125576
Iter: 1547 loss: 0.0040809745
Iter: 1548 loss: 0.0040809596
Iter: 1549 loss: 0.00408097496
Iter: 1550 loss: 0.00408095075
Iter: 1551 loss: 0.004080927
Iter: 1552 loss: 0.00408091862
Iter: 1553 loss: 0.0040809093
Iter: 1554 loss: 0.0040808795
Iter: 1555 loss: 0.00408089114
Iter: 1556 loss: 0.00408085762
Iter: 1557 loss: 0.00408082828
Iter: 1558 loss: 0.00408091862
Iter: 1559 loss: 0.00408082176
Iter: 1560 loss: 0.00408080313
Iter: 1561 loss: 0.0040808036
Iter: 1562 loss: 0.00408079103
Iter: 1563 loss: 0.00408076588
Iter: 1564 loss: 0.00408118591
Iter: 1565 loss: 0.00408076588
Iter: 1566 loss: 0.00408073049
Iter: 1567 loss: 0.00408084597
Iter: 1568 loss: 0.00408072211
Iter: 1569 loss: 0.00408068299
Iter: 1570 loss: 0.00408076029
Iter: 1571 loss: 0.00408066763
Iter: 1572 loss: 0.00408063177
Iter: 1573 loss: 0.0040806625
Iter: 1574 loss: 0.00408061128
Iter: 1575 loss: 0.00408057077
Iter: 1576 loss: 0.00408081198
Iter: 1577 loss: 0.00408056937
Iter: 1578 loss: 0.00408053538
Iter: 1579 loss: 0.00408098288
Iter: 1580 loss: 0.00408053584
Iter: 1581 loss: 0.00408051861
Iter: 1582 loss: 0.00408053678
Iter: 1583 loss: 0.00408050837
Iter: 1584 loss: 0.00408047903
Iter: 1585 loss: 0.00408049393
Iter: 1586 loss: 0.00408046227
Iter: 1587 loss: 0.00408042781
Iter: 1588 loss: 0.00408044085
Iter: 1589 loss: 0.0040804008
Iter: 1590 loss: 0.00408036914
Iter: 1591 loss: 0.00408051256
Iter: 1592 loss: 0.00408036076
Iter: 1593 loss: 0.00408033887
Iter: 1594 loss: 0.00408068
Iter: 1595 loss: 0.00408033701
Iter: 1596 loss: 0.00408031698
Iter: 1597 loss: 0.004080276
Iter: 1598 loss: 0.00408107322
Iter: 1599 loss: 0.00408027787
Iter: 1600 loss: 0.00408023
Iter: 1601 loss: 0.00408035051
Iter: 1602 loss: 0.00408021268
Iter: 1603 loss: 0.00408015028
Iter: 1604 loss: 0.00408033887
Iter: 1605 loss: 0.00408013025
Iter: 1606 loss: 0.00408008415
Iter: 1607 loss: 0.00408006366
Iter: 1608 loss: 0.00408003945
Iter: 1609 loss: 0.00407996867
Iter: 1610 loss: 0.00408050511
Iter: 1611 loss: 0.00407996727
Iter: 1612 loss: 0.00407992024
Iter: 1613 loss: 0.0040806313
Iter: 1614 loss: 0.00407992024
Iter: 1615 loss: 0.00407989603
Iter: 1616 loss: 0.00407993793
Iter: 1617 loss: 0.00407988299
Iter: 1618 loss: 0.00407984573
Iter: 1619 loss: 0.00407984899
Iter: 1620 loss: 0.00407981873
Iter: 1621 loss: 0.00407977
Iter: 1622 loss: 0.00407979125
Iter: 1623 loss: 0.0040797363
Iter: 1624 loss: 0.00407968834
Iter: 1625 loss: 0.00407982897
Iter: 1626 loss: 0.0040796739
Iter: 1627 loss: 0.00407964038
Iter: 1628 loss: 0.00407963758
Iter: 1629 loss: 0.00407961197
Iter: 1630 loss: 0.00407955516
Iter: 1631 loss: 0.00408066902
Iter: 1632 loss: 0.00407955609
Iter: 1633 loss: 0.00407949369
Iter: 1634 loss: 0.00407964829
Iter: 1635 loss: 0.00407947414
Iter: 1636 loss: 0.00407940429
Iter: 1637 loss: 0.00407966599
Iter: 1638 loss: 0.0040793838
Iter: 1639 loss: 0.00407933118
Iter: 1640 loss: 0.0040793824
Iter: 1641 loss: 0.0040793
Iter: 1642 loss: 0.00407924689
Iter: 1643 loss: 0.00407977495
Iter: 1644 loss: 0.00407924596
Iter: 1645 loss: 0.00407920964
Iter: 1646 loss: 0.00407921057
Iter: 1647 loss: 0.00407919101
Iter: 1648 loss: 0.00407921104
Iter: 1649 loss: 0.00407918077
Iter: 1650 loss: 0.00407915097
Iter: 1651 loss: 0.00407916959
Iter: 1652 loss: 0.00407913141
Iter: 1653 loss: 0.00407909509
Iter: 1654 loss: 0.00407912303
Iter: 1655 loss: 0.00407907134
Iter: 1656 loss: 0.00407903595
Iter: 1657 loss: 0.00407910813
Iter: 1658 loss: 0.00407902431
Iter: 1659 loss: 0.00407900196
Iter: 1660 loss: 0.00407900056
Iter: 1661 loss: 0.00407898054
Iter: 1662 loss: 0.00407894468
Iter: 1663 loss: 0.00407894515
Iter: 1664 loss: 0.00407890417
Iter: 1665 loss: 0.00407903874
Iter: 1666 loss: 0.00407889392
Iter: 1667 loss: 0.00407885388
Iter: 1668 loss: 0.00407903967
Iter: 1669 loss: 0.00407884456
Iter: 1670 loss: 0.00407881802
Iter: 1671 loss: 0.00407881616
Iter: 1672 loss: 0.00407879706
Iter: 1673 loss: 0.00407876726
Iter: 1674 loss: 0.00407896563
Iter: 1675 loss: 0.00407876587
Iter: 1676 loss: 0.00407874351
Iter: 1677 loss: 0.00407874398
Iter: 1678 loss: 0.00407872908
Iter: 1679 loss: 0.00407873839
Iter: 1680 loss: 0.00407872349
Iter: 1681 loss: 0.00407869974
Iter: 1682 loss: 0.00407870673
Iter: 1683 loss: 0.00407868577
Iter: 1684 loss: 0.0040786583
Iter: 1685 loss: 0.00407869648
Iter: 1686 loss: 0.00407864572
Iter: 1687 loss: 0.00407862244
Iter: 1688 loss: 0.00407869043
Iter: 1689 loss: 0.0040786122
Iter: 1690 loss: 0.0040785973
Iter: 1691 loss: 0.00407859683
Iter: 1692 loss: 0.00407858379
Iter: 1693 loss: 0.00407855771
Iter: 1694 loss: 0.00407919753
Iter: 1695 loss: 0.00407855585
Iter: 1696 loss: 0.00407852698
Iter: 1697 loss: 0.00407861825
Iter: 1698 loss: 0.00407852279
Iter: 1699 loss: 0.00407849252
Iter: 1700 loss: 0.00407864433
Iter: 1701 loss: 0.00407848833
Iter: 1702 loss: 0.00407846924
Iter: 1703 loss: 0.00407846086
Iter: 1704 loss: 0.00407845
Iter: 1705 loss: 0.00407841895
Iter: 1706 loss: 0.00407859404
Iter: 1707 loss: 0.00407841615
Iter: 1708 loss: 0.00407839473
Iter: 1709 loss: 0.0040783938
Iter: 1710 loss: 0.00407837797
Iter: 1711 loss: 0.00407838728
Iter: 1712 loss: 0.00407837145
Iter: 1713 loss: 0.00407835096
Iter: 1714 loss: 0.004078364
Iter: 1715 loss: 0.00407833653
Iter: 1716 loss: 0.00407831138
Iter: 1717 loss: 0.00407834584
Iter: 1718 loss: 0.00407829741
Iter: 1719 loss: 0.00407827646
Iter: 1720 loss: 0.00407829601
Iter: 1721 loss: 0.00407826528
Iter: 1722 loss: 0.00407824572
Iter: 1723 loss: 0.00407824572
Iter: 1724 loss: 0.00407822942
Iter: 1725 loss: 0.00407820614
Iter: 1726 loss: 0.00407820288
Iter: 1727 loss: 0.0040781768
Iter: 1728 loss: 0.00407825597
Iter: 1729 loss: 0.00407817
Iter: 1730 loss: 0.00407814048
Iter: 1731 loss: 0.00407825969
Iter: 1732 loss: 0.00407813303
Iter: 1733 loss: 0.00407811254
Iter: 1734 loss: 0.00407810789
Iter: 1735 loss: 0.00407808973
Iter: 1736 loss: 0.00407805806
Iter: 1737 loss: 0.00407820055
Iter: 1738 loss: 0.00407805573
Iter: 1739 loss: 0.00407803245
Iter: 1740 loss: 0.00407803338
Iter: 1741 loss: 0.00407802174
Iter: 1742 loss: 0.00407802779
Iter: 1743 loss: 0.00407801103
Iter: 1744 loss: 0.00407798868
Iter: 1745 loss: 0.00407801475
Iter: 1746 loss: 0.00407797657
Iter: 1747 loss: 0.00407795096
Iter: 1748 loss: 0.00407797704
Iter: 1749 loss: 0.00407793839
Iter: 1750 loss: 0.0040779151
Iter: 1751 loss: 0.00407794164
Iter: 1752 loss: 0.00407790579
Iter: 1753 loss: 0.00407788623
Iter: 1754 loss: 0.0040778853
Iter: 1755 loss: 0.00407786854
Iter: 1756 loss: 0.00407784525
Iter: 1757 loss: 0.00407784525
Iter: 1758 loss: 0.00407781452
Iter: 1759 loss: 0.00407786
Iter: 1760 loss: 0.00407780334
Iter: 1761 loss: 0.00407777075
Iter: 1762 loss: 0.00407798495
Iter: 1763 loss: 0.00407776562
Iter: 1764 loss: 0.00407774188
Iter: 1765 loss: 0.00407775817
Iter: 1766 loss: 0.00407772884
Iter: 1767 loss: 0.00407770369
Iter: 1768 loss: 0.00407791231
Iter: 1769 loss: 0.0040777009
Iter: 1770 loss: 0.00407768693
Iter: 1771 loss: 0.00407791184
Iter: 1772 loss: 0.00407768413
Iter: 1773 loss: 0.00407767249
Iter: 1774 loss: 0.00407767808
Iter: 1775 loss: 0.00407766597
Iter: 1776 loss: 0.00407764316
Iter: 1777 loss: 0.00407766784
Iter: 1778 loss: 0.00407763477
Iter: 1779 loss: 0.00407761149
Iter: 1780 loss: 0.00407764548
Iter: 1781 loss: 0.00407760171
Iter: 1782 loss: 0.00407758309
Iter: 1783 loss: 0.00407758635
Iter: 1784 loss: 0.00407756632
Iter: 1785 loss: 0.0040775477
Iter: 1786 loss: 0.00407754583
Iter: 1787 loss: 0.0040775314
Iter: 1788 loss: 0.0040775016
Iter: 1789 loss: 0.00407750066
Iter: 1790 loss: 0.00407747
Iter: 1791 loss: 0.00407756912
Iter: 1792 loss: 0.00407745969
Iter: 1793 loss: 0.00407743035
Iter: 1794 loss: 0.00407764222
Iter: 1795 loss: 0.00407742662
Iter: 1796 loss: 0.00407741
Iter: 1797 loss: 0.00407741731
Iter: 1798 loss: 0.00407739542
Iter: 1799 loss: 0.00407737819
Iter: 1800 loss: 0.00407744246
Iter: 1801 loss: 0.00407737
Iter: 1802 loss: 0.00407735258
Iter: 1803 loss: 0.00407764502
Iter: 1804 loss: 0.00407734932
Iter: 1805 loss: 0.00407733861
Iter: 1806 loss: 0.00407733535
Iter: 1807 loss: 0.00407732651
Iter: 1808 loss: 0.0040773009
Iter: 1809 loss: 0.004077347
Iter: 1810 loss: 0.00407729205
Iter: 1811 loss: 0.00407726411
Iter: 1812 loss: 0.0040772846
Iter: 1813 loss: 0.00407725107
Iter: 1814 loss: 0.00407722406
Iter: 1815 loss: 0.00407723757
Iter: 1816 loss: 0.00407720869
Iter: 1817 loss: 0.00407718448
Iter: 1818 loss: 0.00407746062
Iter: 1819 loss: 0.00407717936
Iter: 1820 loss: 0.00407715328
Iter: 1821 loss: 0.00407712674
Iter: 1822 loss: 0.00407712
Iter: 1823 loss: 0.00407708343
Iter: 1824 loss: 0.00407715328
Iter: 1825 loss: 0.004077069
Iter: 1826 loss: 0.00407702755
Iter: 1827 loss: 0.00407743221
Iter: 1828 loss: 0.00407702802
Iter: 1829 loss: 0.00407700427
Iter: 1830 loss: 0.00407697912
Iter: 1831 loss: 0.00407697493
Iter: 1832 loss: 0.00407693535
Iter: 1833 loss: 0.0040771924
Iter: 1834 loss: 0.00407693302
Iter: 1835 loss: 0.00407690648
Iter: 1836 loss: 0.00407717098
Iter: 1837 loss: 0.00407690462
Iter: 1838 loss: 0.00407688273
Iter: 1839 loss: 0.00407690555
Iter: 1840 loss: 0.0040768683
Iter: 1841 loss: 0.00407683477
Iter: 1842 loss: 0.00407689065
Iter: 1843 loss: 0.00407682406
Iter: 1844 loss: 0.00407678774
Iter: 1845 loss: 0.00407683663
Iter: 1846 loss: 0.00407677144
Iter: 1847 loss: 0.00407674536
Iter: 1848 loss: 0.00407675141
Iter: 1849 loss: 0.00407672115
Iter: 1850 loss: 0.004076696
Iter: 1851 loss: 0.00407716539
Iter: 1852 loss: 0.00407669786
Iter: 1853 loss: 0.00407666946
Iter: 1854 loss: 0.00407663547
Iter: 1855 loss: 0.00407662895
Iter: 1856 loss: 0.00407659076
Iter: 1857 loss: 0.00407665316
Iter: 1858 loss: 0.00407656794
Iter: 1859 loss: 0.00407652929
Iter: 1860 loss: 0.00407682033
Iter: 1861 loss: 0.0040765265
Iter: 1862 loss: 0.00407649204
Iter: 1863 loss: 0.00407653674
Iter: 1864 loss: 0.004076479
Iter: 1865 loss: 0.0040764492
Iter: 1866 loss: 0.00407670252
Iter: 1867 loss: 0.00407644734
Iter: 1868 loss: 0.00407642871
Iter: 1869 loss: 0.00407664897
Iter: 1870 loss: 0.00407642964
Iter: 1871 loss: 0.00407641474
Iter: 1872 loss: 0.00407641567
Iter: 1873 loss: 0.00407640496
Iter: 1874 loss: 0.00407638215
Iter: 1875 loss: 0.00407644641
Iter: 1876 loss: 0.00407637516
Iter: 1877 loss: 0.004076357
Iter: 1878 loss: 0.00407638494
Iter: 1879 loss: 0.00407634443
Iter: 1880 loss: 0.0040763272
Iter: 1881 loss: 0.00407633
Iter: 1882 loss: 0.00407631695
Iter: 1883 loss: 0.00407629181
Iter: 1884 loss: 0.00407653488
Iter: 1885 loss: 0.00407629088
Iter: 1886 loss: 0.00407626946
Iter: 1887 loss: 0.00407624664
Iter: 1888 loss: 0.00407624291
Iter: 1889 loss: 0.00407621218
Iter: 1890 loss: 0.00407625549
Iter: 1891 loss: 0.00407619681
Iter: 1892 loss: 0.00407616748
Iter: 1893 loss: 0.00407642266
Iter: 1894 loss: 0.00407616515
Iter: 1895 loss: 0.00407614885
Iter: 1896 loss: 0.00407614838
Iter: 1897 loss: 0.00407613162
Iter: 1898 loss: 0.00407611346
Iter: 1899 loss: 0.00407633698
Iter: 1900 loss: 0.00407611253
Iter: 1901 loss: 0.00407609949
Iter: 1902 loss: 0.00407631416
Iter: 1903 loss: 0.00407609763
Iter: 1904 loss: 0.00407608971
Iter: 1905 loss: 0.00407609483
Iter: 1906 loss: 0.00407608226
Iter: 1907 loss: 0.00407607062
Iter: 1908 loss: 0.00407609809
Iter: 1909 loss: 0.00407606456
Iter: 1910 loss: 0.00407604827
Iter: 1911 loss: 0.00407606456
Iter: 1912 loss: 0.00407604128
Iter: 1913 loss: 0.00407602452
Iter: 1914 loss: 0.0040760166
Iter: 1915 loss: 0.00407601288
Iter: 1916 loss: 0.0040759882
Iter: 1917 loss: 0.004076262
Iter: 1918 loss: 0.00407598633
Iter: 1919 loss: 0.00407596491
Iter: 1920 loss: 0.00407595048
Iter: 1921 loss: 0.00407593977
Iter: 1922 loss: 0.00407591928
Iter: 1923 loss: 0.00407594955
Iter: 1924 loss: 0.00407590065
Iter: 1925 loss: 0.00407587737
Iter: 1926 loss: 0.00407598773
Iter: 1927 loss: 0.00407587178
Iter: 1928 loss: 0.00407585315
Iter: 1929 loss: 0.00407583779
Iter: 1930 loss: 0.00407583173
Iter: 1931 loss: 0.00407579821
Iter: 1932 loss: 0.00407606969
Iter: 1933 loss: 0.00407579774
Iter: 1934 loss: 0.00407577306
Iter: 1935 loss: 0.00407577306
Iter: 1936 loss: 0.00407576095
Iter: 1937 loss: 0.00407575816
Iter: 1938 loss: 0.00407575443
Iter: 1939 loss: 0.00407573301
Iter: 1940 loss: 0.00407579867
Iter: 1941 loss: 0.00407572929
Iter: 1942 loss: 0.00407571159
Iter: 1943 loss: 0.00407571904
Iter: 1944 loss: 0.00407569436
Iter: 1945 loss: 0.00407567294
Iter: 1946 loss: 0.00407568
Iter: 1947 loss: 0.00407565571
Iter: 1948 loss: 0.00407563057
Iter: 1949 loss: 0.00407589506
Iter: 1950 loss: 0.00407563243
Iter: 1951 loss: 0.00407560263
Iter: 1952 loss: 0.00407562312
Iter: 1953 loss: 0.00407558959
Iter: 1954 loss: 0.0040755691
Iter: 1955 loss: 0.0040755691
Iter: 1956 loss: 0.00407555513
Iter: 1957 loss: 0.00407552207
Iter: 1958 loss: 0.00407562871
Iter: 1959 loss: 0.00407551508
Iter: 1960 loss: 0.00407548295
Iter: 1961 loss: 0.00407544896
Iter: 1962 loss: 0.00407544198
Iter: 1963 loss: 0.00407538516
Iter: 1964 loss: 0.00407560216
Iter: 1965 loss: 0.00407537445
Iter: 1966 loss: 0.00407534186
Iter: 1967 loss: 0.00407533254
Iter: 1968 loss: 0.00407531392
Iter: 1969 loss: 0.00407529715
Iter: 1970 loss: 0.00407529343
Iter: 1971 loss: 0.00407525385
Iter: 1972 loss: 0.00407541
Iter: 1973 loss: 0.00407524779
Iter: 1974 loss: 0.00407521799
Iter: 1975 loss: 0.00407523941
Iter: 1976 loss: 0.0040752003
Iter: 1977 loss: 0.00407517422
Iter: 1978 loss: 0.00407519098
Iter: 1979 loss: 0.00407514954
Iter: 1980 loss: 0.00407512207
Iter: 1981 loss: 0.00407553837
Iter: 1982 loss: 0.00407512346
Iter: 1983 loss: 0.00407509319
Iter: 1984 loss: 0.00407512
Iter: 1985 loss: 0.0040750769
Iter: 1986 loss: 0.00407505454
Iter: 1987 loss: 0.00407505035
Iter: 1988 loss: 0.00407503592
Iter: 1989 loss: 0.004075
Iter: 1990 loss: 0.00407506619
Iter: 1991 loss: 0.00407498237
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3
+ date
Tue Oct 27 17:43:34 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 2 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943e81730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ee2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ee2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ee29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943d77598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943d776a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943d5cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943d1f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943cb1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ccaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943c817b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943c93e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943c3b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943c47c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943c19950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943bb7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943bc7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943bdac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ba0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ba0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943b5a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943b469d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ad2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943ba0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943acd488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943aa9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943a67950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943a07840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943a08840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943a08bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f19439dda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943996400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1943996488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f19439961e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f194393d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f194390bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0299817305
Iter: 2 loss: 1.12726963
Iter: 3 loss: 1.08745277
Iter: 4 loss: 0.705161572
Iter: 5 loss: 0.672171116
Iter: 6 loss: 0.428398252
Iter: 7 loss: 0.398770094
Iter: 8 loss: 0.239079714
Iter: 9 loss: 0.211605981
Iter: 10 loss: 0.113333881
Iter: 11 loss: 0.0928621739
Iter: 12 loss: 0.0432784744
Iter: 13 loss: 0.0337654054
Iter: 14 loss: 0.0173723437
Iter: 15 loss: 0.0161706489
Iter: 16 loss: 0.0152006838
Iter: 17 loss: 0.0136775039
Iter: 18 loss: 0.0135938926
Iter: 19 loss: 0.0125697087
Iter: 20 loss: 0.0115555376
Iter: 21 loss: 0.0112381326
Iter: 22 loss: 0.00874015223
Iter: 23 loss: 0.0177702624
Iter: 24 loss: 0.0086288061
Iter: 25 loss: 0.00806092098
Iter: 26 loss: 0.00948507339
Iter: 27 loss: 0.00779866753
Iter: 28 loss: 0.00743689155
Iter: 29 loss: 0.00776900537
Iter: 30 loss: 0.00722562056
Iter: 31 loss: 0.00668550748
Iter: 32 loss: 0.00777434884
Iter: 33 loss: 0.00652987091
Iter: 34 loss: 0.00630564941
Iter: 35 loss: 0.00609098747
Iter: 36 loss: 0.0060394872
Iter: 37 loss: 0.00576835172
Iter: 38 loss: 0.00609602686
Iter: 39 loss: 0.00562327076
Iter: 40 loss: 0.00542100286
Iter: 41 loss: 0.00640925858
Iter: 42 loss: 0.00539321778
Iter: 43 loss: 0.0052856328
Iter: 44 loss: 0.00586299319
Iter: 45 loss: 0.005269574
Iter: 46 loss: 0.00520547479
Iter: 47 loss: 0.0052429866
Iter: 48 loss: 0.00516270939
Iter: 49 loss: 0.00511314627
Iter: 50 loss: 0.00509273866
Iter: 51 loss: 0.00506788911
Iter: 52 loss: 0.0050329091
Iter: 53 loss: 0.00499998964
Iter: 54 loss: 0.00499161799
Iter: 55 loss: 0.00493575307
Iter: 56 loss: 0.00501146959
Iter: 57 loss: 0.00490897708
Iter: 58 loss: 0.00486619212
Iter: 59 loss: 0.00509879
Iter: 60 loss: 0.00485964352
Iter: 61 loss: 0.00483850669
Iter: 62 loss: 0.00483611692
Iter: 63 loss: 0.00481984671
Iter: 64 loss: 0.00482547656
Iter: 65 loss: 0.00480827549
Iter: 66 loss: 0.00479205512
Iter: 67 loss: 0.00478224503
Iter: 68 loss: 0.00477572391
Iter: 69 loss: 0.00475990726
Iter: 70 loss: 0.0048097875
Iter: 71 loss: 0.0047553163
Iter: 72 loss: 0.0047381008
Iter: 73 loss: 0.00473881466
Iter: 74 loss: 0.00472460687
Iter: 75 loss: 0.00470414665
Iter: 76 loss: 0.00486670621
Iter: 77 loss: 0.00470276596
Iter: 78 loss: 0.00468893303
Iter: 79 loss: 0.00471802056
Iter: 80 loss: 0.00468347222
Iter: 81 loss: 0.0046704663
Iter: 82 loss: 0.00471788319
Iter: 83 loss: 0.00466721971
Iter: 84 loss: 0.00466095656
Iter: 85 loss: 0.00466042478
Iter: 86 loss: 0.00465489458
Iter: 87 loss: 0.0046677338
Iter: 88 loss: 0.00465279538
Iter: 89 loss: 0.00464624073
Iter: 90 loss: 0.00465183333
Iter: 91 loss: 0.00464238133
Iter: 92 loss: 0.00463817455
Iter: 93 loss: 0.00470743515
Iter: 94 loss: 0.00463817362
Iter: 95 loss: 0.00463416241
Iter: 96 loss: 0.00464753481
Iter: 97 loss: 0.0046330886
Iter: 98 loss: 0.00462998264
Iter: 99 loss: 0.00462945737
Iter: 100 loss: 0.00462732324
Iter: 101 loss: 0.0046238103
Iter: 102 loss: 0.00461886
Iter: 103 loss: 0.00461867824
Iter: 104 loss: 0.00461307727
Iter: 105 loss: 0.0046598413
Iter: 106 loss: 0.00461273734
Iter: 107 loss: 0.00460865814
Iter: 108 loss: 0.00461407937
Iter: 109 loss: 0.00460660551
Iter: 110 loss: 0.00460271351
Iter: 111 loss: 0.00462573487
Iter: 112 loss: 0.00460222317
Iter: 113 loss: 0.00459869765
Iter: 114 loss: 0.0046046013
Iter: 115 loss: 0.00459711067
Iter: 116 loss: 0.00459407177
Iter: 117 loss: 0.00460885232
Iter: 118 loss: 0.00459353
Iter: 119 loss: 0.00459150225
Iter: 120 loss: 0.00459148083
Iter: 121 loss: 0.00459021563
Iter: 122 loss: 0.00458928943
Iter: 123 loss: 0.00458885822
Iter: 124 loss: 0.00458741
Iter: 125 loss: 0.00459534302
Iter: 126 loss: 0.00458720699
Iter: 127 loss: 0.00458572246
Iter: 128 loss: 0.00459087174
Iter: 129 loss: 0.00458532572
Iter: 130 loss: 0.00458409917
Iter: 131 loss: 0.00458606891
Iter: 132 loss: 0.00458353478
Iter: 133 loss: 0.00458238367
Iter: 134 loss: 0.00458112732
Iter: 135 loss: 0.00458093733
Iter: 136 loss: 0.0045791897
Iter: 137 loss: 0.00458307937
Iter: 138 loss: 0.00457852706
Iter: 139 loss: 0.00457674
Iter: 140 loss: 0.00458569452
Iter: 141 loss: 0.00457643671
Iter: 142 loss: 0.00457487116
Iter: 143 loss: 0.00457462762
Iter: 144 loss: 0.00457353797
Iter: 145 loss: 0.00457099918
Iter: 146 loss: 0.0045847781
Iter: 147 loss: 0.00457061734
Iter: 148 loss: 0.00456888322
Iter: 149 loss: 0.00457244925
Iter: 150 loss: 0.00456818705
Iter: 151 loss: 0.00456681289
Iter: 152 loss: 0.00456678122
Iter: 153 loss: 0.00456582103
Iter: 154 loss: 0.00456603197
Iter: 155 loss: 0.00456511416
Iter: 156 loss: 0.00456414837
Iter: 157 loss: 0.00456861127
Iter: 158 loss: 0.00456396118
Iter: 159 loss: 0.00456297724
Iter: 160 loss: 0.00456828577
Iter: 161 loss: 0.00456283148
Iter: 162 loss: 0.00456196675
Iter: 163 loss: 0.00456205197
Iter: 164 loss: 0.00456129573
Iter: 165 loss: 0.00456018
Iter: 166 loss: 0.00455959793
Iter: 167 loss: 0.0045590871
Iter: 168 loss: 0.00455768127
Iter: 169 loss: 0.00455929385
Iter: 170 loss: 0.00455692597
Iter: 171 loss: 0.0045553674
Iter: 172 loss: 0.00456244778
Iter: 173 loss: 0.00455506518
Iter: 174 loss: 0.00455366075
Iter: 175 loss: 0.00455678487
Iter: 176 loss: 0.00455312757
Iter: 177 loss: 0.00455177622
Iter: 178 loss: 0.00455966406
Iter: 179 loss: 0.00455159554
Iter: 180 loss: 0.0045504719
Iter: 181 loss: 0.00455222838
Iter: 182 loss: 0.00454994198
Iter: 183 loss: 0.00454928679
Iter: 184 loss: 0.00454923045
Iter: 185 loss: 0.0045486046
Iter: 186 loss: 0.00454870332
Iter: 187 loss: 0.00454812963
Iter: 188 loss: 0.00454746326
Iter: 189 loss: 0.00454863627
Iter: 190 loss: 0.00454717036
Iter: 191 loss: 0.00454643741
Iter: 192 loss: 0.00455275318
Iter: 193 loss: 0.00454639317
Iter: 194 loss: 0.00454588514
Iter: 195 loss: 0.00454619108
Iter: 196 loss: 0.00454555824
Iter: 197 loss: 0.00454494823
Iter: 198 loss: 0.00454481598
Iter: 199 loss: 0.00454442
Iter: 200 loss: 0.0045436332
Iter: 201 loss: 0.00454553496
Iter: 202 loss: 0.00454335101
Iter: 203 loss: 0.00454265159
Iter: 204 loss: 0.00454290165
Iter: 205 loss: 0.00454215799
Iter: 206 loss: 0.00454119546
Iter: 207 loss: 0.004546321
Iter: 208 loss: 0.00454104505
Iter: 209 loss: 0.00454027858
Iter: 210 loss: 0.00454382552
Iter: 211 loss: 0.00454013329
Iter: 212 loss: 0.00453948043
Iter: 213 loss: 0.00454047415
Iter: 214 loss: 0.00453917217
Iter: 215 loss: 0.00453856867
Iter: 216 loss: 0.00454643602
Iter: 217 loss: 0.00453856587
Iter: 218 loss: 0.00453803176
Iter: 219 loss: 0.00454012072
Iter: 220 loss: 0.00453790929
Iter: 221 loss: 0.00453757588
Iter: 222 loss: 0.00453786971
Iter: 223 loss: 0.00453738123
Iter: 224 loss: 0.00453696959
Iter: 225 loss: 0.00454041036
Iter: 226 loss: 0.00453694817
Iter: 227 loss: 0.00453663385
Iter: 228 loss: 0.00453679217
Iter: 229 loss: 0.00453642569
Iter: 230 loss: 0.00453604851
Iter: 231 loss: 0.00453592371
Iter: 232 loss: 0.00453570718
Iter: 233 loss: 0.00453522243
Iter: 234 loss: 0.00453668088
Iter: 235 loss: 0.004535079
Iter: 236 loss: 0.0045346003
Iter: 237 loss: 0.00453417795
Iter: 238 loss: 0.00453405362
Iter: 239 loss: 0.00453338
Iter: 240 loss: 0.00454055704
Iter: 241 loss: 0.00453336257
Iter: 242 loss: 0.00453284197
Iter: 243 loss: 0.00453378167
Iter: 244 loss: 0.00453261752
Iter: 245 loss: 0.00453203265
Iter: 246 loss: 0.0045335535
Iter: 247 loss: 0.00453183521
Iter: 248 loss: 0.00453134719
Iter: 249 loss: 0.00453573233
Iter: 250 loss: 0.00453132577
Iter: 251 loss: 0.00453088805
Iter: 252 loss: 0.00453363499
Iter: 253 loss: 0.00453083497
Iter: 254 loss: 0.00453058258
Iter: 255 loss: 0.00453041866
Iter: 256 loss: 0.00453031948
Iter: 257 loss: 0.00452997815
Iter: 258 loss: 0.00452997629
Iter: 259 loss: 0.00452973833
Iter: 260 loss: 0.00452980632
Iter: 261 loss: 0.0045295665
Iter: 262 loss: 0.00452926
Iter: 263 loss: 0.00452908315
Iter: 264 loss: 0.00452895276
Iter: 265 loss: 0.00452851038
Iter: 266 loss: 0.00452921353
Iter: 267 loss: 0.00452830503
Iter: 268 loss: 0.00452781282
Iter: 269 loss: 0.00452833
Iter: 270 loss: 0.00452754088
Iter: 271 loss: 0.00452705333
Iter: 272 loss: 0.00452942122
Iter: 273 loss: 0.00452696439
Iter: 274 loss: 0.00452650525
Iter: 275 loss: 0.00452787708
Iter: 276 loss: 0.00452636601
Iter: 277 loss: 0.00452591851
Iter: 278 loss: 0.00452729082
Iter: 279 loss: 0.00452578533
Iter: 280 loss: 0.00452537043
Iter: 281 loss: 0.00452701421
Iter: 282 loss: 0.00452527776
Iter: 283 loss: 0.0045248894
Iter: 284 loss: 0.00452995
Iter: 285 loss: 0.0045248894
Iter: 286 loss: 0.00452467892
Iter: 287 loss: 0.00452461513
Iter: 288 loss: 0.00452448893
Iter: 289 loss: 0.00452428684
Iter: 290 loss: 0.00452746078
Iter: 291 loss: 0.00452428777
Iter: 292 loss: 0.00452411734
Iter: 293 loss: 0.00452402513
Iter: 294 loss: 0.0045239497
Iter: 295 loss: 0.00452368101
Iter: 296 loss: 0.00452399533
Iter: 297 loss: 0.00452354318
Iter: 298 loss: 0.00452326052
Iter: 299 loss: 0.00452338811
Iter: 300 loss: 0.00452307286
Iter: 301 loss: 0.00452275854
Iter: 302 loss: 0.00452370103
Iter: 303 loss: 0.0045226668
Iter: 304 loss: 0.00452236971
Iter: 305 loss: 0.00452274643
Iter: 306 loss: 0.00452221651
Iter: 307 loss: 0.00452188682
Iter: 308 loss: 0.00452341326
Iter: 309 loss: 0.00452182582
Iter: 310 loss: 0.00452150265
Iter: 311 loss: 0.00452237763
Iter: 312 loss: 0.00452139694
Iter: 313 loss: 0.0045211073
Iter: 314 loss: 0.00452205352
Iter: 315 loss: 0.00452102534
Iter: 316 loss: 0.00452082511
Iter: 317 loss: 0.00452081673
Iter: 318 loss: 0.00452069798
Iter: 319 loss: 0.00452060672
Iter: 320 loss: 0.004520569
Iter: 321 loss: 0.00452041905
Iter: 322 loss: 0.00452198414
Iter: 323 loss: 0.00452042
Iter: 324 loss: 0.00452027656
Iter: 325 loss: 0.00452031102
Iter: 326 loss: 0.00452017132
Iter: 327 loss: 0.00452002045
Iter: 328 loss: 0.00452022068
Iter: 329 loss: 0.00451994408
Iter: 330 loss: 0.00451977132
Iter: 331 loss: 0.00451966189
Iter: 332 loss: 0.00451959111
Iter: 333 loss: 0.00451935641
Iter: 334 loss: 0.00452075293
Iter: 335 loss: 0.00451932847
Iter: 336 loss: 0.00451914594
Iter: 337 loss: 0.00451914687
Iter: 338 loss: 0.00451900251
Iter: 339 loss: 0.00451876782
Iter: 340 loss: 0.0045203683
Iter: 341 loss: 0.00451874733
Iter: 342 loss: 0.00451855734
Iter: 343 loss: 0.00451915246
Iter: 344 loss: 0.00451849913
Iter: 345 loss: 0.00451832311
Iter: 346 loss: 0.00451874267
Iter: 347 loss: 0.00451825745
Iter: 348 loss: 0.00451817177
Iter: 349 loss: 0.00451815082
Iter: 350 loss: 0.00451807771
Iter: 351 loss: 0.004518
Iter: 352 loss: 0.00451798365
Iter: 353 loss: 0.00451788958
Iter: 354 loss: 0.00451870356
Iter: 355 loss: 0.00451788586
Iter: 356 loss: 0.00451778527
Iter: 357 loss: 0.00451789098
Iter: 358 loss: 0.00451772846
Iter: 359 loss: 0.00451762835
Iter: 360 loss: 0.00451763533
Iter: 361 loss: 0.00451755337
Iter: 362 loss: 0.00451741135
Iter: 363 loss: 0.00451754034
Iter: 364 loss: 0.00451733
Iter: 365 loss: 0.00451719249
Iter: 366 loss: 0.00451757666
Iter: 367 loss: 0.00451714639
Iter: 368 loss: 0.00451701414
Iter: 369 loss: 0.0045172032
Iter: 370 loss: 0.00451694801
Iter: 371 loss: 0.00451679947
Iter: 372 loss: 0.00451737735
Iter: 373 loss: 0.00451676641
Iter: 374 loss: 0.00451663975
Iter: 375 loss: 0.00451718085
Iter: 376 loss: 0.00451661507
Iter: 377 loss: 0.00451648561
Iter: 378 loss: 0.00451663043
Iter: 379 loss: 0.00451641623
Iter: 380 loss: 0.00451639155
Iter: 381 loss: 0.00451635756
Iter: 382 loss: 0.00451630168
Iter: 383 loss: 0.00451623881
Iter: 384 loss: 0.0045162309
Iter: 385 loss: 0.00451615732
Iter: 386 loss: 0.00451674545
Iter: 387 loss: 0.00451615173
Iter: 388 loss: 0.00451608
Iter: 389 loss: 0.00451638922
Iter: 390 loss: 0.00451606512
Iter: 391 loss: 0.00451601529
Iter: 392 loss: 0.00451593893
Iter: 393 loss: 0.00451593706
Iter: 394 loss: 0.00451584347
Iter: 395 loss: 0.00451617083
Iter: 396 loss: 0.00451581739
Iter: 397 loss: 0.00451574288
Iter: 398 loss: 0.00451572519
Iter: 399 loss: 0.00451567676
Iter: 400 loss: 0.00451557525
Iter: 401 loss: 0.00451600365
Iter: 402 loss: 0.00451555662
Iter: 403 loss: 0.0045154551
Iter: 404 loss: 0.00451561064
Iter: 405 loss: 0.00451540714
Iter: 406 loss: 0.00451531261
Iter: 407 loss: 0.00451592263
Iter: 408 loss: 0.00451530237
Iter: 409 loss: 0.00451522227
Iter: 410 loss: 0.00451541087
Iter: 411 loss: 0.00451519201
Iter: 412 loss: 0.00451514777
Iter: 413 loss: 0.00451514823
Iter: 414 loss: 0.00451509468
Iter: 415 loss: 0.00451508
Iter: 416 loss: 0.00451504625
Iter: 417 loss: 0.00451500062
Iter: 418 loss: 0.0045151934
Iter: 419 loss: 0.00451498805
Iter: 420 loss: 0.00451494
Iter: 421 loss: 0.0045152
Iter: 422 loss: 0.0045149331
Iter: 423 loss: 0.00451489724
Iter: 424 loss: 0.004514826
Iter: 425 loss: 0.00451636268
Iter: 426 loss: 0.004514826
Iter: 427 loss: 0.00451474544
Iter: 428 loss: 0.00451522041
Iter: 429 loss: 0.00451473612
Iter: 430 loss: 0.00451468
Iter: 431 loss: 0.00451465417
Iter: 432 loss: 0.0045146253
Iter: 433 loss: 0.00451455265
Iter: 434 loss: 0.00451487396
Iter: 435 loss: 0.00451453496
Iter: 436 loss: 0.0045144679
Iter: 437 loss: 0.00451460574
Iter: 438 loss: 0.00451443437
Iter: 439 loss: 0.00451437384
Iter: 440 loss: 0.0045147459
Iter: 441 loss: 0.00451436592
Iter: 442 loss: 0.0045143161
Iter: 443 loss: 0.00451445347
Iter: 444 loss: 0.00451429933
Iter: 445 loss: 0.00451425649
Iter: 446 loss: 0.00451453449
Iter: 447 loss: 0.00451425
Iter: 448 loss: 0.00451419968
Iter: 449 loss: 0.00451441202
Iter: 450 loss: 0.00451418618
Iter: 451 loss: 0.0045141587
Iter: 452 loss: 0.00451419083
Iter: 453 loss: 0.00451414194
Iter: 454 loss: 0.00451411
Iter: 455 loss: 0.00451447396
Iter: 456 loss: 0.00451411
Iter: 457 loss: 0.00451408653
Iter: 458 loss: 0.00451406278
Iter: 459 loss: 0.00451406185
Iter: 460 loss: 0.00451402972
Iter: 461 loss: 0.00451411586
Iter: 462 loss: 0.00451401807
Iter: 463 loss: 0.00451398455
Iter: 464 loss: 0.00451402087
Iter: 465 loss: 0.00451396452
Iter: 466 loss: 0.00451392867
Iter: 467 loss: 0.00451395568
Iter: 468 loss: 0.00451390631
Iter: 469 loss: 0.00451386161
Iter: 470 loss: 0.00451401807
Iter: 471 loss: 0.00451385183
Iter: 472 loss: 0.00451381691
Iter: 473 loss: 0.0045140544
Iter: 474 loss: 0.00451380946
Iter: 475 loss: 0.00451378105
Iter: 476 loss: 0.00451380899
Iter: 477 loss: 0.00451376149
Iter: 478 loss: 0.00451372331
Iter: 479 loss: 0.00451393519
Iter: 480 loss: 0.00451372098
Iter: 481 loss: 0.0045136949
Iter: 482 loss: 0.0045136949
Iter: 483 loss: 0.00451367954
Iter: 484 loss: 0.00451366
Iter: 485 loss: 0.00451365858
Iter: 486 loss: 0.00451363949
Iter: 487 loss: 0.00451363809
Iter: 488 loss: 0.00451362692
Iter: 489 loss: 0.00451360783
Iter: 490 loss: 0.00451360689
Iter: 491 loss: 0.00451358408
Iter: 492 loss: 0.0045136
Iter: 493 loss: 0.00451356918
Iter: 494 loss: 0.00451353937
Iter: 495 loss: 0.00451364275
Iter: 496 loss: 0.00451353
Iter: 497 loss: 0.00451350166
Iter: 498 loss: 0.00451347884
Iter: 499 loss: 0.00451346813
Iter: 500 loss: 0.00451342529
Iter: 501 loss: 0.00451362552
Iter: 502 loss: 0.00451341877
Iter: 503 loss: 0.00451338291
Iter: 504 loss: 0.00451357244
Iter: 505 loss: 0.00451337919
Iter: 506 loss: 0.00451334799
Iter: 507 loss: 0.0045133722
Iter: 508 loss: 0.00451332889
Iter: 509 loss: 0.00451329583
Iter: 510 loss: 0.00451359153
Iter: 511 loss: 0.00451329537
Iter: 512 loss: 0.00451327488
Iter: 513 loss: 0.00451327441
Iter: 514 loss: 0.00451326091
Iter: 515 loss: 0.00451325113
Iter: 516 loss: 0.00451324554
Iter: 517 loss: 0.00451323064
Iter: 518 loss: 0.00451323343
Iter: 519 loss: 0.00451322272
Iter: 520 loss: 0.00451320363
Iter: 521 loss: 0.00451365951
Iter: 522 loss: 0.00451320177
Iter: 523 loss: 0.00451317569
Iter: 524 loss: 0.00451320224
Iter: 525 loss: 0.00451316172
Iter: 526 loss: 0.00451313518
Iter: 527 loss: 0.0045132488
Iter: 528 loss: 0.00451312819
Iter: 529 loss: 0.00451310258
Iter: 530 loss: 0.00451312
Iter: 531 loss: 0.00451308861
Iter: 532 loss: 0.00451306207
Iter: 533 loss: 0.00451310072
Iter: 534 loss: 0.0045130467
Iter: 535 loss: 0.0045130197
Iter: 536 loss: 0.00451318687
Iter: 537 loss: 0.00451301644
Iter: 538 loss: 0.00451298943
Iter: 539 loss: 0.00451303646
Iter: 540 loss: 0.00451297872
Iter: 541 loss: 0.00451294892
Iter: 542 loss: 0.00451308768
Iter: 543 loss: 0.00451294426
Iter: 544 loss: 0.00451293029
Iter: 545 loss: 0.00451293029
Iter: 546 loss: 0.00451291911
Iter: 547 loss: 0.00451291911
Iter: 548 loss: 0.00451290607
Iter: 549 loss: 0.00451289676
Iter: 550 loss: 0.00451302528
Iter: 551 loss: 0.00451289769
Iter: 552 loss: 0.00451288465
Iter: 553 loss: 0.0045128651
Iter: 554 loss: 0.0045132637
Iter: 555 loss: 0.00451286463
Iter: 556 loss: 0.00451283762
Iter: 557 loss: 0.00451288745
Iter: 558 loss: 0.00451282784
Iter: 559 loss: 0.00451280363
Iter: 560 loss: 0.00451289257
Iter: 561 loss: 0.0045128
Iter: 562 loss: 0.00451277616
Iter: 563 loss: 0.00451279897
Iter: 564 loss: 0.00451276312
Iter: 565 loss: 0.00451273937
Iter: 566 loss: 0.00451274402
Iter: 567 loss: 0.004512724
Iter: 568 loss: 0.00451269187
Iter: 569 loss: 0.0045128935
Iter: 570 loss: 0.00451268815
Iter: 571 loss: 0.00451265927
Iter: 572 loss: 0.00451273378
Iter: 573 loss: 0.00451265182
Iter: 574 loss: 0.00451262388
Iter: 575 loss: 0.00451271702
Iter: 576 loss: 0.00451261783
Iter: 577 loss: 0.004512602
Iter: 578 loss: 0.00451259734
Iter: 579 loss: 0.0045125857
Iter: 580 loss: 0.00451258756
Iter: 581 loss: 0.00451257266
Iter: 582 loss: 0.00451256055
Iter: 583 loss: 0.00451266393
Iter: 584 loss: 0.00451256
Iter: 585 loss: 0.00451254658
Iter: 586 loss: 0.00451252377
Iter: 587 loss: 0.00451252144
Iter: 588 loss: 0.00451249769
Iter: 589 loss: 0.00451254286
Iter: 590 loss: 0.00451248698
Iter: 591 loss: 0.00451246556
Iter: 592 loss: 0.00451251213
Iter: 593 loss: 0.00451245531
Iter: 594 loss: 0.00451243157
Iter: 595 loss: 0.00451248605
Iter: 596 loss: 0.00451242132
Iter: 597 loss: 0.00451239571
Iter: 598 loss: 0.004512385
Iter: 599 loss: 0.00451237196
Iter: 600 loss: 0.00451233611
Iter: 601 loss: 0.00451257126
Iter: 602 loss: 0.00451233331
Iter: 603 loss: 0.00451230258
Iter: 604 loss: 0.00451242691
Iter: 605 loss: 0.00451229652
Iter: 606 loss: 0.00451227045
Iter: 607 loss: 0.00451231841
Iter: 608 loss: 0.00451225881
Iter: 609 loss: 0.00451224204
Iter: 610 loss: 0.00451223832
Iter: 611 loss: 0.00451222388
Iter: 612 loss: 0.00451222342
Iter: 613 loss: 0.00451221224
Iter: 614 loss: 0.00451219641
Iter: 615 loss: 0.00451227743
Iter: 616 loss: 0.00451219268
Iter: 617 loss: 0.00451217638
Iter: 618 loss: 0.00451217033
Iter: 619 loss: 0.00451216241
Iter: 620 loss: 0.00451213773
Iter: 621 loss: 0.00451215543
Iter: 622 loss: 0.00451212749
Iter: 623 loss: 0.00451210421
Iter: 624 loss: 0.00451217778
Iter: 625 loss: 0.00451209769
Iter: 626 loss: 0.00451207347
Iter: 627 loss: 0.00451208372
Iter: 628 loss: 0.00451205857
Iter: 629 loss: 0.00451202784
Iter: 630 loss: 0.00451209117
Iter: 631 loss: 0.00451201899
Iter: 632 loss: 0.004511985
Iter: 633 loss: 0.00451202365
Iter: 634 loss: 0.00451196823
Iter: 635 loss: 0.00451193517
Iter: 636 loss: 0.00451214379
Iter: 637 loss: 0.00451192819
Iter: 638 loss: 0.00451189931
Iter: 639 loss: 0.00451197196
Iter: 640 loss: 0.00451188814
Iter: 641 loss: 0.00451187091
Iter: 642 loss: 0.00451186951
Iter: 643 loss: 0.00451185089
Iter: 644 loss: 0.00451184902
Iter: 645 loss: 0.00451183598
Iter: 646 loss: 0.00451182
Iter: 647 loss: 0.00451193377
Iter: 648 loss: 0.00451181643
Iter: 649 loss: 0.0045117978
Iter: 650 loss: 0.004511829
Iter: 651 loss: 0.00451179
Iter: 652 loss: 0.00451177498
Iter: 653 loss: 0.00451176
Iter: 654 loss: 0.00451175775
Iter: 655 loss: 0.00451173214
Iter: 656 loss: 0.00451183505
Iter: 657 loss: 0.00451173028
Iter: 658 loss: 0.0045117056
Iter: 659 loss: 0.00451170607
Iter: 660 loss: 0.00451168884
Iter: 661 loss: 0.00451165624
Iter: 662 loss: 0.00451174937
Iter: 663 loss: 0.00451164553
Iter: 664 loss: 0.00451161526
Iter: 665 loss: 0.00451165158
Iter: 666 loss: 0.00451159663
Iter: 667 loss: 0.00451156264
Iter: 668 loss: 0.00451166602
Iter: 669 loss: 0.00451155379
Iter: 670 loss: 0.00451151561
Iter: 671 loss: 0.00451171491
Iter: 672 loss: 0.00451151049
Iter: 673 loss: 0.00451149186
Iter: 674 loss: 0.00451179454
Iter: 675 loss: 0.00451149233
Iter: 676 loss: 0.00451146811
Iter: 677 loss: 0.00451150443
Iter: 678 loss: 0.00451146066
Iter: 679 loss: 0.00451144436
Iter: 680 loss: 0.00451151
Iter: 681 loss: 0.00451144
Iter: 682 loss: 0.00451142155
Iter: 683 loss: 0.00451146066
Iter: 684 loss: 0.00451141689
Iter: 685 loss: 0.00451140106
Iter: 686 loss: 0.00451138383
Iter: 687 loss: 0.00451138
Iter: 688 loss: 0.00451135915
Iter: 689 loss: 0.00451142527
Iter: 690 loss: 0.00451134937
Iter: 691 loss: 0.00451132283
Iter: 692 loss: 0.00451134657
Iter: 693 loss: 0.00451130606
Iter: 694 loss: 0.00451127719
Iter: 695 loss: 0.00451133493
Iter: 696 loss: 0.00451126229
Iter: 697 loss: 0.0045112269
Iter: 698 loss: 0.00451129861
Iter: 699 loss: 0.00451121
Iter: 700 loss: 0.00451117475
Iter: 701 loss: 0.00451129535
Iter: 702 loss: 0.0045111659
Iter: 703 loss: 0.00451113377
Iter: 704 loss: 0.00451128
Iter: 705 loss: 0.00451112399
Iter: 706 loss: 0.00451110024
Iter: 707 loss: 0.00451135822
Iter: 708 loss: 0.00451110117
Iter: 709 loss: 0.00451107416
Iter: 710 loss: 0.00451120455
Iter: 711 loss: 0.00451107044
Iter: 712 loss: 0.0045110574
Iter: 713 loss: 0.00451106438
Iter: 714 loss: 0.00451104902
Iter: 715 loss: 0.00451102806
Iter: 716 loss: 0.00451112306
Iter: 717 loss: 0.00451102154
Iter: 718 loss: 0.00451101
Iter: 719 loss: 0.00451098476
Iter: 720 loss: 0.00451098708
Iter: 721 loss: 0.00451096054
Iter: 722 loss: 0.00451103086
Iter: 723 loss: 0.00451094843
Iter: 724 loss: 0.00451092049
Iter: 725 loss: 0.00451099221
Iter: 726 loss: 0.00451091165
Iter: 727 loss: 0.00451088324
Iter: 728 loss: 0.00451091398
Iter: 729 loss: 0.00451086555
Iter: 730 loss: 0.00451083202
Iter: 731 loss: 0.00451087253
Iter: 732 loss: 0.00451081619
Iter: 733 loss: 0.00451078359
Iter: 734 loss: 0.00451100757
Iter: 735 loss: 0.0045107808
Iter: 736 loss: 0.00451075
Iter: 737 loss: 0.00451078545
Iter: 738 loss: 0.00451073563
Iter: 739 loss: 0.00451071281
Iter: 740 loss: 0.00451071281
Iter: 741 loss: 0.00451069232
Iter: 742 loss: 0.00451084739
Iter: 743 loss: 0.00451068953
Iter: 744 loss: 0.00451067835
Iter: 745 loss: 0.00451067556
Iter: 746 loss: 0.00451066578
Iter: 747 loss: 0.00451065088
Iter: 748 loss: 0.00451079849
Iter: 749 loss: 0.00451064669
Iter: 750 loss: 0.00451063737
Iter: 751 loss: 0.00451062061
Iter: 752 loss: 0.00451109186
Iter: 753 loss: 0.00451062154
Iter: 754 loss: 0.00451059779
Iter: 755 loss: 0.0045106858
Iter: 756 loss: 0.00451059081
Iter: 757 loss: 0.00451056892
Iter: 758 loss: 0.00451059826
Iter: 759 loss: 0.00451056194
Iter: 760 loss: 0.00451053446
Iter: 761 loss: 0.00451059593
Iter: 762 loss: 0.00451052375
Iter: 763 loss: 0.00451050233
Iter: 764 loss: 0.00451050047
Iter: 765 loss: 0.00451048277
Iter: 766 loss: 0.00451045437
Iter: 767 loss: 0.00451066531
Iter: 768 loss: 0.0045104539
Iter: 769 loss: 0.00451042876
Iter: 770 loss: 0.00451047719
Iter: 771 loss: 0.00451041944
Iter: 772 loss: 0.00451040268
Iter: 773 loss: 0.00451064156
Iter: 774 loss: 0.00451040082
Iter: 775 loss: 0.00451038731
Iter: 776 loss: 0.00451048929
Iter: 777 loss: 0.00451038498
Iter: 778 loss: 0.00451037567
Iter: 779 loss: 0.004510378
Iter: 780 loss: 0.00451036636
Iter: 781 loss: 0.00451035704
Iter: 782 loss: 0.00451046694
Iter: 783 loss: 0.00451035611
Iter: 784 loss: 0.00451034959
Iter: 785 loss: 0.0045103319
Iter: 786 loss: 0.00451065321
Iter: 787 loss: 0.0045103319
Iter: 788 loss: 0.00451031514
Iter: 789 loss: 0.00451037288
Iter: 790 loss: 0.00451030815
Iter: 791 loss: 0.00451029139
Iter: 792 loss: 0.00451032
Iter: 793 loss: 0.00451028068
Iter: 794 loss: 0.00451026252
Iter: 795 loss: 0.00451034028
Iter: 796 loss: 0.00451025926
Iter: 797 loss: 0.00451024249
Iter: 798 loss: 0.0045102369
Iter: 799 loss: 0.00451022573
Iter: 800 loss: 0.00451020617
Iter: 801 loss: 0.00451034401
Iter: 802 loss: 0.00451020524
Iter: 803 loss: 0.00451018848
Iter: 804 loss: 0.00451023364
Iter: 805 loss: 0.00451018382
Iter: 806 loss: 0.00451016892
Iter: 807 loss: 0.00451032
Iter: 808 loss: 0.00451016752
Iter: 809 loss: 0.00451015681
Iter: 810 loss: 0.00451026345
Iter: 811 loss: 0.00451015588
Iter: 812 loss: 0.00451015029
Iter: 813 loss: 0.00451014843
Iter: 814 loss: 0.00451014331
Iter: 815 loss: 0.00451013213
Iter: 816 loss: 0.0045102085
Iter: 817 loss: 0.0045101312
Iter: 818 loss: 0.00451012515
Iter: 819 loss: 0.00451011676
Iter: 820 loss: 0.00451011583
Iter: 821 loss: 0.00451010186
Iter: 822 loss: 0.00451012515
Iter: 823 loss: 0.00451009581
Iter: 824 loss: 0.00451008137
Iter: 825 loss: 0.00451013073
Iter: 826 loss: 0.00451007858
Iter: 827 loss: 0.00451006554
Iter: 828 loss: 0.00451009674
Iter: 829 loss: 0.00451005856
Iter: 830 loss: 0.00451004645
Iter: 831 loss: 0.00451006275
Iter: 832 loss: 0.00451004
Iter: 833 loss: 0.00451002643
Iter: 834 loss: 0.00451006275
Iter: 835 loss: 0.00451002084
Iter: 836 loss: 0.00451000594
Iter: 837 loss: 0.00451005436
Iter: 838 loss: 0.00451000361
Iter: 839 loss: 0.00450999103
Iter: 840 loss: 0.00451007951
Iter: 841 loss: 0.00450998917
Iter: 842 loss: 0.00450998265
Iter: 843 loss: 0.00450998126
Iter: 844 loss: 0.004509978
Iter: 845 loss: 0.00450997148
Iter: 846 loss: 0.00450997241
Iter: 847 loss: 0.00450996403
Iter: 848 loss: 0.00451001897
Iter: 849 loss: 0.00450996542
Iter: 850 loss: 0.00450995797
Iter: 851 loss: 0.00450995192
Iter: 852 loss: 0.00450995
Iter: 853 loss: 0.00450994167
Iter: 854 loss: 0.00450993842
Iter: 855 loss: 0.00450993422
Iter: 856 loss: 0.00450991932
Iter: 857 loss: 0.00451001618
Iter: 858 loss: 0.00450991932
Iter: 859 loss: 0.00450990908
Iter: 860 loss: 0.00450991699
Iter: 861 loss: 0.00450990535
Iter: 862 loss: 0.00450989371
Iter: 863 loss: 0.00450993329
Iter: 864 loss: 0.00450989325
Iter: 865 loss: 0.00450987928
Iter: 866 loss: 0.00450989325
Iter: 867 loss: 0.00450987509
Iter: 868 loss: 0.00450986391
Iter: 869 loss: 0.00450988673
Iter: 870 loss: 0.00450985692
Iter: 871 loss: 0.00450984668
Iter: 872 loss: 0.00450996868
Iter: 873 loss: 0.00450984668
Iter: 874 loss: 0.00450984389
Iter: 875 loss: 0.00450984202
Iter: 876 loss: 0.00450983597
Iter: 877 loss: 0.00450983271
Iter: 878 loss: 0.00450983224
Iter: 879 loss: 0.00450982712
Iter: 880 loss: 0.0045098695
Iter: 881 loss: 0.00450982619
Iter: 882 loss: 0.00450982247
Iter: 883 loss: 0.00450981781
Iter: 884 loss: 0.00450981501
Iter: 885 loss: 0.00450980663
Iter: 886 loss: 0.00450980477
Iter: 887 loss: 0.00450979779
Iter: 888 loss: 0.00450979173
Iter: 889 loss: 0.00450988393
Iter: 890 loss: 0.00450979
Iter: 891 loss: 0.00450978288
Iter: 892 loss: 0.00450978242
Iter: 893 loss: 0.00450977683
Iter: 894 loss: 0.00450976752
Iter: 895 loss: 0.00450979639
Iter: 896 loss: 0.00450976659
Iter: 897 loss: 0.0045097582
Iter: 898 loss: 0.0045097624
Iter: 899 loss: 0.00450975168
Iter: 900 loss: 0.00450973911
Iter: 901 loss: 0.00450976845
Iter: 902 loss: 0.00450973678
Iter: 903 loss: 0.00450972747
Iter: 904 loss: 0.00450984528
Iter: 905 loss: 0.00450972933
Iter: 906 loss: 0.00450972514
Iter: 907 loss: 0.00450972142
Iter: 908 loss: 0.00450971955
Iter: 909 loss: 0.00450971676
Iter: 910 loss: 0.00450971536
Iter: 911 loss: 0.00450971071
Iter: 912 loss: 0.00450975914
Iter: 913 loss: 0.00450971071
Iter: 914 loss: 0.00450970232
Iter: 915 loss: 0.00450970139
Iter: 916 loss: 0.00450970139
Iter: 917 loss: 0.00450969487
Iter: 918 loss: 0.00450968836
Iter: 919 loss: 0.00450968696
Iter: 920 loss: 0.0045096809
Iter: 921 loss: 0.00450975075
Iter: 922 loss: 0.00450967904
Iter: 923 loss: 0.00450967066
Iter: 924 loss: 0.00450967811
Iter: 925 loss: 0.00450967159
Iter: 926 loss: 0.00450966228
Iter: 927 loss: 0.00450968323
Iter: 928 loss: 0.00450965948
Iter: 929 loss: 0.0045096511
Iter: 930 loss: 0.00450965529
Iter: 931 loss: 0.00450964645
Iter: 932 loss: 0.00450963853
Iter: 933 loss: 0.00450966135
Iter: 934 loss: 0.00450963387
Iter: 935 loss: 0.00450962503
Iter: 936 loss: 0.00450973492
Iter: 937 loss: 0.00450963
Iter: 938 loss: 0.00450962177
Iter: 939 loss: 0.0045096227
Iter: 940 loss: 0.00450961944
Iter: 941 loss: 0.00450961851
Iter: 942 loss: 0.00450961525
Iter: 943 loss: 0.00450961199
Iter: 944 loss: 0.00450964691
Iter: 945 loss: 0.00450961199
Iter: 946 loss: 0.00450960966
Iter: 947 loss: 0.00450960454
Iter: 948 loss: 0.00450960454
Iter: 949 loss: 0.00450959848
Iter: 950 loss: 0.00450959895
Iter: 951 loss: 0.00450959336
Iter: 952 loss: 0.00450958638
Iter: 953 loss: 0.00450963527
Iter: 954 loss: 0.00450958498
Iter: 955 loss: 0.00450958405
Iter: 956 loss: 0.00450958963
Iter: 957 loss: 0.00450957846
Iter: 958 loss: 0.00450957194
Iter: 959 loss: 0.00450958358
Iter: 960 loss: 0.00450957194
Iter: 961 loss: 0.00450956263
Iter: 962 loss: 0.00450957566
Iter: 963 loss: 0.00450956076
Iter: 964 loss: 0.00450955518
Iter: 965 loss: 0.00450957287
Iter: 966 loss: 0.00450955238
Iter: 967 loss: 0.00450954679
Iter: 968 loss: 0.00450959
Iter: 969 loss: 0.00450954633
Iter: 970 loss: 0.00450954586
Iter: 971 loss: 0.00450954214
Iter: 972 loss: 0.00450953748
Iter: 973 loss: 0.00450954167
Iter: 974 loss: 0.00450953655
Iter: 975 loss: 0.00450953655
Iter: 976 loss: 0.00450954773
Iter: 977 loss: 0.00450953329
Iter: 978 loss: 0.00450953282
Iter: 979 loss: 0.0045095277
Iter: 980 loss: 0.0045095277
Iter: 981 loss: 0.00450952258
Iter: 982 loss: 0.00450952351
Iter: 983 loss: 0.00450951792
Iter: 984 loss: 0.00450951606
Iter: 985 loss: 0.00450953748
Iter: 986 loss: 0.00450951234
Iter: 987 loss: 0.00450951
Iter: 988 loss: 0.00450952118
Iter: 989 loss: 0.00450950628
Iter: 990 loss: 0.00450950162
Iter: 991 loss: 0.00450950395
Iter: 992 loss: 0.00450949837
Iter: 993 loss: 0.00450949417
Iter: 994 loss: 0.00450951513
Iter: 995 loss: 0.00450949278
Iter: 996 loss: 0.00450948626
Iter: 997 loss: 0.0045095
Iter: 998 loss: 0.00450948067
Iter: 999 loss: 0.00450947881
Iter: 1000 loss: 0.00450950442
Iter: 1001 loss: 0.00450947741
Iter: 1002 loss: 0.00450947415
Iter: 1003 loss: 0.00450947601
Iter: 1004 loss: 0.00450947089
Iter: 1005 loss: 0.00450947508
Iter: 1006 loss: 0.00450946856
Iter: 1007 loss: 0.00450946903
Iter: 1008 loss: 0.00450947275
Iter: 1009 loss: 0.00450946717
Iter: 1010 loss: 0.00450946437
Iter: 1011 loss: 0.00450946251
Iter: 1012 loss: 0.00450946
Iter: 1013 loss: 0.00450945646
Iter: 1014 loss: 0.00450945646
Iter: 1015 loss: 0.00450945552
Iter: 1016 loss: 0.00450945
Iter: 1017 loss: 0.0045094667
Iter: 1018 loss: 0.00450944761
Iter: 1019 loss: 0.00450944342
Iter: 1020 loss: 0.00450946158
Iter: 1021 loss: 0.00450944342
Iter: 1022 loss: 0.00450943829
Iter: 1023 loss: 0.00450943969
Iter: 1024 loss: 0.0045094369
Iter: 1025 loss: 0.00450942945
Iter: 1026 loss: 0.00450944202
Iter: 1027 loss: 0.00450942852
Iter: 1028 loss: 0.00450942246
Iter: 1029 loss: 0.00450943923
Iter: 1030 loss: 0.00450941967
Iter: 1031 loss: 0.00450941548
Iter: 1032 loss: 0.00450944481
Iter: 1033 loss: 0.00450941455
Iter: 1034 loss: 0.00450941082
Iter: 1035 loss: 0.00450941408
Iter: 1036 loss: 0.00450940896
Iter: 1037 loss: 0.00450941268
Iter: 1038 loss: 0.00450940803
Iter: 1039 loss: 0.00450940523
Iter: 1040 loss: 0.00450941082
Iter: 1041 loss: 0.00450940477
Iter: 1042 loss: 0.0045094043
Iter: 1043 loss: 0.00450940523
Iter: 1044 loss: 0.00450940244
Iter: 1045 loss: 0.00450939965
Iter: 1046 loss: 0.00450939871
Iter: 1047 loss: 0.00450939639
Iter: 1048 loss: 0.00450939126
Iter: 1049 loss: 0.00450941268
Iter: 1050 loss: 0.00450939126
Iter: 1051 loss: 0.00450939
Iter: 1052 loss: 0.00450939825
Iter: 1053 loss: 0.00450938754
Iter: 1054 loss: 0.00450938242
Iter: 1055 loss: 0.0045093908
Iter: 1056 loss: 0.00450938242
Iter: 1057 loss: 0.00450937729
Iter: 1058 loss: 0.00450938102
Iter: 1059 loss: 0.00450937543
Iter: 1060 loss: 0.00450936798
Iter: 1061 loss: 0.00450939406
Iter: 1062 loss: 0.00450936751
Iter: 1063 loss: 0.00450936472
Iter: 1064 loss: 0.00450937822
Iter: 1065 loss: 0.00450936565
Iter: 1066 loss: 0.00450936332
Iter: 1067 loss: 0.00450936425
Iter: 1068 loss: 0.00450936239
Iter: 1069 loss: 0.00450936239
Iter: 1070 loss: 0.00450936053
Iter: 1071 loss: 0.0045093596
Iter: 1072 loss: 0.00450936286
Iter: 1073 loss: 0.00450935913
Iter: 1074 loss: 0.00450935401
Iter: 1075 loss: 0.0045093596
Iter: 1076 loss: 0.00450935448
Iter: 1077 loss: 0.00450935215
Iter: 1078 loss: 0.00450935028
Iter: 1079 loss: 0.00450934889
Iter: 1080 loss: 0.00450934656
Iter: 1081 loss: 0.00450936379
Iter: 1082 loss: 0.0045093447
Iter: 1083 loss: 0.00450934377
Iter: 1084 loss: 0.00450934749
Iter: 1085 loss: 0.0045093419
Iter: 1086 loss: 0.00450933911
Iter: 1087 loss: 0.00450934563
Iter: 1088 loss: 0.00450933864
Iter: 1089 loss: 0.00450933259
Iter: 1090 loss: 0.00450933911
Iter: 1091 loss: 0.00450933073
Iter: 1092 loss: 0.00450932747
Iter: 1093 loss: 0.00450934237
Iter: 1094 loss: 0.004509327
Iter: 1095 loss: 0.00450932421
Iter: 1096 loss: 0.00450932793
Iter: 1097 loss: 0.00450932095
Iter: 1098 loss: 0.00450932
Iter: 1099 loss: 0.00450932235
Iter: 1100 loss: 0.00450931955
Iter: 1101 loss: 0.00450931862
Iter: 1102 loss: 0.00450931815
Iter: 1103 loss: 0.00450931443
Iter: 1104 loss: 0.00450932281
Iter: 1105 loss: 0.00450931583
Iter: 1106 loss: 0.00450931164
Iter: 1107 loss: 0.00450932
Iter: 1108 loss: 0.00450931257
Iter: 1109 loss: 0.00450930931
Iter: 1110 loss: 0.00450930558
Iter: 1111 loss: 0.00450930744
Iter: 1112 loss: 0.00450930605
Iter: 1113 loss: 0.00450931303
Iter: 1114 loss: 0.00450930279
Iter: 1115 loss: 0.00450929906
Iter: 1116 loss: 0.00450931489
Iter: 1117 loss: 0.00450929953
Iter: 1118 loss: 0.00450929627
Iter: 1119 loss: 0.00450929906
Iter: 1120 loss: 0.00450929394
Iter: 1121 loss: 0.00450928882
Iter: 1122 loss: 0.00450930186
Iter: 1123 loss: 0.00450928928
Iter: 1124 loss: 0.00450928416
Iter: 1125 loss: 0.00450928882
Iter: 1126 loss: 0.00450928602
Iter: 1127 loss: 0.00450928416
Iter: 1128 loss: 0.00450930232
Iter: 1129 loss: 0.00450928183
Iter: 1130 loss: 0.0045092795
Iter: 1131 loss: 0.0045092795
Iter: 1132 loss: 0.00450927671
Iter: 1133 loss: 0.00450928
Iter: 1134 loss: 0.00450927764
Iter: 1135 loss: 0.00450927671
Iter: 1136 loss: 0.00450927811
Iter: 1137 loss: 0.00450927299
Iter: 1138 loss: 0.00450927299
Iter: 1139 loss: 0.00450927764
Iter: 1140 loss: 0.00450927205
Iter: 1141 loss: 0.00450926973
Iter: 1142 loss: 0.0045092674
Iter: 1143 loss: 0.00450926926
Iter: 1144 loss: 0.00450926693
Iter: 1145 loss: 0.00450927
Iter: 1146 loss: 0.00450926367
Iter: 1147 loss: 0.00450926507
Iter: 1148 loss: 0.00450928044
Iter: 1149 loss: 0.004509266
Iter: 1150 loss: 0.00450926181
Iter: 1151 loss: 0.00450926227
Iter: 1152 loss: 0.00450925808
Iter: 1153 loss: 0.00450926041
Iter: 1154 loss: 0.00450927112
Iter: 1155 loss: 0.00450925902
Iter: 1156 loss: 0.00450925808
Iter: 1157 loss: 0.00450925902
Iter: 1158 loss: 0.00450925715
Iter: 1159 loss: 0.00450925482
Iter: 1160 loss: 0.004509266
Iter: 1161 loss: 0.00450925436
Iter: 1162 loss: 0.00450925436
Iter: 1163 loss: 0.00450925482
Iter: 1164 loss: 0.0045092525
Iter: 1165 loss: 0.00450925622
Iter: 1166 loss: 0.0045092525
Iter: 1167 loss: 0.0045092525
Iter: 1168 loss: 0.00450925343
Iter: 1169 loss: 0.00450925203
Iter: 1170 loss: 0.00450925203
Iter: 1171 loss: 0.00450925436
Iter: 1172 loss: 0.00450924924
Iter: 1173 loss: 0.00450924924
Iter: 1174 loss: 0.00450924877
Iter: 1175 loss: 0.00450924598
Iter: 1176 loss: 0.00450924644
Iter: 1177 loss: 0.00450924598
Iter: 1178 loss: 0.00450924737
Iter: 1179 loss: 0.00450924551
Iter: 1180 loss: 0.00450925296
Iter: 1181 loss: 0.00450924411
Iter: 1182 loss: 0.00450924318
Iter: 1183 loss: 0.00450924318
Iter: 1184 loss: 0.00450924411
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/k3
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0
+ date
Tue Oct 27 17:48:26 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6d290d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6d273840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6d2909d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2caefb1f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2caefb7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2caefb7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6d22aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6d1fa730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6d1c1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c6d1c1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4825c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c48260e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c48260ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c481f2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c482439d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c481c5e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c481d5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c481d5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c48137840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c480efa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c480ef510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c48098ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c480d6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4805ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4807dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c480368c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c300ed8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c3010cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c3010c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c300a9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c3010c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c3007f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c3002a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2be461bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2be4651a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2be45dbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00776350964
Iter: 2 loss: 0.00773208635
Iter: 3 loss: 0.00763246464
Iter: 4 loss: 0.00776164792
Iter: 5 loss: 0.00755821355
Iter: 6 loss: 0.00754444
Iter: 7 loss: 0.00752442237
Iter: 8 loss: 0.0075194
Iter: 9 loss: 0.00751860067
Iter: 10 loss: 0.00751513429
Iter: 11 loss: 0.00751467841
Iter: 12 loss: 0.007514467
Iter: 13 loss: 0.00751414709
Iter: 14 loss: 0.0075157485
Iter: 15 loss: 0.00751409587
Iter: 16 loss: 0.00751406141
Iter: 17 loss: 0.0075142
Iter: 18 loss: 0.00751405209
Iter: 19 loss: 0.0075140493
Iter: 20 loss: 0.00751404604
Iter: 21 loss: 0.00751404604
Iter: 22 loss: 0.00751404371
Iter: 23 loss: 0.00751404325
Iter: 24 loss: 0.00751404278
Iter: 25 loss: 0.00751404557
Iter: 26 loss: 0.00751404464
Iter: 27 loss: 0.00751404371
Iter: 28 loss: 0.00751404278
Iter: 29 loss: 0.00751404325
Iter: 30 loss: 0.00751404278
Iter: 31 loss: 0.00751404371
Iter: 32 loss: 0.00751404464
Iter: 33 loss: 0.00751404185
Iter: 34 loss: 0.00751404371
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4
+ date
Tue Oct 27 17:48:50 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a6e72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a658d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a6586a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a6589d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a586400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a586158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a50e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a53f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a53f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a4da378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a53fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a44e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a49aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a4059d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a44e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a3d4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a3e5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a3e5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a3588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a358d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a37c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a37ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a2ee9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a28e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a28e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a2437b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a272510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a224510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a224378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a1c7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a1c78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a1ad730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a1b5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a155bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a10b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4a116f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.033586815
Iter: 2 loss: 0.0292983092
Iter: 3 loss: 0.0166787151
Iter: 4 loss: 0.0528400205
Iter: 5 loss: 0.0101139313
Iter: 6 loss: 0.00923363678
Iter: 7 loss: 0.00899941847
Iter: 8 loss: 0.00857613795
Iter: 9 loss: 0.0138740409
Iter: 10 loss: 0.0085653672
Iter: 11 loss: 0.00847673416
Iter: 12 loss: 0.0086935889
Iter: 13 loss: 0.00844529737
Iter: 14 loss: 0.0084333159
Iter: 15 loss: 0.0084214285
Iter: 16 loss: 0.00841162167
Iter: 17 loss: 0.00843161158
Iter: 18 loss: 0.00840768404
Iter: 19 loss: 0.0084053278
Iter: 20 loss: 0.00842859223
Iter: 21 loss: 0.00840524584
Iter: 22 loss: 0.00840483885
Iter: 23 loss: 0.00840476248
Iter: 24 loss: 0.00840464
Iter: 25 loss: 0.0084050484
Iter: 26 loss: 0.00840460788
Iter: 27 loss: 0.00840457
Iter: 28 loss: 0.00840491429
Iter: 29 loss: 0.00840457
Iter: 30 loss: 0.00840456411
Iter: 31 loss: 0.00840456
Iter: 32 loss: 0.00840455852
Iter: 33 loss: 0.00840456225
Iter: 34 loss: 0.00840455666
Iter: 35 loss: 0.0084045548
Iter: 36 loss: 0.00840456318
Iter: 37 loss: 0.00840455666
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8
+ date
Tue Oct 27 17:49:18 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad746840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad839b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad839ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad782bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad6d8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad695400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad6bac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad6a2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad68b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad68b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad5e8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad5f5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad5f5e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad5f5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad58ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad58a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad51d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad538b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad4a0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad4a0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad4c8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad471d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad43e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad443f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad3d4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad3ebe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad3bf6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad3bf598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad376598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad31d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad33cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad2f27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad304268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad2a9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad25ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3ad25b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0276323538
Iter: 2 loss: 0.0242720433
Iter: 3 loss: 0.0162290614
Iter: 4 loss: 0.711610794
Iter: 5 loss: 0.0161858685
Iter: 6 loss: 0.0113321682
Iter: 7 loss: 0.0567481853
Iter: 8 loss: 0.0109784743
Iter: 9 loss: 0.0101378402
Iter: 10 loss: 0.0100242402
Iter: 11 loss: 0.00987724215
Iter: 12 loss: 0.0106554544
Iter: 13 loss: 0.00985274278
Iter: 14 loss: 0.0097559737
Iter: 15 loss: 0.00998726487
Iter: 16 loss: 0.0097199548
Iter: 17 loss: 0.00966384076
Iter: 18 loss: 0.00994830206
Iter: 19 loss: 0.009654833
Iter: 20 loss: 0.00963554904
Iter: 21 loss: 0.00978594739
Iter: 22 loss: 0.00963414088
Iter: 23 loss: 0.00962953363
Iter: 24 loss: 0.00962932594
Iter: 25 loss: 0.00962797459
Iter: 26 loss: 0.00963065587
Iter: 27 loss: 0.00962741952
Iter: 28 loss: 0.00962716434
Iter: 29 loss: 0.00963028707
Iter: 30 loss: 0.00962716062
Iter: 31 loss: 0.00962708797
Iter: 32 loss: 0.0096270889
Iter: 33 loss: 0.00962706096
Iter: 34 loss: 0.00962716434
Iter: 35 loss: 0.00962705538
Iter: 36 loss: 0.00962704327
Iter: 37 loss: 0.00962708704
Iter: 38 loss: 0.0096270442
Iter: 39 loss: 0.00962704
Iter: 40 loss: 0.0096270619
Iter: 41 loss: 0.00962703861
Iter: 42 loss: 0.00962704234
Iter: 43 loss: 0.00962703861
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2
+ date
Tue Oct 27 17:49:46 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi0.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b20c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b20c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b1b3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b1ee048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b143598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b143ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b0ba8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b0ef730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b0efd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b08a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b0ef378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b0068c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1b04bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1afb8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1aff0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1af7bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1af978c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1aff08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1af6b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1aff00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1af26510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1af260d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ae9f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ae38598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ae38158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1adf3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1adf3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1add6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ae386a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ad732f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ad9b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ad63400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ad6b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b1ad07d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ae184c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ae186d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0293626748
Iter: 2 loss: 0.0236977488
Iter: 3 loss: 0.0238449313
Iter: 4 loss: 0.0183122288
Iter: 5 loss: 0.0145285446
Iter: 6 loss: 0.138610154
Iter: 7 loss: 0.0144965444
Iter: 8 loss: 0.0117794164
Iter: 9 loss: 0.031994
Iter: 10 loss: 0.0115175284
Iter: 11 loss: 0.0109257195
Iter: 12 loss: 0.012137237
Iter: 13 loss: 0.0106780659
Iter: 14 loss: 0.0105148768
Iter: 15 loss: 0.0120185781
Iter: 16 loss: 0.0105060395
Iter: 17 loss: 0.0104215555
Iter: 18 loss: 0.0105792284
Iter: 19 loss: 0.0103850011
Iter: 20 loss: 0.010322582
Iter: 21 loss: 0.0103222746
Iter: 22 loss: 0.0102996472
Iter: 23 loss: 0.0104428064
Iter: 24 loss: 0.0102971718
Iter: 25 loss: 0.0102893
Iter: 26 loss: 0.0103055127
Iter: 27 loss: 0.0102861132
Iter: 28 loss: 0.0102830734
Iter: 29 loss: 0.0102983266
Iter: 30 loss: 0.0102825705
Iter: 31 loss: 0.0102815814
Iter: 32 loss: 0.0102881957
Iter: 33 loss: 0.0102814808
Iter: 34 loss: 0.0102811605
Iter: 35 loss: 0.0102835428
Iter: 36 loss: 0.0102811325
Iter: 37 loss: 0.0102810152
Iter: 38 loss: 0.0102819949
Iter: 39 loss: 0.0102810049
Iter: 40 loss: 0.0102809528
Iter: 41 loss: 0.0102812573
Iter: 42 loss: 0.0102809444
Iter: 43 loss: 0.0102809221
Iter: 44 loss: 0.0102811158
Iter: 45 loss: 0.0102809183
Iter: 46 loss: 0.010280909
Iter: 47 loss: 0.010280964
Iter: 48 loss: 0.0102809053
Iter: 49 loss: 0.0102808978
Iter: 50 loss: 0.010280937
Iter: 51 loss: 0.0102809006
Iter: 52 loss: 0.0102808978
Iter: 53 loss: 0.0102809053
Iter: 54 loss: 0.0102809
Iter: 55 loss: 0.010280896
Iter: 56 loss: 0.0102809034
Iter: 57 loss: 0.0102808978
Iter: 58 loss: 0.0102808978
Iter: 59 loss: 0.010280896
Iter: 60 loss: 0.0102808988
Iter: 61 loss: 0.0102808969
Iter: 62 loss: 0.0102808978
Iter: 63 loss: 0.010280896
Iter: 64 loss: 0.0102808969
Iter: 65 loss: 0.0102808941
Iter: 66 loss: 0.0102808978
Iter: 67 loss: 0.0102808969
Iter: 68 loss: 0.010280896
Iter: 69 loss: 0.010280895
Iter: 70 loss: 0.0102808969
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6
+ date
Tue Oct 27 17:50:16 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48201e7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48201e7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48201f5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482017c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482017c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482017c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482015cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482015c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4820122378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4820122158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4820082c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4820096d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482002e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480040f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4800449840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4800449158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48003cf7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48003ff9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480035d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480035dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48003822f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4800382e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48002ef950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48002956a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48002952f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480024d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480027d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480027d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480022b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480027de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4800201ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48001b4158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48001c31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f480015bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4800118510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4800118ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0373857953
Iter: 2 loss: 0.022737598
Iter: 3 loss: 3271.19385
Iter: 4 loss: 0.0227375813
Iter: 5 loss: 0.0206011124
Iter: 6 loss: 0.0184912477
Iter: 7 loss: 0.0158788376
Iter: 8 loss: 0.0348258093
Iter: 9 loss: 0.0154208131
Iter: 10 loss: 0.0130550936
Iter: 11 loss: 0.0308302771
Iter: 12 loss: 0.0128431618
Iter: 13 loss: 0.0121795312
Iter: 14 loss: 0.0117637664
Iter: 15 loss: 0.0114972033
Iter: 16 loss: 0.0110703371
Iter: 17 loss: 0.0163860079
Iter: 18 loss: 0.0110543557
Iter: 19 loss: 0.0109687764
Iter: 20 loss: 0.0116790533
Iter: 21 loss: 0.0109621752
Iter: 22 loss: 0.0109128533
Iter: 23 loss: 0.0108802523
Iter: 24 loss: 0.0108616818
Iter: 25 loss: 0.0107834656
Iter: 26 loss: 0.0108385896
Iter: 27 loss: 0.0107345637
Iter: 28 loss: 0.0106571745
Iter: 29 loss: 0.0109916888
Iter: 30 loss: 0.0106401034
Iter: 31 loss: 0.0106072426
Iter: 32 loss: 0.0106743
Iter: 33 loss: 0.0105941137
Iter: 34 loss: 0.0105773956
Iter: 35 loss: 0.0106526362
Iter: 36 loss: 0.0105741136
Iter: 37 loss: 0.0105693648
Iter: 38 loss: 0.0106237698
Iter: 39 loss: 0.0105692828
Iter: 40 loss: 0.0105669908
Iter: 41 loss: 0.0105751837
Iter: 42 loss: 0.0105664078
Iter: 43 loss: 0.0105654178
Iter: 44 loss: 0.0105767073
Iter: 45 loss: 0.0105654
Iter: 46 loss: 0.0105650323
Iter: 47 loss: 0.0105679547
Iter: 48 loss: 0.0105650052
Iter: 49 loss: 0.0105648469
Iter: 50 loss: 0.0105656181
Iter: 51 loss: 0.0105648199
Iter: 52 loss: 0.0105647286
Iter: 53 loss: 0.0105652073
Iter: 54 loss: 0.0105647109
Iter: 55 loss: 0.0105646644
Iter: 56 loss: 0.0105646625
Iter: 57 loss: 0.0105646383
Iter: 58 loss: 0.0105646439
Iter: 59 loss: 0.0105646187
Iter: 60 loss: 0.0105645964
Iter: 61 loss: 0.0105646932
Iter: 62 loss: 0.0105645936
Iter: 63 loss: 0.0105645787
Iter: 64 loss: 0.0105646346
Iter: 65 loss: 0.0105645768
Iter: 66 loss: 0.0105645675
Iter: 67 loss: 0.0105646234
Iter: 68 loss: 0.0105645657
Iter: 69 loss: 0.0105645619
Iter: 70 loss: 0.0105645768
Iter: 71 loss: 0.0105645563
Iter: 72 loss: 0.0105645563
Iter: 73 loss: 0.0105645685
Iter: 74 loss: 0.0105645554
Iter: 75 loss: 0.0105645508
Iter: 76 loss: 0.0105645545
Iter: 77 loss: 0.0105645489
Iter: 78 loss: 0.010564548
Iter: 79 loss: 0.0105645591
Iter: 80 loss: 0.0105645489
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2
+ date
Tue Oct 27 17:50:47 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi1.6/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5330201e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb5330741e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532fb1048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532fd5d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532f2a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532f2a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532eac840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532ed2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532ed2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532e7c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532e45b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532dec048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532decb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532e18378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532e18840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532dc4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532d7b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532d32f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532ceb9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532d0f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532d0f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532cc0b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532c81598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532c87840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532c29730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532c46268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532c15840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532bc0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532bc70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532b6e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532ba07b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532b4c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532b4cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532ae6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532b166a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb532b16730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0588561594
Iter: 2 loss: 0.953130066
Iter: 3 loss: 0.0584086329
Iter: 4 loss: 0.027913345
Iter: 5 loss: 0.0279209297
Iter: 6 loss: 0.0249260031
Iter: 7 loss: 0.0254687499
Iter: 8 loss: 0.0223034229
Iter: 9 loss: 0.0206914134
Iter: 10 loss: 0.0187376514
Iter: 11 loss: 0.0178098939
Iter: 12 loss: 0.0169642493
Iter: 13 loss: 0.0166800916
Iter: 14 loss: 0.0156664
Iter: 15 loss: 0.0156240128
Iter: 16 loss: 0.0148367658
Iter: 17 loss: 0.0138638141
Iter: 18 loss: 0.0155493105
Iter: 19 loss: 0.0133671183
Iter: 20 loss: 0.0128351022
Iter: 21 loss: 0.0191332269
Iter: 22 loss: 0.0128143039
Iter: 23 loss: 0.0125879161
Iter: 24 loss: 0.0142386109
Iter: 25 loss: 0.0125675788
Iter: 26 loss: 0.0124192918
Iter: 27 loss: 0.01269814
Iter: 28 loss: 0.0123519916
Iter: 29 loss: 0.0122590596
Iter: 30 loss: 0.0129763605
Iter: 31 loss: 0.0122518539
Iter: 32 loss: 0.0122081507
Iter: 33 loss: 0.0125162974
Iter: 34 loss: 0.0122039504
Iter: 35 loss: 0.0121643767
Iter: 36 loss: 0.0121561177
Iter: 37 loss: 0.0121297389
Iter: 38 loss: 0.0120558944
Iter: 39 loss: 0.0126310904
Iter: 40 loss: 0.0120511157
Iter: 41 loss: 0.011994889
Iter: 42 loss: 0.0126882549
Iter: 43 loss: 0.0119937267
Iter: 44 loss: 0.0119631812
Iter: 45 loss: 0.0119506847
Iter: 46 loss: 0.0119344685
Iter: 47 loss: 0.0118852807
Iter: 48 loss: 0.0120229237
Iter: 49 loss: 0.011869533
Iter: 50 loss: 0.0118372189
Iter: 51 loss: 0.0119533027
Iter: 52 loss: 0.0118289683
Iter: 53 loss: 0.0118103959
Iter: 54 loss: 0.0119652729
Iter: 55 loss: 0.0118092289
Iter: 56 loss: 0.011800427
Iter: 57 loss: 0.0118230814
Iter: 58 loss: 0.0117973797
Iter: 59 loss: 0.011790894
Iter: 60 loss: 0.0118430983
Iter: 61 loss: 0.0117904618
Iter: 62 loss: 0.0117866732
Iter: 63 loss: 0.0117997639
Iter: 64 loss: 0.011785673
Iter: 65 loss: 0.0117827617
Iter: 66 loss: 0.011806814
Iter: 67 loss: 0.011782581
Iter: 68 loss: 0.0117812566
Iter: 69 loss: 0.0117811635
Iter: 70 loss: 0.0117801707
Iter: 71 loss: 0.0117792599
Iter: 72 loss: 0.0117860697
Iter: 73 loss: 0.0117791817
Iter: 74 loss: 0.0117788445
Iter: 75 loss: 0.0117787607
Iter: 76 loss: 0.0117784645
Iter: 77 loss: 0.0117807
Iter: 78 loss: 0.011778445
Iter: 79 loss: 0.011778336
Iter: 80 loss: 0.0117781255
Iter: 81 loss: 0.0117823612
Iter: 82 loss: 0.0117781246
Iter: 83 loss: 0.0117779337
Iter: 84 loss: 0.011779055
Iter: 85 loss: 0.0117779095
Iter: 86 loss: 0.0117777735
Iter: 87 loss: 0.0117781581
Iter: 88 loss: 0.0117777316
Iter: 89 loss: 0.0117776357
Iter: 90 loss: 0.0117783761
Iter: 91 loss: 0.0117776273
Iter: 92 loss: 0.011777564
Iter: 93 loss: 0.0117776822
Iter: 94 loss: 0.0117775388
Iter: 95 loss: 0.0117774792
Iter: 96 loss: 0.0117776599
Iter: 97 loss: 0.0117774643
Iter: 98 loss: 0.0117774159
Iter: 99 loss: 0.0117777912
Iter: 100 loss: 0.011777414
Iter: 101 loss: 0.0117773823
Iter: 102 loss: 0.011777482
Iter: 103 loss: 0.011777373
Iter: 104 loss: 0.0117773488
Iter: 105 loss: 0.0117774382
Iter: 106 loss: 0.0117773395
Iter: 107 loss: 0.0117773246
Iter: 108 loss: 0.0117774513
Iter: 109 loss: 0.0117773227
Iter: 110 loss: 0.0117773162
Iter: 111 loss: 0.0117773172
Iter: 112 loss: 0.0117773097
Iter: 113 loss: 0.0117772985
Iter: 114 loss: 0.0117774643
Iter: 115 loss: 0.0117772967
Iter: 116 loss: 0.0117772911
Iter: 117 loss: 0.0117773628
Iter: 118 loss: 0.0117772911
Iter: 119 loss: 0.0117772827
Iter: 120 loss: 0.0117772808
Iter: 121 loss: 0.011777278
Iter: 122 loss: 0.0117772724
Iter: 123 loss: 0.011777319
Iter: 124 loss: 0.0117772743
Iter: 125 loss: 0.0117772697
Iter: 126 loss: 0.0117772911
Iter: 127 loss: 0.0117772669
Iter: 128 loss: 0.0117772641
Iter: 129 loss: 0.0117772687
Iter: 130 loss: 0.0117772669
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4
+ date
Tue Oct 27 17:51:21 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e672fe9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea9081488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ea9081f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e67330bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e67294c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e67294f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e4018a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e401cdf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e401b8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e4014c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e40117c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e400c50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e40117ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e400866a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e400bda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e4004af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e400658c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e400bd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e4003a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e400bd0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e200c78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e20070158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e200389d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8e20033f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd47c9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd477a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd47b08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd4757840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd47b02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd46ff488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd472cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd46e6510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd46ef2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd46927b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd46428c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8dd4654f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.142311499
Iter: 2 loss: 4830.30176
Iter: 3 loss: 933.349548
Iter: 4 loss: 0.139092535
Iter: 5 loss: 320.114532
Iter: 6 loss: 0.0592479184
Iter: 7 loss: 0.112447537
Iter: 8 loss: 0.069938086
Iter: 9 loss: 0.0585581362
Iter: 10 loss: 0.0475291125
Iter: 11 loss: 0.0470287427
Iter: 12 loss: 2.1862843
Iter: 13 loss: 0.123260498
Iter: 14 loss: 0.0467490926
Iter: 15 loss: 0.0443772599
Iter: 16 loss: 0.0434215963
Iter: 17 loss: 0.0418000743
Iter: 18 loss: 0.0438305773
Iter: 19 loss: 0.0409284383
Iter: 20 loss: 0.0372748822
Iter: 21 loss: 0.0378953
Iter: 22 loss: 0.0347638428
Iter: 23 loss: 0.0321061946
Iter: 24 loss: 0.104040489
Iter: 25 loss: 0.0320086107
Iter: 26 loss: 0.0310341399
Iter: 27 loss: 0.0424404517
Iter: 28 loss: 0.0309573598
Iter: 29 loss: 0.0297386739
Iter: 30 loss: 0.0294461641
Iter: 31 loss: 0.0285400227
Iter: 32 loss: 0.0265418869
Iter: 33 loss: 0.0355427638
Iter: 34 loss: 0.0262515843
Iter: 35 loss: 0.0257593133
Iter: 36 loss: 0.0259067
Iter: 37 loss: 0.0254461914
Iter: 38 loss: 0.0242102519
Iter: 39 loss: 0.0233967304
Iter: 40 loss: 0.0228591301
Iter: 41 loss: 0.0215990152
Iter: 42 loss: 0.0276378803
Iter: 43 loss: 0.0213693436
Iter: 44 loss: 0.0206777118
Iter: 45 loss: 0.021258451
Iter: 46 loss: 0.0203219764
Iter: 47 loss: 0.0198131688
Iter: 48 loss: 0.0201525055
Iter: 49 loss: 0.0194686241
Iter: 50 loss: 0.0190376211
Iter: 51 loss: 0.0194388144
Iter: 52 loss: 0.0187775
Iter: 53 loss: 0.0182368942
Iter: 54 loss: 0.0190828554
Iter: 55 loss: 0.0179779343
Iter: 56 loss: 0.0176250786
Iter: 57 loss: 0.0175047331
Iter: 58 loss: 0.0172919855
Iter: 59 loss: 0.0166208111
Iter: 60 loss: 0.0167248845
Iter: 61 loss: 0.0160799474
Iter: 62 loss: 0.0155676045
Iter: 63 loss: 0.0155500406
Iter: 64 loss: 0.0152190262
Iter: 65 loss: 0.0155736348
Iter: 66 loss: 0.0150219081
Iter: 67 loss: 0.014604277
Iter: 68 loss: 0.0163767636
Iter: 69 loss: 0.014505771
Iter: 70 loss: 0.0141698467
Iter: 71 loss: 0.014210077
Iter: 72 loss: 0.0138961803
Iter: 73 loss: 0.0137194172
Iter: 74 loss: 0.0156928264
Iter: 75 loss: 0.0137171857
Iter: 76 loss: 0.0136690391
Iter: 77 loss: 0.0136486692
Iter: 78 loss: 0.013623043
Iter: 79 loss: 0.013530286
Iter: 80 loss: 0.0135810832
Iter: 81 loss: 0.0134697864
Iter: 82 loss: 0.0133486716
Iter: 83 loss: 0.0149894133
Iter: 84 loss: 0.0133470716
Iter: 85 loss: 0.0133462474
Iter: 86 loss: 0.0132806245
Iter: 87 loss: 0.0132416254
Iter: 88 loss: 0.0132093281
Iter: 89 loss: 0.013198155
Iter: 90 loss: 0.0131565491
Iter: 91 loss: 0.0131523097
Iter: 92 loss: 0.0131218806
Iter: 93 loss: 0.0131125627
Iter: 94 loss: 0.0131102614
Iter: 95 loss: 0.0131013338
Iter: 96 loss: 0.0130956061
Iter: 97 loss: 0.0130921658
Iter: 98 loss: 0.0130648762
Iter: 99 loss: 0.0132342838
Iter: 100 loss: 0.0130615365
Iter: 101 loss: 0.013043141
Iter: 102 loss: 0.013103432
Iter: 103 loss: 0.0130379396
Iter: 104 loss: 0.0130456761
Iter: 105 loss: 0.0130325463
Iter: 106 loss: 0.0130270664
Iter: 107 loss: 0.0130417468
Iter: 108 loss: 0.0130252857
Iter: 109 loss: 0.0130205872
Iter: 110 loss: 0.0130067011
Iter: 111 loss: 0.0130551085
Iter: 112 loss: 0.0130004138
Iter: 113 loss: 0.0129686575
Iter: 114 loss: 0.0130458679
Iter: 115 loss: 0.0129569732
Iter: 116 loss: 0.012933217
Iter: 117 loss: 0.0133053502
Iter: 118 loss: 0.0129332067
Iter: 119 loss: 0.0129204644
Iter: 120 loss: 0.0130898701
Iter: 121 loss: 0.0129203517
Iter: 122 loss: 0.0129127419
Iter: 123 loss: 0.0129115656
Iter: 124 loss: 0.0129062571
Iter: 125 loss: 0.012899938
Iter: 126 loss: 0.0129743237
Iter: 127 loss: 0.0128998319
Iter: 128 loss: 0.0128902607
Iter: 129 loss: 0.0128744189
Iter: 130 loss: 0.0128743518
Iter: 131 loss: 0.0128626153
Iter: 132 loss: 0.0128944162
Iter: 133 loss: 0.012858808
Iter: 134 loss: 0.012848855
Iter: 135 loss: 0.0128332432
Iter: 136 loss: 0.0128330365
Iter: 137 loss: 0.0128171407
Iter: 138 loss: 0.0128837321
Iter: 139 loss: 0.0128138252
Iter: 140 loss: 0.0127946418
Iter: 141 loss: 0.0129164904
Iter: 142 loss: 0.0127923992
Iter: 143 loss: 0.0127830449
Iter: 144 loss: 0.012760791
Iter: 145 loss: 0.0130050061
Iter: 146 loss: 0.0127586303
Iter: 147 loss: 0.012728706
Iter: 148 loss: 0.0128217647
Iter: 149 loss: 0.0127197988
Iter: 150 loss: 0.0126990229
Iter: 151 loss: 0.0128005398
Iter: 152 loss: 0.0126953442
Iter: 153 loss: 0.0126802353
Iter: 154 loss: 0.0126718199
Iter: 155 loss: 0.0126651842
Iter: 156 loss: 0.0126451645
Iter: 157 loss: 0.0127343908
Iter: 158 loss: 0.0126410816
Iter: 159 loss: 0.0126271658
Iter: 160 loss: 0.0126027716
Iter: 161 loss: 0.0126027688
Iter: 162 loss: 0.0126377139
Iter: 163 loss: 0.0125893736
Iter: 164 loss: 0.0125867222
Iter: 165 loss: 0.0125991795
Iter: 166 loss: 0.0125862332
Iter: 167 loss: 0.0125791794
Iter: 168 loss: 0.0125647541
Iter: 169 loss: 0.0128272474
Iter: 170 loss: 0.0125645027
Iter: 171 loss: 0.012553581
Iter: 172 loss: 0.0125512723
Iter: 173 loss: 0.0125507517
Iter: 174 loss: 0.012548916
Iter: 175 loss: 0.0125459842
Iter: 176 loss: 0.0125403851
Iter: 177 loss: 0.0126615278
Iter: 178 loss: 0.0125403628
Iter: 179 loss: 0.0125370128
Iter: 180 loss: 0.0125307133
Iter: 181 loss: 0.0126689682
Iter: 182 loss: 0.0125307012
Iter: 183 loss: 0.0125246346
Iter: 184 loss: 0.0125572821
Iter: 185 loss: 0.0125237126
Iter: 186 loss: 0.0125181358
Iter: 187 loss: 0.0125278197
Iter: 188 loss: 0.0125156781
Iter: 189 loss: 0.0125097334
Iter: 190 loss: 0.0125003709
Iter: 191 loss: 0.0125002684
Iter: 192 loss: 0.0124964295
Iter: 193 loss: 0.0124963867
Iter: 194 loss: 0.0124961771
Iter: 195 loss: 0.0124954786
Iter: 196 loss: 0.0124947093
Iter: 197 loss: 0.0124921827
Iter: 198 loss: 0.0124924947
Iter: 199 loss: 0.0124896318
Iter: 200 loss: 0.0124866311
Iter: 201 loss: 0.0124890842
Iter: 202 loss: 0.0124848373
Iter: 203 loss: 0.0124836806
Iter: 204 loss: 0.012484502
Iter: 205 loss: 0.0124829616
Iter: 206 loss: 0.0124819018
Iter: 207 loss: 0.0124788322
Iter: 208 loss: 0.012490388
Iter: 209 loss: 0.0124775078
Iter: 210 loss: 0.012474237
Iter: 211 loss: 0.012493548
Iter: 212 loss: 0.0124738086
Iter: 213 loss: 0.0124716582
Iter: 214 loss: 0.0124827251
Iter: 215 loss: 0.0124713145
Iter: 216 loss: 0.0124700125
Iter: 217 loss: 0.0124699408
Iter: 218 loss: 0.012469138
Iter: 219 loss: 0.0124680391
Iter: 220 loss: 0.0124679841
Iter: 221 loss: 0.0124673229
Iter: 222 loss: 0.012466725
Iter: 223 loss: 0.012466561
Iter: 224 loss: 0.0124659445
Iter: 225 loss: 0.0124669317
Iter: 226 loss: 0.0124656623
Iter: 227 loss: 0.0124653559
Iter: 228 loss: 0.0124690924
Iter: 229 loss: 0.0124653559
Iter: 230 loss: 0.0124650327
Iter: 231 loss: 0.0124654332
Iter: 232 loss: 0.0124648688
Iter: 233 loss: 0.0124643408
Iter: 234 loss: 0.0124632325
Iter: 235 loss: 0.0124804983
Iter: 236 loss: 0.0124631869
Iter: 237 loss: 0.0124653084
Iter: 238 loss: 0.0124628991
Iter: 239 loss: 0.0124628153
Iter: 240 loss: 0.0124626076
Iter: 241 loss: 0.0124649983
Iter: 242 loss: 0.0124625787
Iter: 243 loss: 0.0124621857
Iter: 244 loss: 0.0124621484
Iter: 245 loss: 0.012461856
Iter: 246 loss: 0.0124615356
Iter: 247 loss: 0.0124616772
Iter: 248 loss: 0.0124613224
Iter: 249 loss: 0.0124610225
Iter: 250 loss: 0.0124635156
Iter: 251 loss: 0.0124609927
Iter: 252 loss: 0.0124607291
Iter: 253 loss: 0.0124628702
Iter: 254 loss: 0.0124607179
Iter: 255 loss: 0.0124605764
Iter: 256 loss: 0.0124615049
Iter: 257 loss: 0.0124605708
Iter: 258 loss: 0.012460486
Iter: 259 loss: 0.0124604804
Iter: 260 loss: 0.0124604441
Iter: 261 loss: 0.0124603994
Iter: 262 loss: 0.0124603976
Iter: 263 loss: 0.0124602672
Iter: 264 loss: 0.0124601712
Iter: 265 loss: 0.01246012
Iter: 266 loss: 0.0124599831
Iter: 267 loss: 0.0124597847
Iter: 268 loss: 0.0124597754
Iter: 269 loss: 0.0124599468
Iter: 270 loss: 0.0124597084
Iter: 271 loss: 0.0124596469
Iter: 272 loss: 0.0124594877
Iter: 273 loss: 0.0124598108
Iter: 274 loss: 0.0124593815
Iter: 275 loss: 0.0124592101
Iter: 276 loss: 0.0124605056
Iter: 277 loss: 0.0124592036
Iter: 278 loss: 0.0124590974
Iter: 279 loss: 0.0124590453
Iter: 280 loss: 0.0124589987
Iter: 281 loss: 0.0124588851
Iter: 282 loss: 0.0124595743
Iter: 283 loss: 0.012458873
Iter: 284 loss: 0.0124587966
Iter: 285 loss: 0.0124593386
Iter: 286 loss: 0.0124587957
Iter: 287 loss: 0.0124587473
Iter: 288 loss: 0.0124587025
Iter: 289 loss: 0.012458697
Iter: 290 loss: 0.0124586448
Iter: 291 loss: 0.0124593237
Iter: 292 loss: 0.0124586448
Iter: 293 loss: 0.012458615
Iter: 294 loss: 0.0124586141
Iter: 295 loss: 0.012458602
Iter: 296 loss: 0.0124585908
Iter: 297 loss: 0.0124585852
Iter: 298 loss: 0.0124585535
Iter: 299 loss: 0.0124585694
Iter: 300 loss: 0.0124585461
Iter: 301 loss: 0.0124585405
Iter: 302 loss: 0.012458533
Iter: 303 loss: 0.0124585247
Iter: 304 loss: 0.0124584734
Iter: 305 loss: 0.0124585461
Iter: 306 loss: 0.0124584436
Iter: 307 loss: 0.0124584204
Iter: 308 loss: 0.0124584204
Iter: 309 loss: 0.0124584036
Iter: 310 loss: 0.0124583412
Iter: 311 loss: 0.0124587826
Iter: 312 loss: 0.0124583375
Iter: 313 loss: 0.0124582797
Iter: 314 loss: 0.0124583989
Iter: 315 loss: 0.0124582704
Iter: 316 loss: 0.012458276
Iter: 317 loss: 0.0124582555
Iter: 318 loss: 0.0124582369
Iter: 319 loss: 0.0124582108
Iter: 320 loss: 0.0124586402
Iter: 321 loss: 0.0124582071
Iter: 322 loss: 0.012458181
Iter: 323 loss: 0.0124582089
Iter: 324 loss: 0.0124581587
Iter: 325 loss: 0.0124581978
Iter: 326 loss: 0.0124581531
Iter: 327 loss: 0.0124581456
Iter: 328 loss: 0.0124581354
Iter: 329 loss: 0.0124581913
Iter: 330 loss: 0.0124581233
Iter: 331 loss: 0.0124580991
Iter: 332 loss: 0.0124581736
Iter: 333 loss: 0.0124580888
Iter: 334 loss: 0.0124581214
Iter: 335 loss: 0.0124580748
Iter: 336 loss: 0.0124580702
Iter: 337 loss: 0.0124580497
Iter: 338 loss: 0.0124581736
Iter: 339 loss: 0.0124580422
Iter: 340 loss: 0.0124580283
Iter: 341 loss: 0.0124580255
Iter: 342 loss: 0.0124580227
Iter: 343 loss: 0.012457991
Iter: 344 loss: 0.0124581438
Iter: 345 loss: 0.0124579854
Iter: 346 loss: 0.0124579687
Iter: 347 loss: 0.0124579892
Iter: 348 loss: 0.0124579743
Iter: 349 loss: 0.0124579594
Iter: 350 loss: 0.0124580897
Iter: 351 loss: 0.0124579603
Iter: 352 loss: 0.0124579556
Iter: 353 loss: 0.0124579463
Iter: 354 loss: 0.0124579426
Iter: 355 loss: 0.0124579258
Iter: 356 loss: 0.0124579379
Iter: 357 loss: 0.0124579333
Iter: 358 loss: 0.0124579109
Iter: 359 loss: 0.0124579528
Iter: 360 loss: 0.0124579184
Iter: 361 loss: 0.0124579035
Iter: 362 loss: 0.0124579612
Iter: 363 loss: 0.0124579016
Iter: 364 loss: 0.0124579016
Iter: 365 loss: 0.012457896
Iter: 366 loss: 0.012457883
Iter: 367 loss: 0.0124578774
Iter: 368 loss: 0.0124579035
Iter: 369 loss: 0.0124578765
Iter: 370 loss: 0.0124578793
Iter: 371 loss: 0.0124578737
Iter: 372 loss: 0.012457869
Iter: 373 loss: 0.0124578709
Iter: 374 loss: 0.0124578662
Iter: 375 loss: 0.0124578597
Iter: 376 loss: 0.0124578606
Iter: 377 loss: 0.0124578755
Iter: 378 loss: 0.0124578662
Iter: 379 loss: 0.0124578476
Iter: 380 loss: 0.0124578541
Iter: 381 loss: 0.0124578448
Iter: 382 loss: 0.0124578411
Iter: 383 loss: 0.0124578401
Iter: 384 loss: 0.0124578318
Iter: 385 loss: 0.012457829
Iter: 386 loss: 0.012457842
Iter: 387 loss: 0.0124578327
Iter: 388 loss: 0.0124578327
Iter: 389 loss: 0.0124578374
Iter: 390 loss: 0.0124578234
Iter: 391 loss: 0.012457828
Iter: 392 loss: 0.0124578392
Iter: 393 loss: 0.0124578271
Iter: 394 loss: 0.0124578215
Iter: 395 loss: 0.0124578234
Iter: 396 loss: 0.0124578234
Iter: 397 loss: 0.0124578215
Iter: 398 loss: 0.0124578215
Iter: 399 loss: 0.0124578169
Iter: 400 loss: 0.0124578234
Iter: 401 loss: 0.0124578271
Iter: 402 loss: 0.0124578178
Iter: 403 loss: 0.0124578113
Iter: 404 loss: 0.0124578197
Iter: 405 loss: 0.0124578215
Iter: 406 loss: 0.0124578169
Iter: 407 loss: 0.0124578159
Iter: 408 loss: 0.0124578606
Iter: 409 loss: 0.012457815
Iter: 410 loss: 0.0124578113
Iter: 411 loss: 0.0124578103
Iter: 412 loss: 0.0124578048
Iter: 413 loss: 0.0124578141
Iter: 414 loss: 0.0124578038
Iter: 415 loss: 0.0124578364
Iter: 416 loss: 0.0124578029
Iter: 417 loss: 0.012457802
Iter: 418 loss: 0.0124578048
Iter: 419 loss: 0.012457802
Iter: 420 loss: 0.0124578197
Iter: 421 loss: 0.0124577992
Iter: 422 loss: 0.0124577982
Iter: 423 loss: 0.0124578178
Iter: 424 loss: 0.0124578029
Iter: 425 loss: 0.0124577973
Iter: 426 loss: 0.0124577982
Iter: 427 loss: 0.0124577982
Iter: 428 loss: 0.012457801
Iter: 429 loss: 0.0124578159
Iter: 430 loss: 0.012457801
Iter: 431 loss: 0.0124577992
Iter: 432 loss: 0.0124578075
Iter: 433 loss: 0.0124577926
Iter: 434 loss: 0.0124577954
Iter: 435 loss: 0.0124577964
Iter: 436 loss: 0.0124577945
Iter: 437 loss: 0.0124577926
Iter: 438 loss: 0.0124577899
Iter: 439 loss: 0.0124577954
Iter: 440 loss: 0.0124577982
Iter: 441 loss: 0.0124577917
Iter: 442 loss: 0.0124577833
Iter: 443 loss: 0.012457788
Iter: 444 loss: 0.0124577899
Iter: 445 loss: 0.0124577871
Iter: 446 loss: 0.0124577852
Iter: 447 loss: 0.0124577824
Iter: 448 loss: 0.0124577768
Iter: 449 loss: 0.0124577861
Iter: 450 loss: 0.0124577796
Iter: 451 loss: 0.0124577824
Iter: 452 loss: 0.0124577861
Iter: 453 loss: 0.0124577805
Iter: 454 loss: 0.012457775
Iter: 455 loss: 0.0124577805
Iter: 456 loss: 0.0124577843
Iter: 457 loss: 0.012457775
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8
+ date
Tue Oct 27 17:52:16 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7febb07d02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7febb07d0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb95524f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb95524158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb954b50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb954c8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb954c8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb954c89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9545f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb953f19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9545f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb953dfe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb953df840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9532cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb952e39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb952f1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9530c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb952e30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9530ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9531aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb952dee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb952de510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9520d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb951b86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb951b88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9516a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb951949d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb95140840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb95194a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb950e8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9511ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb950d2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb950d61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb9507d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb95031a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feb95043f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.124299705
Iter: 2 loss: 4.04491901
Iter: 3 loss: 3.87361097
Iter: 4 loss: 2.03640699
Iter: 5 loss: 1.96803617
Iter: 6 loss: 1.10105443
Iter: 7 loss: 1.06466091
Iter: 8 loss: 0.607424617
Iter: 9 loss: 0.584717333
Iter: 10 loss: 0.328740507
Iter: 11 loss: 0.313268363
Iter: 12 loss: 0.167572126
Iter: 13 loss: 0.157402202
Iter: 14 loss: 0.0806629807
Iter: 15 loss: 0.0757107809
Iter: 16 loss: 0.0707898
Iter: 17 loss: 0.052640833
Iter: 18 loss: 390.724182
Iter: 19 loss: 0.0526396632
Iter: 20 loss: 307.901642
Iter: 21 loss: 0.0526394323
Iter: 22 loss: 3930.38
Iter: 23 loss: 0.052639436
Iter: 24 loss: 0.0374472179
Iter: 25 loss: 0.0349304788
Iter: 26 loss: 0.042565383
Iter: 27 loss: 0.033855129
Iter: 28 loss: 0.0300758854
Iter: 29 loss: 0.0300758462
Iter: 30 loss: 0.0280543026
Iter: 31 loss: 0.0297447238
Iter: 32 loss: 0.0266598929
Iter: 33 loss: 0.0244194325
Iter: 34 loss: 0.0262743197
Iter: 35 loss: 0.0231937114
Iter: 36 loss: 0.0218748823
Iter: 37 loss: 0.0269769728
Iter: 38 loss: 0.0215698611
Iter: 39 loss: 0.020758329
Iter: 40 loss: 0.0216575749
Iter: 41 loss: 0.0202887524
Iter: 42 loss: 0.0199156962
Iter: 43 loss: 0.0199069623
Iter: 44 loss: 0.019809071
Iter: 45 loss: 0.020075269
Iter: 46 loss: 0.019776769
Iter: 47 loss: 0.0197215565
Iter: 48 loss: 0.0197533052
Iter: 49 loss: 0.0196856111
Iter: 50 loss: 0.019651534
Iter: 51 loss: 0.0197186898
Iter: 52 loss: 0.0196375363
Iter: 53 loss: 0.0196089521
Iter: 54 loss: 0.0198100246
Iter: 55 loss: 0.0196063556
Iter: 56 loss: 0.0195927769
Iter: 57 loss: 0.0195895098
Iter: 58 loss: 0.0195808504
Iter: 59 loss: 0.0195711702
Iter: 60 loss: 0.019570956
Iter: 61 loss: 0.0195619613
Iter: 62 loss: 0.0195618793
Iter: 63 loss: 0.0195587724
Iter: 64 loss: 0.0195524059
Iter: 65 loss: 0.0196655411
Iter: 66 loss: 0.0195522793
Iter: 67 loss: 0.0195418186
Iter: 68 loss: 0.0196640063
Iter: 69 loss: 0.0195416585
Iter: 70 loss: 0.0195365585
Iter: 71 loss: 0.0195502713
Iter: 72 loss: 0.019534871
Iter: 73 loss: 0.0195294842
Iter: 74 loss: 0.0195289738
Iter: 75 loss: 0.0195250139
Iter: 76 loss: 0.0195208546
Iter: 77 loss: 0.0195208509
Iter: 78 loss: 0.0195174515
Iter: 79 loss: 0.0195136387
Iter: 80 loss: 0.0195131227
Iter: 81 loss: 0.0195087604
Iter: 82 loss: 0.019508753
Iter: 83 loss: 0.0195066109
Iter: 84 loss: 0.0195060298
Iter: 85 loss: 0.0195047148
Iter: 86 loss: 0.0195015
Iter: 87 loss: 0.0195137952
Iter: 88 loss: 0.0195007399
Iter: 89 loss: 0.0194982011
Iter: 90 loss: 0.0195009522
Iter: 91 loss: 0.0194968078
Iter: 92 loss: 0.0194993988
Iter: 93 loss: 0.0194956381
Iter: 94 loss: 0.0194951054
Iter: 95 loss: 0.0194936842
Iter: 96 loss: 0.0195039138
Iter: 97 loss: 0.0194933787
Iter: 98 loss: 0.0194921643
Iter: 99 loss: 0.0194904134
Iter: 100 loss: 0.0194903575
Iter: 101 loss: 0.0194880217
Iter: 102 loss: 0.0194910951
Iter: 103 loss: 0.0194868334
Iter: 104 loss: 0.0194856748
Iter: 105 loss: 0.0194853
Iter: 106 loss: 0.0194845293
Iter: 107 loss: 0.0194837824
Iter: 108 loss: 0.0194836147
Iter: 109 loss: 0.0194823761
Iter: 110 loss: 0.0194859765
Iter: 111 loss: 0.0194819923
Iter: 112 loss: 0.0194806494
Iter: 113 loss: 0.019482296
Iter: 114 loss: 0.019479949
Iter: 115 loss: 0.0194792375
Iter: 116 loss: 0.0194792263
Iter: 117 loss: 0.0194785539
Iter: 118 loss: 0.0194786564
Iter: 119 loss: 0.0194780491
Iter: 120 loss: 0.0194774661
Iter: 121 loss: 0.0194786955
Iter: 122 loss: 0.0194772407
Iter: 123 loss: 0.0194779709
Iter: 124 loss: 0.0194771066
Iter: 125 loss: 0.0194769651
Iter: 126 loss: 0.0194766559
Iter: 127 loss: 0.0194814093
Iter: 128 loss: 0.0194766447
Iter: 129 loss: 0.0194763504
Iter: 130 loss: 0.0194768552
Iter: 131 loss: 0.01947622
Iter: 132 loss: 0.0194759
Iter: 133 loss: 0.0194761027
Iter: 134 loss: 0.0194756985
Iter: 135 loss: 0.0194753464
Iter: 136 loss: 0.0194760822
Iter: 137 loss: 0.019475203
Iter: 138 loss: 0.0194750465
Iter: 139 loss: 0.0194750242
Iter: 140 loss: 0.019474877
Iter: 141 loss: 0.0194747783
Iter: 142 loss: 0.0194747187
Iter: 143 loss: 0.0194744896
Iter: 144 loss: 0.0194744915
Iter: 145 loss: 0.0194743127
Iter: 146 loss: 0.0194741432
Iter: 147 loss: 0.0194756016
Iter: 148 loss: 0.0194741338
Iter: 149 loss: 0.0194740035
Iter: 150 loss: 0.0194750316
Iter: 151 loss: 0.0194739867
Iter: 152 loss: 0.0194739439
Iter: 153 loss: 0.0194740705
Iter: 154 loss: 0.0194739215
Iter: 155 loss: 0.0194738675
Iter: 156 loss: 0.0194739923
Iter: 157 loss: 0.0194738396
Iter: 158 loss: 0.0194737948
Iter: 159 loss: 0.0194737911
Iter: 160 loss: 0.0194737799
Iter: 161 loss: 0.019473739
Iter: 162 loss: 0.01947386
Iter: 163 loss: 0.0194737166
Iter: 164 loss: 0.0194736738
Iter: 165 loss: 0.0194738694
Iter: 166 loss: 0.0194736533
Iter: 167 loss: 0.0194736123
Iter: 168 loss: 0.0194738358
Iter: 169 loss: 0.0194736067
Iter: 170 loss: 0.0194735788
Iter: 171 loss: 0.0194737092
Iter: 172 loss: 0.0194735713
Iter: 173 loss: 0.0194735546
Iter: 174 loss: 0.0194735341
Iter: 175 loss: 0.0194735304
Iter: 176 loss: 0.0194735117
Iter: 177 loss: 0.0194735099
Iter: 178 loss: 0.019473495
Iter: 179 loss: 0.0194735304
Iter: 180 loss: 0.0194734856
Iter: 181 loss: 0.0194734763
Iter: 182 loss: 0.0194734856
Iter: 183 loss: 0.0194734707
Iter: 184 loss: 0.0194734558
Iter: 185 loss: 0.0194735639
Iter: 186 loss: 0.0194734596
Iter: 187 loss: 0.0194734596
Iter: 188 loss: 0.0194734782
Iter: 189 loss: 0.0194734558
Iter: 190 loss: 0.0194734521
Iter: 191 loss: 0.0194734521
Iter: 192 loss: 0.0194734503
Iter: 193 loss: 0.0194734428
Iter: 194 loss: 0.0194735136
Iter: 195 loss: 0.0194734409
Iter: 196 loss: 0.0194734298
Iter: 197 loss: 0.0194734372
Iter: 198 loss: 0.0194734372
Iter: 199 loss: 0.0194734335
Iter: 200 loss: 0.0194734335
Iter: 201 loss: 0.0194734298
Iter: 202 loss: 0.0194734242
Iter: 203 loss: 0.0194734819
Iter: 204 loss: 0.0194734223
Iter: 205 loss: 0.0194734186
Iter: 206 loss: 0.0194734186
Iter: 207 loss: 0.0194734186
Iter: 208 loss: 0.0194734186
Iter: 209 loss: 0.0194734298
Iter: 210 loss: 0.0194734186
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3
+ date
Tue Oct 27 17:52:55 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi2.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 2 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f744ea3f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f744ea3f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f744e9c9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f744e9c96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f744e95ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f744e9806a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f74280b6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f74280796a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7428079488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f742800ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f741010a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f74100c5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f74100c5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7410078488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f74100afae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f741003dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f74100566a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f74100af598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c4736840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c4736b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c47548c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c4700d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c46ca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c4671730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c4671a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c46a1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c465d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c465d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c45fed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c465dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c45d7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c458f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c458f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c45a6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c44f2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f73c4501d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0430850089
Iter: 2 loss: 0.699462414
Iter: 3 loss: 0.545860767
Iter: 4 loss: 0.281836659
Iter: 5 loss: 0.206264973
Iter: 6 loss: 0.0944627449
Iter: 7 loss: 0.0637559593
Iter: 8 loss: 0.0302955359
Iter: 9 loss: 0.0262249447
Iter: 10 loss: 0.0242542811
Iter: 11 loss: 0.0272032768
Iter: 12 loss: 0.022997424
Iter: 13 loss: 0.022368554
Iter: 14 loss: 0.03478048
Iter: 15 loss: 0.0223598033
Iter: 16 loss: 0.0218522977
Iter: 17 loss: 0.0212009586
Iter: 18 loss: 0.0211659856
Iter: 19 loss: 0.0206967
Iter: 20 loss: 0.023496978
Iter: 21 loss: 0.0206521116
Iter: 22 loss: 0.0204993449
Iter: 23 loss: 0.0204256512
Iter: 24 loss: 0.0203511063
Iter: 25 loss: 0.020228181
Iter: 26 loss: 0.0211421102
Iter: 27 loss: 0.0202175584
Iter: 28 loss: 0.020190414
Iter: 29 loss: 0.0203882046
Iter: 30 loss: 0.0201882515
Iter: 31 loss: 0.0201760642
Iter: 32 loss: 0.020225402
Iter: 33 loss: 0.0201734044
Iter: 34 loss: 0.0201630816
Iter: 35 loss: 0.020169206
Iter: 36 loss: 0.0201564468
Iter: 37 loss: 0.020146478
Iter: 38 loss: 0.020196151
Iter: 39 loss: 0.0201448388
Iter: 40 loss: 0.0201407224
Iter: 41 loss: 0.0201716367
Iter: 42 loss: 0.0201404095
Iter: 43 loss: 0.0201385841
Iter: 44 loss: 0.0201452672
Iter: 45 loss: 0.0201381389
Iter: 46 loss: 0.0201371182
Iter: 47 loss: 0.02013712
Iter: 48 loss: 0.0201364961
Iter: 49 loss: 0.0201453529
Iter: 50 loss: 0.0201364942
Iter: 51 loss: 0.0201363135
Iter: 52 loss: 0.0201358944
Iter: 53 loss: 0.0201411359
Iter: 54 loss: 0.0201358628
Iter: 55 loss: 0.020135412
Iter: 56 loss: 0.0201362036
Iter: 57 loss: 0.0201352127
Iter: 58 loss: 0.0201347694
Iter: 59 loss: 0.0201358609
Iter: 60 loss: 0.0201346092
Iter: 61 loss: 0.0201341659
Iter: 62 loss: 0.0201360211
Iter: 63 loss: 0.0201340728
Iter: 64 loss: 0.0201336779
Iter: 65 loss: 0.0201347545
Iter: 66 loss: 0.0201335475
Iter: 67 loss: 0.0201332886
Iter: 68 loss: 0.020136971
Iter: 69 loss: 0.0201332942
Iter: 70 loss: 0.0201331116
Iter: 71 loss: 0.0201331042
Iter: 72 loss: 0.0201329701
Iter: 73 loss: 0.020132795
Iter: 74 loss: 0.0201343
Iter: 75 loss: 0.0201327857
Iter: 76 loss: 0.0201326758
Iter: 77 loss: 0.0201330315
Iter: 78 loss: 0.0201326385
Iter: 79 loss: 0.0201325417
Iter: 80 loss: 0.0201328918
Iter: 81 loss: 0.0201325156
Iter: 82 loss: 0.0201324672
Iter: 83 loss: 0.0201324522
Iter: 84 loss: 0.0201324113
Iter: 85 loss: 0.0201323163
Iter: 86 loss: 0.0201337617
Iter: 87 loss: 0.0201323107
Iter: 88 loss: 0.0201322306
Iter: 89 loss: 0.0201323479
Iter: 90 loss: 0.0201321915
Iter: 91 loss: 0.0201320909
Iter: 92 loss: 0.0201321989
Iter: 93 loss: 0.0201320387
Iter: 94 loss: 0.0201319512
Iter: 95 loss: 0.0201324802
Iter: 96 loss: 0.02013194
Iter: 97 loss: 0.020131886
Iter: 98 loss: 0.0201321505
Iter: 99 loss: 0.0201318786
Iter: 100 loss: 0.0201318394
Iter: 101 loss: 0.0201320723
Iter: 102 loss: 0.0201318339
Iter: 103 loss: 0.0201318
Iter: 104 loss: 0.0201319084
Iter: 105 loss: 0.0201317966
Iter: 106 loss: 0.0201317705
Iter: 107 loss: 0.0201318599
Iter: 108 loss: 0.0201317668
Iter: 109 loss: 0.0201317463
Iter: 110 loss: 0.020131804
Iter: 111 loss: 0.0201317463
Iter: 112 loss: 0.0201317295
Iter: 113 loss: 0.0201317761
Iter: 114 loss: 0.0201317258
Iter: 115 loss: 0.0201317258
Iter: 116 loss: 0.0201317221
Iter: 117 loss: 0.0201317184
Iter: 118 loss: 0.0201317184
Iter: 119 loss: 0.0201317146
Iter: 120 loss: 0.0201317072
Iter: 121 loss: 0.0201317035
Iter: 122 loss: 0.0201317035
Iter: 123 loss: 0.020131696
Iter: 124 loss: 0.0201317184
Iter: 125 loss: 0.020131696
Iter: 126 loss: 0.0201316886
Iter: 127 loss: 0.0201317184
Iter: 128 loss: 0.0201316886
Iter: 129 loss: 0.0201316811
Iter: 130 loss: 0.020131696
Iter: 131 loss: 0.0201316848
Iter: 132 loss: 0.0201316811
Iter: 133 loss: 0.0201317035
Iter: 134 loss: 0.0201316811
Iter: 135 loss: 0.0201316793
Iter: 136 loss: 0.0201316886
Iter: 137 loss: 0.0201316755
Iter: 138 loss: 0.0201316774
Iter: 139 loss: 0.0201316774
Iter: 140 loss: 0.0201316774
Iter: 141 loss: 0.0201316737
Iter: 142 loss: 0.0201316774
Iter: 143 loss: 0.0201316718
Iter: 144 loss: 0.0201316755
Iter: 145 loss: 0.0201316811
Iter: 146 loss: 0.0201316737
Iter: 147 loss: 0.0201316718
Iter: 148 loss: 0.0201316718
Iter: 149 loss: 0.0201316737
Iter: 150 loss: 0.0201316774
Iter: 151 loss: 0.0201316718
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi2_phi3/k2
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0
+ date
Tue Oct 27 17:53:30 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50d65400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50d83840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50d50378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50e38f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50e461e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50cfb048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50e46b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50cfb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50e46620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50ce86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50c50510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50c506a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50c508c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50bb1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50b61b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50b89d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50b9b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50b61f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50af8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50b588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50ab1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50a628c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50ad60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50a3f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50a3f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f509f8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f509f8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f509c1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f509c1ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f5097b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f5092ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f5097b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f508e0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f50919bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f509198c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f5085ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00501008332
Iter: 2 loss: 0.00498798536
Iter: 3 loss: 0.00490103755
Iter: 4 loss: 0.00450129714
Iter: 5 loss: 0.00341055566
Iter: 6 loss: 0.0298809744
Iter: 7 loss: 0.00338724162
Iter: 8 loss: 0.00266856281
Iter: 9 loss: 0.0165463854
Iter: 10 loss: 0.00266845711
Iter: 11 loss: 0.00219325535
Iter: 12 loss: 0.00387906353
Iter: 13 loss: 0.00206762552
Iter: 14 loss: 0.00172073022
Iter: 15 loss: 0.00341924885
Iter: 16 loss: 0.0016639973
Iter: 17 loss: 0.00139906164
Iter: 18 loss: 0.00212019123
Iter: 19 loss: 0.00130663312
Iter: 20 loss: 0.00110917236
Iter: 21 loss: 0.00181579497
Iter: 22 loss: 0.00105728942
Iter: 23 loss: 0.000913499738
Iter: 24 loss: 0.00299040321
Iter: 25 loss: 0.000913325581
Iter: 26 loss: 0.000825388473
Iter: 27 loss: 0.000814216677
Iter: 28 loss: 0.00075139635
Iter: 29 loss: 0.000655068492
Iter: 30 loss: 0.00096906
Iter: 31 loss: 0.000627153553
Iter: 32 loss: 0.000576427148
Iter: 33 loss: 0.000575508282
Iter: 34 loss: 0.000533054525
Iter: 35 loss: 0.00056828215
Iter: 36 loss: 0.000507762365
Iter: 37 loss: 0.000465097371
Iter: 38 loss: 0.000524890784
Iter: 39 loss: 0.000443961035
Iter: 40 loss: 0.000415110408
Iter: 41 loss: 0.000415062561
Iter: 42 loss: 0.000389439228
Iter: 43 loss: 0.000427144754
Iter: 44 loss: 0.000377000018
Iter: 45 loss: 0.000355625962
Iter: 46 loss: 0.000373839983
Iter: 47 loss: 0.000343102525
Iter: 48 loss: 0.000323547632
Iter: 49 loss: 0.000528870441
Iter: 50 loss: 0.000322998851
Iter: 51 loss: 0.000308113493
Iter: 52 loss: 0.000338254787
Iter: 53 loss: 0.000302056753
Iter: 54 loss: 0.000289198564
Iter: 55 loss: 0.000340861734
Iter: 56 loss: 0.000286384544
Iter: 57 loss: 0.000274997903
Iter: 58 loss: 0.000297007093
Iter: 59 loss: 0.000270220946
Iter: 60 loss: 0.000260739936
Iter: 61 loss: 0.000300420594
Iter: 62 loss: 0.000258717017
Iter: 63 loss: 0.000250107812
Iter: 64 loss: 0.000304713118
Iter: 65 loss: 0.000249155448
Iter: 66 loss: 0.000243100163
Iter: 67 loss: 0.000239114568
Iter: 68 loss: 0.000236814871
Iter: 69 loss: 0.000229512894
Iter: 70 loss: 0.000261886
Iter: 71 loss: 0.000228069373
Iter: 72 loss: 0.000223252078
Iter: 73 loss: 0.000298596569
Iter: 74 loss: 0.000223251351
Iter: 75 loss: 0.000219535912
Iter: 76 loss: 0.000217236928
Iter: 77 loss: 0.0002157423
Iter: 78 loss: 0.000211215316
Iter: 79 loss: 0.000222889503
Iter: 80 loss: 0.000209665537
Iter: 81 loss: 0.000206119759
Iter: 82 loss: 0.000247500284
Iter: 83 loss: 0.000206065073
Iter: 84 loss: 0.000202941475
Iter: 85 loss: 0.000206107637
Iter: 86 loss: 0.000201191404
Iter: 87 loss: 0.000198248483
Iter: 88 loss: 0.000202305819
Iter: 89 loss: 0.000196789159
Iter: 90 loss: 0.000193831729
Iter: 91 loss: 0.000214669635
Iter: 92 loss: 0.000193557178
Iter: 93 loss: 0.000191100058
Iter: 94 loss: 0.000194615437
Iter: 95 loss: 0.000189899292
Iter: 96 loss: 0.000187536585
Iter: 97 loss: 0.000202914729
Iter: 98 loss: 0.000187285885
Iter: 99 loss: 0.000185200581
Iter: 100 loss: 0.000187864382
Iter: 101 loss: 0.000184127246
Iter: 102 loss: 0.000182072676
Iter: 103 loss: 0.000182862044
Iter: 104 loss: 0.000180643954
Iter: 105 loss: 0.000178255475
Iter: 106 loss: 0.000189618891
Iter: 107 loss: 0.000177823662
Iter: 108 loss: 0.000175952402
Iter: 109 loss: 0.000198793015
Iter: 110 loss: 0.000175931855
Iter: 111 loss: 0.000174569825
Iter: 112 loss: 0.000173083128
Iter: 113 loss: 0.000172860018
Iter: 114 loss: 0.000170892978
Iter: 115 loss: 0.000180283037
Iter: 116 loss: 0.000170538027
Iter: 117 loss: 0.000168716535
Iter: 118 loss: 0.000181709169
Iter: 119 loss: 0.000168556464
Iter: 120 loss: 0.00016718352
Iter: 121 loss: 0.00016634239
Iter: 122 loss: 0.000165785212
Iter: 123 loss: 0.000163975739
Iter: 124 loss: 0.000169176055
Iter: 125 loss: 0.000163407152
Iter: 126 loss: 0.000161805568
Iter: 127 loss: 0.000176882924
Iter: 128 loss: 0.0001617425
Iter: 129 loss: 0.000160448428
Iter: 130 loss: 0.000161672273
Iter: 131 loss: 0.000159706964
Iter: 132 loss: 0.000158370327
Iter: 133 loss: 0.000166536367
Iter: 134 loss: 0.000158207142
Iter: 135 loss: 0.000157026603
Iter: 136 loss: 0.00015737208
Iter: 137 loss: 0.000156179216
Iter: 138 loss: 0.000154836671
Iter: 139 loss: 0.000157678427
Iter: 140 loss: 0.000154307781
Iter: 141 loss: 0.000153164219
Iter: 142 loss: 0.000167946797
Iter: 143 loss: 0.000153156216
Iter: 144 loss: 0.000152196793
Iter: 145 loss: 0.000151714456
Iter: 146 loss: 0.000151262793
Iter: 147 loss: 0.000150048727
Iter: 148 loss: 0.000151663611
Iter: 149 loss: 0.000149435669
Iter: 150 loss: 0.000148269493
Iter: 151 loss: 0.000157159957
Iter: 152 loss: 0.000148181891
Iter: 153 loss: 0.000147174083
Iter: 154 loss: 0.00015319747
Iter: 155 loss: 0.000147046754
Iter: 156 loss: 0.000146313381
Iter: 157 loss: 0.000145894242
Iter: 158 loss: 0.000145578859
Iter: 159 loss: 0.000144656689
Iter: 160 loss: 0.000151343498
Iter: 161 loss: 0.000144578589
Iter: 162 loss: 0.000143721874
Iter: 163 loss: 0.000146765902
Iter: 164 loss: 0.000143502082
Iter: 165 loss: 0.000142850971
Iter: 166 loss: 0.00014288348
Iter: 167 loss: 0.000142339428
Iter: 168 loss: 0.000141543947
Iter: 169 loss: 0.000147912127
Iter: 170 loss: 0.000141491444
Iter: 171 loss: 0.000140883669
Iter: 172 loss: 0.000141254524
Iter: 173 loss: 0.000140492732
Iter: 174 loss: 0.000139828539
Iter: 175 loss: 0.00014185645
Iter: 176 loss: 0.000139631054
Iter: 177 loss: 0.000139049676
Iter: 178 loss: 0.000145508486
Iter: 179 loss: 0.000139038457
Iter: 180 loss: 0.000138616117
Iter: 181 loss: 0.000138345596
Iter: 182 loss: 0.000138181
Iter: 183 loss: 0.000137630806
Iter: 184 loss: 0.000139067706
Iter: 185 loss: 0.000137444309
Iter: 186 loss: 0.000137018447
Iter: 187 loss: 0.000143279016
Iter: 188 loss: 0.000137018069
Iter: 189 loss: 0.000136666393
Iter: 190 loss: 0.000136632196
Iter: 191 loss: 0.000136374583
Iter: 192 loss: 0.00013598724
Iter: 193 loss: 0.000136448361
Iter: 194 loss: 0.000135782786
Iter: 195 loss: 0.000135454698
Iter: 196 loss: 0.000140200515
Iter: 197 loss: 0.000135454116
Iter: 198 loss: 0.000135181341
Iter: 199 loss: 0.000135560345
Iter: 200 loss: 0.000135046168
Iter: 201 loss: 0.000134797068
Iter: 202 loss: 0.00013511983
Iter: 203 loss: 0.000134670045
Iter: 204 loss: 0.000134411035
Iter: 205 loss: 0.000136377959
Iter: 206 loss: 0.000134391274
Iter: 207 loss: 0.000134191476
Iter: 208 loss: 0.000134411515
Iter: 209 loss: 0.00013408302
Iter: 210 loss: 0.000133883819
Iter: 211 loss: 0.000135270384
Iter: 212 loss: 0.000133865396
Iter: 213 loss: 0.000133702124
Iter: 214 loss: 0.000133748166
Iter: 215 loss: 0.000133584559
Iter: 216 loss: 0.000133401481
Iter: 217 loss: 0.000133703055
Iter: 218 loss: 0.000133317968
Iter: 219 loss: 0.000133146008
Iter: 220 loss: 0.000133803755
Iter: 221 loss: 0.000133105554
Iter: 222 loss: 0.000132985486
Iter: 223 loss: 0.000132985268
Iter: 224 loss: 0.000132899
Iter: 225 loss: 0.00013282639
Iter: 226 loss: 0.000132802204
Iter: 227 loss: 0.000132691377
Iter: 228 loss: 0.000133055859
Iter: 229 loss: 0.00013266044
Iter: 230 loss: 0.000132574205
Iter: 231 loss: 0.000133734837
Iter: 232 loss: 0.00013257371
Iter: 233 loss: 0.0001325099
Iter: 234 loss: 0.000132491841
Iter: 235 loss: 0.000132452886
Iter: 236 loss: 0.000132377565
Iter: 237 loss: 0.000132618734
Iter: 238 loss: 0.000132355912
Iter: 239 loss: 0.000132291156
Iter: 240 loss: 0.000132843445
Iter: 241 loss: 0.000132287401
Iter: 242 loss: 0.000132238434
Iter: 243 loss: 0.000132275149
Iter: 244 loss: 0.000132208428
Iter: 245 loss: 0.000132154732
Iter: 246 loss: 0.000132492685
Iter: 247 loss: 0.000132148416
Iter: 248 loss: 0.000132106463
Iter: 249 loss: 0.000132115922
Iter: 250 loss: 0.000132075278
Iter: 251 loss: 0.000132027897
Iter: 252 loss: 0.000132183777
Iter: 253 loss: 0.000132014684
Iter: 254 loss: 0.000131975277
Iter: 255 loss: 0.00013242173
Iter: 256 loss: 0.000131974608
Iter: 257 loss: 0.000131945824
Iter: 258 loss: 0.000131929672
Iter: 259 loss: 0.000131917011
Iter: 260 loss: 0.000131880195
Iter: 261 loss: 0.000131937602
Iter: 262 loss: 0.00013186298
Iter: 263 loss: 0.000131830326
Iter: 264 loss: 0.000132124813
Iter: 265 loss: 0.000131828827
Iter: 266 loss: 0.000131802517
Iter: 267 loss: 0.000131982248
Iter: 268 loss: 0.000131799985
Iter: 269 loss: 0.000131782101
Iter: 270 loss: 0.00013177123
Iter: 271 loss: 0.000131763576
Iter: 272 loss: 0.000131742243
Iter: 273 loss: 0.000131868845
Iter: 274 loss: 0.000131739682
Iter: 275 loss: 0.000131721696
Iter: 276 loss: 0.00013184041
Iter: 277 loss: 0.000131719833
Iter: 278 loss: 0.000131706882
Iter: 279 loss: 0.00013171832
Iter: 280 loss: 0.000131699373
Iter: 281 loss: 0.000131684981
Iter: 282 loss: 0.000131767243
Iter: 283 loss: 0.00013168274
Iter: 284 loss: 0.000131671317
Iter: 285 loss: 0.00013167657
Iter: 286 loss: 0.000131663648
Iter: 287 loss: 0.000131652574
Iter: 288 loss: 0.000131748238
Iter: 289 loss: 0.00013165173
Iter: 290 loss: 0.000131641951
Iter: 291 loss: 0.000131667097
Iter: 292 loss: 0.000131638793
Iter: 293 loss: 0.000131630688
Iter: 294 loss: 0.000131630062
Iter: 295 loss: 0.000131624271
Iter: 296 loss: 0.000131614855
Iter: 297 loss: 0.000131648179
Iter: 298 loss: 0.000131612323
Iter: 299 loss: 0.000131606037
Iter: 300 loss: 0.000131606081
Iter: 301 loss: 0.000131601118
Iter: 302 loss: 0.000131603651
Iter: 303 loss: 0.00013159767
Iter: 304 loss: 0.000131592809
Iter: 305 loss: 0.000131597248
Iter: 306 loss: 0.000131589783
Iter: 307 loss: 0.000131585199
Iter: 308 loss: 0.000131647859
Iter: 309 loss: 0.000131585228
Iter: 310 loss: 0.000131581357
Iter: 311 loss: 0.000131584588
Iter: 312 loss: 0.000131579189
Iter: 313 loss: 0.000131575507
Iter: 314 loss: 0.000131583045
Iter: 315 loss: 0.000131573979
Iter: 316 loss: 0.000131570414
Iter: 317 loss: 0.000131591398
Iter: 318 loss: 0.000131569774
Iter: 319 loss: 0.000131567154
Iter: 320 loss: 0.000131569526
Iter: 321 loss: 0.000131565466
Iter: 322 loss: 0.000131562905
Iter: 323 loss: 0.000131588517
Iter: 324 loss: 0.000131562876
Iter: 325 loss: 0.000131560635
Iter: 326 loss: 0.000131563342
Iter: 327 loss: 0.000131559471
Iter: 328 loss: 0.000131557361
Iter: 329 loss: 0.000131558991
Iter: 330 loss: 0.000131556255
Iter: 331 loss: 0.000131554363
Iter: 332 loss: 0.000131578301
Iter: 333 loss: 0.000131554247
Iter: 334 loss: 0.000131552908
Iter: 335 loss: 0.00013155464
Iter: 336 loss: 0.000131552079
Iter: 337 loss: 0.000131550696
Iter: 338 loss: 0.000131550813
Iter: 339 loss: 0.000131549576
Iter: 340 loss: 0.000131547829
Iter: 341 loss: 0.000131555338
Iter: 342 loss: 0.000131547509
Iter: 343 loss: 0.000131546316
Iter: 344 loss: 0.000131546374
Iter: 345 loss: 0.00013154553
Iter: 346 loss: 0.000131545617
Iter: 347 loss: 0.000131544948
Iter: 348 loss: 0.000131544119
Iter: 349 loss: 0.000131546825
Iter: 350 loss: 0.000131543726
Iter: 351 loss: 0.000131542824
Iter: 352 loss: 0.000131547422
Iter: 353 loss: 0.000131542882
Iter: 354 loss: 0.00013154211
Iter: 355 loss: 0.000131543202
Iter: 356 loss: 0.000131541732
Iter: 357 loss: 0.000131541019
Iter: 358 loss: 0.000131546534
Iter: 359 loss: 0.000131540961
Iter: 360 loss: 0.000131540437
Iter: 361 loss: 0.000131540553
Iter: 362 loss: 0.000131540059
Iter: 363 loss: 0.000131539447
Iter: 364 loss: 0.000131540728
Iter: 365 loss: 0.000131539258
Iter: 366 loss: 0.000131538865
Iter: 367 loss: 0.000131539
Iter: 368 loss: 0.0001315384
Iter: 369 loss: 0.000131538385
Iter: 370 loss: 0.000131538109
Iter: 371 loss: 0.000131537672
Iter: 372 loss: 0.0001315384
Iter: 373 loss: 0.000131537585
Iter: 374 loss: 0.000131537265
Iter: 375 loss: 0.000131541659
Iter: 376 loss: 0.000131537206
Iter: 377 loss: 0.000131536915
Iter: 378 loss: 0.000131537454
Iter: 379 loss: 0.000131536857
Iter: 380 loss: 0.000131536566
Iter: 381 loss: 0.000131536683
Iter: 382 loss: 0.00013153645
Iter: 383 loss: 0.000131536246
Iter: 384 loss: 0.000131538487
Iter: 385 loss: 0.000131536217
Iter: 386 loss: 0.000131536115
Iter: 387 loss: 0.00013153677
Iter: 388 loss: 0.000131535926
Iter: 389 loss: 0.000131535766
Iter: 390 loss: 0.000131536115
Iter: 391 loss: 0.000131535693
Iter: 392 loss: 0.000131535562
Iter: 393 loss: 0.000131536115
Iter: 394 loss: 0.000131535533
Iter: 395 loss: 0.000131535286
Iter: 396 loss: 0.00013153546
Iter: 397 loss: 0.000131535373
Iter: 398 loss: 0.000131535096
Iter: 399 loss: 0.000131535868
Iter: 400 loss: 0.000131535053
Iter: 401 loss: 0.000131534922
Iter: 402 loss: 0.000131536421
Iter: 403 loss: 0.000131535009
Iter: 404 loss: 0.000131534864
Iter: 405 loss: 0.000131534922
Iter: 406 loss: 0.00013153482
Iter: 407 loss: 0.000131534689
Iter: 408 loss: 0.000131535038
Iter: 409 loss: 0.000131534573
Iter: 410 loss: 0.000131534587
Iter: 411 loss: 0.000131535693
Iter: 412 loss: 0.000131534674
Iter: 413 loss: 0.0001315345
Iter: 414 loss: 0.000131534456
Iter: 415 loss: 0.000131534427
Iter: 416 loss: 0.000131534514
Iter: 417 loss: 0.000131534558
Iter: 418 loss: 0.00013153418
Iter: 419 loss: 0.000131534282
Iter: 420 loss: 0.000131535
Iter: 421 loss: 0.000131534311
Iter: 422 loss: 0.000131534151
Iter: 423 loss: 0.000131534325
Iter: 424 loss: 0.000131534209
Iter: 425 loss: 0.000131534034
Iter: 426 loss: 0.000131534165
Iter: 427 loss: 0.000131534136
Iter: 428 loss: 0.000131533918
Iter: 429 loss: 0.000131534354
Iter: 430 loss: 0.000131534151
Iter: 431 loss: 0.000131533918
Iter: 432 loss: 0.000131534063
Iter: 433 loss: 0.000131533947
Iter: 434 loss: 0.000131534
Iter: 435 loss: 0.000131534456
Iter: 436 loss: 0.000131533801
Iter: 437 loss: 0.000131533961
Iter: 438 loss: 0.00013153386
Iter: 439 loss: 0.000131534063
Iter: 440 loss: 0.00013153383
Iter: 441 loss: 0.000131533947
Iter: 442 loss: 0.00013153386
Iter: 443 loss: 0.000131533947
Iter: 444 loss: 0.000131533947
Iter: 445 loss: 0.00013153386
Iter: 446 loss: 0.000131533874
Iter: 447 loss: 0.000131533918
Iter: 448 loss: 0.000131533918
Iter: 449 loss: 0.000131533932
Iter: 450 loss: 0.000131533932
Iter: 451 loss: 0.000131533918
Iter: 452 loss: 0.000131533947
Iter: 453 loss: 0.000131533932
Iter: 454 loss: 0.000131533947
Iter: 455 loss: 0.000131533947
Iter: 456 loss: 0.000131533947
Iter: 457 loss: 0.000131533947
Iter: 458 loss: 0.000131533947
Iter: 459 loss: 0.000131533947
Iter: 460 loss: 0.000131533932
Iter: 461 loss: 0.000131533947
Iter: 462 loss: 0.000131533932
Iter: 463 loss: 0.000131533801
Iter: 464 loss: 0.000131534252
Iter: 465 loss: 0.000131533918
Iter: 466 loss: 0.000131533772
Iter: 467 loss: 0.000131533874
Iter: 468 loss: 0.000131533889
Iter: 469 loss: 0.00013153383
Iter: 470 loss: 0.000131533772
Iter: 471 loss: 0.00013153383
Iter: 472 loss: 0.000131533656
Iter: 473 loss: 0.00013153386
Iter: 474 loss: 0.000131533845
Iter: 475 loss: 0.00013153383
Iter: 476 loss: 0.000131533743
Iter: 477 loss: 0.000131533743
Iter: 478 loss: 0.000131533918
Iter: 479 loss: 0.000131533772
Iter: 480 loss: 0.000131533845
Iter: 481 loss: 0.000131533714
Iter: 482 loss: 0.000131533743
Iter: 483 loss: 0.000131533729
Iter: 484 loss: 0.000131533918
Iter: 485 loss: 0.000131533743
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4
+ date
Tue Oct 27 18:00:10 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdfbe699d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fce3d413488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fce3d413d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fce3d413ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdfbe089d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdfbe18ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdfbdecd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdfbdeca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd43e8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4375598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd43e8268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd435aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd42fb9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4342400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd42eb9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd426dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4287840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd42eb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd42551e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd421b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd421b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd421b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4197950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4130950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4130620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd416a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd41278c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4127400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd40c7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4127620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd409d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd40581e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdd4061268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdc07d0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdc07839d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcdc079af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0236843228
Iter: 2 loss: 0.023285497
Iter: 3 loss: 0.0217443965
Iter: 4 loss: 0.0152833927
Iter: 5 loss: 0.0119861104
Iter: 6 loss: 0.00737729901
Iter: 7 loss: 0.00400583399
Iter: 8 loss: 0.00383294513
Iter: 9 loss: 0.0023200009
Iter: 10 loss: 0.0121285822
Iter: 11 loss: 0.00203928957
Iter: 12 loss: 0.00138806284
Iter: 13 loss: 0.00460108742
Iter: 14 loss: 0.00126141356
Iter: 15 loss: 0.000915912737
Iter: 16 loss: 0.0053946469
Iter: 17 loss: 0.000913562428
Iter: 18 loss: 0.00071691128
Iter: 19 loss: 0.00322355283
Iter: 20 loss: 0.000715747185
Iter: 21 loss: 0.000618206395
Iter: 22 loss: 0.000710318156
Iter: 23 loss: 0.000562036468
Iter: 24 loss: 0.000471728825
Iter: 25 loss: 0.00100093661
Iter: 26 loss: 0.000459641975
Iter: 27 loss: 0.000401462719
Iter: 28 loss: 0.000532795792
Iter: 29 loss: 0.000379537116
Iter: 30 loss: 0.000335873716
Iter: 31 loss: 0.000532963546
Iter: 32 loss: 0.000327596877
Iter: 33 loss: 0.000295505684
Iter: 34 loss: 0.000388439483
Iter: 35 loss: 0.000285483431
Iter: 36 loss: 0.000264002651
Iter: 37 loss: 0.000322500069
Iter: 38 loss: 0.000256864529
Iter: 39 loss: 0.000238714871
Iter: 40 loss: 0.000362821069
Iter: 41 loss: 0.000237016618
Iter: 42 loss: 0.000224841133
Iter: 43 loss: 0.000259542168
Iter: 44 loss: 0.000220983813
Iter: 45 loss: 0.000210673854
Iter: 46 loss: 0.000250228884
Iter: 47 loss: 0.000208235491
Iter: 48 loss: 0.000200127251
Iter: 49 loss: 0.000222925795
Iter: 50 loss: 0.000197505957
Iter: 51 loss: 0.00019081682
Iter: 52 loss: 0.000232480757
Iter: 53 loss: 0.000190042279
Iter: 54 loss: 0.000184800156
Iter: 55 loss: 0.000199475937
Iter: 56 loss: 0.000183108801
Iter: 57 loss: 0.000178934017
Iter: 58 loss: 0.000202559182
Iter: 59 loss: 0.000178349379
Iter: 60 loss: 0.000174903602
Iter: 61 loss: 0.000188793463
Iter: 62 loss: 0.000174136832
Iter: 63 loss: 0.000171496882
Iter: 64 loss: 0.000174562301
Iter: 65 loss: 0.000170084473
Iter: 66 loss: 0.000167405262
Iter: 67 loss: 0.000172835804
Iter: 68 loss: 0.00016632161
Iter: 69 loss: 0.000163828867
Iter: 70 loss: 0.000177972252
Iter: 71 loss: 0.000163484554
Iter: 72 loss: 0.000161419768
Iter: 73 loss: 0.000167607577
Iter: 74 loss: 0.000160795826
Iter: 75 loss: 0.000159021045
Iter: 76 loss: 0.000162030221
Iter: 77 loss: 0.000158223
Iter: 78 loss: 0.000156618888
Iter: 79 loss: 0.000163348857
Iter: 80 loss: 0.000156277223
Iter: 81 loss: 0.00015493769
Iter: 82 loss: 0.000160200085
Iter: 83 loss: 0.000154629917
Iter: 84 loss: 0.000153491055
Iter: 85 loss: 0.000157235205
Iter: 86 loss: 0.000153175439
Iter: 87 loss: 0.0001522112
Iter: 88 loss: 0.000156274124
Iter: 89 loss: 0.000152006367
Iter: 90 loss: 0.000151205284
Iter: 91 loss: 0.000154514331
Iter: 92 loss: 0.000151032291
Iter: 93 loss: 0.00015035714
Iter: 94 loss: 0.000153028872
Iter: 95 loss: 0.000150202817
Iter: 96 loss: 0.000149618892
Iter: 97 loss: 0.000151703061
Iter: 98 loss: 0.000149469764
Iter: 99 loss: 0.000148972409
Iter: 100 loss: 0.000150065956
Iter: 101 loss: 0.00014878111
Iter: 102 loss: 0.000148284264
Iter: 103 loss: 0.000150143213
Iter: 104 loss: 0.000148163555
Iter: 105 loss: 0.000147757353
Iter: 106 loss: 0.000149228203
Iter: 107 loss: 0.000147655461
Iter: 108 loss: 0.000147288025
Iter: 109 loss: 0.000147986022
Iter: 110 loss: 0.000147133062
Iter: 111 loss: 0.000146790291
Iter: 112 loss: 0.000147610801
Iter: 113 loss: 0.000146666222
Iter: 114 loss: 0.000146324717
Iter: 115 loss: 0.000147780345
Iter: 116 loss: 0.000146253602
Iter: 117 loss: 0.000145975733
Iter: 118 loss: 0.000146284146
Iter: 119 loss: 0.000145825179
Iter: 120 loss: 0.000145543963
Iter: 121 loss: 0.000146546139
Iter: 122 loss: 0.000145472062
Iter: 123 loss: 0.00014522775
Iter: 124 loss: 0.00014645519
Iter: 125 loss: 0.000145187048
Iter: 126 loss: 0.000144973892
Iter: 127 loss: 0.000145509854
Iter: 128 loss: 0.00014489959
Iter: 129 loss: 0.000144716934
Iter: 130 loss: 0.000145616126
Iter: 131 loss: 0.000144685677
Iter: 132 loss: 0.000144531732
Iter: 133 loss: 0.000145268947
Iter: 134 loss: 0.00014450436
Iter: 135 loss: 0.000144379679
Iter: 136 loss: 0.000144686754
Iter: 137 loss: 0.000144335383
Iter: 138 loss: 0.000144217207
Iter: 139 loss: 0.000144592821
Iter: 140 loss: 0.000144183286
Iter: 141 loss: 0.000144083431
Iter: 142 loss: 0.000144378
Iter: 143 loss: 0.000144052872
Iter: 144 loss: 0.00014395309
Iter: 145 loss: 0.000144261634
Iter: 146 loss: 0.000143923971
Iter: 147 loss: 0.000143836951
Iter: 148 loss: 0.000143974306
Iter: 149 loss: 0.000143796467
Iter: 150 loss: 0.000143706478
Iter: 151 loss: 0.000144051766
Iter: 152 loss: 0.000143685393
Iter: 153 loss: 0.000143608981
Iter: 154 loss: 0.00014377461
Iter: 155 loss: 0.000143579382
Iter: 156 loss: 0.000143505691
Iter: 157 loss: 0.000143769372
Iter: 158 loss: 0.000143486977
Iter: 159 loss: 0.000143421232
Iter: 160 loss: 0.000143546087
Iter: 161 loss: 0.00014339335
Iter: 162 loss: 0.000143333426
Iter: 163 loss: 0.00014355185
Iter: 164 loss: 0.000143318583
Iter: 165 loss: 0.000143266283
Iter: 166 loss: 0.000143605022
Iter: 167 loss: 0.000143260739
Iter: 168 loss: 0.000143219862
Iter: 169 loss: 0.00014329722
Iter: 170 loss: 0.000143202487
Iter: 171 loss: 0.000143163867
Iter: 172 loss: 0.000143462792
Iter: 173 loss: 0.00014316116
Iter: 174 loss: 0.000143131823
Iter: 175 loss: 0.000143163939
Iter: 176 loss: 0.000143115903
Iter: 177 loss: 0.000143085563
Iter: 178 loss: 0.000143202386
Iter: 179 loss: 0.000143078418
Iter: 180 loss: 0.000143051089
Iter: 181 loss: 0.000143132405
Iter: 182 loss: 0.000143042824
Iter: 183 loss: 0.000143018216
Iter: 184 loss: 0.000143093799
Iter: 185 loss: 0.00014301078
Iter: 186 loss: 0.00014298837
Iter: 187 loss: 0.000143029873
Iter: 188 loss: 0.00014297865
Iter: 189 loss: 0.000142956967
Iter: 190 loss: 0.000143024736
Iter: 191 loss: 0.000142950928
Iter: 192 loss: 0.000142930687
Iter: 193 loss: 0.000142989637
Iter: 194 loss: 0.000142924604
Iter: 195 loss: 0.000142906574
Iter: 196 loss: 0.000142961551
Iter: 197 loss: 0.000142901146
Iter: 198 loss: 0.00014288415
Iter: 199 loss: 0.000142920311
Iter: 200 loss: 0.000142877572
Iter: 201 loss: 0.000142862
Iter: 202 loss: 0.000142918085
Iter: 203 loss: 0.000142857985
Iter: 204 loss: 0.000142845151
Iter: 205 loss: 0.000142926772
Iter: 206 loss: 0.000142843506
Iter: 207 loss: 0.000142832912
Iter: 208 loss: 0.000142861929
Iter: 209 loss: 0.000142829464
Iter: 210 loss: 0.000142819597
Iter: 211 loss: 0.000142871344
Iter: 212 loss: 0.00014281804
Iter: 213 loss: 0.00014281008
Iter: 214 loss: 0.000142819306
Iter: 215 loss: 0.000142805759
Iter: 216 loss: 0.000142797537
Iter: 217 loss: 0.0001428307
Iter: 218 loss: 0.000142795689
Iter: 219 loss: 0.00014278834
Iter: 220 loss: 0.000142812249
Iter: 221 loss: 0.000142786244
Iter: 222 loss: 0.000142779769
Iter: 223 loss: 0.000142796926
Iter: 224 loss: 0.000142777455
Iter: 225 loss: 0.000142771227
Iter: 226 loss: 0.000142779987
Iter: 227 loss: 0.000142768418
Iter: 228 loss: 0.000142761826
Iter: 229 loss: 0.000142789155
Iter: 230 loss: 0.0001427604
Iter: 231 loss: 0.000142754812
Iter: 232 loss: 0.000142768316
Iter: 233 loss: 0.000142752906
Iter: 234 loss: 0.000142747856
Iter: 235 loss: 0.000142763543
Iter: 236 loss: 0.000142746416
Iter: 237 loss: 0.00014274141
Iter: 238 loss: 0.000142755889
Iter: 239 loss: 0.00014274
Iter: 240 loss: 0.000142735807
Iter: 241 loss: 0.000142748875
Iter: 242 loss: 0.000142734498
Iter: 243 loss: 0.00014273102
Iter: 244 loss: 0.000142751698
Iter: 245 loss: 0.000142730307
Iter: 246 loss: 0.00014272728
Iter: 247 loss: 0.000142740217
Iter: 248 loss: 0.000142726698
Iter: 249 loss: 0.000142724195
Iter: 250 loss: 0.000142729652
Iter: 251 loss: 0.000142723264
Iter: 252 loss: 0.000142720513
Iter: 253 loss: 0.000142727949
Iter: 254 loss: 0.000142719655
Iter: 255 loss: 0.00014271737
Iter: 256 loss: 0.000142722914
Iter: 257 loss: 0.00014271657
Iter: 258 loss: 0.0001427143
Iter: 259 loss: 0.000142724544
Iter: 260 loss: 0.000142713834
Iter: 261 loss: 0.000142711913
Iter: 262 loss: 0.00014271331
Iter: 263 loss: 0.000142710676
Iter: 264 loss: 0.000142708799
Iter: 265 loss: 0.000142717967
Iter: 266 loss: 0.00014270813
Iter: 267 loss: 0.0001427065
Iter: 268 loss: 0.00014271072
Iter: 269 loss: 0.000142705743
Iter: 270 loss: 0.000142704041
Iter: 271 loss: 0.000142709061
Iter: 272 loss: 0.000142703706
Iter: 273 loss: 0.000142701887
Iter: 274 loss: 0.000142707489
Iter: 275 loss: 0.00014270164
Iter: 276 loss: 0.000142700155
Iter: 277 loss: 0.000142703546
Iter: 278 loss: 0.000142699602
Iter: 279 loss: 0.000142698264
Iter: 280 loss: 0.000142704201
Iter: 281 loss: 0.000142698205
Iter: 282 loss: 0.000142696983
Iter: 283 loss: 0.00014270372
Iter: 284 loss: 0.000142697012
Iter: 285 loss: 0.000142696139
Iter: 286 loss: 0.000142698351
Iter: 287 loss: 0.000142695862
Iter: 288 loss: 0.000142694975
Iter: 289 loss: 0.000142696372
Iter: 290 loss: 0.000142694567
Iter: 291 loss: 0.000142693912
Iter: 292 loss: 0.000142697434
Iter: 293 loss: 0.000142693752
Iter: 294 loss: 0.000142693068
Iter: 295 loss: 0.00014269448
Iter: 296 loss: 0.000142692472
Iter: 297 loss: 0.000142692152
Iter: 298 loss: 0.000142694393
Iter: 299 loss: 0.000142691759
Iter: 300 loss: 0.00014269122
Iter: 301 loss: 0.000142692035
Iter: 302 loss: 0.000142690886
Iter: 303 loss: 0.000142690275
Iter: 304 loss: 0.000142691759
Iter: 305 loss: 0.00014269
Iter: 306 loss: 0.00014268946
Iter: 307 loss: 0.000142693112
Iter: 308 loss: 0.000142689431
Iter: 309 loss: 0.000142688878
Iter: 310 loss: 0.00014268962
Iter: 311 loss: 0.00014268863
Iter: 312 loss: 0.00014268831
Iter: 313 loss: 0.000142689329
Iter: 314 loss: 0.00014268799
Iter: 315 loss: 0.000142687684
Iter: 316 loss: 0.000142689911
Iter: 317 loss: 0.000142687553
Iter: 318 loss: 0.000142687233
Iter: 319 loss: 0.000142688499
Iter: 320 loss: 0.000142687204
Iter: 321 loss: 0.00014268668
Iter: 322 loss: 0.000142688194
Iter: 323 loss: 0.000142686709
Iter: 324 loss: 0.00014268652
Iter: 325 loss: 0.000142686826
Iter: 326 loss: 0.000142686404
Iter: 327 loss: 0.000142686011
Iter: 328 loss: 0.000142687
Iter: 329 loss: 0.000142686127
Iter: 330 loss: 0.000142685691
Iter: 331 loss: 0.000142686578
Iter: 332 loss: 0.000142685691
Iter: 333 loss: 0.000142685487
Iter: 334 loss: 0.000142686156
Iter: 335 loss: 0.000142685385
Iter: 336 loss: 0.000142685181
Iter: 337 loss: 0.000142685836
Iter: 338 loss: 0.000142685036
Iter: 339 loss: 0.000142684963
Iter: 340 loss: 0.00014268524
Iter: 341 loss: 0.00014268473
Iter: 342 loss: 0.000142684614
Iter: 343 loss: 0.000142685079
Iter: 344 loss: 0.000142684556
Iter: 345 loss: 0.000142684366
Iter: 346 loss: 0.000142685603
Iter: 347 loss: 0.000142684381
Iter: 348 loss: 0.000142684148
Iter: 349 loss: 0.000142684527
Iter: 350 loss: 0.000142684294
Iter: 351 loss: 0.000142684061
Iter: 352 loss: 0.000142684439
Iter: 353 loss: 0.000142684134
Iter: 354 loss: 0.000142684032
Iter: 355 loss: 0.000142684803
Iter: 356 loss: 0.000142683843
Iter: 357 loss: 0.000142683682
Iter: 358 loss: 0.000142684235
Iter: 359 loss: 0.000142683799
Iter: 360 loss: 0.000142683682
Iter: 361 loss: 0.000142683915
Iter: 362 loss: 0.000142683726
Iter: 363 loss: 0.000142683537
Iter: 364 loss: 0.000142683653
Iter: 365 loss: 0.000142683537
Iter: 366 loss: 0.00014268329
Iter: 367 loss: 0.000142683959
Iter: 368 loss: 0.000142683362
Iter: 369 loss: 0.000142683421
Iter: 370 loss: 0.000142683493
Iter: 371 loss: 0.000142683159
Iter: 372 loss: 0.000142683348
Iter: 373 loss: 0.000142683304
Iter: 374 loss: 0.000142683319
Iter: 375 loss: 0.000142683246
Iter: 376 loss: 0.000142683159
Iter: 377 loss: 0.000142683319
Iter: 378 loss: 0.000142683173
Iter: 379 loss: 0.000142683246
Iter: 380 loss: 0.000142683246
Iter: 381 loss: 0.000142683246
Iter: 382 loss: 0.000142683246
Iter: 383 loss: 0.000142683217
Iter: 384 loss: 0.000142683304
Iter: 385 loss: 0.000142683275
Iter: 386 loss: 0.00014268329
Iter: 387 loss: 0.000142683275
Iter: 388 loss: 0.000142683275
Iter: 389 loss: 0.000142683319
Iter: 390 loss: 0.000142683275
Iter: 391 loss: 0.00014268329
Iter: 392 loss: 0.000142683304
Iter: 393 loss: 0.000142683304
Iter: 394 loss: 0.000142683304
Iter: 395 loss: 0.000142683304
Iter: 396 loss: 0.000142683319
Iter: 397 loss: 0.000142683304
Iter: 398 loss: 0.000142683159
Iter: 399 loss: 0.000142683799
Iter: 400 loss: 0.000142683115
Iter: 401 loss: 0.000142683042
Iter: 402 loss: 0.000142683246
Iter: 403 loss: 0.0001426831
Iter: 404 loss: 0.000142682926
Iter: 405 loss: 0.000142683639
Iter: 406 loss: 0.000142683
Iter: 407 loss: 0.000142683013
Iter: 408 loss: 0.000142682868
Iter: 409 loss: 0.000142682882
Iter: 410 loss: 0.000142682868
Iter: 411 loss: 0.00014268345
Iter: 412 loss: 0.000142682897
Iter: 413 loss: 0.00014268278
Iter: 414 loss: 0.000142682984
Iter: 415 loss: 0.000142682809
Iter: 416 loss: 0.000142682853
Iter: 417 loss: 0.00014268326
Iter: 418 loss: 0.000142682809
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8
+ date
Tue Oct 27 18:06:02 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeedde620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeedb9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeedb9ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeed838c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeece6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeece6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeec5e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeec8c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeec8c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeec34378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeebebbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeb9a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeebb2488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeb586a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeb916a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeb91598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeb1b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeaeec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeb0df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeb0dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeac98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeeac9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbeea438c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbee9e1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbee9f0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbee997a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbee9cc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd051c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd051c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd04bd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd04e7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd04a8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd04b0598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd0442158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd03fb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7efbd03fb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0171341244
Iter: 2 loss: 0.0167837311
Iter: 3 loss: 0.0154554471
Iter: 4 loss: 0.0111188395
Iter: 5 loss: 8366.01367
Iter: 6 loss: 0.0111188386
Iter: 7 loss: 0.00731175207
Iter: 8 loss: 0.054465577
Iter: 9 loss: 0.00692281174
Iter: 10 loss: 0.00368086295
Iter: 11 loss: 0.00367940613
Iter: 12 loss: 0.00254218467
Iter: 13 loss: 0.0106258094
Iter: 14 loss: 0.00236375863
Iter: 15 loss: 0.00176641042
Iter: 16 loss: 0.0111505799
Iter: 17 loss: 0.00176267547
Iter: 18 loss: 0.00138384802
Iter: 19 loss: 0.00498185446
Iter: 20 loss: 0.00136131234
Iter: 21 loss: 0.00113189989
Iter: 22 loss: 0.00155277294
Iter: 23 loss: 0.00102712121
Iter: 24 loss: 0.000830969075
Iter: 25 loss: 0.00141034601
Iter: 26 loss: 0.000770227
Iter: 27 loss: 0.000641916646
Iter: 28 loss: 0.00188423111
Iter: 29 loss: 0.000633847259
Iter: 30 loss: 0.000551325327
Iter: 31 loss: 0.000721869466
Iter: 32 loss: 0.000517941255
Iter: 33 loss: 0.000450033665
Iter: 34 loss: 0.000648603309
Iter: 35 loss: 0.000429028121
Iter: 36 loss: 0.000384168437
Iter: 37 loss: 0.000809353893
Iter: 38 loss: 0.000382347382
Iter: 39 loss: 0.000350566086
Iter: 40 loss: 0.000460428477
Iter: 41 loss: 0.00034211282
Iter: 42 loss: 0.000320441963
Iter: 43 loss: 0.000459528965
Iter: 44 loss: 0.000317661237
Iter: 45 loss: 0.000300853892
Iter: 46 loss: 0.000395808951
Iter: 47 loss: 0.000298682251
Iter: 48 loss: 0.000285087328
Iter: 49 loss: 0.000309649477
Iter: 50 loss: 0.000279110449
Iter: 51 loss: 0.000267664669
Iter: 52 loss: 0.000277931074
Iter: 53 loss: 0.000261029578
Iter: 54 loss: 0.000250628626
Iter: 55 loss: 0.000347546535
Iter: 56 loss: 0.000250198733
Iter: 57 loss: 0.000241618603
Iter: 58 loss: 0.000268313393
Iter: 59 loss: 0.000239105924
Iter: 60 loss: 0.000232930295
Iter: 61 loss: 0.000232732171
Iter: 62 loss: 0.000227919023
Iter: 63 loss: 0.000220739
Iter: 64 loss: 0.000244562805
Iter: 65 loss: 0.000218759684
Iter: 66 loss: 0.000212933635
Iter: 67 loss: 0.000243071292
Iter: 68 loss: 0.000212016865
Iter: 69 loss: 0.00020731808
Iter: 70 loss: 0.000236804655
Iter: 71 loss: 0.000206761819
Iter: 72 loss: 0.000203153104
Iter: 73 loss: 0.000206379613
Iter: 74 loss: 0.000201046627
Iter: 75 loss: 0.000197345798
Iter: 76 loss: 0.000208747952
Iter: 77 loss: 0.000196255773
Iter: 78 loss: 0.000193263331
Iter: 79 loss: 0.000212757499
Iter: 80 loss: 0.000192935069
Iter: 81 loss: 0.000190544524
Iter: 82 loss: 0.000205780554
Iter: 83 loss: 0.000190288585
Iter: 84 loss: 0.000188363978
Iter: 85 loss: 0.000195772067
Iter: 86 loss: 0.00018790178
Iter: 87 loss: 0.000186281148
Iter: 88 loss: 0.000188106234
Iter: 89 loss: 0.000185407232
Iter: 90 loss: 0.000183766009
Iter: 91 loss: 0.000190621882
Iter: 92 loss: 0.0001834141
Iter: 93 loss: 0.000181934534
Iter: 94 loss: 0.00018920959
Iter: 95 loss: 0.000181678275
Iter: 96 loss: 0.000180507224
Iter: 97 loss: 0.000180386851
Iter: 98 loss: 0.000179532479
Iter: 99 loss: 0.000178048256
Iter: 100 loss: 0.000180570292
Iter: 101 loss: 0.000177382535
Iter: 102 loss: 0.000175956564
Iter: 103 loss: 0.000181774958
Iter: 104 loss: 0.000175642897
Iter: 105 loss: 0.00017440127
Iter: 106 loss: 0.000179559225
Iter: 107 loss: 0.000174132045
Iter: 108 loss: 0.000173047549
Iter: 109 loss: 0.000178103423
Iter: 110 loss: 0.000172847183
Iter: 111 loss: 0.000171953201
Iter: 112 loss: 0.000173079257
Iter: 113 loss: 0.000171491294
Iter: 114 loss: 0.000170591113
Iter: 115 loss: 0.000172191561
Iter: 116 loss: 0.000170196843
Iter: 117 loss: 0.000169349601
Iter: 118 loss: 0.000173816021
Iter: 119 loss: 0.000169218984
Iter: 120 loss: 0.000168671861
Iter: 121 loss: 0.000168670507
Iter: 122 loss: 0.000168241255
Iter: 123 loss: 0.000168083614
Iter: 124 loss: 0.000167845981
Iter: 125 loss: 0.000167315797
Iter: 126 loss: 0.000169421546
Iter: 127 loss: 0.000167194899
Iter: 128 loss: 0.000166730693
Iter: 129 loss: 0.000169105217
Iter: 130 loss: 0.000166655111
Iter: 131 loss: 0.000166251557
Iter: 132 loss: 0.000166901824
Iter: 133 loss: 0.000166065758
Iter: 134 loss: 0.000165669568
Iter: 135 loss: 0.000166347483
Iter: 136 loss: 0.000165492296
Iter: 137 loss: 0.00016507697
Iter: 138 loss: 0.000165725476
Iter: 139 loss: 0.000164882105
Iter: 140 loss: 0.000164442288
Iter: 141 loss: 0.000165509846
Iter: 142 loss: 0.000164284924
Iter: 143 loss: 0.000163884892
Iter: 144 loss: 0.000165389036
Iter: 145 loss: 0.000163788529
Iter: 146 loss: 0.000163428282
Iter: 147 loss: 0.00016573038
Iter: 148 loss: 0.00016338806
Iter: 149 loss: 0.000163111661
Iter: 150 loss: 0.000163261604
Iter: 151 loss: 0.000162929762
Iter: 152 loss: 0.000162608892
Iter: 153 loss: 0.000163393168
Iter: 154 loss: 0.000162494165
Iter: 155 loss: 0.000162204989
Iter: 156 loss: 0.000163740566
Iter: 157 loss: 0.000162161159
Iter: 158 loss: 0.000161960575
Iter: 159 loss: 0.00016517035
Iter: 160 loss: 0.000161960648
Iter: 161 loss: 0.000161815056
Iter: 162 loss: 0.000161712902
Iter: 163 loss: 0.000161661184
Iter: 164 loss: 0.000161478209
Iter: 165 loss: 0.000162160344
Iter: 166 loss: 0.000161433651
Iter: 167 loss: 0.000161261705
Iter: 168 loss: 0.000162456199
Iter: 169 loss: 0.000161245713
Iter: 170 loss: 0.000161109318
Iter: 171 loss: 0.000161112272
Iter: 172 loss: 0.000161001022
Iter: 173 loss: 0.000160839481
Iter: 174 loss: 0.000161234697
Iter: 175 loss: 0.000160781929
Iter: 176 loss: 0.000160627213
Iter: 177 loss: 0.000161253192
Iter: 178 loss: 0.000160592695
Iter: 179 loss: 0.000160460913
Iter: 180 loss: 0.000160753523
Iter: 181 loss: 0.000160410593
Iter: 182 loss: 0.000160271913
Iter: 183 loss: 0.000160557771
Iter: 184 loss: 0.000160216354
Iter: 185 loss: 0.000160085649
Iter: 186 loss: 0.000160645926
Iter: 187 loss: 0.000160058989
Iter: 188 loss: 0.000159942952
Iter: 189 loss: 0.000160409065
Iter: 190 loss: 0.000159917166
Iter: 191 loss: 0.000159820076
Iter: 192 loss: 0.000160077121
Iter: 193 loss: 0.000159787509
Iter: 194 loss: 0.000159705902
Iter: 195 loss: 0.000160688156
Iter: 196 loss: 0.000159704941
Iter: 197 loss: 0.000159641859
Iter: 198 loss: 0.000159591407
Iter: 199 loss: 0.000159572344
Iter: 200 loss: 0.000159490737
Iter: 201 loss: 0.000159827963
Iter: 202 loss: 0.000159473231
Iter: 203 loss: 0.000159402931
Iter: 204 loss: 0.000159949879
Iter: 205 loss: 0.000159398012
Iter: 206 loss: 0.000159343312
Iter: 207 loss: 0.000159344505
Iter: 208 loss: 0.000159300034
Iter: 209 loss: 0.000159231888
Iter: 210 loss: 0.000159316915
Iter: 211 loss: 0.000159196643
Iter: 212 loss: 0.000159127259
Iter: 213 loss: 0.000159409552
Iter: 214 loss: 0.00015911198
Iter: 215 loss: 0.000159045783
Iter: 216 loss: 0.000159321673
Iter: 217 loss: 0.000159031741
Iter: 218 loss: 0.000158977869
Iter: 219 loss: 0.000159036776
Iter: 220 loss: 0.000158948169
Iter: 221 loss: 0.000158888637
Iter: 222 loss: 0.000159127754
Iter: 223 loss: 0.000158875366
Iter: 224 loss: 0.000158825482
Iter: 225 loss: 0.000159098796
Iter: 226 loss: 0.00015881806
Iter: 227 loss: 0.000158777679
Iter: 228 loss: 0.000158947965
Iter: 229 loss: 0.000158769195
Iter: 230 loss: 0.000158732495
Iter: 231 loss: 0.000158928917
Iter: 232 loss: 0.000158726558
Iter: 233 loss: 0.000158697789
Iter: 234 loss: 0.000158684095
Iter: 235 loss: 0.000158670344
Iter: 236 loss: 0.000158634415
Iter: 237 loss: 0.000158844341
Iter: 238 loss: 0.0001586297
Iter: 239 loss: 0.000158596493
Iter: 240 loss: 0.000158742449
Iter: 241 loss: 0.000158589653
Iter: 242 loss: 0.000158563809
Iter: 243 loss: 0.000158567869
Iter: 244 loss: 0.000158544659
Iter: 245 loss: 0.000158512092
Iter: 246 loss: 0.000158565075
Iter: 247 loss: 0.000158497147
Iter: 248 loss: 0.000158464158
Iter: 249 loss: 0.000158601091
Iter: 250 loss: 0.000158457056
Iter: 251 loss: 0.000158427923
Iter: 252 loss: 0.000158560273
Iter: 253 loss: 0.000158422394
Iter: 254 loss: 0.00015839799
Iter: 255 loss: 0.000158435243
Iter: 256 loss: 0.000158386538
Iter: 257 loss: 0.000158360417
Iter: 258 loss: 0.000158437033
Iter: 259 loss: 0.000158352181
Iter: 260 loss: 0.000158330193
Iter: 261 loss: 0.000158479903
Iter: 262 loss: 0.000158327966
Iter: 263 loss: 0.000158308249
Iter: 264 loss: 0.000158390321
Iter: 265 loss: 0.000158304174
Iter: 266 loss: 0.000158286843
Iter: 267 loss: 0.000158334966
Iter: 268 loss: 0.000158281415
Iter: 269 loss: 0.000158266907
Iter: 270 loss: 0.000158267678
Iter: 271 loss: 0.000158255483
Iter: 272 loss: 0.000158239127
Iter: 273 loss: 0.000158410432
Iter: 274 loss: 0.000158238618
Iter: 275 loss: 0.000158225215
Iter: 276 loss: 0.000158238225
Iter: 277 loss: 0.00015821759
Iter: 278 loss: 0.000158202674
Iter: 279 loss: 0.00015821628
Iter: 280 loss: 0.000158194161
Iter: 281 loss: 0.000158177922
Iter: 282 loss: 0.000158207346
Iter: 283 loss: 0.000158171
Iter: 284 loss: 0.000158154435
Iter: 285 loss: 0.000158220879
Iter: 286 loss: 0.000158150666
Iter: 287 loss: 0.000158135939
Iter: 288 loss: 0.00015821046
Iter: 289 loss: 0.000158133393
Iter: 290 loss: 0.000158121053
Iter: 291 loss: 0.000158135488
Iter: 292 loss: 0.000158114461
Iter: 293 loss: 0.000158101
Iter: 294 loss: 0.000158154522
Iter: 295 loss: 0.000158098104
Iter: 296 loss: 0.000158087671
Iter: 297 loss: 0.000158184121
Iter: 298 loss: 0.000158087336
Iter: 299 loss: 0.000158078241
Iter: 300 loss: 0.000158095587
Iter: 301 loss: 0.000158074414
Iter: 302 loss: 0.000158065552
Iter: 303 loss: 0.000158077703
Iter: 304 loss: 0.000158061273
Iter: 305 loss: 0.000158051931
Iter: 306 loss: 0.000158079682
Iter: 307 loss: 0.000158049283
Iter: 308 loss: 0.00015804077
Iter: 309 loss: 0.000158095965
Iter: 310 loss: 0.000158040086
Iter: 311 loss: 0.000158033174
Iter: 312 loss: 0.00015803265
Iter: 313 loss: 0.000158027324
Iter: 314 loss: 0.000158018811
Iter: 315 loss: 0.000158029085
Iter: 316 loss: 0.000158014271
Iter: 317 loss: 0.00015800487
Iter: 318 loss: 0.000158043578
Iter: 319 loss: 0.000158002789
Iter: 320 loss: 0.000157994509
Iter: 321 loss: 0.000158021168
Iter: 322 loss: 0.000157992108
Iter: 323 loss: 0.000157984628
Iter: 324 loss: 0.000158014343
Iter: 325 loss: 0.000157982868
Iter: 326 loss: 0.000157975592
Iter: 327 loss: 0.000157991104
Iter: 328 loss: 0.000157972943
Iter: 329 loss: 0.000157966715
Iter: 330 loss: 0.000157993898
Iter: 331 loss: 0.000157965318
Iter: 332 loss: 0.000157959556
Iter: 333 loss: 0.000158005249
Iter: 334 loss: 0.00015795893
Iter: 335 loss: 0.000157954491
Iter: 336 loss: 0.000157955204
Iter: 337 loss: 0.000157950984
Iter: 338 loss: 0.0001579456
Iter: 339 loss: 0.000157964096
Iter: 340 loss: 0.000157944072
Iter: 341 loss: 0.000157939445
Iter: 342 loss: 0.000157960312
Iter: 343 loss: 0.000157938572
Iter: 344 loss: 0.000157934031
Iter: 345 loss: 0.000157945135
Iter: 346 loss: 0.000157932358
Iter: 347 loss: 0.000157928414
Iter: 348 loss: 0.000157927905
Iter: 349 loss: 0.000157924835
Iter: 350 loss: 0.000157919712
Iter: 351 loss: 0.000157938528
Iter: 352 loss: 0.000157918228
Iter: 353 loss: 0.000157913455
Iter: 354 loss: 0.000157923176
Iter: 355 loss: 0.000157911258
Iter: 356 loss: 0.000157906354
Iter: 357 loss: 0.000157928633
Iter: 358 loss: 0.000157905786
Iter: 359 loss: 0.000157901188
Iter: 360 loss: 0.000157916424
Iter: 361 loss: 0.000157900155
Iter: 362 loss: 0.000157896167
Iter: 363 loss: 0.000157904055
Iter: 364 loss: 0.000157894479
Iter: 365 loss: 0.000157891132
Iter: 366 loss: 0.000157924835
Iter: 367 loss: 0.0001578909
Iter: 368 loss: 0.000157887844
Iter: 369 loss: 0.000157892646
Iter: 370 loss: 0.000157886272
Iter: 371 loss: 0.000157883333
Iter: 372 loss: 0.000157887014
Iter: 373 loss: 0.000157881936
Iter: 374 loss: 0.000157878821
Iter: 375 loss: 0.000157893315
Iter: 376 loss: 0.000157877963
Iter: 377 loss: 0.000157875344
Iter: 378 loss: 0.000157885894
Iter: 379 loss: 0.000157874791
Iter: 380 loss: 0.000157872128
Iter: 381 loss: 0.000157873699
Iter: 382 loss: 0.000157870294
Iter: 383 loss: 0.000157867529
Iter: 384 loss: 0.000157872462
Iter: 385 loss: 0.00015786622
Iter: 386 loss: 0.000157863367
Iter: 387 loss: 0.00015786897
Iter: 388 loss: 0.000157862014
Iter: 389 loss: 0.000157858725
Iter: 390 loss: 0.000157871342
Iter: 391 loss: 0.000157858201
Iter: 392 loss: 0.000157855349
Iter: 393 loss: 0.000157867558
Iter: 394 loss: 0.000157854636
Iter: 395 loss: 0.000157852512
Iter: 396 loss: 0.000157859977
Iter: 397 loss: 0.000157851726
Iter: 398 loss: 0.00015784963
Iter: 399 loss: 0.000157856732
Iter: 400 loss: 0.000157848976
Iter: 401 loss: 0.000157847
Iter: 402 loss: 0.000157864735
Iter: 403 loss: 0.000157846836
Iter: 404 loss: 0.000157845163
Iter: 405 loss: 0.00015784445
Iter: 406 loss: 0.000157843751
Iter: 407 loss: 0.000157841641
Iter: 408 loss: 0.000157849398
Iter: 409 loss: 0.000157841365
Iter: 410 loss: 0.000157839444
Iter: 411 loss: 0.000157849063
Iter: 412 loss: 0.000157839328
Iter: 413 loss: 0.000157837727
Iter: 414 loss: 0.00015784
Iter: 415 loss: 0.000157836766
Iter: 416 loss: 0.000157835049
Iter: 417 loss: 0.000157836548
Iter: 418 loss: 0.000157834293
Iter: 419 loss: 0.000157831964
Iter: 420 loss: 0.000157834875
Iter: 421 loss: 0.000157831324
Iter: 422 loss: 0.000157829229
Iter: 423 loss: 0.000157837378
Iter: 424 loss: 0.000157828646
Iter: 425 loss: 0.000157826988
Iter: 426 loss: 0.000157834351
Iter: 427 loss: 0.000157826755
Iter: 428 loss: 0.000157824979
Iter: 429 loss: 0.000157829898
Iter: 430 loss: 0.000157824688
Iter: 431 loss: 0.000157823233
Iter: 432 loss: 0.000157828792
Iter: 433 loss: 0.000157823044
Iter: 434 loss: 0.00015782172
Iter: 435 loss: 0.00015782949
Iter: 436 loss: 0.000157821749
Iter: 437 loss: 0.000157820541
Iter: 438 loss: 0.000157822069
Iter: 439 loss: 0.000157820177
Iter: 440 loss: 0.000157819159
Iter: 441 loss: 0.00015781929
Iter: 442 loss: 0.000157818402
Iter: 443 loss: 0.000157817136
Iter: 444 loss: 0.000157829141
Iter: 445 loss: 0.000157817165
Iter: 446 loss: 0.000157816132
Iter: 447 loss: 0.000157816845
Iter: 448 loss: 0.000157815666
Iter: 449 loss: 0.000157814502
Iter: 450 loss: 0.00015781667
Iter: 451 loss: 0.000157814153
Iter: 452 loss: 0.00015781293
Iter: 453 loss: 0.000157814386
Iter: 454 loss: 0.000157812523
Iter: 455 loss: 0.000157811126
Iter: 456 loss: 0.000157813687
Iter: 457 loss: 0.00015781066
Iter: 458 loss: 0.000157809351
Iter: 459 loss: 0.000157814502
Iter: 460 loss: 0.00015780922
Iter: 461 loss: 0.000157808259
Iter: 462 loss: 0.000157812377
Iter: 463 loss: 0.000157807866
Iter: 464 loss: 0.000157806964
Iter: 465 loss: 0.000157810209
Iter: 466 loss: 0.000157806819
Iter: 467 loss: 0.000157806062
Iter: 468 loss: 0.000157810631
Iter: 469 loss: 0.00015780596
Iter: 470 loss: 0.000157805101
Iter: 471 loss: 0.000157807939
Iter: 472 loss: 0.000157804985
Iter: 473 loss: 0.000157804374
Iter: 474 loss: 0.000157804287
Iter: 475 loss: 0.000157803908
Iter: 476 loss: 0.000157803181
Iter: 477 loss: 0.000157806266
Iter: 478 loss: 0.000157802962
Iter: 479 loss: 0.000157802235
Iter: 480 loss: 0.000157805742
Iter: 481 loss: 0.000157802206
Iter: 482 loss: 0.000157801493
Iter: 483 loss: 0.000157802104
Iter: 484 loss: 0.000157801333
Iter: 485 loss: 0.000157800619
Iter: 486 loss: 0.000157801784
Iter: 487 loss: 0.000157800387
Iter: 488 loss: 0.000157799601
Iter: 489 loss: 0.000157801056
Iter: 490 loss: 0.000157799455
Iter: 491 loss: 0.00015779867
Iter: 492 loss: 0.000157800139
Iter: 493 loss: 0.000157798539
Iter: 494 loss: 0.000157797796
Iter: 495 loss: 0.000157800911
Iter: 496 loss: 0.000157797651
Iter: 497 loss: 0.000157797243
Iter: 498 loss: 0.000157799775
Iter: 499 loss: 0.000157796836
Iter: 500 loss: 0.00015779653
Iter: 501 loss: 0.000157798902
Iter: 502 loss: 0.00015779637
Iter: 503 loss: 0.00015779589
Iter: 504 loss: 0.000157798553
Iter: 505 loss: 0.000157795977
Iter: 506 loss: 0.000157795468
Iter: 507 loss: 0.000157795614
Iter: 508 loss: 0.00015779541
Iter: 509 loss: 0.000157794973
Iter: 510 loss: 0.000157795788
Iter: 511 loss: 0.000157794784
Iter: 512 loss: 0.00015779442
Iter: 513 loss: 0.000157797331
Iter: 514 loss: 0.000157794377
Iter: 515 loss: 0.000157793984
Iter: 516 loss: 0.000157794479
Iter: 517 loss: 0.000157793664
Iter: 518 loss: 0.0001577933
Iter: 519 loss: 0.000157793809
Iter: 520 loss: 0.000157793169
Iter: 521 loss: 0.000157792645
Iter: 522 loss: 0.000157794013
Iter: 523 loss: 0.000157792689
Iter: 524 loss: 0.000157792296
Iter: 525 loss: 0.00015779314
Iter: 526 loss: 0.000157792121
Iter: 527 loss: 0.000157791714
Iter: 528 loss: 0.00015779247
Iter: 529 loss: 0.000157791583
Iter: 530 loss: 0.00015779119
Iter: 531 loss: 0.000157793489
Iter: 532 loss: 0.000157791277
Iter: 533 loss: 0.000157790753
Iter: 534 loss: 0.000157792238
Iter: 535 loss: 0.000157790724
Iter: 536 loss: 0.000157790419
Iter: 537 loss: 0.000157792194
Iter: 538 loss: 0.00015779052
Iter: 539 loss: 0.000157790259
Iter: 540 loss: 0.000157790375
Iter: 541 loss: 0.000157789967
Iter: 542 loss: 0.000157789953
Iter: 543 loss: 0.000157789967
Iter: 544 loss: 0.000157789706
Iter: 545 loss: 0.000157789356
Iter: 546 loss: 0.000157790608
Iter: 547 loss: 0.000157789458
Iter: 548 loss: 0.000157789153
Iter: 549 loss: 0.00015779004
Iter: 550 loss: 0.000157789094
Iter: 551 loss: 0.000157788803
Iter: 552 loss: 0.000157788949
Iter: 553 loss: 0.000157788687
Iter: 554 loss: 0.000157788556
Iter: 555 loss: 0.000157789094
Iter: 556 loss: 0.000157788512
Iter: 557 loss: 0.000157788236
Iter: 558 loss: 0.000157788978
Iter: 559 loss: 0.000157788338
Iter: 560 loss: 0.000157788105
Iter: 561 loss: 0.000157788309
Iter: 562 loss: 0.000157787697
Iter: 563 loss: 0.000157787523
Iter: 564 loss: 0.000157788192
Iter: 565 loss: 0.000157787508
Iter: 566 loss: 0.000157787203
Iter: 567 loss: 0.000157788949
Iter: 568 loss: 0.00015778729
Iter: 569 loss: 0.000157787188
Iter: 570 loss: 0.000157787697
Iter: 571 loss: 0.000157787232
Iter: 572 loss: 0.000157787028
Iter: 573 loss: 0.00015778729
Iter: 574 loss: 0.000157787
Iter: 575 loss: 0.000157786882
Iter: 576 loss: 0.000157786941
Iter: 577 loss: 0.000157786868
Iter: 578 loss: 0.000157786693
Iter: 579 loss: 0.000157786926
Iter: 580 loss: 0.000157786679
Iter: 581 loss: 0.000157786417
Iter: 582 loss: 0.000157787537
Iter: 583 loss: 0.000157786388
Iter: 584 loss: 0.000157786213
Iter: 585 loss: 0.000157786213
Iter: 586 loss: 0.000157786199
Iter: 587 loss: 0.000157786053
Iter: 588 loss: 0.000157786475
Iter: 589 loss: 0.000157785951
Iter: 590 loss: 0.000157786082
Iter: 591 loss: 0.000157786359
Iter: 592 loss: 0.000157785835
Iter: 593 loss: 0.000157785806
Iter: 594 loss: 0.000157786271
Iter: 595 loss: 0.000157785631
Iter: 596 loss: 0.000157785544
Iter: 597 loss: 0.00015778598
Iter: 598 loss: 0.000157785689
Iter: 599 loss: 0.000157785398
Iter: 600 loss: 0.000157785806
Iter: 601 loss: 0.000157785369
Iter: 602 loss: 0.000157785442
Iter: 603 loss: 0.000157786097
Iter: 604 loss: 0.00015778534
Iter: 605 loss: 0.000157785194
Iter: 606 loss: 0.000157785689
Iter: 607 loss: 0.00015778534
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2
+ date
Tue Oct 27 18:14:20 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457417620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4646aad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4646aa158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457450a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4573b4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4573d57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457388c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4573d51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457352598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457352840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4572af598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4572c4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4572c4e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4572c4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457254d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457254268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4571dd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457206b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb45716b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb45716bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457194598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457194730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4570ff950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4571588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4570a7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4570a8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4570939d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457093bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb457036f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4570422f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb4570936a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb456fc17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb456fce268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb456f69d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb456f23a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb456f231e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0173910931
Iter: 2 loss: 0.0163107533
Iter: 3 loss: 0.0128646055
Iter: 4 loss: 8253.72852
Iter: 5 loss: 0.0128643252
Iter: 6 loss: 0.0110398773
Iter: 7 loss: 0.010247292
Iter: 8 loss: 0.00767707126
Iter: 9 loss: 0.103075229
Iter: 10 loss: 0.0076638232
Iter: 11 loss: 0.00549893
Iter: 12 loss: 0.0264881887
Iter: 13 loss: 0.0053019803
Iter: 14 loss: 0.00390470726
Iter: 15 loss: 0.0182347707
Iter: 16 loss: 0.00388207519
Iter: 17 loss: 0.00330195483
Iter: 18 loss: 0.00337375
Iter: 19 loss: 0.00279365946
Iter: 20 loss: 0.00229503983
Iter: 21 loss: 0.0183812845
Iter: 22 loss: 0.00229442492
Iter: 23 loss: 0.00194849144
Iter: 24 loss: 0.00283422717
Iter: 25 loss: 0.00183933775
Iter: 26 loss: 0.00163203792
Iter: 27 loss: 0.00203225063
Iter: 28 loss: 0.00153897586
Iter: 29 loss: 0.00136575382
Iter: 30 loss: 0.00163336727
Iter: 31 loss: 0.00127817923
Iter: 32 loss: 0.00111784891
Iter: 33 loss: 0.00184355
Iter: 34 loss: 0.00108396192
Iter: 35 loss: 0.000950829941
Iter: 36 loss: 0.0014612783
Iter: 37 loss: 0.000915557
Iter: 38 loss: 0.000814961153
Iter: 39 loss: 0.00157379115
Iter: 40 loss: 0.000806914351
Iter: 41 loss: 0.000736367423
Iter: 42 loss: 0.00109197083
Iter: 43 loss: 0.000723983278
Iter: 44 loss: 0.000667572604
Iter: 45 loss: 0.000713689951
Iter: 46 loss: 0.000633230782
Iter: 47 loss: 0.00057853316
Iter: 48 loss: 0.00101340096
Iter: 49 loss: 0.000573850586
Iter: 50 loss: 0.000530746416
Iter: 51 loss: 0.000808385
Iter: 52 loss: 0.000526252901
Iter: 53 loss: 0.00049383787
Iter: 54 loss: 0.000646557426
Iter: 55 loss: 0.000487052923
Iter: 56 loss: 0.000461306481
Iter: 57 loss: 0.000598098733
Iter: 58 loss: 0.000457568443
Iter: 59 loss: 0.000436125352
Iter: 60 loss: 0.000545724586
Iter: 61 loss: 0.000432121655
Iter: 62 loss: 0.000416974595
Iter: 63 loss: 0.000399691518
Iter: 64 loss: 0.000397503492
Iter: 65 loss: 0.000371437171
Iter: 66 loss: 0.00054685137
Iter: 67 loss: 0.000368727138
Iter: 68 loss: 0.000351473514
Iter: 69 loss: 0.000616339617
Iter: 70 loss: 0.000351464085
Iter: 71 loss: 0.000340981409
Iter: 72 loss: 0.0003363094
Iter: 73 loss: 0.000331101532
Iter: 74 loss: 0.000318164093
Iter: 75 loss: 0.000380478334
Iter: 76 loss: 0.000315866
Iter: 77 loss: 0.000306247646
Iter: 78 loss: 0.000319689687
Iter: 79 loss: 0.000301452557
Iter: 80 loss: 0.000291753677
Iter: 81 loss: 0.000339751656
Iter: 82 loss: 0.000290090335
Iter: 83 loss: 0.000282097666
Iter: 84 loss: 0.000322085165
Iter: 85 loss: 0.000280706503
Iter: 86 loss: 0.000274062157
Iter: 87 loss: 0.000309589697
Iter: 88 loss: 0.000273089419
Iter: 89 loss: 0.000267619034
Iter: 90 loss: 0.000287716481
Iter: 91 loss: 0.000266196148
Iter: 92 loss: 0.000261448324
Iter: 93 loss: 0.000275529223
Iter: 94 loss: 0.000260029745
Iter: 95 loss: 0.000255557
Iter: 96 loss: 0.00026125717
Iter: 97 loss: 0.000253246166
Iter: 98 loss: 0.000248787401
Iter: 99 loss: 0.000251182
Iter: 100 loss: 0.000245834584
Iter: 101 loss: 0.000240805835
Iter: 102 loss: 0.00025763447
Iter: 103 loss: 0.000239428031
Iter: 104 loss: 0.000235331463
Iter: 105 loss: 0.000277177489
Iter: 106 loss: 0.000235204119
Iter: 107 loss: 0.000232139515
Iter: 108 loss: 0.000240147579
Iter: 109 loss: 0.000231099461
Iter: 110 loss: 0.000228174948
Iter: 111 loss: 0.000230690726
Iter: 112 loss: 0.000226448523
Iter: 113 loss: 0.000223123658
Iter: 114 loss: 0.000228798686
Iter: 115 loss: 0.000221630529
Iter: 116 loss: 0.000218446221
Iter: 117 loss: 0.000231642
Iter: 118 loss: 0.000217763503
Iter: 119 loss: 0.000214990709
Iter: 120 loss: 0.000232896229
Iter: 121 loss: 0.000214678541
Iter: 122 loss: 0.000212908577
Iter: 123 loss: 0.000234232692
Iter: 124 loss: 0.000212891
Iter: 125 loss: 0.000211534731
Iter: 126 loss: 0.000212592437
Iter: 127 loss: 0.00021070498
Iter: 128 loss: 0.000209011661
Iter: 129 loss: 0.000212845916
Iter: 130 loss: 0.000208375946
Iter: 131 loss: 0.000206852303
Iter: 132 loss: 0.000207577235
Iter: 133 loss: 0.000205825854
Iter: 134 loss: 0.000204011478
Iter: 135 loss: 0.000208413185
Iter: 136 loss: 0.000203362724
Iter: 137 loss: 0.000201663439
Iter: 138 loss: 0.000207555713
Iter: 139 loss: 0.000201215793
Iter: 140 loss: 0.000199767092
Iter: 141 loss: 0.000209074075
Iter: 142 loss: 0.000199605434
Iter: 143 loss: 0.000198243986
Iter: 144 loss: 0.000200966009
Iter: 145 loss: 0.000197687186
Iter: 146 loss: 0.000196435605
Iter: 147 loss: 0.000198391121
Iter: 148 loss: 0.000195845962
Iter: 149 loss: 0.000194389897
Iter: 150 loss: 0.000196936293
Iter: 151 loss: 0.000193744723
Iter: 152 loss: 0.000192451495
Iter: 153 loss: 0.000196220499
Iter: 154 loss: 0.000192052627
Iter: 155 loss: 0.000191057159
Iter: 156 loss: 0.000203489704
Iter: 157 loss: 0.000191046274
Iter: 158 loss: 0.000190179533
Iter: 159 loss: 0.00019439825
Iter: 160 loss: 0.000190032326
Iter: 161 loss: 0.000189368264
Iter: 162 loss: 0.000190241815
Iter: 163 loss: 0.000189029262
Iter: 164 loss: 0.000188280537
Iter: 165 loss: 0.000188947422
Iter: 166 loss: 0.000187844038
Iter: 167 loss: 0.000187046302
Iter: 168 loss: 0.000187759055
Iter: 169 loss: 0.000186580408
Iter: 170 loss: 0.000185659927
Iter: 171 loss: 0.000189151324
Iter: 172 loss: 0.000185439712
Iter: 173 loss: 0.000184644596
Iter: 174 loss: 0.00018723082
Iter: 175 loss: 0.000184422388
Iter: 176 loss: 0.000183674681
Iter: 177 loss: 0.000188192585
Iter: 178 loss: 0.000183582015
Iter: 179 loss: 0.000182925927
Iter: 180 loss: 0.000183936587
Iter: 181 loss: 0.000182616175
Iter: 182 loss: 0.000181973912
Iter: 183 loss: 0.000182557094
Iter: 184 loss: 0.000181601717
Iter: 185 loss: 0.000180913659
Iter: 186 loss: 0.000184010802
Iter: 187 loss: 0.0001807792
Iter: 188 loss: 0.000180162111
Iter: 189 loss: 0.000181421055
Iter: 190 loss: 0.000179914437
Iter: 191 loss: 0.00017951685
Iter: 192 loss: 0.000179500712
Iter: 193 loss: 0.00017913981
Iter: 194 loss: 0.000179048191
Iter: 195 loss: 0.0001788222
Iter: 196 loss: 0.000178366201
Iter: 197 loss: 0.000180284638
Iter: 198 loss: 0.000178268921
Iter: 199 loss: 0.000177899696
Iter: 200 loss: 0.000177784474
Iter: 201 loss: 0.000177567388
Iter: 202 loss: 0.000177029578
Iter: 203 loss: 0.000178918723
Iter: 204 loss: 0.000176889705
Iter: 205 loss: 0.000176419024
Iter: 206 loss: 0.000176928152
Iter: 207 loss: 0.000176160946
Iter: 208 loss: 0.00017573181
Iter: 209 loss: 0.000180401257
Iter: 210 loss: 0.000175722525
Iter: 211 loss: 0.000175349516
Iter: 212 loss: 0.000176045534
Iter: 213 loss: 0.000175190537
Iter: 214 loss: 0.000174807021
Iter: 215 loss: 0.000175562658
Iter: 216 loss: 0.000174649191
Iter: 217 loss: 0.000174245419
Iter: 218 loss: 0.000174732369
Iter: 219 loss: 0.000174032786
Iter: 220 loss: 0.000173601773
Iter: 221 loss: 0.000175088237
Iter: 222 loss: 0.000173487293
Iter: 223 loss: 0.000173160515
Iter: 224 loss: 0.00017621486
Iter: 225 loss: 0.000173147535
Iter: 226 loss: 0.000172853834
Iter: 227 loss: 0.000174649249
Iter: 228 loss: 0.000172817672
Iter: 229 loss: 0.000172615022
Iter: 230 loss: 0.000172518805
Iter: 231 loss: 0.000172420434
Iter: 232 loss: 0.000172101252
Iter: 233 loss: 0.000173133478
Iter: 234 loss: 0.000172010914
Iter: 235 loss: 0.000171742344
Iter: 236 loss: 0.000171864187
Iter: 237 loss: 0.000171560212
Iter: 238 loss: 0.000171244683
Iter: 239 loss: 0.000172322951
Iter: 240 loss: 0.000171160471
Iter: 241 loss: 0.00017085475
Iter: 242 loss: 0.000171651394
Iter: 243 loss: 0.000170751096
Iter: 244 loss: 0.000170480605
Iter: 245 loss: 0.000172502754
Iter: 246 loss: 0.000170459432
Iter: 247 loss: 0.000170221261
Iter: 248 loss: 0.000170574698
Iter: 249 loss: 0.000170106912
Iter: 250 loss: 0.000169863401
Iter: 251 loss: 0.000170231855
Iter: 252 loss: 0.000169747669
Iter: 253 loss: 0.000169501582
Iter: 254 loss: 0.000170216706
Iter: 255 loss: 0.000169425592
Iter: 256 loss: 0.000169200663
Iter: 257 loss: 0.00016994086
Iter: 258 loss: 0.000169137958
Iter: 259 loss: 0.000168988525
Iter: 260 loss: 0.000168984814
Iter: 261 loss: 0.000168856481
Iter: 262 loss: 0.000168829312
Iter: 263 loss: 0.000168745013
Iter: 264 loss: 0.000168590544
Iter: 265 loss: 0.00016878132
Iter: 266 loss: 0.000168510043
Iter: 267 loss: 0.000168330851
Iter: 268 loss: 0.000168892089
Iter: 269 loss: 0.000168278493
Iter: 270 loss: 0.000168105908
Iter: 271 loss: 0.000168258906
Iter: 272 loss: 0.000168004859
Iter: 273 loss: 0.000167824197
Iter: 274 loss: 0.000168101571
Iter: 275 loss: 0.000167738748
Iter: 276 loss: 0.000167552615
Iter: 277 loss: 0.00016902489
Iter: 278 loss: 0.000167539649
Iter: 279 loss: 0.00016739525
Iter: 280 loss: 0.000168003113
Iter: 281 loss: 0.000167364691
Iter: 282 loss: 0.000167232065
Iter: 283 loss: 0.000167428923
Iter: 284 loss: 0.000167168386
Iter: 285 loss: 0.000167030812
Iter: 286 loss: 0.000167131468
Iter: 287 loss: 0.000166945931
Iter: 288 loss: 0.000166790662
Iter: 289 loss: 0.000167522288
Iter: 290 loss: 0.000166762256
Iter: 291 loss: 0.000166640442
Iter: 292 loss: 0.000167373917
Iter: 293 loss: 0.000166625017
Iter: 294 loss: 0.000166518497
Iter: 295 loss: 0.00016754317
Iter: 296 loss: 0.000166514641
Iter: 297 loss: 0.000166442333
Iter: 298 loss: 0.000166327402
Iter: 299 loss: 0.000166326266
Iter: 300 loss: 0.000166208541
Iter: 301 loss: 0.000166937403
Iter: 302 loss: 0.000166194644
Iter: 303 loss: 0.000166087339
Iter: 304 loss: 0.000166227182
Iter: 305 loss: 0.000166032725
Iter: 306 loss: 0.000165922291
Iter: 307 loss: 0.000166045182
Iter: 308 loss: 0.000165862555
Iter: 309 loss: 0.000165746824
Iter: 310 loss: 0.000166261219
Iter: 311 loss: 0.000165723992
Iter: 312 loss: 0.000165625926
Iter: 313 loss: 0.000166116428
Iter: 314 loss: 0.000165609279
Iter: 315 loss: 0.000165522943
Iter: 316 loss: 0.000165872101
Iter: 317 loss: 0.000165503778
Iter: 318 loss: 0.000165427264
Iter: 319 loss: 0.000165474397
Iter: 320 loss: 0.000165378064
Iter: 321 loss: 0.000165285892
Iter: 322 loss: 0.000165471138
Iter: 323 loss: 0.000165248202
Iter: 324 loss: 0.000165160222
Iter: 325 loss: 0.000165384205
Iter: 326 loss: 0.000165130012
Iter: 327 loss: 0.000165090009
Iter: 328 loss: 0.000165079953
Iter: 329 loss: 0.000165039717
Iter: 330 loss: 0.00016500536
Iter: 331 loss: 0.000164994592
Iter: 332 loss: 0.000164932571
Iter: 333 loss: 0.000165009173
Iter: 334 loss: 0.000164900339
Iter: 335 loss: 0.000164837402
Iter: 336 loss: 0.000165034013
Iter: 337 loss: 0.000164819096
Iter: 338 loss: 0.000164752244
Iter: 339 loss: 0.000164963014
Iter: 340 loss: 0.000164732861
Iter: 341 loss: 0.000164677273
Iter: 342 loss: 0.00016469002
Iter: 343 loss: 0.000164636454
Iter: 344 loss: 0.000164570345
Iter: 345 loss: 0.00016494008
Iter: 346 loss: 0.000164560974
Iter: 347 loss: 0.00016450815
Iter: 348 loss: 0.000164799218
Iter: 349 loss: 0.000164500423
Iter: 350 loss: 0.000164453289
Iter: 351 loss: 0.000164575438
Iter: 352 loss: 0.000164437253
Iter: 353 loss: 0.00016439124
Iter: 354 loss: 0.000164396406
Iter: 355 loss: 0.000164355937
Iter: 356 loss: 0.000164300698
Iter: 357 loss: 0.00016444808
Iter: 358 loss: 0.000164282217
Iter: 359 loss: 0.000164230354
Iter: 360 loss: 0.000164704616
Iter: 361 loss: 0.00016422823
Iter: 362 loss: 0.000164191908
Iter: 363 loss: 0.000164632307
Iter: 364 loss: 0.00016419153
Iter: 365 loss: 0.000164167897
Iter: 366 loss: 0.000164119818
Iter: 367 loss: 0.000164997968
Iter: 368 loss: 0.000164119163
Iter: 369 loss: 0.000164070414
Iter: 370 loss: 0.000164333469
Iter: 371 loss: 0.000164063371
Iter: 372 loss: 0.00016401941
Iter: 373 loss: 0.000164144862
Iter: 374 loss: 0.000164005862
Iter: 375 loss: 0.000163965087
Iter: 376 loss: 0.000164099067
Iter: 377 loss: 0.000163953577
Iter: 378 loss: 0.000163916964
Iter: 379 loss: 0.00016392101
Iter: 380 loss: 0.000163889141
Iter: 381 loss: 0.000163844
Iter: 382 loss: 0.000164153
Iter: 383 loss: 0.000163839708
Iter: 384 loss: 0.000163805991
Iter: 385 loss: 0.00016397718
Iter: 386 loss: 0.000163800782
Iter: 387 loss: 0.00016376932
Iter: 388 loss: 0.000163809382
Iter: 389 loss: 0.00016375327
Iter: 390 loss: 0.000163719
Iter: 391 loss: 0.000163755263
Iter: 392 loss: 0.00016369982
Iter: 393 loss: 0.000163660719
Iter: 394 loss: 0.000163776014
Iter: 395 loss: 0.000163648656
Iter: 396 loss: 0.000163623306
Iter: 397 loss: 0.000163623219
Iter: 398 loss: 0.000163596153
Iter: 399 loss: 0.000163610035
Iter: 400 loss: 0.000163578283
Iter: 401 loss: 0.000163555611
Iter: 402 loss: 0.000163550314
Iter: 403 loss: 0.000163535646
Iter: 404 loss: 0.000163506484
Iter: 405 loss: 0.000163622215
Iter: 406 loss: 0.000163500023
Iter: 407 loss: 0.000163471617
Iter: 408 loss: 0.000163619407
Iter: 409 loss: 0.000163467485
Iter: 410 loss: 0.000163444711
Iter: 411 loss: 0.000163444143
Iter: 412 loss: 0.000163426317
Iter: 413 loss: 0.000163399178
Iter: 414 loss: 0.000163551245
Iter: 415 loss: 0.000163395438
Iter: 416 loss: 0.000163369972
Iter: 417 loss: 0.00016341616
Iter: 418 loss: 0.00016335884
Iter: 419 loss: 0.000163336168
Iter: 420 loss: 0.000163521676
Iter: 421 loss: 0.000163334887
Iter: 422 loss: 0.000163315737
Iter: 423 loss: 0.000163320074
Iter: 424 loss: 0.000163301476
Iter: 425 loss: 0.000163279066
Iter: 426 loss: 0.000163321834
Iter: 427 loss: 0.000163269709
Iter: 428 loss: 0.000163246776
Iter: 429 loss: 0.000163352131
Iter: 430 loss: 0.000163242526
Iter: 431 loss: 0.000163230055
Iter: 432 loss: 0.000163229095
Iter: 433 loss: 0.000163219636
Iter: 434 loss: 0.000163200282
Iter: 435 loss: 0.000163546501
Iter: 436 loss: 0.000163199875
Iter: 437 loss: 0.00016318039
Iter: 438 loss: 0.000163210439
Iter: 439 loss: 0.000163171251
Iter: 440 loss: 0.000163152159
Iter: 441 loss: 0.000163297373
Iter: 442 loss: 0.000163150544
Iter: 443 loss: 0.000163133664
Iter: 444 loss: 0.000163175253
Iter: 445 loss: 0.000163127595
Iter: 446 loss: 0.000163111938
Iter: 447 loss: 0.000163136399
Iter: 448 loss: 0.000163104472
Iter: 449 loss: 0.000163087898
Iter: 450 loss: 0.0001631294
Iter: 451 loss: 0.000163081771
Iter: 452 loss: 0.000163066507
Iter: 453 loss: 0.000163166173
Iter: 454 loss: 0.000163064862
Iter: 455 loss: 0.000163051271
Iter: 456 loss: 0.000163076242
Iter: 457 loss: 0.000163045377
Iter: 458 loss: 0.000163031189
Iter: 459 loss: 0.000163064411
Iter: 460 loss: 0.000163026081
Iter: 461 loss: 0.000163012242
Iter: 462 loss: 0.000163028744
Iter: 463 loss: 0.000163005141
Iter: 464 loss: 0.000162993558
Iter: 465 loss: 0.000163144752
Iter: 466 loss: 0.000162993369
Iter: 467 loss: 0.000162981451
Iter: 468 loss: 0.000163011602
Iter: 469 loss: 0.000162977361
Iter: 470 loss: 0.000162968907
Iter: 471 loss: 0.0001629615
Iter: 472 loss: 0.000162959332
Iter: 473 loss: 0.000162945697
Iter: 474 loss: 0.00016298017
Iter: 475 loss: 0.000162941142
Iter: 476 loss: 0.000162927841
Iter: 477 loss: 0.000162967946
Iter: 478 loss: 0.000162924174
Iter: 479 loss: 0.000162911601
Iter: 480 loss: 0.000162980956
Iter: 481 loss: 0.000162909768
Iter: 482 loss: 0.00016289913
Iter: 483 loss: 0.000162918441
Iter: 484 loss: 0.000162894372
Iter: 485 loss: 0.000162883458
Iter: 486 loss: 0.000162897049
Iter: 487 loss: 0.000162877899
Iter: 488 loss: 0.000162867276
Iter: 489 loss: 0.00016293666
Iter: 490 loss: 0.000162866112
Iter: 491 loss: 0.000162855576
Iter: 492 loss: 0.00016287723
Iter: 493 loss: 0.000162851356
Iter: 494 loss: 0.000162841679
Iter: 495 loss: 0.000162845099
Iter: 496 loss: 0.000162834855
Iter: 497 loss: 0.000162824508
Iter: 498 loss: 0.000162907265
Iter: 499 loss: 0.00016282365
Iter: 500 loss: 0.000162816636
Iter: 501 loss: 0.000162917218
Iter: 502 loss: 0.000162816606
Iter: 503 loss: 0.000162810698
Iter: 504 loss: 0.000162804266
Iter: 505 loss: 0.000162803233
Iter: 506 loss: 0.000162794953
Iter: 507 loss: 0.000162800265
Iter: 508 loss: 0.000162789991
Iter: 509 loss: 0.000162779877
Iter: 510 loss: 0.000162816868
Iter: 511 loss: 0.000162777418
Iter: 512 loss: 0.000162768672
Iter: 513 loss: 0.000162792596
Iter: 514 loss: 0.000162765617
Iter: 515 loss: 0.0001627577
Iter: 516 loss: 0.00016282362
Iter: 517 loss: 0.000162757206
Iter: 518 loss: 0.000162750628
Iter: 519 loss: 0.000162751501
Iter: 520 loss: 0.000162746
Iter: 521 loss: 0.000162737735
Iter: 522 loss: 0.000162758413
Iter: 523 loss: 0.000162735
Iter: 524 loss: 0.000162727898
Iter: 525 loss: 0.000162788638
Iter: 526 loss: 0.00016272752
Iter: 527 loss: 0.000162721495
Iter: 528 loss: 0.000162720899
Iter: 529 loss: 0.000162716402
Iter: 530 loss: 0.000162708602
Iter: 531 loss: 0.000162734563
Iter: 532 loss: 0.000162706623
Iter: 533 loss: 0.000162701
Iter: 534 loss: 0.000162756711
Iter: 535 loss: 0.000162700831
Iter: 536 loss: 0.000162695113
Iter: 537 loss: 0.000162714408
Iter: 538 loss: 0.000162693759
Iter: 539 loss: 0.000162689714
Iter: 540 loss: 0.000162685683
Iter: 541 loss: 0.00016268497
Iter: 542 loss: 0.000162678072
Iter: 543 loss: 0.000162687822
Iter: 544 loss: 0.000162674813
Iter: 545 loss: 0.000162668
Iter: 546 loss: 0.000162690558
Iter: 547 loss: 0.000162666285
Iter: 548 loss: 0.000162660013
Iter: 549 loss: 0.000162696611
Iter: 550 loss: 0.000162659155
Iter: 551 loss: 0.000162653771
Iter: 552 loss: 0.000162670141
Iter: 553 loss: 0.000162652243
Iter: 554 loss: 0.000162647208
Iter: 555 loss: 0.000162657729
Iter: 556 loss: 0.000162645083
Iter: 557 loss: 0.000162639946
Iter: 558 loss: 0.000162651893
Iter: 559 loss: 0.000162637705
Iter: 560 loss: 0.00016263251
Iter: 561 loss: 0.000162655109
Iter: 562 loss: 0.000162631739
Iter: 563 loss: 0.000162626617
Iter: 564 loss: 0.000162637152
Iter: 565 loss: 0.00016262487
Iter: 566 loss: 0.000162620039
Iter: 567 loss: 0.000162624376
Iter: 568 loss: 0.000162617216
Iter: 569 loss: 0.000162614146
Iter: 570 loss: 0.000162613884
Iter: 571 loss: 0.00016261061
Iter: 572 loss: 0.000162609242
Iter: 573 loss: 0.000162607539
Iter: 574 loss: 0.00016260377
Iter: 575 loss: 0.000162599405
Iter: 576 loss: 0.00016259891
Iter: 577 loss: 0.000162593758
Iter: 578 loss: 0.000162624812
Iter: 579 loss: 0.000162592944
Iter: 580 loss: 0.000162588229
Iter: 581 loss: 0.000162601951
Iter: 582 loss: 0.000162586599
Iter: 583 loss: 0.000162582117
Iter: 584 loss: 0.000162606753
Iter: 585 loss: 0.000162581826
Iter: 586 loss: 0.00016257778
Iter: 587 loss: 0.000162590382
Iter: 588 loss: 0.000162576645
Iter: 589 loss: 0.000162573124
Iter: 590 loss: 0.000162576122
Iter: 591 loss: 0.000162570926
Iter: 592 loss: 0.000162567012
Iter: 593 loss: 0.000162592274
Iter: 594 loss: 0.000162566692
Iter: 595 loss: 0.000162563403
Iter: 596 loss: 0.000162566925
Iter: 597 loss: 0.000162561439
Iter: 598 loss: 0.00016255783
Iter: 599 loss: 0.000162572862
Iter: 600 loss: 0.000162556782
Iter: 601 loss: 0.000162553595
Iter: 602 loss: 0.000162558601
Iter: 603 loss: 0.000162552169
Iter: 604 loss: 0.000162549171
Iter: 605 loss: 0.00016254923
Iter: 606 loss: 0.000162547425
Iter: 607 loss: 0.000162544035
Iter: 608 loss: 0.000162617667
Iter: 609 loss: 0.000162543874
Iter: 610 loss: 0.000162540324
Iter: 611 loss: 0.000162546
Iter: 612 loss: 0.000162538447
Iter: 613 loss: 0.000162534605
Iter: 614 loss: 0.00016254466
Iter: 615 loss: 0.000162533397
Iter: 616 loss: 0.000162529497
Iter: 617 loss: 0.000162546945
Iter: 618 loss: 0.000162528828
Iter: 619 loss: 0.00016252519
Iter: 620 loss: 0.000162540455
Iter: 621 loss: 0.00016252452
Iter: 622 loss: 0.00016252193
Iter: 623 loss: 0.000162535667
Iter: 624 loss: 0.000162521465
Iter: 625 loss: 0.000162518874
Iter: 626 loss: 0.000162520475
Iter: 627 loss: 0.000162517186
Iter: 628 loss: 0.000162514218
Iter: 629 loss: 0.000162524331
Iter: 630 loss: 0.000162513606
Iter: 631 loss: 0.000162510652
Iter: 632 loss: 0.000162522119
Iter: 633 loss: 0.000162510114
Iter: 634 loss: 0.000162507422
Iter: 635 loss: 0.00016250895
Iter: 636 loss: 0.000162505632
Iter: 637 loss: 0.000162503828
Iter: 638 loss: 0.000162503769
Iter: 639 loss: 0.000162501819
Iter: 640 loss: 0.000162501557
Iter: 641 loss: 0.00016250003
Iter: 642 loss: 0.000162497905
Iter: 643 loss: 0.000162498123
Iter: 644 loss: 0.000162496348
Iter: 645 loss: 0.000162493467
Iter: 646 loss: 0.000162499564
Iter: 647 loss: 0.000162492477
Iter: 648 loss: 0.000162489567
Iter: 649 loss: 0.000162499447
Iter: 650 loss: 0.000162488839
Iter: 651 loss: 0.000162486293
Iter: 652 loss: 0.000162490236
Iter: 653 loss: 0.000162485085
Iter: 654 loss: 0.000162482334
Iter: 655 loss: 0.000162497425
Iter: 656 loss: 0.000162482174
Iter: 657 loss: 0.000162479701
Iter: 658 loss: 0.000162491458
Iter: 659 loss: 0.00016247938
Iter: 660 loss: 0.000162477329
Iter: 661 loss: 0.000162479817
Iter: 662 loss: 0.000162476528
Iter: 663 loss: 0.000162474331
Iter: 664 loss: 0.000162477721
Iter: 665 loss: 0.000162473239
Iter: 666 loss: 0.000162471115
Iter: 667 loss: 0.000162485623
Iter: 668 loss: 0.000162470911
Iter: 669 loss: 0.000162469078
Iter: 670 loss: 0.000162470795
Iter: 671 loss: 0.000162467972
Iter: 672 loss: 0.000162466647
Iter: 673 loss: 0.000162466458
Iter: 674 loss: 0.000162465425
Iter: 675 loss: 0.000162463461
Iter: 676 loss: 0.000162505705
Iter: 677 loss: 0.000162463606
Iter: 678 loss: 0.000162461278
Iter: 679 loss: 0.000162463504
Iter: 680 loss: 0.000162460143
Iter: 681 loss: 0.000162458076
Iter: 682 loss: 0.000162468423
Iter: 683 loss: 0.000162457523
Iter: 684 loss: 0.000162455486
Iter: 685 loss: 0.000162460216
Iter: 686 loss: 0.000162454875
Iter: 687 loss: 0.000162452721
Iter: 688 loss: 0.000162459852
Iter: 689 loss: 0.000162452197
Iter: 690 loss: 0.000162450509
Iter: 691 loss: 0.000162457058
Iter: 692 loss: 0.000162449956
Iter: 693 loss: 0.000162448414
Iter: 694 loss: 0.000162460288
Iter: 695 loss: 0.000162448167
Iter: 696 loss: 0.000162446842
Iter: 697 loss: 0.00016244658
Iter: 698 loss: 0.000162445751
Iter: 699 loss: 0.000162444019
Iter: 700 loss: 0.000162451048
Iter: 701 loss: 0.00016244383
Iter: 702 loss: 0.000162442069
Iter: 703 loss: 0.000162446348
Iter: 704 loss: 0.000162441749
Iter: 705 loss: 0.000162440279
Iter: 706 loss: 0.00016245096
Iter: 707 loss: 0.000162440338
Iter: 708 loss: 0.000162439086
Iter: 709 loss: 0.000162442389
Iter: 710 loss: 0.00016243862
Iter: 711 loss: 0.000162437573
Iter: 712 loss: 0.000162437616
Iter: 713 loss: 0.000162436554
Iter: 714 loss: 0.000162435288
Iter: 715 loss: 0.000162435812
Iter: 716 loss: 0.00016243456
Iter: 717 loss: 0.00016243264
Iter: 718 loss: 0.000162435928
Iter: 719 loss: 0.000162432145
Iter: 720 loss: 0.000162430428
Iter: 721 loss: 0.000162438169
Iter: 722 loss: 0.000162430195
Iter: 723 loss: 0.000162428594
Iter: 724 loss: 0.000162430646
Iter: 725 loss: 0.000162427925
Iter: 726 loss: 0.000162426615
Iter: 727 loss: 0.000162443117
Iter: 728 loss: 0.000162426586
Iter: 729 loss: 0.000162425538
Iter: 730 loss: 0.000162427459
Iter: 731 loss: 0.00016242516
Iter: 732 loss: 0.000162424141
Iter: 733 loss: 0.000162425888
Iter: 734 loss: 0.000162423516
Iter: 735 loss: 0.000162422366
Iter: 736 loss: 0.0001624242
Iter: 737 loss: 0.000162421871
Iter: 738 loss: 0.000162420765
Iter: 739 loss: 0.000162429671
Iter: 740 loss: 0.000162420634
Iter: 741 loss: 0.000162419819
Iter: 742 loss: 0.000162427285
Iter: 743 loss: 0.000162419747
Iter: 744 loss: 0.000162419077
Iter: 745 loss: 0.000162418466
Iter: 746 loss: 0.000162418262
Iter: 747 loss: 0.000162417244
Iter: 748 loss: 0.000162418
Iter: 749 loss: 0.000162416589
Iter: 750 loss: 0.000162415585
Iter: 751 loss: 0.000162419485
Iter: 752 loss: 0.000162415236
Iter: 753 loss: 0.0001624141
Iter: 754 loss: 0.000162414857
Iter: 755 loss: 0.000162413504
Iter: 756 loss: 0.000162412281
Iter: 757 loss: 0.000162417506
Iter: 758 loss: 0.000162411889
Iter: 759 loss: 0.000162410899
Iter: 760 loss: 0.00016241282
Iter: 761 loss: 0.000162410404
Iter: 762 loss: 0.000162409327
Iter: 763 loss: 0.000162417607
Iter: 764 loss: 0.000162409211
Iter: 765 loss: 0.000162408222
Iter: 766 loss: 0.000162412252
Iter: 767 loss: 0.00016240796
Iter: 768 loss: 0.000162407261
Iter: 769 loss: 0.000162407523
Iter: 770 loss: 0.000162406766
Iter: 771 loss: 0.000162405602
Iter: 772 loss: 0.000162409342
Iter: 773 loss: 0.000162405457
Iter: 774 loss: 0.000162404729
Iter: 775 loss: 0.000162411307
Iter: 776 loss: 0.000162404715
Iter: 777 loss: 0.000162403943
Iter: 778 loss: 0.000162405719
Iter: 779 loss: 0.000162403667
Iter: 780 loss: 0.000162403041
Iter: 781 loss: 0.000162403288
Iter: 782 loss: 0.000162402488
Iter: 783 loss: 0.000162401921
Iter: 784 loss: 0.000162402677
Iter: 785 loss: 0.000162401309
Iter: 786 loss: 0.00016240048
Iter: 787 loss: 0.000162401106
Iter: 788 loss: 0.000162399941
Iter: 789 loss: 0.000162398879
Iter: 790 loss: 0.000162404438
Iter: 791 loss: 0.000162398705
Iter: 792 loss: 0.000162397831
Iter: 793 loss: 0.000162400902
Iter: 794 loss: 0.000162397482
Iter: 795 loss: 0.000162396769
Iter: 796 loss: 0.000162399097
Iter: 797 loss: 0.00016239658
Iter: 798 loss: 0.00016239562
Iter: 799 loss: 0.000162400029
Iter: 800 loss: 0.000162395489
Iter: 801 loss: 0.00016239495
Iter: 802 loss: 0.000162398093
Iter: 803 loss: 0.000162394805
Iter: 804 loss: 0.000162394252
Iter: 805 loss: 0.000162394514
Iter: 806 loss: 0.000162393902
Iter: 807 loss: 0.000162393117
Iter: 808 loss: 0.000162395823
Iter: 809 loss: 0.000162393131
Iter: 810 loss: 0.00016239268
Iter: 811 loss: 0.000162392491
Iter: 812 loss: 0.000162392113
Iter: 813 loss: 0.000162391749
Iter: 814 loss: 0.000162391778
Iter: 815 loss: 0.000162391094
Iter: 816 loss: 0.000162392811
Iter: 817 loss: 0.000162390977
Iter: 818 loss: 0.000162390352
Iter: 819 loss: 0.00016239105
Iter: 820 loss: 0.00016239
Iter: 821 loss: 0.000162389333
Iter: 822 loss: 0.000162390832
Iter: 823 loss: 0.000162389
Iter: 824 loss: 0.000162388344
Iter: 825 loss: 0.000162389711
Iter: 826 loss: 0.000162388053
Iter: 827 loss: 0.000162387529
Iter: 828 loss: 0.000162389581
Iter: 829 loss: 0.000162387238
Iter: 830 loss: 0.000162386481
Iter: 831 loss: 0.000162390963
Iter: 832 loss: 0.000162386423
Iter: 833 loss: 0.000162386132
Iter: 834 loss: 0.000162388038
Iter: 835 loss: 0.000162385841
Iter: 836 loss: 0.000162385302
Iter: 837 loss: 0.000162386365
Iter: 838 loss: 0.000162385171
Iter: 839 loss: 0.000162384662
Iter: 840 loss: 0.00016238555
Iter: 841 loss: 0.000162384327
Iter: 842 loss: 0.000162384124
Iter: 843 loss: 0.000162387674
Iter: 844 loss: 0.000162384094
Iter: 845 loss: 0.000162383541
Iter: 846 loss: 0.000162384851
Iter: 847 loss: 0.000162383425
Iter: 848 loss: 0.000162383018
Iter: 849 loss: 0.000162382727
Iter: 850 loss: 0.000162382799
Iter: 851 loss: 0.000162382377
Iter: 852 loss: 0.000162384735
Iter: 853 loss: 0.000162382203
Iter: 854 loss: 0.000162381679
Iter: 855 loss: 0.000162381941
Iter: 856 loss: 0.000162381417
Iter: 857 loss: 0.000162380951
Iter: 858 loss: 0.000162381824
Iter: 859 loss: 0.000162380646
Iter: 860 loss: 0.000162380078
Iter: 861 loss: 0.000162383134
Iter: 862 loss: 0.000162380107
Iter: 863 loss: 0.000162379685
Iter: 864 loss: 0.000162379962
Iter: 865 loss: 0.000162379409
Iter: 866 loss: 0.00016237903
Iter: 867 loss: 0.000162381795
Iter: 868 loss: 0.000162378885
Iter: 869 loss: 0.000162378245
Iter: 870 loss: 0.000162381606
Iter: 871 loss: 0.000162378274
Iter: 872 loss: 0.000162377983
Iter: 873 loss: 0.000162378681
Iter: 874 loss: 0.000162377968
Iter: 875 loss: 0.000162377546
Iter: 876 loss: 0.000162377939
Iter: 877 loss: 0.00016237743
Iter: 878 loss: 0.000162377168
Iter: 879 loss: 0.000162377226
Iter: 880 loss: 0.00016237676
Iter: 881 loss: 0.000162376469
Iter: 882 loss: 0.000162376571
Iter: 883 loss: 0.00016237612
Iter: 884 loss: 0.000162377037
Iter: 885 loss: 0.000162376411
Iter: 886 loss: 0.000162375771
Iter: 887 loss: 0.000162376527
Iter: 888 loss: 0.000162375625
Iter: 889 loss: 0.000162375247
Iter: 890 loss: 0.000162376338
Iter: 891 loss: 0.00016237516
Iter: 892 loss: 0.000162374781
Iter: 893 loss: 0.000162375509
Iter: 894 loss: 0.000162374592
Iter: 895 loss: 0.000162374461
Iter: 896 loss: 0.00016237548
Iter: 897 loss: 0.000162374257
Iter: 898 loss: 0.000162374
Iter: 899 loss: 0.000162374796
Iter: 900 loss: 0.000162373908
Iter: 901 loss: 0.000162373733
Iter: 902 loss: 0.000162374199
Iter: 903 loss: 0.000162373457
Iter: 904 loss: 0.000162373093
Iter: 905 loss: 0.000162376848
Iter: 906 loss: 0.000162373108
Iter: 907 loss: 0.000162372817
Iter: 908 loss: 0.000162372831
Iter: 909 loss: 0.000162372628
Iter: 910 loss: 0.00016237254
Iter: 911 loss: 0.000162373733
Iter: 912 loss: 0.000162372336
Iter: 913 loss: 0.000162372351
Iter: 914 loss: 0.000162373617
Iter: 915 loss: 0.000162372133
Iter: 916 loss: 0.000162371958
Iter: 917 loss: 0.000162371711
Iter: 918 loss: 0.00016237174
Iter: 919 loss: 0.000162371667
Iter: 920 loss: 0.000162372686
Iter: 921 loss: 0.000162371347
Iter: 922 loss: 0.000162371172
Iter: 923 loss: 0.000162372075
Iter: 924 loss: 0.000162371085
Iter: 925 loss: 0.000162370852
Iter: 926 loss: 0.000162371
Iter: 927 loss: 0.000162370692
Iter: 928 loss: 0.000162370387
Iter: 929 loss: 0.000162371434
Iter: 930 loss: 0.000162370372
Iter: 931 loss: 0.000162370095
Iter: 932 loss: 0.000162370619
Iter: 933 loss: 0.000162370095
Iter: 934 loss: 0.00016236963
Iter: 935 loss: 0.000162370008
Iter: 936 loss: 0.000162369688
Iter: 937 loss: 0.000162369397
Iter: 938 loss: 0.000162371754
Iter: 939 loss: 0.000162369513
Iter: 940 loss: 0.000162369353
Iter: 941 loss: 0.000162370008
Iter: 942 loss: 0.00016236915
Iter: 943 loss: 0.000162369062
Iter: 944 loss: 0.000162369033
Iter: 945 loss: 0.000162368931
Iter: 946 loss: 0.000162368684
Iter: 947 loss: 0.000162368699
Iter: 948 loss: 0.000162368655
Iter: 949 loss: 0.000162368437
Iter: 950 loss: 0.000162368509
Iter: 951 loss: 0.000162368335
Iter: 952 loss: 0.000162368247
Iter: 953 loss: 0.000162368116
Iter: 954 loss: 0.000162367869
Iter: 955 loss: 0.00016236915
Iter: 956 loss: 0.000162367884
Iter: 957 loss: 0.00016236768
Iter: 958 loss: 0.00016236832
Iter: 959 loss: 0.000162367651
Iter: 960 loss: 0.000162367389
Iter: 961 loss: 0.000162368
Iter: 962 loss: 0.000162367418
Iter: 963 loss: 0.000162367389
Iter: 964 loss: 0.000162367403
Iter: 965 loss: 0.000162367214
Iter: 966 loss: 0.000162366952
Iter: 967 loss: 0.000162367214
Iter: 968 loss: 0.000162366865
Iter: 969 loss: 0.000162366545
Iter: 970 loss: 0.000162367302
Iter: 971 loss: 0.000162366516
Iter: 972 loss: 0.000162366414
Iter: 973 loss: 0.000162367331
Iter: 974 loss: 0.000162366487
Iter: 975 loss: 0.000162366399
Iter: 976 loss: 0.000162367243
Iter: 977 loss: 0.000162366283
Iter: 978 loss: 0.000162366137
Iter: 979 loss: 0.000162366283
Iter: 980 loss: 0.000162366108
Iter: 981 loss: 0.000162365846
Iter: 982 loss: 0.000162367272
Iter: 983 loss: 0.000162365934
Iter: 984 loss: 0.000162365934
Iter: 985 loss: 0.000162365817
Iter: 986 loss: 0.000162365905
Iter: 987 loss: 0.000162365614
Iter: 988 loss: 0.000162365701
Iter: 989 loss: 0.000162365497
Iter: 990 loss: 0.000162365512
Iter: 991 loss: 0.00016236605
Iter: 992 loss: 0.000162365395
Iter: 993 loss: 0.000162365352
Iter: 994 loss: 0.000162365497
Iter: 995 loss: 0.000162365104
Iter: 996 loss: 0.00016236509
Iter: 997 loss: 0.000162365817
Iter: 998 loss: 0.000162365119
Iter: 999 loss: 0.000162364973
Iter: 1000 loss: 0.000162364944
Iter: 1001 loss: 0.000162364711
Iter: 1002 loss: 0.000162364624
Iter: 1003 loss: 0.000162364944
Iter: 1004 loss: 0.000162364711
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6
+ date
Tue Oct 27 18:27:39 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda768ac730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda768ac048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda768bbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda768411e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76841c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76841bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76829e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76804ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda767f1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76783488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7674e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7675bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7675be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda766bcd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7675ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7675bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76684510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda766a5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7660a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7660a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda766246a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76624d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda765a29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76546a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76546730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda764f7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda765318c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda765319d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda764ce598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda764e0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76531378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda764551e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda76469268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda7640aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda763bf598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fda763bf400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0224860962
Iter: 2 loss: 0.0166911129
Iter: 3 loss: 4000.81445
Iter: 4 loss: 0.0904969797
Iter: 5 loss: 0.0216345172
Iter: 6 loss: 0.0159349684
Iter: 7 loss: 0.0159313269
Iter: 8 loss: 0.013581723
Iter: 9 loss: 0.0196694154
Iter: 10 loss: 0.0123951742
Iter: 11 loss: 0.00935566612
Iter: 12 loss: 0.0843385
Iter: 13 loss: 0.00933241285
Iter: 14 loss: 0.00792811718
Iter: 15 loss: 0.0240413621
Iter: 16 loss: 0.00787366461
Iter: 17 loss: 0.00690269843
Iter: 18 loss: 0.0111618992
Iter: 19 loss: 0.0066759428
Iter: 20 loss: 0.005700876
Iter: 21 loss: 0.0120664835
Iter: 22 loss: 0.00549163064
Iter: 23 loss: 0.00446621049
Iter: 24 loss: 0.00446564797
Iter: 25 loss: 0.00392208295
Iter: 26 loss: 0.0100534773
Iter: 27 loss: 0.00392205687
Iter: 28 loss: 0.00362674706
Iter: 29 loss: 0.00776804844
Iter: 30 loss: 0.0036148834
Iter: 31 loss: 0.00323547702
Iter: 32 loss: 0.00474689901
Iter: 33 loss: 0.00314974505
Iter: 34 loss: 0.00281565497
Iter: 35 loss: 0.00325917313
Iter: 36 loss: 0.00264145667
Iter: 37 loss: 0.00228181947
Iter: 38 loss: 0.00545225
Iter: 39 loss: 0.00225557177
Iter: 40 loss: 0.00203283411
Iter: 41 loss: 0.00377337635
Iter: 42 loss: 0.00200590887
Iter: 43 loss: 0.00184562546
Iter: 44 loss: 0.00214294717
Iter: 45 loss: 0.00177219906
Iter: 46 loss: 0.00160775206
Iter: 47 loss: 0.00213428726
Iter: 48 loss: 0.00155557122
Iter: 49 loss: 0.00145016797
Iter: 50 loss: 0.0014494349
Iter: 51 loss: 0.0013786268
Iter: 52 loss: 0.00141055917
Iter: 53 loss: 0.00132743758
Iter: 54 loss: 0.00126133405
Iter: 55 loss: 0.00135150459
Iter: 56 loss: 0.00122966059
Iter: 57 loss: 0.00115549902
Iter: 58 loss: 0.00137572945
Iter: 59 loss: 0.00112950755
Iter: 60 loss: 0.00106496294
Iter: 61 loss: 0.00106493721
Iter: 62 loss: 0.0010310947
Iter: 63 loss: 0.0010220703
Iter: 64 loss: 0.00100049481
Iter: 65 loss: 0.000953464303
Iter: 66 loss: 0.000996487914
Iter: 67 loss: 0.000925830216
Iter: 68 loss: 0.00087571
Iter: 69 loss: 0.00118963572
Iter: 70 loss: 0.000869380427
Iter: 71 loss: 0.000824969495
Iter: 72 loss: 0.00104325579
Iter: 73 loss: 0.000817109307
Iter: 74 loss: 0.000787028926
Iter: 75 loss: 0.00122120441
Iter: 76 loss: 0.000786779507
Iter: 77 loss: 0.000762695039
Iter: 78 loss: 0.000768145779
Iter: 79 loss: 0.000745099853
Iter: 80 loss: 0.000717308256
Iter: 81 loss: 0.000745354919
Iter: 82 loss: 0.000701297657
Iter: 83 loss: 0.000671485206
Iter: 84 loss: 0.000880509499
Iter: 85 loss: 0.000669019297
Iter: 86 loss: 0.000642376835
Iter: 87 loss: 0.000742209493
Iter: 88 loss: 0.000635275152
Iter: 89 loss: 0.000619347673
Iter: 90 loss: 0.000621885702
Iter: 91 loss: 0.000607419
Iter: 92 loss: 0.000585351663
Iter: 93 loss: 0.000643870851
Iter: 94 loss: 0.000577624538
Iter: 95 loss: 0.000562746311
Iter: 96 loss: 0.000562663423
Iter: 97 loss: 0.000549270539
Iter: 98 loss: 0.00054231548
Iter: 99 loss: 0.000536054431
Iter: 100 loss: 0.00052126724
Iter: 101 loss: 0.000510647602
Iter: 102 loss: 0.000505476259
Iter: 103 loss: 0.000487816345
Iter: 104 loss: 0.000684409402
Iter: 105 loss: 0.000487403711
Iter: 106 loss: 0.000472031301
Iter: 107 loss: 0.000499508751
Iter: 108 loss: 0.000465378893
Iter: 109 loss: 0.000453075889
Iter: 110 loss: 0.000553497288
Iter: 111 loss: 0.000452179171
Iter: 112 loss: 0.000440923352
Iter: 113 loss: 0.000466751691
Iter: 114 loss: 0.000436755538
Iter: 115 loss: 0.000425119593
Iter: 116 loss: 0.000434201
Iter: 117 loss: 0.000418031908
Iter: 118 loss: 0.000410422799
Iter: 119 loss: 0.000410146
Iter: 120 loss: 0.000402824226
Iter: 121 loss: 0.000403869315
Iter: 122 loss: 0.000397188065
Iter: 123 loss: 0.0003897282
Iter: 124 loss: 0.000396569551
Iter: 125 loss: 0.000385450025
Iter: 126 loss: 0.000377593416
Iter: 127 loss: 0.000420562719
Iter: 128 loss: 0.000376344367
Iter: 129 loss: 0.000369748363
Iter: 130 loss: 0.000425762293
Iter: 131 loss: 0.000369400776
Iter: 132 loss: 0.000364474137
Iter: 133 loss: 0.000356857461
Iter: 134 loss: 0.00035674253
Iter: 135 loss: 0.000348537666
Iter: 136 loss: 0.00035392592
Iter: 137 loss: 0.000343305
Iter: 138 loss: 0.000335191929
Iter: 139 loss: 0.00042092189
Iter: 140 loss: 0.000334964832
Iter: 141 loss: 0.000328642491
Iter: 142 loss: 0.0003629438
Iter: 143 loss: 0.00032772313
Iter: 144 loss: 0.000322581182
Iter: 145 loss: 0.000348138623
Iter: 146 loss: 0.000321637839
Iter: 147 loss: 0.000316843041
Iter: 148 loss: 0.000315348851
Iter: 149 loss: 0.000312524498
Iter: 150 loss: 0.000307812064
Iter: 151 loss: 0.000331392454
Iter: 152 loss: 0.000306985807
Iter: 153 loss: 0.00030247384
Iter: 154 loss: 0.000339177641
Iter: 155 loss: 0.000302207
Iter: 156 loss: 0.000298642262
Iter: 157 loss: 0.00030070002
Iter: 158 loss: 0.000296302023
Iter: 159 loss: 0.000292788929
Iter: 160 loss: 0.000304053072
Iter: 161 loss: 0.000291822565
Iter: 162 loss: 0.000288583164
Iter: 163 loss: 0.000316073361
Iter: 164 loss: 0.000288386742
Iter: 165 loss: 0.000285898277
Iter: 166 loss: 0.000285649498
Iter: 167 loss: 0.000283832953
Iter: 168 loss: 0.000280553184
Iter: 169 loss: 0.000280980836
Iter: 170 loss: 0.000278045802
Iter: 171 loss: 0.00027367397
Iter: 172 loss: 0.000284551323
Iter: 173 loss: 0.000272139529
Iter: 174 loss: 0.000268567033
Iter: 175 loss: 0.000307690061
Iter: 176 loss: 0.000268484087
Iter: 177 loss: 0.000265521434
Iter: 178 loss: 0.000278169289
Iter: 179 loss: 0.000264923758
Iter: 180 loss: 0.000262150803
Iter: 181 loss: 0.00026791339
Iter: 182 loss: 0.00026102853
Iter: 183 loss: 0.000258470362
Iter: 184 loss: 0.000261280045
Iter: 185 loss: 0.000257087639
Iter: 186 loss: 0.000254806131
Iter: 187 loss: 0.000279966742
Iter: 188 loss: 0.000254752085
Iter: 189 loss: 0.000252693717
Iter: 190 loss: 0.000255043735
Iter: 191 loss: 0.000251595746
Iter: 192 loss: 0.000249805744
Iter: 193 loss: 0.000254299899
Iter: 194 loss: 0.000249169
Iter: 195 loss: 0.000247430289
Iter: 196 loss: 0.000264112634
Iter: 197 loss: 0.000247368444
Iter: 198 loss: 0.000245994306
Iter: 199 loss: 0.000246547919
Iter: 200 loss: 0.000245040748
Iter: 201 loss: 0.000243428862
Iter: 202 loss: 0.000241642585
Iter: 203 loss: 0.000241389833
Iter: 204 loss: 0.000238735243
Iter: 205 loss: 0.00025221231
Iter: 206 loss: 0.000238292589
Iter: 207 loss: 0.000236005173
Iter: 208 loss: 0.000244872179
Iter: 209 loss: 0.000235473868
Iter: 210 loss: 0.00023355658
Iter: 211 loss: 0.000252547325
Iter: 212 loss: 0.000233486513
Iter: 213 loss: 0.000231897182
Iter: 214 loss: 0.00023275087
Iter: 215 loss: 0.000230856938
Iter: 216 loss: 0.000229043275
Iter: 217 loss: 0.000235334592
Iter: 218 loss: 0.000228557605
Iter: 219 loss: 0.000227056866
Iter: 220 loss: 0.000229798738
Iter: 221 loss: 0.000226415345
Iter: 222 loss: 0.000224567193
Iter: 223 loss: 0.000238839944
Iter: 224 loss: 0.000224424293
Iter: 225 loss: 0.000223419425
Iter: 226 loss: 0.000223125346
Iter: 227 loss: 0.000222523056
Iter: 228 loss: 0.000221189199
Iter: 229 loss: 0.000235533123
Iter: 230 loss: 0.000221153983
Iter: 231 loss: 0.000220115442
Iter: 232 loss: 0.000221411348
Iter: 233 loss: 0.00021957951
Iter: 234 loss: 0.000218419955
Iter: 235 loss: 0.000217507928
Iter: 236 loss: 0.000217148132
Iter: 237 loss: 0.000215543958
Iter: 238 loss: 0.000220885762
Iter: 239 loss: 0.000215106702
Iter: 240 loss: 0.00021351999
Iter: 241 loss: 0.000219317924
Iter: 242 loss: 0.000213118532
Iter: 243 loss: 0.000211863138
Iter: 244 loss: 0.000224835108
Iter: 245 loss: 0.000211830091
Iter: 246 loss: 0.000210735117
Iter: 247 loss: 0.000212498067
Iter: 248 loss: 0.000210224011
Iter: 249 loss: 0.000209154299
Iter: 250 loss: 0.000211319275
Iter: 251 loss: 0.000208722835
Iter: 252 loss: 0.000207601988
Iter: 253 loss: 0.000210521772
Iter: 254 loss: 0.000207217134
Iter: 255 loss: 0.000206276047
Iter: 256 loss: 0.000215769265
Iter: 257 loss: 0.000206248893
Iter: 258 loss: 0.00020554263
Iter: 259 loss: 0.000205215532
Iter: 260 loss: 0.000204864336
Iter: 261 loss: 0.00020401596
Iter: 262 loss: 0.000210958198
Iter: 263 loss: 0.000203965523
Iter: 264 loss: 0.000203158488
Iter: 265 loss: 0.000204493685
Iter: 266 loss: 0.000202789175
Iter: 267 loss: 0.000202049079
Iter: 268 loss: 0.000201881747
Iter: 269 loss: 0.000201403833
Iter: 270 loss: 0.000200318638
Iter: 271 loss: 0.00020200407
Iter: 272 loss: 0.000199808157
Iter: 273 loss: 0.000198706461
Iter: 274 loss: 0.000202220297
Iter: 275 loss: 0.000198393012
Iter: 276 loss: 0.000197549525
Iter: 277 loss: 0.000207622288
Iter: 278 loss: 0.000197537534
Iter: 279 loss: 0.000196826906
Iter: 280 loss: 0.000198375055
Iter: 281 loss: 0.000196554625
Iter: 282 loss: 0.000195775312
Iter: 283 loss: 0.000196788824
Iter: 284 loss: 0.000195376066
Iter: 285 loss: 0.000194594526
Iter: 286 loss: 0.000197544068
Iter: 287 loss: 0.000194408989
Iter: 288 loss: 0.000193725398
Iter: 289 loss: 0.000198159571
Iter: 290 loss: 0.000193649292
Iter: 291 loss: 0.000193063985
Iter: 292 loss: 0.000193550513
Iter: 293 loss: 0.000192716368
Iter: 294 loss: 0.000192113541
Iter: 295 loss: 0.000193988264
Iter: 296 loss: 0.000191935
Iter: 297 loss: 0.000191298721
Iter: 298 loss: 0.000195080138
Iter: 299 loss: 0.000191218831
Iter: 300 loss: 0.000190769992
Iter: 301 loss: 0.000190177685
Iter: 302 loss: 0.000190142106
Iter: 303 loss: 0.000189340441
Iter: 304 loss: 0.000192045089
Iter: 305 loss: 0.000189123442
Iter: 306 loss: 0.000188388658
Iter: 307 loss: 0.000189533312
Iter: 308 loss: 0.000188042643
Iter: 309 loss: 0.000187379483
Iter: 310 loss: 0.000192819207
Iter: 311 loss: 0.000187339101
Iter: 312 loss: 0.000186716788
Iter: 313 loss: 0.000189173108
Iter: 314 loss: 0.000186573045
Iter: 315 loss: 0.000186080288
Iter: 316 loss: 0.000186934776
Iter: 317 loss: 0.000185862387
Iter: 318 loss: 0.000185313882
Iter: 319 loss: 0.000185898534
Iter: 320 loss: 0.000185010358
Iter: 321 loss: 0.00018449832
Iter: 322 loss: 0.000189827289
Iter: 323 loss: 0.000184485034
Iter: 324 loss: 0.00018406639
Iter: 325 loss: 0.000184542616
Iter: 326 loss: 0.00018384037
Iter: 327 loss: 0.000183390977
Iter: 328 loss: 0.000184150515
Iter: 329 loss: 0.000183189899
Iter: 330 loss: 0.000182717617
Iter: 331 loss: 0.000186688325
Iter: 332 loss: 0.000182689342
Iter: 333 loss: 0.000182321906
Iter: 334 loss: 0.000181818148
Iter: 335 loss: 0.000181794545
Iter: 336 loss: 0.000181225856
Iter: 337 loss: 0.000183426921
Iter: 338 loss: 0.000181091935
Iter: 339 loss: 0.000180515344
Iter: 340 loss: 0.000181196359
Iter: 341 loss: 0.000180209667
Iter: 342 loss: 0.000179673603
Iter: 343 loss: 0.000183213473
Iter: 344 loss: 0.000179616938
Iter: 345 loss: 0.000179152281
Iter: 346 loss: 0.000182799515
Iter: 347 loss: 0.00017912066
Iter: 348 loss: 0.00017878064
Iter: 349 loss: 0.000179080642
Iter: 350 loss: 0.000178581104
Iter: 351 loss: 0.000178156566
Iter: 352 loss: 0.000179068651
Iter: 353 loss: 0.000177991285
Iter: 354 loss: 0.000177625261
Iter: 355 loss: 0.000180356292
Iter: 356 loss: 0.000177595328
Iter: 357 loss: 0.000177275186
Iter: 358 loss: 0.000177942449
Iter: 359 loss: 0.000177148206
Iter: 360 loss: 0.000176842819
Iter: 361 loss: 0.000177246373
Iter: 362 loss: 0.000176687405
Iter: 363 loss: 0.000176362373
Iter: 364 loss: 0.000179347509
Iter: 365 loss: 0.000176348214
Iter: 366 loss: 0.000176092173
Iter: 367 loss: 0.000175834517
Iter: 368 loss: 0.000175782887
Iter: 369 loss: 0.000175402864
Iter: 370 loss: 0.000175895912
Iter: 371 loss: 0.000175209279
Iter: 372 loss: 0.00017477147
Iter: 373 loss: 0.000176285335
Iter: 374 loss: 0.000174656016
Iter: 375 loss: 0.000174268556
Iter: 376 loss: 0.000175558147
Iter: 377 loss: 0.000174163171
Iter: 378 loss: 0.000173846347
Iter: 379 loss: 0.000177561131
Iter: 380 loss: 0.000173841632
Iter: 381 loss: 0.000173580251
Iter: 382 loss: 0.000173599561
Iter: 383 loss: 0.000173376931
Iter: 384 loss: 0.000173075212
Iter: 385 loss: 0.000174356901
Iter: 386 loss: 0.000173011722
Iter: 387 loss: 0.000172739848
Iter: 388 loss: 0.000173518958
Iter: 389 loss: 0.000172654749
Iter: 390 loss: 0.000172381406
Iter: 391 loss: 0.000173840745
Iter: 392 loss: 0.000172339292
Iter: 393 loss: 0.000172131069
Iter: 394 loss: 0.000172153028
Iter: 395 loss: 0.0001719711
Iter: 396 loss: 0.000171733991
Iter: 397 loss: 0.000174553134
Iter: 398 loss: 0.000171730644
Iter: 399 loss: 0.000171541848
Iter: 400 loss: 0.000171392079
Iter: 401 loss: 0.000171334512
Iter: 402 loss: 0.00017103579
Iter: 403 loss: 0.000171238091
Iter: 404 loss: 0.000170848303
Iter: 405 loss: 0.000170507279
Iter: 406 loss: 0.00017140081
Iter: 407 loss: 0.000170391955
Iter: 408 loss: 0.000170062
Iter: 409 loss: 0.000171585794
Iter: 410 loss: 0.000169999548
Iter: 411 loss: 0.00016970982
Iter: 412 loss: 0.000171574036
Iter: 413 loss: 0.000169678315
Iter: 414 loss: 0.000169402789
Iter: 415 loss: 0.000170074112
Iter: 416 loss: 0.00016930385
Iter: 417 loss: 0.000169081526
Iter: 418 loss: 0.000169374893
Iter: 419 loss: 0.000168969273
Iter: 420 loss: 0.000168702521
Iter: 421 loss: 0.000169966355
Iter: 422 loss: 0.0001686537
Iter: 423 loss: 0.0001684374
Iter: 424 loss: 0.00016965314
Iter: 425 loss: 0.000168407365
Iter: 426 loss: 0.000168220082
Iter: 427 loss: 0.000168185798
Iter: 428 loss: 0.00016805937
Iter: 429 loss: 0.000167871491
Iter: 430 loss: 0.000170475221
Iter: 431 loss: 0.000167870661
Iter: 432 loss: 0.000167709368
Iter: 433 loss: 0.000167536025
Iter: 434 loss: 0.000167508304
Iter: 435 loss: 0.000167238759
Iter: 436 loss: 0.000167650316
Iter: 437 loss: 0.000167111037
Iter: 438 loss: 0.000166822865
Iter: 439 loss: 0.000167214253
Iter: 440 loss: 0.000166678641
Iter: 441 loss: 0.000166372512
Iter: 442 loss: 0.000167732491
Iter: 443 loss: 0.000166312442
Iter: 444 loss: 0.000166045851
Iter: 445 loss: 0.000168030369
Iter: 446 loss: 0.000166024212
Iter: 447 loss: 0.000165790902
Iter: 448 loss: 0.000166555619
Iter: 449 loss: 0.000165726582
Iter: 450 loss: 0.000165527774
Iter: 451 loss: 0.000165554477
Iter: 452 loss: 0.000165376085
Iter: 453 loss: 0.00016512291
Iter: 454 loss: 0.000166748
Iter: 455 loss: 0.000165095174
Iter: 456 loss: 0.000164904865
Iter: 457 loss: 0.000165695645
Iter: 458 loss: 0.00016486377
Iter: 459 loss: 0.000164681289
Iter: 460 loss: 0.000164809375
Iter: 461 loss: 0.00016456822
Iter: 462 loss: 0.000164380879
Iter: 463 loss: 0.000165585516
Iter: 464 loss: 0.000164359633
Iter: 465 loss: 0.000164162775
Iter: 466 loss: 0.000164241559
Iter: 467 loss: 0.000164026598
Iter: 468 loss: 0.000163818884
Iter: 469 loss: 0.000163896621
Iter: 470 loss: 0.000163673627
Iter: 471 loss: 0.000163413119
Iter: 472 loss: 0.000163996068
Iter: 473 loss: 0.000163314166
Iter: 474 loss: 0.000163033023
Iter: 475 loss: 0.000163780584
Iter: 476 loss: 0.000162938421
Iter: 477 loss: 0.000162712779
Iter: 478 loss: 0.000165061792
Iter: 479 loss: 0.000162706769
Iter: 480 loss: 0.000162506592
Iter: 481 loss: 0.000162982818
Iter: 482 loss: 0.0001624336
Iter: 483 loss: 0.000162243814
Iter: 484 loss: 0.000162430864
Iter: 485 loss: 0.000162136595
Iter: 486 loss: 0.000161919714
Iter: 487 loss: 0.000162950411
Iter: 488 loss: 0.000161880336
Iter: 489 loss: 0.000161700766
Iter: 490 loss: 0.000162708369
Iter: 491 loss: 0.000161675605
Iter: 492 loss: 0.000161530304
Iter: 493 loss: 0.000161665419
Iter: 494 loss: 0.000161446413
Iter: 495 loss: 0.000161281234
Iter: 496 loss: 0.000161927819
Iter: 497 loss: 0.000161243413
Iter: 498 loss: 0.000161070551
Iter: 499 loss: 0.000161603602
Iter: 500 loss: 0.000161019532
Iter: 501 loss: 0.000160880067
Iter: 502 loss: 0.000160721102
Iter: 503 loss: 0.000160700918
Iter: 504 loss: 0.000160477139
Iter: 505 loss: 0.000161263393
Iter: 506 loss: 0.000160419062
Iter: 507 loss: 0.00016018562
Iter: 508 loss: 0.00016081729
Iter: 509 loss: 0.000160108335
Iter: 510 loss: 0.000159914343
Iter: 511 loss: 0.00016124142
Iter: 512 loss: 0.000159895309
Iter: 513 loss: 0.000159719784
Iter: 514 loss: 0.000160675918
Iter: 515 loss: 0.000159694
Iter: 516 loss: 0.000159567484
Iter: 517 loss: 0.00015960107
Iter: 518 loss: 0.000159475574
Iter: 519 loss: 0.00015930763
Iter: 520 loss: 0.000160031079
Iter: 521 loss: 0.000159273244
Iter: 522 loss: 0.000159141637
Iter: 523 loss: 0.00016006743
Iter: 524 loss: 0.00015912985
Iter: 525 loss: 0.000159024406
Iter: 526 loss: 0.000159106741
Iter: 527 loss: 0.000158960989
Iter: 528 loss: 0.000158844123
Iter: 529 loss: 0.000159333751
Iter: 530 loss: 0.000158818555
Iter: 531 loss: 0.000158701441
Iter: 532 loss: 0.000159072049
Iter: 533 loss: 0.000158667521
Iter: 534 loss: 0.000158556941
Iter: 535 loss: 0.000158438575
Iter: 536 loss: 0.000158419629
Iter: 537 loss: 0.000158252689
Iter: 538 loss: 0.000158556417
Iter: 539 loss: 0.000158180541
Iter: 540 loss: 0.000157990231
Iter: 541 loss: 0.000158909184
Iter: 542 loss: 0.000157956631
Iter: 543 loss: 0.000157807197
Iter: 544 loss: 0.000158475756
Iter: 545 loss: 0.000157778355
Iter: 546 loss: 0.000157648959
Iter: 547 loss: 0.000158777882
Iter: 548 loss: 0.00015764212
Iter: 549 loss: 0.000157549279
Iter: 550 loss: 0.000157506918
Iter: 551 loss: 0.000157460716
Iter: 552 loss: 0.000157331495
Iter: 553 loss: 0.000158058101
Iter: 554 loss: 0.000157313247
Iter: 555 loss: 0.000157209084
Iter: 556 loss: 0.000157734496
Iter: 557 loss: 0.000157191927
Iter: 558 loss: 0.000157101764
Iter: 559 loss: 0.000157255272
Iter: 560 loss: 0.000157061397
Iter: 561 loss: 0.000156971364
Iter: 562 loss: 0.00015720923
Iter: 563 loss: 0.000156941358
Iter: 564 loss: 0.000156839465
Iter: 565 loss: 0.000157234797
Iter: 566 loss: 0.000156815542
Iter: 567 loss: 0.000156726077
Iter: 568 loss: 0.000156647555
Iter: 569 loss: 0.000156624199
Iter: 570 loss: 0.00015648728
Iter: 571 loss: 0.000156788912
Iter: 572 loss: 0.000156434704
Iter: 573 loss: 0.000156293958
Iter: 574 loss: 0.00015662545
Iter: 575 loss: 0.000156242517
Iter: 576 loss: 0.000156109774
Iter: 577 loss: 0.000157094619
Iter: 578 loss: 0.000156099093
Iter: 579 loss: 0.000155992515
Iter: 580 loss: 0.000156676397
Iter: 581 loss: 0.000155980888
Iter: 582 loss: 0.000155890564
Iter: 583 loss: 0.000155961374
Iter: 584 loss: 0.000155836
Iter: 585 loss: 0.000155741174
Iter: 586 loss: 0.000155979098
Iter: 587 loss: 0.000155708141
Iter: 588 loss: 0.00015560555
Iter: 589 loss: 0.000156188908
Iter: 590 loss: 0.000155591377
Iter: 591 loss: 0.000155511021
Iter: 592 loss: 0.000155699876
Iter: 593 loss: 0.000155481874
Iter: 594 loss: 0.000155402013
Iter: 595 loss: 0.000155540009
Iter: 596 loss: 0.000155366506
Iter: 597 loss: 0.000155280795
Iter: 598 loss: 0.000155832458
Iter: 599 loss: 0.000155271526
Iter: 600 loss: 0.000155201589
Iter: 601 loss: 0.00015509584
Iter: 602 loss: 0.000155093643
Iter: 603 loss: 0.000154967769
Iter: 604 loss: 0.000155391856
Iter: 605 loss: 0.000154933659
Iter: 606 loss: 0.000154812908
Iter: 607 loss: 0.000155032583
Iter: 608 loss: 0.000154760623
Iter: 609 loss: 0.000154647918
Iter: 610 loss: 0.000155353744
Iter: 611 loss: 0.000154634618
Iter: 612 loss: 0.000154537425
Iter: 613 loss: 0.000155225338
Iter: 614 loss: 0.000154528563
Iter: 615 loss: 0.000154452515
Iter: 616 loss: 0.000154558977
Iter: 617 loss: 0.000154414796
Iter: 618 loss: 0.00015433412
Iter: 619 loss: 0.000154427195
Iter: 620 loss: 0.000154291
Iter: 621 loss: 0.000154202251
Iter: 622 loss: 0.000154975089
Iter: 623 loss: 0.000154197754
Iter: 624 loss: 0.000154130743
Iter: 625 loss: 0.000154210938
Iter: 626 loss: 0.000154095527
Iter: 627 loss: 0.000154018955
Iter: 628 loss: 0.000154206209
Iter: 629 loss: 0.000153991801
Iter: 630 loss: 0.000153918256
Iter: 631 loss: 0.00015434841
Iter: 632 loss: 0.000153908331
Iter: 633 loss: 0.000153841262
Iter: 634 loss: 0.000153762114
Iter: 635 loss: 0.000153753557
Iter: 636 loss: 0.000153646848
Iter: 637 loss: 0.000153873887
Iter: 638 loss: 0.000153604895
Iter: 639 loss: 0.000153494737
Iter: 640 loss: 0.000153811678
Iter: 641 loss: 0.000153460045
Iter: 642 loss: 0.00015335955
Iter: 643 loss: 0.000153824891
Iter: 644 loss: 0.000153340807
Iter: 645 loss: 0.000153257657
Iter: 646 loss: 0.000154033653
Iter: 647 loss: 0.000153254543
Iter: 648 loss: 0.000153184708
Iter: 649 loss: 0.000153216824
Iter: 650 loss: 0.000153137444
Iter: 651 loss: 0.000153058238
Iter: 652 loss: 0.000153259607
Iter: 653 loss: 0.000153030705
Iter: 654 loss: 0.000152955414
Iter: 655 loss: 0.00015345015
Iter: 656 loss: 0.000152947177
Iter: 657 loss: 0.000152883862
Iter: 658 loss: 0.000153024885
Iter: 659 loss: 0.000152859779
Iter: 660 loss: 0.000152800319
Iter: 661 loss: 0.000152925088
Iter: 662 loss: 0.000152776658
Iter: 663 loss: 0.000152713008
Iter: 664 loss: 0.000153033296
Iter: 665 loss: 0.000152702531
Iter: 666 loss: 0.000152645298
Iter: 667 loss: 0.000152643246
Iter: 668 loss: 0.000152598979
Iter: 669 loss: 0.000152524139
Iter: 670 loss: 0.000152514651
Iter: 671 loss: 0.000152461464
Iter: 672 loss: 0.000152361812
Iter: 673 loss: 0.00015266909
Iter: 674 loss: 0.000152332417
Iter: 675 loss: 0.000152242879
Iter: 676 loss: 0.000152844266
Iter: 677 loss: 0.000152233828
Iter: 678 loss: 0.000152163411
Iter: 679 loss: 0.000152588909
Iter: 680 loss: 0.000152154797
Iter: 681 loss: 0.000152086097
Iter: 682 loss: 0.000152204884
Iter: 683 loss: 0.000152055291
Iter: 684 loss: 0.000151993983
Iter: 685 loss: 0.000152084263
Iter: 686 loss: 0.000151964472
Iter: 687 loss: 0.000151897
Iter: 688 loss: 0.0001523674
Iter: 689 loss: 0.000151890883
Iter: 690 loss: 0.000151839136
Iter: 691 loss: 0.000152000561
Iter: 692 loss: 0.000151824381
Iter: 693 loss: 0.000151778222
Iter: 694 loss: 0.000151831046
Iter: 695 loss: 0.000151753513
Iter: 696 loss: 0.000151702116
Iter: 697 loss: 0.000152037974
Iter: 698 loss: 0.000151696295
Iter: 699 loss: 0.000151651795
Iter: 700 loss: 0.000151634682
Iter: 701 loss: 0.00015161038
Iter: 702 loss: 0.000151545348
Iter: 703 loss: 0.000151597662
Iter: 704 loss: 0.000151506203
Iter: 705 loss: 0.000151432614
Iter: 706 loss: 0.000151538436
Iter: 707 loss: 0.000151396962
Iter: 708 loss: 0.000151318847
Iter: 709 loss: 0.000151784421
Iter: 710 loss: 0.000151308894
Iter: 711 loss: 0.000151246451
Iter: 712 loss: 0.000151764427
Iter: 713 loss: 0.000151242682
Iter: 714 loss: 0.000151190528
Iter: 715 loss: 0.000151313
Iter: 716 loss: 0.00015117132
Iter: 717 loss: 0.000151122804
Iter: 718 loss: 0.000151149128
Iter: 719 loss: 0.000151091124
Iter: 720 loss: 0.000151036511
Iter: 721 loss: 0.000151473971
Iter: 722 loss: 0.00015103296
Iter: 723 loss: 0.000150988693
Iter: 724 loss: 0.000151114335
Iter: 725 loss: 0.000150974927
Iter: 726 loss: 0.00015093651
Iter: 727 loss: 0.00015101787
Iter: 728 loss: 0.000150921609
Iter: 729 loss: 0.00015088229
Iter: 730 loss: 0.000151060944
Iter: 731 loss: 0.000150874897
Iter: 732 loss: 0.000150835607
Iter: 733 loss: 0.000150840322
Iter: 734 loss: 0.000150805543
Iter: 735 loss: 0.000150756343
Iter: 736 loss: 0.000150760199
Iter: 737 loss: 0.000150717664
Iter: 738 loss: 0.000150653868
Iter: 739 loss: 0.00015084265
Iter: 740 loss: 0.0001506345
Iter: 741 loss: 0.000150570966
Iter: 742 loss: 0.000150762906
Iter: 743 loss: 0.000150551859
Iter: 744 loss: 0.000150502
Iter: 745 loss: 0.000151077489
Iter: 746 loss: 0.000150501321
Iter: 747 loss: 0.000150456501
Iter: 748 loss: 0.000150528533
Iter: 749 loss: 0.000150436157
Iter: 750 loss: 0.000150393549
Iter: 751 loss: 0.000150472915
Iter: 752 loss: 0.000150375476
Iter: 753 loss: 0.000150331151
Iter: 754 loss: 0.000150517517
Iter: 755 loss: 0.000150321619
Iter: 756 loss: 0.000150280219
Iter: 757 loss: 0.000150491222
Iter: 758 loss: 0.000150273714
Iter: 759 loss: 0.00015024461
Iter: 760 loss: 0.000150277177
Iter: 761 loss: 0.000150229273
Iter: 762 loss: 0.000150194202
Iter: 763 loss: 0.000150344771
Iter: 764 loss: 0.00015018681
Iter: 765 loss: 0.000150152249
Iter: 766 loss: 0.000150182415
Iter: 767 loss: 0.000150132
Iter: 768 loss: 0.000150090549
Iter: 769 loss: 0.000150069594
Iter: 770 loss: 0.000150050444
Iter: 771 loss: 0.000149995074
Iter: 772 loss: 0.000150159147
Iter: 773 loss: 0.000149978237
Iter: 774 loss: 0.000149922038
Iter: 775 loss: 0.000150130189
Iter: 776 loss: 0.000149908519
Iter: 777 loss: 0.000149863263
Iter: 778 loss: 0.000150246458
Iter: 779 loss: 0.000149860731
Iter: 780 loss: 0.000149820276
Iter: 781 loss: 0.000149958738
Iter: 782 loss: 0.000149809348
Iter: 783 loss: 0.000149776839
Iter: 784 loss: 0.000149790925
Iter: 785 loss: 0.000149754604
Iter: 786 loss: 0.000149713771
Iter: 787 loss: 0.000149939093
Iter: 788 loss: 0.000149707892
Iter: 789 loss: 0.00014967451
Iter: 790 loss: 0.000149854837
Iter: 791 loss: 0.000149669562
Iter: 792 loss: 0.000149644125
Iter: 793 loss: 0.000149663465
Iter: 794 loss: 0.000149628497
Iter: 795 loss: 0.000149597836
Iter: 796 loss: 0.00014975002
Iter: 797 loss: 0.000149592641
Iter: 798 loss: 0.000149562373
Iter: 799 loss: 0.000149578918
Iter: 800 loss: 0.000149542728
Iter: 801 loss: 0.000149506872
Iter: 802 loss: 0.000149520056
Iter: 803 loss: 0.000149481784
Iter: 804 loss: 0.000149436586
Iter: 805 loss: 0.000149499581
Iter: 806 loss: 0.000149414613
Iter: 807 loss: 0.000149363565
Iter: 808 loss: 0.000149516636
Iter: 809 loss: 0.0001493483
Iter: 810 loss: 0.00014931045
Iter: 811 loss: 0.00014979062
Iter: 812 loss: 0.000149310174
Iter: 813 loss: 0.000149277097
Iter: 814 loss: 0.000149358326
Iter: 815 loss: 0.000149265456
Iter: 816 loss: 0.00014923235
Iter: 817 loss: 0.000149264699
Iter: 818 loss: 0.000149213534
Iter: 819 loss: 0.000149179512
Iter: 820 loss: 0.000149349013
Iter: 821 loss: 0.000149174011
Iter: 822 loss: 0.00014914418
Iter: 823 loss: 0.000149305619
Iter: 824 loss: 0.000149139596
Iter: 825 loss: 0.000149117332
Iter: 826 loss: 0.000149141124
Iter: 827 loss: 0.000149105093
Iter: 828 loss: 0.000149078129
Iter: 829 loss: 0.000149169035
Iter: 830 loss: 0.000149070736
Iter: 831 loss: 0.000149042433
Iter: 832 loss: 0.000149101019
Iter: 833 loss: 0.000149030966
Iter: 834 loss: 0.000149004598
Iter: 835 loss: 0.000148989537
Iter: 836 loss: 0.000148977953
Iter: 837 loss: 0.000148937615
Iter: 838 loss: 0.000149045431
Iter: 839 loss: 0.000148923864
Iter: 840 loss: 0.000148882522
Iter: 841 loss: 0.000148966938
Iter: 842 loss: 0.000148866035
Iter: 843 loss: 0.000148831474
Iter: 844 loss: 0.000149157029
Iter: 845 loss: 0.000148830179
Iter: 846 loss: 0.000148797582
Iter: 847 loss: 0.000148923325
Iter: 848 loss: 0.000148790248
Iter: 849 loss: 0.000148763662
Iter: 850 loss: 0.000148783787
Iter: 851 loss: 0.000148747742
Iter: 852 loss: 0.000148717663
Iter: 853 loss: 0.000148842038
Iter: 854 loss: 0.00014871094
Iter: 855 loss: 0.00014868546
Iter: 856 loss: 0.000148860272
Iter: 857 loss: 0.000148682826
Iter: 858 loss: 0.00014866321
Iter: 859 loss: 0.000148675492
Iter: 860 loss: 0.00014865071
Iter: 861 loss: 0.000148627762
Iter: 862 loss: 0.000148740772
Iter: 863 loss: 0.000148623818
Iter: 864 loss: 0.000148601714
Iter: 865 loss: 0.000148633204
Iter: 866 loss: 0.000148591163
Iter: 867 loss: 0.000148567517
Iter: 868 loss: 0.000148563588
Iter: 869 loss: 0.000148547231
Iter: 870 loss: 0.000148514
Iter: 871 loss: 0.000148568623
Iter: 872 loss: 0.000148498948
Iter: 873 loss: 0.000148463
Iter: 874 loss: 0.00014854988
Iter: 875 loss: 0.000148450374
Iter: 876 loss: 0.000148418083
Iter: 877 loss: 0.000148681254
Iter: 878 loss: 0.000148416206
Iter: 879 loss: 0.000148388906
Iter: 880 loss: 0.000148556879
Iter: 881 loss: 0.000148385981
Iter: 882 loss: 0.000148364023
Iter: 883 loss: 0.000148368854
Iter: 884 loss: 0.000148347855
Iter: 885 loss: 0.00014832367
Iter: 886 loss: 0.000148445688
Iter: 887 loss: 0.000148319421
Iter: 888 loss: 0.00014829784
Iter: 889 loss: 0.000148406514
Iter: 890 loss: 0.000148294203
Iter: 891 loss: 0.000148277
Iter: 892 loss: 0.000148313062
Iter: 893 loss: 0.000148270105
Iter: 894 loss: 0.000148253283
Iter: 895 loss: 0.000148300693
Iter: 896 loss: 0.000148247927
Iter: 897 loss: 0.000148228661
Iter: 898 loss: 0.000148264633
Iter: 899 loss: 0.00014822057
Iter: 900 loss: 0.000148200867
Iter: 901 loss: 0.000148193445
Iter: 902 loss: 0.000148182953
Iter: 903 loss: 0.000148153325
Iter: 904 loss: 0.000148225779
Iter: 905 loss: 0.000148143037
Iter: 906 loss: 0.000148113977
Iter: 907 loss: 0.000148143765
Iter: 908 loss: 0.000148097708
Iter: 909 loss: 0.000148068691
Iter: 910 loss: 0.000148332227
Iter: 911 loss: 0.00014806712
Iter: 912 loss: 0.000148043837
Iter: 913 loss: 0.000148222956
Iter: 914 loss: 0.00014804196
Iter: 915 loss: 0.000148025225
Iter: 916 loss: 0.000148034218
Iter: 917 loss: 0.000148014224
Iter: 918 loss: 0.000147994608
Iter: 919 loss: 0.000148052946
Iter: 920 loss: 0.000147988991
Iter: 921 loss: 0.00014797051
Iter: 922 loss: 0.000148100735
Iter: 923 loss: 0.00014796872
Iter: 924 loss: 0.000147955128
Iter: 925 loss: 0.000147975705
Iter: 926 loss: 0.000147948493
Iter: 927 loss: 0.000147934392
Iter: 928 loss: 0.000147978702
Iter: 929 loss: 0.000147930114
Iter: 930 loss: 0.000147914165
Iter: 931 loss: 0.00014794436
Iter: 932 loss: 0.0001479075
Iter: 933 loss: 0.000147890183
Iter: 934 loss: 0.000147884304
Iter: 935 loss: 0.00014787438
Iter: 936 loss: 0.000147850049
Iter: 937 loss: 0.000147903746
Iter: 938 loss: 0.000147840925
Iter: 939 loss: 0.000147815881
Iter: 940 loss: 0.000147859595
Iter: 941 loss: 0.000147805054
Iter: 942 loss: 0.000147779647
Iter: 943 loss: 0.000147931423
Iter: 944 loss: 0.000147776314
Iter: 945 loss: 0.000147758416
Iter: 946 loss: 0.000147983606
Iter: 947 loss: 0.000147758314
Iter: 948 loss: 0.000147744635
Iter: 949 loss: 0.000147738552
Iter: 950 loss: 0.000147731276
Iter: 951 loss: 0.000147714134
Iter: 952 loss: 0.000147795377
Iter: 953 loss: 0.000147711122
Iter: 954 loss: 0.000147695624
Iter: 955 loss: 0.000147774699
Iter: 956 loss: 0.000147693092
Iter: 957 loss: 0.000147680184
Iter: 958 loss: 0.000147711879
Iter: 959 loss: 0.000147675717
Iter: 960 loss: 0.00014766361
Iter: 961 loss: 0.000147685831
Iter: 962 loss: 0.000147658517
Iter: 963 loss: 0.000147643412
Iter: 964 loss: 0.000147681567
Iter: 965 loss: 0.000147638013
Iter: 966 loss: 0.000147623636
Iter: 967 loss: 0.000147624436
Iter: 968 loss: 0.000147612067
Iter: 969 loss: 0.000147592262
Iter: 970 loss: 0.000147617509
Iter: 971 loss: 0.000147582017
Iter: 972 loss: 0.000147559855
Iter: 973 loss: 0.000147594648
Iter: 974 loss: 0.000147549566
Iter: 975 loss: 0.000147527739
Iter: 976 loss: 0.000147685059
Iter: 977 loss: 0.00014752589
Iter: 978 loss: 0.000147509418
Iter: 979 loss: 0.000147670245
Iter: 980 loss: 0.000147508894
Iter: 981 loss: 0.00014749539
Iter: 982 loss: 0.000147498678
Iter: 983 loss: 0.000147485582
Iter: 984 loss: 0.000147471234
Iter: 985 loss: 0.000147518411
Iter: 986 loss: 0.00014746713
Iter: 987 loss: 0.000147453829
Iter: 988 loss: 0.000147544604
Iter: 989 loss: 0.000147452301
Iter: 990 loss: 0.00014744178
Iter: 991 loss: 0.00014745917
Iter: 992 loss: 0.000147436745
Iter: 993 loss: 0.000147425293
Iter: 994 loss: 0.000147450235
Iter: 995 loss: 0.000147420826
Iter: 996 loss: 0.000147407976
Iter: 997 loss: 0.000147453349
Iter: 998 loss: 0.000147404542
Iter: 999 loss: 0.000147392944
Iter: 1000 loss: 0.000147388724
Iter: 1001 loss: 0.000147382118
Iter: 1002 loss: 0.000147364539
Iter: 1003 loss: 0.000147383951
Iter: 1004 loss: 0.000147355167
Iter: 1005 loss: 0.000147335
Iter: 1006 loss: 0.000147389117
Iter: 1007 loss: 0.000147328232
Iter: 1008 loss: 0.000147309154
Iter: 1009 loss: 0.000147385203
Iter: 1010 loss: 0.000147304658
Iter: 1011 loss: 0.000147291517
Iter: 1012 loss: 0.000147496597
Iter: 1013 loss: 0.000147291314
Iter: 1014 loss: 0.000147280109
Iter: 1015 loss: 0.000147277693
Iter: 1016 loss: 0.000147270315
Iter: 1017 loss: 0.000147257408
Iter: 1018 loss: 0.000147308543
Iter: 1019 loss: 0.000147254483
Iter: 1020 loss: 0.000147242637
Iter: 1021 loss: 0.000147307917
Iter: 1022 loss: 0.000147240877
Iter: 1023 loss: 0.000147230865
Iter: 1024 loss: 0.000147257655
Iter: 1025 loss: 0.000147227474
Iter: 1026 loss: 0.000147218423
Iter: 1027 loss: 0.000147233543
Iter: 1028 loss: 0.000147214145
Iter: 1029 loss: 0.000147202983
Iter: 1030 loss: 0.000147238112
Iter: 1031 loss: 0.000147199826
Iter: 1032 loss: 0.000147189261
Iter: 1033 loss: 0.000147190207
Iter: 1034 loss: 0.000147181025
Iter: 1035 loss: 0.000147166676
Iter: 1036 loss: 0.000147178755
Iter: 1037 loss: 0.000147157931
Iter: 1038 loss: 0.000147141385
Iter: 1039 loss: 0.000147174142
Iter: 1040 loss: 0.000147134153
Iter: 1041 loss: 0.000147116923
Iter: 1042 loss: 0.000147205355
Iter: 1043 loss: 0.000147113882
Iter: 1044 loss: 0.000147102226
Iter: 1045 loss: 0.000147248938
Iter: 1046 loss: 0.000147101935
Iter: 1047 loss: 0.000147091501
Iter: 1048 loss: 0.000147098457
Iter: 1049 loss: 0.000147084924
Iter: 1050 loss: 0.000147074083
Iter: 1051 loss: 0.000147093378
Iter: 1052 loss: 0.00014706979
Iter: 1053 loss: 0.000147058439
Iter: 1054 loss: 0.000147146784
Iter: 1055 loss: 0.000147057959
Iter: 1056 loss: 0.000147049504
Iter: 1057 loss: 0.0001470672
Iter: 1058 loss: 0.000147046056
Iter: 1059 loss: 0.000147037848
Iter: 1060 loss: 0.000147054365
Iter: 1061 loss: 0.000147034574
Iter: 1062 loss: 0.000147025145
Iter: 1063 loss: 0.000147057071
Iter: 1064 loss: 0.000147022656
Iter: 1065 loss: 0.000147013416
Iter: 1066 loss: 0.000147012935
Iter: 1067 loss: 0.000147006183
Iter: 1068 loss: 0.000146993872
Iter: 1069 loss: 0.00014700435
Iter: 1070 loss: 0.000146986669
Iter: 1071 loss: 0.000146972205
Iter: 1072 loss: 0.000147012528
Iter: 1073 loss: 0.000146967854
Iter: 1074 loss: 0.000146953302
Iter: 1075 loss: 0.00014699153
Iter: 1076 loss: 0.000146948383
Iter: 1077 loss: 0.000146938037
Iter: 1078 loss: 0.000147101819
Iter: 1079 loss: 0.000146938139
Iter: 1080 loss: 0.000146928767
Iter: 1081 loss: 0.000146934646
Iter: 1082 loss: 0.000146922481
Iter: 1083 loss: 0.000146913197
Iter: 1084 loss: 0.000146932973
Iter: 1085 loss: 0.000146909457
Iter: 1086 loss: 0.000146900027
Iter: 1087 loss: 0.000146965758
Iter: 1088 loss: 0.000146899169
Iter: 1089 loss: 0.000146891311
Iter: 1090 loss: 0.000146912949
Iter: 1091 loss: 0.000146888851
Iter: 1092 loss: 0.000146882056
Iter: 1093 loss: 0.000146893799
Iter: 1094 loss: 0.000146878796
Iter: 1095 loss: 0.000146870807
Iter: 1096 loss: 0.000146897859
Iter: 1097 loss: 0.000146868493
Iter: 1098 loss: 0.000146860984
Iter: 1099 loss: 0.000146863065
Iter: 1100 loss: 0.000146855222
Iter: 1101 loss: 0.000146845312
Iter: 1102 loss: 0.000146850085
Iter: 1103 loss: 0.000146838414
Iter: 1104 loss: 0.000146826191
Iter: 1105 loss: 0.000146852748
Iter: 1106 loss: 0.000146821345
Iter: 1107 loss: 0.000146807972
Iter: 1108 loss: 0.000146855687
Iter: 1109 loss: 0.000146804712
Iter: 1110 loss: 0.00014679489
Iter: 1111 loss: 0.00014690758
Iter: 1112 loss: 0.000146794599
Iter: 1113 loss: 0.000146785402
Iter: 1114 loss: 0.000146802457
Iter: 1115 loss: 0.000146781589
Iter: 1116 loss: 0.000146773717
Iter: 1117 loss: 0.000146781036
Iter: 1118 loss: 0.000146769104
Iter: 1119 loss: 0.000146760882
Iter: 1120 loss: 0.000146836814
Iter: 1121 loss: 0.000146760678
Iter: 1122 loss: 0.00014675378
Iter: 1123 loss: 0.000146767212
Iter: 1124 loss: 0.000146751234
Iter: 1125 loss: 0.000146744685
Iter: 1126 loss: 0.000146759674
Iter: 1127 loss: 0.000146742503
Iter: 1128 loss: 0.000146735649
Iter: 1129 loss: 0.000146756036
Iter: 1130 loss: 0.000146733597
Iter: 1131 loss: 0.000146726597
Iter: 1132 loss: 0.000146730628
Iter: 1133 loss: 0.000146721926
Iter: 1134 loss: 0.000146713777
Iter: 1135 loss: 0.000146713894
Iter: 1136 loss: 0.000146706821
Iter: 1137 loss: 0.000146695282
Iter: 1138 loss: 0.000146733044
Iter: 1139 loss: 0.000146692313
Iter: 1140 loss: 0.000146680846
Iter: 1141 loss: 0.000146706923
Iter: 1142 loss: 0.000146676612
Iter: 1143 loss: 0.000146667793
Iter: 1144 loss: 0.000146770049
Iter: 1145 loss: 0.000146667677
Iter: 1146 loss: 0.000146659062
Iter: 1147 loss: 0.000146676757
Iter: 1148 loss: 0.000146655395
Iter: 1149 loss: 0.000146648497
Iter: 1150 loss: 0.000146655701
Iter: 1151 loss: 0.00014664451
Iter: 1152 loss: 0.000146636929
Iter: 1153 loss: 0.000146696621
Iter: 1154 loss: 0.000146636492
Iter: 1155 loss: 0.00014663038
Iter: 1156 loss: 0.000146646591
Iter: 1157 loss: 0.000146628401
Iter: 1158 loss: 0.000146622609
Iter: 1159 loss: 0.00014663313
Iter: 1160 loss: 0.000146620121
Iter: 1161 loss: 0.000146613835
Iter: 1162 loss: 0.000146635008
Iter: 1163 loss: 0.000146611957
Iter: 1164 loss: 0.000146605831
Iter: 1165 loss: 0.000146610153
Iter: 1166 loss: 0.000146601946
Iter: 1167 loss: 0.000146594452
Iter: 1168 loss: 0.000146594524
Iter: 1169 loss: 0.00014658834
Iter: 1170 loss: 0.000146578415
Iter: 1171 loss: 0.000146604565
Iter: 1172 loss: 0.000146574923
Iter: 1173 loss: 0.000146564576
Iter: 1174 loss: 0.000146593768
Iter: 1175 loss: 0.000146561419
Iter: 1176 loss: 0.000146552891
Iter: 1177 loss: 0.000146633174
Iter: 1178 loss: 0.000146552542
Iter: 1179 loss: 0.000146544829
Iter: 1180 loss: 0.000146573962
Iter: 1181 loss: 0.000146543229
Iter: 1182 loss: 0.000146537379
Iter: 1183 loss: 0.000146539358
Iter: 1184 loss: 0.000146533188
Iter: 1185 loss: 0.000146526698
Iter: 1186 loss: 0.000146578095
Iter: 1187 loss: 0.000146526552
Iter: 1188 loss: 0.000146520659
Iter: 1189 loss: 0.000146534308
Iter: 1190 loss: 0.000146518738
Iter: 1191 loss: 0.000146513572
Iter: 1192 loss: 0.000146526989
Iter: 1193 loss: 0.000146511826
Iter: 1194 loss: 0.000146506631
Iter: 1195 loss: 0.000146519538
Iter: 1196 loss: 0.000146504841
Iter: 1197 loss: 0.000146498947
Iter: 1198 loss: 0.000146504768
Iter: 1199 loss: 0.000146495586
Iter: 1200 loss: 0.000146488921
Iter: 1201 loss: 0.000146488484
Iter: 1202 loss: 0.000146483799
Iter: 1203 loss: 0.000146475
Iter: 1204 loss: 0.000146507751
Iter: 1205 loss: 0.000146473103
Iter: 1206 loss: 0.000146464823
Iter: 1207 loss: 0.000146477163
Iter: 1208 loss: 0.00014646085
Iter: 1209 loss: 0.000146453327
Iter: 1210 loss: 0.000146530539
Iter: 1211 loss: 0.000146453211
Iter: 1212 loss: 0.00014644675
Iter: 1213 loss: 0.000146478895
Iter: 1214 loss: 0.000146445454
Iter: 1215 loss: 0.000146441133
Iter: 1216 loss: 0.00014644023
Iter: 1217 loss: 0.000146437174
Iter: 1218 loss: 0.000146431266
Iter: 1219 loss: 0.000146473103
Iter: 1220 loss: 0.000146430888
Iter: 1221 loss: 0.000146425737
Iter: 1222 loss: 0.000146442908
Iter: 1223 loss: 0.000146424587
Iter: 1224 loss: 0.000146420527
Iter: 1225 loss: 0.00014642888
Iter: 1226 loss: 0.000146418897
Iter: 1227 loss: 0.000146414066
Iter: 1228 loss: 0.000146426741
Iter: 1229 loss: 0.000146412654
Iter: 1230 loss: 0.000146407867
Iter: 1231 loss: 0.000146412451
Iter: 1232 loss: 0.000146405102
Iter: 1233 loss: 0.000146399645
Iter: 1234 loss: 0.000146402395
Iter: 1235 loss: 0.000146396094
Iter: 1236 loss: 0.000146389226
Iter: 1237 loss: 0.000146403589
Iter: 1238 loss: 0.000146386737
Iter: 1239 loss: 0.00014637952
Iter: 1240 loss: 0.000146393111
Iter: 1241 loss: 0.000146376711
Iter: 1242 loss: 0.00014637025
Iter: 1243 loss: 0.000146434089
Iter: 1244 loss: 0.000146370192
Iter: 1245 loss: 0.000146364735
Iter: 1246 loss: 0.000146395279
Iter: 1247 loss: 0.000146364066
Iter: 1248 loss: 0.000146359991
Iter: 1249 loss: 0.000146359293
Iter: 1250 loss: 0.000146356775
Iter: 1251 loss: 0.000146351726
Iter: 1252 loss: 0.000146383114
Iter: 1253 loss: 0.000146351143
Iter: 1254 loss: 0.000146346982
Iter: 1255 loss: 0.000146362654
Iter: 1256 loss: 0.000146345978
Iter: 1257 loss: 0.000146342325
Iter: 1258 loss: 0.000146350081
Iter: 1259 loss: 0.000146340768
Iter: 1260 loss: 0.000146337145
Iter: 1261 loss: 0.000146346283
Iter: 1262 loss: 0.000146335602
Iter: 1263 loss: 0.000146331615
Iter: 1264 loss: 0.000146339298
Iter: 1265 loss: 0.000146329723
Iter: 1266 loss: 0.000146325532
Iter: 1267 loss: 0.000146324543
Iter: 1268 loss: 0.000146322083
Iter: 1269 loss: 0.000146316248
Iter: 1270 loss: 0.000146332226
Iter: 1271 loss: 0.000146314269
Iter: 1272 loss: 0.000146308041
Iter: 1273 loss: 0.000146319217
Iter: 1274 loss: 0.000146305669
Iter: 1275 loss: 0.000146299892
Iter: 1276 loss: 0.000146340244
Iter: 1277 loss: 0.000146299164
Iter: 1278 loss: 0.000146294304
Iter: 1279 loss: 0.000146332095
Iter: 1280 loss: 0.000146293663
Iter: 1281 loss: 0.000146290258
Iter: 1282 loss: 0.000146289254
Iter: 1283 loss: 0.000146287348
Iter: 1284 loss: 0.000146282982
Iter: 1285 loss: 0.000146311388
Iter: 1286 loss: 0.000146282604
Iter: 1287 loss: 0.000146279
Iter: 1288 loss: 0.000146292354
Iter: 1289 loss: 0.000146277787
Iter: 1290 loss: 0.00014627463
Iter: 1291 loss: 0.000146279766
Iter: 1292 loss: 0.000146273145
Iter: 1293 loss: 0.000146269595
Iter: 1294 loss: 0.000146281469
Iter: 1295 loss: 0.00014626859
Iter: 1296 loss: 0.000146265331
Iter: 1297 loss: 0.000146269886
Iter: 1298 loss: 0.000146263483
Iter: 1299 loss: 0.000146259787
Iter: 1300 loss: 0.000146259947
Iter: 1301 loss: 0.000146256731
Iter: 1302 loss: 0.000146251317
Iter: 1303 loss: 0.000146261358
Iter: 1304 loss: 0.000146248771
Iter: 1305 loss: 0.00014624311
Iter: 1306 loss: 0.00014625382
Iter: 1307 loss: 0.000146240709
Iter: 1308 loss: 0.000146235107
Iter: 1309 loss: 0.000146279344
Iter: 1310 loss: 0.000146234554
Iter: 1311 loss: 0.000146229882
Iter: 1312 loss: 0.000146265782
Iter: 1313 loss: 0.000146229781
Iter: 1314 loss: 0.00014622623
Iter: 1315 loss: 0.000146226841
Iter: 1316 loss: 0.000146223771
Iter: 1317 loss: 0.000146219943
Iter: 1318 loss: 0.000146237013
Iter: 1319 loss: 0.00014621939
Iter: 1320 loss: 0.000146215534
Iter: 1321 loss: 0.000146231381
Iter: 1322 loss: 0.000146214894
Iter: 1323 loss: 0.000146211911
Iter: 1324 loss: 0.000146216626
Iter: 1325 loss: 0.000146210688
Iter: 1326 loss: 0.000146207196
Iter: 1327 loss: 0.000146217644
Iter: 1328 loss: 0.000146206236
Iter: 1329 loss: 0.000146202889
Iter: 1330 loss: 0.000146209175
Iter: 1331 loss: 0.000146201346
Iter: 1332 loss: 0.000146198145
Iter: 1333 loss: 0.000146196515
Iter: 1334 loss: 0.00014619471
Iter: 1335 loss: 0.000146189355
Iter: 1336 loss: 0.000146201346
Iter: 1337 loss: 0.000146187493
Iter: 1338 loss: 0.000146181905
Iter: 1339 loss: 0.000146193983
Iter: 1340 loss: 0.000146179736
Iter: 1341 loss: 0.000146174687
Iter: 1342 loss: 0.000146205421
Iter: 1343 loss: 0.000146174134
Iter: 1344 loss: 0.000146170089
Iter: 1345 loss: 0.000146214326
Iter: 1346 loss: 0.000146169798
Iter: 1347 loss: 0.000146166887
Iter: 1348 loss: 0.000146166072
Iter: 1349 loss: 0.000146164224
Iter: 1350 loss: 0.000146160834
Iter: 1351 loss: 0.000146178674
Iter: 1352 loss: 0.000146160251
Iter: 1353 loss: 0.000146156948
Iter: 1354 loss: 0.000146172228
Iter: 1355 loss: 0.000146156206
Iter: 1356 loss: 0.000146153412
Iter: 1357 loss: 0.000146157938
Iter: 1358 loss: 0.000146152233
Iter: 1359 loss: 0.000146149265
Iter: 1360 loss: 0.0001461582
Iter: 1361 loss: 0.00014614829
Iter: 1362 loss: 0.000146145525
Iter: 1363 loss: 0.000146149876
Iter: 1364 loss: 0.000146144113
Iter: 1365 loss: 0.000146140781
Iter: 1366 loss: 0.000146141509
Iter: 1367 loss: 0.000146138307
Iter: 1368 loss: 0.000146133956
Iter: 1369 loss: 0.000146142935
Iter: 1370 loss: 0.00014613205
Iter: 1371 loss: 0.000146127539
Iter: 1372 loss: 0.000146133432
Iter: 1373 loss: 0.00014612521
Iter: 1374 loss: 0.000146120568
Iter: 1375 loss: 0.00014615494
Iter: 1376 loss: 0.000146120175
Iter: 1377 loss: 0.000146116232
Iter: 1378 loss: 0.000146151855
Iter: 1379 loss: 0.000146116305
Iter: 1380 loss: 0.000146113758
Iter: 1381 loss: 0.000146113685
Iter: 1382 loss: 0.000146111634
Iter: 1383 loss: 0.000146108781
Iter: 1384 loss: 0.000146120132
Iter: 1385 loss: 0.00014610801
Iter: 1386 loss: 0.000146105231
Iter: 1387 loss: 0.00014612329
Iter: 1388 loss: 0.000146104663
Iter: 1389 loss: 0.000146102626
Iter: 1390 loss: 0.000146105391
Iter: 1391 loss: 0.000146101593
Iter: 1392 loss: 0.000146099163
Iter: 1393 loss: 0.000146106075
Iter: 1394 loss: 0.000146098435
Iter: 1395 loss: 0.000146095757
Iter: 1396 loss: 0.000146099919
Iter: 1397 loss: 0.000146094593
Iter: 1398 loss: 0.000146091857
Iter: 1399 loss: 0.000146092803
Iter: 1400 loss: 0.000146090024
Iter: 1401 loss: 0.000146086371
Iter: 1402 loss: 0.000146091275
Iter: 1403 loss: 0.000146084698
Iter: 1404 loss: 0.000146080725
Iter: 1405 loss: 0.000146087536
Iter: 1406 loss: 0.000146078921
Iter: 1407 loss: 0.000146074875
Iter: 1408 loss: 0.000146102626
Iter: 1409 loss: 0.000146074584
Iter: 1410 loss: 0.000146071732
Iter: 1411 loss: 0.000146104605
Iter: 1412 loss: 0.000146071849
Iter: 1413 loss: 0.000146069578
Iter: 1414 loss: 0.000146069346
Iter: 1415 loss: 0.000146067803
Iter: 1416 loss: 0.000146065446
Iter: 1417 loss: 0.000146074948
Iter: 1418 loss: 0.000146064951
Iter: 1419 loss: 0.000146062681
Iter: 1420 loss: 0.000146077073
Iter: 1421 loss: 0.000146062332
Iter: 1422 loss: 0.000146060789
Iter: 1423 loss: 0.000146062841
Iter: 1424 loss: 0.000146059814
Iter: 1425 loss: 0.000146057777
Iter: 1426 loss: 0.000146062841
Iter: 1427 loss: 0.000146057137
Iter: 1428 loss: 0.000146055056
Iter: 1429 loss: 0.000146059174
Iter: 1430 loss: 0.000146054139
Iter: 1431 loss: 0.000146052116
Iter: 1432 loss: 0.000146052364
Iter: 1433 loss: 0.000146050457
Iter: 1434 loss: 0.000146047561
Iter: 1435 loss: 0.000146052538
Iter: 1436 loss: 0.000146046281
Iter: 1437 loss: 0.000146043254
Iter: 1438 loss: 0.00014604746
Iter: 1439 loss: 0.000146041391
Iter: 1440 loss: 0.000146038103
Iter: 1441 loss: 0.000146058883
Iter: 1442 loss: 0.000146037957
Iter: 1443 loss: 0.000146035629
Iter: 1444 loss: 0.000146066683
Iter: 1445 loss: 0.000146035381
Iter: 1446 loss: 0.000146033839
Iter: 1447 loss: 0.00014603397
Iter: 1448 loss: 0.000146032471
Iter: 1449 loss: 0.00014603071
Iter: 1450 loss: 0.00014603672
Iter: 1451 loss: 0.000146030216
Iter: 1452 loss: 0.000146028353
Iter: 1453 loss: 0.000146040067
Iter: 1454 loss: 0.000146028062
Iter: 1455 loss: 0.000146026781
Iter: 1456 loss: 0.000146028498
Iter: 1457 loss: 0.000146025923
Iter: 1458 loss: 0.000146024191
Iter: 1459 loss: 0.000146029488
Iter: 1460 loss: 0.000146023973
Iter: 1461 loss: 0.000146022256
Iter: 1462 loss: 0.00014602422
Iter: 1463 loss: 0.000146021295
Iter: 1464 loss: 0.000146019578
Iter: 1465 loss: 0.000146020961
Iter: 1466 loss: 0.000146018225
Iter: 1467 loss: 0.000146015838
Iter: 1468 loss: 0.000146018516
Iter: 1469 loss: 0.000146014587
Iter: 1470 loss: 0.000146011735
Iter: 1471 loss: 0.000146016653
Iter: 1472 loss: 0.0001460106
Iter: 1473 loss: 0.000146007806
Iter: 1474 loss: 0.000146025181
Iter: 1475 loss: 0.000146007602
Iter: 1476 loss: 0.000146005637
Iter: 1477 loss: 0.000146028804
Iter: 1478 loss: 0.000146005827
Iter: 1479 loss: 0.000146004197
Iter: 1480 loss: 0.000146004779
Iter: 1481 loss: 0.000146002887
Iter: 1482 loss: 0.000146001519
Iter: 1483 loss: 0.000146005623
Iter: 1484 loss: 0.000146000937
Iter: 1485 loss: 0.000145999249
Iter: 1486 loss: 0.000146012899
Iter: 1487 loss: 0.000145999104
Iter: 1488 loss: 0.000145997896
Iter: 1489 loss: 0.000145999278
Iter: 1490 loss: 0.000145997285
Iter: 1491 loss: 0.000145995771
Iter: 1492 loss: 0.000145999249
Iter: 1493 loss: 0.000145995349
Iter: 1494 loss: 0.000145993865
Iter: 1495 loss: 0.000145996397
Iter: 1496 loss: 0.000145993195
Iter: 1497 loss: 0.000145991362
Iter: 1498 loss: 0.00014599241
Iter: 1499 loss: 0.000145990329
Iter: 1500 loss: 0.000145988335
Iter: 1501 loss: 0.000145991551
Iter: 1502 loss: 0.000145987346
Iter: 1503 loss: 0.000145984915
Iter: 1504 loss: 0.000145988568
Iter: 1505 loss: 0.000145983795
Iter: 1506 loss: 0.000145981321
Iter: 1507 loss: 0.00014599369
Iter: 1508 loss: 0.000145980826
Iter: 1509 loss: 0.000145979167
Iter: 1510 loss: 0.000146004226
Iter: 1511 loss: 0.000145979197
Iter: 1512 loss: 0.00014597777
Iter: 1513 loss: 0.000145977916
Iter: 1514 loss: 0.000145976679
Iter: 1515 loss: 0.000145975268
Iter: 1516 loss: 0.000145979808
Iter: 1517 loss: 0.000145974715
Iter: 1518 loss: 0.000145973157
Iter: 1519 loss: 0.000145984217
Iter: 1520 loss: 0.000145973216
Iter: 1521 loss: 0.000145972
Iter: 1522 loss: 0.000145973609
Iter: 1523 loss: 0.000145971368
Iter: 1524 loss: 0.000145970116
Iter: 1525 loss: 0.000145973085
Iter: 1526 loss: 0.000145969476
Iter: 1527 loss: 0.000145968137
Iter: 1528 loss: 0.000145970349
Iter: 1529 loss: 0.000145967424
Iter: 1530 loss: 0.000145965751
Iter: 1531 loss: 0.000145967613
Iter: 1532 loss: 0.000145964965
Iter: 1533 loss: 0.000145962986
Iter: 1534 loss: 0.000145964863
Iter: 1535 loss: 0.000145962098
Iter: 1536 loss: 0.000145959755
Iter: 1537 loss: 0.00014596252
Iter: 1538 loss: 0.000145958678
Iter: 1539 loss: 0.000145956074
Iter: 1540 loss: 0.000145969956
Iter: 1541 loss: 0.000145955812
Iter: 1542 loss: 0.000145954269
Iter: 1543 loss: 0.000145975573
Iter: 1544 loss: 0.000145954196
Iter: 1545 loss: 0.000145952625
Iter: 1546 loss: 0.000145953425
Iter: 1547 loss: 0.000145951752
Iter: 1548 loss: 0.000145950093
Iter: 1549 loss: 0.000145953556
Iter: 1550 loss: 0.000145949729
Iter: 1551 loss: 0.00014594823
Iter: 1552 loss: 0.000145961763
Iter: 1553 loss: 0.000145948317
Iter: 1554 loss: 0.000145947139
Iter: 1555 loss: 0.000145948186
Iter: 1556 loss: 0.000145946426
Iter: 1557 loss: 0.000145945203
Iter: 1558 loss: 0.000145948434
Iter: 1559 loss: 0.000145944767
Iter: 1560 loss: 0.000145943399
Iter: 1561 loss: 0.000145945523
Iter: 1562 loss: 0.000145942729
Iter: 1563 loss: 0.000145941303
Iter: 1564 loss: 0.000145942933
Iter: 1565 loss: 0.000145940518
Iter: 1566 loss: 0.000145938844
Iter: 1567 loss: 0.000145940037
Iter: 1568 loss: 0.000145937782
Iter: 1569 loss: 0.000145935526
Iter: 1570 loss: 0.00014593883
Iter: 1571 loss: 0.000145934406
Iter: 1572 loss: 0.000145932194
Iter: 1573 loss: 0.000145943253
Iter: 1574 loss: 0.000145931772
Iter: 1575 loss: 0.000145929895
Iter: 1576 loss: 0.000145951693
Iter: 1577 loss: 0.000145929807
Iter: 1578 loss: 0.000145928265
Iter: 1579 loss: 0.0001459294
Iter: 1580 loss: 0.000145927334
Iter: 1581 loss: 0.000145926111
Iter: 1582 loss: 0.000145928527
Iter: 1583 loss: 0.000145925078
Iter: 1584 loss: 0.000145923768
Iter: 1585 loss: 0.000145937476
Iter: 1586 loss: 0.000145923696
Iter: 1587 loss: 0.00014592259
Iter: 1588 loss: 0.000145924103
Iter: 1589 loss: 0.000145922124
Iter: 1590 loss: 0.000145920931
Iter: 1591 loss: 0.000145924219
Iter: 1592 loss: 0.000145920523
Iter: 1593 loss: 0.000145919359
Iter: 1594 loss: 0.000145921236
Iter: 1595 loss: 0.000145918588
Iter: 1596 loss: 0.000145917162
Iter: 1597 loss: 0.000145918268
Iter: 1598 loss: 0.00014591642
Iter: 1599 loss: 0.000145914702
Iter: 1600 loss: 0.000145916361
Iter: 1601 loss: 0.000145913305
Iter: 1602 loss: 0.000145911385
Iter: 1603 loss: 0.000145914484
Iter: 1604 loss: 0.000145910264
Iter: 1605 loss: 0.000145907776
Iter: 1606 loss: 0.00014591706
Iter: 1607 loss: 0.000145907296
Iter: 1608 loss: 0.000145905287
Iter: 1609 loss: 0.000145929167
Iter: 1610 loss: 0.000145905404
Iter: 1611 loss: 0.000145903818
Iter: 1612 loss: 0.000145905855
Iter: 1613 loss: 0.000145902988
Iter: 1614 loss: 0.000145901664
Iter: 1615 loss: 0.000145903818
Iter: 1616 loss: 0.000145900849
Iter: 1617 loss: 0.000145899568
Iter: 1618 loss: 0.000145912942
Iter: 1619 loss: 0.000145899437
Iter: 1620 loss: 0.000145898346
Iter: 1621 loss: 0.000145899729
Iter: 1622 loss: 0.000145898026
Iter: 1623 loss: 0.000145896716
Iter: 1624 loss: 0.000145899859
Iter: 1625 loss: 0.000145896411
Iter: 1626 loss: 0.000145894941
Iter: 1627 loss: 0.000145896745
Iter: 1628 loss: 0.000145894388
Iter: 1629 loss: 0.000145893064
Iter: 1630 loss: 0.000145894446
Iter: 1631 loss: 0.000145892118
Iter: 1632 loss: 0.000145890226
Iter: 1633 loss: 0.000145891943
Iter: 1634 loss: 0.000145889266
Iter: 1635 loss: 0.000145887287
Iter: 1636 loss: 0.000145890866
Iter: 1637 loss: 0.000145886297
Iter: 1638 loss: 0.000145884114
Iter: 1639 loss: 0.000145893384
Iter: 1640 loss: 0.000145883459
Iter: 1641 loss: 0.000145881961
Iter: 1642 loss: 0.000145900034
Iter: 1643 loss: 0.000145881626
Iter: 1644 loss: 0.00014588004
Iter: 1645 loss: 0.000145883416
Iter: 1646 loss: 0.000145879399
Iter: 1647 loss: 0.000145878264
Iter: 1648 loss: 0.000145879487
Iter: 1649 loss: 0.000145877391
Iter: 1650 loss: 0.00014587614
Iter: 1651 loss: 0.000145890401
Iter: 1652 loss: 0.000145876023
Iter: 1653 loss: 0.000145875281
Iter: 1654 loss: 0.000145876111
Iter: 1655 loss: 0.000145874699
Iter: 1656 loss: 0.000145873506
Iter: 1657 loss: 0.000145876256
Iter: 1658 loss: 0.000145872968
Iter: 1659 loss: 0.00014587176
Iter: 1660 loss: 0.000145873608
Iter: 1661 loss: 0.00014587128
Iter: 1662 loss: 0.000145870028
Iter: 1663 loss: 0.000145871585
Iter: 1664 loss: 0.000145869257
Iter: 1665 loss: 0.0001458677
Iter: 1666 loss: 0.000145869592
Iter: 1667 loss: 0.000145866623
Iter: 1668 loss: 0.000145864891
Iter: 1669 loss: 0.000145867612
Iter: 1670 loss: 0.000145864047
Iter: 1671 loss: 0.000145862083
Iter: 1672 loss: 0.000145869242
Iter: 1673 loss: 0.000145861413
Iter: 1674 loss: 0.00014586
Iter: 1675 loss: 0.000145878
Iter: 1676 loss: 0.000145859885
Iter: 1677 loss: 0.000145858561
Iter: 1678 loss: 0.000145860977
Iter: 1679 loss: 0.000145857863
Iter: 1680 loss: 0.000145856713
Iter: 1681 loss: 0.00014585795
Iter: 1682 loss: 0.000145856
Iter: 1683 loss: 0.000145854894
Iter: 1684 loss: 0.000145867947
Iter: 1685 loss: 0.000145854807
Iter: 1686 loss: 0.00014585405
Iter: 1687 loss: 0.000145855345
Iter: 1688 loss: 0.000145853381
Iter: 1689 loss: 0.00014585258
Iter: 1690 loss: 0.000145854487
Iter: 1691 loss: 0.000145852158
Iter: 1692 loss: 0.000145851111
Iter: 1693 loss: 0.000145852711
Iter: 1694 loss: 0.00014585047
Iter: 1695 loss: 0.000145849379
Iter: 1696 loss: 0.000145851474
Iter: 1697 loss: 0.000145848899
Iter: 1698 loss: 0.000145847531
Iter: 1699 loss: 0.000145848899
Iter: 1700 loss: 0.000145846745
Iter: 1701 loss: 0.00014584529
Iter: 1702 loss: 0.000145847152
Iter: 1703 loss: 0.000145844388
Iter: 1704 loss: 0.000145842641
Iter: 1705 loss: 0.000145850659
Iter: 1706 loss: 0.000145842379
Iter: 1707 loss: 0.000145841113
Iter: 1708 loss: 0.000145853
Iter: 1709 loss: 0.000145841113
Iter: 1710 loss: 0.000145839702
Iter: 1711 loss: 0.000145843034
Iter: 1712 loss: 0.000145839353
Iter: 1713 loss: 0.000145838247
Iter: 1714 loss: 0.000145839367
Iter: 1715 loss: 0.000145837796
Iter: 1716 loss: 0.000145836937
Iter: 1717 loss: 0.0001458482
Iter: 1718 loss: 0.000145836937
Iter: 1719 loss: 0.000145836137
Iter: 1720 loss: 0.000145837272
Iter: 1721 loss: 0.000145835744
Iter: 1722 loss: 0.000145835045
Iter: 1723 loss: 0.000145836544
Iter: 1724 loss: 0.000145834696
Iter: 1725 loss: 0.000145833881
Iter: 1726 loss: 0.00014583522
Iter: 1727 loss: 0.000145833619
Iter: 1728 loss: 0.00014583247
Iter: 1729 loss: 0.000145833954
Iter: 1730 loss: 0.000145832062
Iter: 1731 loss: 0.000145831
Iter: 1732 loss: 0.000145831757
Iter: 1733 loss: 0.000145830476
Iter: 1734 loss: 0.000145829094
Iter: 1735 loss: 0.000145831378
Iter: 1736 loss: 0.00014582873
Iter: 1737 loss: 0.000145827333
Iter: 1738 loss: 0.000145832048
Iter: 1739 loss: 0.0001458271
Iter: 1740 loss: 0.000145825979
Iter: 1741 loss: 0.000145835278
Iter: 1742 loss: 0.000145825936
Iter: 1743 loss: 0.000145825019
Iter: 1744 loss: 0.000145827944
Iter: 1745 loss: 0.000145824743
Iter: 1746 loss: 0.000145823898
Iter: 1747 loss: 0.000145824422
Iter: 1748 loss: 0.000145823316
Iter: 1749 loss: 0.000145822603
Iter: 1750 loss: 0.000145830636
Iter: 1751 loss: 0.000145822676
Iter: 1752 loss: 0.000145822152
Iter: 1753 loss: 0.00014582336
Iter: 1754 loss: 0.000145821905
Iter: 1755 loss: 0.00014582125
Iter: 1756 loss: 0.000145822341
Iter: 1757 loss: 0.000145821163
Iter: 1758 loss: 0.000145820421
Iter: 1759 loss: 0.000145821396
Iter: 1760 loss: 0.000145819984
Iter: 1761 loss: 0.000145819446
Iter: 1762 loss: 0.000145819911
Iter: 1763 loss: 0.000145818849
Iter: 1764 loss: 0.000145818078
Iter: 1765 loss: 0.000145819155
Iter: 1766 loss: 0.000145817656
Iter: 1767 loss: 0.000145816652
Iter: 1768 loss: 0.000145817859
Iter: 1769 loss: 0.000145816171
Iter: 1770 loss: 0.000145815255
Iter: 1771 loss: 0.00014581866
Iter: 1772 loss: 0.000145814789
Iter: 1773 loss: 0.000145813916
Iter: 1774 loss: 0.000145822298
Iter: 1775 loss: 0.000145813901
Iter: 1776 loss: 0.000145812985
Iter: 1777 loss: 0.000145815837
Iter: 1778 loss: 0.00014581265
Iter: 1779 loss: 0.000145812082
Iter: 1780 loss: 0.000145812475
Iter: 1781 loss: 0.000145811675
Iter: 1782 loss: 0.000145811035
Iter: 1783 loss: 0.000145818252
Iter: 1784 loss: 0.000145810976
Iter: 1785 loss: 0.000145810453
Iter: 1786 loss: 0.000145811617
Iter: 1787 loss: 0.00014581038
Iter: 1788 loss: 0.000145809783
Iter: 1789 loss: 0.000145810583
Iter: 1790 loss: 0.000145809623
Iter: 1791 loss: 0.000145808866
Iter: 1792 loss: 0.000145809885
Iter: 1793 loss: 0.000145808444
Iter: 1794 loss: 0.000145807746
Iter: 1795 loss: 0.000145808808
Iter: 1796 loss: 0.000145807469
Iter: 1797 loss: 0.000145806756
Iter: 1798 loss: 0.000145807586
Iter: 1799 loss: 0.000145806174
Iter: 1800 loss: 0.000145805374
Iter: 1801 loss: 0.000145806291
Iter: 1802 loss: 0.000145804734
Iter: 1803 loss: 0.000145803861
Iter: 1804 loss: 0.000145807426
Iter: 1805 loss: 0.000145803526
Iter: 1806 loss: 0.000145802464
Iter: 1807 loss: 0.000145810627
Iter: 1808 loss: 0.00014580242
Iter: 1809 loss: 0.000145801547
Iter: 1810 loss: 0.000145805505
Iter: 1811 loss: 0.000145801489
Iter: 1812 loss: 0.000145800615
Iter: 1813 loss: 0.000145800892
Iter: 1814 loss: 0.000145800324
Iter: 1815 loss: 0.000145799553
Iter: 1816 loss: 0.000145807047
Iter: 1817 loss: 0.000145799597
Iter: 1818 loss: 0.000145799015
Iter: 1819 loss: 0.000145800135
Iter: 1820 loss: 0.000145798724
Iter: 1821 loss: 0.000145798302
Iter: 1822 loss: 0.000145798811
Iter: 1823 loss: 0.000145797952
Iter: 1824 loss: 0.000145797298
Iter: 1825 loss: 0.000145798665
Iter: 1826 loss: 0.00014579689
Iter: 1827 loss: 0.000145796192
Iter: 1828 loss: 0.000145797036
Iter: 1829 loss: 0.000145795726
Iter: 1830 loss: 0.000145794984
Iter: 1831 loss: 0.000145796032
Iter: 1832 loss: 0.000145794649
Iter: 1833 loss: 0.000145793718
Iter: 1834 loss: 0.000145794736
Iter: 1835 loss: 0.000145793267
Iter: 1836 loss: 0.000145792146
Iter: 1837 loss: 0.000145795653
Iter: 1838 loss: 0.000145791739
Iter: 1839 loss: 0.000145790953
Iter: 1840 loss: 0.00014579884
Iter: 1841 loss: 0.000145790749
Iter: 1842 loss: 0.000145789643
Iter: 1843 loss: 0.000145793645
Iter: 1844 loss: 0.000145789905
Iter: 1845 loss: 0.00014578909
Iter: 1846 loss: 0.000145789367
Iter: 1847 loss: 0.000145788683
Iter: 1848 loss: 0.000145787868
Iter: 1849 loss: 0.000145794169
Iter: 1850 loss: 0.000145787897
Iter: 1851 loss: 0.00014578746
Iter: 1852 loss: 0.000145788727
Iter: 1853 loss: 0.000145787111
Iter: 1854 loss: 0.000145786718
Iter: 1855 loss: 0.000145787577
Iter: 1856 loss: 0.000145786369
Iter: 1857 loss: 0.000145785685
Iter: 1858 loss: 0.000145787257
Iter: 1859 loss: 0.000145785511
Iter: 1860 loss: 0.000145784652
Iter: 1861 loss: 0.000145785656
Iter: 1862 loss: 0.000145784492
Iter: 1863 loss: 0.000145783677
Iter: 1864 loss: 0.000145784521
Iter: 1865 loss: 0.00014578324
Iter: 1866 loss: 0.00014578228
Iter: 1867 loss: 0.000145783575
Iter: 1868 loss: 0.000145781887
Iter: 1869 loss: 0.000145780941
Iter: 1870 loss: 0.000145783793
Iter: 1871 loss: 0.000145780679
Iter: 1872 loss: 0.000145779879
Iter: 1873 loss: 0.0001457865
Iter: 1874 loss: 0.00014577985
Iter: 1875 loss: 0.000145779064
Iter: 1876 loss: 0.000145783313
Iter: 1877 loss: 0.000145778933
Iter: 1878 loss: 0.000145778526
Iter: 1879 loss: 0.000145778322
Iter: 1880 loss: 0.000145778031
Iter: 1881 loss: 0.000145777391
Iter: 1882 loss: 0.000145783764
Iter: 1883 loss: 0.000145777405
Iter: 1884 loss: 0.000145776983
Iter: 1885 loss: 0.000145778104
Iter: 1886 loss: 0.000145776838
Iter: 1887 loss: 0.000145776474
Iter: 1888 loss: 0.0001457771
Iter: 1889 loss: 0.000145776081
Iter: 1890 loss: 0.000145775528
Iter: 1891 loss: 0.00014577659
Iter: 1892 loss: 0.000145775528
Iter: 1893 loss: 0.0001457748
Iter: 1894 loss: 0.000145775324
Iter: 1895 loss: 0.000145774742
Iter: 1896 loss: 0.000145774029
Iter: 1897 loss: 0.0001457748
Iter: 1898 loss: 0.000145773491
Iter: 1899 loss: 0.00014577304
Iter: 1900 loss: 0.000145774189
Iter: 1901 loss: 0.000145772938
Iter: 1902 loss: 0.000145771948
Iter: 1903 loss: 0.00014577368
Iter: 1904 loss: 0.000145771657
Iter: 1905 loss: 0.000145771221
Iter: 1906 loss: 0.000145776066
Iter: 1907 loss: 0.000145771031
Iter: 1908 loss: 0.000145770522
Iter: 1909 loss: 0.000145774335
Iter: 1910 loss: 0.000145770173
Iter: 1911 loss: 0.00014576994
Iter: 1912 loss: 0.000145769678
Iter: 1913 loss: 0.000145769416
Iter: 1914 loss: 0.000145769023
Iter: 1915 loss: 0.00014577384
Iter: 1916 loss: 0.00014576914
Iter: 1917 loss: 0.000145768747
Iter: 1918 loss: 0.000145769824
Iter: 1919 loss: 0.000145768601
Iter: 1920 loss: 0.000145768339
Iter: 1921 loss: 0.000145769
Iter: 1922 loss: 0.000145768077
Iter: 1923 loss: 0.000145767815
Iter: 1924 loss: 0.000145768456
Iter: 1925 loss: 0.000145767612
Iter: 1926 loss: 0.000145767219
Iter: 1927 loss: 0.000145767772
Iter: 1928 loss: 0.000145767219
Iter: 1929 loss: 0.000145766564
Iter: 1930 loss: 0.000145767335
Iter: 1931 loss: 0.000145766302
Iter: 1932 loss: 0.000145766069
Iter: 1933 loss: 0.000145766477
Iter: 1934 loss: 0.00014576556
Iter: 1935 loss: 0.000145764978
Iter: 1936 loss: 0.000145766404
Iter: 1937 loss: 0.00014576476
Iter: 1938 loss: 0.000145764381
Iter: 1939 loss: 0.000145768645
Iter: 1940 loss: 0.000145764396
Iter: 1941 loss: 0.000145763726
Iter: 1942 loss: 0.000145766971
Iter: 1943 loss: 0.000145763886
Iter: 1944 loss: 0.000145763421
Iter: 1945 loss: 0.000145763333
Iter: 1946 loss: 0.000145763159
Iter: 1947 loss: 0.000145762868
Iter: 1948 loss: 0.000145765909
Iter: 1949 loss: 0.000145762795
Iter: 1950 loss: 0.000145762489
Iter: 1951 loss: 0.000145763493
Iter: 1952 loss: 0.000145762489
Iter: 1953 loss: 0.000145762213
Iter: 1954 loss: 0.000145762431
Iter: 1955 loss: 0.000145762082
Iter: 1956 loss: 0.000145761616
Iter: 1957 loss: 0.000145762693
Iter: 1958 loss: 0.0001457615
Iter: 1959 loss: 0.000145761267
Iter: 1960 loss: 0.000145761689
Iter: 1961 loss: 0.000145761151
Iter: 1962 loss: 0.000145760772
Iter: 1963 loss: 0.000145761194
Iter: 1964 loss: 0.000145760627
Iter: 1965 loss: 0.000145760132
Iter: 1966 loss: 0.000145760423
Iter: 1967 loss: 0.000145759928
Iter: 1968 loss: 0.000145759346
Iter: 1969 loss: 0.000145760685
Iter: 1970 loss: 0.000145759026
Iter: 1971 loss: 0.00014575856
Iter: 1972 loss: 0.000145761936
Iter: 1973 loss: 0.000145758677
Iter: 1974 loss: 0.000145758328
Iter: 1975 loss: 0.000145761485
Iter: 1976 loss: 0.000145758298
Iter: 1977 loss: 0.000145758007
Iter: 1978 loss: 0.000145757833
Iter: 1979 loss: 0.000145757585
Iter: 1980 loss: 0.000145757367
Iter: 1981 loss: 0.000145760598
Iter: 1982 loss: 0.000145757323
Iter: 1983 loss: 0.000145756916
Iter: 1984 loss: 0.000145757571
Iter: 1985 loss: 0.000145756785
Iter: 1986 loss: 0.00014575661
Iter: 1987 loss: 0.000145757047
Iter: 1988 loss: 0.000145756509
Iter: 1989 loss: 0.000145756145
Iter: 1990 loss: 0.000145757018
Iter: 1991 loss: 0.000145756174
Iter: 1992 loss: 0.000145755868
Iter: 1993 loss: 0.000145756232
Iter: 1994 loss: 0.000145755519
Iter: 1995 loss: 0.000145755126
Iter: 1996 loss: 0.000145755606
Iter: 1997 loss: 0.000145755024
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2
+ date
Tue Oct 27 18:53:38 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac6a27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac6a3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac6b9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac6b98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac6ebae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac64aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac5b19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac5b18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac5dd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac5dd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac573510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac560f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac4ee8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac4ad8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac4e6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac4e61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac46f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac4e6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac462730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac499ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac41f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac41fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac3927b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac38ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac3326a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac36a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac321598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac2b2d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac2ca620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac2cac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac2d3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac24f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac260510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac1f5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac1bbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3fac1bb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0355498195
Iter: 2 loss: 850.078247
Iter: 3 loss: 1631.83704
Iter: 4 loss: 0.0355483741
Iter: 5 loss: 0.327741534
Iter: 6 loss: 0.0355309024
Iter: 7 loss: 0.0257864408
Iter: 8 loss: 0.0257848
Iter: 9 loss: 0.0363796912
Iter: 10 loss: 0.0244125761
Iter: 11 loss: 0.0208285861
Iter: 12 loss: 0.0375846401
Iter: 13 loss: 0.0197691601
Iter: 14 loss: 0.017400777
Iter: 15 loss: 0.02993658
Iter: 16 loss: 0.0168723501
Iter: 17 loss: 0.0146665666
Iter: 18 loss: 0.0430553854
Iter: 19 loss: 0.0146309966
Iter: 20 loss: 0.0136160832
Iter: 21 loss: 0.0148295006
Iter: 22 loss: 0.0129815862
Iter: 23 loss: 0.0120047536
Iter: 24 loss: 0.0119936801
Iter: 25 loss: 0.01126609
Iter: 26 loss: 0.0149420761
Iter: 27 loss: 0.0111260498
Iter: 28 loss: 0.0103705069
Iter: 29 loss: 0.0135544334
Iter: 30 loss: 0.0101168063
Iter: 31 loss: 0.00922932662
Iter: 32 loss: 0.0145000173
Iter: 33 loss: 0.00907250308
Iter: 34 loss: 0.00810629129
Iter: 35 loss: 0.00911619607
Iter: 36 loss: 0.00753071439
Iter: 37 loss: 0.00664941268
Iter: 38 loss: 0.0222048946
Iter: 39 loss: 0.00664604641
Iter: 40 loss: 0.00647144439
Iter: 41 loss: 0.00640637334
Iter: 42 loss: 0.00619249046
Iter: 43 loss: 0.00769581227
Iter: 44 loss: 0.00618164567
Iter: 45 loss: 0.00596275972
Iter: 46 loss: 0.00621331856
Iter: 47 loss: 0.00584485102
Iter: 48 loss: 0.00553052686
Iter: 49 loss: 0.0064446805
Iter: 50 loss: 0.00543214381
Iter: 51 loss: 0.00516820559
Iter: 52 loss: 0.0078440709
Iter: 53 loss: 0.00514730625
Iter: 54 loss: 0.00498135947
Iter: 55 loss: 0.00519242603
Iter: 56 loss: 0.00490204617
Iter: 57 loss: 0.00466200337
Iter: 58 loss: 0.00450129341
Iter: 59 loss: 0.00440143701
Iter: 60 loss: 0.00425902661
Iter: 61 loss: 0.00421478413
Iter: 62 loss: 0.00405309722
Iter: 63 loss: 0.00463312073
Iter: 64 loss: 0.0040039788
Iter: 65 loss: 0.00386821898
Iter: 66 loss: 0.00395122636
Iter: 67 loss: 0.00378041249
Iter: 68 loss: 0.00358220609
Iter: 69 loss: 0.00446691317
Iter: 70 loss: 0.00354328752
Iter: 71 loss: 0.00337683503
Iter: 72 loss: 0.00475790398
Iter: 73 loss: 0.00335946446
Iter: 74 loss: 0.00324625103
Iter: 75 loss: 0.00417013885
Iter: 76 loss: 0.00324299373
Iter: 77 loss: 0.00315501075
Iter: 78 loss: 0.00313677266
Iter: 79 loss: 0.00307448395
Iter: 80 loss: 0.00296816276
Iter: 81 loss: 0.00289654825
Iter: 82 loss: 0.00285850908
Iter: 83 loss: 0.00274109864
Iter: 84 loss: 0.00314082461
Iter: 85 loss: 0.00270658755
Iter: 86 loss: 0.00261983695
Iter: 87 loss: 0.00310666859
Iter: 88 loss: 0.00260850391
Iter: 89 loss: 0.00251047267
Iter: 90 loss: 0.00314440532
Iter: 91 loss: 0.00249629817
Iter: 92 loss: 0.00242247037
Iter: 93 loss: 0.0024744696
Iter: 94 loss: 0.00237734476
Iter: 95 loss: 0.00231951824
Iter: 96 loss: 0.00227013254
Iter: 97 loss: 0.0022527054
Iter: 98 loss: 0.00214457978
Iter: 99 loss: 0.0026730895
Iter: 100 loss: 0.00212783646
Iter: 101 loss: 0.00206652982
Iter: 102 loss: 0.00206633471
Iter: 103 loss: 0.00202183425
Iter: 104 loss: 0.00203653192
Iter: 105 loss: 0.00199046894
Iter: 106 loss: 0.00193416397
Iter: 107 loss: 0.00256776903
Iter: 108 loss: 0.00193238782
Iter: 109 loss: 0.00189664727
Iter: 110 loss: 0.00215253793
Iter: 111 loss: 0.00189447531
Iter: 112 loss: 0.00186992297
Iter: 113 loss: 0.001854831
Iter: 114 loss: 0.00184425584
Iter: 115 loss: 0.00181461684
Iter: 116 loss: 0.00179363438
Iter: 117 loss: 0.00178313593
Iter: 118 loss: 0.00174065656
Iter: 119 loss: 0.00174425275
Iter: 120 loss: 0.00170774246
Iter: 121 loss: 0.00166269636
Iter: 122 loss: 0.00167178339
Iter: 123 loss: 0.00162892963
Iter: 124 loss: 0.00156177336
Iter: 125 loss: 0.00231105229
Iter: 126 loss: 0.0015600269
Iter: 127 loss: 0.00153718609
Iter: 128 loss: 0.001537184
Iter: 129 loss: 0.00151722436
Iter: 130 loss: 0.00150287058
Iter: 131 loss: 0.00149602571
Iter: 132 loss: 0.00146297377
Iter: 133 loss: 0.00184567063
Iter: 134 loss: 0.00146256352
Iter: 135 loss: 0.00143359893
Iter: 136 loss: 0.00159185659
Iter: 137 loss: 0.00142857828
Iter: 138 loss: 0.00141250249
Iter: 139 loss: 0.001384167
Iter: 140 loss: 0.00138416607
Iter: 141 loss: 0.00135289715
Iter: 142 loss: 0.00135289412
Iter: 143 loss: 0.00133157114
Iter: 144 loss: 0.00137531478
Iter: 145 loss: 0.0013240478
Iter: 146 loss: 0.00130492705
Iter: 147 loss: 0.00129087793
Iter: 148 loss: 0.00128399511
Iter: 149 loss: 0.00127110363
Iter: 150 loss: 0.00125419197
Iter: 151 loss: 0.00125314039
Iter: 152 loss: 0.00122228242
Iter: 153 loss: 0.00125855883
Iter: 154 loss: 0.00120586529
Iter: 155 loss: 0.00117957953
Iter: 156 loss: 0.00141351623
Iter: 157 loss: 0.00117826555
Iter: 158 loss: 0.00115608401
Iter: 159 loss: 0.00131231011
Iter: 160 loss: 0.00115426921
Iter: 161 loss: 0.00113349315
Iter: 162 loss: 0.00127988518
Iter: 163 loss: 0.00113135774
Iter: 164 loss: 0.00111203839
Iter: 165 loss: 0.00109205709
Iter: 166 loss: 0.00108834344
Iter: 167 loss: 0.00106497901
Iter: 168 loss: 0.00138402556
Iter: 169 loss: 0.00106489379
Iter: 170 loss: 0.00104855082
Iter: 171 loss: 0.00104940264
Iter: 172 loss: 0.00103553361
Iter: 173 loss: 0.00101610739
Iter: 174 loss: 0.00105915428
Iter: 175 loss: 0.00100878463
Iter: 176 loss: 0.000995535753
Iter: 177 loss: 0.000994567759
Iter: 178 loss: 0.000982793863
Iter: 179 loss: 0.00103029388
Iter: 180 loss: 0.000980418175
Iter: 181 loss: 0.000971241854
Iter: 182 loss: 0.000968860753
Iter: 183 loss: 0.000963020721
Iter: 184 loss: 0.000950953516
Iter: 185 loss: 0.000948189292
Iter: 186 loss: 0.000940453843
Iter: 187 loss: 0.000926446053
Iter: 188 loss: 0.000935753458
Iter: 189 loss: 0.000917608675
Iter: 190 loss: 0.000898829312
Iter: 191 loss: 0.000986074563
Iter: 192 loss: 0.000895215082
Iter: 193 loss: 0.000879267929
Iter: 194 loss: 0.000956558855
Iter: 195 loss: 0.000876605802
Iter: 196 loss: 0.000863390276
Iter: 197 loss: 0.000960138161
Iter: 198 loss: 0.000862254412
Iter: 199 loss: 0.000852879253
Iter: 200 loss: 0.000845626346
Iter: 201 loss: 0.000842636044
Iter: 202 loss: 0.000827845652
Iter: 203 loss: 0.000870637887
Iter: 204 loss: 0.000823236
Iter: 205 loss: 0.000808912
Iter: 206 loss: 0.000885245914
Iter: 207 loss: 0.000806520518
Iter: 208 loss: 0.000794233056
Iter: 209 loss: 0.000830650737
Iter: 210 loss: 0.00079054758
Iter: 211 loss: 0.000786569668
Iter: 212 loss: 0.000784708769
Iter: 213 loss: 0.000780887727
Iter: 214 loss: 0.000775073131
Iter: 215 loss: 0.000774979766
Iter: 216 loss: 0.000767026679
Iter: 217 loss: 0.000781859737
Iter: 218 loss: 0.000763572869
Iter: 219 loss: 0.000755896501
Iter: 220 loss: 0.000749414263
Iter: 221 loss: 0.00074728718
Iter: 222 loss: 0.000732107786
Iter: 223 loss: 0.000735427951
Iter: 224 loss: 0.000720918411
Iter: 225 loss: 0.000704939826
Iter: 226 loss: 0.000790454331
Iter: 227 loss: 0.000702394173
Iter: 228 loss: 0.000685744861
Iter: 229 loss: 0.000797221321
Iter: 230 loss: 0.000684103521
Iter: 231 loss: 0.000675284769
Iter: 232 loss: 0.000691008696
Iter: 233 loss: 0.000671377755
Iter: 234 loss: 0.000661798404
Iter: 235 loss: 0.000669051311
Iter: 236 loss: 0.000655953423
Iter: 237 loss: 0.000647607
Iter: 238 loss: 0.00065977
Iter: 239 loss: 0.000643606298
Iter: 240 loss: 0.000634773518
Iter: 241 loss: 0.000670899404
Iter: 242 loss: 0.000632892596
Iter: 243 loss: 0.000634898315
Iter: 244 loss: 0.00062852737
Iter: 245 loss: 0.000625849818
Iter: 246 loss: 0.00062010932
Iter: 247 loss: 0.000710929744
Iter: 248 loss: 0.000619913335
Iter: 249 loss: 0.000610996154
Iter: 250 loss: 0.000677283912
Iter: 251 loss: 0.000610230432
Iter: 252 loss: 0.000601840438
Iter: 253 loss: 0.000629320217
Iter: 254 loss: 0.000599519932
Iter: 255 loss: 0.000595376
Iter: 256 loss: 0.000590975396
Iter: 257 loss: 0.000590210897
Iter: 258 loss: 0.000586025068
Iter: 259 loss: 0.000583694899
Iter: 260 loss: 0.000581882603
Iter: 261 loss: 0.000578432926
Iter: 262 loss: 0.000575787504
Iter: 263 loss: 0.000574649719
Iter: 264 loss: 0.000570836593
Iter: 265 loss: 0.000562495785
Iter: 266 loss: 0.000686731131
Iter: 267 loss: 0.000562136353
Iter: 268 loss: 0.000552460784
Iter: 269 loss: 0.00059017149
Iter: 270 loss: 0.000550216355
Iter: 271 loss: 0.000543629867
Iter: 272 loss: 0.000565547729
Iter: 273 loss: 0.000541879795
Iter: 274 loss: 0.000535627245
Iter: 275 loss: 0.000574831618
Iter: 276 loss: 0.000534906867
Iter: 277 loss: 0.000529122131
Iter: 278 loss: 0.000547148287
Iter: 279 loss: 0.000527376833
Iter: 280 loss: 0.000520801637
Iter: 281 loss: 0.000517917797
Iter: 282 loss: 0.00051457365
Iter: 283 loss: 0.000507752062
Iter: 284 loss: 0.000536073407
Iter: 285 loss: 0.000506217184
Iter: 286 loss: 0.000500652241
Iter: 287 loss: 0.000554783968
Iter: 288 loss: 0.000500474358
Iter: 289 loss: 0.000496818393
Iter: 290 loss: 0.000502077222
Iter: 291 loss: 0.000494995853
Iter: 292 loss: 0.000491658342
Iter: 293 loss: 0.000514820335
Iter: 294 loss: 0.00049136387
Iter: 295 loss: 0.000488874852
Iter: 296 loss: 0.000503720832
Iter: 297 loss: 0.000488542661
Iter: 298 loss: 0.000486016681
Iter: 299 loss: 0.000483257259
Iter: 300 loss: 0.00048285065
Iter: 301 loss: 0.000478533504
Iter: 302 loss: 0.000481646712
Iter: 303 loss: 0.000475853391
Iter: 304 loss: 0.000470889703
Iter: 305 loss: 0.000479700073
Iter: 306 loss: 0.000468715152
Iter: 307 loss: 0.000462898985
Iter: 308 loss: 0.000495426473
Iter: 309 loss: 0.000462082971
Iter: 310 loss: 0.000457331451
Iter: 311 loss: 0.000497587724
Iter: 312 loss: 0.000457035814
Iter: 313 loss: 0.000452976674
Iter: 314 loss: 0.000454293273
Iter: 315 loss: 0.000450095249
Iter: 316 loss: 0.000446036109
Iter: 317 loss: 0.000453611952
Iter: 318 loss: 0.000444271864
Iter: 319 loss: 0.00044055155
Iter: 320 loss: 0.00044055059
Iter: 321 loss: 0.000438089832
Iter: 322 loss: 0.000443516066
Iter: 323 loss: 0.000437124836
Iter: 324 loss: 0.000434723654
Iter: 325 loss: 0.000440563017
Iter: 326 loss: 0.000433874317
Iter: 327 loss: 0.000431605091
Iter: 328 loss: 0.000448317092
Iter: 329 loss: 0.000431405468
Iter: 330 loss: 0.000429120963
Iter: 331 loss: 0.000426250044
Iter: 332 loss: 0.000426026207
Iter: 333 loss: 0.000422443845
Iter: 334 loss: 0.000426829269
Iter: 335 loss: 0.00042055588
Iter: 336 loss: 0.000416477589
Iter: 337 loss: 0.000421788602
Iter: 338 loss: 0.000414384616
Iter: 339 loss: 0.000409648521
Iter: 340 loss: 0.00043151225
Iter: 341 loss: 0.000408755091
Iter: 342 loss: 0.000405453553
Iter: 343 loss: 0.000450477557
Iter: 344 loss: 0.000405436
Iter: 345 loss: 0.000402767502
Iter: 346 loss: 0.000405391736
Iter: 347 loss: 0.00040126688
Iter: 348 loss: 0.000398799893
Iter: 349 loss: 0.000399221317
Iter: 350 loss: 0.000396933843
Iter: 351 loss: 0.000395006966
Iter: 352 loss: 0.000394847069
Iter: 353 loss: 0.000393407943
Iter: 354 loss: 0.000395886862
Iter: 355 loss: 0.000392757
Iter: 356 loss: 0.00039095548
Iter: 357 loss: 0.000390881905
Iter: 358 loss: 0.000389496796
Iter: 359 loss: 0.00038737338
Iter: 360 loss: 0.000408921624
Iter: 361 loss: 0.000387299224
Iter: 362 loss: 0.000385244377
Iter: 363 loss: 0.000384152227
Iter: 364 loss: 0.000383229577
Iter: 365 loss: 0.00038068305
Iter: 366 loss: 0.000380550453
Iter: 367 loss: 0.00037859974
Iter: 368 loss: 0.000374923053
Iter: 369 loss: 0.000380965648
Iter: 370 loss: 0.000373234943
Iter: 371 loss: 0.000369787856
Iter: 372 loss: 0.00038254002
Iter: 373 loss: 0.00036894207
Iter: 374 loss: 0.000366219145
Iter: 375 loss: 0.000391533831
Iter: 376 loss: 0.000366097142
Iter: 377 loss: 0.000363587373
Iter: 378 loss: 0.000368551468
Iter: 379 loss: 0.000362565101
Iter: 380 loss: 0.000360142178
Iter: 381 loss: 0.000359346392
Iter: 382 loss: 0.000357938115
Iter: 383 loss: 0.000356117089
Iter: 384 loss: 0.000355829019
Iter: 385 loss: 0.00035395968
Iter: 386 loss: 0.000359201571
Iter: 387 loss: 0.000353346171
Iter: 388 loss: 0.00035144118
Iter: 389 loss: 0.000350838702
Iter: 390 loss: 0.000349726353
Iter: 391 loss: 0.000347819238
Iter: 392 loss: 0.000378125784
Iter: 393 loss: 0.00034781947
Iter: 394 loss: 0.000346227112
Iter: 395 loss: 0.000346081419
Iter: 396 loss: 0.000344915781
Iter: 397 loss: 0.000343177875
Iter: 398 loss: 0.000342473097
Iter: 399 loss: 0.000341543113
Iter: 400 loss: 0.000339118473
Iter: 401 loss: 0.000341120292
Iter: 402 loss: 0.000337668374
Iter: 403 loss: 0.000335043413
Iter: 404 loss: 0.000337495119
Iter: 405 loss: 0.000333534408
Iter: 406 loss: 0.000330561277
Iter: 407 loss: 0.000353103213
Iter: 408 loss: 0.000330322917
Iter: 409 loss: 0.000327625778
Iter: 410 loss: 0.000334606098
Iter: 411 loss: 0.000326708745
Iter: 412 loss: 0.000323902641
Iter: 413 loss: 0.00032571386
Iter: 414 loss: 0.000322120904
Iter: 415 loss: 0.000318754377
Iter: 416 loss: 0.000332134747
Iter: 417 loss: 0.000318035192
Iter: 418 loss: 0.000316787366
Iter: 419 loss: 0.000316382706
Iter: 420 loss: 0.000315363228
Iter: 421 loss: 0.000313384167
Iter: 422 loss: 0.000353756943
Iter: 423 loss: 0.000313371071
Iter: 424 loss: 0.000312083313
Iter: 425 loss: 0.000311992073
Iter: 426 loss: 0.00031081753
Iter: 427 loss: 0.000311358686
Iter: 428 loss: 0.000310027332
Iter: 429 loss: 0.000308757648
Iter: 430 loss: 0.00030753226
Iter: 431 loss: 0.000307246577
Iter: 432 loss: 0.000305796217
Iter: 433 loss: 0.000304681365
Iter: 434 loss: 0.000304220128
Iter: 435 loss: 0.000302757457
Iter: 436 loss: 0.000302860455
Iter: 437 loss: 0.000301618
Iter: 438 loss: 0.000299205
Iter: 439 loss: 0.000307367882
Iter: 440 loss: 0.000298559025
Iter: 441 loss: 0.000296861224
Iter: 442 loss: 0.000302269735
Iter: 443 loss: 0.000296379847
Iter: 444 loss: 0.000294654688
Iter: 445 loss: 0.000301567838
Iter: 446 loss: 0.000294266676
Iter: 447 loss: 0.000293067715
Iter: 448 loss: 0.00029356603
Iter: 449 loss: 0.00029224329
Iter: 450 loss: 0.000290403899
Iter: 451 loss: 0.000297067803
Iter: 452 loss: 0.000289926771
Iter: 453 loss: 0.000288035779
Iter: 454 loss: 0.000303849229
Iter: 455 loss: 0.000287934206
Iter: 456 loss: 0.000286844035
Iter: 457 loss: 0.000288391544
Iter: 458 loss: 0.000286305207
Iter: 459 loss: 0.000285274116
Iter: 460 loss: 0.000289965712
Iter: 461 loss: 0.000285081391
Iter: 462 loss: 0.000284018752
Iter: 463 loss: 0.00028565494
Iter: 464 loss: 0.00028350763
Iter: 465 loss: 0.000282473309
Iter: 466 loss: 0.000284337671
Iter: 467 loss: 0.000282030611
Iter: 468 loss: 0.000280851149
Iter: 469 loss: 0.000279633736
Iter: 470 loss: 0.000279408298
Iter: 471 loss: 0.000277838495
Iter: 472 loss: 0.000288587122
Iter: 473 loss: 0.000277688669
Iter: 474 loss: 0.000276371255
Iter: 475 loss: 0.000280191569
Iter: 476 loss: 0.000275963772
Iter: 477 loss: 0.000274570193
Iter: 478 loss: 0.000277678017
Iter: 479 loss: 0.000274038146
Iter: 480 loss: 0.000272341713
Iter: 481 loss: 0.000275072583
Iter: 482 loss: 0.000271559024
Iter: 483 loss: 0.000270079123
Iter: 484 loss: 0.000272905454
Iter: 485 loss: 0.000269450218
Iter: 486 loss: 0.000268627307
Iter: 487 loss: 0.000268437463
Iter: 488 loss: 0.000267818279
Iter: 489 loss: 0.000268502365
Iter: 490 loss: 0.000267479161
Iter: 491 loss: 0.000266787247
Iter: 492 loss: 0.000267491298
Iter: 493 loss: 0.000266404182
Iter: 494 loss: 0.000265390903
Iter: 495 loss: 0.0002680404
Iter: 496 loss: 0.000265040842
Iter: 497 loss: 0.000264192931
Iter: 498 loss: 0.000265437178
Iter: 499 loss: 0.000263786205
Iter: 500 loss: 0.000262747228
Iter: 501 loss: 0.00026184952
Iter: 502 loss: 0.000261567067
Iter: 503 loss: 0.000259968627
Iter: 504 loss: 0.000266553718
Iter: 505 loss: 0.000259623572
Iter: 506 loss: 0.000258091954
Iter: 507 loss: 0.000258682325
Iter: 508 loss: 0.000257026288
Iter: 509 loss: 0.000255459483
Iter: 510 loss: 0.000255459134
Iter: 511 loss: 0.000254443876
Iter: 512 loss: 0.000254564337
Iter: 513 loss: 0.000253668491
Iter: 514 loss: 0.000252327416
Iter: 515 loss: 0.000256524247
Iter: 516 loss: 0.000251940539
Iter: 517 loss: 0.000250972342
Iter: 518 loss: 0.000257557404
Iter: 519 loss: 0.000250881509
Iter: 520 loss: 0.000249861041
Iter: 521 loss: 0.000256094441
Iter: 522 loss: 0.000249732984
Iter: 523 loss: 0.000249177101
Iter: 524 loss: 0.000249565725
Iter: 525 loss: 0.000248833501
Iter: 526 loss: 0.000247967051
Iter: 527 loss: 0.000249519653
Iter: 528 loss: 0.000247585966
Iter: 529 loss: 0.000246811687
Iter: 530 loss: 0.000248390599
Iter: 531 loss: 0.000246500684
Iter: 532 loss: 0.00024568825
Iter: 533 loss: 0.000245154079
Iter: 534 loss: 0.000244843977
Iter: 535 loss: 0.000243687406
Iter: 536 loss: 0.000248042372
Iter: 537 loss: 0.000243410381
Iter: 538 loss: 0.0002420815
Iter: 539 loss: 0.000242616836
Iter: 540 loss: 0.000241160596
Iter: 541 loss: 0.000240142399
Iter: 542 loss: 0.000240138819
Iter: 543 loss: 0.000239352623
Iter: 544 loss: 0.000239521411
Iter: 545 loss: 0.000238773093
Iter: 546 loss: 0.000237673259
Iter: 547 loss: 0.0002399527
Iter: 548 loss: 0.000237233297
Iter: 549 loss: 0.000236212174
Iter: 550 loss: 0.000238090463
Iter: 551 loss: 0.000235776417
Iter: 552 loss: 0.000234862324
Iter: 553 loss: 0.000234830441
Iter: 554 loss: 0.000234269581
Iter: 555 loss: 0.000235629879
Iter: 556 loss: 0.000234070962
Iter: 557 loss: 0.000233537197
Iter: 558 loss: 0.000234211853
Iter: 559 loss: 0.000233260304
Iter: 560 loss: 0.000232642968
Iter: 561 loss: 0.000233190396
Iter: 562 loss: 0.000232284132
Iter: 563 loss: 0.00023158206
Iter: 564 loss: 0.000232572958
Iter: 565 loss: 0.00023123571
Iter: 566 loss: 0.000230451653
Iter: 567 loss: 0.000231672835
Iter: 568 loss: 0.000230083795
Iter: 569 loss: 0.000229162659
Iter: 570 loss: 0.000229759811
Iter: 571 loss: 0.000228575635
Iter: 572 loss: 0.000227617915
Iter: 573 loss: 0.000235747037
Iter: 574 loss: 0.000227561366
Iter: 575 loss: 0.000226686068
Iter: 576 loss: 0.000228087229
Iter: 577 loss: 0.000226282456
Iter: 578 loss: 0.000225293828
Iter: 579 loss: 0.000229762169
Iter: 580 loss: 0.000225100594
Iter: 581 loss: 0.000224467978
Iter: 582 loss: 0.00022494694
Iter: 583 loss: 0.000224082512
Iter: 584 loss: 0.000223616604
Iter: 585 loss: 0.000223546129
Iter: 586 loss: 0.000223145442
Iter: 587 loss: 0.000223972573
Iter: 588 loss: 0.000222986651
Iter: 589 loss: 0.000222586677
Iter: 590 loss: 0.000222715753
Iter: 591 loss: 0.000222301358
Iter: 592 loss: 0.000221742928
Iter: 593 loss: 0.000222256858
Iter: 594 loss: 0.000221421375
Iter: 595 loss: 0.000220824091
Iter: 596 loss: 0.000221888055
Iter: 597 loss: 0.000220560614
Iter: 598 loss: 0.000219910449
Iter: 599 loss: 0.000220074449
Iter: 600 loss: 0.000219436275
Iter: 601 loss: 0.000218550049
Iter: 602 loss: 0.00022153859
Iter: 603 loss: 0.000218308429
Iter: 604 loss: 0.00021763175
Iter: 605 loss: 0.000219952562
Iter: 606 loss: 0.000217449196
Iter: 607 loss: 0.000216788103
Iter: 608 loss: 0.000220255897
Iter: 609 loss: 0.000216685177
Iter: 610 loss: 0.000216103785
Iter: 611 loss: 0.000217109453
Iter: 612 loss: 0.000215844571
Iter: 613 loss: 0.000215254273
Iter: 614 loss: 0.000216336062
Iter: 615 loss: 0.00021500155
Iter: 616 loss: 0.000214466083
Iter: 617 loss: 0.000221124326
Iter: 618 loss: 0.000214460495
Iter: 619 loss: 0.000214021944
Iter: 620 loss: 0.000216793705
Iter: 621 loss: 0.000213973748
Iter: 622 loss: 0.000213697058
Iter: 623 loss: 0.000213649386
Iter: 624 loss: 0.000213460342
Iter: 625 loss: 0.000213019201
Iter: 626 loss: 0.000213473424
Iter: 627 loss: 0.000212774074
Iter: 628 loss: 0.000212251398
Iter: 629 loss: 0.000213300053
Iter: 630 loss: 0.000212038227
Iter: 631 loss: 0.000211528895
Iter: 632 loss: 0.000211456441
Iter: 633 loss: 0.000211098741
Iter: 634 loss: 0.000210333863
Iter: 635 loss: 0.000213513427
Iter: 636 loss: 0.000210168539
Iter: 637 loss: 0.000209585705
Iter: 638 loss: 0.000210307859
Iter: 639 loss: 0.000209281963
Iter: 640 loss: 0.000208616751
Iter: 641 loss: 0.000214106723
Iter: 642 loss: 0.000208576763
Iter: 643 loss: 0.000208098922
Iter: 644 loss: 0.000209191028
Iter: 645 loss: 0.000207919555
Iter: 646 loss: 0.000207387289
Iter: 647 loss: 0.000207908932
Iter: 648 loss: 0.000207085715
Iter: 649 loss: 0.000206585828
Iter: 650 loss: 0.000213141044
Iter: 651 loss: 0.000206581957
Iter: 652 loss: 0.000206174038
Iter: 653 loss: 0.000209200502
Iter: 654 loss: 0.000206142533
Iter: 655 loss: 0.000205869714
Iter: 656 loss: 0.000205786811
Iter: 657 loss: 0.000205623655
Iter: 658 loss: 0.000205213641
Iter: 659 loss: 0.000205832272
Iter: 660 loss: 0.000205019373
Iter: 661 loss: 0.000204530341
Iter: 662 loss: 0.000205083255
Iter: 663 loss: 0.000204265991
Iter: 664 loss: 0.000203713134
Iter: 665 loss: 0.000204230601
Iter: 666 loss: 0.000203394651
Iter: 667 loss: 0.000202744064
Iter: 668 loss: 0.000204269978
Iter: 669 loss: 0.000202504452
Iter: 670 loss: 0.000201919873
Iter: 671 loss: 0.000204285025
Iter: 672 loss: 0.00020178876
Iter: 673 loss: 0.000201226605
Iter: 674 loss: 0.000202461437
Iter: 675 loss: 0.000201011353
Iter: 676 loss: 0.000200477516
Iter: 677 loss: 0.000204924771
Iter: 678 loss: 0.000200444571
Iter: 679 loss: 0.000200049311
Iter: 680 loss: 0.000200164708
Iter: 681 loss: 0.0001997652
Iter: 682 loss: 0.000199280417
Iter: 683 loss: 0.000203013638
Iter: 684 loss: 0.000199243135
Iter: 685 loss: 0.0001989046
Iter: 686 loss: 0.000203917967
Iter: 687 loss: 0.000198904367
Iter: 688 loss: 0.000198697948
Iter: 689 loss: 0.00019849361
Iter: 690 loss: 0.000198450129
Iter: 691 loss: 0.000198046328
Iter: 692 loss: 0.000198526453
Iter: 693 loss: 0.000197834044
Iter: 694 loss: 0.000197387097
Iter: 695 loss: 0.000198491733
Iter: 696 loss: 0.000197228073
Iter: 697 loss: 0.00019677516
Iter: 698 loss: 0.000196771667
Iter: 699 loss: 0.000196411915
Iter: 700 loss: 0.000195842105
Iter: 701 loss: 0.000197961315
Iter: 702 loss: 0.000195702814
Iter: 703 loss: 0.000195194763
Iter: 704 loss: 0.000196240231
Iter: 705 loss: 0.000194990324
Iter: 706 loss: 0.00019447747
Iter: 707 loss: 0.000196857902
Iter: 708 loss: 0.000194381544
Iter: 709 loss: 0.000193937027
Iter: 710 loss: 0.00019595807
Iter: 711 loss: 0.000193851243
Iter: 712 loss: 0.000193433225
Iter: 713 loss: 0.000194346911
Iter: 714 loss: 0.000193273096
Iter: 715 loss: 0.000192866544
Iter: 716 loss: 0.000194392836
Iter: 717 loss: 0.000192766965
Iter: 718 loss: 0.000192452659
Iter: 719 loss: 0.000192452033
Iter: 720 loss: 0.0001922589
Iter: 721 loss: 0.000192087726
Iter: 722 loss: 0.00019203726
Iter: 723 loss: 0.000191697429
Iter: 724 loss: 0.000192274776
Iter: 725 loss: 0.000191545958
Iter: 726 loss: 0.000191163796
Iter: 727 loss: 0.000191879808
Iter: 728 loss: 0.000191001251
Iter: 729 loss: 0.000190626452
Iter: 730 loss: 0.000191022569
Iter: 731 loss: 0.000190419669
Iter: 732 loss: 0.000189958228
Iter: 733 loss: 0.000190263541
Iter: 734 loss: 0.000189667509
Iter: 735 loss: 0.000189182334
Iter: 736 loss: 0.000191861938
Iter: 737 loss: 0.000189112063
Iter: 738 loss: 0.000188683887
Iter: 739 loss: 0.000189866667
Iter: 740 loss: 0.000188545324
Iter: 741 loss: 0.000188203092
Iter: 742 loss: 0.000190731458
Iter: 743 loss: 0.000188174949
Iter: 744 loss: 0.000187843034
Iter: 745 loss: 0.000188044825
Iter: 746 loss: 0.000187630096
Iter: 747 loss: 0.000187261292
Iter: 748 loss: 0.000189944403
Iter: 749 loss: 0.000187228812
Iter: 750 loss: 0.000187008467
Iter: 751 loss: 0.000187008744
Iter: 752 loss: 0.000186853678
Iter: 753 loss: 0.000186735095
Iter: 754 loss: 0.000186685473
Iter: 755 loss: 0.000186440942
Iter: 756 loss: 0.000186787773
Iter: 757 loss: 0.000186322548
Iter: 758 loss: 0.000186027319
Iter: 759 loss: 0.000186524121
Iter: 760 loss: 0.000185893921
Iter: 761 loss: 0.000185560319
Iter: 762 loss: 0.000185734025
Iter: 763 loss: 0.000185339246
Iter: 764 loss: 0.000184929
Iter: 765 loss: 0.000185660305
Iter: 766 loss: 0.000184749035
Iter: 767 loss: 0.000184354751
Iter: 768 loss: 0.000185943441
Iter: 769 loss: 0.000184266755
Iter: 770 loss: 0.000183920085
Iter: 771 loss: 0.000184949196
Iter: 772 loss: 0.000183814933
Iter: 773 loss: 0.000183476048
Iter: 774 loss: 0.000184874
Iter: 775 loss: 0.000183402124
Iter: 776 loss: 0.000183067808
Iter: 777 loss: 0.00018435216
Iter: 778 loss: 0.000182989548
Iter: 779 loss: 0.000182700605
Iter: 780 loss: 0.000183452532
Iter: 781 loss: 0.000182601332
Iter: 782 loss: 0.000182401418
Iter: 783 loss: 0.000182397
Iter: 784 loss: 0.000182259362
Iter: 785 loss: 0.000182221193
Iter: 786 loss: 0.000182136428
Iter: 787 loss: 0.000181936877
Iter: 788 loss: 0.000182001007
Iter: 789 loss: 0.000181795564
Iter: 790 loss: 0.000181508818
Iter: 791 loss: 0.000182171818
Iter: 792 loss: 0.000181402269
Iter: 793 loss: 0.000181125215
Iter: 794 loss: 0.000181418349
Iter: 795 loss: 0.000180972449
Iter: 796 loss: 0.000180625531
Iter: 797 loss: 0.000180826028
Iter: 798 loss: 0.000180400093
Iter: 799 loss: 0.000180041854
Iter: 800 loss: 0.000181691474
Iter: 801 loss: 0.000179973911
Iter: 802 loss: 0.000179632974
Iter: 803 loss: 0.000180605566
Iter: 804 loss: 0.000179525188
Iter: 805 loss: 0.000179223949
Iter: 806 loss: 0.000180349802
Iter: 807 loss: 0.000179149763
Iter: 808 loss: 0.000178829447
Iter: 809 loss: 0.000180427189
Iter: 810 loss: 0.000178775488
Iter: 811 loss: 0.000178537259
Iter: 812 loss: 0.00017928856
Iter: 813 loss: 0.000178468297
Iter: 814 loss: 0.000178310569
Iter: 815 loss: 0.000178309681
Iter: 816 loss: 0.000178187387
Iter: 817 loss: 0.000178101516
Iter: 818 loss: 0.000178058253
Iter: 819 loss: 0.000177858368
Iter: 820 loss: 0.000178045651
Iter: 821 loss: 0.000177744048
Iter: 822 loss: 0.000177486159
Iter: 823 loss: 0.000178033137
Iter: 824 loss: 0.000177383859
Iter: 825 loss: 0.000177114474
Iter: 826 loss: 0.000177393536
Iter: 827 loss: 0.000176964968
Iter: 828 loss: 0.000176650108
Iter: 829 loss: 0.000176978
Iter: 830 loss: 0.000176475325
Iter: 831 loss: 0.000176130605
Iter: 832 loss: 0.000177120965
Iter: 833 loss: 0.000176021567
Iter: 834 loss: 0.000175685767
Iter: 835 loss: 0.000176830916
Iter: 836 loss: 0.000175595836
Iter: 837 loss: 0.000175255293
Iter: 838 loss: 0.000175978916
Iter: 839 loss: 0.000175121226
Iter: 840 loss: 0.000174820219
Iter: 841 loss: 0.000178317947
Iter: 842 loss: 0.000174815825
Iter: 843 loss: 0.000174590852
Iter: 844 loss: 0.000174859015
Iter: 845 loss: 0.000174471614
Iter: 846 loss: 0.000174324232
Iter: 847 loss: 0.000174316941
Iter: 848 loss: 0.000174198853
Iter: 849 loss: 0.000174145651
Iter: 850 loss: 0.000174086163
Iter: 851 loss: 0.000173904264
Iter: 852 loss: 0.000173890992
Iter: 853 loss: 0.000173755194
Iter: 854 loss: 0.000173475346
Iter: 855 loss: 0.000174390196
Iter: 856 loss: 0.000173396722
Iter: 857 loss: 0.000173152133
Iter: 858 loss: 0.000173414592
Iter: 859 loss: 0.00017301811
Iter: 860 loss: 0.00017270715
Iter: 861 loss: 0.000172975953
Iter: 862 loss: 0.000172524567
Iter: 863 loss: 0.000172208
Iter: 864 loss: 0.000172912536
Iter: 865 loss: 0.000172087486
Iter: 866 loss: 0.000171752472
Iter: 867 loss: 0.000173329143
Iter: 868 loss: 0.00017169051
Iter: 869 loss: 0.00017141219
Iter: 870 loss: 0.000171927968
Iter: 871 loss: 0.000171292937
Iter: 872 loss: 0.0001710254
Iter: 873 loss: 0.000173712018
Iter: 874 loss: 0.000171017018
Iter: 875 loss: 0.000170800442
Iter: 876 loss: 0.000171285414
Iter: 877 loss: 0.000170717525
Iter: 878 loss: 0.000170567044
Iter: 879 loss: 0.000170566753
Iter: 880 loss: 0.000170441621
Iter: 881 loss: 0.000170483574
Iter: 882 loss: 0.000170352665
Iter: 883 loss: 0.00017021058
Iter: 884 loss: 0.000170158572
Iter: 885 loss: 0.000170079584
Iter: 886 loss: 0.000169850187
Iter: 887 loss: 0.000170503714
Iter: 888 loss: 0.000169777035
Iter: 889 loss: 0.000169555831
Iter: 890 loss: 0.000169862353
Iter: 891 loss: 0.000169446212
Iter: 892 loss: 0.00016918972
Iter: 893 loss: 0.00016940257
Iter: 894 loss: 0.000169036575
Iter: 895 loss: 0.000168758706
Iter: 896 loss: 0.000169457693
Iter: 897 loss: 0.000168661616
Iter: 898 loss: 0.000168385071
Iter: 899 loss: 0.000169310617
Iter: 900 loss: 0.000168310085
Iter: 901 loss: 0.000168041719
Iter: 902 loss: 0.000168991741
Iter: 903 loss: 0.000167972132
Iter: 904 loss: 0.000167765131
Iter: 905 loss: 0.000169247767
Iter: 906 loss: 0.000167747348
Iter: 907 loss: 0.000167545892
Iter: 908 loss: 0.000167992825
Iter: 909 loss: 0.000167468577
Iter: 910 loss: 0.000167342921
Iter: 911 loss: 0.000167342077
Iter: 912 loss: 0.000167233462
Iter: 913 loss: 0.000167251754
Iter: 914 loss: 0.000167151549
Iter: 915 loss: 0.000167011021
Iter: 916 loss: 0.00016697924
Iter: 917 loss: 0.000166888669
Iter: 918 loss: 0.000166692276
Iter: 919 loss: 0.000167404374
Iter: 920 loss: 0.000166642611
Iter: 921 loss: 0.00016646678
Iter: 922 loss: 0.00016662314
Iter: 923 loss: 0.000166363898
Iter: 924 loss: 0.000166140613
Iter: 925 loss: 0.000166426093
Iter: 926 loss: 0.000166025624
Iter: 927 loss: 0.000165795573
Iter: 928 loss: 0.000166106678
Iter: 929 loss: 0.000165679943
Iter: 930 loss: 0.000165426143
Iter: 931 loss: 0.000166671671
Iter: 932 loss: 0.000165382284
Iter: 933 loss: 0.00016516
Iter: 934 loss: 0.000165745063
Iter: 935 loss: 0.000165085279
Iter: 936 loss: 0.000164901779
Iter: 937 loss: 0.000166444399
Iter: 938 loss: 0.000164890866
Iter: 939 loss: 0.000164728874
Iter: 940 loss: 0.000165125457
Iter: 941 loss: 0.000164670899
Iter: 942 loss: 0.000164554891
Iter: 943 loss: 0.000166214624
Iter: 944 loss: 0.00016455492
Iter: 945 loss: 0.000164451048
Iter: 946 loss: 0.000164489378
Iter: 947 loss: 0.000164378769
Iter: 948 loss: 0.000164247176
Iter: 949 loss: 0.000164258
Iter: 950 loss: 0.000164145546
Iter: 951 loss: 0.000163972916
Iter: 952 loss: 0.000164523371
Iter: 953 loss: 0.000163923032
Iter: 954 loss: 0.000163762321
Iter: 955 loss: 0.000163952049
Iter: 956 loss: 0.00016367709
Iter: 957 loss: 0.000163479795
Iter: 958 loss: 0.000163653895
Iter: 959 loss: 0.000163364428
Iter: 960 loss: 0.000163144243
Iter: 961 loss: 0.000163623205
Iter: 962 loss: 0.00016305843
Iter: 963 loss: 0.000162837503
Iter: 964 loss: 0.000163410048
Iter: 965 loss: 0.000162762037
Iter: 966 loss: 0.000162538
Iter: 967 loss: 0.000163643301
Iter: 968 loss: 0.000162499651
Iter: 969 loss: 0.000162319848
Iter: 970 loss: 0.000163027158
Iter: 971 loss: 0.000162278331
Iter: 972 loss: 0.000162088734
Iter: 973 loss: 0.000162979035
Iter: 974 loss: 0.000162053271
Iter: 975 loss: 0.000161947042
Iter: 976 loss: 0.000163312856
Iter: 977 loss: 0.000161946242
Iter: 978 loss: 0.000161849472
Iter: 979 loss: 0.000161902877
Iter: 980 loss: 0.000161785676
Iter: 981 loss: 0.000161670207
Iter: 982 loss: 0.000161696211
Iter: 983 loss: 0.000161585282
Iter: 984 loss: 0.000161445874
Iter: 985 loss: 0.000161847813
Iter: 986 loss: 0.000161402131
Iter: 987 loss: 0.000161258591
Iter: 988 loss: 0.000161366945
Iter: 989 loss: 0.000161170698
Iter: 990 loss: 0.00016098778
Iter: 991 loss: 0.000161339383
Iter: 992 loss: 0.000160911513
Iter: 993 loss: 0.00016073318
Iter: 994 loss: 0.00016091537
Iter: 995 loss: 0.000160633354
Iter: 996 loss: 0.000160426775
Iter: 997 loss: 0.000161129225
Iter: 998 loss: 0.000160371099
Iter: 999 loss: 0.000160168711
Iter: 1000 loss: 0.000160935277
Iter: 1001 loss: 0.000160119976
Iter: 1002 loss: 0.000159945135
Iter: 1003 loss: 0.000160617754
Iter: 1004 loss: 0.000159904012
Iter: 1005 loss: 0.000159721705
Iter: 1006 loss: 0.000160585536
Iter: 1007 loss: 0.000159688221
Iter: 1008 loss: 0.000159570918
Iter: 1009 loss: 0.000160815951
Iter: 1010 loss: 0.000159568357
Iter: 1011 loss: 0.000159462186
Iter: 1012 loss: 0.000159664778
Iter: 1013 loss: 0.000159417788
Iter: 1014 loss: 0.00015931821
Iter: 1015 loss: 0.000159304444
Iter: 1016 loss: 0.000159234391
Iter: 1017 loss: 0.000159100775
Iter: 1018 loss: 0.000159409727
Iter: 1019 loss: 0.000159050483
Iter: 1020 loss: 0.000158904179
Iter: 1021 loss: 0.000159077434
Iter: 1022 loss: 0.00015882717
Iter: 1023 loss: 0.000158651528
Iter: 1024 loss: 0.000158897135
Iter: 1025 loss: 0.000158565439
Iter: 1026 loss: 0.000158374503
Iter: 1027 loss: 0.000158741575
Iter: 1028 loss: 0.000158294904
Iter: 1029 loss: 0.000158092254
Iter: 1030 loss: 0.000158319686
Iter: 1031 loss: 0.000157982809
Iter: 1032 loss: 0.000157771603
Iter: 1033 loss: 0.000159619143
Iter: 1034 loss: 0.000157760544
Iter: 1035 loss: 0.000157606933
Iter: 1036 loss: 0.000157899136
Iter: 1037 loss: 0.000157542469
Iter: 1038 loss: 0.000157372953
Iter: 1039 loss: 0.000158750612
Iter: 1040 loss: 0.000157361908
Iter: 1041 loss: 0.000157263858
Iter: 1042 loss: 0.000157993549
Iter: 1043 loss: 0.000157256145
Iter: 1044 loss: 0.000157158924
Iter: 1045 loss: 0.000157364295
Iter: 1046 loss: 0.000157120128
Iter: 1047 loss: 0.000157028349
Iter: 1048 loss: 0.000157036062
Iter: 1049 loss: 0.000156957307
Iter: 1050 loss: 0.0001568429
Iter: 1051 loss: 0.000157070928
Iter: 1052 loss: 0.000156795315
Iter: 1053 loss: 0.000156664086
Iter: 1054 loss: 0.000156800059
Iter: 1055 loss: 0.000156591239
Iter: 1056 loss: 0.000156438182
Iter: 1057 loss: 0.000156755967
Iter: 1058 loss: 0.000156376947
Iter: 1059 loss: 0.00015621855
Iter: 1060 loss: 0.000156411581
Iter: 1061 loss: 0.000156135749
Iter: 1062 loss: 0.000155960384
Iter: 1063 loss: 0.000156288181
Iter: 1064 loss: 0.000155885849
Iter: 1065 loss: 0.000155707938
Iter: 1066 loss: 0.000156882219
Iter: 1067 loss: 0.000155689631
Iter: 1068 loss: 0.000155554706
Iter: 1069 loss: 0.000155985588
Iter: 1070 loss: 0.000155516551
Iter: 1071 loss: 0.00015538474
Iter: 1072 loss: 0.000156254624
Iter: 1073 loss: 0.000155371046
Iter: 1074 loss: 0.000155282978
Iter: 1075 loss: 0.000155872724
Iter: 1076 loss: 0.000155274058
Iter: 1077 loss: 0.000155190413
Iter: 1078 loss: 0.000155485148
Iter: 1079 loss: 0.00015516876
Iter: 1080 loss: 0.000155099566
Iter: 1081 loss: 0.000155072121
Iter: 1082 loss: 0.000155034882
Iter: 1083 loss: 0.000154932175
Iter: 1084 loss: 0.000155094356
Iter: 1085 loss: 0.000154884139
Iter: 1086 loss: 0.000154765396
Iter: 1087 loss: 0.00015497196
Iter: 1088 loss: 0.000154713111
Iter: 1089 loss: 0.000154577836
Iter: 1090 loss: 0.000154691646
Iter: 1091 loss: 0.00015449764
Iter: 1092 loss: 0.000154340232
Iter: 1093 loss: 0.000154824549
Iter: 1094 loss: 0.000154293957
Iter: 1095 loss: 0.000154145077
Iter: 1096 loss: 0.00015417629
Iter: 1097 loss: 0.000154035282
Iter: 1098 loss: 0.00015387396
Iter: 1099 loss: 0.000155549904
Iter: 1100 loss: 0.000153869623
Iter: 1101 loss: 0.000153739893
Iter: 1102 loss: 0.000153937493
Iter: 1103 loss: 0.000153678106
Iter: 1104 loss: 0.0001535458
Iter: 1105 loss: 0.000154854788
Iter: 1106 loss: 0.000153541128
Iter: 1107 loss: 0.000153458357
Iter: 1108 loss: 0.000153908535
Iter: 1109 loss: 0.000153446046
Iter: 1110 loss: 0.000153363144
Iter: 1111 loss: 0.000153694651
Iter: 1112 loss: 0.000153344314
Iter: 1113 loss: 0.000153276982
Iter: 1114 loss: 0.000153254106
Iter: 1115 loss: 0.000153215631
Iter: 1116 loss: 0.00015311726
Iter: 1117 loss: 0.000153240908
Iter: 1118 loss: 0.000153065834
Iter: 1119 loss: 0.000152946013
Iter: 1120 loss: 0.000153168978
Iter: 1121 loss: 0.00015289498
Iter: 1122 loss: 0.000152766879
Iter: 1123 loss: 0.000152943772
Iter: 1124 loss: 0.000152703316
Iter: 1125 loss: 0.00015256225
Iter: 1126 loss: 0.000152853827
Iter: 1127 loss: 0.000152506022
Iter: 1128 loss: 0.000152359804
Iter: 1129 loss: 0.000152484339
Iter: 1130 loss: 0.000152273627
Iter: 1131 loss: 0.000152115215
Iter: 1132 loss: 0.000153174013
Iter: 1133 loss: 0.000152099528
Iter: 1134 loss: 0.00015197169
Iter: 1135 loss: 0.000152359527
Iter: 1136 loss: 0.000151933637
Iter: 1137 loss: 0.000151802815
Iter: 1138 loss: 0.000152534019
Iter: 1139 loss: 0.000151784188
Iter: 1140 loss: 0.000151685847
Iter: 1141 loss: 0.000152380177
Iter: 1142 loss: 0.000151677174
Iter: 1143 loss: 0.000151597545
Iter: 1144 loss: 0.000152026798
Iter: 1145 loss: 0.000151585307
Iter: 1146 loss: 0.000151523142
Iter: 1147 loss: 0.00015146799
Iter: 1148 loss: 0.000151451968
Iter: 1149 loss: 0.000151344953
Iter: 1150 loss: 0.000151504122
Iter: 1151 loss: 0.000151292857
Iter: 1152 loss: 0.000151176719
Iter: 1153 loss: 0.000151506421
Iter: 1154 loss: 0.000151139873
Iter: 1155 loss: 0.000151020504
Iter: 1156 loss: 0.000151066008
Iter: 1157 loss: 0.000150937791
Iter: 1158 loss: 0.000150795095
Iter: 1159 loss: 0.000151354194
Iter: 1160 loss: 0.000150762178
Iter: 1161 loss: 0.000150632055
Iter: 1162 loss: 0.000150616179
Iter: 1163 loss: 0.000150522828
Iter: 1164 loss: 0.000150375199
Iter: 1165 loss: 0.000151723594
Iter: 1166 loss: 0.000150368607
Iter: 1167 loss: 0.000150244799
Iter: 1168 loss: 0.000150486565
Iter: 1169 loss: 0.000150193897
Iter: 1170 loss: 0.00015006373
Iter: 1171 loss: 0.000150996289
Iter: 1172 loss: 0.000150052365
Iter: 1173 loss: 0.000149961619
Iter: 1174 loss: 0.000150604174
Iter: 1175 loss: 0.000149953528
Iter: 1176 loss: 0.000149878368
Iter: 1177 loss: 0.000150280146
Iter: 1178 loss: 0.000149866304
Iter: 1179 loss: 0.000149806583
Iter: 1180 loss: 0.00014976933
Iter: 1181 loss: 0.00014974513
Iter: 1182 loss: 0.000149651692
Iter: 1183 loss: 0.000149779749
Iter: 1184 loss: 0.000149604544
Iter: 1185 loss: 0.000149498417
Iter: 1186 loss: 0.000149775122
Iter: 1187 loss: 0.000149462401
Iter: 1188 loss: 0.000149353611
Iter: 1189 loss: 0.000149466417
Iter: 1190 loss: 0.000149293686
Iter: 1191 loss: 0.000149171421
Iter: 1192 loss: 0.000149461805
Iter: 1193 loss: 0.000149127241
Iter: 1194 loss: 0.000149003463
Iter: 1195 loss: 0.000149143307
Iter: 1196 loss: 0.000148936233
Iter: 1197 loss: 0.000148796826
Iter: 1198 loss: 0.000149301486
Iter: 1199 loss: 0.000148762207
Iter: 1200 loss: 0.000148641673
Iter: 1201 loss: 0.000149370782
Iter: 1202 loss: 0.000148626554
Iter: 1203 loss: 0.000148519277
Iter: 1204 loss: 0.000148883759
Iter: 1205 loss: 0.000148489868
Iter: 1206 loss: 0.000148399951
Iter: 1207 loss: 0.000149257903
Iter: 1208 loss: 0.000148396648
Iter: 1209 loss: 0.000148335792
Iter: 1210 loss: 0.000148709529
Iter: 1211 loss: 0.00014832837
Iter: 1212 loss: 0.000148278559
Iter: 1213 loss: 0.000148229417
Iter: 1214 loss: 0.000148218794
Iter: 1215 loss: 0.000148130086
Iter: 1216 loss: 0.000148255844
Iter: 1217 loss: 0.000148086314
Iter: 1218 loss: 0.000147994331
Iter: 1219 loss: 0.000148324965
Iter: 1220 loss: 0.000147970844
Iter: 1221 loss: 0.000147879546
Iter: 1222 loss: 0.000147908984
Iter: 1223 loss: 0.000147814397
Iter: 1224 loss: 0.000147703628
Iter: 1225 loss: 0.000148102888
Iter: 1226 loss: 0.000147675135
Iter: 1227 loss: 0.000147570303
Iter: 1228 loss: 0.000147576196
Iter: 1229 loss: 0.00014748791
Iter: 1230 loss: 0.000147354789
Iter: 1231 loss: 0.000148158462
Iter: 1232 loss: 0.000147338433
Iter: 1233 loss: 0.000147232509
Iter: 1234 loss: 0.000147619008
Iter: 1235 loss: 0.000147205807
Iter: 1236 loss: 0.000147104147
Iter: 1237 loss: 0.000147693208
Iter: 1238 loss: 0.000147090264
Iter: 1239 loss: 0.00014702075
Iter: 1240 loss: 0.000147729123
Iter: 1241 loss: 0.000147018523
Iter: 1242 loss: 0.00014696829
Iter: 1243 loss: 0.00014720569
Iter: 1244 loss: 0.000146959137
Iter: 1245 loss: 0.000146913
Iter: 1246 loss: 0.000146871433
Iter: 1247 loss: 0.00014685982
Iter: 1248 loss: 0.000146784223
Iter: 1249 loss: 0.000146916194
Iter: 1250 loss: 0.000146750521
Iter: 1251 loss: 0.000146669394
Iter: 1252 loss: 0.000146862702
Iter: 1253 loss: 0.000146639941
Iter: 1254 loss: 0.000146551538
Iter: 1255 loss: 0.00014668185
Iter: 1256 loss: 0.000146509294
Iter: 1257 loss: 0.000146416336
Iter: 1258 loss: 0.000146546809
Iter: 1259 loss: 0.000146370396
Iter: 1260 loss: 0.000146264385
Iter: 1261 loss: 0.000146501407
Iter: 1262 loss: 0.000146223872
Iter: 1263 loss: 0.000146114835
Iter: 1264 loss: 0.000146318373
Iter: 1265 loss: 0.000146068167
Iter: 1266 loss: 0.000145965198
Iter: 1267 loss: 0.00014671628
Iter: 1268 loss: 0.000145956641
Iter: 1269 loss: 0.000145865837
Iter: 1270 loss: 0.000146153121
Iter: 1271 loss: 0.00014584008
Iter: 1272 loss: 0.0001457654
Iter: 1273 loss: 0.000146658276
Iter: 1274 loss: 0.000145764221
Iter: 1275 loss: 0.000145718121
Iter: 1276 loss: 0.0001460192
Iter: 1277 loss: 0.000145713057
Iter: 1278 loss: 0.000145675149
Iter: 1279 loss: 0.000145636586
Iter: 1280 loss: 0.000145629368
Iter: 1281 loss: 0.000145561673
Iter: 1282 loss: 0.000145610247
Iter: 1283 loss: 0.000145519909
Iter: 1284 loss: 0.000145438156
Iter: 1285 loss: 0.000145717917
Iter: 1286 loss: 0.000145416489
Iter: 1287 loss: 0.0001453367
Iter: 1288 loss: 0.000145442813
Iter: 1289 loss: 0.000145296886
Iter: 1290 loss: 0.000145203754
Iter: 1291 loss: 0.00014532177
Iter: 1292 loss: 0.000145155849
Iter: 1293 loss: 0.000145060578
Iter: 1294 loss: 0.000145304526
Iter: 1295 loss: 0.000145028374
Iter: 1296 loss: 0.000144923964
Iter: 1297 loss: 0.000145157945
Iter: 1298 loss: 0.000144884179
Iter: 1299 loss: 0.000144796635
Iter: 1300 loss: 0.000145208673
Iter: 1301 loss: 0.000144780352
Iter: 1302 loss: 0.000144689329
Iter: 1303 loss: 0.000145039885
Iter: 1304 loss: 0.00014466756
Iter: 1305 loss: 0.000144607911
Iter: 1306 loss: 0.000144607809
Iter: 1307 loss: 0.000144569043
Iter: 1308 loss: 0.000144752805
Iter: 1309 loss: 0.00014456184
Iter: 1310 loss: 0.000144524849
Iter: 1311 loss: 0.00014448716
Iter: 1312 loss: 0.000144479913
Iter: 1313 loss: 0.000144416816
Iter: 1314 loss: 0.000144481412
Iter: 1315 loss: 0.000144381687
Iter: 1316 loss: 0.000144307502
Iter: 1317 loss: 0.000144467311
Iter: 1318 loss: 0.00014427831
Iter: 1319 loss: 0.000144197969
Iter: 1320 loss: 0.000144427046
Iter: 1321 loss: 0.000144172518
Iter: 1322 loss: 0.000144097372
Iter: 1323 loss: 0.000144151709
Iter: 1324 loss: 0.000144050893
Iter: 1325 loss: 0.000143960016
Iter: 1326 loss: 0.00014419634
Iter: 1327 loss: 0.000143928715
Iter: 1328 loss: 0.000143833779
Iter: 1329 loss: 0.000144019345
Iter: 1330 loss: 0.000143794663
Iter: 1331 loss: 0.000143702899
Iter: 1332 loss: 0.000144201666
Iter: 1333 loss: 0.000143689191
Iter: 1334 loss: 0.000143613666
Iter: 1335 loss: 0.000143977479
Iter: 1336 loss: 0.0001436
Iter: 1337 loss: 0.00014353903
Iter: 1338 loss: 0.000144076213
Iter: 1339 loss: 0.000143535814
Iter: 1340 loss: 0.000143490077
Iter: 1341 loss: 0.000143794139
Iter: 1342 loss: 0.000143485246
Iter: 1343 loss: 0.000143447876
Iter: 1344 loss: 0.000143424084
Iter: 1345 loss: 0.000143409095
Iter: 1346 loss: 0.00014335064
Iter: 1347 loss: 0.000143364683
Iter: 1348 loss: 0.000143307829
Iter: 1349 loss: 0.000143223384
Iter: 1350 loss: 0.000143424564
Iter: 1351 loss: 0.00014319297
Iter: 1352 loss: 0.000143119847
Iter: 1353 loss: 0.000143466255
Iter: 1354 loss: 0.000143107201
Iter: 1355 loss: 0.000143038051
Iter: 1356 loss: 0.000142972858
Iter: 1357 loss: 0.00014295656
Iter: 1358 loss: 0.000142856399
Iter: 1359 loss: 0.000143485551
Iter: 1360 loss: 0.000142844947
Iter: 1361 loss: 0.000142750592
Iter: 1362 loss: 0.000142792909
Iter: 1363 loss: 0.000142686768
Iter: 1364 loss: 0.000142593854
Iter: 1365 loss: 0.000143323065
Iter: 1366 loss: 0.000142587436
Iter: 1367 loss: 0.000142508856
Iter: 1368 loss: 0.000142736666
Iter: 1369 loss: 0.000142484554
Iter: 1370 loss: 0.000142418721
Iter: 1371 loss: 0.000143213983
Iter: 1372 loss: 0.000142418226
Iter: 1373 loss: 0.000142373232
Iter: 1374 loss: 0.000142641074
Iter: 1375 loss: 0.000142367571
Iter: 1376 loss: 0.000142327684
Iter: 1377 loss: 0.000142297882
Iter: 1378 loss: 0.000142284873
Iter: 1379 loss: 0.000142221616
Iter: 1380 loss: 0.000142263685
Iter: 1381 loss: 0.000142181379
Iter: 1382 loss: 0.000142105244
Iter: 1383 loss: 0.000142362216
Iter: 1384 loss: 0.00014208506
Iter: 1385 loss: 0.000142019446
Iter: 1386 loss: 0.000142230405
Iter: 1387 loss: 0.00014200095
Iter: 1388 loss: 0.000141933677
Iter: 1389 loss: 0.000141927128
Iter: 1390 loss: 0.000141877405
Iter: 1391 loss: 0.000141789904
Iter: 1392 loss: 0.000142034871
Iter: 1393 loss: 0.000141761702
Iter: 1394 loss: 0.000141673474
Iter: 1395 loss: 0.000141988072
Iter: 1396 loss: 0.000141651049
Iter: 1397 loss: 0.000141573299
Iter: 1398 loss: 0.000141738186
Iter: 1399 loss: 0.000141542594
Iter: 1400 loss: 0.00014146883
Iter: 1401 loss: 0.000142035773
Iter: 1402 loss: 0.000141463097
Iter: 1403 loss: 0.000141403929
Iter: 1404 loss: 0.000141779266
Iter: 1405 loss: 0.000141396915
Iter: 1406 loss: 0.000141347089
Iter: 1407 loss: 0.000141706842
Iter: 1408 loss: 0.000141342869
Iter: 1409 loss: 0.000141305631
Iter: 1410 loss: 0.000141294106
Iter: 1411 loss: 0.000141271827
Iter: 1412 loss: 0.000141222496
Iter: 1413 loss: 0.000141233846
Iter: 1414 loss: 0.00014118565
Iter: 1415 loss: 0.00014111404
Iter: 1416 loss: 0.000141234981
Iter: 1417 loss: 0.00014108204
Iter: 1418 loss: 0.000141017226
Iter: 1419 loss: 0.000141438562
Iter: 1420 loss: 0.000141010023
Iter: 1421 loss: 0.000140952878
Iter: 1422 loss: 0.000140891847
Iter: 1423 loss: 0.000140882039
Iter: 1424 loss: 0.000140787481
Iter: 1425 loss: 0.000141285651
Iter: 1426 loss: 0.000140772812
Iter: 1427 loss: 0.000140695818
Iter: 1428 loss: 0.000140838238
Iter: 1429 loss: 0.000140662945
Iter: 1430 loss: 0.000140575736
Iter: 1431 loss: 0.000140857417
Iter: 1432 loss: 0.000140550983
Iter: 1433 loss: 0.000140476855
Iter: 1434 loss: 0.000140805932
Iter: 1435 loss: 0.000140461882
Iter: 1436 loss: 0.00014038838
Iter: 1437 loss: 0.000140923759
Iter: 1438 loss: 0.000140382399
Iter: 1439 loss: 0.000140331016
Iter: 1440 loss: 0.000140880817
Iter: 1441 loss: 0.000140329561
Iter: 1442 loss: 0.000140295451
Iter: 1443 loss: 0.000140279357
Iter: 1444 loss: 0.000140262797
Iter: 1445 loss: 0.000140212767
Iter: 1446 loss: 0.000140196877
Iter: 1447 loss: 0.000140167584
Iter: 1448 loss: 0.000140092452
Iter: 1449 loss: 0.000140342105
Iter: 1450 loss: 0.000140072065
Iter: 1451 loss: 0.000140012737
Iter: 1452 loss: 0.000140257718
Iter: 1453 loss: 0.000139999946
Iter: 1454 loss: 0.000139935379
Iter: 1455 loss: 0.00013990108
Iter: 1456 loss: 0.000139872223
Iter: 1457 loss: 0.000139782351
Iter: 1458 loss: 0.000140087446
Iter: 1459 loss: 0.000139758631
Iter: 1460 loss: 0.00013967292
Iter: 1461 loss: 0.000139927113
Iter: 1462 loss: 0.000139646712
Iter: 1463 loss: 0.000139559808
Iter: 1464 loss: 0.000139741387
Iter: 1465 loss: 0.000139525408
Iter: 1466 loss: 0.000139438125
Iter: 1467 loss: 0.00013988759
Iter: 1468 loss: 0.000139423879
Iter: 1469 loss: 0.000139356853
Iter: 1470 loss: 0.000140116783
Iter: 1471 loss: 0.000139355921
Iter: 1472 loss: 0.000139309355
Iter: 1473 loss: 0.000139680822
Iter: 1474 loss: 0.000139306328
Iter: 1475 loss: 0.000139269192
Iter: 1476 loss: 0.000139247015
Iter: 1477 loss: 0.000139231954
Iter: 1478 loss: 0.000139180222
Iter: 1479 loss: 0.000139206983
Iter: 1480 loss: 0.000139145792
Iter: 1481 loss: 0.000139079217
Iter: 1482 loss: 0.000139195079
Iter: 1483 loss: 0.000139049691
Iter: 1484 loss: 0.000138978838
Iter: 1485 loss: 0.000139279655
Iter: 1486 loss: 0.000138963849
Iter: 1487 loss: 0.000138901261
Iter: 1488 loss: 0.000138973744
Iter: 1489 loss: 0.000138867545
Iter: 1490 loss: 0.000138784992
Iter: 1491 loss: 0.000138810501
Iter: 1492 loss: 0.000138725809
Iter: 1493 loss: 0.000138643969
Iter: 1494 loss: 0.000139127194
Iter: 1495 loss: 0.000138633157
Iter: 1496 loss: 0.000138546064
Iter: 1497 loss: 0.000138614501
Iter: 1498 loss: 0.000138492833
Iter: 1499 loss: 0.000138409087
Iter: 1500 loss: 0.000139014359
Iter: 1501 loss: 0.000138401927
Iter: 1502 loss: 0.000138333184
Iter: 1503 loss: 0.000138914183
Iter: 1504 loss: 0.000138328935
Iter: 1505 loss: 0.000138280069
Iter: 1506 loss: 0.000138758362
Iter: 1507 loss: 0.000138278367
Iter: 1508 loss: 0.000138241638
Iter: 1509 loss: 0.000138226256
Iter: 1510 loss: 0.00013820731
Iter: 1511 loss: 0.00013815728
Iter: 1512 loss: 0.00013815405
Iter: 1513 loss: 0.000138115895
Iter: 1514 loss: 0.000138042262
Iter: 1515 loss: 0.000138216972
Iter: 1516 loss: 0.000138015617
Iter: 1517 loss: 0.000137948693
Iter: 1518 loss: 0.000138268777
Iter: 1519 loss: 0.000137936295
Iter: 1520 loss: 0.000137873925
Iter: 1521 loss: 0.000137886324
Iter: 1522 loss: 0.000137827563
Iter: 1523 loss: 0.000137738971
Iter: 1524 loss: 0.000137900992
Iter: 1525 loss: 0.000137700714
Iter: 1526 loss: 0.000137618816
Iter: 1527 loss: 0.000137827388
Iter: 1528 loss: 0.000137590469
Iter: 1529 loss: 0.000137497205
Iter: 1530 loss: 0.00013778366
Iter: 1531 loss: 0.000137469717
Iter: 1532 loss: 0.000137385767
Iter: 1533 loss: 0.000137670839
Iter: 1534 loss: 0.000137362978
Iter: 1535 loss: 0.00013730512
Iter: 1536 loss: 0.000137305353
Iter: 1537 loss: 0.000137265684
Iter: 1538 loss: 0.00013754901
Iter: 1539 loss: 0.000137262075
Iter: 1540 loss: 0.000137225521
Iter: 1541 loss: 0.000137193914
Iter: 1542 loss: 0.000137184048
Iter: 1543 loss: 0.000137128911
Iter: 1544 loss: 0.000137176336
Iter: 1545 loss: 0.0001370963
Iter: 1546 loss: 0.000137032475
Iter: 1547 loss: 0.000137128809
Iter: 1548 loss: 0.000137001713
Iter: 1549 loss: 0.000136927905
Iter: 1550 loss: 0.000137249328
Iter: 1551 loss: 0.000136912553
Iter: 1552 loss: 0.000136856106
Iter: 1553 loss: 0.000136987277
Iter: 1554 loss: 0.00013683521
Iter: 1555 loss: 0.000136766874
Iter: 1556 loss: 0.000136747098
Iter: 1557 loss: 0.000136706221
Iter: 1558 loss: 0.000136632167
Iter: 1559 loss: 0.000137072988
Iter: 1560 loss: 0.000136623101
Iter: 1561 loss: 0.000136548464
Iter: 1562 loss: 0.000136607458
Iter: 1563 loss: 0.000136503513
Iter: 1564 loss: 0.000136422241
Iter: 1565 loss: 0.000136924704
Iter: 1566 loss: 0.000136412316
Iter: 1567 loss: 0.000136357441
Iter: 1568 loss: 0.000137005904
Iter: 1569 loss: 0.000136356626
Iter: 1570 loss: 0.000136314629
Iter: 1571 loss: 0.000136612522
Iter: 1572 loss: 0.000136310759
Iter: 1573 loss: 0.000136273025
Iter: 1574 loss: 0.000136259448
Iter: 1575 loss: 0.000136238348
Iter: 1576 loss: 0.000136191753
Iter: 1577 loss: 0.000136200513
Iter: 1578 loss: 0.000136156945
Iter: 1579 loss: 0.000136092422
Iter: 1580 loss: 0.000136167917
Iter: 1581 loss: 0.000136057963
Iter: 1582 loss: 0.000135990354
Iter: 1583 loss: 0.000136453149
Iter: 1584 loss: 0.000135983646
Iter: 1585 loss: 0.000135931725
Iter: 1586 loss: 0.000135963055
Iter: 1587 loss: 0.000135898634
Iter: 1588 loss: 0.000135826936
Iter: 1589 loss: 0.000135959985
Iter: 1590 loss: 0.000135796523
Iter: 1591 loss: 0.000135731665
Iter: 1592 loss: 0.000135854643
Iter: 1593 loss: 0.000135703915
Iter: 1594 loss: 0.000135631766
Iter: 1595 loss: 0.000135882132
Iter: 1596 loss: 0.00013561247
Iter: 1597 loss: 0.000135537353
Iter: 1598 loss: 0.000135719398
Iter: 1599 loss: 0.000135510141
Iter: 1600 loss: 0.000135463488
Iter: 1601 loss: 0.000135463
Iter: 1602 loss: 0.000135427399
Iter: 1603 loss: 0.000135652692
Iter: 1604 loss: 0.000135423354
Iter: 1605 loss: 0.000135388051
Iter: 1606 loss: 0.000135365612
Iter: 1607 loss: 0.000135351613
Iter: 1608 loss: 0.000135302689
Iter: 1609 loss: 0.000135344308
Iter: 1610 loss: 0.000135274182
Iter: 1611 loss: 0.000135218797
Iter: 1612 loss: 0.000135279377
Iter: 1613 loss: 0.000135188864
Iter: 1614 loss: 0.00013512533
Iter: 1615 loss: 0.000135486596
Iter: 1616 loss: 0.00013511625
Iter: 1617 loss: 0.000135070353
Iter: 1618 loss: 0.000135161186
Iter: 1619 loss: 0.000135051421
Iter: 1620 loss: 0.000134995236
Iter: 1621 loss: 0.000135009308
Iter: 1622 loss: 0.000134954491
Iter: 1623 loss: 0.000134890186
Iter: 1624 loss: 0.000135164388
Iter: 1625 loss: 0.000134877148
Iter: 1626 loss: 0.000134814502
Iter: 1627 loss: 0.000134855247
Iter: 1628 loss: 0.000134774746
Iter: 1629 loss: 0.000134696747
Iter: 1630 loss: 0.000135231123
Iter: 1631 loss: 0.000134689093
Iter: 1632 loss: 0.000134642702
Iter: 1633 loss: 0.000135079099
Iter: 1634 loss: 0.000134641319
Iter: 1635 loss: 0.000134600981
Iter: 1636 loss: 0.000134875081
Iter: 1637 loss: 0.000134597256
Iter: 1638 loss: 0.000134560309
Iter: 1639 loss: 0.000134560687
Iter: 1640 loss: 0.000134530492
Iter: 1641 loss: 0.000134486676
Iter: 1642 loss: 0.000134486312
Iter: 1643 loss: 0.00013445181
Iter: 1644 loss: 0.000134391361
Iter: 1645 loss: 0.000134498914
Iter: 1646 loss: 0.000134365502
Iter: 1647 loss: 0.000134308284
Iter: 1648 loss: 0.00013466386
Iter: 1649 loss: 0.00013430175
Iter: 1650 loss: 0.000134255271
Iter: 1651 loss: 0.000134278234
Iter: 1652 loss: 0.000134224116
Iter: 1653 loss: 0.000134162867
Iter: 1654 loss: 0.00013432643
Iter: 1655 loss: 0.000134142567
Iter: 1656 loss: 0.000134083064
Iter: 1657 loss: 0.000134152142
Iter: 1658 loss: 0.000134051545
Iter: 1659 loss: 0.000133986992
Iter: 1660 loss: 0.000134156784
Iter: 1661 loss: 0.000133965223
Iter: 1662 loss: 0.000133890164
Iter: 1663 loss: 0.000134156697
Iter: 1664 loss: 0.000133871014
Iter: 1665 loss: 0.000133826
Iter: 1666 loss: 0.000134499991
Iter: 1667 loss: 0.000133825786
Iter: 1668 loss: 0.000133791676
Iter: 1669 loss: 0.000134046277
Iter: 1670 loss: 0.000133788766
Iter: 1671 loss: 0.000133756024
Iter: 1672 loss: 0.000133742753
Iter: 1673 loss: 0.000133725378
Iter: 1674 loss: 0.00013368018
Iter: 1675 loss: 0.000133682988
Iter: 1676 loss: 0.00013364508
Iter: 1677 loss: 0.000133592679
Iter: 1678 loss: 0.00013372922
Iter: 1679 loss: 0.000133575057
Iter: 1680 loss: 0.000133521651
Iter: 1681 loss: 0.000133712063
Iter: 1682 loss: 0.000133508089
Iter: 1683 loss: 0.000133460475
Iter: 1684 loss: 0.000133575755
Iter: 1685 loss: 0.000133443187
Iter: 1686 loss: 0.00013339438
Iter: 1687 loss: 0.000133424342
Iter: 1688 loss: 0.000133362875
Iter: 1689 loss: 0.000133302441
Iter: 1690 loss: 0.00013355125
Iter: 1691 loss: 0.000133289112
Iter: 1692 loss: 0.000133240348
Iter: 1693 loss: 0.000133246649
Iter: 1694 loss: 0.000133203415
Iter: 1695 loss: 0.000133139212
Iter: 1696 loss: 0.000133715308
Iter: 1697 loss: 0.000133136244
Iter: 1698 loss: 0.00013309771
Iter: 1699 loss: 0.000133376248
Iter: 1700 loss: 0.00013309416
Iter: 1701 loss: 0.000133061476
Iter: 1702 loss: 0.00013334956
Iter: 1703 loss: 0.000133059657
Iter: 1704 loss: 0.000133031383
Iter: 1705 loss: 0.000133041074
Iter: 1706 loss: 0.000133011141
Iter: 1707 loss: 0.000132978617
Iter: 1708 loss: 0.000132952933
Iter: 1709 loss: 0.00013294298
Iter: 1710 loss: 0.00013289554
Iter: 1711 loss: 0.000133060385
Iter: 1712 loss: 0.000132883099
Iter: 1713 loss: 0.000132840039
Iter: 1714 loss: 0.00013299445
Iter: 1715 loss: 0.000132829053
Iter: 1716 loss: 0.000132784699
Iter: 1717 loss: 0.000132844856
Iter: 1718 loss: 0.000132762405
Iter: 1719 loss: 0.000132715635
Iter: 1720 loss: 0.000132841407
Iter: 1721 loss: 0.000132700341
Iter: 1722 loss: 0.000132652582
Iter: 1723 loss: 0.000132733403
Iter: 1724 loss: 0.000132631045
Iter: 1725 loss: 0.000132584624
Iter: 1726 loss: 0.000132687972
Iter: 1727 loss: 0.000132567
Iter: 1728 loss: 0.000132514091
Iter: 1729 loss: 0.000132668763
Iter: 1730 loss: 0.000132497458
Iter: 1731 loss: 0.000132456829
Iter: 1732 loss: 0.000132994654
Iter: 1733 loss: 0.000132456917
Iter: 1734 loss: 0.000132430694
Iter: 1735 loss: 0.000132709116
Iter: 1736 loss: 0.000132430228
Iter: 1737 loss: 0.000132407353
Iter: 1738 loss: 0.000132401736
Iter: 1739 loss: 0.000132386966
Iter: 1740 loss: 0.000132353205
Iter: 1741 loss: 0.000132320609
Iter: 1742 loss: 0.000132313158
Iter: 1743 loss: 0.000132268178
Iter: 1744 loss: 0.000132500732
Iter: 1745 loss: 0.000132261121
Iter: 1746 loss: 0.000132218498
Iter: 1747 loss: 0.000132281159
Iter: 1748 loss: 0.000132198
Iter: 1749 loss: 0.000132150628
Iter: 1750 loss: 0.000132333284
Iter: 1751 loss: 0.000132139365
Iter: 1752 loss: 0.00013209958
Iter: 1753 loss: 0.000132122
Iter: 1754 loss: 0.000132073561
Iter: 1755 loss: 0.000132024259
Iter: 1756 loss: 0.000132237416
Iter: 1757 loss: 0.000132013927
Iter: 1758 loss: 0.000131974142
Iter: 1759 loss: 0.000131978566
Iter: 1760 loss: 0.000131943176
Iter: 1761 loss: 0.000131889828
Iter: 1762 loss: 0.000132236368
Iter: 1763 loss: 0.000131884372
Iter: 1764 loss: 0.000131846959
Iter: 1765 loss: 0.000132230809
Iter: 1766 loss: 0.000131845969
Iter: 1767 loss: 0.000131820911
Iter: 1768 loss: 0.00013206969
Iter: 1769 loss: 0.000131819863
Iter: 1770 loss: 0.000131798093
Iter: 1771 loss: 0.000131806883
Iter: 1772 loss: 0.000131782726
Iter: 1773 loss: 0.000131754219
Iter: 1774 loss: 0.000131715729
Iter: 1775 loss: 0.000131713852
Iter: 1776 loss: 0.000131668581
Iter: 1777 loss: 0.000131912064
Iter: 1778 loss: 0.000131662
Iter: 1779 loss: 0.000131623296
Iter: 1780 loss: 0.000131725392
Iter: 1781 loss: 0.000131609893
Iter: 1782 loss: 0.000131567416
Iter: 1783 loss: 0.000131643028
Iter: 1784 loss: 0.00013154879
Iter: 1785 loss: 0.000131506327
Iter: 1786 loss: 0.000131621084
Iter: 1787 loss: 0.000131492096
Iter: 1788 loss: 0.000131451132
Iter: 1789 loss: 0.000131517838
Iter: 1790 loss: 0.000131432287
Iter: 1791 loss: 0.000131387074
Iter: 1792 loss: 0.000131485693
Iter: 1793 loss: 0.000131369568
Iter: 1794 loss: 0.000131321503
Iter: 1795 loss: 0.000131373905
Iter: 1796 loss: 0.000131295237
Iter: 1797 loss: 0.00013125682
Iter: 1798 loss: 0.00013125538
Iter: 1799 loss: 0.000131232198
Iter: 1800 loss: 0.000131468245
Iter: 1801 loss: 0.000131231165
Iter: 1802 loss: 0.000131209817
Iter: 1803 loss: 0.000131202483
Iter: 1804 loss: 0.00013119
Iter: 1805 loss: 0.000131154942
Iter: 1806 loss: 0.000131118257
Iter: 1807 loss: 0.000131111461
Iter: 1808 loss: 0.000131068562
Iter: 1809 loss: 0.000131258566
Iter: 1810 loss: 0.000131060122
Iter: 1811 loss: 0.000131016801
Iter: 1812 loss: 0.000131133638
Iter: 1813 loss: 0.000131002424
Iter: 1814 loss: 0.000130959379
Iter: 1815 loss: 0.000131093111
Iter: 1816 loss: 0.000130946806
Iter: 1817 loss: 0.000130907
Iter: 1818 loss: 0.000130945613
Iter: 1819 loss: 0.000130884509
Iter: 1820 loss: 0.000130841
Iter: 1821 loss: 0.000131006906
Iter: 1822 loss: 0.000130830536
Iter: 1823 loss: 0.000130789354
Iter: 1824 loss: 0.000130827626
Iter: 1825 loss: 0.000130765489
Iter: 1826 loss: 0.000130719098
Iter: 1827 loss: 0.000130820175
Iter: 1828 loss: 0.000130701213
Iter: 1829 loss: 0.000130663699
Iter: 1830 loss: 0.000130663771
Iter: 1831 loss: 0.000130640197
Iter: 1832 loss: 0.000130894521
Iter: 1833 loss: 0.000130639586
Iter: 1834 loss: 0.000130619053
Iter: 1835 loss: 0.000130628207
Iter: 1836 loss: 0.000130605011
Iter: 1837 loss: 0.000130578032
Iter: 1838 loss: 0.000130550121
Iter: 1839 loss: 0.00013054529
Iter: 1840 loss: 0.000130507673
Iter: 1841 loss: 0.000130618486
Iter: 1842 loss: 0.000130496337
Iter: 1843 loss: 0.000130460408
Iter: 1844 loss: 0.000130626271
Iter: 1845 loss: 0.00013045354
Iter: 1846 loss: 0.000130417204
Iter: 1847 loss: 0.000130445289
Iter: 1848 loss: 0.000130395143
Iter: 1849 loss: 0.000130356551
Iter: 1850 loss: 0.000130533095
Iter: 1851 loss: 0.000130348897
Iter: 1852 loss: 0.000130316854
Iter: 1853 loss: 0.000130323606
Iter: 1854 loss: 0.000130293076
Iter: 1855 loss: 0.000130248722
Iter: 1856 loss: 0.000130450775
Iter: 1857 loss: 0.000130240645
Iter: 1858 loss: 0.00013020332
Iter: 1859 loss: 0.000130194618
Iter: 1860 loss: 0.000130170461
Iter: 1861 loss: 0.000130141983
Iter: 1862 loss: 0.000130138942
Iter: 1863 loss: 0.000130117172
Iter: 1864 loss: 0.000130298286
Iter: 1865 loss: 0.000130115586
Iter: 1866 loss: 0.000130094573
Iter: 1867 loss: 0.000130100321
Iter: 1868 loss: 0.000130079366
Iter: 1869 loss: 0.000130052533
Iter: 1870 loss: 0.000130041066
Iter: 1871 loss: 0.0001300273
Iter: 1872 loss: 0.000129993889
Iter: 1873 loss: 0.000130021901
Iter: 1874 loss: 0.000129974127
Iter: 1875 loss: 0.000129936496
Iter: 1876 loss: 0.000130222295
Iter: 1877 loss: 0.000129933425
Iter: 1878 loss: 0.000129899388
Iter: 1879 loss: 0.000129919223
Iter: 1880 loss: 0.00012987743
Iter: 1881 loss: 0.000129838212
Iter: 1882 loss: 0.000130011147
Iter: 1883 loss: 0.000129830165
Iter: 1884 loss: 0.000129799038
Iter: 1885 loss: 0.000129806926
Iter: 1886 loss: 0.000129776337
Iter: 1887 loss: 0.000129731474
Iter: 1888 loss: 0.00012991362
Iter: 1889 loss: 0.00012972187
Iter: 1890 loss: 0.000129685533
Iter: 1891 loss: 0.00012969019
Iter: 1892 loss: 0.000129657899
Iter: 1893 loss: 0.000129623426
Iter: 1894 loss: 0.000129623251
Iter: 1895 loss: 0.000129600769
Iter: 1896 loss: 0.000129882537
Iter: 1897 loss: 0.000129600521
Iter: 1898 loss: 0.000129581051
Iter: 1899 loss: 0.000129591179
Iter: 1900 loss: 0.000129568682
Iter: 1901 loss: 0.000129544234
Iter: 1902 loss: 0.000129524502
Iter: 1903 loss: 0.000129517954
Iter: 1904 loss: 0.000129482985
Iter: 1905 loss: 0.000129526219
Iter: 1906 loss: 0.000129464897
Iter: 1907 loss: 0.000129428052
Iter: 1908 loss: 0.000129639549
Iter: 1909 loss: 0.000129423162
Iter: 1910 loss: 0.000129385604
Iter: 1911 loss: 0.000129428227
Iter: 1912 loss: 0.000129365246
Iter: 1913 loss: 0.00012933035
Iter: 1914 loss: 0.000129492822
Iter: 1915 loss: 0.000129324122
Iter: 1916 loss: 0.000129292399
Iter: 1917 loss: 0.000129290827
Iter: 1918 loss: 0.000129266438
Iter: 1919 loss: 0.000129225373
Iter: 1920 loss: 0.000129439111
Iter: 1921 loss: 0.000129218737
Iter: 1922 loss: 0.000129183114
Iter: 1923 loss: 0.000129214779
Iter: 1924 loss: 0.000129162203
Iter: 1925 loss: 0.000129126449
Iter: 1926 loss: 0.000129394903
Iter: 1927 loss: 0.000129123684
Iter: 1928 loss: 0.000129099601
Iter: 1929 loss: 0.000129099644
Iter: 1930 loss: 0.000129081498
Iter: 1931 loss: 0.000129104621
Iter: 1932 loss: 0.000129071821
Iter: 1933 loss: 0.000129051972
Iter: 1934 loss: 0.000129029009
Iter: 1935 loss: 0.000129026448
Iter: 1936 loss: 0.000128991669
Iter: 1937 loss: 0.000129027409
Iter: 1938 loss: 0.00012897233
Iter: 1939 loss: 0.000128937158
Iter: 1940 loss: 0.00012913809
Iter: 1941 loss: 0.000128932297
Iter: 1942 loss: 0.000128893895
Iter: 1943 loss: 0.000128942309
Iter: 1944 loss: 0.000128873726
Iter: 1945 loss: 0.000128844025
Iter: 1946 loss: 0.000129002714
Iter: 1947 loss: 0.000128839223
Iter: 1948 loss: 0.000128809712
Iter: 1949 loss: 0.000128791813
Iter: 1950 loss: 0.000128780113
Iter: 1951 loss: 0.000128740547
Iter: 1952 loss: 0.000129006337
Iter: 1953 loss: 0.000128736545
Iter: 1954 loss: 0.000128702202
Iter: 1955 loss: 0.000128717191
Iter: 1956 loss: 0.00012867857
Iter: 1957 loss: 0.000128642685
Iter: 1958 loss: 0.000128923246
Iter: 1959 loss: 0.0001286404
Iter: 1960 loss: 0.000128617641
Iter: 1961 loss: 0.000128617277
Iter: 1962 loss: 0.000128599524
Iter: 1963 loss: 0.000128620741
Iter: 1964 loss: 0.000128590313
Iter: 1965 loss: 0.00012857042
Iter: 1966 loss: 0.000128549233
Iter: 1967 loss: 0.000128545769
Iter: 1968 loss: 0.000128512824
Iter: 1969 loss: 0.00012854152
Iter: 1970 loss: 0.000128493513
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4
+ date
Tue Oct 27 19:19:13 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d93d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5da0a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5da0a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5da0a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d8ca378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d8caf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d852950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d87d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d80b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d82c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d7df950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d79a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d7a61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d74aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d782840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d782158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d7127b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d739950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d69b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d69b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d6bf1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d6bf510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d633950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d5d66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d5d62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d588378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d5b5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d5b5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d56d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d507400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d56d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d4f3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d4fb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef5d49fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef2e7e19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef2e7f37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0958645493
Iter: 2 loss: 17077.6016
Iter: 3 loss: 5037.40332
Iter: 4 loss: 0.0958595574
Iter: 5 loss: 1299.3158
Iter: 6 loss: 3029.85352
Iter: 7 loss: 1853.81519
Iter: 8 loss: 1056.42468
Iter: 9 loss: 169.032806
Iter: 10 loss: 0.0958577543
Iter: 11 loss: 0.0966798961
Iter: 12 loss: 0.09472958
Iter: 13 loss: 0.0722804517
Iter: 14 loss: 0.070630677
Iter: 15 loss: 0.0543875024
Iter: 16 loss: 0.0535040572
Iter: 17 loss: 0.0844036788
Iter: 18 loss: 0.0941845328
Iter: 19 loss: 0.0927295834
Iter: 20 loss: 0.0710477084
Iter: 21 loss: 0.068987146
Iter: 22 loss: 0.0667428896
Iter: 23 loss: 0.0571409762
Iter: 24 loss: 48.9415283
Iter: 25 loss: 0.0636378154
Iter: 26 loss: 0.0646398515
Iter: 27 loss: 0.0522016659
Iter: 28 loss: 0.0509372801
Iter: 29 loss: 66.0666962
Iter: 30 loss: 1.70435691
Iter: 31 loss: 0.0509254299
Iter: 32 loss: 0.0504708141
Iter: 33 loss: 0.0488674305
Iter: 34 loss: 0.0488268882
Iter: 35 loss: 0.0482065827
Iter: 36 loss: 0.0464561693
Iter: 37 loss: 0.0553977564
Iter: 38 loss: 0.045817703
Iter: 39 loss: 0.0447901
Iter: 40 loss: 0.0441431329
Iter: 41 loss: 0.0438343063
Iter: 42 loss: 0.0429608598
Iter: 43 loss: 0.0426656641
Iter: 44 loss: 0.0420474336
Iter: 45 loss: 0.0397430658
Iter: 46 loss: 0.0758000538
Iter: 47 loss: 0.0405353978
Iter: 48 loss: 0.0397403762
Iter: 49 loss: 0.0385846198
Iter: 50 loss: 0.0367010944
Iter: 51 loss: 0.0344639607
Iter: 52 loss: 0.0335496143
Iter: 53 loss: 0.0309638232
Iter: 54 loss: 0.0710964501
Iter: 55 loss: 0.0307944473
Iter: 56 loss: 0.0291825403
Iter: 57 loss: 0.0439393111
Iter: 58 loss: 0.0290407427
Iter: 59 loss: 0.0283544753
Iter: 60 loss: 0.0303945653
Iter: 61 loss: 0.0282391757
Iter: 62 loss: 0.0279476829
Iter: 63 loss: 0.0313697122
Iter: 64 loss: 0.0279250555
Iter: 65 loss: 0.0277832784
Iter: 66 loss: 0.0278838482
Iter: 67 loss: 0.0276878197
Iter: 68 loss: 0.0273328815
Iter: 69 loss: 0.0268214382
Iter: 70 loss: 0.0268162191
Iter: 71 loss: 0.0256240778
Iter: 72 loss: 0.0351809487
Iter: 73 loss: 0.0255150832
Iter: 74 loss: 0.025316447
Iter: 75 loss: 0.0295590982
Iter: 76 loss: 0.0253160521
Iter: 77 loss: 0.0249841064
Iter: 78 loss: 0.025109522
Iter: 79 loss: 0.0247545671
Iter: 80 loss: 0.0238083601
Iter: 81 loss: 0.0474131666
Iter: 82 loss: 0.0238008052
Iter: 83 loss: 0.0230596215
Iter: 84 loss: 0.0446828492
Iter: 85 loss: 0.0230458062
Iter: 86 loss: 0.022688847
Iter: 87 loss: 0.0292083956
Iter: 88 loss: 0.0226771645
Iter: 89 loss: 0.0224711448
Iter: 90 loss: 0.024375299
Iter: 91 loss: 0.0224591289
Iter: 92 loss: 0.0223302059
Iter: 93 loss: 0.0224178247
Iter: 94 loss: 0.0222400259
Iter: 95 loss: 0.0218283273
Iter: 96 loss: 0.0218179263
Iter: 97 loss: 0.0243707933
Iter: 98 loss: 0.0215205401
Iter: 99 loss: 0.0212284122
Iter: 100 loss: 0.0234648399
Iter: 101 loss: 0.0211903658
Iter: 102 loss: 0.0211483967
Iter: 103 loss: 0.0212910045
Iter: 104 loss: 0.0211383812
Iter: 105 loss: 0.0210652389
Iter: 106 loss: 0.0211253799
Iter: 107 loss: 0.021020649
Iter: 108 loss: 0.0208185334
Iter: 109 loss: 0.0205555297
Iter: 110 loss: 0.0205408409
Iter: 111 loss: 0.0201771501
Iter: 112 loss: 0.0201733224
Iter: 113 loss: 0.0198661182
Iter: 114 loss: 0.0197344199
Iter: 115 loss: 0.0203554519
Iter: 116 loss: 0.0197111703
Iter: 117 loss: 0.01956979
Iter: 118 loss: 0.0195915811
Iter: 119 loss: 0.019463215
Iter: 120 loss: 0.0192799494
Iter: 121 loss: 0.01935637
Iter: 122 loss: 0.0191352312
Iter: 123 loss: 0.0189716034
Iter: 124 loss: 0.0191849172
Iter: 125 loss: 0.0188809168
Iter: 126 loss: 0.0185637586
Iter: 127 loss: 0.0195340086
Iter: 128 loss: 0.0184582639
Iter: 129 loss: 0.0181542467
Iter: 130 loss: 0.0182156879
Iter: 131 loss: 0.0179038718
Iter: 132 loss: 0.0178378634
Iter: 133 loss: 0.0177827366
Iter: 134 loss: 0.0177491028
Iter: 135 loss: 0.0180501789
Iter: 136 loss: 0.0177479181
Iter: 137 loss: 0.0176481828
Iter: 138 loss: 0.0189174768
Iter: 139 loss: 0.0176476911
Iter: 140 loss: 0.0173910651
Iter: 141 loss: 0.0183350835
Iter: 142 loss: 0.0173342563
Iter: 143 loss: 0.0171241798
Iter: 144 loss: 0.0176303033
Iter: 145 loss: 0.0170390084
Iter: 146 loss: 0.0169083476
Iter: 147 loss: 0.01731533
Iter: 148 loss: 0.0168643445
Iter: 149 loss: 0.016765181
Iter: 150 loss: 0.0174465645
Iter: 151 loss: 0.0167505294
Iter: 152 loss: 0.0165897943
Iter: 153 loss: 0.0164883472
Iter: 154 loss: 0.0164221078
Iter: 155 loss: 0.0161885247
Iter: 156 loss: 0.016065143
Iter: 157 loss: 0.0159519967
Iter: 158 loss: 0.0158801116
Iter: 159 loss: 0.0159814153
Iter: 160 loss: 0.0158445872
Iter: 161 loss: 0.015650332
Iter: 162 loss: 0.0179767665
Iter: 163 loss: 0.0156496018
Iter: 164 loss: 0.0161406733
Iter: 165 loss: 0.0156141827
Iter: 166 loss: 0.0155699393
Iter: 167 loss: 0.0155259
Iter: 168 loss: 0.0155166509
Iter: 169 loss: 0.0152884433
Iter: 170 loss: 0.0159044415
Iter: 171 loss: 0.0152202342
Iter: 172 loss: 0.0156123387
Iter: 173 loss: 0.0151325231
Iter: 174 loss: 0.0150164748
Iter: 175 loss: 0.0148559436
Iter: 176 loss: 0.0148498314
Iter: 177 loss: 0.0146118822
Iter: 178 loss: 0.0154952249
Iter: 179 loss: 0.0145477029
Iter: 180 loss: 0.0145010175
Iter: 181 loss: 0.0147966985
Iter: 182 loss: 0.0144953
Iter: 183 loss: 0.014354391
Iter: 184 loss: 0.0148835909
Iter: 185 loss: 0.0143130366
Iter: 186 loss: 0.0141449515
Iter: 187 loss: 0.0146810524
Iter: 188 loss: 0.0140984012
Iter: 189 loss: 0.0137656359
Iter: 190 loss: 0.01726209
Iter: 191 loss: 0.0137524568
Iter: 192 loss: 0.0134918503
Iter: 193 loss: 0.0153706595
Iter: 194 loss: 0.0134646641
Iter: 195 loss: 0.0254627727
Iter: 196 loss: 0.0133911511
Iter: 197 loss: 0.0133537017
Iter: 198 loss: 0.0134072527
Iter: 199 loss: 0.0133345407
Iter: 200 loss: 0.0131768966
Iter: 201 loss: 0.0128773209
Iter: 202 loss: 0.0185858458
Iter: 203 loss: 0.0128752701
Iter: 204 loss: 0.0127778649
Iter: 205 loss: 0.0127625316
Iter: 206 loss: 0.0126531236
Iter: 207 loss: 0.0127107119
Iter: 208 loss: 0.0125847319
Iter: 209 loss: 0.0146877123
Iter: 210 loss: 0.0125291208
Iter: 211 loss: 0.0124011766
Iter: 212 loss: 0.0127603915
Iter: 213 loss: 0.0123557784
Iter: 214 loss: 0.0123200351
Iter: 215 loss: 0.0122487787
Iter: 216 loss: 0.0137925614
Iter: 217 loss: 0.0122480635
Iter: 218 loss: 0.0120765334
Iter: 219 loss: 0.0124821179
Iter: 220 loss: 0.0120228585
Iter: 221 loss: 0.0120456545
Iter: 222 loss: 0.011865695
Iter: 223 loss: 0.0117054395
Iter: 224 loss: 0.0115829501
Iter: 225 loss: 0.0115307942
Iter: 226 loss: 0.0113173686
Iter: 227 loss: 0.0131202638
Iter: 228 loss: 0.0113092139
Iter: 229 loss: 0.0112073924
Iter: 230 loss: 0.0117221149
Iter: 231 loss: 0.0111925649
Iter: 232 loss: 0.0111257955
Iter: 233 loss: 0.0111103039
Iter: 234 loss: 0.011065728
Iter: 235 loss: 0.0110239284
Iter: 236 loss: 0.0109976474
Iter: 237 loss: 0.0109340865
Iter: 238 loss: 0.0113091897
Iter: 239 loss: 0.0109272171
Iter: 240 loss: 0.0108892219
Iter: 241 loss: 0.0113353161
Iter: 242 loss: 0.0108886231
Iter: 243 loss: 0.0108547537
Iter: 244 loss: 0.0108664734
Iter: 245 loss: 0.0108313635
Iter: 246 loss: 0.0107610533
Iter: 247 loss: 0.0106181018
Iter: 248 loss: 0.0131395981
Iter: 249 loss: 0.0106155314
Iter: 250 loss: 0.010244105
Iter: 251 loss: 0.012251541
Iter: 252 loss: 0.0101911612
Iter: 253 loss: 0.0100171566
Iter: 254 loss: 0.00990999397
Iter: 255 loss: 0.00984737091
Iter: 256 loss: 0.00968155451
Iter: 257 loss: 0.0109876785
Iter: 258 loss: 0.00967066456
Iter: 259 loss: 0.00961475912
Iter: 260 loss: 0.0100264931
Iter: 261 loss: 0.00961068179
Iter: 262 loss: 0.00953869242
Iter: 263 loss: 0.00968741067
Iter: 264 loss: 0.00951470528
Iter: 265 loss: 0.00942412764
Iter: 266 loss: 0.00941281579
Iter: 267 loss: 0.00934684835
Iter: 268 loss: 0.00927444175
Iter: 269 loss: 0.00912832469
Iter: 270 loss: 0.01195997
Iter: 271 loss: 0.00912614353
Iter: 272 loss: 0.00901222602
Iter: 273 loss: 0.00920834485
Iter: 274 loss: 0.00895798765
Iter: 275 loss: 0.00890507549
Iter: 276 loss: 0.00958437566
Iter: 277 loss: 0.00890492834
Iter: 278 loss: 0.00888413377
Iter: 279 loss: 0.00888959877
Iter: 280 loss: 0.00886913761
Iter: 281 loss: 0.00867730938
Iter: 282 loss: 0.00934557803
Iter: 283 loss: 0.00861761905
Iter: 284 loss: 0.00842494238
Iter: 285 loss: 0.00841870066
Iter: 286 loss: 0.00840555225
Iter: 287 loss: 0.008359598
Iter: 288 loss: 0.0083307242
Iter: 289 loss: 0.00836600084
Iter: 290 loss: 0.00831620116
Iter: 291 loss: 0.00829668809
Iter: 292 loss: 0.00829268619
Iter: 293 loss: 0.00827964395
Iter: 294 loss: 0.00823687389
Iter: 295 loss: 0.00823906064
Iter: 296 loss: 0.00820304547
Iter: 297 loss: 0.00814090297
Iter: 298 loss: 0.00816365
Iter: 299 loss: 0.00809676107
Iter: 300 loss: 0.00805524364
Iter: 301 loss: 0.00806948729
Iter: 302 loss: 0.00802511722
Iter: 303 loss: 0.00794321857
Iter: 304 loss: 0.00851641688
Iter: 305 loss: 0.00793597661
Iter: 306 loss: 0.0124643007
Iter: 307 loss: 0.00791872293
Iter: 308 loss: 0.0078731142
Iter: 309 loss: 0.00799522921
Iter: 310 loss: 0.00785868801
Iter: 311 loss: 0.00778780971
Iter: 312 loss: 0.0084369313
Iter: 313 loss: 0.00778616127
Iter: 314 loss: 0.00773488265
Iter: 315 loss: 0.0076076719
Iter: 316 loss: 0.00922477338
Iter: 317 loss: 0.00759343058
Iter: 318 loss: 0.00748651102
Iter: 319 loss: 0.00775285624
Iter: 320 loss: 0.00745132659
Iter: 321 loss: 0.00743071223
Iter: 322 loss: 0.00743061304
Iter: 323 loss: 0.00742079597
Iter: 324 loss: 0.00742816273
Iter: 325 loss: 0.00741469581
Iter: 326 loss: 0.00737584662
Iter: 327 loss: 0.00733605772
Iter: 328 loss: 0.0073285317
Iter: 329 loss: 0.00727484748
Iter: 330 loss: 0.0075529553
Iter: 331 loss: 0.00726498663
Iter: 332 loss: 0.00717916619
Iter: 333 loss: 0.00776999723
Iter: 334 loss: 0.00717026414
Iter: 335 loss: 0.00699078944
Iter: 336 loss: 0.00818579271
Iter: 337 loss: 0.00696890615
Iter: 338 loss: 0.006939549
Iter: 339 loss: 0.00691812579
Iter: 340 loss: 0.00685633533
Iter: 341 loss: 0.00709782634
Iter: 342 loss: 0.0068409387
Iter: 343 loss: 0.00679725083
Iter: 344 loss: 0.00676442962
Iter: 345 loss: 0.00675056223
Iter: 346 loss: 0.00669066701
Iter: 347 loss: 0.00687342836
Iter: 348 loss: 0.00667202752
Iter: 349 loss: 0.00662947027
Iter: 350 loss: 0.00688434811
Iter: 351 loss: 0.00662419433
Iter: 352 loss: 0.00666734111
Iter: 353 loss: 0.00661129365
Iter: 354 loss: 0.00660210848
Iter: 355 loss: 0.00658400171
Iter: 356 loss: 0.0069801244
Iter: 357 loss: 0.00658390205
Iter: 358 loss: 0.00655749952
Iter: 359 loss: 0.00653421599
Iter: 360 loss: 0.00652716029
Iter: 361 loss: 0.0064294003
Iter: 362 loss: 0.00722814491
Iter: 363 loss: 0.00642243214
Iter: 364 loss: 0.00638556
Iter: 365 loss: 0.00634376612
Iter: 366 loss: 0.00629270822
Iter: 367 loss: 0.00633373857
Iter: 368 loss: 0.00626104791
Iter: 369 loss: 0.00620597
Iter: 370 loss: 0.00701251533
Iter: 371 loss: 0.00620594714
Iter: 372 loss: 0.00629956275
Iter: 373 loss: 0.00617286749
Iter: 374 loss: 0.0061250031
Iter: 375 loss: 0.00613123365
Iter: 376 loss: 0.00608805381
Iter: 377 loss: 0.00599869248
Iter: 378 loss: 0.00589599367
Iter: 379 loss: 0.00588420313
Iter: 380 loss: 0.00586042041
Iter: 381 loss: 0.00585722458
Iter: 382 loss: 0.00584944803
Iter: 383 loss: 0.00592034776
Iter: 384 loss: 0.00584902149
Iter: 385 loss: 0.005838932
Iter: 386 loss: 0.00587611599
Iter: 387 loss: 0.00583661161
Iter: 388 loss: 0.00581598841
Iter: 389 loss: 0.00578102469
Iter: 390 loss: 0.0057809595
Iter: 391 loss: 0.00573539734
Iter: 392 loss: 0.00586590078
Iter: 393 loss: 0.00572159607
Iter: 394 loss: 0.00565441418
Iter: 395 loss: 0.00583082624
Iter: 396 loss: 0.00563110458
Iter: 397 loss: 0.00556421606
Iter: 398 loss: 0.00615957566
Iter: 399 loss: 0.00555989379
Iter: 400 loss: 0.00552789122
Iter: 401 loss: 0.00553257717
Iter: 402 loss: 0.00550308218
Iter: 403 loss: 0.00546122622
Iter: 404 loss: 0.00574209262
Iter: 405 loss: 0.0054576369
Iter: 406 loss: 0.00538935186
Iter: 407 loss: 0.00568266865
Iter: 408 loss: 0.00537425419
Iter: 409 loss: 0.0053073084
Iter: 410 loss: 0.00531714503
Iter: 411 loss: 0.0052559874
Iter: 412 loss: 0.00516762119
Iter: 413 loss: 0.00538291456
Iter: 414 loss: 0.00513402512
Iter: 415 loss: 0.00520569505
Iter: 416 loss: 0.00512317475
Iter: 417 loss: 0.00510715833
Iter: 418 loss: 0.00510694832
Iter: 419 loss: 0.00510107
Iter: 420 loss: 0.00508061191
Iter: 421 loss: 0.00505121471
Iter: 422 loss: 0.00504728174
Iter: 423 loss: 0.00501021184
Iter: 424 loss: 0.00500678
Iter: 425 loss: 0.00497830845
Iter: 426 loss: 0.00497685745
Iter: 427 loss: 0.00496368343
Iter: 428 loss: 0.00495081581
Iter: 429 loss: 0.00494806468
Iter: 430 loss: 0.00491339061
Iter: 431 loss: 0.00487925205
Iter: 432 loss: 0.00487178564
Iter: 433 loss: 0.00481834542
Iter: 434 loss: 0.00503529608
Iter: 435 loss: 0.00480739819
Iter: 436 loss: 0.00479863165
Iter: 437 loss: 0.00478259148
Iter: 438 loss: 0.0047655357
Iter: 439 loss: 0.00475527858
Iter: 440 loss: 0.00474840635
Iter: 441 loss: 0.00473026279
Iter: 442 loss: 0.00472677499
Iter: 443 loss: 0.00471462635
Iter: 444 loss: 0.00469818385
Iter: 445 loss: 0.0047040903
Iter: 446 loss: 0.00468663406
Iter: 447 loss: 0.00466244062
Iter: 448 loss: 0.00475872261
Iter: 449 loss: 0.00465718471
Iter: 450 loss: 0.00463726558
Iter: 451 loss: 0.0046591456
Iter: 452 loss: 0.00462625083
Iter: 453 loss: 0.0046055126
Iter: 454 loss: 0.00459788367
Iter: 455 loss: 0.00458614808
Iter: 456 loss: 0.00455896277
Iter: 457 loss: 0.0047190832
Iter: 458 loss: 0.00455495436
Iter: 459 loss: 0.00450563803
Iter: 460 loss: 0.00463692518
Iter: 461 loss: 0.00449051242
Iter: 462 loss: 0.0044692615
Iter: 463 loss: 0.00449425634
Iter: 464 loss: 0.00445798412
Iter: 465 loss: 0.00444372231
Iter: 466 loss: 0.00442029256
Iter: 467 loss: 0.00442016777
Iter: 468 loss: 0.00441032462
Iter: 469 loss: 0.0044138818
Iter: 470 loss: 0.0044035255
Iter: 471 loss: 0.00439682556
Iter: 472 loss: 0.00439500622
Iter: 473 loss: 0.00439089909
Iter: 474 loss: 0.00444355793
Iter: 475 loss: 0.00438015163
Iter: 476 loss: 0.00435813842
Iter: 477 loss: 0.00435686205
Iter: 478 loss: 0.00434089592
Iter: 479 loss: 0.00449843612
Iter: 480 loss: 0.00434027752
Iter: 481 loss: 0.00433083577
Iter: 482 loss: 0.00435864553
Iter: 483 loss: 0.00432785042
Iter: 484 loss: 0.00431742147
Iter: 485 loss: 0.00430787215
Iter: 486 loss: 0.00429498171
Iter: 487 loss: 0.00426611584
Iter: 488 loss: 0.00469670258
Iter: 489 loss: 0.00426461641
Iter: 490 loss: 0.00424756715
Iter: 491 loss: 0.00427948125
Iter: 492 loss: 0.00424040062
Iter: 493 loss: 0.00423516612
Iter: 494 loss: 0.00422175415
Iter: 495 loss: 0.00433631521
Iter: 496 loss: 0.00421950128
Iter: 497 loss: 0.00420507137
Iter: 498 loss: 0.0042108437
Iter: 499 loss: 0.00419500936
Iter: 500 loss: 0.00419030432
Iter: 501 loss: 0.0042541055
Iter: 502 loss: 0.00419027545
Iter: 503 loss: 0.00417978
Iter: 504 loss: 0.0041722781
Iter: 505 loss: 0.00416861242
Iter: 506 loss: 0.00416110922
Iter: 507 loss: 0.00414054468
Iter: 508 loss: 0.00411749445
Iter: 509 loss: 0.00416253507
Iter: 510 loss: 0.00410822
Iter: 511 loss: 0.00409537647
Iter: 512 loss: 0.0041313679
Iter: 513 loss: 0.00409119297
Iter: 514 loss: 0.00408769026
Iter: 515 loss: 0.00408385275
Iter: 516 loss: 0.00407937774
Iter: 517 loss: 0.00407213438
Iter: 518 loss: 0.004072126
Iter: 519 loss: 0.00405976735
Iter: 520 loss: 0.00402785838
Iter: 521 loss: 0.00430829
Iter: 522 loss: 0.0040224
Iter: 523 loss: 0.00401959103
Iter: 524 loss: 0.00398280798
Iter: 525 loss: 0.00394865312
Iter: 526 loss: 0.00415891269
Iter: 527 loss: 0.00394491386
Iter: 528 loss: 0.00393528026
Iter: 529 loss: 0.00393562205
Iter: 530 loss: 0.0039277738
Iter: 531 loss: 0.00391249917
Iter: 532 loss: 0.00387814338
Iter: 533 loss: 0.00439503137
Iter: 534 loss: 0.00387633406
Iter: 535 loss: 0.00385353109
Iter: 536 loss: 0.00383030856
Iter: 537 loss: 0.00382597116
Iter: 538 loss: 0.00380689185
Iter: 539 loss: 0.0038211334
Iter: 540 loss: 0.00379530131
Iter: 541 loss: 0.0037877569
Iter: 542 loss: 0.00377655984
Iter: 543 loss: 0.0037763142
Iter: 544 loss: 0.00375707471
Iter: 545 loss: 0.00388258137
Iter: 546 loss: 0.00375487725
Iter: 547 loss: 0.00374537078
Iter: 548 loss: 0.00373897143
Iter: 549 loss: 0.00372651336
Iter: 550 loss: 0.00371260988
Iter: 551 loss: 0.00371074839
Iter: 552 loss: 0.00371203688
Iter: 553 loss: 0.00370262261
Iter: 554 loss: 0.00369820697
Iter: 555 loss: 0.00370173017
Iter: 556 loss: 0.00369554479
Iter: 557 loss: 0.00367521308
Iter: 558 loss: 0.00387534313
Iter: 559 loss: 0.00367451878
Iter: 560 loss: 0.00366183114
Iter: 561 loss: 0.00366150495
Iter: 562 loss: 0.0036518
Iter: 563 loss: 0.00363335642
Iter: 564 loss: 0.00363284862
Iter: 565 loss: 0.0036288416
Iter: 566 loss: 0.00362278498
Iter: 567 loss: 0.00362265436
Iter: 568 loss: 0.00361317187
Iter: 569 loss: 0.0036025641
Iter: 570 loss: 0.00360108027
Iter: 571 loss: 0.00359504
Iter: 572 loss: 0.00360234478
Iter: 573 loss: 0.00359190395
Iter: 574 loss: 0.00356823346
Iter: 575 loss: 0.00369392708
Iter: 576 loss: 0.00356451888
Iter: 577 loss: 0.00356283365
Iter: 578 loss: 0.00354867382
Iter: 579 loss: 0.00352983642
Iter: 580 loss: 0.00360872201
Iter: 581 loss: 0.00352585665
Iter: 582 loss: 0.00350250234
Iter: 583 loss: 0.00346847484
Iter: 584 loss: 0.0034673363
Iter: 585 loss: 0.00351210427
Iter: 586 loss: 0.00345267868
Iter: 587 loss: 0.00345058669
Iter: 588 loss: 0.0034521753
Iter: 589 loss: 0.00344932731
Iter: 590 loss: 0.00343247596
Iter: 591 loss: 0.00342388474
Iter: 592 loss: 0.00341594219
Iter: 593 loss: 0.00345649477
Iter: 594 loss: 0.00341141876
Iter: 595 loss: 0.0034070313
Iter: 596 loss: 0.00339624914
Iter: 597 loss: 0.00351343816
Iter: 598 loss: 0.00339496555
Iter: 599 loss: 0.00338377012
Iter: 600 loss: 0.00342155737
Iter: 601 loss: 0.00338078104
Iter: 602 loss: 0.00339147705
Iter: 603 loss: 0.00336126168
Iter: 604 loss: 0.00334653072
Iter: 605 loss: 0.00335634523
Iter: 606 loss: 0.0033373402
Iter: 607 loss: 0.00331752468
Iter: 608 loss: 0.00333739258
Iter: 609 loss: 0.00330635975
Iter: 610 loss: 0.00328671909
Iter: 611 loss: 0.0033778369
Iter: 612 loss: 0.0032831342
Iter: 613 loss: 0.00326222926
Iter: 614 loss: 0.00323797483
Iter: 615 loss: 0.00323512033
Iter: 616 loss: 0.00326415
Iter: 617 loss: 0.00323077803
Iter: 618 loss: 0.00322822761
Iter: 619 loss: 0.00323051773
Iter: 620 loss: 0.00322675286
Iter: 621 loss: 0.00322221196
Iter: 622 loss: 0.00321462238
Iter: 623 loss: 0.00321460329
Iter: 624 loss: 0.00320846075
Iter: 625 loss: 0.00319266925
Iter: 626 loss: 0.00333178695
Iter: 627 loss: 0.00319001731
Iter: 628 loss: 0.00319048413
Iter: 629 loss: 0.00317970151
Iter: 630 loss: 0.00317490241
Iter: 631 loss: 0.00317812664
Iter: 632 loss: 0.00317186373
Iter: 633 loss: 0.00315064657
Iter: 634 loss: 0.00327675766
Iter: 635 loss: 0.00314804399
Iter: 636 loss: 0.00313391117
Iter: 637 loss: 0.0033082352
Iter: 638 loss: 0.00313371
Iter: 639 loss: 0.00312236114
Iter: 640 loss: 0.00309981988
Iter: 641 loss: 0.00352757541
Iter: 642 loss: 0.00309955189
Iter: 643 loss: 0.00308219902
Iter: 644 loss: 0.00310917897
Iter: 645 loss: 0.00307406788
Iter: 646 loss: 0.00306038326
Iter: 647 loss: 0.00308026792
Iter: 648 loss: 0.00305382418
Iter: 649 loss: 0.00304874382
Iter: 650 loss: 0.00307329441
Iter: 651 loss: 0.00304785324
Iter: 652 loss: 0.0030444474
Iter: 653 loss: 0.00304184435
Iter: 654 loss: 0.00303951208
Iter: 655 loss: 0.00304063223
Iter: 656 loss: 0.00303797144
Iter: 657 loss: 0.0030317544
Iter: 658 loss: 0.00302535715
Iter: 659 loss: 0.00302415085
Iter: 660 loss: 0.00302833621
Iter: 661 loss: 0.00301854569
Iter: 662 loss: 0.0030170416
Iter: 663 loss: 0.00301602017
Iter: 664 loss: 0.00301545765
Iter: 665 loss: 0.00300290342
Iter: 666 loss: 0.00297343312
Iter: 667 loss: 0.00331504783
Iter: 668 loss: 0.00297090947
Iter: 669 loss: 0.00294770859
Iter: 670 loss: 0.00324562937
Iter: 671 loss: 0.00294757122
Iter: 672 loss: 0.00293580862
Iter: 673 loss: 0.00293456577
Iter: 674 loss: 0.00292785023
Iter: 675 loss: 0.00290975836
Iter: 676 loss: 0.00303793349
Iter: 677 loss: 0.002905556
Iter: 678 loss: 0.00288149458
Iter: 679 loss: 0.00292245625
Iter: 680 loss: 0.00287057972
Iter: 681 loss: 0.00286718691
Iter: 682 loss: 0.00286516175
Iter: 683 loss: 0.00286403834
Iter: 684 loss: 0.00286371144
Iter: 685 loss: 0.00286240736
Iter: 686 loss: 0.0028590227
Iter: 687 loss: 0.00288567925
Iter: 688 loss: 0.00285838684
Iter: 689 loss: 0.00285008829
Iter: 690 loss: 0.00284423423
Iter: 691 loss: 0.00284134271
Iter: 692 loss: 0.00297293114
Iter: 693 loss: 0.00283917389
Iter: 694 loss: 0.0028368393
Iter: 695 loss: 0.00283084926
Iter: 696 loss: 0.00288092019
Iter: 697 loss: 0.0028297964
Iter: 698 loss: 0.00281573
Iter: 699 loss: 0.00282428227
Iter: 700 loss: 0.00280660857
Iter: 701 loss: 0.00279438309
Iter: 702 loss: 0.00280991662
Iter: 703 loss: 0.00278790039
Iter: 704 loss: 0.00277626398
Iter: 705 loss: 0.00281033898
Iter: 706 loss: 0.00277278246
Iter: 707 loss: 0.00275755767
Iter: 708 loss: 0.0027476321
Iter: 709 loss: 0.00274179038
Iter: 710 loss: 0.00271582138
Iter: 711 loss: 0.0028408682
Iter: 712 loss: 0.00271104858
Iter: 713 loss: 0.00270165317
Iter: 714 loss: 0.00278988318
Iter: 715 loss: 0.00270134117
Iter: 716 loss: 0.00269970228
Iter: 717 loss: 0.00269950135
Iter: 718 loss: 0.00269688433
Iter: 719 loss: 0.00269006705
Iter: 720 loss: 0.00274609216
Iter: 721 loss: 0.00268877065
Iter: 722 loss: 0.00268106512
Iter: 723 loss: 0.00266897399
Iter: 724 loss: 0.00266884686
Iter: 725 loss: 0.00266776094
Iter: 726 loss: 0.00266203377
Iter: 727 loss: 0.00265611475
Iter: 728 loss: 0.00268309284
Iter: 729 loss: 0.0026549187
Iter: 730 loss: 0.00264747557
Iter: 731 loss: 0.00262922375
Iter: 732 loss: 0.00280677737
Iter: 733 loss: 0.00262692384
Iter: 734 loss: 0.00260726665
Iter: 735 loss: 0.00290432526
Iter: 736 loss: 0.00260722358
Iter: 737 loss: 0.00258681038
Iter: 738 loss: 0.002616663
Iter: 739 loss: 0.00257650809
Iter: 740 loss: 0.00256371265
Iter: 741 loss: 0.00256097922
Iter: 742 loss: 0.00255256332
Iter: 743 loss: 0.00254382612
Iter: 744 loss: 0.00264225621
Iter: 745 loss: 0.00254367758
Iter: 746 loss: 0.00259312801
Iter: 747 loss: 0.00254038349
Iter: 748 loss: 0.00253923517
Iter: 749 loss: 0.00253648311
Iter: 750 loss: 0.00256632501
Iter: 751 loss: 0.00253619906
Iter: 752 loss: 0.00254031271
Iter: 753 loss: 0.00253292499
Iter: 754 loss: 0.00252346601
Iter: 755 loss: 0.00249559339
Iter: 756 loss: 0.00260014948
Iter: 757 loss: 0.0024833912
Iter: 758 loss: 0.00248123379
Iter: 759 loss: 0.00248034438
Iter: 760 loss: 0.00247718487
Iter: 761 loss: 0.00247953413
Iter: 762 loss: 0.00247522676
Iter: 763 loss: 0.00246668654
Iter: 764 loss: 0.00244290056
Iter: 765 loss: 0.002576
Iter: 766 loss: 0.00243575475
Iter: 767 loss: 0.00242182
Iter: 768 loss: 0.00240821438
Iter: 769 loss: 0.00240521505
Iter: 770 loss: 0.00239444571
Iter: 771 loss: 0.00241797324
Iter: 772 loss: 0.00239014393
Iter: 773 loss: 0.00238516741
Iter: 774 loss: 0.00237602228
Iter: 775 loss: 0.00257710647
Iter: 776 loss: 0.002376016
Iter: 777 loss: 0.00236870977
Iter: 778 loss: 0.00236154161
Iter: 779 loss: 0.00235645962
Iter: 780 loss: 0.00235639606
Iter: 781 loss: 0.00235281466
Iter: 782 loss: 0.00234726723
Iter: 783 loss: 0.00234720088
Iter: 784 loss: 0.00234684069
Iter: 785 loss: 0.0023439331
Iter: 786 loss: 0.00233996357
Iter: 787 loss: 0.00233213091
Iter: 788 loss: 0.00247922679
Iter: 789 loss: 0.00233202428
Iter: 790 loss: 0.0023327
Iter: 791 loss: 0.00232464541
Iter: 792 loss: 0.00231651263
Iter: 793 loss: 0.00231445348
Iter: 794 loss: 0.00230933586
Iter: 795 loss: 0.00228259689
Iter: 796 loss: 0.00244706916
Iter: 797 loss: 0.00227935077
Iter: 798 loss: 0.00227095908
Iter: 799 loss: 0.00232795137
Iter: 800 loss: 0.00227020518
Iter: 801 loss: 0.00233848533
Iter: 802 loss: 0.0022679558
Iter: 803 loss: 0.00226630596
Iter: 804 loss: 0.00226202072
Iter: 805 loss: 0.00229656696
Iter: 806 loss: 0.00226126285
Iter: 807 loss: 0.00225101714
Iter: 808 loss: 0.00224239333
Iter: 809 loss: 0.00223958818
Iter: 810 loss: 0.00223540561
Iter: 811 loss: 0.00223516556
Iter: 812 loss: 0.00223147543
Iter: 813 loss: 0.00224588905
Iter: 814 loss: 0.00223061559
Iter: 815 loss: 0.00223079557
Iter: 816 loss: 0.0022283732
Iter: 817 loss: 0.0022271683
Iter: 818 loss: 0.0022251131
Iter: 819 loss: 0.00222510379
Iter: 820 loss: 0.00222059339
Iter: 821 loss: 0.00220943498
Iter: 822 loss: 0.00232862914
Iter: 823 loss: 0.00220804149
Iter: 824 loss: 0.00220273179
Iter: 825 loss: 0.0022027
Iter: 826 loss: 0.0021988824
Iter: 827 loss: 0.00219304045
Iter: 828 loss: 0.00219294056
Iter: 829 loss: 0.00218375074
Iter: 830 loss: 0.00219562254
Iter: 831 loss: 0.00217910274
Iter: 832 loss: 0.00217027077
Iter: 833 loss: 0.00216437248
Iter: 834 loss: 0.00216106419
Iter: 835 loss: 0.00214718538
Iter: 836 loss: 0.00231886748
Iter: 837 loss: 0.00214696536
Iter: 838 loss: 0.00214423658
Iter: 839 loss: 0.00213819346
Iter: 840 loss: 0.00223312411
Iter: 841 loss: 0.00213791244
Iter: 842 loss: 0.00212676823
Iter: 843 loss: 0.00213167816
Iter: 844 loss: 0.00211921497
Iter: 845 loss: 0.00211244915
Iter: 846 loss: 0.00214465638
Iter: 847 loss: 0.00211120653
Iter: 848 loss: 0.00216606609
Iter: 849 loss: 0.0021097525
Iter: 850 loss: 0.00210800814
Iter: 851 loss: 0.00210919278
Iter: 852 loss: 0.00210692058
Iter: 853 loss: 0.00210423348
Iter: 854 loss: 0.00209799502
Iter: 855 loss: 0.00218212092
Iter: 856 loss: 0.00209754845
Iter: 857 loss: 0.00209408626
Iter: 858 loss: 0.00209389115
Iter: 859 loss: 0.00209099543
Iter: 860 loss: 0.00208541797
Iter: 861 loss: 0.00220643962
Iter: 862 loss: 0.00208539655
Iter: 863 loss: 0.00207811967
Iter: 864 loss: 0.00206841924
Iter: 865 loss: 0.00206789048
Iter: 866 loss: 0.00206774566
Iter: 867 loss: 0.00206460082
Iter: 868 loss: 0.00206229836
Iter: 869 loss: 0.00209490256
Iter: 870 loss: 0.00206229556
Iter: 871 loss: 0.00206103642
Iter: 872 loss: 0.00205788226
Iter: 873 loss: 0.00208702451
Iter: 874 loss: 0.00205742382
Iter: 875 loss: 0.0020544643
Iter: 876 loss: 0.00204814761
Iter: 877 loss: 0.0021509931
Iter: 878 loss: 0.0020479511
Iter: 879 loss: 0.00204410683
Iter: 880 loss: 0.00204923912
Iter: 881 loss: 0.00204219343
Iter: 882 loss: 0.00204075105
Iter: 883 loss: 0.00203727209
Iter: 884 loss: 0.00207488122
Iter: 885 loss: 0.00203690073
Iter: 886 loss: 0.00205400889
Iter: 887 loss: 0.00203477684
Iter: 888 loss: 0.00203168043
Iter: 889 loss: 0.00203279802
Iter: 890 loss: 0.00202948926
Iter: 891 loss: 0.00202732673
Iter: 892 loss: 0.00202635699
Iter: 893 loss: 0.00202234741
Iter: 894 loss: 0.00201825402
Iter: 895 loss: 0.00201746984
Iter: 896 loss: 0.00201392407
Iter: 897 loss: 0.00201841467
Iter: 898 loss: 0.00201209402
Iter: 899 loss: 0.00201228075
Iter: 900 loss: 0.00200852612
Iter: 901 loss: 0.00200284622
Iter: 902 loss: 0.00198926916
Iter: 903 loss: 0.0021383469
Iter: 904 loss: 0.00198795693
Iter: 905 loss: 0.0019804379
Iter: 906 loss: 0.00206142524
Iter: 907 loss: 0.00198027818
Iter: 908 loss: 0.00197763043
Iter: 909 loss: 0.00197722018
Iter: 910 loss: 0.00197527185
Iter: 911 loss: 0.00197854755
Iter: 912 loss: 0.001974402
Iter: 913 loss: 0.00197189115
Iter: 914 loss: 0.00196342124
Iter: 915 loss: 0.00195866032
Iter: 916 loss: 0.00195297506
Iter: 917 loss: 0.00201485818
Iter: 918 loss: 0.00195156829
Iter: 919 loss: 0.00194958586
Iter: 920 loss: 0.00195621769
Iter: 921 loss: 0.00194906711
Iter: 922 loss: 0.0019500471
Iter: 923 loss: 0.00194756093
Iter: 924 loss: 0.00194604928
Iter: 925 loss: 0.00194555987
Iter: 926 loss: 0.001944697
Iter: 927 loss: 0.0019429808
Iter: 928 loss: 0.00193762896
Iter: 929 loss: 0.00194692879
Iter: 930 loss: 0.00193402881
Iter: 931 loss: 0.00192823086
Iter: 932 loss: 0.00199379586
Iter: 933 loss: 0.00192809582
Iter: 934 loss: 0.00192670524
Iter: 935 loss: 0.0019239129
Iter: 936 loss: 0.0019231328
Iter: 937 loss: 0.00192077865
Iter: 938 loss: 0.00192743517
Iter: 939 loss: 0.0019195223
Iter: 940 loss: 0.00191483437
Iter: 941 loss: 0.00192651164
Iter: 942 loss: 0.00191322772
Iter: 943 loss: 0.0019303367
Iter: 944 loss: 0.00191050232
Iter: 945 loss: 0.00190920813
Iter: 946 loss: 0.00190557819
Iter: 947 loss: 0.00192442606
Iter: 948 loss: 0.00190443161
Iter: 949 loss: 0.00192457333
Iter: 950 loss: 0.00190172042
Iter: 951 loss: 0.00189929619
Iter: 952 loss: 0.0019077973
Iter: 953 loss: 0.00189865439
Iter: 954 loss: 0.00189544202
Iter: 955 loss: 0.00189074653
Iter: 956 loss: 0.00189060031
Iter: 957 loss: 0.00188717432
Iter: 958 loss: 0.00191930681
Iter: 959 loss: 0.00188703358
Iter: 960 loss: 0.00188549096
Iter: 961 loss: 0.00188085495
Iter: 962 loss: 0.00189342501
Iter: 963 loss: 0.00187836634
Iter: 964 loss: 0.00187483244
Iter: 965 loss: 0.00186901633
Iter: 966 loss: 0.0018689807
Iter: 967 loss: 0.00186260021
Iter: 968 loss: 0.00193266151
Iter: 969 loss: 0.00186247739
Iter: 970 loss: 0.0018598251
Iter: 971 loss: 0.00186453247
Iter: 972 loss: 0.00185866933
Iter: 973 loss: 0.00185570726
Iter: 974 loss: 0.00185480132
Iter: 975 loss: 0.00185302098
Iter: 976 loss: 0.00184817438
Iter: 977 loss: 0.00185862498
Iter: 978 loss: 0.00184632186
Iter: 979 loss: 0.00184372789
Iter: 980 loss: 0.00184251112
Iter: 981 loss: 0.00184031215
Iter: 982 loss: 0.00183900155
Iter: 983 loss: 0.00183809863
Iter: 984 loss: 0.00183167437
Iter: 985 loss: 0.00182508398
Iter: 986 loss: 0.00182383601
Iter: 987 loss: 0.00182002946
Iter: 988 loss: 0.0018307541
Iter: 989 loss: 0.00181882433
Iter: 990 loss: 0.00182499806
Iter: 991 loss: 0.00181737426
Iter: 992 loss: 0.00181603793
Iter: 993 loss: 0.00181799429
Iter: 994 loss: 0.00181539916
Iter: 995 loss: 0.00181340543
Iter: 996 loss: 0.00181189761
Iter: 997 loss: 0.00181126618
Iter: 998 loss: 0.00180461
Iter: 999 loss: 0.00187762897
Iter: 1000 loss: 0.00180449872
Iter: 1001 loss: 0.00179804093
Iter: 1002 loss: 0.00179259328
Iter: 1003 loss: 0.00179080258
Iter: 1004 loss: 0.00178812549
Iter: 1005 loss: 0.00178504083
Iter: 1006 loss: 0.0017846555
Iter: 1007 loss: 0.001781506
Iter: 1008 loss: 0.00178047945
Iter: 1009 loss: 0.0017786657
Iter: 1010 loss: 0.0017766424
Iter: 1011 loss: 0.00178184919
Iter: 1012 loss: 0.00177594414
Iter: 1013 loss: 0.00177476974
Iter: 1014 loss: 0.00177453179
Iter: 1015 loss: 0.00177283771
Iter: 1016 loss: 0.0017720483
Iter: 1017 loss: 0.00177121419
Iter: 1018 loss: 0.00176936598
Iter: 1019 loss: 0.00176996505
Iter: 1020 loss: 0.001768052
Iter: 1021 loss: 0.00176634174
Iter: 1022 loss: 0.00177568966
Iter: 1023 loss: 0.00176607736
Iter: 1024 loss: 0.00176393485
Iter: 1025 loss: 0.00176971115
Iter: 1026 loss: 0.00176320074
Iter: 1027 loss: 0.00176118722
Iter: 1028 loss: 0.00175583363
Iter: 1029 loss: 0.00179526373
Iter: 1030 loss: 0.00175472838
Iter: 1031 loss: 0.0017484799
Iter: 1032 loss: 0.00180792133
Iter: 1033 loss: 0.00174826989
Iter: 1034 loss: 0.00174525054
Iter: 1035 loss: 0.00174128276
Iter: 1036 loss: 0.00174103526
Iter: 1037 loss: 0.00173576584
Iter: 1038 loss: 0.00174686837
Iter: 1039 loss: 0.00173370028
Iter: 1040 loss: 0.00173082226
Iter: 1041 loss: 0.00173075125
Iter: 1042 loss: 0.00172839884
Iter: 1043 loss: 0.00172748
Iter: 1044 loss: 0.001726193
Iter: 1045 loss: 0.00172425341
Iter: 1046 loss: 0.00172376377
Iter: 1047 loss: 0.00172227249
Iter: 1048 loss: 0.001720072
Iter: 1049 loss: 0.00172001601
Iter: 1050 loss: 0.00171814207
Iter: 1051 loss: 0.00171885185
Iter: 1052 loss: 0.00171685149
Iter: 1053 loss: 0.00171556161
Iter: 1054 loss: 0.00171722728
Iter: 1055 loss: 0.00171489909
Iter: 1056 loss: 0.00171344844
Iter: 1057 loss: 0.00172811793
Iter: 1058 loss: 0.00171340513
Iter: 1059 loss: 0.0017126801
Iter: 1060 loss: 0.00171083095
Iter: 1061 loss: 0.00172596448
Iter: 1062 loss: 0.00171050034
Iter: 1063 loss: 0.00170855725
Iter: 1064 loss: 0.00173860393
Iter: 1065 loss: 0.00170855969
Iter: 1066 loss: 0.00170648494
Iter: 1067 loss: 0.00171592645
Iter: 1068 loss: 0.0017060861
Iter: 1069 loss: 0.00170195918
Iter: 1070 loss: 0.00168972113
Iter: 1071 loss: 0.00173335569
Iter: 1072 loss: 0.00168409431
Iter: 1073 loss: 0.00167617621
Iter: 1074 loss: 0.00167566282
Iter: 1075 loss: 0.001670136
Iter: 1076 loss: 0.0016861147
Iter: 1077 loss: 0.00166842144
Iter: 1078 loss: 0.00166247215
Iter: 1079 loss: 0.00171887549
Iter: 1080 loss: 0.00166223524
Iter: 1081 loss: 0.00165949401
Iter: 1082 loss: 0.0016623144
Iter: 1083 loss: 0.00165796978
Iter: 1084 loss: 0.0016532056
Iter: 1085 loss: 0.00169592036
Iter: 1086 loss: 0.00165300863
Iter: 1087 loss: 0.00165234646
Iter: 1088 loss: 0.00165216648
Iter: 1089 loss: 0.0016515553
Iter: 1090 loss: 0.00165126636
Iter: 1091 loss: 0.00165097299
Iter: 1092 loss: 0.00165022328
Iter: 1093 loss: 0.00164863328
Iter: 1094 loss: 0.00167501124
Iter: 1095 loss: 0.00164858135
Iter: 1096 loss: 0.00164603582
Iter: 1097 loss: 0.00164702791
Iter: 1098 loss: 0.00164425373
Iter: 1099 loss: 0.00164085859
Iter: 1100 loss: 0.00164522009
Iter: 1101 loss: 0.00163910352
Iter: 1102 loss: 0.0016362915
Iter: 1103 loss: 0.00167891034
Iter: 1104 loss: 0.00163628673
Iter: 1105 loss: 0.00163318426
Iter: 1106 loss: 0.00162987807
Iter: 1107 loss: 0.00162932847
Iter: 1108 loss: 0.00162794301
Iter: 1109 loss: 0.00162783137
Iter: 1110 loss: 0.00162684917
Iter: 1111 loss: 0.00163713016
Iter: 1112 loss: 0.00162681576
Iter: 1113 loss: 0.00162614428
Iter: 1114 loss: 0.00162447616
Iter: 1115 loss: 0.00164052483
Iter: 1116 loss: 0.00162426359
Iter: 1117 loss: 0.00162090268
Iter: 1118 loss: 0.00163836055
Iter: 1119 loss: 0.00162034843
Iter: 1120 loss: 0.00161993
Iter: 1121 loss: 0.00161938404
Iter: 1122 loss: 0.00161823933
Iter: 1123 loss: 0.0016238034
Iter: 1124 loss: 0.00161804794
Iter: 1125 loss: 0.00161726156
Iter: 1126 loss: 0.00161518576
Iter: 1127 loss: 0.00162959739
Iter: 1128 loss: 0.00161471684
Iter: 1129 loss: 0.00160895847
Iter: 1130 loss: 0.00161028316
Iter: 1131 loss: 0.00160471816
Iter: 1132 loss: 0.00159826945
Iter: 1133 loss: 0.00159625849
Iter: 1134 loss: 0.001592424
Iter: 1135 loss: 0.00158607692
Iter: 1136 loss: 0.00164902012
Iter: 1137 loss: 0.00158586167
Iter: 1138 loss: 0.00157999981
Iter: 1139 loss: 0.00157915195
Iter: 1140 loss: 0.00157502969
Iter: 1141 loss: 0.00157387508
Iter: 1142 loss: 0.00157228764
Iter: 1143 loss: 0.00157121546
Iter: 1144 loss: 0.0015701697
Iter: 1145 loss: 0.00156941067
Iter: 1146 loss: 0.00156706246
Iter: 1147 loss: 0.00157193886
Iter: 1148 loss: 0.00156566
Iter: 1149 loss: 0.00155730522
Iter: 1150 loss: 0.00154695695
Iter: 1151 loss: 0.00154605578
Iter: 1152 loss: 0.00154157821
Iter: 1153 loss: 0.00154153584
Iter: 1154 loss: 0.00153957261
Iter: 1155 loss: 0.001538157
Iter: 1156 loss: 0.00153744011
Iter: 1157 loss: 0.00153566059
Iter: 1158 loss: 0.00155339006
Iter: 1159 loss: 0.00153541972
Iter: 1160 loss: 0.00152677461
Iter: 1161 loss: 0.00153648073
Iter: 1162 loss: 0.00152218295
Iter: 1163 loss: 0.00151298335
Iter: 1164 loss: 0.00153738633
Iter: 1165 loss: 0.00150982267
Iter: 1166 loss: 0.0015111292
Iter: 1167 loss: 0.0015066989
Iter: 1168 loss: 0.00150460564
Iter: 1169 loss: 0.00151335751
Iter: 1170 loss: 0.00150416931
Iter: 1171 loss: 0.00150344591
Iter: 1172 loss: 0.0015026601
Iter: 1173 loss: 0.00150254183
Iter: 1174 loss: 0.00150079257
Iter: 1175 loss: 0.0015140482
Iter: 1176 loss: 0.00150065334
Iter: 1177 loss: 0.00149858347
Iter: 1178 loss: 0.00149682723
Iter: 1179 loss: 0.00149626203
Iter: 1180 loss: 0.00149171241
Iter: 1181 loss: 0.00149099948
Iter: 1182 loss: 0.00148784323
Iter: 1183 loss: 0.0015030934
Iter: 1184 loss: 0.00148674101
Iter: 1185 loss: 0.00148617383
Iter: 1186 loss: 0.00148615101
Iter: 1187 loss: 0.00148583204
Iter: 1188 loss: 0.0014846985
Iter: 1189 loss: 0.00148238894
Iter: 1190 loss: 0.00148236565
Iter: 1191 loss: 0.00147566502
Iter: 1192 loss: 0.00149684213
Iter: 1193 loss: 0.00147376396
Iter: 1194 loss: 0.00146688067
Iter: 1195 loss: 0.00146592583
Iter: 1196 loss: 0.00146105851
Iter: 1197 loss: 0.00145420828
Iter: 1198 loss: 0.00145382131
Iter: 1199 loss: 0.00144993304
Iter: 1200 loss: 0.00148626
Iter: 1201 loss: 0.00144975947
Iter: 1202 loss: 0.00144926016
Iter: 1203 loss: 0.00144753733
Iter: 1204 loss: 0.00144574582
Iter: 1205 loss: 0.00144506805
Iter: 1206 loss: 0.00144059584
Iter: 1207 loss: 0.00144630601
Iter: 1208 loss: 0.00143832131
Iter: 1209 loss: 0.00143586728
Iter: 1210 loss: 0.00143567915
Iter: 1211 loss: 0.00143103534
Iter: 1212 loss: 0.00145861413
Iter: 1213 loss: 0.00143042416
Iter: 1214 loss: 0.00142888923
Iter: 1215 loss: 0.00142881251
Iter: 1216 loss: 0.0014275047
Iter: 1217 loss: 0.0014238836
Iter: 1218 loss: 0.0014435614
Iter: 1219 loss: 0.00142276147
Iter: 1220 loss: 0.00146340625
Iter: 1221 loss: 0.00142157264
Iter: 1222 loss: 0.00142087205
Iter: 1223 loss: 0.00142163225
Iter: 1224 loss: 0.00142049836
Iter: 1225 loss: 0.00141902186
Iter: 1226 loss: 0.0014137961
Iter: 1227 loss: 0.00140426541
Iter: 1228 loss: 0.0014039306
Iter: 1229 loss: 0.0014009102
Iter: 1230 loss: 0.0014008974
Iter: 1231 loss: 0.00140130136
Iter: 1232 loss: 0.00139980402
Iter: 1233 loss: 0.0013984004
Iter: 1234 loss: 0.00139737793
Iter: 1235 loss: 0.00139689655
Iter: 1236 loss: 0.00139564835
Iter: 1237 loss: 0.00139393075
Iter: 1238 loss: 0.00139385322
Iter: 1239 loss: 0.00138767564
Iter: 1240 loss: 0.00143806171
Iter: 1241 loss: 0.00138731441
Iter: 1242 loss: 0.00138284103
Iter: 1243 loss: 0.00137602491
Iter: 1244 loss: 0.00137591315
Iter: 1245 loss: 0.00137682818
Iter: 1246 loss: 0.00137238507
Iter: 1247 loss: 0.00136921904
Iter: 1248 loss: 0.00139202736
Iter: 1249 loss: 0.00136895268
Iter: 1250 loss: 0.00136832183
Iter: 1251 loss: 0.00136817421
Iter: 1252 loss: 0.00136732543
Iter: 1253 loss: 0.00137216132
Iter: 1254 loss: 0.00136721844
Iter: 1255 loss: 0.00136690331
Iter: 1256 loss: 0.001365926
Iter: 1257 loss: 0.00136753335
Iter: 1258 loss: 0.00136525568
Iter: 1259 loss: 0.00136219244
Iter: 1260 loss: 0.00136694242
Iter: 1261 loss: 0.00136077369
Iter: 1262 loss: 0.00140474702
Iter: 1263 loss: 0.00135853281
Iter: 1264 loss: 0.00135727797
Iter: 1265 loss: 0.00135868602
Iter: 1266 loss: 0.00135660334
Iter: 1267 loss: 0.00135142438
Iter: 1268 loss: 0.00137588312
Iter: 1269 loss: 0.0013505246
Iter: 1270 loss: 0.0013485807
Iter: 1271 loss: 0.00134825753
Iter: 1272 loss: 0.0013465865
Iter: 1273 loss: 0.00134651153
Iter: 1274 loss: 0.00134522864
Iter: 1275 loss: 0.00134345121
Iter: 1276 loss: 0.00133967947
Iter: 1277 loss: 0.00139835442
Iter: 1278 loss: 0.00133956387
Iter: 1279 loss: 0.00133153272
Iter: 1280 loss: 0.00133673195
Iter: 1281 loss: 0.00132635899
Iter: 1282 loss: 0.00132478401
Iter: 1283 loss: 0.00132470578
Iter: 1284 loss: 0.00132366596
Iter: 1285 loss: 0.00132365397
Iter: 1286 loss: 0.00132300181
Iter: 1287 loss: 0.00132153102
Iter: 1288 loss: 0.00134178007
Iter: 1289 loss: 0.00132144848
Iter: 1290 loss: 0.00131911458
Iter: 1291 loss: 0.00131642027
Iter: 1292 loss: 0.0013160971
Iter: 1293 loss: 0.00137812016
Iter: 1294 loss: 0.00131464074
Iter: 1295 loss: 0.00131342583
Iter: 1296 loss: 0.00131034327
Iter: 1297 loss: 0.00133720634
Iter: 1298 loss: 0.00130987354
Iter: 1299 loss: 0.00130305369
Iter: 1300 loss: 0.0013049019
Iter: 1301 loss: 0.00129804853
Iter: 1302 loss: 0.00130566349
Iter: 1303 loss: 0.00129537215
Iter: 1304 loss: 0.00129267341
Iter: 1305 loss: 0.00129792094
Iter: 1306 loss: 0.00129156839
Iter: 1307 loss: 0.0012903274
Iter: 1308 loss: 0.00129071565
Iter: 1309 loss: 0.00128944824
Iter: 1310 loss: 0.00128774485
Iter: 1311 loss: 0.00128561514
Iter: 1312 loss: 0.0012854347
Iter: 1313 loss: 0.00128435879
Iter: 1314 loss: 0.00128353084
Iter: 1315 loss: 0.00128989015
Iter: 1316 loss: 0.00128300418
Iter: 1317 loss: 0.00128271803
Iter: 1318 loss: 0.00128212664
Iter: 1319 loss: 0.00129197107
Iter: 1320 loss: 0.00128211349
Iter: 1321 loss: 0.00128099578
Iter: 1322 loss: 0.00127955014
Iter: 1323 loss: 0.00127945479
Iter: 1324 loss: 0.00127750845
Iter: 1325 loss: 0.00128652621
Iter: 1326 loss: 0.00127714081
Iter: 1327 loss: 0.0012733083
Iter: 1328 loss: 0.00127854652
Iter: 1329 loss: 0.00127139722
Iter: 1330 loss: 0.00126920815
Iter: 1331 loss: 0.0012650498
Iter: 1332 loss: 0.00135593349
Iter: 1333 loss: 0.00126502942
Iter: 1334 loss: 0.00126396597
Iter: 1335 loss: 0.00126298179
Iter: 1336 loss: 0.00126317795
Iter: 1337 loss: 0.00126202498
Iter: 1338 loss: 0.00126154209
Iter: 1339 loss: 0.00126063242
Iter: 1340 loss: 0.0012808647
Iter: 1341 loss: 0.0012606344
Iter: 1342 loss: 0.0012577906
Iter: 1343 loss: 0.00124958134
Iter: 1344 loss: 0.00128501817
Iter: 1345 loss: 0.00124636013
Iter: 1346 loss: 0.00124311377
Iter: 1347 loss: 0.00124286488
Iter: 1348 loss: 0.00124096149
Iter: 1349 loss: 0.00127168605
Iter: 1350 loss: 0.00124096149
Iter: 1351 loss: 0.00124091411
Iter: 1352 loss: 0.00124014588
Iter: 1353 loss: 0.00123982481
Iter: 1354 loss: 0.00123898906
Iter: 1355 loss: 0.00124553568
Iter: 1356 loss: 0.00123882457
Iter: 1357 loss: 0.00123726192
Iter: 1358 loss: 0.00123723364
Iter: 1359 loss: 0.00123599765
Iter: 1360 loss: 0.00123769208
Iter: 1361 loss: 0.00123392453
Iter: 1362 loss: 0.00123024324
Iter: 1363 loss: 0.00122771051
Iter: 1364 loss: 0.00122635497
Iter: 1365 loss: 0.00122472586
Iter: 1366 loss: 0.0012370022
Iter: 1367 loss: 0.00122458849
Iter: 1368 loss: 0.00123065826
Iter: 1369 loss: 0.00122429361
Iter: 1370 loss: 0.00122416718
Iter: 1371 loss: 0.00122375716
Iter: 1372 loss: 0.00122413144
Iter: 1373 loss: 0.00122342573
Iter: 1374 loss: 0.00122247031
Iter: 1375 loss: 0.00122135156
Iter: 1376 loss: 0.00122123188
Iter: 1377 loss: 0.00122016796
Iter: 1378 loss: 0.00121966843
Iter: 1379 loss: 0.00121914619
Iter: 1380 loss: 0.0012182768
Iter: 1381 loss: 0.00122945406
Iter: 1382 loss: 0.00121827028
Iter: 1383 loss: 0.0012171017
Iter: 1384 loss: 0.00121805456
Iter: 1385 loss: 0.00121640041
Iter: 1386 loss: 0.0012148621
Iter: 1387 loss: 0.00121485884
Iter: 1388 loss: 0.00121463882
Iter: 1389 loss: 0.0012141075
Iter: 1390 loss: 0.00121999788
Iter: 1391 loss: 0.0012140699
Iter: 1392 loss: 0.0012132877
Iter: 1393 loss: 0.00121304835
Iter: 1394 loss: 0.00121258781
Iter: 1395 loss: 0.00121172774
Iter: 1396 loss: 0.00120881014
Iter: 1397 loss: 0.00120649592
Iter: 1398 loss: 0.00120496075
Iter: 1399 loss: 0.00120292557
Iter: 1400 loss: 0.00121340994
Iter: 1401 loss: 0.00120259915
Iter: 1402 loss: 0.00120570301
Iter: 1403 loss: 0.0012023407
Iter: 1404 loss: 0.00120204664
Iter: 1405 loss: 0.00120149797
Iter: 1406 loss: 0.00121356733
Iter: 1407 loss: 0.00120149844
Iter: 1408 loss: 0.0012004599
Iter: 1409 loss: 0.00120079913
Iter: 1410 loss: 0.00119971763
Iter: 1411 loss: 0.00119797629
Iter: 1412 loss: 0.0012070809
Iter: 1413 loss: 0.00119769992
Iter: 1414 loss: 0.00119631994
Iter: 1415 loss: 0.00119505066
Iter: 1416 loss: 0.00119471876
Iter: 1417 loss: 0.00119514123
Iter: 1418 loss: 0.00119329547
Iter: 1419 loss: 0.0011910575
Iter: 1420 loss: 0.00118727307
Iter: 1421 loss: 0.00118726562
Iter: 1422 loss: 0.00118562649
Iter: 1423 loss: 0.00118488306
Iter: 1424 loss: 0.00118405931
Iter: 1425 loss: 0.00118352554
Iter: 1426 loss: 0.00118348189
Iter: 1427 loss: 0.00118212239
Iter: 1428 loss: 0.00118577364
Iter: 1429 loss: 0.00118168595
Iter: 1430 loss: 0.00118061248
Iter: 1431 loss: 0.00117881107
Iter: 1432 loss: 0.00117880874
Iter: 1433 loss: 0.00117769791
Iter: 1434 loss: 0.00118983188
Iter: 1435 loss: 0.00117767393
Iter: 1436 loss: 0.00117706391
Iter: 1437 loss: 0.00118098152
Iter: 1438 loss: 0.00117699592
Iter: 1439 loss: 0.00117601478
Iter: 1440 loss: 0.00117579603
Iter: 1441 loss: 0.00117516029
Iter: 1442 loss: 0.0011736278
Iter: 1443 loss: 0.00118004298
Iter: 1444 loss: 0.00117329927
Iter: 1445 loss: 0.00117042882
Iter: 1446 loss: 0.00116747036
Iter: 1447 loss: 0.0011669196
Iter: 1448 loss: 0.00116759608
Iter: 1449 loss: 0.00116612506
Iter: 1450 loss: 0.00116510596
Iter: 1451 loss: 0.00117200916
Iter: 1452 loss: 0.00116499851
Iter: 1453 loss: 0.0011646956
Iter: 1454 loss: 0.00116387254
Iter: 1455 loss: 0.00116911228
Iter: 1456 loss: 0.00116367487
Iter: 1457 loss: 0.00116166077
Iter: 1458 loss: 0.00115941348
Iter: 1459 loss: 0.00115911476
Iter: 1460 loss: 0.00115692732
Iter: 1461 loss: 0.00115641044
Iter: 1462 loss: 0.00115475338
Iter: 1463 loss: 0.0011627397
Iter: 1464 loss: 0.00115445151
Iter: 1465 loss: 0.00115398492
Iter: 1466 loss: 0.00115345954
Iter: 1467 loss: 0.00115283497
Iter: 1468 loss: 0.00115245115
Iter: 1469 loss: 0.00115219248
Iter: 1470 loss: 0.00115153799
Iter: 1471 loss: 0.00115062681
Iter: 1472 loss: 0.00115058757
Iter: 1473 loss: 0.00114945904
Iter: 1474 loss: 0.00114635308
Iter: 1475 loss: 0.00116494007
Iter: 1476 loss: 0.00114549627
Iter: 1477 loss: 0.00114489044
Iter: 1478 loss: 0.00114379404
Iter: 1479 loss: 0.00114482979
Iter: 1480 loss: 0.00114265643
Iter: 1481 loss: 0.00114103383
Iter: 1482 loss: 0.00114904065
Iter: 1483 loss: 0.00114075537
Iter: 1484 loss: 0.00113986223
Iter: 1485 loss: 0.00113924756
Iter: 1486 loss: 0.00113892485
Iter: 1487 loss: 0.00113624847
Iter: 1488 loss: 0.00113252108
Iter: 1489 loss: 0.00113236276
Iter: 1490 loss: 0.00112799159
Iter: 1491 loss: 0.00117369555
Iter: 1492 loss: 0.00112786319
Iter: 1493 loss: 0.00112308795
Iter: 1494 loss: 0.0011609958
Iter: 1495 loss: 0.00112276594
Iter: 1496 loss: 0.00112206722
Iter: 1497 loss: 0.00112116849
Iter: 1498 loss: 0.00112055521
Iter: 1499 loss: 0.00112410332
Iter: 1500 loss: 0.00112047477
Iter: 1501 loss: 0.00112008874
Iter: 1502 loss: 0.0011200303
Iter: 1503 loss: 0.00111977081
Iter: 1504 loss: 0.00111924135
Iter: 1505 loss: 0.00111808523
Iter: 1506 loss: 0.00113514694
Iter: 1507 loss: 0.0011180304
Iter: 1508 loss: 0.00111716078
Iter: 1509 loss: 0.00111457356
Iter: 1510 loss: 0.00112311414
Iter: 1511 loss: 0.00111334655
Iter: 1512 loss: 0.00110763183
Iter: 1513 loss: 0.00113676139
Iter: 1514 loss: 0.00110673311
Iter: 1515 loss: 0.00110006251
Iter: 1516 loss: 0.00111413165
Iter: 1517 loss: 0.00109736389
Iter: 1518 loss: 0.00109444675
Iter: 1519 loss: 0.00110308302
Iter: 1520 loss: 0.00109354965
Iter: 1521 loss: 0.0010915969
Iter: 1522 loss: 0.00109008304
Iter: 1523 loss: 0.0010894544
Iter: 1524 loss: 0.00108627696
Iter: 1525 loss: 0.00108640315
Iter: 1526 loss: 0.00108378404
Iter: 1527 loss: 0.0010791542
Iter: 1528 loss: 0.00110055367
Iter: 1529 loss: 0.00107828155
Iter: 1530 loss: 0.00117746973
Iter: 1531 loss: 0.00107798469
Iter: 1532 loss: 0.00107769715
Iter: 1533 loss: 0.00107935292
Iter: 1534 loss: 0.00107765407
Iter: 1535 loss: 0.00107746129
Iter: 1536 loss: 0.00107671809
Iter: 1537 loss: 0.00107359141
Iter: 1538 loss: 0.00107343204
Iter: 1539 loss: 0.00107027986
Iter: 1540 loss: 0.0010720205
Iter: 1541 loss: 0.00106964144
Iter: 1542 loss: 0.00106853875
Iter: 1543 loss: 0.00107238302
Iter: 1544 loss: 0.00106824969
Iter: 1545 loss: 0.00106686784
Iter: 1546 loss: 0.00107236113
Iter: 1547 loss: 0.00106654339
Iter: 1548 loss: 0.00106579228
Iter: 1549 loss: 0.00106879417
Iter: 1550 loss: 0.00106561137
Iter: 1551 loss: 0.00106487982
Iter: 1552 loss: 0.00106926751
Iter: 1553 loss: 0.00106477772
Iter: 1554 loss: 0.00106407562
Iter: 1555 loss: 0.00106241228
Iter: 1556 loss: 0.00108120881
Iter: 1557 loss: 0.00106225896
Iter: 1558 loss: 0.00106034009
Iter: 1559 loss: 0.00105816382
Iter: 1560 loss: 0.00105788128
Iter: 1561 loss: 0.00105489441
Iter: 1562 loss: 0.00105311954
Iter: 1563 loss: 0.0010518881
Iter: 1564 loss: 0.00105135154
Iter: 1565 loss: 0.00105032558
Iter: 1566 loss: 0.00105059124
Iter: 1567 loss: 0.00104969461
Iter: 1568 loss: 0.00104942336
Iter: 1569 loss: 0.00104849529
Iter: 1570 loss: 0.00104679936
Iter: 1571 loss: 0.00104673533
Iter: 1572 loss: 0.00104531774
Iter: 1573 loss: 0.00104528735
Iter: 1574 loss: 0.00104435463
Iter: 1575 loss: 0.00104410469
Iter: 1576 loss: 0.00104352913
Iter: 1577 loss: 0.00104033772
Iter: 1578 loss: 0.00104034552
Iter: 1579 loss: 0.0010352016
Iter: 1580 loss: 0.00110689655
Iter: 1581 loss: 0.00103518181
Iter: 1582 loss: 0.00103347935
Iter: 1583 loss: 0.00103804283
Iter: 1584 loss: 0.00103291112
Iter: 1585 loss: 0.00103221694
Iter: 1586 loss: 0.00103127584
Iter: 1587 loss: 0.00103123323
Iter: 1588 loss: 0.00103009748
Iter: 1589 loss: 0.00102712237
Iter: 1590 loss: 0.00104885362
Iter: 1591 loss: 0.0010264772
Iter: 1592 loss: 0.00102476077
Iter: 1593 loss: 0.00102374842
Iter: 1594 loss: 0.00102304877
Iter: 1595 loss: 0.00102132675
Iter: 1596 loss: 0.00103000179
Iter: 1597 loss: 0.00102103758
Iter: 1598 loss: 0.00102231302
Iter: 1599 loss: 0.00102053361
Iter: 1600 loss: 0.00102012674
Iter: 1601 loss: 0.00101864897
Iter: 1602 loss: 0.00101590925
Iter: 1603 loss: 0.00101583032
Iter: 1604 loss: 0.00101480423
Iter: 1605 loss: 0.00101349899
Iter: 1606 loss: 0.00101073133
Iter: 1607 loss: 0.00100572174
Iter: 1608 loss: 0.00112673151
Iter: 1609 loss: 0.00100572733
Iter: 1610 loss: 0.00100175641
Iter: 1611 loss: 0.00101544871
Iter: 1612 loss: 0.00100070774
Iter: 1613 loss: 0.000998965465
Iter: 1614 loss: 0.000998911913
Iter: 1615 loss: 0.000997453
Iter: 1616 loss: 0.000996440416
Iter: 1617 loss: 0.00099590444
Iter: 1618 loss: 0.000993451336
Iter: 1619 loss: 0.00102006155
Iter: 1620 loss: 0.000993393129
Iter: 1621 loss: 0.000988576096
Iter: 1622 loss: 0.00099065667
Iter: 1623 loss: 0.000985285267
Iter: 1624 loss: 0.000983371865
Iter: 1625 loss: 0.000983302
Iter: 1626 loss: 0.000982075697
Iter: 1627 loss: 0.000982945552
Iter: 1628 loss: 0.000981308753
Iter: 1629 loss: 0.000980152
Iter: 1630 loss: 0.00097681419
Iter: 1631 loss: 0.000991858542
Iter: 1632 loss: 0.000975567964
Iter: 1633 loss: 0.000972339069
Iter: 1634 loss: 0.00101731461
Iter: 1635 loss: 0.00097233447
Iter: 1636 loss: 0.000971766538
Iter: 1637 loss: 0.0009736949
Iter: 1638 loss: 0.000971610425
Iter: 1639 loss: 0.000970365
Iter: 1640 loss: 0.000970119319
Iter: 1641 loss: 0.000968827633
Iter: 1642 loss: 0.000970403256
Iter: 1643 loss: 0.000968146429
Iter: 1644 loss: 0.000967434142
Iter: 1645 loss: 0.000965332671
Iter: 1646 loss: 0.000972589594
Iter: 1647 loss: 0.000964340405
Iter: 1648 loss: 0.00096244819
Iter: 1649 loss: 0.000962447899
Iter: 1650 loss: 0.000961685
Iter: 1651 loss: 0.000959459925
Iter: 1652 loss: 0.000968434615
Iter: 1653 loss: 0.000958551653
Iter: 1654 loss: 0.00105396286
Iter: 1655 loss: 0.000957089418
Iter: 1656 loss: 0.000955279625
Iter: 1657 loss: 0.00096280931
Iter: 1658 loss: 0.000954889
Iter: 1659 loss: 0.000954477466
Iter: 1660 loss: 0.000954609481
Iter: 1661 loss: 0.000954187
Iter: 1662 loss: 0.00095340726
Iter: 1663 loss: 0.000954615709
Iter: 1664 loss: 0.000953044044
Iter: 1665 loss: 0.000951469294
Iter: 1666 loss: 0.000954122632
Iter: 1667 loss: 0.000950753398
Iter: 1668 loss: 0.000949005247
Iter: 1669 loss: 0.00095111283
Iter: 1670 loss: 0.000948106288
Iter: 1671 loss: 0.000946960179
Iter: 1672 loss: 0.000948188826
Iter: 1673 loss: 0.000946338172
Iter: 1674 loss: 0.0009460398
Iter: 1675 loss: 0.000945977867
Iter: 1676 loss: 0.000945786189
Iter: 1677 loss: 0.000945157837
Iter: 1678 loss: 0.00094513729
Iter: 1679 loss: 0.000944909349
Iter: 1680 loss: 0.000944657717
Iter: 1681 loss: 0.000944619183
Iter: 1682 loss: 0.000944399042
Iter: 1683 loss: 0.000943818653
Iter: 1684 loss: 0.000948245754
Iter: 1685 loss: 0.000943703577
Iter: 1686 loss: 0.000943128136
Iter: 1687 loss: 0.000945768552
Iter: 1688 loss: 0.000943016144
Iter: 1689 loss: 0.000948831846
Iter: 1690 loss: 0.000942667248
Iter: 1691 loss: 0.000942335813
Iter: 1692 loss: 0.000941892504
Iter: 1693 loss: 0.000941872946
Iter: 1694 loss: 0.00094029319
Iter: 1695 loss: 0.000946520304
Iter: 1696 loss: 0.00093992654
Iter: 1697 loss: 0.000938324258
Iter: 1698 loss: 0.000963972707
Iter: 1699 loss: 0.000938318612
Iter: 1700 loss: 0.000937853474
Iter: 1701 loss: 0.000937569
Iter: 1702 loss: 0.000937350211
Iter: 1703 loss: 0.000937038451
Iter: 1704 loss: 0.000937023433
Iter: 1705 loss: 0.000935744494
Iter: 1706 loss: 0.000932788767
Iter: 1707 loss: 0.000969787827
Iter: 1708 loss: 0.000932569383
Iter: 1709 loss: 0.000971408561
Iter: 1710 loss: 0.000930645
Iter: 1711 loss: 0.000929750851
Iter: 1712 loss: 0.0009324649
Iter: 1713 loss: 0.000929482398
Iter: 1714 loss: 0.000928813766
Iter: 1715 loss: 0.00092772
Iter: 1716 loss: 0.000927712186
Iter: 1717 loss: 0.000927320914
Iter: 1718 loss: 0.000926748791
Iter: 1719 loss: 0.000926730165
Iter: 1720 loss: 0.000924440683
Iter: 1721 loss: 0.00095365959
Iter: 1722 loss: 0.000924420659
Iter: 1723 loss: 0.000922426349
Iter: 1724 loss: 0.000955457625
Iter: 1725 loss: 0.000922431413
Iter: 1726 loss: 0.000920670747
Iter: 1727 loss: 0.000920075341
Iter: 1728 loss: 0.000918138307
Iter: 1729 loss: 0.0009205651
Iter: 1730 loss: 0.000917131605
Iter: 1731 loss: 0.000922868552
Iter: 1732 loss: 0.000916756166
Iter: 1733 loss: 0.000916526653
Iter: 1734 loss: 0.000915817101
Iter: 1735 loss: 0.000917311059
Iter: 1736 loss: 0.000915390672
Iter: 1737 loss: 0.000914850563
Iter: 1738 loss: 0.000914617965
Iter: 1739 loss: 0.000914341712
Iter: 1740 loss: 0.000913915923
Iter: 1741 loss: 0.000913216849
Iter: 1742 loss: 0.000913210621
Iter: 1743 loss: 0.000929761212
Iter: 1744 loss: 0.000912712771
Iter: 1745 loss: 0.000912061078
Iter: 1746 loss: 0.0009118772
Iter: 1747 loss: 0.00091147935
Iter: 1748 loss: 0.000910269911
Iter: 1749 loss: 0.000906684727
Iter: 1750 loss: 0.000918564154
Iter: 1751 loss: 0.000905004097
Iter: 1752 loss: 0.000902289408
Iter: 1753 loss: 0.000908737711
Iter: 1754 loss: 0.000901311
Iter: 1755 loss: 0.000899679
Iter: 1756 loss: 0.000897424237
Iter: 1757 loss: 0.000897323131
Iter: 1758 loss: 0.000895686448
Iter: 1759 loss: 0.000894585741
Iter: 1760 loss: 0.000893983874
Iter: 1761 loss: 0.000892759417
Iter: 1762 loss: 0.000892682874
Iter: 1763 loss: 0.000891766627
Iter: 1764 loss: 0.000891014177
Iter: 1765 loss: 0.000888947572
Iter: 1766 loss: 0.000902119617
Iter: 1767 loss: 0.000888418348
Iter: 1768 loss: 0.000928421156
Iter: 1769 loss: 0.000888133422
Iter: 1770 loss: 0.000887670263
Iter: 1771 loss: 0.000892355223
Iter: 1772 loss: 0.000887651811
Iter: 1773 loss: 0.000887548667
Iter: 1774 loss: 0.000887161586
Iter: 1775 loss: 0.000886221067
Iter: 1776 loss: 0.000906385947
Iter: 1777 loss: 0.000886222057
Iter: 1778 loss: 0.000884975656
Iter: 1779 loss: 0.000899332226
Iter: 1780 loss: 0.000884956389
Iter: 1781 loss: 0.000884048524
Iter: 1782 loss: 0.000888664799
Iter: 1783 loss: 0.000883899338
Iter: 1784 loss: 0.000882588793
Iter: 1785 loss: 0.000880726
Iter: 1786 loss: 0.000880664156
Iter: 1787 loss: 0.00087821082
Iter: 1788 loss: 0.000877068553
Iter: 1789 loss: 0.000875860685
Iter: 1790 loss: 0.000873358746
Iter: 1791 loss: 0.000875857542
Iter: 1792 loss: 0.000871938537
Iter: 1793 loss: 0.000870426768
Iter: 1794 loss: 0.000878129329
Iter: 1795 loss: 0.0008701685
Iter: 1796 loss: 0.000868463132
Iter: 1797 loss: 0.000879835221
Iter: 1798 loss: 0.00086828717
Iter: 1799 loss: 0.000866730232
Iter: 1800 loss: 0.000864865491
Iter: 1801 loss: 0.000864671601
Iter: 1802 loss: 0.000879767758
Iter: 1803 loss: 0.000864257221
Iter: 1804 loss: 0.00086333818
Iter: 1805 loss: 0.000874548103
Iter: 1806 loss: 0.000863326306
Iter: 1807 loss: 0.000863167283
Iter: 1808 loss: 0.000862596673
Iter: 1809 loss: 0.000861482811
Iter: 1810 loss: 0.000861455745
Iter: 1811 loss: 0.000904796587
Iter: 1812 loss: 0.00086072681
Iter: 1813 loss: 0.000859893567
Iter: 1814 loss: 0.000861787295
Iter: 1815 loss: 0.000859582
Iter: 1816 loss: 0.000859251653
Iter: 1817 loss: 0.000858654152
Iter: 1818 loss: 0.000872261066
Iter: 1819 loss: 0.000858655781
Iter: 1820 loss: 0.000857372128
Iter: 1821 loss: 0.000857967301
Iter: 1822 loss: 0.000856502564
Iter: 1823 loss: 0.000855002552
Iter: 1824 loss: 0.000860345084
Iter: 1825 loss: 0.000854609476
Iter: 1826 loss: 0.000853248755
Iter: 1827 loss: 0.000853029313
Iter: 1828 loss: 0.000852434547
Iter: 1829 loss: 0.000851881
Iter: 1830 loss: 0.000851742923
Iter: 1831 loss: 0.000851539546
Iter: 1832 loss: 0.000851027435
Iter: 1833 loss: 0.000855920953
Iter: 1834 loss: 0.000850960379
Iter: 1835 loss: 0.000850127195
Iter: 1836 loss: 0.000849115
Iter: 1837 loss: 0.000849019911
Iter: 1838 loss: 0.000847516814
Iter: 1839 loss: 0.000852525409
Iter: 1840 loss: 0.000847111107
Iter: 1841 loss: 0.000845163479
Iter: 1842 loss: 0.000845121802
Iter: 1843 loss: 0.000844205148
Iter: 1844 loss: 0.000843523943
Iter: 1845 loss: 0.000846327923
Iter: 1846 loss: 0.000842992042
Iter: 1847 loss: 0.000842174049
Iter: 1848 loss: 0.000841269328
Iter: 1849 loss: 0.000841144
Iter: 1850 loss: 0.000840806169
Iter: 1851 loss: 0.000840189285
Iter: 1852 loss: 0.000839303189
Iter: 1853 loss: 0.000837683911
Iter: 1854 loss: 0.000876382343
Iter: 1855 loss: 0.000837685599
Iter: 1856 loss: 0.000850311248
Iter: 1857 loss: 0.000837133208
Iter: 1858 loss: 0.000836676569
Iter: 1859 loss: 0.000836666324
Iter: 1860 loss: 0.000836542458
Iter: 1861 loss: 0.000836248742
Iter: 1862 loss: 0.000839074957
Iter: 1863 loss: 0.000836203806
Iter: 1864 loss: 0.000835094368
Iter: 1865 loss: 0.00083289016
Iter: 1866 loss: 0.000876071164
Iter: 1867 loss: 0.000832867576
Iter: 1868 loss: 0.000831948593
Iter: 1869 loss: 0.000840077642
Iter: 1870 loss: 0.000831897487
Iter: 1871 loss: 0.0008312235
Iter: 1872 loss: 0.000830138568
Iter: 1873 loss: 0.000830135192
Iter: 1874 loss: 0.000828743
Iter: 1875 loss: 0.000830366334
Iter: 1876 loss: 0.000828000833
Iter: 1877 loss: 0.00082625926
Iter: 1878 loss: 0.000835442683
Iter: 1879 loss: 0.000825990224
Iter: 1880 loss: 0.000823596
Iter: 1881 loss: 0.000828539254
Iter: 1882 loss: 0.000822637
Iter: 1883 loss: 0.000821710739
Iter: 1884 loss: 0.000833227241
Iter: 1885 loss: 0.000821702182
Iter: 1886 loss: 0.000820706831
Iter: 1887 loss: 0.000822094153
Iter: 1888 loss: 0.000820207526
Iter: 1889 loss: 0.00082035095
Iter: 1890 loss: 0.000819980516
Iter: 1891 loss: 0.000819888
Iter: 1892 loss: 0.000819886045
Iter: 1893 loss: 0.000819798675
Iter: 1894 loss: 0.000819653447
Iter: 1895 loss: 0.000819654553
Iter: 1896 loss: 0.000819503
Iter: 1897 loss: 0.000819366367
Iter: 1898 loss: 0.000819329696
Iter: 1899 loss: 0.000819032197
Iter: 1900 loss: 0.000818312517
Iter: 1901 loss: 0.000826141913
Iter: 1902 loss: 0.000818236265
Iter: 1903 loss: 0.000816543587
Iter: 1904 loss: 0.000822389848
Iter: 1905 loss: 0.000816099579
Iter: 1906 loss: 0.000814367668
Iter: 1907 loss: 0.000814339088
Iter: 1908 loss: 0.00081319228
Iter: 1909 loss: 0.000818752
Iter: 1910 loss: 0.000812988379
Iter: 1911 loss: 0.000811857521
Iter: 1912 loss: 0.000825695228
Iter: 1913 loss: 0.000811850303
Iter: 1914 loss: 0.000811268343
Iter: 1915 loss: 0.000812607119
Iter: 1916 loss: 0.0008110528
Iter: 1917 loss: 0.000810388767
Iter: 1918 loss: 0.000810984871
Iter: 1919 loss: 0.000809998251
Iter: 1920 loss: 0.000809677527
Iter: 1921 loss: 0.00080967322
Iter: 1922 loss: 0.000809840392
Iter: 1923 loss: 0.000809587538
Iter: 1924 loss: 0.000809528399
Iter: 1925 loss: 0.0008093699
Iter: 1926 loss: 0.000810392783
Iter: 1927 loss: 0.000809327816
Iter: 1928 loss: 0.000809076475
Iter: 1929 loss: 0.000811167
Iter: 1930 loss: 0.000809056277
Iter: 1931 loss: 0.000808890793
Iter: 1932 loss: 0.000808410055
Iter: 1933 loss: 0.000810323399
Iter: 1934 loss: 0.000808211
Iter: 1935 loss: 0.000807830191
Iter: 1936 loss: 0.000808951445
Iter: 1937 loss: 0.00080771
Iter: 1938 loss: 0.000807542936
Iter: 1939 loss: 0.000806936529
Iter: 1940 loss: 0.000805291231
Iter: 1941 loss: 0.000831609941
Iter: 1942 loss: 0.000805235642
Iter: 1943 loss: 0.000804673531
Iter: 1944 loss: 0.0008078065
Iter: 1945 loss: 0.000804593961
Iter: 1946 loss: 0.000804502517
Iter: 1947 loss: 0.000804227951
Iter: 1948 loss: 0.000805078307
Iter: 1949 loss: 0.000804092502
Iter: 1950 loss: 0.000803849194
Iter: 1951 loss: 0.000803672
Iter: 1952 loss: 0.000803587667
Iter: 1953 loss: 0.000803347677
Iter: 1954 loss: 0.000803234812
Iter: 1955 loss: 0.000802562223
Iter: 1956 loss: 0.000810625148
Iter: 1957 loss: 0.000802557159
Iter: 1958 loss: 0.00080243405
Iter: 1959 loss: 0.000802141032
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8
+ date
Tue Oct 27 19:44:38 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2552cb72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2552cd2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2552cdaf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2552cda620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c2f8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c2f8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c2e1c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c2f8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c2a5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c2a5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c204598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c1b70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c1b7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c173bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c173e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c173400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c148730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c1b7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c1170d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c15e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c0df620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c08f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f252c0596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f25100a8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f25100a8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2510059378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f25100a86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f25100a8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2510030510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2510044ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f24bc7f0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f24bc7a61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f24bc7a6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f24bc7aa488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f24bc774bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f24bc719e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0793225318
Iter: 2 loss: 2.75327
Iter: 3 loss: 2.75190902
Iter: 4 loss: 1.90603077
Iter: 5 loss: 1.90480685
Iter: 6 loss: 1.33302903
Iter: 7 loss: 1.33191848
Iter: 8 loss: 0.949322701
Iter: 9 loss: 0.948317885
Iter: 10 loss: 0.684858799
Iter: 11 loss: 0.683844
Iter: 12 loss: 0.492462099
Iter: 13 loss: 0.491339058
Iter: 14 loss: 0.347557962
Iter: 15 loss: 0.346281588
Iter: 16 loss: 0.240661025
Iter: 17 loss: 0.239368081
Iter: 18 loss: 0.165931225
Iter: 19 loss: 0.164679661
Iter: 20 loss: 0.112644315
Iter: 21 loss: 0.111304775
Iter: 22 loss: 0.0738468096
Iter: 23 loss: 0.0725507885
Iter: 24 loss: 0.0708963871
Iter: 25 loss: 0.0640875101
Iter: 26 loss: 0.0344598554
Iter: 27 loss: 0.0381202698
Iter: 28 loss: 2854.1748
Iter: 29 loss: 1217.89148
Iter: 30 loss: 0.0381202027
Iter: 31 loss: 229.534821
Iter: 32 loss: 0.0381197296
Iter: 33 loss: 0.218336463
Iter: 34 loss: 0.0343337953
Iter: 35 loss: 0.0340784341
Iter: 36 loss: 0.0527645238
Iter: 37 loss: 0.0336316228
Iter: 38 loss: 0.0309356693
Iter: 39 loss: 0.0309398435
Iter: 40 loss: 0.0285193846
Iter: 41 loss: 0.0283857509
Iter: 42 loss: 0.0248827934
Iter: 43 loss: 0.0248749647
Iter: 44 loss: 0.024163479
Iter: 45 loss: 0.116228342
Iter: 46 loss: 0.0241629202
Iter: 47 loss: 0.0235404912
Iter: 48 loss: 0.0226061866
Iter: 49 loss: 0.0225791335
Iter: 50 loss: 0.0215867758
Iter: 51 loss: 0.0253314618
Iter: 52 loss: 0.021513829
Iter: 53 loss: 0.0211275835
Iter: 54 loss: 0.0208902657
Iter: 55 loss: 0.0207220986
Iter: 56 loss: 0.019804934
Iter: 57 loss: 0.0183272678
Iter: 58 loss: 0.0183250494
Iter: 59 loss: 0.017296901
Iter: 60 loss: 0.0214032829
Iter: 61 loss: 0.0170313902
Iter: 62 loss: 0.0162145812
Iter: 63 loss: 0.0165570378
Iter: 64 loss: 0.015663797
Iter: 65 loss: 0.0148113519
Iter: 66 loss: 0.0158622209
Iter: 67 loss: 0.0143309887
Iter: 68 loss: 0.0137874642
Iter: 69 loss: 0.0128465369
Iter: 70 loss: 0.0128459884
Iter: 71 loss: 0.0119120358
Iter: 72 loss: 0.0206168108
Iter: 73 loss: 0.0118308645
Iter: 74 loss: 0.0113225915
Iter: 75 loss: 0.0139505686
Iter: 76 loss: 0.0112377405
Iter: 77 loss: 0.010741123
Iter: 78 loss: 0.0109340977
Iter: 79 loss: 0.0103680445
Iter: 80 loss: 0.0099158911
Iter: 81 loss: 0.0098934453
Iter: 82 loss: 0.00960724
Iter: 83 loss: 0.0095793549
Iter: 84 loss: 0.00945243519
Iter: 85 loss: 0.009583598
Iter: 86 loss: 0.00937579572
Iter: 87 loss: 0.0091578979
Iter: 88 loss: 0.00878802594
Iter: 89 loss: 0.00878777727
Iter: 90 loss: 0.00829311088
Iter: 91 loss: 0.013583703
Iter: 92 loss: 0.00827508606
Iter: 93 loss: 0.00799253
Iter: 94 loss: 0.0110048205
Iter: 95 loss: 0.00798004866
Iter: 96 loss: 0.0077944058
Iter: 97 loss: 0.00765590556
Iter: 98 loss: 0.00759176817
Iter: 99 loss: 0.00724010682
Iter: 100 loss: 0.00934400223
Iter: 101 loss: 0.00718225073
Iter: 102 loss: 0.00693425443
Iter: 103 loss: 0.00860937871
Iter: 104 loss: 0.00690977555
Iter: 105 loss: 0.0067055691
Iter: 106 loss: 0.00762456097
Iter: 107 loss: 0.00666865846
Iter: 108 loss: 0.00649030646
Iter: 109 loss: 0.00621595234
Iter: 110 loss: 0.00621212553
Iter: 111 loss: 0.00642030733
Iter: 112 loss: 0.00604516454
Iter: 113 loss: 0.00593878049
Iter: 114 loss: 0.00669215294
Iter: 115 loss: 0.00593395904
Iter: 116 loss: 0.00585844461
Iter: 117 loss: 0.00607126579
Iter: 118 loss: 0.00583070237
Iter: 119 loss: 0.00573225785
Iter: 120 loss: 0.00558243273
Iter: 121 loss: 0.00557895377
Iter: 122 loss: 0.00537818065
Iter: 123 loss: 0.00601342
Iter: 124 loss: 0.00532428455
Iter: 125 loss: 0.00517838681
Iter: 126 loss: 0.00517836818
Iter: 127 loss: 0.00506358594
Iter: 128 loss: 0.0049844482
Iter: 129 loss: 0.00493736286
Iter: 130 loss: 0.00485052355
Iter: 131 loss: 0.00513960095
Iter: 132 loss: 0.00482812244
Iter: 133 loss: 0.00473171892
Iter: 134 loss: 0.00458906591
Iter: 135 loss: 0.00458470453
Iter: 136 loss: 0.00444458
Iter: 137 loss: 0.00444451347
Iter: 138 loss: 0.00439381786
Iter: 139 loss: 0.00429123454
Iter: 140 loss: 0.00641185138
Iter: 141 loss: 0.00428988505
Iter: 142 loss: 0.00414625369
Iter: 143 loss: 0.0046561351
Iter: 144 loss: 0.00411008252
Iter: 145 loss: 0.0040507759
Iter: 146 loss: 0.00403574482
Iter: 147 loss: 0.0039593461
Iter: 148 loss: 0.00432169763
Iter: 149 loss: 0.00394291338
Iter: 150 loss: 0.0039032246
Iter: 151 loss: 0.00394145958
Iter: 152 loss: 0.0038802952
Iter: 153 loss: 0.00379718374
Iter: 154 loss: 0.00380629627
Iter: 155 loss: 0.00373502448
Iter: 156 loss: 0.00367466314
Iter: 157 loss: 0.00431598257
Iter: 158 loss: 0.0036714836
Iter: 159 loss: 0.00363147445
Iter: 160 loss: 0.00367390271
Iter: 161 loss: 0.00360938674
Iter: 162 loss: 0.00352183497
Iter: 163 loss: 0.00385602773
Iter: 164 loss: 0.00350033352
Iter: 165 loss: 0.00343797333
Iter: 166 loss: 0.00367039745
Iter: 167 loss: 0.00342307915
Iter: 168 loss: 0.00338423415
Iter: 169 loss: 0.0036032584
Iter: 170 loss: 0.00337928021
Iter: 171 loss: 0.00333197089
Iter: 172 loss: 0.00364761
Iter: 173 loss: 0.00332576549
Iter: 174 loss: 0.00330757187
Iter: 175 loss: 0.00329172472
Iter: 176 loss: 0.00328684086
Iter: 177 loss: 0.00324760843
Iter: 178 loss: 0.00324540446
Iter: 179 loss: 0.00321591552
Iter: 180 loss: 0.00332037918
Iter: 181 loss: 0.00319006154
Iter: 182 loss: 0.0031743173
Iter: 183 loss: 0.0031573372
Iter: 184 loss: 0.00315438421
Iter: 185 loss: 0.0031260713
Iter: 186 loss: 0.00311997603
Iter: 187 loss: 0.00310156122
Iter: 188 loss: 0.00308149448
Iter: 189 loss: 0.00305159
Iter: 190 loss: 0.00305095292
Iter: 191 loss: 0.00302797393
Iter: 192 loss: 0.00302713551
Iter: 193 loss: 0.00299584819
Iter: 194 loss: 0.00301163225
Iter: 195 loss: 0.00297587272
Iter: 196 loss: 0.00293546962
Iter: 197 loss: 0.00299979141
Iter: 198 loss: 0.00291662663
Iter: 199 loss: 0.00289563974
Iter: 200 loss: 0.00286671659
Iter: 201 loss: 0.0028653
Iter: 202 loss: 0.00283200014
Iter: 203 loss: 0.00303322682
Iter: 204 loss: 0.00282788556
Iter: 205 loss: 0.00280011888
Iter: 206 loss: 0.0028328835
Iter: 207 loss: 0.00278546428
Iter: 208 loss: 0.00275338208
Iter: 209 loss: 0.00284658023
Iter: 210 loss: 0.00274394313
Iter: 211 loss: 0.00272134179
Iter: 212 loss: 0.00303893513
Iter: 213 loss: 0.00272111967
Iter: 214 loss: 0.00271343067
Iter: 215 loss: 0.00269968808
Iter: 216 loss: 0.00300556188
Iter: 217 loss: 0.00269968295
Iter: 218 loss: 0.0026760844
Iter: 219 loss: 0.00280987797
Iter: 220 loss: 0.00267247809
Iter: 221 loss: 0.00264854683
Iter: 222 loss: 0.00273448671
Iter: 223 loss: 0.0026424618
Iter: 224 loss: 0.00261047925
Iter: 225 loss: 0.00267165853
Iter: 226 loss: 0.00259682769
Iter: 227 loss: 0.00257947575
Iter: 228 loss: 0.00287310174
Iter: 229 loss: 0.00257947575
Iter: 230 loss: 0.0025685539
Iter: 231 loss: 0.00255283
Iter: 232 loss: 0.00255238963
Iter: 233 loss: 0.00252979272
Iter: 234 loss: 0.00253388495
Iter: 235 loss: 0.00251286919
Iter: 236 loss: 0.00249769143
Iter: 237 loss: 0.00252171047
Iter: 238 loss: 0.00249056146
Iter: 239 loss: 0.00247841259
Iter: 240 loss: 0.00266386801
Iter: 241 loss: 0.0024783765
Iter: 242 loss: 0.00246789819
Iter: 243 loss: 0.00246543111
Iter: 244 loss: 0.00245879078
Iter: 245 loss: 0.00244956091
Iter: 246 loss: 0.00244950876
Iter: 247 loss: 0.0024444703
Iter: 248 loss: 0.00243865233
Iter: 249 loss: 0.00243794289
Iter: 250 loss: 0.00242923223
Iter: 251 loss: 0.00242610229
Iter: 252 loss: 0.00241170661
Iter: 253 loss: 0.00245477865
Iter: 254 loss: 0.00240747351
Iter: 255 loss: 0.00240331842
Iter: 256 loss: 0.00239712233
Iter: 257 loss: 0.00239697238
Iter: 258 loss: 0.00239220192
Iter: 259 loss: 0.00238813553
Iter: 260 loss: 0.00238683098
Iter: 261 loss: 0.00237737922
Iter: 262 loss: 0.00236154045
Iter: 263 loss: 0.00236150064
Iter: 264 loss: 0.00233634049
Iter: 265 loss: 0.00263724383
Iter: 266 loss: 0.00233605178
Iter: 267 loss: 0.0023162656
Iter: 268 loss: 0.00238799816
Iter: 269 loss: 0.00231117732
Iter: 270 loss: 0.00229639444
Iter: 271 loss: 0.00231462577
Iter: 272 loss: 0.0022885846
Iter: 273 loss: 0.00227558706
Iter: 274 loss: 0.00227176398
Iter: 275 loss: 0.00226398883
Iter: 276 loss: 0.00227720244
Iter: 277 loss: 0.00225762324
Iter: 278 loss: 0.00225016964
Iter: 279 loss: 0.00223288662
Iter: 280 loss: 0.00243637944
Iter: 281 loss: 0.00223151478
Iter: 282 loss: 0.0022211615
Iter: 283 loss: 0.00221841829
Iter: 284 loss: 0.00220985245
Iter: 285 loss: 0.00225575408
Iter: 286 loss: 0.00220849738
Iter: 287 loss: 0.00220158789
Iter: 288 loss: 0.00221446715
Iter: 289 loss: 0.00219875248
Iter: 290 loss: 0.00219216943
Iter: 291 loss: 0.00218991679
Iter: 292 loss: 0.00218610885
Iter: 293 loss: 0.00217429595
Iter: 294 loss: 0.00217972067
Iter: 295 loss: 0.00216630194
Iter: 296 loss: 0.00215835962
Iter: 297 loss: 0.00214539305
Iter: 298 loss: 0.00214531436
Iter: 299 loss: 0.00213028211
Iter: 300 loss: 0.00215661642
Iter: 301 loss: 0.00212367252
Iter: 302 loss: 0.00211229455
Iter: 303 loss: 0.002122937
Iter: 304 loss: 0.0021056172
Iter: 305 loss: 0.00209607487
Iter: 306 loss: 0.00209336122
Iter: 307 loss: 0.00208758726
Iter: 308 loss: 0.00206933962
Iter: 309 loss: 0.00216179108
Iter: 310 loss: 0.00206631166
Iter: 311 loss: 0.00204853
Iter: 312 loss: 0.00210567843
Iter: 313 loss: 0.00204350776
Iter: 314 loss: 0.00203466089
Iter: 315 loss: 0.00203465787
Iter: 316 loss: 0.00202887645
Iter: 317 loss: 0.00202566432
Iter: 318 loss: 0.00202316837
Iter: 319 loss: 0.0020153448
Iter: 320 loss: 0.00204875832
Iter: 321 loss: 0.0020135548
Iter: 322 loss: 0.00201034313
Iter: 323 loss: 0.00200281036
Iter: 324 loss: 0.00209251093
Iter: 325 loss: 0.00200217706
Iter: 326 loss: 0.00199299026
Iter: 327 loss: 0.00211321469
Iter: 328 loss: 0.0019929097
Iter: 329 loss: 0.00198508753
Iter: 330 loss: 0.00198042253
Iter: 331 loss: 0.00197716709
Iter: 332 loss: 0.00196986319
Iter: 333 loss: 0.00196757913
Iter: 334 loss: 0.00196319213
Iter: 335 loss: 0.00195447472
Iter: 336 loss: 0.00194792857
Iter: 337 loss: 0.00194513588
Iter: 338 loss: 0.00193379913
Iter: 339 loss: 0.00194943883
Iter: 340 loss: 0.00192828523
Iter: 341 loss: 0.00190909067
Iter: 342 loss: 0.00194960902
Iter: 343 loss: 0.00190143648
Iter: 344 loss: 0.00188703393
Iter: 345 loss: 0.00195810455
Iter: 346 loss: 0.00188440457
Iter: 347 loss: 0.00187889
Iter: 348 loss: 0.00187881803
Iter: 349 loss: 0.00187460077
Iter: 350 loss: 0.00188943953
Iter: 351 loss: 0.00187347142
Iter: 352 loss: 0.00186833355
Iter: 353 loss: 0.00186048506
Iter: 354 loss: 0.00186035456
Iter: 355 loss: 0.00185055984
Iter: 356 loss: 0.00184863841
Iter: 357 loss: 0.0018421649
Iter: 358 loss: 0.00183648267
Iter: 359 loss: 0.00188073213
Iter: 360 loss: 0.0018361042
Iter: 361 loss: 0.00182919961
Iter: 362 loss: 0.00183344819
Iter: 363 loss: 0.00182478223
Iter: 364 loss: 0.00181577925
Iter: 365 loss: 0.00186624611
Iter: 366 loss: 0.00181458809
Iter: 367 loss: 0.00180888805
Iter: 368 loss: 0.00184531952
Iter: 369 loss: 0.00180817384
Iter: 370 loss: 0.00180408498
Iter: 371 loss: 0.00179622893
Iter: 372 loss: 0.00196782034
Iter: 373 loss: 0.00179619237
Iter: 374 loss: 0.00178286945
Iter: 375 loss: 0.00185889425
Iter: 376 loss: 0.00178106269
Iter: 377 loss: 0.00176833069
Iter: 378 loss: 0.00176949683
Iter: 379 loss: 0.00175856752
Iter: 380 loss: 0.00174694252
Iter: 381 loss: 0.00179451564
Iter: 382 loss: 0.00174416078
Iter: 383 loss: 0.00173976202
Iter: 384 loss: 0.00173077593
Iter: 385 loss: 0.00189656415
Iter: 386 loss: 0.0017306197
Iter: 387 loss: 0.00172076747
Iter: 388 loss: 0.00181067537
Iter: 389 loss: 0.00172028888
Iter: 390 loss: 0.00171060243
Iter: 391 loss: 0.00185633264
Iter: 392 loss: 0.00171060406
Iter: 393 loss: 0.00170652417
Iter: 394 loss: 0.00170353637
Iter: 395 loss: 0.00170211145
Iter: 396 loss: 0.00169606891
Iter: 397 loss: 0.00169263419
Iter: 398 loss: 0.0016900904
Iter: 399 loss: 0.00168380945
Iter: 400 loss: 0.00172334793
Iter: 401 loss: 0.00168304297
Iter: 402 loss: 0.00167845585
Iter: 403 loss: 0.00167767017
Iter: 404 loss: 0.00167457247
Iter: 405 loss: 0.00166260696
Iter: 406 loss: 0.0016393814
Iter: 407 loss: 0.00210843282
Iter: 408 loss: 0.00163921691
Iter: 409 loss: 0.00162352226
Iter: 410 loss: 0.00162290409
Iter: 411 loss: 0.00161300227
Iter: 412 loss: 0.00169754238
Iter: 413 loss: 0.00161240017
Iter: 414 loss: 0.00160683901
Iter: 415 loss: 0.00160679501
Iter: 416 loss: 0.00160278799
Iter: 417 loss: 0.0015952189
Iter: 418 loss: 0.00177238509
Iter: 419 loss: 0.00159519853
Iter: 420 loss: 0.00158618484
Iter: 421 loss: 0.00159512309
Iter: 422 loss: 0.00158120436
Iter: 423 loss: 0.00157436938
Iter: 424 loss: 0.00158747821
Iter: 425 loss: 0.00157142221
Iter: 426 loss: 0.00156441424
Iter: 427 loss: 0.00155641395
Iter: 428 loss: 0.00155538553
Iter: 429 loss: 0.00154698966
Iter: 430 loss: 0.00154691935
Iter: 431 loss: 0.00154460617
Iter: 432 loss: 0.00154410873
Iter: 433 loss: 0.00154029601
Iter: 434 loss: 0.00153603731
Iter: 435 loss: 0.00153544173
Iter: 436 loss: 0.00152952631
Iter: 437 loss: 0.00152194535
Iter: 438 loss: 0.00152139633
Iter: 439 loss: 0.00151339697
Iter: 440 loss: 0.00151508104
Iter: 441 loss: 0.00150754536
Iter: 442 loss: 0.00149929011
Iter: 443 loss: 0.0014952817
Iter: 444 loss: 0.00149127515
Iter: 445 loss: 0.00149557553
Iter: 446 loss: 0.00148673297
Iter: 447 loss: 0.00148263178
Iter: 448 loss: 0.00149219041
Iter: 449 loss: 0.00148105226
Iter: 450 loss: 0.0014773648
Iter: 451 loss: 0.00146878965
Iter: 452 loss: 0.00156887947
Iter: 453 loss: 0.00146809849
Iter: 454 loss: 0.00145990576
Iter: 455 loss: 0.00146693888
Iter: 456 loss: 0.00145503506
Iter: 457 loss: 0.00144421565
Iter: 458 loss: 0.00146108749
Iter: 459 loss: 0.00143915159
Iter: 460 loss: 0.00143163605
Iter: 461 loss: 0.00150151178
Iter: 462 loss: 0.00143129588
Iter: 463 loss: 0.00142581132
Iter: 464 loss: 0.00141398236
Iter: 465 loss: 0.00159811135
Iter: 466 loss: 0.0014135479
Iter: 467 loss: 0.00140032382
Iter: 468 loss: 0.00148506719
Iter: 469 loss: 0.00139887969
Iter: 470 loss: 0.0013923957
Iter: 471 loss: 0.00144600985
Iter: 472 loss: 0.00139202038
Iter: 473 loss: 0.00138842314
Iter: 474 loss: 0.00138842
Iter: 475 loss: 0.00138614606
Iter: 476 loss: 0.00138074218
Iter: 477 loss: 0.00144533534
Iter: 478 loss: 0.00138025009
Iter: 479 loss: 0.00137472432
Iter: 480 loss: 0.00143996126
Iter: 481 loss: 0.00137465179
Iter: 482 loss: 0.00137056026
Iter: 483 loss: 0.0013705357
Iter: 484 loss: 0.0013672458
Iter: 485 loss: 0.00136095216
Iter: 486 loss: 0.0014440564
Iter: 487 loss: 0.0013609333
Iter: 488 loss: 0.00135834981
Iter: 489 loss: 0.00135475327
Iter: 490 loss: 0.00135459565
Iter: 491 loss: 0.00134885113
Iter: 492 loss: 0.00135283137
Iter: 493 loss: 0.00134528207
Iter: 494 loss: 0.00133901509
Iter: 495 loss: 0.00133292819
Iter: 496 loss: 0.00133159431
Iter: 497 loss: 0.0013200962
Iter: 498 loss: 0.00139877282
Iter: 499 loss: 0.00131901167
Iter: 500 loss: 0.00130959146
Iter: 501 loss: 0.00136567932
Iter: 502 loss: 0.00130833534
Iter: 503 loss: 0.00130009116
Iter: 504 loss: 0.00130730367
Iter: 505 loss: 0.0012952087
Iter: 506 loss: 0.00129795587
Iter: 507 loss: 0.00129270868
Iter: 508 loss: 0.00129025162
Iter: 509 loss: 0.00129084778
Iter: 510 loss: 0.00128846045
Iter: 511 loss: 0.00128630968
Iter: 512 loss: 0.00128797
Iter: 513 loss: 0.00128498324
Iter: 514 loss: 0.00128088298
Iter: 515 loss: 0.0012905692
Iter: 516 loss: 0.0012793967
Iter: 517 loss: 0.00127633056
Iter: 518 loss: 0.00132336118
Iter: 519 loss: 0.00127632404
Iter: 520 loss: 0.00127470167
Iter: 521 loss: 0.00127507374
Iter: 522 loss: 0.00127351866
Iter: 523 loss: 0.00127112214
Iter: 524 loss: 0.00126876263
Iter: 525 loss: 0.00126824994
Iter: 526 loss: 0.00126383826
Iter: 527 loss: 0.00126794749
Iter: 528 loss: 0.00126126769
Iter: 529 loss: 0.00125495275
Iter: 530 loss: 0.00125912356
Iter: 531 loss: 0.0012509746
Iter: 532 loss: 0.00124313287
Iter: 533 loss: 0.0012770819
Iter: 534 loss: 0.00124150096
Iter: 535 loss: 0.00123391813
Iter: 536 loss: 0.00127218268
Iter: 537 loss: 0.00123261684
Iter: 538 loss: 0.00122876128
Iter: 539 loss: 0.00125199091
Iter: 540 loss: 0.00122830295
Iter: 541 loss: 0.00122279581
Iter: 542 loss: 0.00123790011
Iter: 543 loss: 0.00122095423
Iter: 544 loss: 0.00121843768
Iter: 545 loss: 0.00121363369
Iter: 546 loss: 0.00131367135
Iter: 547 loss: 0.00121361134
Iter: 548 loss: 0.00120963866
Iter: 549 loss: 0.00126604806
Iter: 550 loss: 0.00120962318
Iter: 551 loss: 0.00120674632
Iter: 552 loss: 0.00120406318
Iter: 553 loss: 0.00120338239
Iter: 554 loss: 0.00119853532
Iter: 555 loss: 0.00121182785
Iter: 556 loss: 0.00119688699
Iter: 557 loss: 0.00119201047
Iter: 558 loss: 0.00119159278
Iter: 559 loss: 0.00118796714
Iter: 560 loss: 0.00118286069
Iter: 561 loss: 0.00119415112
Iter: 562 loss: 0.00118088338
Iter: 563 loss: 0.00117589277
Iter: 564 loss: 0.00117731187
Iter: 565 loss: 0.00117230951
Iter: 566 loss: 0.00116624846
Iter: 567 loss: 0.00117207668
Iter: 568 loss: 0.00116277905
Iter: 569 loss: 0.00115630811
Iter: 570 loss: 0.0012032974
Iter: 571 loss: 0.00115569239
Iter: 572 loss: 0.00114946975
Iter: 573 loss: 0.0011557187
Iter: 574 loss: 0.00114593492
Iter: 575 loss: 0.00115262286
Iter: 576 loss: 0.00114427763
Iter: 577 loss: 0.00114261941
Iter: 578 loss: 0.00113789167
Iter: 579 loss: 0.00116226787
Iter: 580 loss: 0.00113627478
Iter: 581 loss: 0.00113182887
Iter: 582 loss: 0.00113766466
Iter: 583 loss: 0.00112962036
Iter: 584 loss: 0.00112714153
Iter: 585 loss: 0.00112217548
Iter: 586 loss: 0.00121900137
Iter: 587 loss: 0.00112211308
Iter: 588 loss: 0.00111742294
Iter: 589 loss: 0.00113795453
Iter: 590 loss: 0.00111649756
Iter: 591 loss: 0.00111206737
Iter: 592 loss: 0.00114756823
Iter: 593 loss: 0.00111173652
Iter: 594 loss: 0.00110684894
Iter: 595 loss: 0.00113491574
Iter: 596 loss: 0.00110620633
Iter: 597 loss: 0.00110077846
Iter: 598 loss: 0.00110848888
Iter: 599 loss: 0.0010980675
Iter: 600 loss: 0.00109307712
Iter: 601 loss: 0.0010965243
Iter: 602 loss: 0.00108993344
Iter: 603 loss: 0.001082459
Iter: 604 loss: 0.0010912657
Iter: 605 loss: 0.0010784578
Iter: 606 loss: 0.00106895703
Iter: 607 loss: 0.00110865105
Iter: 608 loss: 0.00106689311
Iter: 609 loss: 0.00106138689
Iter: 610 loss: 0.00108773354
Iter: 611 loss: 0.00106034125
Iter: 612 loss: 0.00105758477
Iter: 613 loss: 0.00105714309
Iter: 614 loss: 0.00105591584
Iter: 615 loss: 0.00105413527
Iter: 616 loss: 0.00105408055
Iter: 617 loss: 0.00105112814
Iter: 618 loss: 0.00104389817
Iter: 619 loss: 0.00111736613
Iter: 620 loss: 0.00104302703
Iter: 621 loss: 0.00103820197
Iter: 622 loss: 0.00105657359
Iter: 623 loss: 0.00103702664
Iter: 624 loss: 0.00103177968
Iter: 625 loss: 0.00103803526
Iter: 626 loss: 0.00102898432
Iter: 627 loss: 0.00102516264
Iter: 628 loss: 0.00104056112
Iter: 629 loss: 0.00102427963
Iter: 630 loss: 0.00101956748
Iter: 631 loss: 0.00102622632
Iter: 632 loss: 0.00101723953
Iter: 633 loss: 0.00101250317
Iter: 634 loss: 0.00104083191
Iter: 635 loss: 0.00101190468
Iter: 636 loss: 0.00100846891
Iter: 637 loss: 0.00102161942
Iter: 638 loss: 0.00100765389
Iter: 639 loss: 0.00100301509
Iter: 640 loss: 0.00100119261
Iter: 641 loss: 0.000998687
Iter: 642 loss: 0.000994412461
Iter: 643 loss: 0.00105944858
Iter: 644 loss: 0.000994413509
Iter: 645 loss: 0.000992866931
Iter: 646 loss: 0.000992630376
Iter: 647 loss: 0.000991062843
Iter: 648 loss: 0.000993565
Iter: 649 loss: 0.000990351
Iter: 650 loss: 0.000988766551
Iter: 651 loss: 0.000985141844
Iter: 652 loss: 0.00103304489
Iter: 653 loss: 0.000984909711
Iter: 654 loss: 0.00098214
Iter: 655 loss: 0.000991432
Iter: 656 loss: 0.000981393
Iter: 657 loss: 0.000978566823
Iter: 658 loss: 0.000982036348
Iter: 659 loss: 0.000977102201
Iter: 660 loss: 0.000974371098
Iter: 661 loss: 0.00098047452
Iter: 662 loss: 0.000973340939
Iter: 663 loss: 0.00096974062
Iter: 664 loss: 0.000964888197
Iter: 665 loss: 0.000964630162
Iter: 666 loss: 0.000959626865
Iter: 667 loss: 0.000995767419
Iter: 668 loss: 0.000959194731
Iter: 669 loss: 0.000954654766
Iter: 670 loss: 0.000972973183
Iter: 671 loss: 0.000953614071
Iter: 672 loss: 0.000949281326
Iter: 673 loss: 0.000947124616
Iter: 674 loss: 0.000945075182
Iter: 675 loss: 0.000939603546
Iter: 676 loss: 0.000960246776
Iter: 677 loss: 0.000938226411
Iter: 678 loss: 0.00094629667
Iter: 679 loss: 0.000937134493
Iter: 680 loss: 0.000936154858
Iter: 681 loss: 0.000937411503
Iter: 682 loss: 0.000935654214
Iter: 683 loss: 0.000934217824
Iter: 684 loss: 0.000933619216
Iter: 685 loss: 0.000932866649
Iter: 686 loss: 0.00093078753
Iter: 687 loss: 0.00093284715
Iter: 688 loss: 0.000929623668
Iter: 689 loss: 0.000927478657
Iter: 690 loss: 0.000927429181
Iter: 691 loss: 0.000925739179
Iter: 692 loss: 0.000923670945
Iter: 693 loss: 0.000917597674
Iter: 694 loss: 0.000939068967
Iter: 695 loss: 0.000914906734
Iter: 696 loss: 0.000907118898
Iter: 697 loss: 0.000946170301
Iter: 698 loss: 0.000905772
Iter: 699 loss: 0.000899418665
Iter: 700 loss: 0.000941781327
Iter: 701 loss: 0.000898726285
Iter: 702 loss: 0.000895202393
Iter: 703 loss: 0.000894613157
Iter: 704 loss: 0.000892205746
Iter: 705 loss: 0.000889023533
Iter: 706 loss: 0.000885697198
Iter: 707 loss: 0.000885105925
Iter: 708 loss: 0.000880787557
Iter: 709 loss: 0.000928799796
Iter: 710 loss: 0.000880718173
Iter: 711 loss: 0.000878793187
Iter: 712 loss: 0.000880339823
Iter: 713 loss: 0.000877627404
Iter: 714 loss: 0.00087498693
Iter: 715 loss: 0.000889759802
Iter: 716 loss: 0.000874625577
Iter: 717 loss: 0.000873132376
Iter: 718 loss: 0.000872576493
Iter: 719 loss: 0.000871756813
Iter: 720 loss: 0.00087151461
Iter: 721 loss: 0.000870220247
Iter: 722 loss: 0.00086856744
Iter: 723 loss: 0.000874656427
Iter: 724 loss: 0.000868155039
Iter: 725 loss: 0.000866679125
Iter: 726 loss: 0.000862437184
Iter: 727 loss: 0.000880866195
Iter: 728 loss: 0.000860831293
Iter: 729 loss: 0.000855097314
Iter: 730 loss: 0.000904782792
Iter: 731 loss: 0.000854770362
Iter: 732 loss: 0.000851041812
Iter: 733 loss: 0.000872028177
Iter: 734 loss: 0.000850519282
Iter: 735 loss: 0.000846826
Iter: 736 loss: 0.000896485464
Iter: 737 loss: 0.000846814306
Iter: 738 loss: 0.000844803697
Iter: 739 loss: 0.000846001203
Iter: 740 loss: 0.000843497925
Iter: 741 loss: 0.000841833942
Iter: 742 loss: 0.000843647053
Iter: 743 loss: 0.000840936205
Iter: 744 loss: 0.000839655346
Iter: 745 loss: 0.000841922243
Iter: 746 loss: 0.000839088
Iter: 747 loss: 0.000838036649
Iter: 748 loss: 0.000846733572
Iter: 749 loss: 0.000837975764
Iter: 750 loss: 0.000836732
Iter: 751 loss: 0.000835998682
Iter: 752 loss: 0.000835479528
Iter: 753 loss: 0.000834313279
Iter: 754 loss: 0.000836903346
Iter: 755 loss: 0.000833869213
Iter: 756 loss: 0.000832550519
Iter: 757 loss: 0.000842947047
Iter: 758 loss: 0.000832456863
Iter: 759 loss: 0.000831624086
Iter: 760 loss: 0.00083037687
Iter: 761 loss: 0.00083035056
Iter: 762 loss: 0.000828976568
Iter: 763 loss: 0.000830447418
Iter: 764 loss: 0.000828222721
Iter: 765 loss: 0.000827035343
Iter: 766 loss: 0.000826087315
Iter: 767 loss: 0.000825724448
Iter: 768 loss: 0.000824333518
Iter: 769 loss: 0.000824246323
Iter: 770 loss: 0.000822993345
Iter: 771 loss: 0.000827085634
Iter: 772 loss: 0.000822645496
Iter: 773 loss: 0.00082148076
Iter: 774 loss: 0.000829544268
Iter: 775 loss: 0.000821363
Iter: 776 loss: 0.000820547924
Iter: 777 loss: 0.000820357352
Iter: 778 loss: 0.000819837907
Iter: 779 loss: 0.000819018693
Iter: 780 loss: 0.000825295108
Iter: 781 loss: 0.000818956294
Iter: 782 loss: 0.00081822474
Iter: 783 loss: 0.000818978529
Iter: 784 loss: 0.000817820546
Iter: 785 loss: 0.000817139633
Iter: 786 loss: 0.000817701279
Iter: 787 loss: 0.00081673183
Iter: 788 loss: 0.000816183281
Iter: 789 loss: 0.000816173
Iter: 790 loss: 0.000815866806
Iter: 791 loss: 0.000815066509
Iter: 792 loss: 0.000821341877
Iter: 793 loss: 0.000814912783
Iter: 794 loss: 0.000813700724
Iter: 795 loss: 0.000813882682
Iter: 796 loss: 0.000812783255
Iter: 797 loss: 0.000810910482
Iter: 798 loss: 0.000810468
Iter: 799 loss: 0.000809263554
Iter: 800 loss: 0.000806617725
Iter: 801 loss: 0.000805214513
Iter: 802 loss: 0.000804025563
Iter: 803 loss: 0.000802218274
Iter: 804 loss: 0.000823977869
Iter: 805 loss: 0.000802191847
Iter: 806 loss: 0.000801043527
Iter: 807 loss: 0.000801545044
Iter: 808 loss: 0.00080026919
Iter: 809 loss: 0.000798896072
Iter: 810 loss: 0.000802467577
Iter: 811 loss: 0.000798422669
Iter: 812 loss: 0.00079717912
Iter: 813 loss: 0.000795937376
Iter: 814 loss: 0.000795688131
Iter: 815 loss: 0.000793727697
Iter: 816 loss: 0.000803137198
Iter: 817 loss: 0.000793377
Iter: 818 loss: 0.000792206149
Iter: 819 loss: 0.000799369649
Iter: 820 loss: 0.00079206482
Iter: 821 loss: 0.000791231578
Iter: 822 loss: 0.000796479406
Iter: 823 loss: 0.000791132334
Iter: 824 loss: 0.000790072605
Iter: 825 loss: 0.00078730355
Iter: 826 loss: 0.00080801954
Iter: 827 loss: 0.000786750694
Iter: 828 loss: 0.000783978
Iter: 829 loss: 0.000786568213
Iter: 830 loss: 0.000782378484
Iter: 831 loss: 0.000778456335
Iter: 832 loss: 0.000783040305
Iter: 833 loss: 0.00077635597
Iter: 834 loss: 0.000773774344
Iter: 835 loss: 0.000792471
Iter: 836 loss: 0.000773538952
Iter: 837 loss: 0.000771980151
Iter: 838 loss: 0.000771980966
Iter: 839 loss: 0.000770567101
Iter: 840 loss: 0.000786868273
Iter: 841 loss: 0.000770537066
Iter: 842 loss: 0.000769951264
Iter: 843 loss: 0.000768872
Iter: 844 loss: 0.000793218962
Iter: 845 loss: 0.000768870697
Iter: 846 loss: 0.000766974059
Iter: 847 loss: 0.000777501322
Iter: 848 loss: 0.000766694196
Iter: 849 loss: 0.000765348901
Iter: 850 loss: 0.000766969461
Iter: 851 loss: 0.000764642842
Iter: 852 loss: 0.000762910582
Iter: 853 loss: 0.000766300596
Iter: 854 loss: 0.000762193638
Iter: 855 loss: 0.000760394207
Iter: 856 loss: 0.000763820542
Iter: 857 loss: 0.000759647519
Iter: 858 loss: 0.000757004
Iter: 859 loss: 0.000764588884
Iter: 860 loss: 0.000756157
Iter: 861 loss: 0.000754838518
Iter: 862 loss: 0.000751972548
Iter: 863 loss: 0.000794401742
Iter: 864 loss: 0.000751851
Iter: 865 loss: 0.00074822281
Iter: 866 loss: 0.000760014751
Iter: 867 loss: 0.000747187354
Iter: 868 loss: 0.000743940356
Iter: 869 loss: 0.000752937107
Iter: 870 loss: 0.000742897275
Iter: 871 loss: 0.000739965937
Iter: 872 loss: 0.000756165595
Iter: 873 loss: 0.000739534502
Iter: 874 loss: 0.000738121103
Iter: 875 loss: 0.000738004281
Iter: 876 loss: 0.000737175345
Iter: 877 loss: 0.000735973474
Iter: 878 loss: 0.000735936221
Iter: 879 loss: 0.00073428324
Iter: 880 loss: 0.000743782613
Iter: 881 loss: 0.000734066823
Iter: 882 loss: 0.000732614601
Iter: 883 loss: 0.000733812863
Iter: 884 loss: 0.000731739856
Iter: 885 loss: 0.000730173
Iter: 886 loss: 0.000730939268
Iter: 887 loss: 0.000729119929
Iter: 888 loss: 0.000727547333
Iter: 889 loss: 0.000735299196
Iter: 890 loss: 0.00072727
Iter: 891 loss: 0.000726034
Iter: 892 loss: 0.000731210399
Iter: 893 loss: 0.00072577165
Iter: 894 loss: 0.000724786485
Iter: 895 loss: 0.000722021679
Iter: 896 loss: 0.000736071204
Iter: 897 loss: 0.000721124932
Iter: 898 loss: 0.000718109193
Iter: 899 loss: 0.000721824239
Iter: 900 loss: 0.00071652513
Iter: 901 loss: 0.000713684247
Iter: 902 loss: 0.000733072404
Iter: 903 loss: 0.000713387737
Iter: 904 loss: 0.000710572058
Iter: 905 loss: 0.000708275707
Iter: 906 loss: 0.000707443338
Iter: 907 loss: 0.000714221736
Iter: 908 loss: 0.000706774183
Iter: 909 loss: 0.000706030463
Iter: 910 loss: 0.000706285238
Iter: 911 loss: 0.000705501938
Iter: 912 loss: 0.000704500242
Iter: 913 loss: 0.000703260186
Iter: 914 loss: 0.000703152909
Iter: 915 loss: 0.000701351208
Iter: 916 loss: 0.000700284785
Iter: 917 loss: 0.000699535653
Iter: 918 loss: 0.000697893673
Iter: 919 loss: 0.000697098556
Iter: 920 loss: 0.000696577656
Iter: 921 loss: 0.000696333358
Iter: 922 loss: 0.000696075382
Iter: 923 loss: 0.000694526767
Iter: 924 loss: 0.000694186427
Iter: 925 loss: 0.00069317664
Iter: 926 loss: 0.000690818764
Iter: 927 loss: 0.000693032
Iter: 928 loss: 0.000689477543
Iter: 929 loss: 0.000687192
Iter: 930 loss: 0.000687320484
Iter: 931 loss: 0.000685384264
Iter: 932 loss: 0.000683154329
Iter: 933 loss: 0.000688393426
Iter: 934 loss: 0.000682338839
Iter: 935 loss: 0.000680527766
Iter: 936 loss: 0.000682747399
Iter: 937 loss: 0.000679585675
Iter: 938 loss: 0.00067739666
Iter: 939 loss: 0.000689070555
Iter: 940 loss: 0.000677063712
Iter: 941 loss: 0.000677284843
Iter: 942 loss: 0.000676555559
Iter: 943 loss: 0.000675872259
Iter: 944 loss: 0.000673896
Iter: 945 loss: 0.000682188722
Iter: 946 loss: 0.00067311
Iter: 947 loss: 0.000671086425
Iter: 948 loss: 0.000685184961
Iter: 949 loss: 0.00067090732
Iter: 950 loss: 0.000670246489
Iter: 951 loss: 0.000678055512
Iter: 952 loss: 0.000670234789
Iter: 953 loss: 0.000669691828
Iter: 954 loss: 0.000668452354
Iter: 955 loss: 0.00068491
Iter: 956 loss: 0.000668371213
Iter: 957 loss: 0.000666036969
Iter: 958 loss: 0.000673736562
Iter: 959 loss: 0.000665389
Iter: 960 loss: 0.000663062849
Iter: 961 loss: 0.000689765962
Iter: 962 loss: 0.000663026
Iter: 963 loss: 0.000661662489
Iter: 964 loss: 0.000660127844
Iter: 965 loss: 0.000659919
Iter: 966 loss: 0.000658286328
Iter: 967 loss: 0.000657718861
Iter: 968 loss: 0.000656796969
Iter: 969 loss: 0.00065380719
Iter: 970 loss: 0.000657523051
Iter: 971 loss: 0.000652245129
Iter: 972 loss: 0.000648762332
Iter: 973 loss: 0.000664550927
Iter: 974 loss: 0.000648125308
Iter: 975 loss: 0.000645996246
Iter: 976 loss: 0.000675831
Iter: 977 loss: 0.000645990716
Iter: 978 loss: 0.00064454152
Iter: 979 loss: 0.000644536573
Iter: 980 loss: 0.000643535284
Iter: 981 loss: 0.000641223101
Iter: 982 loss: 0.000671367452
Iter: 983 loss: 0.000641057
Iter: 984 loss: 0.000640277169
Iter: 985 loss: 0.000639746
Iter: 986 loss: 0.000638874
Iter: 987 loss: 0.000636799494
Iter: 988 loss: 0.000660498161
Iter: 989 loss: 0.000636606128
Iter: 990 loss: 0.000634040451
Iter: 991 loss: 0.000636063865
Iter: 992 loss: 0.000632480485
Iter: 993 loss: 0.000631119241
Iter: 994 loss: 0.000630957657
Iter: 995 loss: 0.000629462593
Iter: 996 loss: 0.000631960109
Iter: 997 loss: 0.000628788373
Iter: 998 loss: 0.000627471833
Iter: 999 loss: 0.000624727109
Iter: 1000 loss: 0.000672369148
Iter: 1001 loss: 0.0006246618
Iter: 1002 loss: 0.000622327963
Iter: 1003 loss: 0.000634523691
Iter: 1004 loss: 0.000621961604
Iter: 1005 loss: 0.000620280043
Iter: 1006 loss: 0.000634222408
Iter: 1007 loss: 0.000620176666
Iter: 1008 loss: 0.000618636725
Iter: 1009 loss: 0.000616346
Iter: 1010 loss: 0.000616292062
Iter: 1011 loss: 0.000622121966
Iter: 1012 loss: 0.000615632278
Iter: 1013 loss: 0.000615121098
Iter: 1014 loss: 0.00061547471
Iter: 1015 loss: 0.000614797696
Iter: 1016 loss: 0.000614174583
Iter: 1017 loss: 0.000613912358
Iter: 1018 loss: 0.000613588374
Iter: 1019 loss: 0.00061186729
Iter: 1020 loss: 0.000611073687
Iter: 1021 loss: 0.000610209885
Iter: 1022 loss: 0.000609037699
Iter: 1023 loss: 0.000610581483
Iter: 1024 loss: 0.000608442351
Iter: 1025 loss: 0.000607091584
Iter: 1026 loss: 0.000615057943
Iter: 1027 loss: 0.00060691149
Iter: 1028 loss: 0.000605552807
Iter: 1029 loss: 0.000616442412
Iter: 1030 loss: 0.000605464622
Iter: 1031 loss: 0.000604815548
Iter: 1032 loss: 0.000602849759
Iter: 1033 loss: 0.000608247123
Iter: 1034 loss: 0.000601810403
Iter: 1035 loss: 0.000599365332
Iter: 1036 loss: 0.000615976169
Iter: 1037 loss: 0.000599129
Iter: 1038 loss: 0.000597100123
Iter: 1039 loss: 0.000597199076
Iter: 1040 loss: 0.000595509773
Iter: 1041 loss: 0.000592868659
Iter: 1042 loss: 0.000606417772
Iter: 1043 loss: 0.000592436234
Iter: 1044 loss: 0.000593364588
Iter: 1045 loss: 0.000591650372
Iter: 1046 loss: 0.000590974814
Iter: 1047 loss: 0.000591272663
Iter: 1048 loss: 0.000590512063
Iter: 1049 loss: 0.000589866773
Iter: 1050 loss: 0.000591672
Iter: 1051 loss: 0.000589664094
Iter: 1052 loss: 0.00058896956
Iter: 1053 loss: 0.000589545292
Iter: 1054 loss: 0.000588550698
Iter: 1055 loss: 0.000587775372
Iter: 1056 loss: 0.00058660307
Iter: 1057 loss: 0.000586580602
Iter: 1058 loss: 0.000584856258
Iter: 1059 loss: 0.000587271061
Iter: 1060 loss: 0.000584006542
Iter: 1061 loss: 0.000583861955
Iter: 1062 loss: 0.000582989538
Iter: 1063 loss: 0.000582038308
Iter: 1064 loss: 0.000580112101
Iter: 1065 loss: 0.000617003359
Iter: 1066 loss: 0.000580084336
Iter: 1067 loss: 0.000578634674
Iter: 1068 loss: 0.000576901773
Iter: 1069 loss: 0.000576724822
Iter: 1070 loss: 0.000574490405
Iter: 1071 loss: 0.000595507445
Iter: 1072 loss: 0.00057440059
Iter: 1073 loss: 0.000572400924
Iter: 1074 loss: 0.000580324908
Iter: 1075 loss: 0.000571939105
Iter: 1076 loss: 0.000570585951
Iter: 1077 loss: 0.000578897
Iter: 1078 loss: 0.000570419128
Iter: 1079 loss: 0.000568956719
Iter: 1080 loss: 0.000589582312
Iter: 1081 loss: 0.000568955
Iter: 1082 loss: 0.000568207528
Iter: 1083 loss: 0.000567784882
Iter: 1084 loss: 0.00056745857
Iter: 1085 loss: 0.000566512463
Iter: 1086 loss: 0.000572889
Iter: 1087 loss: 0.000566423114
Iter: 1088 loss: 0.000565813505
Iter: 1089 loss: 0.000564233458
Iter: 1090 loss: 0.000577145
Iter: 1091 loss: 0.000563944574
Iter: 1092 loss: 0.000561977096
Iter: 1093 loss: 0.000565996626
Iter: 1094 loss: 0.000561177
Iter: 1095 loss: 0.000559665728
Iter: 1096 loss: 0.000563781708
Iter: 1097 loss: 0.000559165201
Iter: 1098 loss: 0.000558249885
Iter: 1099 loss: 0.000558213
Iter: 1100 loss: 0.000557363033
Iter: 1101 loss: 0.000556245563
Iter: 1102 loss: 0.000556175481
Iter: 1103 loss: 0.000554267608
Iter: 1104 loss: 0.000554517086
Iter: 1105 loss: 0.000552800077
Iter: 1106 loss: 0.000550531549
Iter: 1107 loss: 0.000556543353
Iter: 1108 loss: 0.000549770077
Iter: 1109 loss: 0.000548786309
Iter: 1110 loss: 0.000548489566
Iter: 1111 loss: 0.000548206794
Iter: 1112 loss: 0.000548130774
Iter: 1113 loss: 0.00054787792
Iter: 1114 loss: 0.00054786203
Iter: 1115 loss: 0.000547672389
Iter: 1116 loss: 0.000547331758
Iter: 1117 loss: 0.000548113661
Iter: 1118 loss: 0.000547205447
Iter: 1119 loss: 0.000546723721
Iter: 1120 loss: 0.000545307877
Iter: 1121 loss: 0.000550380908
Iter: 1122 loss: 0.000544674462
Iter: 1123 loss: 0.000543714268
Iter: 1124 loss: 0.000543710659
Iter: 1125 loss: 0.000542711583
Iter: 1126 loss: 0.000542400929
Iter: 1127 loss: 0.000541808316
Iter: 1128 loss: 0.00054115575
Iter: 1129 loss: 0.000548729673
Iter: 1130 loss: 0.000541145564
Iter: 1131 loss: 0.000540705048
Iter: 1132 loss: 0.000540211855
Iter: 1133 loss: 0.000540143927
Iter: 1134 loss: 0.000539132219
Iter: 1135 loss: 0.000538152352
Iter: 1136 loss: 0.000537927379
Iter: 1137 loss: 0.000537221844
Iter: 1138 loss: 0.000536994601
Iter: 1139 loss: 0.00053658348
Iter: 1140 loss: 0.000536129
Iter: 1141 loss: 0.000535433472
Iter: 1142 loss: 0.000535422
Iter: 1143 loss: 0.000534701627
Iter: 1144 loss: 0.000535909203
Iter: 1145 loss: 0.000534377294
Iter: 1146 loss: 0.00053377141
Iter: 1147 loss: 0.000536194653
Iter: 1148 loss: 0.000533638056
Iter: 1149 loss: 0.000533862039
Iter: 1150 loss: 0.000533253362
Iter: 1151 loss: 0.000533055456
Iter: 1152 loss: 0.000532440492
Iter: 1153 loss: 0.000533693878
Iter: 1154 loss: 0.000532054866
Iter: 1155 loss: 0.00053109962
Iter: 1156 loss: 0.000541164889
Iter: 1157 loss: 0.000531074533
Iter: 1158 loss: 0.000530453748
Iter: 1159 loss: 0.000530439313
Iter: 1160 loss: 0.000530067598
Iter: 1161 loss: 0.000533957616
Iter: 1162 loss: 0.000530058052
Iter: 1163 loss: 0.000529599609
Iter: 1164 loss: 0.000528555596
Iter: 1165 loss: 0.00054285751
Iter: 1166 loss: 0.000528491219
Iter: 1167 loss: 0.000527803786
Iter: 1168 loss: 0.000527412631
Iter: 1169 loss: 0.000527116121
Iter: 1170 loss: 0.000528177887
Iter: 1171 loss: 0.000526653719
Iter: 1172 loss: 0.000526158838
Iter: 1173 loss: 0.000525731884
Iter: 1174 loss: 0.000525596377
Iter: 1175 loss: 0.000525142357
Iter: 1176 loss: 0.000525090378
Iter: 1177 loss: 0.000524761213
Iter: 1178 loss: 0.000524408766
Iter: 1179 loss: 0.000523989554
Iter: 1180 loss: 0.000523944909
Iter: 1181 loss: 0.000523304683
Iter: 1182 loss: 0.000521740876
Iter: 1183 loss: 0.000537889893
Iter: 1184 loss: 0.000521557813
Iter: 1185 loss: 0.000519227644
Iter: 1186 loss: 0.000526660704
Iter: 1187 loss: 0.00051856
Iter: 1188 loss: 0.000516360393
Iter: 1189 loss: 0.000525517506
Iter: 1190 loss: 0.00051587366
Iter: 1191 loss: 0.0005145818
Iter: 1192 loss: 0.000517390727
Iter: 1193 loss: 0.00051407842
Iter: 1194 loss: 0.000512361818
Iter: 1195 loss: 0.000511123159
Iter: 1196 loss: 0.000510529149
Iter: 1197 loss: 0.000512855302
Iter: 1198 loss: 0.000509648
Iter: 1199 loss: 0.000508926
Iter: 1200 loss: 0.000507116842
Iter: 1201 loss: 0.000524409232
Iter: 1202 loss: 0.00050686032
Iter: 1203 loss: 0.000505653
Iter: 1204 loss: 0.000505226199
Iter: 1205 loss: 0.000504546217
Iter: 1206 loss: 0.000503858377
Iter: 1207 loss: 0.000503571704
Iter: 1208 loss: 0.000502937532
Iter: 1209 loss: 0.000505802571
Iter: 1210 loss: 0.000502817158
Iter: 1211 loss: 0.000502197421
Iter: 1212 loss: 0.000501217786
Iter: 1213 loss: 0.000501207716
Iter: 1214 loss: 0.000499557122
Iter: 1215 loss: 0.000501663424
Iter: 1216 loss: 0.000498719281
Iter: 1217 loss: 0.000497669564
Iter: 1218 loss: 0.000496677822
Iter: 1219 loss: 0.000496434164
Iter: 1220 loss: 0.000495745684
Iter: 1221 loss: 0.000495206565
Iter: 1222 loss: 0.000494608073
Iter: 1223 loss: 0.000495611108
Iter: 1224 loss: 0.000494340726
Iter: 1225 loss: 0.000493954227
Iter: 1226 loss: 0.000492990657
Iter: 1227 loss: 0.000502581242
Iter: 1228 loss: 0.000492861611
Iter: 1229 loss: 0.00049206
Iter: 1230 loss: 0.000492907944
Iter: 1231 loss: 0.00049161975
Iter: 1232 loss: 0.00049077
Iter: 1233 loss: 0.000491287909
Iter: 1234 loss: 0.000490221253
Iter: 1235 loss: 0.00048922823
Iter: 1236 loss: 0.000490136328
Iter: 1237 loss: 0.000488652033
Iter: 1238 loss: 0.000487343583
Iter: 1239 loss: 0.000494782114
Iter: 1240 loss: 0.000487169571
Iter: 1241 loss: 0.000486387959
Iter: 1242 loss: 0.000486308069
Iter: 1243 loss: 0.000485942204
Iter: 1244 loss: 0.000485202239
Iter: 1245 loss: 0.000498889
Iter: 1246 loss: 0.000485190656
Iter: 1247 loss: 0.000484577497
Iter: 1248 loss: 0.000485745171
Iter: 1249 loss: 0.000484319637
Iter: 1250 loss: 0.000483810552
Iter: 1251 loss: 0.000483226526
Iter: 1252 loss: 0.000483156648
Iter: 1253 loss: 0.000482658856
Iter: 1254 loss: 0.000482320174
Iter: 1255 loss: 0.00048213487
Iter: 1256 loss: 0.000481254654
Iter: 1257 loss: 0.000484272721
Iter: 1258 loss: 0.000481021358
Iter: 1259 loss: 0.000480637042
Iter: 1260 loss: 0.000484969671
Iter: 1261 loss: 0.000480626768
Iter: 1262 loss: 0.000480342394
Iter: 1263 loss: 0.000481052906
Iter: 1264 loss: 0.000480240269
Iter: 1265 loss: 0.000479805312
Iter: 1266 loss: 0.000478887843
Iter: 1267 loss: 0.000494272623
Iter: 1268 loss: 0.000478862639
Iter: 1269 loss: 0.000477494701
Iter: 1270 loss: 0.00047801208
Iter: 1271 loss: 0.000476540125
Iter: 1272 loss: 0.000474752451
Iter: 1273 loss: 0.000482244621
Iter: 1274 loss: 0.000474377186
Iter: 1275 loss: 0.000476309709
Iter: 1276 loss: 0.000473900756
Iter: 1277 loss: 0.000473604974
Iter: 1278 loss: 0.000473127177
Iter: 1279 loss: 0.000473123277
Iter: 1280 loss: 0.000472592772
Iter: 1281 loss: 0.000472905551
Iter: 1282 loss: 0.000472250656
Iter: 1283 loss: 0.000471511798
Iter: 1284 loss: 0.000474968692
Iter: 1285 loss: 0.000471377076
Iter: 1286 loss: 0.00047091287
Iter: 1287 loss: 0.000471689564
Iter: 1288 loss: 0.000470702624
Iter: 1289 loss: 0.000470297644
Iter: 1290 loss: 0.000470695464
Iter: 1291 loss: 0.000470067316
Iter: 1292 loss: 0.000469695777
Iter: 1293 loss: 0.000471189443
Iter: 1294 loss: 0.000469611783
Iter: 1295 loss: 0.000469180057
Iter: 1296 loss: 0.000470068568
Iter: 1297 loss: 0.000469005259
Iter: 1298 loss: 0.000468101643
Iter: 1299 loss: 0.000468115555
Iter: 1300 loss: 0.000467379403
Iter: 1301 loss: 0.000466676924
Iter: 1302 loss: 0.000466567668
Iter: 1303 loss: 0.000466079509
Iter: 1304 loss: 0.000465319026
Iter: 1305 loss: 0.000464475859
Iter: 1306 loss: 0.000464353187
Iter: 1307 loss: 0.000463769189
Iter: 1308 loss: 0.000463767676
Iter: 1309 loss: 0.000463035365
Iter: 1310 loss: 0.000462043681
Iter: 1311 loss: 0.000461992546
Iter: 1312 loss: 0.000460955722
Iter: 1313 loss: 0.000476323039
Iter: 1314 loss: 0.000460953946
Iter: 1315 loss: 0.000460301933
Iter: 1316 loss: 0.000463455566
Iter: 1317 loss: 0.000460186682
Iter: 1318 loss: 0.000459703908
Iter: 1319 loss: 0.00045942323
Iter: 1320 loss: 0.000459221221
Iter: 1321 loss: 0.000458765979
Iter: 1322 loss: 0.000465242
Iter: 1323 loss: 0.000458764524
Iter: 1324 loss: 0.000458542374
Iter: 1325 loss: 0.000458268361
Iter: 1326 loss: 0.000458245398
Iter: 1327 loss: 0.000457663235
Iter: 1328 loss: 0.000460622337
Iter: 1329 loss: 0.000457569142
Iter: 1330 loss: 0.00045707653
Iter: 1331 loss: 0.000460532086
Iter: 1332 loss: 0.000457031594
Iter: 1333 loss: 0.000456735463
Iter: 1334 loss: 0.000456268026
Iter: 1335 loss: 0.000456262671
Iter: 1336 loss: 0.000455723261
Iter: 1337 loss: 0.000457956805
Iter: 1338 loss: 0.000455608068
Iter: 1339 loss: 0.000455314701
Iter: 1340 loss: 0.000455315225
Iter: 1341 loss: 0.000454998488
Iter: 1342 loss: 0.000454759953
Iter: 1343 loss: 0.000454656285
Iter: 1344 loss: 0.000454284833
Iter: 1345 loss: 0.000455974106
Iter: 1346 loss: 0.00045421251
Iter: 1347 loss: 0.000453887915
Iter: 1348 loss: 0.000454209425
Iter: 1349 loss: 0.000453704502
Iter: 1350 loss: 0.000453310349
Iter: 1351 loss: 0.000454913883
Iter: 1352 loss: 0.000453222077
Iter: 1353 loss: 0.0004529898
Iter: 1354 loss: 0.000453906483
Iter: 1355 loss: 0.00045293686
Iter: 1356 loss: 0.000452653214
Iter: 1357 loss: 0.000451868109
Iter: 1358 loss: 0.000456370675
Iter: 1359 loss: 0.000451635395
Iter: 1360 loss: 0.000450636202
Iter: 1361 loss: 0.000460700772
Iter: 1362 loss: 0.000450606429
Iter: 1363 loss: 0.000449973275
Iter: 1364 loss: 0.000456540147
Iter: 1365 loss: 0.00044995622
Iter: 1366 loss: 0.00044944926
Iter: 1367 loss: 0.000448634877
Iter: 1368 loss: 0.000448627921
Iter: 1369 loss: 0.000447780621
Iter: 1370 loss: 0.000455856934
Iter: 1371 loss: 0.000447744504
Iter: 1372 loss: 0.000447177532
Iter: 1373 loss: 0.000449172687
Iter: 1374 loss: 0.000447033584
Iter: 1375 loss: 0.000446200371
Iter: 1376 loss: 0.000446602266
Iter: 1377 loss: 0.00044564018
Iter: 1378 loss: 0.000444862293
Iter: 1379 loss: 0.00044660439
Iter: 1380 loss: 0.000444566831
Iter: 1381 loss: 0.000443791942
Iter: 1382 loss: 0.000447718601
Iter: 1383 loss: 0.00044366502
Iter: 1384 loss: 0.000443151745
Iter: 1385 loss: 0.000445426238
Iter: 1386 loss: 0.000443051104
Iter: 1387 loss: 0.000442657329
Iter: 1388 loss: 0.000445384532
Iter: 1389 loss: 0.000442619727
Iter: 1390 loss: 0.000442271528
Iter: 1391 loss: 0.000441711
Iter: 1392 loss: 0.000441705692
Iter: 1393 loss: 0.000441282056
Iter: 1394 loss: 0.000444889767
Iter: 1395 loss: 0.000441256445
Iter: 1396 loss: 0.000440961041
Iter: 1397 loss: 0.000441399461
Iter: 1398 loss: 0.000440818083
Iter: 1399 loss: 0.000440345873
Iter: 1400 loss: 0.000440369
Iter: 1401 loss: 0.000439974421
Iter: 1402 loss: 0.000439482217
Iter: 1403 loss: 0.000443913246
Iter: 1404 loss: 0.000439460127
Iter: 1405 loss: 0.000439126568
Iter: 1406 loss: 0.000441656681
Iter: 1407 loss: 0.000439099967
Iter: 1408 loss: 0.000438741117
Iter: 1409 loss: 0.000439312775
Iter: 1410 loss: 0.000438573246
Iter: 1411 loss: 0.000438278803
Iter: 1412 loss: 0.000439324445
Iter: 1413 loss: 0.000438203249
Iter: 1414 loss: 0.000437946903
Iter: 1415 loss: 0.000438516057
Iter: 1416 loss: 0.00043784859
Iter: 1417 loss: 0.000437595212
Iter: 1418 loss: 0.000438606512
Iter: 1419 loss: 0.00043753651
Iter: 1420 loss: 0.00043738223
Iter: 1421 loss: 0.000437795505
Iter: 1422 loss: 0.000437331619
Iter: 1423 loss: 0.000437135
Iter: 1424 loss: 0.000436980103
Iter: 1425 loss: 0.000436919159
Iter: 1426 loss: 0.000436670089
Iter: 1427 loss: 0.000437379407
Iter: 1428 loss: 0.000436593109
Iter: 1429 loss: 0.000436230068
Iter: 1430 loss: 0.00043666453
Iter: 1431 loss: 0.000436039438
Iter: 1432 loss: 0.000435519265
Iter: 1433 loss: 0.000435798487
Iter: 1434 loss: 0.000435177761
Iter: 1435 loss: 0.000434769638
Iter: 1436 loss: 0.000437885261
Iter: 1437 loss: 0.000434737885
Iter: 1438 loss: 0.000434425718
Iter: 1439 loss: 0.000436012924
Iter: 1440 loss: 0.000434375834
Iter: 1441 loss: 0.000434021931
Iter: 1442 loss: 0.000434363261
Iter: 1443 loss: 0.000433819892
Iter: 1444 loss: 0.000433462497
Iter: 1445 loss: 0.000433824345
Iter: 1446 loss: 0.000433262438
Iter: 1447 loss: 0.00043281843
Iter: 1448 loss: 0.000434885063
Iter: 1449 loss: 0.000432735367
Iter: 1450 loss: 0.00043236246
Iter: 1451 loss: 0.000433657377
Iter: 1452 loss: 0.000432266
Iter: 1453 loss: 0.0004319328
Iter: 1454 loss: 0.000432744
Iter: 1455 loss: 0.000431814464
Iter: 1456 loss: 0.000431380147
Iter: 1457 loss: 0.000431277789
Iter: 1458 loss: 0.000431000633
Iter: 1459 loss: 0.000430585089
Iter: 1460 loss: 0.000430345041
Iter: 1461 loss: 0.000430167158
Iter: 1462 loss: 0.000429402426
Iter: 1463 loss: 0.000429871405
Iter: 1464 loss: 0.000428912
Iter: 1465 loss: 0.00042795128
Iter: 1466 loss: 0.000431058928
Iter: 1467 loss: 0.000427678606
Iter: 1468 loss: 0.000427127408
Iter: 1469 loss: 0.000431146647
Iter: 1470 loss: 0.00042708157
Iter: 1471 loss: 0.000426610437
Iter: 1472 loss: 0.0004331737
Iter: 1473 loss: 0.000426607759
Iter: 1474 loss: 0.000426149869
Iter: 1475 loss: 0.000426828978
Iter: 1476 loss: 0.000425930426
Iter: 1477 loss: 0.000425510836
Iter: 1478 loss: 0.000426203827
Iter: 1479 loss: 0.000425320701
Iter: 1480 loss: 0.00042490277
Iter: 1481 loss: 0.000425727805
Iter: 1482 loss: 0.000424730475
Iter: 1483 loss: 0.000424275902
Iter: 1484 loss: 0.000426592829
Iter: 1485 loss: 0.000424198864
Iter: 1486 loss: 0.000423854508
Iter: 1487 loss: 0.000424532918
Iter: 1488 loss: 0.000423710182
Iter: 1489 loss: 0.000423216785
Iter: 1490 loss: 0.000424003549
Iter: 1491 loss: 0.00042298506
Iter: 1492 loss: 0.000422632264
Iter: 1493 loss: 0.000423298916
Iter: 1494 loss: 0.000422485056
Iter: 1495 loss: 0.00042193089
Iter: 1496 loss: 0.000423077669
Iter: 1497 loss: 0.000421709265
Iter: 1498 loss: 0.000421223347
Iter: 1499 loss: 0.000422248937
Iter: 1500 loss: 0.000421032368
Iter: 1501 loss: 0.00042075658
Iter: 1502 loss: 0.000420549826
Iter: 1503 loss: 0.000420458906
Iter: 1504 loss: 0.000420136028
Iter: 1505 loss: 0.000420131866
Iter: 1506 loss: 0.000419891148
Iter: 1507 loss: 0.000420037482
Iter: 1508 loss: 0.000419737422
Iter: 1509 loss: 0.000419402611
Iter: 1510 loss: 0.000420160504
Iter: 1511 loss: 0.000419275137
Iter: 1512 loss: 0.000418874493
Iter: 1513 loss: 0.000419513934
Iter: 1514 loss: 0.00041868753
Iter: 1515 loss: 0.000418278883
Iter: 1516 loss: 0.000420093478
Iter: 1517 loss: 0.000418198062
Iter: 1518 loss: 0.000417891366
Iter: 1519 loss: 0.000418094074
Iter: 1520 loss: 0.000417698
Iter: 1521 loss: 0.000417260046
Iter: 1522 loss: 0.000417356729
Iter: 1523 loss: 0.000416937459
Iter: 1524 loss: 0.000416554132
Iter: 1525 loss: 0.000416998111
Iter: 1526 loss: 0.000416349503
Iter: 1527 loss: 0.000415785878
Iter: 1528 loss: 0.000417905743
Iter: 1529 loss: 0.000415650051
Iter: 1530 loss: 0.000415192742
Iter: 1531 loss: 0.000415994902
Iter: 1532 loss: 0.000414990704
Iter: 1533 loss: 0.000414590642
Iter: 1534 loss: 0.000414981332
Iter: 1535 loss: 0.000414366776
Iter: 1536 loss: 0.000414038077
Iter: 1537 loss: 0.000414003764
Iter: 1538 loss: 0.000413710979
Iter: 1539 loss: 0.000413715432
Iter: 1540 loss: 0.000413477741
Iter: 1541 loss: 0.000413087255
Iter: 1542 loss: 0.000413377158
Iter: 1543 loss: 0.000412848021
Iter: 1544 loss: 0.000412423164
Iter: 1545 loss: 0.000412920257
Iter: 1546 loss: 0.000412196736
Iter: 1547 loss: 0.000411753077
Iter: 1548 loss: 0.000416276278
Iter: 1549 loss: 0.000411739456
Iter: 1550 loss: 0.000411435845
Iter: 1551 loss: 0.000411612971
Iter: 1552 loss: 0.000411238871
Iter: 1553 loss: 0.000410738663
Iter: 1554 loss: 0.000412039051
Iter: 1555 loss: 0.000410567678
Iter: 1556 loss: 0.000410257955
Iter: 1557 loss: 0.00041058939
Iter: 1558 loss: 0.000410087872
Iter: 1559 loss: 0.000409623637
Iter: 1560 loss: 0.000411473273
Iter: 1561 loss: 0.000409515924
Iter: 1562 loss: 0.00040919194
Iter: 1563 loss: 0.000409931032
Iter: 1564 loss: 0.000409069529
Iter: 1565 loss: 0.000408794323
Iter: 1566 loss: 0.000408292195
Iter: 1567 loss: 0.000420305121
Iter: 1568 loss: 0.000408292515
Iter: 1569 loss: 0.000407961488
Iter: 1570 loss: 0.000407891115
Iter: 1571 loss: 0.000407600048
Iter: 1572 loss: 0.000407882733
Iter: 1573 loss: 0.000407435116
Iter: 1574 loss: 0.000407120562
Iter: 1575 loss: 0.000407358282
Iter: 1576 loss: 0.000406928826
Iter: 1577 loss: 0.000406546722
Iter: 1578 loss: 0.000407390064
Iter: 1579 loss: 0.000406400854
Iter: 1580 loss: 0.000406083302
Iter: 1581 loss: 0.000408022315
Iter: 1582 loss: 0.000406044477
Iter: 1583 loss: 0.000405781611
Iter: 1584 loss: 0.000406125735
Iter: 1585 loss: 0.000405648199
Iter: 1586 loss: 0.000405316387
Iter: 1587 loss: 0.000405603088
Iter: 1588 loss: 0.000405121449
Iter: 1589 loss: 0.000404875143
Iter: 1590 loss: 0.000405074534
Iter: 1591 loss: 0.00040472715
Iter: 1592 loss: 0.000404335617
Iter: 1593 loss: 0.000404768041
Iter: 1594 loss: 0.000404125545
Iter: 1595 loss: 0.000403776445
Iter: 1596 loss: 0.00040424554
Iter: 1597 loss: 0.000403601472
Iter: 1598 loss: 0.000403139624
Iter: 1599 loss: 0.000402452308
Iter: 1600 loss: 0.000402435777
Iter: 1601 loss: 0.000402388105
Iter: 1602 loss: 0.000401983096
Iter: 1603 loss: 0.000401662925
Iter: 1604 loss: 0.000402266567
Iter: 1605 loss: 0.000401529425
Iter: 1606 loss: 0.000401183264
Iter: 1607 loss: 0.000401594676
Iter: 1608 loss: 0.000400999794
Iter: 1609 loss: 0.000400617369
Iter: 1610 loss: 0.00040136982
Iter: 1611 loss: 0.000400459481
Iter: 1612 loss: 0.000400128891
Iter: 1613 loss: 0.000402273959
Iter: 1614 loss: 0.000400092686
Iter: 1615 loss: 0.000399844372
Iter: 1616 loss: 0.000400251476
Iter: 1617 loss: 0.000399730285
Iter: 1618 loss: 0.000399418233
Iter: 1619 loss: 0.000399793353
Iter: 1620 loss: 0.000399254903
Iter: 1621 loss: 0.000398971722
Iter: 1622 loss: 0.000399868441
Iter: 1623 loss: 0.000398891862
Iter: 1624 loss: 0.000398480333
Iter: 1625 loss: 0.000399675046
Iter: 1626 loss: 0.000398352102
Iter: 1627 loss: 0.00039802742
Iter: 1628 loss: 0.000398405944
Iter: 1629 loss: 0.000397855067
Iter: 1630 loss: 0.000397489115
Iter: 1631 loss: 0.000396731135
Iter: 1632 loss: 0.000409946486
Iter: 1633 loss: 0.000396713847
Iter: 1634 loss: 0.000396752032
Iter: 1635 loss: 0.000396352552
Iter: 1636 loss: 0.000396144402
Iter: 1637 loss: 0.0003961568
Iter: 1638 loss: 0.000395980722
Iter: 1639 loss: 0.000395678275
Iter: 1640 loss: 0.000395855051
Iter: 1641 loss: 0.000395483337
Iter: 1642 loss: 0.000395094656
Iter: 1643 loss: 0.000396289077
Iter: 1644 loss: 0.000394979754
Iter: 1645 loss: 0.000394702656
Iter: 1646 loss: 0.000396159943
Iter: 1647 loss: 0.000394659641
Iter: 1648 loss: 0.000394381525
Iter: 1649 loss: 0.000395077863
Iter: 1650 loss: 0.000394284376
Iter: 1651 loss: 0.000393976632
Iter: 1652 loss: 0.00039412058
Iter: 1653 loss: 0.000393770315
Iter: 1654 loss: 0.000393517839
Iter: 1655 loss: 0.000394041359
Iter: 1656 loss: 0.000393416
Iter: 1657 loss: 0.000393107184
Iter: 1658 loss: 0.000393999682
Iter: 1659 loss: 0.000393010792
Iter: 1660 loss: 0.000392759
Iter: 1661 loss: 0.000392883783
Iter: 1662 loss: 0.000392591261
Iter: 1663 loss: 0.000392168062
Iter: 1664 loss: 0.000391726091
Iter: 1665 loss: 0.000391647569
Iter: 1666 loss: 0.00039193948
Iter: 1667 loss: 0.000391360547
Iter: 1668 loss: 0.000391163077
Iter: 1669 loss: 0.000391219219
Iter: 1670 loss: 0.000391019537
Iter: 1671 loss: 0.000390732603
Iter: 1672 loss: 0.000390957284
Iter: 1673 loss: 0.000390556845
Iter: 1674 loss: 0.00039020789
Iter: 1675 loss: 0.000390993489
Iter: 1676 loss: 0.000390075
Iter: 1677 loss: 0.000389774417
Iter: 1678 loss: 0.000390825793
Iter: 1679 loss: 0.000389696826
Iter: 1680 loss: 0.00038938949
Iter: 1681 loss: 0.000390740403
Iter: 1682 loss: 0.00038932875
Iter: 1683 loss: 0.000389059423
Iter: 1684 loss: 0.000389327557
Iter: 1685 loss: 0.000388907676
Iter: 1686 loss: 0.000388690038
Iter: 1687 loss: 0.000389524736
Iter: 1688 loss: 0.000388639164
Iter: 1689 loss: 0.00038835904
Iter: 1690 loss: 0.000388916174
Iter: 1691 loss: 0.000388244545
Iter: 1692 loss: 0.000387979788
Iter: 1693 loss: 0.000388258195
Iter: 1694 loss: 0.000387833396
Iter: 1695 loss: 0.000387469656
Iter: 1696 loss: 0.000386550149
Iter: 1697 loss: 0.000394837698
Iter: 1698 loss: 0.00038640952
Iter: 1699 loss: 0.000386702362
Iter: 1700 loss: 0.000386015658
Iter: 1701 loss: 0.000385755207
Iter: 1702 loss: 0.000385948864
Iter: 1703 loss: 0.000385597057
Iter: 1704 loss: 0.000385211
Iter: 1705 loss: 0.000385351595
Iter: 1706 loss: 0.00038494129
Iter: 1707 loss: 0.000384294312
Iter: 1708 loss: 0.000385912077
Iter: 1709 loss: 0.000384067273
Iter: 1710 loss: 0.000383574457
Iter: 1711 loss: 0.000384400599
Iter: 1712 loss: 0.000383352046
Iter: 1713 loss: 0.000382778788
Iter: 1714 loss: 0.000384922372
Iter: 1715 loss: 0.000382636441
Iter: 1716 loss: 0.000382143247
Iter: 1717 loss: 0.000382513215
Iter: 1718 loss: 0.000381840393
Iter: 1719 loss: 0.000381392572
Iter: 1720 loss: 0.000383062521
Iter: 1721 loss: 0.000381279911
Iter: 1722 loss: 0.000380772923
Iter: 1723 loss: 0.000382017432
Iter: 1724 loss: 0.000380593672
Iter: 1725 loss: 0.000380118261
Iter: 1726 loss: 0.000380041369
Iter: 1727 loss: 0.000379712379
Iter: 1728 loss: 0.00037881147
Iter: 1729 loss: 0.000378177792
Iter: 1730 loss: 0.0003778596
Iter: 1731 loss: 0.00037938013
Iter: 1732 loss: 0.00037753777
Iter: 1733 loss: 0.000377320335
Iter: 1734 loss: 0.000377146236
Iter: 1735 loss: 0.000377082033
Iter: 1736 loss: 0.000376673735
Iter: 1737 loss: 0.000376634649
Iter: 1738 loss: 0.000376334938
Iter: 1739 loss: 0.000375730568
Iter: 1740 loss: 0.000378200551
Iter: 1741 loss: 0.000375597359
Iter: 1742 loss: 0.000375201489
Iter: 1743 loss: 0.000375358679
Iter: 1744 loss: 0.000374925759
Iter: 1745 loss: 0.0003744399
Iter: 1746 loss: 0.000377444143
Iter: 1747 loss: 0.000374383584
Iter: 1748 loss: 0.00037408396
Iter: 1749 loss: 0.000374030846
Iter: 1750 loss: 0.000373826246
Iter: 1751 loss: 0.000373489631
Iter: 1752 loss: 0.000375230215
Iter: 1753 loss: 0.000373436225
Iter: 1754 loss: 0.000373005983
Iter: 1755 loss: 0.000377742457
Iter: 1756 loss: 0.000372996117
Iter: 1757 loss: 0.000372711685
Iter: 1758 loss: 0.000372711336
Iter: 1759 loss: 0.000372485723
Iter: 1760 loss: 0.000372178969
Iter: 1761 loss: 0.000371538
Iter: 1762 loss: 0.000382530648
Iter: 1763 loss: 0.000371522678
Iter: 1764 loss: 0.000371131289
Iter: 1765 loss: 0.000371124246
Iter: 1766 loss: 0.000370955444
Iter: 1767 loss: 0.000370510155
Iter: 1768 loss: 0.000373757357
Iter: 1769 loss: 0.00037041321
Iter: 1770 loss: 0.000369707239
Iter: 1771 loss: 0.000376568321
Iter: 1772 loss: 0.000369681045
Iter: 1773 loss: 0.00036899402
Iter: 1774 loss: 0.000371649396
Iter: 1775 loss: 0.000368833134
Iter: 1776 loss: 0.000368396315
Iter: 1777 loss: 0.000368284265
Iter: 1778 loss: 0.000368012406
Iter: 1779 loss: 0.000367592671
Iter: 1780 loss: 0.00036757093
Iter: 1781 loss: 0.000367318629
Iter: 1782 loss: 0.000366932363
Iter: 1783 loss: 0.00036692631
Iter: 1784 loss: 0.000366408669
Iter: 1785 loss: 0.000365467247
Iter: 1786 loss: 0.000388366403
Iter: 1787 loss: 0.000365467335
Iter: 1788 loss: 0.000367309694
Iter: 1789 loss: 0.000365185813
Iter: 1790 loss: 0.000365011045
Iter: 1791 loss: 0.000365600863
Iter: 1792 loss: 0.000364962616
Iter: 1793 loss: 0.000364860898
Iter: 1794 loss: 0.000364694715
Iter: 1795 loss: 0.000364694541
Iter: 1796 loss: 0.000364586536
Iter: 1797 loss: 0.000364586478
Iter: 1798 loss: 0.00036449192
Iter: 1799 loss: 0.000364328065
Iter: 1800 loss: 0.000364327978
Iter: 1801 loss: 0.000363997882
Iter: 1802 loss: 0.000364373584
Iter: 1803 loss: 0.000363821397
Iter: 1804 loss: 0.000363431842
Iter: 1805 loss: 0.00036343
Iter: 1806 loss: 0.000363241648
Iter: 1807 loss: 0.000363297702
Iter: 1808 loss: 0.000363106403
Iter: 1809 loss: 0.000362983148
Iter: 1810 loss: 0.000363041559
Iter: 1811 loss: 0.000362901075
Iter: 1812 loss: 0.000362648745
Iter: 1813 loss: 0.000362016872
Iter: 1814 loss: 0.000368004432
Iter: 1815 loss: 0.000361926795
Iter: 1816 loss: 0.000360910781
Iter: 1817 loss: 0.000362841529
Iter: 1818 loss: 0.000360480422
Iter: 1819 loss: 0.000358836725
Iter: 1820 loss: 0.00035941464
Iter: 1821 loss: 0.00035767752
Iter: 1822 loss: 0.000357354234
Iter: 1823 loss: 0.000356847479
Iter: 1824 loss: 0.000356119417
Iter: 1825 loss: 0.000358472171
Iter: 1826 loss: 0.000355908938
Iter: 1827 loss: 0.000355335942
Iter: 1828 loss: 0.000354121585
Iter: 1829 loss: 0.000373628834
Iter: 1830 loss: 0.000354085321
Iter: 1831 loss: 0.000353614509
Iter: 1832 loss: 0.000353396725
Iter: 1833 loss: 0.000353059557
Iter: 1834 loss: 0.000352314382
Iter: 1835 loss: 0.000363192463
Iter: 1836 loss: 0.00035227905
Iter: 1837 loss: 0.000351326336
Iter: 1838 loss: 0.000357771962
Iter: 1839 loss: 0.000351231924
Iter: 1840 loss: 0.000352308387
Iter: 1841 loss: 0.000350857736
Iter: 1842 loss: 0.000350758433
Iter: 1843 loss: 0.000350415241
Iter: 1844 loss: 0.00035011326
Iter: 1845 loss: 0.000349947601
Iter: 1846 loss: 0.000349197595
Iter: 1847 loss: 0.000349617272
Iter: 1848 loss: 0.000348707836
Iter: 1849 loss: 0.000348554284
Iter: 1850 loss: 0.000348588888
Iter: 1851 loss: 0.000348441245
Iter: 1852 loss: 0.000348082918
Iter: 1853 loss: 0.0003503107
Iter: 1854 loss: 0.000348040572
Iter: 1855 loss: 0.000347778376
Iter: 1856 loss: 0.000347371126
Iter: 1857 loss: 0.000347365509
Iter: 1858 loss: 0.000347030233
Iter: 1859 loss: 0.000348666741
Iter: 1860 loss: 0.000346972054
Iter: 1861 loss: 0.000346525398
Iter: 1862 loss: 0.000352419971
Iter: 1863 loss: 0.000346523622
Iter: 1864 loss: 0.000346186396
Iter: 1865 loss: 0.000347815774
Iter: 1866 loss: 0.000346124754
Iter: 1867 loss: 0.000345809211
Iter: 1868 loss: 0.000346189598
Iter: 1869 loss: 0.000345642213
Iter: 1870 loss: 0.000345301029
Iter: 1871 loss: 0.00034552539
Iter: 1872 loss: 0.00034508502
Iter: 1873 loss: 0.000344766653
Iter: 1874 loss: 0.000344765052
Iter: 1875 loss: 0.00034441243
Iter: 1876 loss: 0.000344307802
Iter: 1877 loss: 0.000344098022
Iter: 1878 loss: 0.000343798078
Iter: 1879 loss: 0.000343795458
Iter: 1880 loss: 0.000343662628
Iter: 1881 loss: 0.000343237916
Iter: 1882 loss: 0.000343564054
Iter: 1883 loss: 0.000342877232
Iter: 1884 loss: 0.000342005398
Iter: 1885 loss: 0.000345145207
Iter: 1886 loss: 0.000341782346
Iter: 1887 loss: 0.000340939965
Iter: 1888 loss: 0.000341012492
Iter: 1889 loss: 0.000340288039
Iter: 1890 loss: 0.000339207181
Iter: 1891 loss: 0.000340541388
Iter: 1892 loss: 0.000338641519
Iter: 1893 loss: 0.000337960897
Iter: 1894 loss: 0.000344312721
Iter: 1895 loss: 0.000337933132
Iter: 1896 loss: 0.000337453326
Iter: 1897 loss: 0.000341099221
Iter: 1898 loss: 0.00033741619
Iter: 1899 loss: 0.000336903409
Iter: 1900 loss: 0.000341190345
Iter: 1901 loss: 0.000336874364
Iter: 1902 loss: 0.000336617668
Iter: 1903 loss: 0.000336299127
Iter: 1904 loss: 0.000336271594
Iter: 1905 loss: 0.000336093741
Iter: 1906 loss: 0.000336055527
Iter: 1907 loss: 0.000335859309
Iter: 1908 loss: 0.000336250814
Iter: 1909 loss: 0.000335780845
Iter: 1910 loss: 0.000335636287
Iter: 1911 loss: 0.000336605066
Iter: 1912 loss: 0.000335622928
Iter: 1913 loss: 0.000335484743
Iter: 1914 loss: 0.000335088116
Iter: 1915 loss: 0.000336902041
Iter: 1916 loss: 0.000334944343
Iter: 1917 loss: 0.000334500102
Iter: 1918 loss: 0.00033471809
Iter: 1919 loss: 0.000334201148
Iter: 1920 loss: 0.000333475153
Iter: 1921 loss: 0.00033654843
Iter: 1922 loss: 0.000333325122
Iter: 1923 loss: 0.000332766358
Iter: 1924 loss: 0.000334671349
Iter: 1925 loss: 0.00033261982
Iter: 1926 loss: 0.000332244614
Iter: 1927 loss: 0.000332342606
Iter: 1928 loss: 0.000331972638
Iter: 1929 loss: 0.000331621559
Iter: 1930 loss: 0.000335377641
Iter: 1931 loss: 0.000331612682
Iter: 1932 loss: 0.000331583607
Iter: 1933 loss: 0.000331516145
Iter: 1934 loss: 0.000331430463
Iter: 1935 loss: 0.000331224466
Iter: 1936 loss: 0.000333549397
Iter: 1937 loss: 0.000331204559
Iter: 1938 loss: 0.000331026269
Iter: 1939 loss: 0.000331025105
Iter: 1940 loss: 0.000330891955
Iter: 1941 loss: 0.000332476338
Iter: 1942 loss: 0.000330890267
Iter: 1943 loss: 0.000330827723
Iter: 1944 loss: 0.000330790353
Iter: 1945 loss: 0.000330764044
Iter: 1946 loss: 0.000330622162
Iter: 1947 loss: 0.000330398092
Iter: 1948 loss: 0.000330395822
Iter: 1949 loss: 0.000330151874
Iter: 1950 loss: 0.000329824805
Iter: 1951 loss: 0.000329807139
Iter: 1952 loss: 0.00032957946
Iter: 1953 loss: 0.000329577015
Iter: 1954 loss: 0.000329373521
Iter: 1955 loss: 0.000329271279
Iter: 1956 loss: 0.000329175527
Iter: 1957 loss: 0.000329001283
Iter: 1958 loss: 0.00032983179
Iter: 1959 loss: 0.000328969385
Iter: 1960 loss: 0.000328848779
Iter: 1961 loss: 0.000328876253
Iter: 1962 loss: 0.000328760943
Iter: 1963 loss: 0.00032862951
Iter: 1964 loss: 0.000330018
Iter: 1965 loss: 0.000328625552
Iter: 1966 loss: 0.000328467169
Iter: 1967 loss: 0.000329272909
Iter: 1968 loss: 0.000328440365
Iter: 1969 loss: 0.000328393
Iter: 1970 loss: 0.00032839214
Iter: 1971 loss: 0.000328354246
Iter: 1972 loss: 0.00032828335
Iter: 1973 loss: 0.000328561699
Iter: 1974 loss: 0.000328265392
Iter: 1975 loss: 0.000328209542
Iter: 1976 loss: 0.000328115246
Iter: 1977 loss: 0.000328114198
Iter: 1978 loss: 0.000327944
Iter: 1979 loss: 0.00032838044
Iter: 1980 loss: 0.000327884045
Iter: 1981 loss: 0.000327781978
Iter: 1982 loss: 0.000327475835
Iter: 1983 loss: 0.00032848402
Iter: 1984 loss: 0.000327331421
Iter: 1985 loss: 0.000326880428
Iter: 1986 loss: 0.000327729853
Iter: 1987 loss: 0.000326689042
Iter: 1988 loss: 0.000326443667
Iter: 1989 loss: 0.000326425477
Iter: 1990 loss: 0.000326245325
Iter: 1991 loss: 0.000325955043
Iter: 1992 loss: 0.000325952657
Iter: 1993 loss: 0.000325634493
Iter: 1994 loss: 0.0003274263
Iter: 1995 loss: 0.000325590605
Iter: 1996 loss: 0.000325401314
Iter: 1997 loss: 0.000327237154
Iter: 1998 loss: 0.000325395202
Iter: 1999 loss: 0.00032522963
Iter: 2000 loss: 0.000327841786
Iter: 2001 loss: 0.000325229805
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3
+ date
Tue Oct 27 20:10:39 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 3 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab84a4b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab84aadd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab84a78048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab84a96510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab84a96d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab84a96e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab60259620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6027a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6027a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6023a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab601f2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6019e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6019e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab601c6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab601c69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6012e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab601716a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6019e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab601719d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab600c2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab600c29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6007ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab6002d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab4071c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab40725620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab40740158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab4070b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab406ba510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab406ba2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab406bed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab406be400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab4062ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab406996a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab40659b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab40659a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fab405ce488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0193252936
Iter: 2 loss: 1.12963629
Iter: 3 loss: 1.12123108
Iter: 4 loss: 0.77835077
Iter: 5 loss: 0.770666838
Iter: 6 loss: 0.536077142
Iter: 7 loss: 0.528456
Iter: 8 loss: 0.361249059
Iter: 9 loss: 0.352965117
Iter: 10 loss: 0.230326056
Iter: 11 loss: 0.221366018
Iter: 12 loss: 0.136502981
Iter: 13 loss: 0.128215283
Iter: 14 loss: 0.0731903389
Iter: 15 loss: 0.0659678727
Iter: 16 loss: 0.0330414176
Iter: 17 loss: 0.0282994676
Iter: 18 loss: 0.0133663053
Iter: 19 loss: 0.0119454
Iter: 20 loss: 0.0107723456
Iter: 21 loss: 0.00813296251
Iter: 22 loss: 0.00813296717
Iter: 23 loss: 0.00756976288
Iter: 24 loss: 0.00678280648
Iter: 25 loss: 0.00669814833
Iter: 26 loss: 0.00557093974
Iter: 27 loss: 0.012891179
Iter: 28 loss: 0.00557242427
Iter: 29 loss: 0.00508506456
Iter: 30 loss: 0.0426620021
Iter: 31 loss: 0.00508429296
Iter: 32 loss: 0.00470732152
Iter: 33 loss: 0.00545389298
Iter: 34 loss: 0.00454549631
Iter: 35 loss: 0.00411926256
Iter: 36 loss: 0.0050576292
Iter: 37 loss: 0.00400146935
Iter: 38 loss: 0.00383654214
Iter: 39 loss: 0.0037890377
Iter: 40 loss: 0.00368131232
Iter: 41 loss: 0.00349835935
Iter: 42 loss: 0.00339165027
Iter: 43 loss: 0.003308543
Iter: 44 loss: 0.00300373789
Iter: 45 loss: 0.00316719431
Iter: 46 loss: 0.00281083304
Iter: 47 loss: 0.00259232451
Iter: 48 loss: 0.0034333372
Iter: 49 loss: 0.00254083751
Iter: 50 loss: 0.00237273541
Iter: 51 loss: 0.00246537058
Iter: 52 loss: 0.00226363027
Iter: 53 loss: 0.00210995786
Iter: 54 loss: 0.00225369912
Iter: 55 loss: 0.00201455364
Iter: 56 loss: 0.00188177673
Iter: 57 loss: 0.00190585258
Iter: 58 loss: 0.00178808789
Iter: 59 loss: 0.00172070391
Iter: 60 loss: 0.00164612662
Iter: 61 loss: 0.00163388683
Iter: 62 loss: 0.00157252303
Iter: 63 loss: 0.0020217963
Iter: 64 loss: 0.00156930683
Iter: 65 loss: 0.00149724609
Iter: 66 loss: 0.00163277925
Iter: 67 loss: 0.00146626297
Iter: 68 loss: 0.00138657598
Iter: 69 loss: 0.00143933645
Iter: 70 loss: 0.00133566372
Iter: 71 loss: 0.0012555056
Iter: 72 loss: 0.00169397809
Iter: 73 loss: 0.00124123599
Iter: 74 loss: 0.00117351022
Iter: 75 loss: 0.0020270152
Iter: 76 loss: 0.00117343513
Iter: 77 loss: 0.00113228045
Iter: 78 loss: 0.0011276952
Iter: 79 loss: 0.0010976966
Iter: 80 loss: 0.00104998285
Iter: 81 loss: 0.00149055687
Iter: 82 loss: 0.00104706618
Iter: 83 loss: 0.00100244803
Iter: 84 loss: 0.00101594231
Iter: 85 loss: 0.000971087429
Iter: 86 loss: 0.000930256094
Iter: 87 loss: 0.0010993043
Iter: 88 loss: 0.00092183752
Iter: 89 loss: 0.000888471142
Iter: 90 loss: 0.000957648328
Iter: 91 loss: 0.000874626
Iter: 92 loss: 0.000844375812
Iter: 93 loss: 0.000915117096
Iter: 94 loss: 0.000834015664
Iter: 95 loss: 0.000822724192
Iter: 96 loss: 0.000822144095
Iter: 97 loss: 0.000812346931
Iter: 98 loss: 0.000796939596
Iter: 99 loss: 0.000796756591
Iter: 100 loss: 0.00077077304
Iter: 101 loss: 0.000791507075
Iter: 102 loss: 0.000755093526
Iter: 103 loss: 0.000731270527
Iter: 104 loss: 0.00102207379
Iter: 105 loss: 0.000730982516
Iter: 106 loss: 0.000713727786
Iter: 107 loss: 0.000799639733
Iter: 108 loss: 0.000710976368
Iter: 109 loss: 0.000692484202
Iter: 110 loss: 0.000823017035
Iter: 111 loss: 0.000690657762
Iter: 112 loss: 0.000680736848
Iter: 113 loss: 0.00068220275
Iter: 114 loss: 0.000673316361
Iter: 115 loss: 0.000662902254
Iter: 116 loss: 0.000659906
Iter: 117 loss: 0.000653565861
Iter: 118 loss: 0.000642335624
Iter: 119 loss: 0.000752979715
Iter: 120 loss: 0.000641939347
Iter: 121 loss: 0.000633242074
Iter: 122 loss: 0.000647935783
Iter: 123 loss: 0.000629454502
Iter: 124 loss: 0.000622799504
Iter: 125 loss: 0.000616728561
Iter: 126 loss: 0.000615033437
Iter: 127 loss: 0.000610553951
Iter: 128 loss: 0.000610203715
Iter: 129 loss: 0.000606615969
Iter: 130 loss: 0.000599357649
Iter: 131 loss: 0.000734683359
Iter: 132 loss: 0.000599247403
Iter: 133 loss: 0.000589023053
Iter: 134 loss: 0.000636037556
Iter: 135 loss: 0.000587170129
Iter: 136 loss: 0.000579829095
Iter: 137 loss: 0.000612402859
Iter: 138 loss: 0.000578296545
Iter: 139 loss: 0.000572263845
Iter: 140 loss: 0.000584715628
Iter: 141 loss: 0.000569895434
Iter: 142 loss: 0.000564438873
Iter: 143 loss: 0.000586057
Iter: 144 loss: 0.000563183567
Iter: 145 loss: 0.000558788539
Iter: 146 loss: 0.000591341639
Iter: 147 loss: 0.000558466418
Iter: 148 loss: 0.000554320344
Iter: 149 loss: 0.000554219587
Iter: 150 loss: 0.000550954894
Iter: 151 loss: 0.000546861032
Iter: 152 loss: 0.000555620412
Iter: 153 loss: 0.000545290299
Iter: 154 loss: 0.000542174559
Iter: 155 loss: 0.000537283835
Iter: 156 loss: 0.000537228421
Iter: 157 loss: 0.000532623148
Iter: 158 loss: 0.000542958616
Iter: 159 loss: 0.000530911
Iter: 160 loss: 0.000530620222
Iter: 161 loss: 0.000529103156
Iter: 162 loss: 0.000527255761
Iter: 163 loss: 0.000525048934
Iter: 164 loss: 0.000524826231
Iter: 165 loss: 0.000522379181
Iter: 166 loss: 0.000519157969
Iter: 167 loss: 0.000518963148
Iter: 168 loss: 0.000513486506
Iter: 169 loss: 0.000523637864
Iter: 170 loss: 0.000511141203
Iter: 171 loss: 0.000507030869
Iter: 172 loss: 0.000506963872
Iter: 173 loss: 0.000504539406
Iter: 174 loss: 0.000502607203
Iter: 175 loss: 0.000501875533
Iter: 176 loss: 0.000497964676
Iter: 177 loss: 0.000497963105
Iter: 178 loss: 0.000495605636
Iter: 179 loss: 0.000511133578
Iter: 180 loss: 0.00049537071
Iter: 181 loss: 0.000493886648
Iter: 182 loss: 0.000491956249
Iter: 183 loss: 0.000491827086
Iter: 184 loss: 0.00048918376
Iter: 185 loss: 0.000505298958
Iter: 186 loss: 0.000488874794
Iter: 187 loss: 0.000486687175
Iter: 188 loss: 0.000488285557
Iter: 189 loss: 0.000485332537
Iter: 190 loss: 0.000483736279
Iter: 191 loss: 0.000498255598
Iter: 192 loss: 0.000483673182
Iter: 193 loss: 0.000481677736
Iter: 194 loss: 0.000487319485
Iter: 195 loss: 0.000481030555
Iter: 196 loss: 0.000480151153
Iter: 197 loss: 0.000477402122
Iter: 198 loss: 0.000482144213
Iter: 199 loss: 0.000475558219
Iter: 200 loss: 0.000471468142
Iter: 201 loss: 0.000493935542
Iter: 202 loss: 0.000470885076
Iter: 203 loss: 0.000467434234
Iter: 204 loss: 0.000484156568
Iter: 205 loss: 0.000466818339
Iter: 206 loss: 0.000463895209
Iter: 207 loss: 0.000480801973
Iter: 208 loss: 0.0004635019
Iter: 209 loss: 0.000461464922
Iter: 210 loss: 0.000466084515
Iter: 211 loss: 0.00046071026
Iter: 212 loss: 0.000458675029
Iter: 213 loss: 0.000479847367
Iter: 214 loss: 0.000458616792
Iter: 215 loss: 0.000456923037
Iter: 216 loss: 0.000459211
Iter: 217 loss: 0.000456073903
Iter: 218 loss: 0.000454610738
Iter: 219 loss: 0.000464208424
Iter: 220 loss: 0.000454448687
Iter: 221 loss: 0.00045298
Iter: 222 loss: 0.000457350368
Iter: 223 loss: 0.00045254259
Iter: 224 loss: 0.000451189757
Iter: 225 loss: 0.000460929179
Iter: 226 loss: 0.000451068132
Iter: 227 loss: 0.000449983781
Iter: 228 loss: 0.000449983461
Iter: 229 loss: 0.000449585961
Iter: 230 loss: 0.00044825676
Iter: 231 loss: 0.000447865634
Iter: 232 loss: 0.000446750491
Iter: 233 loss: 0.000444451376
Iter: 234 loss: 0.000465825433
Iter: 235 loss: 0.000444352947
Iter: 236 loss: 0.000442381628
Iter: 237 loss: 0.000445442565
Iter: 238 loss: 0.000441461336
Iter: 239 loss: 0.000439635885
Iter: 240 loss: 0.000444303761
Iter: 241 loss: 0.000439005642
Iter: 242 loss: 0.000437513139
Iter: 243 loss: 0.000447590079
Iter: 244 loss: 0.000437364914
Iter: 245 loss: 0.000436048198
Iter: 246 loss: 0.000436642091
Iter: 247 loss: 0.000435155642
Iter: 248 loss: 0.000434101385
Iter: 249 loss: 0.000433978683
Iter: 250 loss: 0.00043331596
Iter: 251 loss: 0.000431924098
Iter: 252 loss: 0.000454983267
Iter: 253 loss: 0.000431885826
Iter: 254 loss: 0.000430583692
Iter: 255 loss: 0.000445170474
Iter: 256 loss: 0.000430557411
Iter: 257 loss: 0.000429711363
Iter: 258 loss: 0.000441056851
Iter: 259 loss: 0.000429708161
Iter: 260 loss: 0.000429188018
Iter: 261 loss: 0.000434728776
Iter: 262 loss: 0.000429173029
Iter: 263 loss: 0.000428719795
Iter: 264 loss: 0.000427663123
Iter: 265 loss: 0.000440564938
Iter: 266 loss: 0.000427580322
Iter: 267 loss: 0.000426523329
Iter: 268 loss: 0.000425323757
Iter: 269 loss: 0.000425170409
Iter: 270 loss: 0.000423714228
Iter: 271 loss: 0.000444069563
Iter: 272 loss: 0.000423710211
Iter: 273 loss: 0.000422638492
Iter: 274 loss: 0.00042145871
Iter: 275 loss: 0.000421286415
Iter: 276 loss: 0.000419684977
Iter: 277 loss: 0.00043804798
Iter: 278 loss: 0.0004196589
Iter: 279 loss: 0.000418463256
Iter: 280 loss: 0.000419631484
Iter: 281 loss: 0.000417785312
Iter: 282 loss: 0.000416411553
Iter: 283 loss: 0.000418189797
Iter: 284 loss: 0.000415708695
Iter: 285 loss: 0.00041448517
Iter: 286 loss: 0.000422260026
Iter: 287 loss: 0.000414346
Iter: 288 loss: 0.000413298578
Iter: 289 loss: 0.000421995035
Iter: 290 loss: 0.000413239468
Iter: 291 loss: 0.000412783411
Iter: 292 loss: 0.000413464353
Iter: 293 loss: 0.000412563066
Iter: 294 loss: 0.000412064081
Iter: 295 loss: 0.00041206181
Iter: 296 loss: 0.000411552697
Iter: 297 loss: 0.000411098765
Iter: 298 loss: 0.000410968554
Iter: 299 loss: 0.000410530774
Iter: 300 loss: 0.000409540138
Iter: 301 loss: 0.000422960147
Iter: 302 loss: 0.00040948
Iter: 303 loss: 0.000408364169
Iter: 304 loss: 0.000414424721
Iter: 305 loss: 0.000408197695
Iter: 306 loss: 0.000406919571
Iter: 307 loss: 0.000407257408
Iter: 308 loss: 0.00040599535
Iter: 309 loss: 0.000404412829
Iter: 310 loss: 0.000411613961
Iter: 311 loss: 0.00040410948
Iter: 312 loss: 0.000402692938
Iter: 313 loss: 0.000412038877
Iter: 314 loss: 0.000402546546
Iter: 315 loss: 0.000401502795
Iter: 316 loss: 0.000401684636
Iter: 317 loss: 0.000400717079
Iter: 318 loss: 0.000399644807
Iter: 319 loss: 0.000403834449
Iter: 320 loss: 0.000399400829
Iter: 321 loss: 0.000398845819
Iter: 322 loss: 0.000398836681
Iter: 323 loss: 0.000398169272
Iter: 324 loss: 0.000398494187
Iter: 325 loss: 0.000397727
Iter: 326 loss: 0.000397294032
Iter: 327 loss: 0.000402785547
Iter: 328 loss: 0.00039729022
Iter: 329 loss: 0.000396892894
Iter: 330 loss: 0.000397484138
Iter: 331 loss: 0.000396704359
Iter: 332 loss: 0.000396304822
Iter: 333 loss: 0.000395429845
Iter: 334 loss: 0.000408452
Iter: 335 loss: 0.00039539265
Iter: 336 loss: 0.00039458205
Iter: 337 loss: 0.000394396746
Iter: 338 loss: 0.000393874
Iter: 339 loss: 0.00039289915
Iter: 340 loss: 0.000406240782
Iter: 341 loss: 0.000392894464
Iter: 342 loss: 0.00039225677
Iter: 343 loss: 0.000391713344
Iter: 344 loss: 0.000391537731
Iter: 345 loss: 0.000390393048
Iter: 346 loss: 0.000395616866
Iter: 347 loss: 0.000390175672
Iter: 348 loss: 0.000389215449
Iter: 349 loss: 0.000391928508
Iter: 350 loss: 0.000388908753
Iter: 351 loss: 0.000387874024
Iter: 352 loss: 0.000388171728
Iter: 353 loss: 0.000387127773
Iter: 354 loss: 0.000386039552
Iter: 355 loss: 0.000389443623
Iter: 356 loss: 0.000385725289
Iter: 357 loss: 0.000385713531
Iter: 358 loss: 0.000385220395
Iter: 359 loss: 0.000385000836
Iter: 360 loss: 0.000385022955
Iter: 361 loss: 0.000384832791
Iter: 362 loss: 0.000384395331
Iter: 363 loss: 0.000384294312
Iter: 364 loss: 0.000384011015
Iter: 365 loss: 0.000383528066
Iter: 366 loss: 0.000383215403
Iter: 367 loss: 0.000383028761
Iter: 368 loss: 0.000382320664
Iter: 369 loss: 0.000383093458
Iter: 370 loss: 0.000381934544
Iter: 371 loss: 0.000381293328
Iter: 372 loss: 0.000382355
Iter: 373 loss: 0.000381002086
Iter: 374 loss: 0.000380334328
Iter: 375 loss: 0.000380428333
Iter: 376 loss: 0.000379826699
Iter: 377 loss: 0.000378928962
Iter: 378 loss: 0.000389983
Iter: 379 loss: 0.000378920435
Iter: 380 loss: 0.000378362689
Iter: 381 loss: 0.000378529367
Iter: 382 loss: 0.000377963064
Iter: 383 loss: 0.000377035933
Iter: 384 loss: 0.000378751458
Iter: 385 loss: 0.000376637385
Iter: 386 loss: 0.000375902804
Iter: 387 loss: 0.000375609932
Iter: 388 loss: 0.000375216128
Iter: 389 loss: 0.000374420139
Iter: 390 loss: 0.000383081613
Iter: 391 loss: 0.000374401687
Iter: 392 loss: 0.000374221301
Iter: 393 loss: 0.000374038529
Iter: 394 loss: 0.000373807386
Iter: 395 loss: 0.000373669085
Iter: 396 loss: 0.000373572431
Iter: 397 loss: 0.000373240182
Iter: 398 loss: 0.000372824259
Iter: 399 loss: 0.000372789975
Iter: 400 loss: 0.000372316339
Iter: 401 loss: 0.000373187242
Iter: 402 loss: 0.000372111303
Iter: 403 loss: 0.000371439382
Iter: 404 loss: 0.000372774753
Iter: 405 loss: 0.000371163245
Iter: 406 loss: 0.000370673486
Iter: 407 loss: 0.000371002068
Iter: 408 loss: 0.000370366091
Iter: 409 loss: 0.000369804504
Iter: 410 loss: 0.000371150905
Iter: 411 loss: 0.000369601534
Iter: 412 loss: 0.000369046931
Iter: 413 loss: 0.000373321178
Iter: 414 loss: 0.000369005837
Iter: 415 loss: 0.000368516
Iter: 416 loss: 0.000369092857
Iter: 417 loss: 0.000368254259
Iter: 418 loss: 0.000367628119
Iter: 419 loss: 0.000369358022
Iter: 420 loss: 0.000367425324
Iter: 421 loss: 0.000366914
Iter: 422 loss: 0.000367581146
Iter: 423 loss: 0.000366654829
Iter: 424 loss: 0.000366000226
Iter: 425 loss: 0.000369398709
Iter: 426 loss: 0.000365892949
Iter: 427 loss: 0.000365533226
Iter: 428 loss: 0.000365460292
Iter: 429 loss: 0.000365303509
Iter: 430 loss: 0.000364914944
Iter: 431 loss: 0.000368813344
Iter: 432 loss: 0.000364866
Iter: 433 loss: 0.000364312436
Iter: 434 loss: 0.000363615283
Iter: 435 loss: 0.00036356083
Iter: 436 loss: 0.000362864695
Iter: 437 loss: 0.000362898572
Iter: 438 loss: 0.000362316088
Iter: 439 loss: 0.000361628656
Iter: 440 loss: 0.000361591752
Iter: 441 loss: 0.000361078652
Iter: 442 loss: 0.000360673876
Iter: 443 loss: 0.000360514969
Iter: 444 loss: 0.000359747792
Iter: 445 loss: 0.000361337152
Iter: 446 loss: 0.000359442638
Iter: 447 loss: 0.000358744932
Iter: 448 loss: 0.000359504018
Iter: 449 loss: 0.000358363905
Iter: 450 loss: 0.000357758894
Iter: 451 loss: 0.000364423206
Iter: 452 loss: 0.00035774539
Iter: 453 loss: 0.000357279088
Iter: 454 loss: 0.000359531783
Iter: 455 loss: 0.000357197481
Iter: 456 loss: 0.000356722769
Iter: 457 loss: 0.000356734759
Iter: 458 loss: 0.000356345437
Iter: 459 loss: 0.000356798759
Iter: 460 loss: 0.000356147764
Iter: 461 loss: 0.000355948403
Iter: 462 loss: 0.000355482771
Iter: 463 loss: 0.000361156097
Iter: 464 loss: 0.000355444849
Iter: 465 loss: 0.00035508757
Iter: 466 loss: 0.000354704331
Iter: 467 loss: 0.000354643096
Iter: 468 loss: 0.000354152726
Iter: 469 loss: 0.000357911689
Iter: 470 loss: 0.000354115153
Iter: 471 loss: 0.000353732379
Iter: 472 loss: 0.000353450305
Iter: 473 loss: 0.0003533212
Iter: 474 loss: 0.000352708565
Iter: 475 loss: 0.000355429016
Iter: 476 loss: 0.000352588395
Iter: 477 loss: 0.000352098083
Iter: 478 loss: 0.000353621726
Iter: 479 loss: 0.000351955532
Iter: 480 loss: 0.000351433759
Iter: 481 loss: 0.000350793533
Iter: 482 loss: 0.000350735645
Iter: 483 loss: 0.000349819951
Iter: 484 loss: 0.00035251971
Iter: 485 loss: 0.000349538634
Iter: 486 loss: 0.000348865462
Iter: 487 loss: 0.00035767752
Iter: 488 loss: 0.000348861853
Iter: 489 loss: 0.000348304253
Iter: 490 loss: 0.0003513431
Iter: 491 loss: 0.0003482225
Iter: 492 loss: 0.000348038157
Iter: 493 loss: 0.000348020578
Iter: 494 loss: 0.000347779074
Iter: 495 loss: 0.0003477344
Iter: 496 loss: 0.000347572408
Iter: 497 loss: 0.000347310852
Iter: 498 loss: 0.000346734596
Iter: 499 loss: 0.000355321274
Iter: 500 loss: 0.000346708664
Iter: 501 loss: 0.000346177898
Iter: 502 loss: 0.00035143859
Iter: 503 loss: 0.000346160232
Iter: 504 loss: 0.000345718086
Iter: 505 loss: 0.000346082583
Iter: 506 loss: 0.000345453271
Iter: 507 loss: 0.000344933302
Iter: 508 loss: 0.000347076624
Iter: 509 loss: 0.000344819855
Iter: 510 loss: 0.000344425032
Iter: 511 loss: 0.000346831
Iter: 512 loss: 0.000344377651
Iter: 513 loss: 0.000344034808
Iter: 514 loss: 0.000343799329
Iter: 515 loss: 0.000343674445
Iter: 516 loss: 0.000343234715
Iter: 517 loss: 0.00034321993
Iter: 518 loss: 0.00034287927
Iter: 519 loss: 0.000342309242
Iter: 520 loss: 0.000346557063
Iter: 521 loss: 0.000342263113
Iter: 522 loss: 0.000341798208
Iter: 523 loss: 0.0003425451
Iter: 524 loss: 0.000341583072
Iter: 525 loss: 0.000341160863
Iter: 526 loss: 0.000341160223
Iter: 527 loss: 0.000340895669
Iter: 528 loss: 0.000340894738
Iter: 529 loss: 0.000340766914
Iter: 530 loss: 0.000340386672
Iter: 531 loss: 0.000341484731
Iter: 532 loss: 0.000340189843
Iter: 533 loss: 0.00033967226
Iter: 534 loss: 0.000340362487
Iter: 535 loss: 0.000339412189
Iter: 536 loss: 0.000338645419
Iter: 537 loss: 0.000341550796
Iter: 538 loss: 0.0003384632
Iter: 539 loss: 0.000338002399
Iter: 540 loss: 0.000341741368
Iter: 541 loss: 0.000337973644
Iter: 542 loss: 0.000337622914
Iter: 543 loss: 0.000338061684
Iter: 544 loss: 0.000337440579
Iter: 545 loss: 0.000336971134
Iter: 546 loss: 0.000338030921
Iter: 547 loss: 0.000336795
Iter: 548 loss: 0.000336435041
Iter: 549 loss: 0.000335807097
Iter: 550 loss: 0.000335806282
Iter: 551 loss: 0.000335111836
Iter: 552 loss: 0.000341709558
Iter: 553 loss: 0.000335084798
Iter: 554 loss: 0.000334566925
Iter: 555 loss: 0.000335856748
Iter: 556 loss: 0.000334385055
Iter: 557 loss: 0.000334014767
Iter: 558 loss: 0.000334013428
Iter: 559 loss: 0.000333810982
Iter: 560 loss: 0.000333801436
Iter: 561 loss: 0.000333658652
Iter: 562 loss: 0.000333246891
Iter: 563 loss: 0.000335020828
Iter: 564 loss: 0.000333089265
Iter: 565 loss: 0.000332652708
Iter: 566 loss: 0.000332435942
Iter: 567 loss: 0.000332229829
Iter: 568 loss: 0.000331677671
Iter: 569 loss: 0.000331677817
Iter: 570 loss: 0.000331282063
Iter: 571 loss: 0.00033151955
Iter: 572 loss: 0.000331026851
Iter: 573 loss: 0.000330551702
Iter: 574 loss: 0.000333110453
Iter: 575 loss: 0.000330480631
Iter: 576 loss: 0.000330066221
Iter: 577 loss: 0.000331600691
Iter: 578 loss: 0.000329963746
Iter: 579 loss: 0.000329517818
Iter: 580 loss: 0.000329121918
Iter: 581 loss: 0.000329007424
Iter: 582 loss: 0.000328475668
Iter: 583 loss: 0.000329473871
Iter: 584 loss: 0.00032824988
Iter: 585 loss: 0.000327566813
Iter: 586 loss: 0.000331939285
Iter: 587 loss: 0.000327491434
Iter: 588 loss: 0.000327177579
Iter: 589 loss: 0.000327177055
Iter: 590 loss: 0.000327000336
Iter: 591 loss: 0.000326999492
Iter: 592 loss: 0.000326842128
Iter: 593 loss: 0.000326449808
Iter: 594 loss: 0.000330215058
Iter: 595 loss: 0.000326396606
Iter: 596 loss: 0.000326025358
Iter: 597 loss: 0.000325581292
Iter: 598 loss: 0.000325536123
Iter: 599 loss: 0.000325021567
Iter: 600 loss: 0.000330522365
Iter: 601 loss: 0.000325008354
Iter: 602 loss: 0.000324557332
Iter: 603 loss: 0.000325948815
Iter: 604 loss: 0.000324423308
Iter: 605 loss: 0.000324033841
Iter: 606 loss: 0.000325237372
Iter: 607 loss: 0.000323918706
Iter: 608 loss: 0.000323558517
Iter: 609 loss: 0.000325008645
Iter: 610 loss: 0.000323478656
Iter: 611 loss: 0.000323062
Iter: 612 loss: 0.00032261372
Iter: 613 loss: 0.000322542852
Iter: 614 loss: 0.000321987958
Iter: 615 loss: 0.000324655266
Iter: 616 loss: 0.000321889
Iter: 617 loss: 0.000321375905
Iter: 618 loss: 0.000322302745
Iter: 619 loss: 0.000321154279
Iter: 620 loss: 0.000320788793
Iter: 621 loss: 0.00032365
Iter: 622 loss: 0.000320761814
Iter: 623 loss: 0.000320640567
Iter: 624 loss: 0.00032056676
Iter: 625 loss: 0.000320419786
Iter: 626 loss: 0.000320122461
Iter: 627 loss: 0.000325750036
Iter: 628 loss: 0.000320118153
Iter: 629 loss: 0.000319849816
Iter: 630 loss: 0.000319373969
Iter: 631 loss: 0.000319374347
Iter: 632 loss: 0.000318869628
Iter: 633 loss: 0.00032131
Iter: 634 loss: 0.000318779901
Iter: 635 loss: 0.000318385544
Iter: 636 loss: 0.000321031519
Iter: 637 loss: 0.000318346487
Iter: 638 loss: 0.000317951082
Iter: 639 loss: 0.000318191684
Iter: 640 loss: 0.000317697937
Iter: 641 loss: 0.000317209662
Iter: 642 loss: 0.000319761341
Iter: 643 loss: 0.000317131751
Iter: 644 loss: 0.000316619815
Iter: 645 loss: 0.000317426369
Iter: 646 loss: 0.000316382211
Iter: 647 loss: 0.000315975223
Iter: 648 loss: 0.000315999758
Iter: 649 loss: 0.000315656827
Iter: 650 loss: 0.000315062527
Iter: 651 loss: 0.00031806581
Iter: 652 loss: 0.000314961129
Iter: 653 loss: 0.000314608042
Iter: 654 loss: 0.000317489961
Iter: 655 loss: 0.000314586068
Iter: 656 loss: 0.000314486329
Iter: 657 loss: 0.000314436969
Iter: 658 loss: 0.000314303965
Iter: 659 loss: 0.000314098637
Iter: 660 loss: 0.00031409564
Iter: 661 loss: 0.000313895638
Iter: 662 loss: 0.000313501339
Iter: 663 loss: 0.00032124971
Iter: 664 loss: 0.000313497265
Iter: 665 loss: 0.000313017459
Iter: 666 loss: 0.000314379722
Iter: 667 loss: 0.00031286609
Iter: 668 loss: 0.000312406279
Iter: 669 loss: 0.000315343204
Iter: 670 loss: 0.000312354532
Iter: 671 loss: 0.000311903685
Iter: 672 loss: 0.000312412827
Iter: 673 loss: 0.000311660755
Iter: 674 loss: 0.000311188836
Iter: 675 loss: 0.000312291144
Iter: 676 loss: 0.000311014766
Iter: 677 loss: 0.00031046907
Iter: 678 loss: 0.000312734046
Iter: 679 loss: 0.000310350675
Iter: 680 loss: 0.000309913128
Iter: 681 loss: 0.000309713883
Iter: 682 loss: 0.000309493917
Iter: 683 loss: 0.00030886996
Iter: 684 loss: 0.00031221169
Iter: 685 loss: 0.000308776798
Iter: 686 loss: 0.000308378076
Iter: 687 loss: 0.000310400384
Iter: 688 loss: 0.000308311544
Iter: 689 loss: 0.000308298622
Iter: 690 loss: 0.000308152172
Iter: 691 loss: 0.000307999057
Iter: 692 loss: 0.000307749026
Iter: 693 loss: 0.000307747861
Iter: 694 loss: 0.000307499868
Iter: 695 loss: 0.000307226874
Iter: 696 loss: 0.000307187613
Iter: 697 loss: 0.000306827715
Iter: 698 loss: 0.000307060021
Iter: 699 loss: 0.000306598173
Iter: 700 loss: 0.000306121656
Iter: 701 loss: 0.000307443494
Iter: 702 loss: 0.000305966561
Iter: 703 loss: 0.000305398
Iter: 704 loss: 0.000309117255
Iter: 705 loss: 0.00030533722
Iter: 706 loss: 0.000304938701
Iter: 707 loss: 0.000305829773
Iter: 708 loss: 0.000304786547
Iter: 709 loss: 0.000304368907
Iter: 710 loss: 0.000307167531
Iter: 711 loss: 0.000304327405
Iter: 712 loss: 0.000304002693
Iter: 713 loss: 0.000303948444
Iter: 714 loss: 0.000303725246
Iter: 715 loss: 0.000303277571
Iter: 716 loss: 0.000304065587
Iter: 717 loss: 0.000303080044
Iter: 718 loss: 0.000302640139
Iter: 719 loss: 0.000305152498
Iter: 720 loss: 0.00030258164
Iter: 721 loss: 0.000302518602
Iter: 722 loss: 0.000302413566
Iter: 723 loss: 0.000302245346
Iter: 724 loss: 0.000302194618
Iter: 725 loss: 0.000302093627
Iter: 726 loss: 0.000301930675
Iter: 727 loss: 0.000301581284
Iter: 728 loss: 0.000307212234
Iter: 729 loss: 0.000301570282
Iter: 730 loss: 0.000301115069
Iter: 731 loss: 0.00030172948
Iter: 732 loss: 0.000300886284
Iter: 733 loss: 0.000300386
Iter: 734 loss: 0.000301729975
Iter: 735 loss: 0.000300219835
Iter: 736 loss: 0.000299704523
Iter: 737 loss: 0.000303910871
Iter: 738 loss: 0.000299671781
Iter: 739 loss: 0.000299315318
Iter: 740 loss: 0.000299398496
Iter: 741 loss: 0.000299054373
Iter: 742 loss: 0.000298645638
Iter: 743 loss: 0.000301762135
Iter: 744 loss: 0.000298614614
Iter: 745 loss: 0.00029828315
Iter: 746 loss: 0.000298040861
Iter: 747 loss: 0.000297928607
Iter: 748 loss: 0.000297393679
Iter: 749 loss: 0.000299047126
Iter: 750 loss: 0.000297235179
Iter: 751 loss: 0.000296829618
Iter: 752 loss: 0.000298079918
Iter: 753 loss: 0.000296710525
Iter: 754 loss: 0.000296559796
Iter: 755 loss: 0.000296492974
Iter: 756 loss: 0.000296230428
Iter: 757 loss: 0.000296189857
Iter: 758 loss: 0.00029600627
Iter: 759 loss: 0.000295728969
Iter: 760 loss: 0.000295180071
Iter: 761 loss: 0.000305799942
Iter: 762 loss: 0.000295175065
Iter: 763 loss: 0.000294625177
Iter: 764 loss: 0.000296027196
Iter: 765 loss: 0.000294433674
Iter: 766 loss: 0.000293895777
Iter: 767 loss: 0.000293926627
Iter: 768 loss: 0.000293474208
Iter: 769 loss: 0.00029302208
Iter: 770 loss: 0.00029299609
Iter: 771 loss: 0.000292596524
Iter: 772 loss: 0.000292628247
Iter: 773 loss: 0.000292285113
Iter: 774 loss: 0.000291846489
Iter: 775 loss: 0.00029602513
Iter: 776 loss: 0.000291829812
Iter: 777 loss: 0.00029144052
Iter: 778 loss: 0.000291357137
Iter: 779 loss: 0.00029110277
Iter: 780 loss: 0.000290635624
Iter: 781 loss: 0.000291636446
Iter: 782 loss: 0.000290453143
Iter: 783 loss: 0.000289984193
Iter: 784 loss: 0.000292128127
Iter: 785 loss: 0.000289895426
Iter: 786 loss: 0.000289748481
Iter: 787 loss: 0.000289690739
Iter: 788 loss: 0.000289464515
Iter: 789 loss: 0.000289856631
Iter: 790 loss: 0.000289365
Iter: 791 loss: 0.000289185846
Iter: 792 loss: 0.000288772804
Iter: 793 loss: 0.000294079393
Iter: 794 loss: 0.000288743875
Iter: 795 loss: 0.000288339099
Iter: 796 loss: 0.000289445219
Iter: 797 loss: 0.000288207171
Iter: 798 loss: 0.000287782197
Iter: 799 loss: 0.000288160169
Iter: 800 loss: 0.00028753333
Iter: 801 loss: 0.000287128147
Iter: 802 loss: 0.000290942029
Iter: 803 loss: 0.000287112198
Iter: 804 loss: 0.000286701252
Iter: 805 loss: 0.000287122908
Iter: 806 loss: 0.000286472961
Iter: 807 loss: 0.000286043796
Iter: 808 loss: 0.000287772564
Iter: 809 loss: 0.000285947375
Iter: 810 loss: 0.000285507413
Iter: 811 loss: 0.000286245
Iter: 812 loss: 0.000285308954
Iter: 813 loss: 0.000284856884
Iter: 814 loss: 0.000285034184
Iter: 815 loss: 0.00028454329
Iter: 816 loss: 0.000284013979
Iter: 817 loss: 0.000285372196
Iter: 818 loss: 0.000283830741
Iter: 819 loss: 0.000283584115
Iter: 820 loss: 0.000283528731
Iter: 821 loss: 0.000283229398
Iter: 822 loss: 0.000284454436
Iter: 823 loss: 0.000283162692
Iter: 824 loss: 0.000282971363
Iter: 825 loss: 0.000282511406
Iter: 826 loss: 0.000287607312
Iter: 827 loss: 0.000282464491
Iter: 828 loss: 0.000281963847
Iter: 829 loss: 0.000283045985
Iter: 830 loss: 0.000281769433
Iter: 831 loss: 0.000281299814
Iter: 832 loss: 0.000282377761
Iter: 833 loss: 0.000281125365
Iter: 834 loss: 0.000280708133
Iter: 835 loss: 0.000282849796
Iter: 836 loss: 0.000280640263
Iter: 837 loss: 0.000280194799
Iter: 838 loss: 0.000281510525
Iter: 839 loss: 0.000280057953
Iter: 840 loss: 0.000279672415
Iter: 841 loss: 0.00028103264
Iter: 842 loss: 0.0002795732
Iter: 843 loss: 0.000279239
Iter: 844 loss: 0.000280057895
Iter: 845 loss: 0.000279119791
Iter: 846 loss: 0.000278723
Iter: 847 loss: 0.000278743071
Iter: 848 loss: 0.000278411055
Iter: 849 loss: 0.00027798157
Iter: 850 loss: 0.000278634485
Iter: 851 loss: 0.000277777319
Iter: 852 loss: 0.000277503452
Iter: 853 loss: 0.000277469197
Iter: 854 loss: 0.000277195242
Iter: 855 loss: 0.000280154578
Iter: 856 loss: 0.000277189567
Iter: 857 loss: 0.000277054205
Iter: 858 loss: 0.00027668642
Iter: 859 loss: 0.000279009284
Iter: 860 loss: 0.000276591221
Iter: 861 loss: 0.00027619116
Iter: 862 loss: 0.000277323765
Iter: 863 loss: 0.000276064209
Iter: 864 loss: 0.000275719853
Iter: 865 loss: 0.000275900529
Iter: 866 loss: 0.000275491504
Iter: 867 loss: 0.000275089522
Iter: 868 loss: 0.000277878193
Iter: 869 loss: 0.000275051338
Iter: 870 loss: 0.000274678983
Iter: 871 loss: 0.000276530307
Iter: 872 loss: 0.000274615944
Iter: 873 loss: 0.000274299295
Iter: 874 loss: 0.00027512075
Iter: 875 loss: 0.000274191028
Iter: 876 loss: 0.000273860816
Iter: 877 loss: 0.000274534628
Iter: 878 loss: 0.000273728074
Iter: 879 loss: 0.000273336336
Iter: 880 loss: 0.000273546699
Iter: 881 loss: 0.000273077923
Iter: 882 loss: 0.00027265976
Iter: 883 loss: 0.000272549602
Iter: 884 loss: 0.000272289384
Iter: 885 loss: 0.000272037258
Iter: 886 loss: 0.000271965982
Iter: 887 loss: 0.000271743338
Iter: 888 loss: 0.00027174296
Iter: 889 loss: 0.000271618279
Iter: 890 loss: 0.00027126135
Iter: 891 loss: 0.000272908888
Iter: 892 loss: 0.000271131401
Iter: 893 loss: 0.000270697084
Iter: 894 loss: 0.000271673169
Iter: 895 loss: 0.000270532153
Iter: 896 loss: 0.000270072254
Iter: 897 loss: 0.000270185905
Iter: 898 loss: 0.000269736222
Iter: 899 loss: 0.000269231095
Iter: 900 loss: 0.000272953126
Iter: 901 loss: 0.00026918907
Iter: 902 loss: 0.000268789649
Iter: 903 loss: 0.000271205266
Iter: 904 loss: 0.000268741307
Iter: 905 loss: 0.000268381205
Iter: 906 loss: 0.00026920822
Iter: 907 loss: 0.000268248084
Iter: 908 loss: 0.000267901283
Iter: 909 loss: 0.000269122713
Iter: 910 loss: 0.00026781112
Iter: 911 loss: 0.000267457042
Iter: 912 loss: 0.000267799391
Iter: 913 loss: 0.000267255731
Iter: 914 loss: 0.000266872637
Iter: 915 loss: 0.000266756222
Iter: 916 loss: 0.000266529038
Iter: 917 loss: 0.000266212621
Iter: 918 loss: 0.000266207149
Iter: 919 loss: 0.000266035961
Iter: 920 loss: 0.000266015471
Iter: 921 loss: 0.000265896204
Iter: 922 loss: 0.000265566836
Iter: 923 loss: 0.000267491734
Iter: 924 loss: 0.000265473383
Iter: 925 loss: 0.00026511593
Iter: 926 loss: 0.000265892217
Iter: 927 loss: 0.00026497792
Iter: 928 loss: 0.000264643808
Iter: 929 loss: 0.000264563714
Iter: 930 loss: 0.000264351082
Iter: 931 loss: 0.000263959519
Iter: 932 loss: 0.00026705669
Iter: 933 loss: 0.000263933238
Iter: 934 loss: 0.000263650873
Iter: 935 loss: 0.000265430252
Iter: 936 loss: 0.000263618364
Iter: 937 loss: 0.00026333431
Iter: 938 loss: 0.000263873662
Iter: 939 loss: 0.00026321417
Iter: 940 loss: 0.000262924528
Iter: 941 loss: 0.000263753172
Iter: 942 loss: 0.000262835
Iter: 943 loss: 0.000262520916
Iter: 944 loss: 0.000263025693
Iter: 945 loss: 0.000262376154
Iter: 946 loss: 0.000262082962
Iter: 947 loss: 0.000261959474
Iter: 948 loss: 0.000261806446
Iter: 949 loss: 0.00026146468
Iter: 950 loss: 0.00026506756
Iter: 951 loss: 0.000261456
Iter: 952 loss: 0.000261509907
Iter: 953 loss: 0.000261348207
Iter: 954 loss: 0.000261273817
Iter: 955 loss: 0.000261070876
Iter: 956 loss: 0.00026226748
Iter: 957 loss: 0.000261013512
Iter: 958 loss: 0.000260731525
Iter: 959 loss: 0.000261042616
Iter: 960 loss: 0.000260577304
Iter: 961 loss: 0.000260262517
Iter: 962 loss: 0.000260327943
Iter: 963 loss: 0.000260029192
Iter: 964 loss: 0.00025966781
Iter: 965 loss: 0.000262044079
Iter: 966 loss: 0.000259630062
Iter: 967 loss: 0.000259358698
Iter: 968 loss: 0.000260100293
Iter: 969 loss: 0.000259269407
Iter: 970 loss: 0.000258982123
Iter: 971 loss: 0.00026117565
Iter: 972 loss: 0.000258960179
Iter: 973 loss: 0.0002587692
Iter: 974 loss: 0.000258808606
Iter: 975 loss: 0.000258627406
Iter: 976 loss: 0.000258303597
Iter: 977 loss: 0.000259702123
Iter: 978 loss: 0.000258236367
Iter: 979 loss: 0.000258008804
Iter: 980 loss: 0.00025787254
Iter: 981 loss: 0.000257778738
Iter: 982 loss: 0.000257499516
Iter: 983 loss: 0.000257980137
Iter: 984 loss: 0.000257374311
Iter: 985 loss: 0.000258277811
Iter: 986 loss: 0.000257284788
Iter: 987 loss: 0.00025721945
Iter: 988 loss: 0.000257031701
Iter: 989 loss: 0.000257875043
Iter: 990 loss: 0.000256962143
Iter: 991 loss: 0.000256757456
Iter: 992 loss: 0.000256911706
Iter: 993 loss: 0.000256633502
Iter: 994 loss: 0.000256373372
Iter: 995 loss: 0.000256241474
Iter: 996 loss: 0.000256119587
Iter: 997 loss: 0.000255819061
Iter: 998 loss: 0.00025802973
Iter: 999 loss: 0.000255793362
Iter: 1000 loss: 0.000255518971
Iter: 1001 loss: 0.000256097061
Iter: 1002 loss: 0.000255410618
Iter: 1003 loss: 0.00025516405
Iter: 1004 loss: 0.000258297136
Iter: 1005 loss: 0.000255163
Iter: 1006 loss: 0.000254989835
Iter: 1007 loss: 0.000254967425
Iter: 1008 loss: 0.000254845363
Iter: 1009 loss: 0.000254628219
Iter: 1010 loss: 0.000255358
Iter: 1011 loss: 0.000254568848
Iter: 1012 loss: 0.000254392275
Iter: 1013 loss: 0.000254503044
Iter: 1014 loss: 0.000254279643
Iter: 1015 loss: 0.000253998383
Iter: 1016 loss: 0.000253817125
Iter: 1017 loss: 0.0002537088
Iter: 1018 loss: 0.000254157116
Iter: 1019 loss: 0.000253624312
Iter: 1020 loss: 0.000253532344
Iter: 1021 loss: 0.000253345468
Iter: 1022 loss: 0.000256744475
Iter: 1023 loss: 0.000253342703
Iter: 1024 loss: 0.000253160251
Iter: 1025 loss: 0.000253301056
Iter: 1026 loss: 0.000253048667
Iter: 1027 loss: 0.000252833648
Iter: 1028 loss: 0.000253199396
Iter: 1029 loss: 0.000252737256
Iter: 1030 loss: 0.000252530153
Iter: 1031 loss: 0.000252817466
Iter: 1032 loss: 0.000252427562
Iter: 1033 loss: 0.000252201367
Iter: 1034 loss: 0.000253001432
Iter: 1035 loss: 0.000252143334
Iter: 1036 loss: 0.000251983205
Iter: 1037 loss: 0.000253835
Iter: 1038 loss: 0.000251980149
Iter: 1039 loss: 0.000251832535
Iter: 1040 loss: 0.000251762656
Iter: 1041 loss: 0.000251689868
Iter: 1042 loss: 0.000251537131
Iter: 1043 loss: 0.000251536723
Iter: 1044 loss: 0.000251422665
Iter: 1045 loss: 0.000251336605
Iter: 1046 loss: 0.000251299469
Iter: 1047 loss: 0.000251158839
Iter: 1048 loss: 0.000251105812
Iter: 1049 loss: 0.000251027843
Iter: 1050 loss: 0.000250880868
Iter: 1051 loss: 0.000250789861
Iter: 1052 loss: 0.000250730256
Iter: 1053 loss: 0.000250683283
Iter: 1054 loss: 0.000250583718
Iter: 1055 loss: 0.000250543962
Iter: 1056 loss: 0.000250428333
Iter: 1057 loss: 0.000250873883
Iter: 1058 loss: 0.000250378362
Iter: 1059 loss: 0.000250214769
Iter: 1060 loss: 0.000250913436
Iter: 1061 loss: 0.000250179844
Iter: 1062 loss: 0.000250056211
Iter: 1063 loss: 0.000250475219
Iter: 1064 loss: 0.000250022975
Iter: 1065 loss: 0.000249885
Iter: 1066 loss: 0.000249779172
Iter: 1067 loss: 0.000249735807
Iter: 1068 loss: 0.000249576289
Iter: 1069 loss: 0.00025175343
Iter: 1070 loss: 0.000249575707
Iter: 1071 loss: 0.000249453587
Iter: 1072 loss: 0.000249730394
Iter: 1073 loss: 0.000249406963
Iter: 1074 loss: 0.000249216071
Iter: 1075 loss: 0.000249258184
Iter: 1076 loss: 0.000249075092
Iter: 1077 loss: 0.000248938624
Iter: 1078 loss: 0.000248938333
Iter: 1079 loss: 0.000248832512
Iter: 1080 loss: 0.000248710334
Iter: 1081 loss: 0.000248695287
Iter: 1082 loss: 0.000248505268
Iter: 1083 loss: 0.000249512377
Iter: 1084 loss: 0.000248476339
Iter: 1085 loss: 0.000248581462
Iter: 1086 loss: 0.000248414581
Iter: 1087 loss: 0.00024837727
Iter: 1088 loss: 0.000248256489
Iter: 1089 loss: 0.000248383614
Iter: 1090 loss: 0.000248161843
Iter: 1091 loss: 0.000248014781
Iter: 1092 loss: 0.000248390163
Iter: 1093 loss: 0.000247964053
Iter: 1094 loss: 0.000247785094
Iter: 1095 loss: 0.000248076103
Iter: 1096 loss: 0.000247702934
Iter: 1097 loss: 0.000247505726
Iter: 1098 loss: 0.000247962307
Iter: 1099 loss: 0.0002474332
Iter: 1100 loss: 0.000247252086
Iter: 1101 loss: 0.000247942022
Iter: 1102 loss: 0.000247209158
Iter: 1103 loss: 0.000247066928
Iter: 1104 loss: 0.000247131335
Iter: 1105 loss: 0.000246970914
Iter: 1106 loss: 0.000246764161
Iter: 1107 loss: 0.000248335651
Iter: 1108 loss: 0.00024674923
Iter: 1109 loss: 0.000246614334
Iter: 1110 loss: 0.000246886979
Iter: 1111 loss: 0.000246559706
Iter: 1112 loss: 0.00024642
Iter: 1113 loss: 0.000246365089
Iter: 1114 loss: 0.000246289244
Iter: 1115 loss: 0.000246108219
Iter: 1116 loss: 0.0002463907
Iter: 1117 loss: 0.000246022653
Iter: 1118 loss: 0.000245971838
Iter: 1119 loss: 0.000245942036
Iter: 1120 loss: 0.000245835225
Iter: 1121 loss: 0.000245749136
Iter: 1122 loss: 0.000245716539
Iter: 1123 loss: 0.000245604402
Iter: 1124 loss: 0.000245303905
Iter: 1125 loss: 0.000247330812
Iter: 1126 loss: 0.000245233299
Iter: 1127 loss: 0.00024500335
Iter: 1128 loss: 0.000244994095
Iter: 1129 loss: 0.000244815106
Iter: 1130 loss: 0.000244845753
Iter: 1131 loss: 0.000244680967
Iter: 1132 loss: 0.000244492374
Iter: 1133 loss: 0.000245205825
Iter: 1134 loss: 0.000244446856
Iter: 1135 loss: 0.000244245515
Iter: 1136 loss: 0.000244233408
Iter: 1137 loss: 0.000244080875
Iter: 1138 loss: 0.000243882823
Iter: 1139 loss: 0.000243882299
Iter: 1140 loss: 0.000243751041
Iter: 1141 loss: 0.000244452356
Iter: 1142 loss: 0.000243731483
Iter: 1143 loss: 0.000243633171
Iter: 1144 loss: 0.000243997492
Iter: 1145 loss: 0.000243608389
Iter: 1146 loss: 0.000243496499
Iter: 1147 loss: 0.000243324233
Iter: 1148 loss: 0.00024332157
Iter: 1149 loss: 0.000243128874
Iter: 1150 loss: 0.000244114897
Iter: 1151 loss: 0.000243096991
Iter: 1152 loss: 0.000242935756
Iter: 1153 loss: 0.000242926748
Iter: 1154 loss: 0.000242872964
Iter: 1155 loss: 0.000242729919
Iter: 1156 loss: 0.000243694929
Iter: 1157 loss: 0.000242696187
Iter: 1158 loss: 0.000242529757
Iter: 1159 loss: 0.000242629147
Iter: 1160 loss: 0.000242422422
Iter: 1161 loss: 0.000242255323
Iter: 1162 loss: 0.000244142575
Iter: 1163 loss: 0.000242252077
Iter: 1164 loss: 0.00024213572
Iter: 1165 loss: 0.000242075592
Iter: 1166 loss: 0.000242021953
Iter: 1167 loss: 0.000241841451
Iter: 1168 loss: 0.000242176931
Iter: 1169 loss: 0.000241764661
Iter: 1170 loss: 0.000241566711
Iter: 1171 loss: 0.000242389913
Iter: 1172 loss: 0.000241524453
Iter: 1173 loss: 0.000241367132
Iter: 1174 loss: 0.000243144576
Iter: 1175 loss: 0.000241364833
Iter: 1176 loss: 0.000241271991
Iter: 1177 loss: 0.000241832429
Iter: 1178 loss: 0.000241260481
Iter: 1179 loss: 0.000241169619
Iter: 1180 loss: 0.000241152273
Iter: 1181 loss: 0.00024109146
Iter: 1182 loss: 0.000240977155
Iter: 1183 loss: 0.00024109667
Iter: 1184 loss: 0.000240913752
Iter: 1185 loss: 0.000240857698
Iter: 1186 loss: 0.00024085358
Iter: 1187 loss: 0.000240774825
Iter: 1188 loss: 0.000240756504
Iter: 1189 loss: 0.000240705733
Iter: 1190 loss: 0.000240649766
Iter: 1191 loss: 0.000240507958
Iter: 1192 loss: 0.000241808026
Iter: 1193 loss: 0.000240487279
Iter: 1194 loss: 0.000240340451
Iter: 1195 loss: 0.000241658519
Iter: 1196 loss: 0.000240332709
Iter: 1197 loss: 0.000240215551
Iter: 1198 loss: 0.00024057136
Iter: 1199 loss: 0.000240180278
Iter: 1200 loss: 0.000240057256
Iter: 1201 loss: 0.00023993256
Iter: 1202 loss: 0.000239908084
Iter: 1203 loss: 0.000239697227
Iter: 1204 loss: 0.000240314155
Iter: 1205 loss: 0.00023963186
Iter: 1206 loss: 0.000239444707
Iter: 1207 loss: 0.000241804373
Iter: 1208 loss: 0.000239443121
Iter: 1209 loss: 0.000239297166
Iter: 1210 loss: 0.000239770874
Iter: 1211 loss: 0.000239256333
Iter: 1212 loss: 0.000239116023
Iter: 1213 loss: 0.000239739325
Iter: 1214 loss: 0.000239089102
Iter: 1215 loss: 0.000238922599
Iter: 1216 loss: 0.000238710607
Iter: 1217 loss: 0.000238695269
Iter: 1218 loss: 0.000238456938
Iter: 1219 loss: 0.000239626766
Iter: 1220 loss: 0.000238415538
Iter: 1221 loss: 0.000238214561
Iter: 1222 loss: 0.000238023407
Iter: 1223 loss: 0.000237977802
Iter: 1224 loss: 0.000238751716
Iter: 1225 loss: 0.000237903179
Iter: 1226 loss: 0.00023786095
Iter: 1227 loss: 0.000237739281
Iter: 1228 loss: 0.000238165958
Iter: 1229 loss: 0.00023768346
Iter: 1230 loss: 0.000237564847
Iter: 1231 loss: 0.00023752969
Iter: 1232 loss: 0.000237458255
Iter: 1233 loss: 0.000237322281
Iter: 1234 loss: 0.000238665438
Iter: 1235 loss: 0.000237317785
Iter: 1236 loss: 0.000237220462
Iter: 1237 loss: 0.000237045286
Iter: 1238 loss: 0.000241354152
Iter: 1239 loss: 0.000237045067
Iter: 1240 loss: 0.000236924665
Iter: 1241 loss: 0.000236978478
Iter: 1242 loss: 0.000236843029
Iter: 1243 loss: 0.000236765918
Iter: 1244 loss: 0.000236642489
Iter: 1245 loss: 0.000236641252
Iter: 1246 loss: 0.00023656436
Iter: 1247 loss: 0.000236517255
Iter: 1248 loss: 0.000236486012
Iter: 1249 loss: 0.000236357024
Iter: 1250 loss: 0.000237023763
Iter: 1251 loss: 0.00023633716
Iter: 1252 loss: 0.000236207503
Iter: 1253 loss: 0.000236231775
Iter: 1254 loss: 0.000236110835
Iter: 1255 loss: 0.000235990665
Iter: 1256 loss: 0.00023613096
Iter: 1257 loss: 0.000235927131
Iter: 1258 loss: 0.000235789834
Iter: 1259 loss: 0.000236292079
Iter: 1260 loss: 0.000235756379
Iter: 1261 loss: 0.000235658124
Iter: 1262 loss: 0.000235829386
Iter: 1263 loss: 0.000235614774
Iter: 1264 loss: 0.000235475833
Iter: 1265 loss: 0.000235796411
Iter: 1266 loss: 0.000235424232
Iter: 1267 loss: 0.00023528657
Iter: 1268 loss: 0.000235468571
Iter: 1269 loss: 0.000235216445
Iter: 1270 loss: 0.000235068685
Iter: 1271 loss: 0.00023550808
Iter: 1272 loss: 0.000235023894
Iter: 1273 loss: 0.000234874693
Iter: 1274 loss: 0.00023553615
Iter: 1275 loss: 0.000234845706
Iter: 1276 loss: 0.000234788284
Iter: 1277 loss: 0.000234771898
Iter: 1278 loss: 0.000234738982
Iter: 1279 loss: 0.00023467443
Iter: 1280 loss: 0.000235914282
Iter: 1281 loss: 0.00023467376
Iter: 1282 loss: 0.00023457878
Iter: 1283 loss: 0.000234876206
Iter: 1284 loss: 0.000234551058
Iter: 1285 loss: 0.000234464838
Iter: 1286 loss: 0.000234370498
Iter: 1287 loss: 0.000234356
Iter: 1288 loss: 0.000234249164
Iter: 1289 loss: 0.000235594198
Iter: 1290 loss: 0.000234248582
Iter: 1291 loss: 0.000234137944
Iter: 1292 loss: 0.00023414084
Iter: 1293 loss: 0.000234049687
Iter: 1294 loss: 0.000233898521
Iter: 1295 loss: 0.000234505278
Iter: 1296 loss: 0.00023386447
Iter: 1297 loss: 0.000233757833
Iter: 1298 loss: 0.000235247033
Iter: 1299 loss: 0.000233757703
Iter: 1300 loss: 0.000233693019
Iter: 1301 loss: 0.000233567538
Iter: 1302 loss: 0.000236069696
Iter: 1303 loss: 0.000233566039
Iter: 1304 loss: 0.00023340265
Iter: 1305 loss: 0.000233859377
Iter: 1306 loss: 0.000233349943
Iter: 1307 loss: 0.000233207669
Iter: 1308 loss: 0.000234548133
Iter: 1309 loss: 0.000233202401
Iter: 1310 loss: 0.000233143714
Iter: 1311 loss: 0.000233140832
Iter: 1312 loss: 0.000233087543
Iter: 1313 loss: 0.000233003797
Iter: 1314 loss: 0.000233003
Iter: 1315 loss: 0.000232898645
Iter: 1316 loss: 0.000233337894
Iter: 1317 loss: 0.000232876482
Iter: 1318 loss: 0.000232781749
Iter: 1319 loss: 0.000232712744
Iter: 1320 loss: 0.000232681181
Iter: 1321 loss: 0.000232549981
Iter: 1322 loss: 0.000232892125
Iter: 1323 loss: 0.000232505437
Iter: 1324 loss: 0.00023237853
Iter: 1325 loss: 0.000233855506
Iter: 1326 loss: 0.000232376391
Iter: 1327 loss: 0.000232278268
Iter: 1328 loss: 0.000232177597
Iter: 1329 loss: 0.000232159073
Iter: 1330 loss: 0.000232083665
Iter: 1331 loss: 0.000232073144
Iter: 1332 loss: 0.000231997576
Iter: 1333 loss: 0.000231848651
Iter: 1334 loss: 0.000234822757
Iter: 1335 loss: 0.000231846818
Iter: 1336 loss: 0.000231723301
Iter: 1337 loss: 0.000232206454
Iter: 1338 loss: 0.000231695012
Iter: 1339 loss: 0.000231573911
Iter: 1340 loss: 0.000231884318
Iter: 1341 loss: 0.000231531856
Iter: 1342 loss: 0.000231451879
Iter: 1343 loss: 0.0002314468
Iter: 1344 loss: 0.000231373269
Iter: 1345 loss: 0.000231383427
Iter: 1346 loss: 0.000231316837
Iter: 1347 loss: 0.000231241313
Iter: 1348 loss: 0.000231285434
Iter: 1349 loss: 0.000231192607
Iter: 1350 loss: 0.000231082886
Iter: 1351 loss: 0.00023115956
Iter: 1352 loss: 0.000231014405
Iter: 1353 loss: 0.000230888225
Iter: 1354 loss: 0.00023095221
Iter: 1355 loss: 0.00023080458
Iter: 1356 loss: 0.000230682781
Iter: 1357 loss: 0.000232537408
Iter: 1358 loss: 0.000230683101
Iter: 1359 loss: 0.000230571008
Iter: 1360 loss: 0.000230454782
Iter: 1361 loss: 0.000230434
Iter: 1362 loss: 0.000230279504
Iter: 1363 loss: 0.000231029291
Iter: 1364 loss: 0.000230253412
Iter: 1365 loss: 0.00023011805
Iter: 1366 loss: 0.000231829035
Iter: 1367 loss: 0.000230117294
Iter: 1368 loss: 0.000230041769
Iter: 1369 loss: 0.000229856247
Iter: 1370 loss: 0.000231695376
Iter: 1371 loss: 0.000229832425
Iter: 1372 loss: 0.000229665355
Iter: 1373 loss: 0.000230962469
Iter: 1374 loss: 0.000229653291
Iter: 1375 loss: 0.000229551137
Iter: 1376 loss: 0.000229551108
Iter: 1377 loss: 0.000229461235
Iter: 1378 loss: 0.000229905811
Iter: 1379 loss: 0.000229446101
Iter: 1380 loss: 0.000229389349
Iter: 1381 loss: 0.000229259604
Iter: 1382 loss: 0.000231030281
Iter: 1383 loss: 0.000229252124
Iter: 1384 loss: 0.000229090074
Iter: 1385 loss: 0.000229716272
Iter: 1386 loss: 0.000229051628
Iter: 1387 loss: 0.000228915742
Iter: 1388 loss: 0.000229045399
Iter: 1389 loss: 0.000228837627
Iter: 1390 loss: 0.000228685458
Iter: 1391 loss: 0.000229049459
Iter: 1392 loss: 0.00022863019
Iter: 1393 loss: 0.000228450648
Iter: 1394 loss: 0.000229484896
Iter: 1395 loss: 0.000228426274
Iter: 1396 loss: 0.000228286313
Iter: 1397 loss: 0.00022807777
Iter: 1398 loss: 0.000228072167
Iter: 1399 loss: 0.000228076606
Iter: 1400 loss: 0.000227982731
Iter: 1401 loss: 0.000227904107
Iter: 1402 loss: 0.000227761353
Iter: 1403 loss: 0.000231135942
Iter: 1404 loss: 0.000227761615
Iter: 1405 loss: 0.000227580866
Iter: 1406 loss: 0.000227985569
Iter: 1407 loss: 0.000227512151
Iter: 1408 loss: 0.000227337572
Iter: 1409 loss: 0.000227974349
Iter: 1410 loss: 0.000227292941
Iter: 1411 loss: 0.000227201788
Iter: 1412 loss: 0.000227180295
Iter: 1413 loss: 0.000227088909
Iter: 1414 loss: 0.00022700784
Iter: 1415 loss: 0.000226983859
Iter: 1416 loss: 0.000226888646
Iter: 1417 loss: 0.000226898439
Iter: 1418 loss: 0.000226815348
Iter: 1419 loss: 0.000226670178
Iter: 1420 loss: 0.00022697539
Iter: 1421 loss: 0.000226612159
Iter: 1422 loss: 0.000226460106
Iter: 1423 loss: 0.000226685559
Iter: 1424 loss: 0.000226386575
Iter: 1425 loss: 0.000226242162
Iter: 1426 loss: 0.000227749406
Iter: 1427 loss: 0.000226238277
Iter: 1428 loss: 0.000226115953
Iter: 1429 loss: 0.000226111879
Iter: 1430 loss: 0.000226016215
Iter: 1431 loss: 0.000225882395
Iter: 1432 loss: 0.000226586097
Iter: 1433 loss: 0.000225861659
Iter: 1434 loss: 0.000225717726
Iter: 1435 loss: 0.00022640606
Iter: 1436 loss: 0.000225693249
Iter: 1437 loss: 0.000225609503
Iter: 1438 loss: 0.00022545876
Iter: 1439 loss: 0.000229057216
Iter: 1440 loss: 0.000225459022
Iter: 1441 loss: 0.000225308831
Iter: 1442 loss: 0.000226319273
Iter: 1443 loss: 0.000225294061
Iter: 1444 loss: 0.00022524246
Iter: 1445 loss: 0.000225227646
Iter: 1446 loss: 0.000225163691
Iter: 1447 loss: 0.000225241267
Iter: 1448 loss: 0.00022513009
Iter: 1449 loss: 0.000225069511
Iter: 1450 loss: 0.000224952862
Iter: 1451 loss: 0.000227312863
Iter: 1452 loss: 0.000224951815
Iter: 1453 loss: 0.000224800111
Iter: 1454 loss: 0.00022556333
Iter: 1455 loss: 0.000224775111
Iter: 1456 loss: 0.000224637508
Iter: 1457 loss: 0.000224758085
Iter: 1458 loss: 0.000224557181
Iter: 1459 loss: 0.000224415082
Iter: 1460 loss: 0.000225106982
Iter: 1461 loss: 0.000224390329
Iter: 1462 loss: 0.000224267787
Iter: 1463 loss: 0.000225209908
Iter: 1464 loss: 0.000224258285
Iter: 1465 loss: 0.000224186544
Iter: 1466 loss: 0.000224074203
Iter: 1467 loss: 0.000224073214
Iter: 1468 loss: 0.000224031828
Iter: 1469 loss: 0.000224006362
Iter: 1470 loss: 0.000223944
Iter: 1471 loss: 0.000223838695
Iter: 1472 loss: 0.000223838608
Iter: 1473 loss: 0.000223744355
Iter: 1474 loss: 0.000223825569
Iter: 1475 loss: 0.000223689363
Iter: 1476 loss: 0.000223559691
Iter: 1477 loss: 0.000223895579
Iter: 1478 loss: 0.000223515701
Iter: 1479 loss: 0.000223535637
Iter: 1480 loss: 0.000223458032
Iter: 1481 loss: 0.000223419
Iter: 1482 loss: 0.000223331284
Iter: 1483 loss: 0.00022450721
Iter: 1484 loss: 0.000223325274
Iter: 1485 loss: 0.000223198032
Iter: 1486 loss: 0.00022322865
Iter: 1487 loss: 0.000223104944
Iter: 1488 loss: 0.000222991162
Iter: 1489 loss: 0.000222991133
Iter: 1490 loss: 0.000222896
Iter: 1491 loss: 0.000222813425
Iter: 1492 loss: 0.000222788483
Iter: 1493 loss: 0.000222672374
Iter: 1494 loss: 0.000223917465
Iter: 1495 loss: 0.000222669652
Iter: 1496 loss: 0.000222562288
Iter: 1497 loss: 0.000222666553
Iter: 1498 loss: 0.000222500879
Iter: 1499 loss: 0.000222414354
Iter: 1500 loss: 0.00022240718
Iter: 1501 loss: 0.000222343311
Iter: 1502 loss: 0.000222264629
Iter: 1503 loss: 0.000222262315
Iter: 1504 loss: 0.000222198069
Iter: 1505 loss: 0.00022211649
Iter: 1506 loss: 0.000222110335
Iter: 1507 loss: 0.000222001079
Iter: 1508 loss: 0.000221969458
Iter: 1509 loss: 0.000221903392
Iter: 1510 loss: 0.000221777154
Iter: 1511 loss: 0.000222841438
Iter: 1512 loss: 0.000221770024
Iter: 1513 loss: 0.000221686598
Iter: 1514 loss: 0.000221682421
Iter: 1515 loss: 0.000221645547
Iter: 1516 loss: 0.00022155515
Iter: 1517 loss: 0.000222453527
Iter: 1518 loss: 0.0002215438
Iter: 1519 loss: 0.000221448252
Iter: 1520 loss: 0.00022149198
Iter: 1521 loss: 0.000221383438
Iter: 1522 loss: 0.000221258641
Iter: 1523 loss: 0.000222254472
Iter: 1524 loss: 0.000221250259
Iter: 1525 loss: 0.000221178634
Iter: 1526 loss: 0.000221276321
Iter: 1527 loss: 0.000221143346
Iter: 1528 loss: 0.000221024427
Iter: 1529 loss: 0.000221094844
Iter: 1530 loss: 0.000220947375
Iter: 1531 loss: 0.000220849906
Iter: 1532 loss: 0.000221878785
Iter: 1533 loss: 0.000220847942
Iter: 1534 loss: 0.000220767412
Iter: 1535 loss: 0.000221094262
Iter: 1536 loss: 0.000220749775
Iter: 1537 loss: 0.000220687201
Iter: 1538 loss: 0.000220899819
Iter: 1539 loss: 0.000220670903
Iter: 1540 loss: 0.000220623246
Iter: 1541 loss: 0.000220518472
Iter: 1542 loss: 0.000221984359
Iter: 1543 loss: 0.00022051284
Iter: 1544 loss: 0.000220408401
Iter: 1545 loss: 0.000220913149
Iter: 1546 loss: 0.00022039059
Iter: 1547 loss: 0.000220386821
Iter: 1548 loss: 0.000220352842
Iter: 1549 loss: 0.000220316622
Iter: 1550 loss: 0.000220274233
Iter: 1551 loss: 0.000220269852
Iter: 1552 loss: 0.000220229194
Iter: 1553 loss: 0.000220144429
Iter: 1554 loss: 0.000221567054
Iter: 1555 loss: 0.000220142028
Iter: 1556 loss: 0.000220066358
Iter: 1557 loss: 0.0002200663
Iter: 1558 loss: 0.000220009766
Iter: 1559 loss: 0.000219969632
Iter: 1560 loss: 0.000219948968
Iter: 1561 loss: 0.000219867507
Iter: 1562 loss: 0.000220689792
Iter: 1563 loss: 0.000219864538
Iter: 1564 loss: 0.000219802867
Iter: 1565 loss: 0.000220097063
Iter: 1566 loss: 0.000219791254
Iter: 1567 loss: 0.000219744747
Iter: 1568 loss: 0.000219944865
Iter: 1569 loss: 0.000219735113
Iter: 1570 loss: 0.000219676498
Iter: 1571 loss: 0.000219741603
Iter: 1572 loss: 0.000219644338
Iter: 1573 loss: 0.00021958565
Iter: 1574 loss: 0.000219637615
Iter: 1575 loss: 0.000219551643
Iter: 1576 loss: 0.000219494163
Iter: 1577 loss: 0.000219438865
Iter: 1578 loss: 0.000219426438
Iter: 1579 loss: 0.000219375535
Iter: 1580 loss: 0.000219373731
Iter: 1581 loss: 0.000219310285
Iter: 1582 loss: 0.000219481939
Iter: 1583 loss: 0.000219289417
Iter: 1584 loss: 0.000219256079
Iter: 1585 loss: 0.000219196285
Iter: 1586 loss: 0.00022063707
Iter: 1587 loss: 0.000219196227
Iter: 1588 loss: 0.000219128182
Iter: 1589 loss: 0.000219278227
Iter: 1590 loss: 0.000219102221
Iter: 1591 loss: 0.000219032256
Iter: 1592 loss: 0.00021931497
Iter: 1593 loss: 0.000219015899
Iter: 1594 loss: 0.000218950867
Iter: 1595 loss: 0.000219137874
Iter: 1596 loss: 0.000218930858
Iter: 1597 loss: 0.000218882895
Iter: 1598 loss: 0.000219375652
Iter: 1599 loss: 0.00021888125
Iter: 1600 loss: 0.000218836314
Iter: 1601 loss: 0.000218819638
Iter: 1602 loss: 0.000218795132
Iter: 1603 loss: 0.000218759335
Iter: 1604 loss: 0.000218753616
Iter: 1605 loss: 0.000218729692
Iter: 1606 loss: 0.000218691843
Iter: 1607 loss: 0.000218692192
Iter: 1608 loss: 0.000218643923
Iter: 1609 loss: 0.000218643603
Iter: 1610 loss: 0.000218604982
Iter: 1611 loss: 0.000218554516
Iter: 1612 loss: 0.000218595873
Iter: 1613 loss: 0.000218524612
Iter: 1614 loss: 0.000218513829
Iter: 1615 loss: 0.0002184888
Iter: 1616 loss: 0.000218466725
Iter: 1617 loss: 0.000218403526
Iter: 1618 loss: 0.000218689529
Iter: 1619 loss: 0.000218380301
Iter: 1620 loss: 0.000218317509
Iter: 1621 loss: 0.000218540255
Iter: 1622 loss: 0.000218301648
Iter: 1623 loss: 0.000218240821
Iter: 1624 loss: 0.000218428759
Iter: 1625 loss: 0.000218222645
Iter: 1626 loss: 0.000218149842
Iter: 1627 loss: 0.000218274799
Iter: 1628 loss: 0.000218117013
Iter: 1629 loss: 0.000218063957
Iter: 1630 loss: 0.000218222645
Iter: 1631 loss: 0.00021804843
Iter: 1632 loss: 0.000217985362
Iter: 1633 loss: 0.000218118177
Iter: 1634 loss: 0.000217960245
Iter: 1635 loss: 0.000217889145
Iter: 1636 loss: 0.000218226312
Iter: 1637 loss: 0.000217876266
Iter: 1638 loss: 0.00021782676
Iter: 1639 loss: 0.000218524161
Iter: 1640 loss: 0.000217826571
Iter: 1641 loss: 0.000217802604
Iter: 1642 loss: 0.000217760113
Iter: 1643 loss: 0.000218782516
Iter: 1644 loss: 0.000217759865
Iter: 1645 loss: 0.000217713314
Iter: 1646 loss: 0.000217873661
Iter: 1647 loss: 0.000217700814
Iter: 1648 loss: 0.000217655383
Iter: 1649 loss: 0.00021761391
Iter: 1650 loss: 0.000217602967
Iter: 1651 loss: 0.000217676861
Iter: 1652 loss: 0.000217575638
Iter: 1653 loss: 0.000217565408
Iter: 1654 loss: 0.000217532579
Iter: 1655 loss: 0.000217529392
Iter: 1656 loss: 0.000217496621
Iter: 1657 loss: 0.000217440713
Iter: 1658 loss: 0.000217785651
Iter: 1659 loss: 0.000217433466
Iter: 1660 loss: 0.000217388893
Iter: 1661 loss: 0.000217443972
Iter: 1662 loss: 0.000217365116
Iter: 1663 loss: 0.000217309818
Iter: 1664 loss: 0.000217387103
Iter: 1665 loss: 0.000217282533
Iter: 1666 loss: 0.000217230481
Iter: 1667 loss: 0.000217284061
Iter: 1668 loss: 0.000217201479
Iter: 1669 loss: 0.000217136869
Iter: 1670 loss: 0.000217181238
Iter: 1671 loss: 0.000217096647
Iter: 1672 loss: 0.000217052817
Iter: 1673 loss: 0.000217048393
Iter: 1674 loss: 0.000217014924
Iter: 1675 loss: 0.000217007662
Iter: 1676 loss: 0.00021698582
Iter: 1677 loss: 0.000216932065
Iter: 1678 loss: 0.00021688483
Iter: 1679 loss: 0.000216870612
Iter: 1680 loss: 0.000216791232
Iter: 1681 loss: 0.000216822766
Iter: 1682 loss: 0.000216735934
Iter: 1683 loss: 0.000216641653
Iter: 1684 loss: 0.000217193578
Iter: 1685 loss: 0.000216628876
Iter: 1686 loss: 0.000216610351
Iter: 1687 loss: 0.000216583605
Iter: 1688 loss: 0.000216550718
Iter: 1689 loss: 0.000216487475
Iter: 1690 loss: 0.000217871144
Iter: 1691 loss: 0.000216487504
Iter: 1692 loss: 0.000216435292
Iter: 1693 loss: 0.000216424043
Iter: 1694 loss: 0.000216389279
Iter: 1695 loss: 0.000216318862
Iter: 1696 loss: 0.000216543267
Iter: 1697 loss: 0.000216298504
Iter: 1698 loss: 0.000216227229
Iter: 1699 loss: 0.000216642205
Iter: 1700 loss: 0.000216218439
Iter: 1701 loss: 0.000216161934
Iter: 1702 loss: 0.000216171786
Iter: 1703 loss: 0.000216120097
Iter: 1704 loss: 0.000216046028
Iter: 1705 loss: 0.000216211702
Iter: 1706 loss: 0.000216018336
Iter: 1707 loss: 0.00021600374
Iter: 1708 loss: 0.000215983222
Iter: 1709 loss: 0.000215963038
Iter: 1710 loss: 0.00021590633
Iter: 1711 loss: 0.000216233399
Iter: 1712 loss: 0.000215890192
Iter: 1713 loss: 0.000215819236
Iter: 1714 loss: 0.000216484434
Iter: 1715 loss: 0.000215816428
Iter: 1716 loss: 0.000215768727
Iter: 1717 loss: 0.000215725988
Iter: 1718 loss: 0.000215714
Iter: 1719 loss: 0.000215651817
Iter: 1720 loss: 0.000216349436
Iter: 1721 loss: 0.000215650332
Iter: 1722 loss: 0.000215586246
Iter: 1723 loss: 0.000215992724
Iter: 1724 loss: 0.00021557897
Iter: 1725 loss: 0.000215554581
Iter: 1726 loss: 0.000215489345
Iter: 1727 loss: 0.000215970242
Iter: 1728 loss: 0.000215475739
Iter: 1729 loss: 0.000215406646
Iter: 1730 loss: 0.000216195593
Iter: 1731 loss: 0.000215405715
Iter: 1732 loss: 0.000215347551
Iter: 1733 loss: 0.000215326872
Iter: 1734 loss: 0.000215293316
Iter: 1735 loss: 0.000215221415
Iter: 1736 loss: 0.000215905093
Iter: 1737 loss: 0.000215218606
Iter: 1738 loss: 0.00021516261
Iter: 1739 loss: 0.000215080392
Iter: 1740 loss: 0.000215078093
Iter: 1741 loss: 0.000215026143
Iter: 1742 loss: 0.000215020205
Iter: 1743 loss: 0.000214972868
Iter: 1744 loss: 0.000214899657
Iter: 1745 loss: 0.000214898289
Iter: 1746 loss: 0.000214799773
Iter: 1747 loss: 0.000214973901
Iter: 1748 loss: 0.000214756845
Iter: 1749 loss: 0.00021464302
Iter: 1750 loss: 0.000215314911
Iter: 1751 loss: 0.000214628235
Iter: 1752 loss: 0.0002145693
Iter: 1753 loss: 0.000214569285
Iter: 1754 loss: 0.000214521642
Iter: 1755 loss: 0.000214522122
Iter: 1756 loss: 0.000214494561
Iter: 1757 loss: 0.00021441502
Iter: 1758 loss: 0.000214677115
Iter: 1759 loss: 0.000214376734
Iter: 1760 loss: 0.000214277417
Iter: 1761 loss: 0.000214246014
Iter: 1762 loss: 0.000214186948
Iter: 1763 loss: 0.000214087748
Iter: 1764 loss: 0.000214088184
Iter: 1765 loss: 0.000213983818
Iter: 1766 loss: 0.000214117055
Iter: 1767 loss: 0.000213930442
Iter: 1768 loss: 0.000213849708
Iter: 1769 loss: 0.000214445419
Iter: 1770 loss: 0.000213843596
Iter: 1771 loss: 0.000213756488
Iter: 1772 loss: 0.00021372606
Iter: 1773 loss: 0.000213676787
Iter: 1774 loss: 0.000213603082
Iter: 1775 loss: 0.000214365689
Iter: 1776 loss: 0.000213600724
Iter: 1777 loss: 0.00021353121
Iter: 1778 loss: 0.000213953841
Iter: 1779 loss: 0.000213522188
Iter: 1780 loss: 0.000213466934
Iter: 1781 loss: 0.000213359075
Iter: 1782 loss: 0.00021556209
Iter: 1783 loss: 0.000213358173
Iter: 1784 loss: 0.000213247258
Iter: 1785 loss: 0.000213565625
Iter: 1786 loss: 0.000213212625
Iter: 1787 loss: 0.000213137246
Iter: 1788 loss: 0.000213134306
Iter: 1789 loss: 0.000213071777
Iter: 1790 loss: 0.000213572173
Iter: 1791 loss: 0.000213067251
Iter: 1792 loss: 0.000213030435
Iter: 1793 loss: 0.000212927931
Iter: 1794 loss: 0.00021348006
Iter: 1795 loss: 0.000212896237
Iter: 1796 loss: 0.000212784711
Iter: 1797 loss: 0.000212914951
Iter: 1798 loss: 0.000212725252
Iter: 1799 loss: 0.000212585903
Iter: 1800 loss: 0.000213035033
Iter: 1801 loss: 0.000212546642
Iter: 1802 loss: 0.000212416402
Iter: 1803 loss: 0.00021346088
Iter: 1804 loss: 0.000212407176
Iter: 1805 loss: 0.000212282219
Iter: 1806 loss: 0.000212281418
Iter: 1807 loss: 0.000212182174
Iter: 1808 loss: 0.000212033
Iter: 1809 loss: 0.000213563064
Iter: 1810 loss: 0.000212028506
Iter: 1811 loss: 0.000211932522
Iter: 1812 loss: 0.000212344676
Iter: 1813 loss: 0.000211912775
Iter: 1814 loss: 0.000211795035
Iter: 1815 loss: 0.000212007464
Iter: 1816 loss: 0.000211744322
Iter: 1817 loss: 0.00021164697
Iter: 1818 loss: 0.000211578168
Iter: 1819 loss: 0.000211543113
Iter: 1820 loss: 0.000211423088
Iter: 1821 loss: 0.000211341889
Iter: 1822 loss: 0.000211296807
Iter: 1823 loss: 0.000211451013
Iter: 1824 loss: 0.000211236606
Iter: 1825 loss: 0.000211182603
Iter: 1826 loss: 0.000211120845
Iter: 1827 loss: 0.000211112914
Iter: 1828 loss: 0.000211029779
Iter: 1829 loss: 0.000210957485
Iter: 1830 loss: 0.000210935395
Iter: 1831 loss: 0.000210792641
Iter: 1832 loss: 0.000211235558
Iter: 1833 loss: 0.000210751226
Iter: 1834 loss: 0.000210628816
Iter: 1835 loss: 0.000210674567
Iter: 1836 loss: 0.000210543192
Iter: 1837 loss: 0.000210429935
Iter: 1838 loss: 0.000210429847
Iter: 1839 loss: 0.000210347309
Iter: 1840 loss: 0.00021030051
Iter: 1841 loss: 0.000210264261
Iter: 1842 loss: 0.000210182232
Iter: 1843 loss: 0.000210179933
Iter: 1844 loss: 0.000210124446
Iter: 1845 loss: 0.000210475089
Iter: 1846 loss: 0.000210117782
Iter: 1847 loss: 0.000210075304
Iter: 1848 loss: 0.000209974765
Iter: 1849 loss: 0.00021112994
Iter: 1850 loss: 0.000209965481
Iter: 1851 loss: 0.000209864069
Iter: 1852 loss: 0.000209878286
Iter: 1853 loss: 0.000209787308
Iter: 1854 loss: 0.000209662379
Iter: 1855 loss: 0.000209989885
Iter: 1856 loss: 0.000209620193
Iter: 1857 loss: 0.000209544989
Iter: 1858 loss: 0.000209534322
Iter: 1859 loss: 0.000209440681
Iter: 1860 loss: 0.000209389153
Iter: 1861 loss: 0.000209347927
Iter: 1862 loss: 0.000209269478
Iter: 1863 loss: 0.000209088525
Iter: 1864 loss: 0.000211406383
Iter: 1865 loss: 0.000209075777
Iter: 1866 loss: 0.00020891428
Iter: 1867 loss: 0.000208914076
Iter: 1868 loss: 0.000208789119
Iter: 1869 loss: 0.000208833255
Iter: 1870 loss: 0.000208701778
Iter: 1871 loss: 0.00020856809
Iter: 1872 loss: 0.00020923691
Iter: 1873 loss: 0.00020854536
Iter: 1874 loss: 0.000208411206
Iter: 1875 loss: 0.000208840196
Iter: 1876 loss: 0.000208372789
Iter: 1877 loss: 0.000208298297
Iter: 1878 loss: 0.000209469348
Iter: 1879 loss: 0.000208298283
Iter: 1880 loss: 0.000208226353
Iter: 1881 loss: 0.000208395824
Iter: 1882 loss: 0.000208199766
Iter: 1883 loss: 0.000208132347
Iter: 1884 loss: 0.000208038095
Iter: 1885 loss: 0.000208034442
Iter: 1886 loss: 0.000207925244
Iter: 1887 loss: 0.0002079634
Iter: 1888 loss: 0.000207847857
Iter: 1889 loss: 0.00020768831
Iter: 1890 loss: 0.000207523481
Iter: 1891 loss: 0.000207492732
Iter: 1892 loss: 0.000207657955
Iter: 1893 loss: 0.000207425968
Iter: 1894 loss: 0.00020734407
Iter: 1895 loss: 0.000207185643
Iter: 1896 loss: 0.000210480386
Iter: 1897 loss: 0.000207185047
Iter: 1898 loss: 0.000207041157
Iter: 1899 loss: 0.000207124627
Iter: 1900 loss: 0.000206948083
Iter: 1901 loss: 0.000206753408
Iter: 1902 loss: 0.000207247067
Iter: 1903 loss: 0.000206685712
Iter: 1904 loss: 0.000206511206
Iter: 1905 loss: 0.000207851204
Iter: 1906 loss: 0.000206498313
Iter: 1907 loss: 0.00020637353
Iter: 1908 loss: 0.000206576282
Iter: 1909 loss: 0.000206315177
Iter: 1910 loss: 0.000206171651
Iter: 1911 loss: 0.000206713143
Iter: 1912 loss: 0.000206137047
Iter: 1913 loss: 0.000206060795
Iter: 1914 loss: 0.000206059864
Iter: 1915 loss: 0.00020598952
Iter: 1916 loss: 0.000205931909
Iter: 1917 loss: 0.000205911143
Iter: 1918 loss: 0.000205817545
Iter: 1919 loss: 0.000205909106
Iter: 1920 loss: 0.000205764576
Iter: 1921 loss: 0.000205639662
Iter: 1922 loss: 0.000205537159
Iter: 1923 loss: 0.000205501114
Iter: 1924 loss: 0.00020534372
Iter: 1925 loss: 0.000205829507
Iter: 1926 loss: 0.000205296717
Iter: 1927 loss: 0.000205293938
Iter: 1928 loss: 0.000205222896
Iter: 1929 loss: 0.000205173259
Iter: 1930 loss: 0.000205043703
Iter: 1931 loss: 0.000206113269
Iter: 1932 loss: 0.000205021221
Iter: 1933 loss: 0.000204886717
Iter: 1934 loss: 0.00020501946
Iter: 1935 loss: 0.000204811338
Iter: 1936 loss: 0.000204685
Iter: 1937 loss: 0.00020618191
Iter: 1938 loss: 0.000204683136
Iter: 1939 loss: 0.000204587821
Iter: 1940 loss: 0.000204827229
Iter: 1941 loss: 0.000204554148
Iter: 1942 loss: 0.000204457348
Iter: 1943 loss: 0.000204923417
Iter: 1944 loss: 0.000204440483
Iter: 1945 loss: 0.000204357828
Iter: 1946 loss: 0.000204978685
Iter: 1947 loss: 0.000204351134
Iter: 1948 loss: 0.000204265525
Iter: 1949 loss: 0.000204394251
Iter: 1950 loss: 0.000204223921
Iter: 1951 loss: 0.000204153635
Iter: 1952 loss: 0.000204087439
Iter: 1953 loss: 0.000204071286
Iter: 1954 loss: 0.000203937583
Iter: 1955 loss: 0.000204011158
Iter: 1956 loss: 0.000203850184
Iter: 1957 loss: 0.000203674528
Iter: 1958 loss: 0.000204230484
Iter: 1959 loss: 0.000203622971
Iter: 1960 loss: 0.000203518677
Iter: 1961 loss: 0.00020420397
Iter: 1962 loss: 0.000203507763
Iter: 1963 loss: 0.000203356583
Iter: 1964 loss: 0.000203540898
Iter: 1965 loss: 0.000203277552
Iter: 1966 loss: 0.000203212214
Iter: 1967 loss: 0.000203068746
Iter: 1968 loss: 0.000205181059
Iter: 1969 loss: 0.000203062315
Iter: 1970 loss: 0.00020288823
Iter: 1971 loss: 0.00020366504
Iter: 1972 loss: 0.000202853174
Iter: 1973 loss: 0.000202699535
Iter: 1974 loss: 0.000204157492
Iter: 1975 loss: 0.000202693467
Iter: 1976 loss: 0.000202582887
Iter: 1977 loss: 0.000202804353
Iter: 1978 loss: 0.000202537107
Iter: 1979 loss: 0.000202430936
Iter: 1980 loss: 0.000203453877
Iter: 1981 loss: 0.000202426978
Iter: 1982 loss: 0.000202345895
Iter: 1983 loss: 0.000203001196
Iter: 1984 loss: 0.000202340831
Iter: 1985 loss: 0.000202291238
Iter: 1986 loss: 0.00020218399
Iter: 1987 loss: 0.00020387015
Iter: 1988 loss: 0.000202180992
Iter: 1989 loss: 0.000202048512
Iter: 1990 loss: 0.00020233712
Iter: 1991 loss: 0.000201997318
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/k4
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0
+ date
Tue Oct 27 20:36:31 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29383d0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29383d0d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2938395510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f295cb60c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f295cb81268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f293835a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f295cb81a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2938306a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f295cb81e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29382d52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29382d5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29382a1f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29382a1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2938203510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29382a1d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29381aeea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f293816d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f293816dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f293816da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2938100048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29381002f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29380adbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29380ea620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2938074f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29380747b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29380488c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29200ec378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29200f78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29200f7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29200a91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29200ecd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29200a9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f29200867b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f292004e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28d464d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28d45dcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00780423544
Iter: 2 loss: 0.00777390506
Iter: 3 loss: 0.00765837589
Iter: 4 loss: 0.0072208792
Iter: 5 loss: 0.00870321132
Iter: 6 loss: 0.00700766593
Iter: 7 loss: 0.00679703383
Iter: 8 loss: 0.0098341275
Iter: 9 loss: 0.00679670507
Iter: 10 loss: 0.0066568628
Iter: 11 loss: 0.00749009103
Iter: 12 loss: 0.00663951784
Iter: 13 loss: 0.00657983264
Iter: 14 loss: 0.00661372533
Iter: 15 loss: 0.006540915
Iter: 16 loss: 0.00650908891
Iter: 17 loss: 0.00700418418
Iter: 18 loss: 0.00650908612
Iter: 19 loss: 0.00648774253
Iter: 20 loss: 0.00663138926
Iter: 21 loss: 0.00648561958
Iter: 22 loss: 0.00647599436
Iter: 23 loss: 0.00647915527
Iter: 24 loss: 0.00646917243
Iter: 25 loss: 0.00646206271
Iter: 26 loss: 0.00649738032
Iter: 27 loss: 0.00646085851
Iter: 28 loss: 0.00645819493
Iter: 29 loss: 0.00645818841
Iter: 30 loss: 0.00645641144
Iter: 31 loss: 0.0064697382
Iter: 32 loss: 0.00645627175
Iter: 33 loss: 0.00645548245
Iter: 34 loss: 0.00645555649
Iter: 35 loss: 0.0064548729
Iter: 36 loss: 0.0064542857
Iter: 37 loss: 0.00645824801
Iter: 38 loss: 0.00645422703
Iter: 39 loss: 0.00645401515
Iter: 40 loss: 0.00645401515
Iter: 41 loss: 0.00645386567
Iter: 42 loss: 0.0064544268
Iter: 43 loss: 0.00645383168
Iter: 44 loss: 0.00645375717
Iter: 45 loss: 0.0064537772
Iter: 46 loss: 0.00645370223
Iter: 47 loss: 0.0064536538
Iter: 48 loss: 0.00645408
Iter: 49 loss: 0.00645365054
Iter: 50 loss: 0.0064536389
Iter: 51 loss: 0.00645363517
Iter: 52 loss: 0.00645362493
Iter: 53 loss: 0.00645362446
Iter: 54 loss: 0.00645361748
Iter: 55 loss: 0.00645360909
Iter: 56 loss: 0.00645363517
Iter: 57 loss: 0.0064536077
Iter: 58 loss: 0.00645360351
Iter: 59 loss: 0.00645360351
Iter: 60 loss: 0.00645360257
Iter: 61 loss: 0.00645361189
Iter: 62 loss: 0.00645360211
Iter: 63 loss: 0.00645360071
Iter: 64 loss: 0.00645360071
Iter: 65 loss: 0.00645360071
Iter: 66 loss: 0.00645359838
Iter: 67 loss: 0.00645360537
Iter: 68 loss: 0.00645359838
Iter: 69 loss: 0.00645359885
Iter: 70 loss: 0.0064536
Iter: 71 loss: 0.00645359932
Iter: 72 loss: 0.00645360025
Iter: 73 loss: 0.0064536
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4
+ date
Tue Oct 27 20:37:12 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1adc1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c3e077d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c3e077e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ae050d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ad54400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ad54b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1acd58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ad03ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1acd5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1aca7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ac5d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ac11ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ac119d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1abcaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ac11598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ab86950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ab86f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ab4a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ab1a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ab1a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ab33488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1ab1a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1aab29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1aa49950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1aa49620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1aa09378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1aa398c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1aa399d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a9ef620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a98f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a9efa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a9731e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a97d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a919a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a8d58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1a97d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.031007465
Iter: 2 loss: 0.0299301632
Iter: 3 loss: 0.0259599257
Iter: 4 loss: 0.0132959513
Iter: 5 loss: 0.148895398
Iter: 6 loss: 0.0114797018
Iter: 7 loss: 0.00774400774
Iter: 8 loss: 0.0748757198
Iter: 9 loss: 0.00772933
Iter: 10 loss: 0.00743834
Iter: 11 loss: 0.00710359029
Iter: 12 loss: 0.00686060404
Iter: 13 loss: 0.00744937966
Iter: 14 loss: 0.00677477336
Iter: 15 loss: 0.00666072872
Iter: 16 loss: 0.00731594302
Iter: 17 loss: 0.00664444081
Iter: 18 loss: 0.006597606
Iter: 19 loss: 0.00730056968
Iter: 20 loss: 0.00659757527
Iter: 21 loss: 0.00657146936
Iter: 22 loss: 0.0066307839
Iter: 23 loss: 0.00656165509
Iter: 24 loss: 0.00654777791
Iter: 25 loss: 0.0066475654
Iter: 26 loss: 0.00654658582
Iter: 27 loss: 0.00653644
Iter: 28 loss: 0.006588744
Iter: 29 loss: 0.00653479574
Iter: 30 loss: 0.0065297191
Iter: 31 loss: 0.00653494
Iter: 32 loss: 0.00652688975
Iter: 33 loss: 0.00652297121
Iter: 34 loss: 0.00654325401
Iter: 35 loss: 0.00652234722
Iter: 36 loss: 0.0065199621
Iter: 37 loss: 0.00654466636
Iter: 38 loss: 0.00651989784
Iter: 39 loss: 0.0065185111
Iter: 40 loss: 0.0065230215
Iter: 41 loss: 0.00651812321
Iter: 42 loss: 0.00651734788
Iter: 43 loss: 0.00652024522
Iter: 44 loss: 0.00651716068
Iter: 45 loss: 0.00651669
Iter: 46 loss: 0.00652336515
Iter: 47 loss: 0.00651669083
Iter: 48 loss: 0.00651644357
Iter: 49 loss: 0.00651659723
Iter: 50 loss: 0.00651628571
Iter: 51 loss: 0.00651609153
Iter: 52 loss: 0.00651663821
Iter: 53 loss: 0.00651603192
Iter: 54 loss: 0.00651592668
Iter: 55 loss: 0.00651750062
Iter: 56 loss: 0.00651592575
Iter: 57 loss: 0.00651585497
Iter: 58 loss: 0.0065162587
Iter: 59 loss: 0.00651584659
Iter: 60 loss: 0.00651581306
Iter: 61 loss: 0.00651589315
Iter: 62 loss: 0.00651579909
Iter: 63 loss: 0.00651577115
Iter: 64 loss: 0.0065160403
Iter: 65 loss: 0.00651576975
Iter: 66 loss: 0.00651575439
Iter: 67 loss: 0.0065157651
Iter: 68 loss: 0.00651574507
Iter: 69 loss: 0.00651573483
Iter: 70 loss: 0.00651579956
Iter: 71 loss: 0.0065157325
Iter: 72 loss: 0.00651572738
Iter: 73 loss: 0.0065157814
Iter: 74 loss: 0.00651572691
Iter: 75 loss: 0.00651572365
Iter: 76 loss: 0.00651574414
Iter: 77 loss: 0.00651572272
Iter: 78 loss: 0.00651572039
Iter: 79 loss: 0.00651572552
Iter: 80 loss: 0.00651571807
Iter: 81 loss: 0.00651571713
Iter: 82 loss: 0.00651572458
Iter: 83 loss: 0.00651571807
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8
+ date
Tue Oct 27 20:37:58 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0c99152f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe10b6620d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe10b662840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0c9913840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0c9875d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0c9875c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0a413ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0a4103c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0a4103158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0a4090ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0a4063ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0a4074f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0a40117b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe09064bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0906859d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090685730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0906186a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090638950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090595620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090595268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0905c1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090563d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090535730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0904ca6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0904ca2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe09048b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0904a7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090465840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090470598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090414598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0904709d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0903f41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0903ff268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe09039aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090354ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe090354378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0241318978
Iter: 2 loss: 0.0233073942
Iter: 3 loss: 0.0203331076
Iter: 4 loss: 0.017031759
Iter: 5 loss: 0.0155257834
Iter: 6 loss: 0.0110059688
Iter: 7 loss: 0.0560207255
Iter: 8 loss: 0.0104815643
Iter: 9 loss: 0.0082497187
Iter: 10 loss: 0.00804215
Iter: 11 loss: 0.00756356772
Iter: 12 loss: 0.011959793
Iter: 13 loss: 0.00752786361
Iter: 14 loss: 0.00727342628
Iter: 15 loss: 0.00938645937
Iter: 16 loss: 0.00725020561
Iter: 17 loss: 0.00711887423
Iter: 18 loss: 0.00737463962
Iter: 19 loss: 0.00706618559
Iter: 20 loss: 0.00696248747
Iter: 21 loss: 0.00724081788
Iter: 22 loss: 0.00692640524
Iter: 23 loss: 0.006874952
Iter: 24 loss: 0.0071477145
Iter: 25 loss: 0.00686677685
Iter: 26 loss: 0.00683766976
Iter: 27 loss: 0.00718017481
Iter: 28 loss: 0.0068372651
Iter: 29 loss: 0.00682291202
Iter: 30 loss: 0.00687577203
Iter: 31 loss: 0.00681934878
Iter: 32 loss: 0.00681042206
Iter: 33 loss: 0.00684325676
Iter: 34 loss: 0.0068082
Iter: 35 loss: 0.00680247322
Iter: 36 loss: 0.00682419632
Iter: 37 loss: 0.00680110557
Iter: 38 loss: 0.00679727457
Iter: 39 loss: 0.00682437513
Iter: 40 loss: 0.00679692812
Iter: 41 loss: 0.00679438934
Iter: 42 loss: 0.00680332724
Iter: 43 loss: 0.00679373229
Iter: 44 loss: 0.00679204147
Iter: 45 loss: 0.00680242432
Iter: 46 loss: 0.00679183565
Iter: 47 loss: 0.00679066451
Iter: 48 loss: 0.00679958146
Iter: 49 loss: 0.00679057697
Iter: 50 loss: 0.00678965403
Iter: 51 loss: 0.00679065799
Iter: 52 loss: 0.00678914785
Iter: 53 loss: 0.00678830966
Iter: 54 loss: 0.00679168059
Iter: 55 loss: 0.00678812293
Iter: 56 loss: 0.00678755809
Iter: 57 loss: 0.00679230737
Iter: 58 loss: 0.00678752456
Iter: 59 loss: 0.00678710593
Iter: 60 loss: 0.00678870082
Iter: 61 loss: 0.00678700628
Iter: 62 loss: 0.0067867
Iter: 63 loss: 0.00678664353
Iter: 64 loss: 0.00678643864
Iter: 65 loss: 0.00678609638
Iter: 66 loss: 0.00678740349
Iter: 67 loss: 0.00678601628
Iter: 68 loss: 0.00678577647
Iter: 69 loss: 0.00678718695
Iter: 70 loss: 0.00678574434
Iter: 71 loss: 0.00678557949
Iter: 72 loss: 0.00678630732
Iter: 73 loss: 0.00678554643
Iter: 74 loss: 0.00678543421
Iter: 75 loss: 0.00678583095
Iter: 76 loss: 0.00678540301
Iter: 77 loss: 0.00678531919
Iter: 78 loss: 0.00678584119
Iter: 79 loss: 0.00678530848
Iter: 80 loss: 0.0067852526
Iter: 81 loss: 0.00678544538
Iter: 82 loss: 0.00678523723
Iter: 83 loss: 0.00678520231
Iter: 84 loss: 0.00678520184
Iter: 85 loss: 0.00678518042
Iter: 86 loss: 0.00678519672
Iter: 87 loss: 0.00678516505
Iter: 88 loss: 0.00678514875
Iter: 89 loss: 0.00678522326
Iter: 90 loss: 0.0067851441
Iter: 91 loss: 0.00678513106
Iter: 92 loss: 0.00678527681
Iter: 93 loss: 0.00678513106
Iter: 94 loss: 0.00678512268
Iter: 95 loss: 0.0067851278
Iter: 96 loss: 0.00678511662
Iter: 97 loss: 0.00678510964
Iter: 98 loss: 0.0067851292
Iter: 99 loss: 0.00678510591
Iter: 100 loss: 0.00678510079
Iter: 101 loss: 0.00678512407
Iter: 102 loss: 0.0067851
Iter: 103 loss: 0.00678509613
Iter: 104 loss: 0.00678511476
Iter: 105 loss: 0.0067850952
Iter: 106 loss: 0.00678509288
Iter: 107 loss: 0.00678510033
Iter: 108 loss: 0.00678509101
Iter: 109 loss: 0.00678509055
Iter: 110 loss: 0.00678510405
Iter: 111 loss: 0.00678509
Iter: 112 loss: 0.00678508822
Iter: 113 loss: 0.00678509055
Iter: 114 loss: 0.00678508868
Iter: 115 loss: 0.00678508775
Iter: 116 loss: 0.00678509567
Iter: 117 loss: 0.00678508822
Iter: 118 loss: 0.00678508682
Iter: 119 loss: 0.00678509
Iter: 120 loss: 0.00678508729
Iter: 121 loss: 0.00678508822
Iter: 122 loss: 0.00678508682
Iter: 123 loss: 0.00678508542
Iter: 124 loss: 0.00678508589
Iter: 125 loss: 0.00678508822
Iter: 126 loss: 0.00678508636
Iter: 127 loss: 0.00678508542
Iter: 128 loss: 0.00678508775
Iter: 129 loss: 0.00678508729
Iter: 130 loss: 0.00678508775
Iter: 131 loss: 0.00678508542
Iter: 132 loss: 0.00678508542
Iter: 133 loss: 0.00678508636
Iter: 134 loss: 0.00678508729
Iter: 135 loss: 0.00678508775
Iter: 136 loss: 0.00678508589
Iter: 137 loss: 0.00678508636
Iter: 138 loss: 0.00678508636
Iter: 139 loss: 0.00678508682
Iter: 140 loss: 0.00678508636
Iter: 141 loss: 0.00678508682
Iter: 142 loss: 0.00678508542
Iter: 143 loss: 0.00678508589
Iter: 144 loss: 0.00678508449
Iter: 145 loss: 0.00678508496
Iter: 146 loss: 0.00678508542
Iter: 147 loss: 0.00678508496
Iter: 148 loss: 0.00678508496
Iter: 149 loss: 0.00678508729
Iter: 150 loss: 0.00678508542
Iter: 151 loss: 0.00678508636
Iter: 152 loss: 0.00678508682
Iter: 153 loss: 0.00678508729
Iter: 154 loss: 0.00678508682
Iter: 155 loss: 0.00678508636
Iter: 156 loss: 0.00678508636
Iter: 157 loss: 0.00678508636
Iter: 158 loss: 0.00678508729
Iter: 159 loss: 0.00678508636
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2
+ date
Tue Oct 27 20:39:03 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b44396268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b443b8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b443b8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b4434cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b442baae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b4434cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b4421b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b442459d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b441d96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b441f48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b441ae2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b4415b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b44185158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b44185a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b44141ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b440e3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b440fb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b44141158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b4405e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b44092048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b440920d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b44092ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b440019d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43f98730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43f988c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43fc9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43f8f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43f31620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43f3c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43f3c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43f07ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43ec01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43eccb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43e6f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43e6f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9b43e451e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0246190783
Iter: 2 loss: 0.0226707309
Iter: 3 loss: 0.0171004348
Iter: 4 loss: 5636.24219
Iter: 5 loss: 0.0349126793
Iter: 6 loss: 0.0207986459
Iter: 7 loss: 0.025008224
Iter: 8 loss: 0.0168355927
Iter: 9 loss: 0.0143380379
Iter: 10 loss: 0.0128201256
Iter: 11 loss: 0.0106513
Iter: 12 loss: 0.0486696512
Iter: 13 loss: 0.0105693219
Iter: 14 loss: 0.00892428309
Iter: 15 loss: 0.0192551948
Iter: 16 loss: 0.0087136263
Iter: 17 loss: 0.00825789943
Iter: 18 loss: 0.00892488193
Iter: 19 loss: 0.00803655572
Iter: 20 loss: 0.00774574932
Iter: 21 loss: 0.00963744707
Iter: 22 loss: 0.0076987166
Iter: 23 loss: 0.00757431099
Iter: 24 loss: 0.00932614133
Iter: 25 loss: 0.00757323112
Iter: 26 loss: 0.00749655813
Iter: 27 loss: 0.00755302282
Iter: 28 loss: 0.0074500544
Iter: 29 loss: 0.00738620199
Iter: 30 loss: 0.00751010235
Iter: 31 loss: 0.00735916337
Iter: 32 loss: 0.00729945442
Iter: 33 loss: 0.00741523504
Iter: 34 loss: 0.00727351895
Iter: 35 loss: 0.00722880056
Iter: 36 loss: 0.00767882681
Iter: 37 loss: 0.00722721871
Iter: 38 loss: 0.00720007624
Iter: 39 loss: 0.00724223163
Iter: 40 loss: 0.00718716392
Iter: 41 loss: 0.00716651
Iter: 42 loss: 0.00732703321
Iter: 43 loss: 0.00716493232
Iter: 44 loss: 0.00715088844
Iter: 45 loss: 0.00720710214
Iter: 46 loss: 0.0071477592
Iter: 47 loss: 0.0071387128
Iter: 48 loss: 0.007171473
Iter: 49 loss: 0.00713640964
Iter: 50 loss: 0.00713043
Iter: 51 loss: 0.00716433674
Iter: 52 loss: 0.00712959748
Iter: 53 loss: 0.00712686032
Iter: 54 loss: 0.00712679559
Iter: 55 loss: 0.00712459954
Iter: 56 loss: 0.00712552946
Iter: 57 loss: 0.00712309359
Iter: 58 loss: 0.00712094642
Iter: 59 loss: 0.00712288916
Iter: 60 loss: 0.00711970311
Iter: 61 loss: 0.00711757969
Iter: 62 loss: 0.00714695826
Iter: 63 loss: 0.00711756945
Iter: 64 loss: 0.00711628655
Iter: 65 loss: 0.00711654685
Iter: 66 loss: 0.00711533567
Iter: 67 loss: 0.00711391959
Iter: 68 loss: 0.00711587723
Iter: 69 loss: 0.00711321831
Iter: 70 loss: 0.0071117226
Iter: 71 loss: 0.00711694919
Iter: 72 loss: 0.00711133331
Iter: 73 loss: 0.00711008301
Iter: 74 loss: 0.00711568817
Iter: 75 loss: 0.00710983761
Iter: 76 loss: 0.00710883783
Iter: 77 loss: 0.00711125461
Iter: 78 loss: 0.00710847788
Iter: 79 loss: 0.00710760243
Iter: 80 loss: 0.00711226184
Iter: 81 loss: 0.00710746832
Iter: 82 loss: 0.00710680289
Iter: 83 loss: 0.00710833399
Iter: 84 loss: 0.00710655469
Iter: 85 loss: 0.00710592512
Iter: 86 loss: 0.00710687414
Iter: 87 loss: 0.00710562477
Iter: 88 loss: 0.00710501801
Iter: 89 loss: 0.00710800244
Iter: 90 loss: 0.00710491091
Iter: 91 loss: 0.00710456306
Iter: 92 loss: 0.00710454863
Iter: 93 loss: 0.00710427715
Iter: 94 loss: 0.00710405828
Iter: 95 loss: 0.00710397772
Iter: 96 loss: 0.00710364617
Iter: 97 loss: 0.00710449
Iter: 98 loss: 0.00710353255
Iter: 99 loss: 0.00710327458
Iter: 100 loss: 0.00710690767
Iter: 101 loss: 0.00710327365
Iter: 102 loss: 0.00710308552
Iter: 103 loss: 0.00710309902
Iter: 104 loss: 0.0071029379
Iter: 105 loss: 0.00710272556
Iter: 106 loss: 0.00710293138
Iter: 107 loss: 0.00710260449
Iter: 108 loss: 0.0071023968
Iter: 109 loss: 0.00710382685
Iter: 110 loss: 0.00710237678
Iter: 111 loss: 0.00710222963
Iter: 112 loss: 0.00710242521
Iter: 113 loss: 0.0071021528
Iter: 114 loss: 0.00710201403
Iter: 115 loss: 0.00710280053
Iter: 116 loss: 0.00710199494
Iter: 117 loss: 0.00710189203
Iter: 118 loss: 0.00710234046
Iter: 119 loss: 0.00710187107
Iter: 120 loss: 0.00710178632
Iter: 121 loss: 0.00710209645
Iter: 122 loss: 0.00710176723
Iter: 123 loss: 0.0071017
Iter: 124 loss: 0.00710181426
Iter: 125 loss: 0.00710167084
Iter: 126 loss: 0.00710162194
Iter: 127 loss: 0.00710205361
Iter: 128 loss: 0.00710161915
Iter: 129 loss: 0.0071015819
Iter: 130 loss: 0.00710200192
Iter: 131 loss: 0.00710158236
Iter: 132 loss: 0.00710155722
Iter: 133 loss: 0.00710155535
Iter: 134 loss: 0.00710153859
Iter: 135 loss: 0.00710151158
Iter: 136 loss: 0.00710163219
Iter: 137 loss: 0.00710150739
Iter: 138 loss: 0.00710148551
Iter: 139 loss: 0.00710163685
Iter: 140 loss: 0.00710148644
Iter: 141 loss: 0.00710147107
Iter: 142 loss: 0.00710146362
Iter: 143 loss: 0.00710145803
Iter: 144 loss: 0.0071014422
Iter: 145 loss: 0.00710151112
Iter: 146 loss: 0.00710143754
Iter: 147 loss: 0.0071014273
Iter: 148 loss: 0.00710146595
Iter: 149 loss: 0.00710142311
Iter: 150 loss: 0.00710141566
Iter: 151 loss: 0.00710146409
Iter: 152 loss: 0.00710141473
Iter: 153 loss: 0.00710140727
Iter: 154 loss: 0.00710143801
Iter: 155 loss: 0.00710140727
Iter: 156 loss: 0.00710140262
Iter: 157 loss: 0.00710141193
Iter: 158 loss: 0.00710140169
Iter: 159 loss: 0.0071013961
Iter: 160 loss: 0.00710141845
Iter: 161 loss: 0.0071013961
Iter: 162 loss: 0.00710139191
Iter: 163 loss: 0.00710140541
Iter: 164 loss: 0.00710139191
Iter: 165 loss: 0.00710139051
Iter: 166 loss: 0.00710141473
Iter: 167 loss: 0.00710139051
Iter: 168 loss: 0.00710139
Iter: 169 loss: 0.00710138958
Iter: 170 loss: 0.00710138865
Iter: 171 loss: 0.00710138818
Iter: 172 loss: 0.00710138865
Iter: 173 loss: 0.00710138585
Iter: 174 loss: 0.00710138446
Iter: 175 loss: 0.00710139889
Iter: 176 loss: 0.00710138446
Iter: 177 loss: 0.00710138446
Iter: 178 loss: 0.00710138399
Iter: 179 loss: 0.00710138306
Iter: 180 loss: 0.00710138306
Iter: 181 loss: 0.00710138492
Iter: 182 loss: 0.00710138259
Iter: 183 loss: 0.0071013812
Iter: 184 loss: 0.00710138492
Iter: 185 loss: 0.00710138073
Iter: 186 loss: 0.00710138213
Iter: 187 loss: 0.00710138399
Iter: 188 loss: 0.00710138073
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6
+ date
Tue Oct 27 20:40:12 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a86772730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7ac9d06d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7ac9d06d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a867bb0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a86712158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a86720ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a86720e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a86720488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6063e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a605cc488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6059bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6059b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6059b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a60507d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6053f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6053f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a604d27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a604f7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a604588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a604582f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a60475488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a604758c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a603f0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a60475ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a60394840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a60394e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a603828c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a603829d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a60326620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a602c4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a60326a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a602af268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a602b7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6025ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6020fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a6020f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0302911773
Iter: 2 loss: 0.0225266963
Iter: 3 loss: 4917.66211
Iter: 4 loss: 0.0225265697
Iter: 5 loss: 0.0598707423
Iter: 6 loss: 0.0216489062
Iter: 7 loss: 0.0243027788
Iter: 8 loss: 0.0179512035
Iter: 9 loss: 0.0179318227
Iter: 10 loss: 0.0159506109
Iter: 11 loss: 0.0145418923
Iter: 12 loss: 0.0136334691
Iter: 13 loss: 0.0114519019
Iter: 14 loss: 0.0114467833
Iter: 15 loss: 0.0106174825
Iter: 16 loss: 0.0120482035
Iter: 17 loss: 0.0102756722
Iter: 18 loss: 0.00948281214
Iter: 19 loss: 0.0143291084
Iter: 20 loss: 0.00930072553
Iter: 21 loss: 0.00886490569
Iter: 22 loss: 0.0129164988
Iter: 23 loss: 0.00881803
Iter: 24 loss: 0.00851433817
Iter: 25 loss: 0.00977267325
Iter: 26 loss: 0.00844587944
Iter: 27 loss: 0.00827963836
Iter: 28 loss: 0.00818015262
Iter: 29 loss: 0.00811147876
Iter: 30 loss: 0.00792763568
Iter: 31 loss: 0.0109830424
Iter: 32 loss: 0.00792632811
Iter: 33 loss: 0.00782497
Iter: 34 loss: 0.0088340193
Iter: 35 loss: 0.00782152638
Iter: 36 loss: 0.00777089596
Iter: 37 loss: 0.00790222362
Iter: 38 loss: 0.00775245344
Iter: 39 loss: 0.00770856533
Iter: 40 loss: 0.00792736933
Iter: 41 loss: 0.00770186493
Iter: 42 loss: 0.00766520109
Iter: 43 loss: 0.00764645357
Iter: 44 loss: 0.00762906624
Iter: 45 loss: 0.00758196041
Iter: 46 loss: 0.0079066772
Iter: 47 loss: 0.00757699413
Iter: 48 loss: 0.00755201653
Iter: 49 loss: 0.00769574568
Iter: 50 loss: 0.00754838204
Iter: 51 loss: 0.0075253346
Iter: 52 loss: 0.00760313123
Iter: 53 loss: 0.00751927448
Iter: 54 loss: 0.00750050088
Iter: 55 loss: 0.00759738591
Iter: 56 loss: 0.00749722589
Iter: 57 loss: 0.00748241041
Iter: 58 loss: 0.00754694734
Iter: 59 loss: 0.00747946
Iter: 60 loss: 0.00746514602
Iter: 61 loss: 0.00747993775
Iter: 62 loss: 0.00745706726
Iter: 63 loss: 0.0074416874
Iter: 64 loss: 0.00746721122
Iter: 65 loss: 0.00743465405
Iter: 66 loss: 0.0074211522
Iter: 67 loss: 0.00752903149
Iter: 68 loss: 0.00742027629
Iter: 69 loss: 0.00741033349
Iter: 70 loss: 0.00743855396
Iter: 71 loss: 0.00740712369
Iter: 72 loss: 0.00740059325
Iter: 73 loss: 0.00748752
Iter: 74 loss: 0.0074005709
Iter: 75 loss: 0.00739600882
Iter: 76 loss: 0.00739196735
Iter: 77 loss: 0.00739077292
Iter: 78 loss: 0.00738432445
Iter: 79 loss: 0.00741371606
Iter: 80 loss: 0.00738306204
Iter: 81 loss: 0.00737820612
Iter: 82 loss: 0.00739265326
Iter: 83 loss: 0.00737669598
Iter: 84 loss: 0.00737330317
Iter: 85 loss: 0.00738236681
Iter: 86 loss: 0.00737217162
Iter: 87 loss: 0.00736925285
Iter: 88 loss: 0.00739991479
Iter: 89 loss: 0.0073691681
Iter: 90 loss: 0.00736728776
Iter: 91 loss: 0.00737877376
Iter: 92 loss: 0.0073670689
Iter: 93 loss: 0.00736553874
Iter: 94 loss: 0.0073669618
Iter: 95 loss: 0.00736465445
Iter: 96 loss: 0.00736314524
Iter: 97 loss: 0.00736337
Iter: 98 loss: 0.00736200344
Iter: 99 loss: 0.00736012263
Iter: 100 loss: 0.00736848777
Iter: 101 loss: 0.00735975057
Iter: 102 loss: 0.00735848304
Iter: 103 loss: 0.00736483932
Iter: 104 loss: 0.00735826837
Iter: 105 loss: 0.00735720852
Iter: 106 loss: 0.0073625003
Iter: 107 loss: 0.00735703483
Iter: 108 loss: 0.00735608488
Iter: 109 loss: 0.00735992845
Iter: 110 loss: 0.00735587487
Iter: 111 loss: 0.00735503109
Iter: 112 loss: 0.00735562434
Iter: 113 loss: 0.00735450676
Iter: 114 loss: 0.00735365553
Iter: 115 loss: 0.00735478103
Iter: 116 loss: 0.00735322386
Iter: 117 loss: 0.0073524341
Iter: 118 loss: 0.00735495239
Iter: 119 loss: 0.00735220732
Iter: 120 loss: 0.00735134678
Iter: 121 loss: 0.00735403784
Iter: 122 loss: 0.00735109393
Iter: 123 loss: 0.00735045411
Iter: 124 loss: 0.00735348277
Iter: 125 loss: 0.00735033862
Iter: 126 loss: 0.0073498548
Iter: 127 loss: 0.00734985247
Iter: 128 loss: 0.00734957308
Iter: 129 loss: 0.00734935841
Iter: 130 loss: 0.00734926574
Iter: 131 loss: 0.00734886248
Iter: 132 loss: 0.00734940358
Iter: 133 loss: 0.00734866038
Iter: 134 loss: 0.00734819658
Iter: 135 loss: 0.0073494222
Iter: 136 loss: 0.00734803872
Iter: 137 loss: 0.00734764291
Iter: 138 loss: 0.00734882057
Iter: 139 loss: 0.00734752463
Iter: 140 loss: 0.00734719262
Iter: 141 loss: 0.00734963082
Iter: 142 loss: 0.00734716468
Iter: 143 loss: 0.00734685455
Iter: 144 loss: 0.00734800752
Iter: 145 loss: 0.00734677818
Iter: 146 loss: 0.0073465053
Iter: 147 loss: 0.00734668178
Iter: 148 loss: 0.00734633254
Iter: 149 loss: 0.00734606571
Iter: 150 loss: 0.00734698726
Iter: 151 loss: 0.00734599726
Iter: 152 loss: 0.00734574068
Iter: 153 loss: 0.0073460429
Iter: 154 loss: 0.00734560611
Iter: 155 loss: 0.00734534534
Iter: 156 loss: 0.00734585663
Iter: 157 loss: 0.00734524056
Iter: 158 loss: 0.00734507712
Iter: 159 loss: 0.00734507618
Iter: 160 loss: 0.00734490342
Iter: 161 loss: 0.00734513393
Iter: 162 loss: 0.00734481774
Iter: 163 loss: 0.00734466594
Iter: 164 loss: 0.00734481262
Iter: 165 loss: 0.00734458119
Iter: 166 loss: 0.00734441029
Iter: 167 loss: 0.00734446757
Iter: 168 loss: 0.00734429061
Iter: 169 loss: 0.0073440955
Iter: 170 loss: 0.00734508364
Iter: 171 loss: 0.00734406151
Iter: 172 loss: 0.00734387711
Iter: 173 loss: 0.00734430179
Iter: 174 loss: 0.00734380959
Iter: 175 loss: 0.00734365731
Iter: 176 loss: 0.00734452438
Iter: 177 loss: 0.00734363543
Iter: 178 loss: 0.00734348688
Iter: 179 loss: 0.00734424358
Iter: 180 loss: 0.00734346081
Iter: 181 loss: 0.00734335091
Iter: 182 loss: 0.00734324288
Iter: 183 loss: 0.0073432168
Iter: 184 loss: 0.00734304823
Iter: 185 loss: 0.00734400097
Iter: 186 loss: 0.00734302308
Iter: 187 loss: 0.00734288245
Iter: 188 loss: 0.00734321168
Iter: 189 loss: 0.00734283123
Iter: 190 loss: 0.00734270364
Iter: 191 loss: 0.00734294951
Iter: 192 loss: 0.00734265242
Iter: 193 loss: 0.00734257605
Iter: 194 loss: 0.00734256674
Iter: 195 loss: 0.00734249642
Iter: 196 loss: 0.00734239537
Iter: 197 loss: 0.00734239304
Iter: 198 loss: 0.00734228222
Iter: 199 loss: 0.00734259421
Iter: 200 loss: 0.00734224916
Iter: 201 loss: 0.00734214298
Iter: 202 loss: 0.007342258
Iter: 203 loss: 0.00734208431
Iter: 204 loss: 0.00734198
Iter: 205 loss: 0.0073427204
Iter: 206 loss: 0.00734197069
Iter: 207 loss: 0.00734188221
Iter: 208 loss: 0.00734197861
Iter: 209 loss: 0.00734183565
Iter: 210 loss: 0.00734177232
Iter: 211 loss: 0.00734177092
Iter: 212 loss: 0.0073417169
Iter: 213 loss: 0.00734173134
Iter: 214 loss: 0.00734167825
Iter: 215 loss: 0.00734162331
Iter: 216 loss: 0.00734171411
Iter: 217 loss: 0.00734159956
Iter: 218 loss: 0.00734153669
Iter: 219 loss: 0.00734164473
Iter: 220 loss: 0.00734150875
Iter: 221 loss: 0.00734145287
Iter: 222 loss: 0.00734173181
Iter: 223 loss: 0.00734144496
Iter: 224 loss: 0.0073414
Iter: 225 loss: 0.00734168477
Iter: 226 loss: 0.0073413942
Iter: 227 loss: 0.00734135928
Iter: 228 loss: 0.0073416885
Iter: 229 loss: 0.00734135788
Iter: 230 loss: 0.00734133739
Iter: 231 loss: 0.00734130805
Iter: 232 loss: 0.00734130945
Iter: 233 loss: 0.0073412708
Iter: 234 loss: 0.00734132901
Iter: 235 loss: 0.00734125637
Iter: 236 loss: 0.00734122191
Iter: 237 loss: 0.0073414566
Iter: 238 loss: 0.00734121911
Iter: 239 loss: 0.0073411935
Iter: 240 loss: 0.00734124798
Iter: 241 loss: 0.00734118372
Iter: 242 loss: 0.00734115904
Iter: 243 loss: 0.00734127266
Iter: 244 loss: 0.00734115485
Iter: 245 loss: 0.00734113529
Iter: 246 loss: 0.00734134763
Iter: 247 loss: 0.00734113529
Iter: 248 loss: 0.00734112132
Iter: 249 loss: 0.00734111667
Iter: 250 loss: 0.00734110922
Iter: 251 loss: 0.00734109338
Iter: 252 loss: 0.00734113809
Iter: 253 loss: 0.00734108733
Iter: 254 loss: 0.00734107476
Iter: 255 loss: 0.00734110689
Iter: 256 loss: 0.00734106824
Iter: 257 loss: 0.00734105287
Iter: 258 loss: 0.00734114926
Iter: 259 loss: 0.00734105287
Iter: 260 loss: 0.00734104682
Iter: 261 loss: 0.00734104542
Iter: 262 loss: 0.00734104
Iter: 263 loss: 0.00734103378
Iter: 264 loss: 0.00734103471
Iter: 265 loss: 0.00734102726
Iter: 266 loss: 0.00734102819
Iter: 267 loss: 0.00734101888
Iter: 268 loss: 0.0073410091
Iter: 269 loss: 0.00734104868
Iter: 270 loss: 0.00734100677
Iter: 271 loss: 0.00734100025
Iter: 272 loss: 0.00734102214
Iter: 273 loss: 0.00734099792
Iter: 274 loss: 0.00734098908
Iter: 275 loss: 0.00734102912
Iter: 276 loss: 0.00734099
Iter: 277 loss: 0.00734098442
Iter: 278 loss: 0.00734101189
Iter: 279 loss: 0.00734098349
Iter: 280 loss: 0.00734098069
Iter: 281 loss: 0.00734100537
Iter: 282 loss: 0.00734097976
Iter: 283 loss: 0.00734097697
Iter: 284 loss: 0.00734097324
Iter: 285 loss: 0.00734097185
Iter: 286 loss: 0.00734096766
Iter: 287 loss: 0.00734098814
Iter: 288 loss: 0.00734096719
Iter: 289 loss: 0.00734096393
Iter: 290 loss: 0.00734099187
Iter: 291 loss: 0.00734096393
Iter: 292 loss: 0.00734096114
Iter: 293 loss: 0.00734097511
Iter: 294 loss: 0.00734096114
Iter: 295 loss: 0.00734095694
Iter: 296 loss: 0.00734096812
Iter: 297 loss: 0.00734095555
Iter: 298 loss: 0.00734095462
Iter: 299 loss: 0.00734095462
Iter: 300 loss: 0.00734095462
Iter: 301 loss: 0.00734095136
Iter: 302 loss: 0.00734095555
Iter: 303 loss: 0.00734094903
Iter: 304 loss: 0.00734094717
Iter: 305 loss: 0.00734095369
Iter: 306 loss: 0.00734094623
Iter: 307 loss: 0.00734094344
Iter: 308 loss: 0.00734095322
Iter: 309 loss: 0.00734094437
Iter: 310 loss: 0.00734094344
Iter: 311 loss: 0.00734095788
Iter: 312 loss: 0.00734094251
Iter: 313 loss: 0.00734094
Iter: 314 loss: 0.0073409453
Iter: 315 loss: 0.00734093972
Iter: 316 loss: 0.00734093972
Iter: 317 loss: 0.00734094
Iter: 318 loss: 0.00734093785
Iter: 319 loss: 0.00734093692
Iter: 320 loss: 0.00734093692
Iter: 321 loss: 0.00734093506
Iter: 322 loss: 0.00734093413
Iter: 323 loss: 0.00734094111
Iter: 324 loss: 0.00734093552
Iter: 325 loss: 0.0073409332
Iter: 326 loss: 0.00734093878
Iter: 327 loss: 0.0073409332
Iter: 328 loss: 0.00734093273
Iter: 329 loss: 0.00734093832
Iter: 330 loss: 0.00734093226
Iter: 331 loss: 0.0073409332
Iter: 332 loss: 0.00734093087
Iter: 333 loss: 0.00734093226
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2
+ date
Tue Oct 27 20:41:53 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc85c66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cef748ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cef748510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8603048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc85586a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8558b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc84d17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc84fc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc84fc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc84a8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc845f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8419400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8428378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc83cdc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc84049d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc84042f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc83918c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc83b68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc837ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8342510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc82cc488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc82ccb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc82a3950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8252950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc82521e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc82526a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc823b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc81df598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc81dfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc820bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc81af2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8168598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc817c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8168400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc8147620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2cc80f5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0432445481
Iter: 2 loss: 886.448059
Iter: 3 loss: 0.0569283515
Iter: 4 loss: 0.0405060798
Iter: 5 loss: 0.0278499015
Iter: 6 loss: 0.0274761319
Iter: 7 loss: 0.142329246
Iter: 8 loss: 0.0272692908
Iter: 9 loss: 0.0269701704
Iter: 10 loss: 0.0257224143
Iter: 11 loss: 0.023488773
Iter: 12 loss: 0.076117605
Iter: 13 loss: 0.0233837515
Iter: 14 loss: 0.0198375545
Iter: 15 loss: 0.116883121
Iter: 16 loss: 0.0197292492
Iter: 17 loss: 0.0167088024
Iter: 18 loss: 0.0166289732
Iter: 19 loss: 0.0149475345
Iter: 20 loss: 0.0214320719
Iter: 21 loss: 0.0147666959
Iter: 22 loss: 0.0144256875
Iter: 23 loss: 0.0139358416
Iter: 24 loss: 0.0139045147
Iter: 25 loss: 0.0132870823
Iter: 26 loss: 0.0134689733
Iter: 27 loss: 0.0128280204
Iter: 28 loss: 0.0116759837
Iter: 29 loss: 0.0153673487
Iter: 30 loss: 0.0113664009
Iter: 31 loss: 0.0107765123
Iter: 32 loss: 0.0113248695
Iter: 33 loss: 0.0104001388
Iter: 34 loss: 0.00985486247
Iter: 35 loss: 0.0141533557
Iter: 36 loss: 0.00978309382
Iter: 37 loss: 0.00937003
Iter: 38 loss: 0.0125330286
Iter: 39 loss: 0.00933292694
Iter: 40 loss: 0.00909029786
Iter: 41 loss: 0.0117869563
Iter: 42 loss: 0.00908408
Iter: 43 loss: 0.00890963152
Iter: 44 loss: 0.00914153643
Iter: 45 loss: 0.0088167442
Iter: 46 loss: 0.00863132905
Iter: 47 loss: 0.0100263814
Iter: 48 loss: 0.00861365348
Iter: 49 loss: 0.00845566206
Iter: 50 loss: 0.0101085678
Iter: 51 loss: 0.00845130719
Iter: 52 loss: 0.00832661428
Iter: 53 loss: 0.00832550786
Iter: 54 loss: 0.0082559241
Iter: 55 loss: 0.00917635486
Iter: 56 loss: 0.00825592224
Iter: 57 loss: 0.00819484
Iter: 58 loss: 0.00820102729
Iter: 59 loss: 0.0081455037
Iter: 60 loss: 0.00805774238
Iter: 61 loss: 0.00802826509
Iter: 62 loss: 0.0079758158
Iter: 63 loss: 0.00788005535
Iter: 64 loss: 0.00818480644
Iter: 65 loss: 0.00785103627
Iter: 66 loss: 0.00778779387
Iter: 67 loss: 0.00778721645
Iter: 68 loss: 0.00773035642
Iter: 69 loss: 0.00786590576
Iter: 70 loss: 0.00770917628
Iter: 71 loss: 0.00767410966
Iter: 72 loss: 0.00793937873
Iter: 73 loss: 0.00767156482
Iter: 74 loss: 0.00764114875
Iter: 75 loss: 0.00770690246
Iter: 76 loss: 0.00762903225
Iter: 77 loss: 0.00759217422
Iter: 78 loss: 0.00766098173
Iter: 79 loss: 0.00757622905
Iter: 80 loss: 0.00754849426
Iter: 81 loss: 0.00758964662
Iter: 82 loss: 0.00753500266
Iter: 83 loss: 0.00750336051
Iter: 84 loss: 0.00765442941
Iter: 85 loss: 0.00749749551
Iter: 86 loss: 0.0075016
Iter: 87 loss: 0.00748752896
Iter: 88 loss: 0.00747981528
Iter: 89 loss: 0.00750444
Iter: 90 loss: 0.00747773517
Iter: 91 loss: 0.00746984454
Iter: 92 loss: 0.00745455362
Iter: 93 loss: 0.00777468458
Iter: 94 loss: 0.00745445956
Iter: 95 loss: 0.00743931811
Iter: 96 loss: 0.00747034932
Iter: 97 loss: 0.00743317744
Iter: 98 loss: 0.00741726393
Iter: 99 loss: 0.00744354
Iter: 100 loss: 0.00740984455
Iter: 101 loss: 0.00739944866
Iter: 102 loss: 0.00754370447
Iter: 103 loss: 0.00739940954
Iter: 104 loss: 0.00738913054
Iter: 105 loss: 0.00739875436
Iter: 106 loss: 0.00738314725
Iter: 107 loss: 0.00737438584
Iter: 108 loss: 0.00740098581
Iter: 109 loss: 0.00737185357
Iter: 110 loss: 0.00736251613
Iter: 111 loss: 0.00735501898
Iter: 112 loss: 0.00735221151
Iter: 113 loss: 0.00734125264
Iter: 114 loss: 0.0074433093
Iter: 115 loss: 0.00734079396
Iter: 116 loss: 0.00733111892
Iter: 117 loss: 0.00733519485
Iter: 118 loss: 0.00732441107
Iter: 119 loss: 0.00731509
Iter: 120 loss: 0.00733855879
Iter: 121 loss: 0.0073119672
Iter: 122 loss: 0.00730410311
Iter: 123 loss: 0.00734673254
Iter: 124 loss: 0.00730282813
Iter: 125 loss: 0.00729740039
Iter: 126 loss: 0.00729114795
Iter: 127 loss: 0.00729038659
Iter: 128 loss: 0.00727962609
Iter: 129 loss: 0.00731831975
Iter: 130 loss: 0.00727684563
Iter: 131 loss: 0.00726760458
Iter: 132 loss: 0.00731596909
Iter: 133 loss: 0.00726614054
Iter: 134 loss: 0.00725943921
Iter: 135 loss: 0.0072637843
Iter: 136 loss: 0.00725515839
Iter: 137 loss: 0.00724735856
Iter: 138 loss: 0.0072854124
Iter: 139 loss: 0.00724601932
Iter: 140 loss: 0.00723960856
Iter: 141 loss: 0.00727015734
Iter: 142 loss: 0.00723843044
Iter: 143 loss: 0.0072316397
Iter: 144 loss: 0.00726912171
Iter: 145 loss: 0.00723069347
Iter: 146 loss: 0.00722593
Iter: 147 loss: 0.00722966576
Iter: 148 loss: 0.00722304173
Iter: 149 loss: 0.00721769966
Iter: 150 loss: 0.00721617416
Iter: 151 loss: 0.00721293222
Iter: 152 loss: 0.0072074933
Iter: 153 loss: 0.00720749469
Iter: 154 loss: 0.00720442133
Iter: 155 loss: 0.00724341394
Iter: 156 loss: 0.0072044055
Iter: 157 loss: 0.00720183738
Iter: 158 loss: 0.00719920825
Iter: 159 loss: 0.0071987086
Iter: 160 loss: 0.00719580427
Iter: 161 loss: 0.00719252508
Iter: 162 loss: 0.00719209807
Iter: 163 loss: 0.00718742935
Iter: 164 loss: 0.0072287675
Iter: 165 loss: 0.00718719047
Iter: 166 loss: 0.00718344236
Iter: 167 loss: 0.00718912156
Iter: 168 loss: 0.00718165748
Iter: 169 loss: 0.00717836898
Iter: 170 loss: 0.00721211964
Iter: 171 loss: 0.00717826653
Iter: 172 loss: 0.00717575289
Iter: 173 loss: 0.00718451664
Iter: 174 loss: 0.0071751
Iter: 175 loss: 0.00717287604
Iter: 176 loss: 0.0071786521
Iter: 177 loss: 0.00717210444
Iter: 178 loss: 0.00716991723
Iter: 179 loss: 0.00717564905
Iter: 180 loss: 0.00716917869
Iter: 181 loss: 0.00716696307
Iter: 182 loss: 0.0071716141
Iter: 183 loss: 0.00716608251
Iter: 184 loss: 0.0071641109
Iter: 185 loss: 0.00717510376
Iter: 186 loss: 0.00716383941
Iter: 187 loss: 0.00716215512
Iter: 188 loss: 0.00717562437
Iter: 189 loss: 0.00716203358
Iter: 190 loss: 0.00716051739
Iter: 191 loss: 0.0071626408
Iter: 192 loss: 0.00715977186
Iter: 193 loss: 0.00715852808
Iter: 194 loss: 0.00715654716
Iter: 195 loss: 0.00715652946
Iter: 196 loss: 0.00715466961
Iter: 197 loss: 0.00717348419
Iter: 198 loss: 0.00715461373
Iter: 199 loss: 0.00715295877
Iter: 200 loss: 0.00715551339
Iter: 201 loss: 0.0071521732
Iter: 202 loss: 0.00715077342
Iter: 203 loss: 0.00715596508
Iter: 204 loss: 0.00715043442
Iter: 205 loss: 0.00714919902
Iter: 206 loss: 0.00715666916
Iter: 207 loss: 0.00714904442
Iter: 208 loss: 0.00714804325
Iter: 209 loss: 0.00715323025
Iter: 210 loss: 0.00714788446
Iter: 211 loss: 0.00714709191
Iter: 212 loss: 0.00714837434
Iter: 213 loss: 0.0071467245
Iter: 214 loss: 0.00714587094
Iter: 215 loss: 0.00714645628
Iter: 216 loss: 0.0071453359
Iter: 217 loss: 0.0071444558
Iter: 218 loss: 0.00715007447
Iter: 219 loss: 0.00714435661
Iter: 220 loss: 0.0071437587
Iter: 221 loss: 0.00715044886
Iter: 222 loss: 0.00714374706
Iter: 223 loss: 0.00714322645
Iter: 224 loss: 0.0071437424
Iter: 225 loss: 0.00714293029
Iter: 226 loss: 0.00714237057
Iter: 227 loss: 0.00714150909
Iter: 228 loss: 0.00714149745
Iter: 229 loss: 0.00714052422
Iter: 230 loss: 0.00714361435
Iter: 231 loss: 0.00714024529
Iter: 232 loss: 0.0071394043
Iter: 233 loss: 0.00714407
Iter: 234 loss: 0.00713928277
Iter: 235 loss: 0.00713855447
Iter: 236 loss: 0.00714165578
Iter: 237 loss: 0.00713840313
Iter: 238 loss: 0.00713781267
Iter: 239 loss: 0.00713845156
Iter: 240 loss: 0.00713749323
Iter: 241 loss: 0.00713682733
Iter: 242 loss: 0.00714402506
Iter: 243 loss: 0.00713681197
Iter: 244 loss: 0.00713639613
Iter: 245 loss: 0.00713678077
Iter: 246 loss: 0.00713615865
Iter: 247 loss: 0.00713560358
Iter: 248 loss: 0.00713657215
Iter: 249 loss: 0.0071353605
Iter: 250 loss: 0.00713490229
Iter: 251 loss: 0.00713669928
Iter: 252 loss: 0.00713479845
Iter: 253 loss: 0.00713439332
Iter: 254 loss: 0.0071380157
Iter: 255 loss: 0.00713437237
Iter: 256 loss: 0.00713402219
Iter: 257 loss: 0.00713518169
Iter: 258 loss: 0.00713392766
Iter: 259 loss: 0.00713364687
Iter: 260 loss: 0.00713323243
Iter: 261 loss: 0.00713322125
Iter: 262 loss: 0.00713267969
Iter: 263 loss: 0.00713371066
Iter: 264 loss: 0.00713244686
Iter: 265 loss: 0.00713194115
Iter: 266 loss: 0.0071331826
Iter: 267 loss: 0.00713176094
Iter: 268 loss: 0.00713134
Iter: 269 loss: 0.00713610649
Iter: 270 loss: 0.00713133113
Iter: 271 loss: 0.00713098701
Iter: 272 loss: 0.00713099632
Iter: 273 loss: 0.00713071274
Iter: 274 loss: 0.00713040773
Iter: 275 loss: 0.00713040587
Iter: 276 loss: 0.00713017024
Iter: 277 loss: 0.00713011343
Iter: 278 loss: 0.00712996162
Iter: 279 loss: 0.00712963
Iter: 280 loss: 0.00713082
Iter: 281 loss: 0.00712954625
Iter: 282 loss: 0.00712926267
Iter: 283 loss: 0.00712985825
Iter: 284 loss: 0.00712914905
Iter: 285 loss: 0.00712891296
Iter: 286 loss: 0.00713155512
Iter: 287 loss: 0.0071289055
Iter: 288 loss: 0.00712870434
Iter: 289 loss: 0.00712931156
Iter: 290 loss: 0.00712864334
Iter: 291 loss: 0.00712846173
Iter: 292 loss: 0.00712829735
Iter: 293 loss: 0.00712825265
Iter: 294 loss: 0.00712795835
Iter: 295 loss: 0.00712813251
Iter: 296 loss: 0.00712776929
Iter: 297 loss: 0.00712745124
Iter: 298 loss: 0.0071283672
Iter: 299 loss: 0.00712735299
Iter: 300 loss: 0.00712706242
Iter: 301 loss: 0.00712912669
Iter: 302 loss: 0.00712703494
Iter: 303 loss: 0.00712680351
Iter: 304 loss: 0.00712761283
Iter: 305 loss: 0.00712674297
Iter: 306 loss: 0.00712655578
Iter: 307 loss: 0.00712745171
Iter: 308 loss: 0.00712652
Iter: 309 loss: 0.00712634111
Iter: 310 loss: 0.00712689199
Iter: 311 loss: 0.00712629
Iter: 312 loss: 0.0071261134
Iter: 313 loss: 0.00712618837
Iter: 314 loss: 0.0071259886
Iter: 315 loss: 0.00712582748
Iter: 316 loss: 0.00712708943
Iter: 317 loss: 0.0071258177
Iter: 318 loss: 0.00712568918
Iter: 319 loss: 0.00712606031
Iter: 320 loss: 0.007125651
Iter: 321 loss: 0.00712550106
Iter: 322 loss: 0.00712644681
Iter: 323 loss: 0.00712548522
Iter: 324 loss: 0.00712539116
Iter: 325 loss: 0.00712533249
Iter: 326 loss: 0.00712529244
Iter: 327 loss: 0.00712514762
Iter: 328 loss: 0.00712516718
Iter: 329 loss: 0.00712503213
Iter: 330 loss: 0.00712486915
Iter: 331 loss: 0.00712503958
Iter: 332 loss: 0.00712477788
Iter: 333 loss: 0.00712460745
Iter: 334 loss: 0.00712631736
Iter: 335 loss: 0.00712460233
Iter: 336 loss: 0.00712445937
Iter: 337 loss: 0.00712488778
Iter: 338 loss: 0.00712441886
Iter: 339 loss: 0.00712430524
Iter: 340 loss: 0.00712487567
Iter: 341 loss: 0.00712428242
Iter: 342 loss: 0.00712417904
Iter: 343 loss: 0.00712456601
Iter: 344 loss: 0.00712415716
Iter: 345 loss: 0.00712406
Iter: 346 loss: 0.00712411897
Iter: 347 loss: 0.0071239965
Iter: 348 loss: 0.00712389685
Iter: 349 loss: 0.0071243071
Iter: 350 loss: 0.00712387683
Iter: 351 loss: 0.00712378696
Iter: 352 loss: 0.00712418882
Iter: 353 loss: 0.00712376926
Iter: 354 loss: 0.00712369243
Iter: 355 loss: 0.00712442491
Iter: 356 loss: 0.00712368963
Iter: 357 loss: 0.00712363468
Iter: 358 loss: 0.00712356716
Iter: 359 loss: 0.00712356064
Iter: 360 loss: 0.00712346192
Iter: 361 loss: 0.00712357182
Iter: 362 loss: 0.00712340698
Iter: 363 loss: 0.00712330639
Iter: 364 loss: 0.00712348754
Iter: 365 loss: 0.00712325796
Iter: 366 loss: 0.00712314574
Iter: 367 loss: 0.00712347217
Iter: 368 loss: 0.00712311
Iter: 369 loss: 0.00712302374
Iter: 370 loss: 0.00712389126
Iter: 371 loss: 0.00712302
Iter: 372 loss: 0.00712294597
Iter: 373 loss: 0.00712310662
Iter: 374 loss: 0.00712291431
Iter: 375 loss: 0.00712284632
Iter: 376 loss: 0.00712324027
Iter: 377 loss: 0.00712283421
Iter: 378 loss: 0.00712277228
Iter: 379 loss: 0.0071227923
Iter: 380 loss: 0.00712273037
Iter: 381 loss: 0.00712266192
Iter: 382 loss: 0.00712294597
Iter: 383 loss: 0.00712265028
Iter: 384 loss: 0.00712258741
Iter: 385 loss: 0.00712279649
Iter: 386 loss: 0.00712256879
Iter: 387 loss: 0.00712250965
Iter: 388 loss: 0.00712311175
Iter: 389 loss: 0.00712250918
Iter: 390 loss: 0.0071224696
Iter: 391 loss: 0.00712243374
Iter: 392 loss: 0.0071224249
Iter: 393 loss: 0.00712235924
Iter: 394 loss: 0.00712234806
Iter: 395 loss: 0.00712230196
Iter: 396 loss: 0.00712221954
Iter: 397 loss: 0.00712255901
Iter: 398 loss: 0.00712220417
Iter: 399 loss: 0.00712212175
Iter: 400 loss: 0.00712218601
Iter: 401 loss: 0.00712207565
Iter: 402 loss: 0.00712200487
Iter: 403 loss: 0.00712270942
Iter: 404 loss: 0.00712200208
Iter: 405 loss: 0.00712193595
Iter: 406 loss: 0.0071221753
Iter: 407 loss: 0.00712192385
Iter: 408 loss: 0.00712187309
Iter: 409 loss: 0.00712205376
Iter: 410 loss: 0.00712185819
Iter: 411 loss: 0.00712180138
Iter: 412 loss: 0.00712181814
Iter: 413 loss: 0.00712176412
Iter: 414 loss: 0.00712170033
Iter: 415 loss: 0.00712194387
Iter: 416 loss: 0.00712168682
Iter: 417 loss: 0.00712162536
Iter: 418 loss: 0.00712182792
Iter: 419 loss: 0.00712160952
Iter: 420 loss: 0.00712155644
Iter: 421 loss: 0.00712221814
Iter: 422 loss: 0.00712155737
Iter: 423 loss: 0.00712151965
Iter: 424 loss: 0.0071214838
Iter: 425 loss: 0.00712147309
Iter: 426 loss: 0.00712141208
Iter: 427 loss: 0.00712141953
Iter: 428 loss: 0.00712136645
Iter: 429 loss: 0.00712129287
Iter: 430 loss: 0.00712152664
Iter: 431 loss: 0.00712127239
Iter: 432 loss: 0.00712119183
Iter: 433 loss: 0.00712131895
Iter: 434 loss: 0.00712115644
Iter: 435 loss: 0.00712109031
Iter: 436 loss: 0.00712145399
Iter: 437 loss: 0.00712108
Iter: 438 loss: 0.00712101348
Iter: 439 loss: 0.00712142605
Iter: 440 loss: 0.00712100742
Iter: 441 loss: 0.00712095853
Iter: 442 loss: 0.00712107122
Iter: 443 loss: 0.00712094083
Iter: 444 loss: 0.00712088868
Iter: 445 loss: 0.00712094223
Iter: 446 loss: 0.00712085376
Iter: 447 loss: 0.00712079974
Iter: 448 loss: 0.00712094
Iter: 449 loss: 0.00712078158
Iter: 450 loss: 0.0071207257
Iter: 451 loss: 0.00712099625
Iter: 452 loss: 0.00712071499
Iter: 453 loss: 0.00712067122
Iter: 454 loss: 0.00712121371
Iter: 455 loss: 0.00712067215
Iter: 456 loss: 0.00712063815
Iter: 457 loss: 0.00712061115
Iter: 458 loss: 0.00712060137
Iter: 459 loss: 0.00712055573
Iter: 460 loss: 0.00712057063
Iter: 461 loss: 0.00712052174
Iter: 462 loss: 0.007120464
Iter: 463 loss: 0.00712058367
Iter: 464 loss: 0.00712043885
Iter: 465 loss: 0.00712037273
Iter: 466 loss: 0.0071204803
Iter: 467 loss: 0.00712034199
Iter: 468 loss: 0.0071202796
Iter: 469 loss: 0.00712067168
Iter: 470 loss: 0.00712027401
Iter: 471 loss: 0.0071202172
Iter: 472 loss: 0.00712052314
Iter: 473 loss: 0.00712021068
Iter: 474 loss: 0.00712016225
Iter: 475 loss: 0.00712028425
Iter: 476 loss: 0.00712014548
Iter: 477 loss: 0.00712010032
Iter: 478 loss: 0.00712022372
Iter: 479 loss: 0.00712008681
Iter: 480 loss: 0.00712004164
Iter: 481 loss: 0.0071200626
Iter: 482 loss: 0.00712001184
Iter: 483 loss: 0.00711996574
Iter: 484 loss: 0.00712034293
Iter: 485 loss: 0.00711996295
Iter: 486 loss: 0.00711992662
Iter: 487 loss: 0.00712022558
Iter: 488 loss: 0.00711992476
Iter: 489 loss: 0.0071198917
Iter: 490 loss: 0.00711988285
Iter: 491 loss: 0.00711986376
Iter: 492 loss: 0.00711982697
Iter: 493 loss: 0.00711983908
Iter: 494 loss: 0.0071198009
Iter: 495 loss: 0.00711975247
Iter: 496 loss: 0.00711983582
Iter: 497 loss: 0.00711972732
Iter: 498 loss: 0.00711967563
Iter: 499 loss: 0.00711974315
Iter: 500 loss: 0.00711964909
Iter: 501 loss: 0.00711959507
Iter: 502 loss: 0.00712002488
Iter: 503 loss: 0.00711959042
Iter: 504 loss: 0.00711955177
Iter: 505 loss: 0.00711975154
Iter: 506 loss: 0.00711954385
Iter: 507 loss: 0.0071195038
Iter: 508 loss: 0.00711963326
Iter: 509 loss: 0.00711949356
Iter: 510 loss: 0.00711946283
Iter: 511 loss: 0.00711955316
Iter: 512 loss: 0.00711945118
Iter: 513 loss: 0.00711941766
Iter: 514 loss: 0.0071194144
Iter: 515 loss: 0.00711939158
Iter: 516 loss: 0.00711935479
Iter: 517 loss: 0.00711970218
Iter: 518 loss: 0.00711935572
Iter: 519 loss: 0.00711932825
Iter: 520 loss: 0.00711953081
Iter: 521 loss: 0.00711932685
Iter: 522 loss: 0.00711930264
Iter: 523 loss: 0.00711930171
Iter: 524 loss: 0.00711928215
Iter: 525 loss: 0.00711925607
Iter: 526 loss: 0.00711925793
Iter: 527 loss: 0.00711923745
Iter: 528 loss: 0.00711919926
Iter: 529 loss: 0.00711925048
Iter: 530 loss: 0.00711918157
Iter: 531 loss: 0.00711914
Iter: 532 loss: 0.00711919786
Iter: 533 loss: 0.00711911777
Iter: 534 loss: 0.00711907679
Iter: 535 loss: 0.0071193995
Iter: 536 loss: 0.0071190726
Iter: 537 loss: 0.00711904
Iter: 538 loss: 0.00711919414
Iter: 539 loss: 0.00711903628
Iter: 540 loss: 0.00711900461
Iter: 541 loss: 0.00711910799
Iter: 542 loss: 0.0071189953
Iter: 543 loss: 0.00711896876
Iter: 544 loss: 0.00711903954
Iter: 545 loss: 0.00711896038
Iter: 546 loss: 0.00711893244
Iter: 547 loss: 0.00711893663
Iter: 548 loss: 0.00711891381
Iter: 549 loss: 0.00711888634
Iter: 550 loss: 0.00711912056
Iter: 551 loss: 0.00711888354
Iter: 552 loss: 0.00711886259
Iter: 553 loss: 0.00711904652
Iter: 554 loss: 0.00711886166
Iter: 555 loss: 0.0071188407
Iter: 556 loss: 0.00711884629
Iter: 557 loss: 0.0071188272
Iter: 558 loss: 0.00711880857
Iter: 559 loss: 0.00711880159
Iter: 560 loss: 0.00711878855
Iter: 561 loss: 0.00711876
Iter: 562 loss: 0.00711879926
Iter: 563 loss: 0.00711874198
Iter: 564 loss: 0.0071187038
Iter: 565 loss: 0.00711879693
Iter: 566 loss: 0.00711869262
Iter: 567 loss: 0.00711865863
Iter: 568 loss: 0.00711877923
Iter: 569 loss: 0.00711864932
Iter: 570 loss: 0.00711862184
Iter: 571 loss: 0.00711888727
Iter: 572 loss: 0.00711862
Iter: 573 loss: 0.0071185939
Iter: 574 loss: 0.00711866608
Iter: 575 loss: 0.00711858645
Iter: 576 loss: 0.00711856782
Iter: 577 loss: 0.00711861392
Iter: 578 loss: 0.00711855898
Iter: 579 loss: 0.00711853663
Iter: 580 loss: 0.0071185641
Iter: 581 loss: 0.00711852638
Iter: 582 loss: 0.00711850077
Iter: 583 loss: 0.00711860415
Iter: 584 loss: 0.00711849751
Iter: 585 loss: 0.00711848307
Iter: 586 loss: 0.00711848354
Iter: 587 loss: 0.0071184705
Iter: 588 loss: 0.00711847236
Iter: 589 loss: 0.00711846119
Iter: 590 loss: 0.00711844536
Iter: 591 loss: 0.00711843744
Iter: 592 loss: 0.00711842906
Iter: 593 loss: 0.0071184081
Iter: 594 loss: 0.00711843558
Iter: 595 loss: 0.00711839506
Iter: 596 loss: 0.00711836433
Iter: 597 loss: 0.00711846631
Iter: 598 loss: 0.00711835921
Iter: 599 loss: 0.00711833453
Iter: 600 loss: 0.00711836386
Iter: 601 loss: 0.00711832289
Iter: 602 loss: 0.0071183
Iter: 603 loss: 0.00711862464
Iter: 604 loss: 0.0071182996
Iter: 605 loss: 0.00711828191
Iter: 606 loss: 0.00711832941
Iter: 607 loss: 0.00711827585
Iter: 608 loss: 0.00711826188
Iter: 609 loss: 0.00711829495
Iter: 610 loss: 0.00711825397
Iter: 611 loss: 0.0071182414
Iter: 612 loss: 0.0071182684
Iter: 613 loss: 0.00711823441
Iter: 614 loss: 0.00711821485
Iter: 615 loss: 0.00711826
Iter: 616 loss: 0.00711820927
Iter: 617 loss: 0.00711819949
Iter: 618 loss: 0.00711819762
Iter: 619 loss: 0.00711818784
Iter: 620 loss: 0.00711818691
Iter: 621 loss: 0.00711818226
Iter: 622 loss: 0.00711816875
Iter: 623 loss: 0.0071181613
Iter: 624 loss: 0.00711815618
Iter: 625 loss: 0.00711813755
Iter: 626 loss: 0.00711815944
Iter: 627 loss: 0.00711812917
Iter: 628 loss: 0.00711810542
Iter: 629 loss: 0.00711820461
Iter: 630 loss: 0.00711810077
Iter: 631 loss: 0.007118084
Iter: 632 loss: 0.00711810123
Iter: 633 loss: 0.00711807609
Iter: 634 loss: 0.00711806025
Iter: 635 loss: 0.00711805932
Iter: 636 loss: 0.00711805
Iter: 637 loss: 0.00711808261
Iter: 638 loss: 0.00711804628
Iter: 639 loss: 0.00711803464
Iter: 640 loss: 0.00711805467
Iter: 641 loss: 0.00711803231
Iter: 642 loss: 0.00711801834
Iter: 643 loss: 0.00711804163
Iter: 644 loss: 0.00711801369
Iter: 645 loss: 0.00711800344
Iter: 646 loss: 0.00711803464
Iter: 647 loss: 0.00711799879
Iter: 648 loss: 0.00711799227
Iter: 649 loss: 0.0071179904
Iter: 650 loss: 0.00711798342
Iter: 651 loss: 0.00711798482
Iter: 652 loss: 0.00711798
Iter: 653 loss: 0.00711797
Iter: 654 loss: 0.00711796433
Iter: 655 loss: 0.0071179606
Iter: 656 loss: 0.00711795
Iter: 657 loss: 0.00711796805
Iter: 658 loss: 0.00711794337
Iter: 659 loss: 0.00711792894
Iter: 660 loss: 0.00711798389
Iter: 661 loss: 0.00711792847
Iter: 662 loss: 0.0071179173
Iter: 663 loss: 0.0071179308
Iter: 664 loss: 0.00711791264
Iter: 665 loss: 0.00711790286
Iter: 666 loss: 0.00711801555
Iter: 667 loss: 0.00711790053
Iter: 668 loss: 0.00711789355
Iter: 669 loss: 0.0071179322
Iter: 670 loss: 0.00711788889
Iter: 671 loss: 0.00711788423
Iter: 672 loss: 0.00711789075
Iter: 673 loss: 0.00711788
Iter: 674 loss: 0.00711787073
Iter: 675 loss: 0.00711788749
Iter: 676 loss: 0.00711786794
Iter: 677 loss: 0.00711786095
Iter: 678 loss: 0.00711789
Iter: 679 loss: 0.00711785816
Iter: 680 loss: 0.0071178549
Iter: 681 loss: 0.00711793406
Iter: 682 loss: 0.0071178535
Iter: 683 loss: 0.00711784698
Iter: 684 loss: 0.00711785071
Iter: 685 loss: 0.00711784605
Iter: 686 loss: 0.00711784093
Iter: 687 loss: 0.00711783767
Iter: 688 loss: 0.0071178358
Iter: 689 loss: 0.00711782742
Iter: 690 loss: 0.00711783906
Iter: 691 loss: 0.00711782603
Iter: 692 loss: 0.00711781532
Iter: 693 loss: 0.00711783255
Iter: 694 loss: 0.00711781252
Iter: 695 loss: 0.00711780321
Iter: 696 loss: 0.0071178386
Iter: 697 loss: 0.00711780135
Iter: 698 loss: 0.00711779436
Iter: 699 loss: 0.00711781625
Iter: 700 loss: 0.0071177925
Iter: 701 loss: 0.00711778644
Iter: 702 loss: 0.00711786188
Iter: 703 loss: 0.00711778458
Iter: 704 loss: 0.00711778132
Iter: 705 loss: 0.00711778412
Iter: 706 loss: 0.00711777899
Iter: 707 loss: 0.00711777341
Iter: 708 loss: 0.00711778412
Iter: 709 loss: 0.00711776968
Iter: 710 loss: 0.00711776549
Iter: 711 loss: 0.00711779157
Iter: 712 loss: 0.00711776363
Iter: 713 loss: 0.00711775944
Iter: 714 loss: 0.00711779576
Iter: 715 loss: 0.00711775851
Iter: 716 loss: 0.00711775711
Iter: 717 loss: 0.00711776176
Iter: 718 loss: 0.00711775338
Iter: 719 loss: 0.00711775059
Iter: 720 loss: 0.00711775
Iter: 721 loss: 0.00711774826
Iter: 722 loss: 0.00711774267
Iter: 723 loss: 0.00711774873
Iter: 724 loss: 0.00711774174
Iter: 725 loss: 0.00711773615
Iter: 726 loss: 0.00711774593
Iter: 727 loss: 0.00711773243
Iter: 728 loss: 0.00711772591
Iter: 729 loss: 0.00711775897
Iter: 730 loss: 0.00711772498
Iter: 731 loss: 0.00711772
Iter: 732 loss: 0.00711772963
Iter: 733 loss: 0.00711772032
Iter: 734 loss: 0.00711771287
Iter: 735 loss: 0.00711777853
Iter: 736 loss: 0.00711771473
Iter: 737 loss: 0.00711771147
Iter: 738 loss: 0.00711771101
Iter: 739 loss: 0.00711770914
Iter: 740 loss: 0.00711770402
Iter: 741 loss: 0.00711771287
Iter: 742 loss: 0.00711770076
Iter: 743 loss: 0.00711769843
Iter: 744 loss: 0.00711771939
Iter: 745 loss: 0.00711769657
Iter: 746 loss: 0.00711769285
Iter: 747 loss: 0.00711772
Iter: 748 loss: 0.00711769285
Iter: 749 loss: 0.00711769378
Iter: 750 loss: 0.00711769611
Iter: 751 loss: 0.00711769052
Iter: 752 loss: 0.00711768493
Iter: 753 loss: 0.00711768726
Iter: 754 loss: 0.007117684
Iter: 755 loss: 0.0071176826
Iter: 756 loss: 0.007117684
Iter: 757 loss: 0.00711767795
Iter: 758 loss: 0.00711767282
Iter: 759 loss: 0.00711768679
Iter: 760 loss: 0.00711767236
Iter: 761 loss: 0.0071176663
Iter: 762 loss: 0.00711768586
Iter: 763 loss: 0.00711766724
Iter: 764 loss: 0.00711766258
Iter: 765 loss: 0.00711767189
Iter: 766 loss: 0.00711766118
Iter: 767 loss: 0.00711765792
Iter: 768 loss: 0.0071176989
Iter: 769 loss: 0.00711765746
Iter: 770 loss: 0.0071176542
Iter: 771 loss: 0.00711765606
Iter: 772 loss: 0.00711765233
Iter: 773 loss: 0.00711764954
Iter: 774 loss: 0.00711765932
Iter: 775 loss: 0.00711764814
Iter: 776 loss: 0.00711764675
Iter: 777 loss: 0.00711766165
Iter: 778 loss: 0.00711764488
Iter: 779 loss: 0.00711764256
Iter: 780 loss: 0.00711766817
Iter: 781 loss: 0.00711764302
Iter: 782 loss: 0.00711764
Iter: 783 loss: 0.00711764488
Iter: 784 loss: 0.00711764
Iter: 785 loss: 0.00711763976
Iter: 786 loss: 0.0071176365
Iter: 787 loss: 0.00711763697
Iter: 788 loss: 0.00711763091
Iter: 789 loss: 0.0071176351
Iter: 790 loss: 0.00711763091
Iter: 791 loss: 0.00711762719
Iter: 792 loss: 0.00711763697
Iter: 793 loss: 0.00711762533
Iter: 794 loss: 0.00711762346
Iter: 795 loss: 0.00711763045
Iter: 796 loss: 0.00711762
Iter: 797 loss: 0.00711761694
Iter: 798 loss: 0.00711763697
Iter: 799 loss: 0.00711761508
Iter: 800 loss: 0.00711761415
Iter: 801 loss: 0.00711763836
Iter: 802 loss: 0.00711761508
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4
+ date
Tue Oct 27 20:45:19 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbc91268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbc95d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbc95b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbb95e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbba9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbba9c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbb226a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbb51598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbb22840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbada730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbadad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbb220d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adbacdf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adba1dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adba54400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb9e6d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adba02730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adba54048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb9d0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adba09730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb98f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb98f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb903620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb8aa6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb8aa840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb85a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb885840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb83b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb8856a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb7e6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb80e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb7be840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb7be268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb772598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb726840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1adb7471e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.101021089
Iter: 2 loss: 7108.44629
Iter: 3 loss: 1708.62756
Iter: 4 loss: 704.168213
Iter: 5 loss: 0.101020202
Iter: 6 loss: 394.132965
Iter: 7 loss: 61.3091965
Iter: 8 loss: 0.0484550186
Iter: 9 loss: 0.930820465
Iter: 10 loss: 0.0483413935
Iter: 11 loss: 0.0553987399
Iter: 12 loss: 0.0929877758
Iter: 13 loss: 0.0859360695
Iter: 14 loss: 0.0620109551
Iter: 15 loss: 0.0560349971
Iter: 16 loss: 0.0462717339
Iter: 17 loss: 0.0455278158
Iter: 18 loss: 0.0451058745
Iter: 19 loss: 0.0452551395
Iter: 20 loss: 0.0447575636
Iter: 21 loss: 0.0444315523
Iter: 22 loss: 0.0436836109
Iter: 23 loss: 0.0658274
Iter: 24 loss: 0.0436647199
Iter: 25 loss: 0.0415849313
Iter: 26 loss: 0.0442541353
Iter: 27 loss: 0.0402039662
Iter: 28 loss: 0.0369419158
Iter: 29 loss: 0.0493117273
Iter: 30 loss: 0.0365237147
Iter: 31 loss: 0.0353263021
Iter: 32 loss: 0.0375833772
Iter: 33 loss: 0.0352272615
Iter: 34 loss: 0.033723183
Iter: 35 loss: 0.0345798917
Iter: 36 loss: 0.0325511731
Iter: 37 loss: 0.0317280628
Iter: 38 loss: 0.0336162
Iter: 39 loss: 0.031321831
Iter: 40 loss: 0.0303368717
Iter: 41 loss: 0.0311705787
Iter: 42 loss: 0.0298170745
Iter: 43 loss: 0.0279692262
Iter: 44 loss: 0.0296171326
Iter: 45 loss: 0.0269105192
Iter: 46 loss: 0.0263494533
Iter: 47 loss: 0.0337889194
Iter: 48 loss: 0.0263079181
Iter: 49 loss: 0.0258432925
Iter: 50 loss: 0.0280467737
Iter: 51 loss: 0.0257467795
Iter: 52 loss: 0.0246744081
Iter: 53 loss: 0.0234116577
Iter: 54 loss: 0.0231942385
Iter: 55 loss: 0.0215742551
Iter: 56 loss: 0.0215385891
Iter: 57 loss: 0.0218892731
Iter: 58 loss: 0.0205763541
Iter: 59 loss: 0.019634692
Iter: 60 loss: 0.0234115236
Iter: 61 loss: 0.019383898
Iter: 62 loss: 0.0190324
Iter: 63 loss: 0.0217802897
Iter: 64 loss: 0.0189960133
Iter: 65 loss: 0.0188131444
Iter: 66 loss: 0.0189529173
Iter: 67 loss: 0.0187011231
Iter: 68 loss: 0.0183022358
Iter: 69 loss: 0.0195860453
Iter: 70 loss: 0.0181887504
Iter: 71 loss: 0.0178164802
Iter: 72 loss: 0.0177993625
Iter: 73 loss: 0.0177376345
Iter: 74 loss: 0.0180077031
Iter: 75 loss: 0.0177243091
Iter: 76 loss: 0.0175347067
Iter: 77 loss: 0.017025223
Iter: 78 loss: 0.0209697224
Iter: 79 loss: 0.0169089679
Iter: 80 loss: 0.0194223635
Iter: 81 loss: 0.0166996401
Iter: 82 loss: 0.0165235586
Iter: 83 loss: 0.0180134308
Iter: 84 loss: 0.0165054146
Iter: 85 loss: 0.016438365
Iter: 86 loss: 0.0163235851
Iter: 87 loss: 0.0163234156
Iter: 88 loss: 0.0161783881
Iter: 89 loss: 0.0161187239
Iter: 90 loss: 0.016039256
Iter: 91 loss: 0.0159164816
Iter: 92 loss: 0.0163218379
Iter: 93 loss: 0.0158762019
Iter: 94 loss: 0.0154256504
Iter: 95 loss: 0.0169937126
Iter: 96 loss: 0.0152988285
Iter: 97 loss: 0.0149445441
Iter: 98 loss: 0.0179735161
Iter: 99 loss: 0.014918562
Iter: 100 loss: 0.0147423111
Iter: 101 loss: 0.0151396431
Iter: 102 loss: 0.014674332
Iter: 103 loss: 0.0144209769
Iter: 104 loss: 0.0143976156
Iter: 105 loss: 0.0139896162
Iter: 106 loss: 0.0177750811
Iter: 107 loss: 0.0139666982
Iter: 108 loss: 0.0137773519
Iter: 109 loss: 0.0136139896
Iter: 110 loss: 0.0135627
Iter: 111 loss: 0.0132520199
Iter: 112 loss: 0.0132322852
Iter: 113 loss: 0.0128752394
Iter: 114 loss: 0.0143856592
Iter: 115 loss: 0.0127952527
Iter: 116 loss: 0.0125726312
Iter: 117 loss: 0.0127026513
Iter: 118 loss: 0.0124309296
Iter: 119 loss: 0.0123354755
Iter: 120 loss: 0.0123332618
Iter: 121 loss: 0.0122481762
Iter: 122 loss: 0.0128619391
Iter: 123 loss: 0.0122423973
Iter: 124 loss: 0.0119695673
Iter: 125 loss: 0.012827063
Iter: 126 loss: 0.011871432
Iter: 127 loss: 0.0133881699
Iter: 128 loss: 0.0117631517
Iter: 129 loss: 0.0116361585
Iter: 130 loss: 0.0117744235
Iter: 131 loss: 0.011562394
Iter: 132 loss: 0.011428223
Iter: 133 loss: 0.0113043152
Iter: 134 loss: 0.0112740528
Iter: 135 loss: 0.0109613482
Iter: 136 loss: 0.0126882065
Iter: 137 loss: 0.0109145641
Iter: 138 loss: 0.0107710687
Iter: 139 loss: 0.0118399784
Iter: 140 loss: 0.0107613839
Iter: 141 loss: 0.010971291
Iter: 142 loss: 0.0106974524
Iter: 143 loss: 0.0106006395
Iter: 144 loss: 0.0105454866
Iter: 145 loss: 0.010503415
Iter: 146 loss: 0.0103490725
Iter: 147 loss: 0.0124393739
Iter: 148 loss: 0.010348483
Iter: 149 loss: 0.0103152683
Iter: 150 loss: 0.0102722021
Iter: 151 loss: 0.0102231763
Iter: 152 loss: 0.0101913167
Iter: 153 loss: 0.0101721585
Iter: 154 loss: 0.0100649586
Iter: 155 loss: 0.010072967
Iter: 156 loss: 0.00998272561
Iter: 157 loss: 0.00987729616
Iter: 158 loss: 0.00984351523
Iter: 159 loss: 0.00977866352
Iter: 160 loss: 0.0096010128
Iter: 161 loss: 0.00959327631
Iter: 162 loss: 0.00945775
Iter: 163 loss: 0.0110076573
Iter: 164 loss: 0.00939746
Iter: 165 loss: 0.00930012
Iter: 166 loss: 0.00954148
Iter: 167 loss: 0.00926563237
Iter: 168 loss: 0.00917802099
Iter: 169 loss: 0.00943301059
Iter: 170 loss: 0.00915247
Iter: 171 loss: 0.00911810901
Iter: 172 loss: 0.00907241832
Iter: 173 loss: 0.00906946
Iter: 174 loss: 0.0090074949
Iter: 175 loss: 0.0090137
Iter: 176 loss: 0.00896004
Iter: 177 loss: 0.00921721756
Iter: 178 loss: 0.00892287493
Iter: 179 loss: 0.00886774156
Iter: 180 loss: 0.00895333476
Iter: 181 loss: 0.00884086
Iter: 182 loss: 0.00882275403
Iter: 183 loss: 0.0087775914
Iter: 184 loss: 0.00925614405
Iter: 185 loss: 0.00877173524
Iter: 186 loss: 0.00871657394
Iter: 187 loss: 0.00870763697
Iter: 188 loss: 0.00861605071
Iter: 189 loss: 0.00880542118
Iter: 190 loss: 0.00857786275
Iter: 191 loss: 0.00853684358
Iter: 192 loss: 0.0085303355
Iter: 193 loss: 0.00850209221
Iter: 194 loss: 0.00843426678
Iter: 195 loss: 0.00926003885
Iter: 196 loss: 0.00843324233
Iter: 197 loss: 0.00837276876
Iter: 198 loss: 0.00830884185
Iter: 199 loss: 0.00829758774
Iter: 200 loss: 0.00821355358
Iter: 201 loss: 0.00852488354
Iter: 202 loss: 0.00819376763
Iter: 203 loss: 0.00812139735
Iter: 204 loss: 0.00873705372
Iter: 205 loss: 0.00811798871
Iter: 206 loss: 0.00807475299
Iter: 207 loss: 0.0080842562
Iter: 208 loss: 0.00804278348
Iter: 209 loss: 0.00801085867
Iter: 210 loss: 0.00800260063
Iter: 211 loss: 0.00798238255
Iter: 212 loss: 0.00801387243
Iter: 213 loss: 0.00797394849
Iter: 214 loss: 0.00796394795
Iter: 215 loss: 0.00796774216
Iter: 216 loss: 0.00795688946
Iter: 217 loss: 0.00791128539
Iter: 218 loss: 0.00791910291
Iter: 219 loss: 0.00787745323
Iter: 220 loss: 0.00782350264
Iter: 221 loss: 0.00776275154
Iter: 222 loss: 0.00775386812
Iter: 223 loss: 0.00770143606
Iter: 224 loss: 0.00805030391
Iter: 225 loss: 0.00769611821
Iter: 226 loss: 0.0076586036
Iter: 227 loss: 0.00774660567
Iter: 228 loss: 0.00764470315
Iter: 229 loss: 0.00759643456
Iter: 230 loss: 0.00806490704
Iter: 231 loss: 0.00759511255
Iter: 232 loss: 0.00756899826
Iter: 233 loss: 0.00766027439
Iter: 234 loss: 0.00756210089
Iter: 235 loss: 0.0075452528
Iter: 236 loss: 0.00751237944
Iter: 237 loss: 0.00813539699
Iter: 238 loss: 0.0075121047
Iter: 239 loss: 0.00746820774
Iter: 240 loss: 0.00765126664
Iter: 241 loss: 0.00745821
Iter: 242 loss: 0.0074105286
Iter: 243 loss: 0.00751049584
Iter: 244 loss: 0.00739148632
Iter: 245 loss: 0.00787968375
Iter: 246 loss: 0.00738303456
Iter: 247 loss: 0.00738018099
Iter: 248 loss: 0.00739498157
Iter: 249 loss: 0.00737970276
Iter: 250 loss: 0.00737275183
Iter: 251 loss: 0.00735168252
Iter: 252 loss: 0.00741611049
Iter: 253 loss: 0.00734062446
Iter: 254 loss: 0.00730485376
Iter: 255 loss: 0.00744951749
Iter: 256 loss: 0.00729743857
Iter: 257 loss: 0.0072551216
Iter: 258 loss: 0.00728565594
Iter: 259 loss: 0.00722858
Iter: 260 loss: 0.00720178196
Iter: 261 loss: 0.00720043853
Iter: 262 loss: 0.00717984233
Iter: 263 loss: 0.00716486573
Iter: 264 loss: 0.00717101805
Iter: 265 loss: 0.00715442281
Iter: 266 loss: 0.00713656936
Iter: 267 loss: 0.00709912833
Iter: 268 loss: 0.00782479253
Iter: 269 loss: 0.00709831342
Iter: 270 loss: 0.00707966834
Iter: 271 loss: 0.00707388436
Iter: 272 loss: 0.00704227574
Iter: 273 loss: 0.007142168
Iter: 274 loss: 0.00703263888
Iter: 275 loss: 0.00702150632
Iter: 276 loss: 0.007009767
Iter: 277 loss: 0.00700773206
Iter: 278 loss: 0.00699265534
Iter: 279 loss: 0.00699265674
Iter: 280 loss: 0.00698739523
Iter: 281 loss: 0.00699227117
Iter: 282 loss: 0.00698432233
Iter: 283 loss: 0.0069732652
Iter: 284 loss: 0.00697763544
Iter: 285 loss: 0.00696548074
Iter: 286 loss: 0.00692946464
Iter: 287 loss: 0.00712103117
Iter: 288 loss: 0.0069238618
Iter: 289 loss: 0.00690511521
Iter: 290 loss: 0.00690566376
Iter: 291 loss: 0.00689047
Iter: 292 loss: 0.00687296083
Iter: 293 loss: 0.00684804143
Iter: 294 loss: 0.00684715761
Iter: 295 loss: 0.00682259025
Iter: 296 loss: 0.00678498624
Iter: 297 loss: 0.00678429846
Iter: 298 loss: 0.00699167373
Iter: 299 loss: 0.00676615629
Iter: 300 loss: 0.00674779527
Iter: 301 loss: 0.00674849609
Iter: 302 loss: 0.00673338072
Iter: 303 loss: 0.00671256892
Iter: 304 loss: 0.00690451637
Iter: 305 loss: 0.00671159476
Iter: 306 loss: 0.00669728965
Iter: 307 loss: 0.0068357531
Iter: 308 loss: 0.00669673039
Iter: 309 loss: 0.00669033127
Iter: 310 loss: 0.00668033957
Iter: 311 loss: 0.00668022223
Iter: 312 loss: 0.00665603392
Iter: 313 loss: 0.00665504392
Iter: 314 loss: 0.00663629035
Iter: 315 loss: 0.00662365323
Iter: 316 loss: 0.00662750704
Iter: 317 loss: 0.00661450531
Iter: 318 loss: 0.00659120455
Iter: 319 loss: 0.00669267867
Iter: 320 loss: 0.00658651162
Iter: 321 loss: 0.00656143529
Iter: 322 loss: 0.00675130589
Iter: 323 loss: 0.0065593021
Iter: 324 loss: 0.00655090809
Iter: 325 loss: 0.00664255675
Iter: 326 loss: 0.00655067712
Iter: 327 loss: 0.00654753717
Iter: 328 loss: 0.00653901836
Iter: 329 loss: 0.00659766933
Iter: 330 loss: 0.00653693127
Iter: 331 loss: 0.00652236026
Iter: 332 loss: 0.00652327063
Iter: 333 loss: 0.00651075132
Iter: 334 loss: 0.00649718475
Iter: 335 loss: 0.00649017096
Iter: 336 loss: 0.0064840042
Iter: 337 loss: 0.00646591885
Iter: 338 loss: 0.00647484884
Iter: 339 loss: 0.00645367196
Iter: 340 loss: 0.00645731622
Iter: 341 loss: 0.00644537108
Iter: 342 loss: 0.00643272419
Iter: 343 loss: 0.00649339193
Iter: 344 loss: 0.00643045735
Iter: 345 loss: 0.00642564381
Iter: 346 loss: 0.00641261227
Iter: 347 loss: 0.00649140403
Iter: 348 loss: 0.00640928419
Iter: 349 loss: 0.00638658646
Iter: 350 loss: 0.00652976893
Iter: 351 loss: 0.00638394244
Iter: 352 loss: 0.00637066364
Iter: 353 loss: 0.00645787129
Iter: 354 loss: 0.00636933837
Iter: 355 loss: 0.0063601248
Iter: 356 loss: 0.00634474
Iter: 357 loss: 0.00634469371
Iter: 358 loss: 0.00635738298
Iter: 359 loss: 0.00633763149
Iter: 360 loss: 0.0063333232
Iter: 361 loss: 0.00633898797
Iter: 362 loss: 0.00633115321
Iter: 363 loss: 0.00631759921
Iter: 364 loss: 0.006319826
Iter: 365 loss: 0.00630731648
Iter: 366 loss: 0.00629526377
Iter: 367 loss: 0.00632598437
Iter: 368 loss: 0.00629097084
Iter: 369 loss: 0.00628176704
Iter: 370 loss: 0.0062556765
Iter: 371 loss: 0.00638215616
Iter: 372 loss: 0.00624674186
Iter: 373 loss: 0.00623888709
Iter: 374 loss: 0.00623733737
Iter: 375 loss: 0.00622940157
Iter: 376 loss: 0.00632053427
Iter: 377 loss: 0.00622925488
Iter: 378 loss: 0.00622435752
Iter: 379 loss: 0.00620992668
Iter: 380 loss: 0.00626454875
Iter: 381 loss: 0.00620359741
Iter: 382 loss: 0.00618825294
Iter: 383 loss: 0.00624010852
Iter: 384 loss: 0.00618418399
Iter: 385 loss: 0.00617197901
Iter: 386 loss: 0.00616671378
Iter: 387 loss: 0.0061604185
Iter: 388 loss: 0.00617555715
Iter: 389 loss: 0.0061524231
Iter: 390 loss: 0.00615998451
Iter: 391 loss: 0.00614899769
Iter: 392 loss: 0.0061465539
Iter: 393 loss: 0.00614696834
Iter: 394 loss: 0.00614469871
Iter: 395 loss: 0.00613748096
Iter: 396 loss: 0.00613271631
Iter: 397 loss: 0.00612993073
Iter: 398 loss: 0.0061238
Iter: 399 loss: 0.00614215527
Iter: 400 loss: 0.0061220238
Iter: 401 loss: 0.00611585472
Iter: 402 loss: 0.00612043682
Iter: 403 loss: 0.00611205446
Iter: 404 loss: 0.00610644091
Iter: 405 loss: 0.00610631704
Iter: 406 loss: 0.00610908493
Iter: 407 loss: 0.0061028786
Iter: 408 loss: 0.00610099547
Iter: 409 loss: 0.00609509647
Iter: 410 loss: 0.00610573124
Iter: 411 loss: 0.00609112252
Iter: 412 loss: 0.0060876403
Iter: 413 loss: 0.00609265221
Iter: 414 loss: 0.00608597323
Iter: 415 loss: 0.00608369661
Iter: 416 loss: 0.00607729144
Iter: 417 loss: 0.00610992964
Iter: 418 loss: 0.00607521459
Iter: 419 loss: 0.00611746544
Iter: 420 loss: 0.00606111251
Iter: 421 loss: 0.00604160689
Iter: 422 loss: 0.00608145073
Iter: 423 loss: 0.00603349088
Iter: 424 loss: 0.00602473132
Iter: 425 loss: 0.00602232432
Iter: 426 loss: 0.00601348747
Iter: 427 loss: 0.00604002411
Iter: 428 loss: 0.00601082249
Iter: 429 loss: 0.00600549905
Iter: 430 loss: 0.00600402756
Iter: 431 loss: 0.00599922147
Iter: 432 loss: 0.00601132773
Iter: 433 loss: 0.0059975842
Iter: 434 loss: 0.00599343702
Iter: 435 loss: 0.00598376431
Iter: 436 loss: 0.00610415
Iter: 437 loss: 0.00598300342
Iter: 438 loss: 0.00597764
Iter: 439 loss: 0.00597712537
Iter: 440 loss: 0.00596920773
Iter: 441 loss: 0.00600578729
Iter: 442 loss: 0.00596765
Iter: 443 loss: 0.0059651807
Iter: 444 loss: 0.00595998112
Iter: 445 loss: 0.00604650844
Iter: 446 loss: 0.00595984329
Iter: 447 loss: 0.0059486581
Iter: 448 loss: 0.00602768
Iter: 449 loss: 0.00594752654
Iter: 450 loss: 0.00594287273
Iter: 451 loss: 0.0059699025
Iter: 452 loss: 0.00594228413
Iter: 453 loss: 0.0059380508
Iter: 454 loss: 0.00592529401
Iter: 455 loss: 0.00596309593
Iter: 456 loss: 0.00591873378
Iter: 457 loss: 0.00591759663
Iter: 458 loss: 0.00590771809
Iter: 459 loss: 0.0059001483
Iter: 460 loss: 0.00589898601
Iter: 461 loss: 0.00589377619
Iter: 462 loss: 0.00590172922
Iter: 463 loss: 0.00588953216
Iter: 464 loss: 0.00588573236
Iter: 465 loss: 0.00591190299
Iter: 466 loss: 0.00588534027
Iter: 467 loss: 0.00588411652
Iter: 468 loss: 0.00588166341
Iter: 469 loss: 0.00592742255
Iter: 470 loss: 0.00588163594
Iter: 471 loss: 0.00587810809
Iter: 472 loss: 0.00588694774
Iter: 473 loss: 0.00587685406
Iter: 474 loss: 0.00587530946
Iter: 475 loss: 0.00587389898
Iter: 476 loss: 0.00587236788
Iter: 477 loss: 0.00586819462
Iter: 478 loss: 0.00589501113
Iter: 479 loss: 0.00586711057
Iter: 480 loss: 0.0058592339
Iter: 481 loss: 0.00592093635
Iter: 482 loss: 0.00585872587
Iter: 483 loss: 0.00585379638
Iter: 484 loss: 0.005867959
Iter: 485 loss: 0.00585224433
Iter: 486 loss: 0.00584182562
Iter: 487 loss: 0.00586339226
Iter: 488 loss: 0.00583765376
Iter: 489 loss: 0.00583323184
Iter: 490 loss: 0.00583321601
Iter: 491 loss: 0.00582880806
Iter: 492 loss: 0.00583337434
Iter: 493 loss: 0.00582633168
Iter: 494 loss: 0.00582385156
Iter: 495 loss: 0.00582834939
Iter: 496 loss: 0.00582278101
Iter: 497 loss: 0.0058212392
Iter: 498 loss: 0.00581711624
Iter: 499 loss: 0.00584439933
Iter: 500 loss: 0.00581614906
Iter: 501 loss: 0.00581125915
Iter: 502 loss: 0.00582185853
Iter: 503 loss: 0.00580934295
Iter: 504 loss: 0.00580767449
Iter: 505 loss: 0.00580351381
Iter: 506 loss: 0.00584434625
Iter: 507 loss: 0.00580295548
Iter: 508 loss: 0.00579829235
Iter: 509 loss: 0.00580681209
Iter: 510 loss: 0.00579629093
Iter: 511 loss: 0.00579462061
Iter: 512 loss: 0.00579448696
Iter: 513 loss: 0.00579371676
Iter: 514 loss: 0.00579124037
Iter: 515 loss: 0.00579332747
Iter: 516 loss: 0.00578918913
Iter: 517 loss: 0.00578281237
Iter: 518 loss: 0.0058204555
Iter: 519 loss: 0.00578195788
Iter: 520 loss: 0.0057761916
Iter: 521 loss: 0.00579529488
Iter: 522 loss: 0.0057746144
Iter: 523 loss: 0.00576889561
Iter: 524 loss: 0.00577624794
Iter: 525 loss: 0.00576592796
Iter: 526 loss: 0.00576114748
Iter: 527 loss: 0.00578834722
Iter: 528 loss: 0.00576045644
Iter: 529 loss: 0.00575846899
Iter: 530 loss: 0.00577956531
Iter: 531 loss: 0.00575842336
Iter: 532 loss: 0.00575693138
Iter: 533 loss: 0.005759
Iter: 534 loss: 0.00575619237
Iter: 535 loss: 0.00575459423
Iter: 536 loss: 0.00575463567
Iter: 537 loss: 0.00575333089
Iter: 538 loss: 0.00575211644
Iter: 539 loss: 0.00574825
Iter: 540 loss: 0.00575256441
Iter: 541 loss: 0.00574522745
Iter: 542 loss: 0.00574215315
Iter: 543 loss: 0.00577510847
Iter: 544 loss: 0.00574208423
Iter: 545 loss: 0.00574110541
Iter: 546 loss: 0.00575548504
Iter: 547 loss: 0.00574110821
Iter: 548 loss: 0.00573960459
Iter: 549 loss: 0.00573589187
Iter: 550 loss: 0.00577253755
Iter: 551 loss: 0.00573541038
Iter: 552 loss: 0.00573101174
Iter: 553 loss: 0.0057506063
Iter: 554 loss: 0.00573010836
Iter: 555 loss: 0.00572801568
Iter: 556 loss: 0.00572588481
Iter: 557 loss: 0.00572546618
Iter: 558 loss: 0.00572273694
Iter: 559 loss: 0.00572640076
Iter: 560 loss: 0.00572136696
Iter: 561 loss: 0.00571853947
Iter: 562 loss: 0.00575645268
Iter: 563 loss: 0.0057185269
Iter: 564 loss: 0.00571695901
Iter: 565 loss: 0.00572834117
Iter: 566 loss: 0.0057168249
Iter: 567 loss: 0.0057159178
Iter: 568 loss: 0.00572244544
Iter: 569 loss: 0.0057158377
Iter: 570 loss: 0.00571525283
Iter: 571 loss: 0.00571516389
Iter: 572 loss: 0.00571477972
Iter: 573 loss: 0.00571432617
Iter: 574 loss: 0.00571427308
Iter: 575 loss: 0.00571368355
Iter: 576 loss: 0.00571678113
Iter: 577 loss: 0.00571359135
Iter: 578 loss: 0.00571319
Iter: 579 loss: 0.00571482349
Iter: 580 loss: 0.00571309216
Iter: 581 loss: 0.00571252126
Iter: 582 loss: 0.00571070425
Iter: 583 loss: 0.00571301673
Iter: 584 loss: 0.00570932869
Iter: 585 loss: 0.00570591493
Iter: 586 loss: 0.00571589544
Iter: 587 loss: 0.00570485834
Iter: 588 loss: 0.00569942
Iter: 589 loss: 0.00568964798
Iter: 590 loss: 0.00594121777
Iter: 591 loss: 0.00568964938
Iter: 592 loss: 0.00568048516
Iter: 593 loss: 0.00568088796
Iter: 594 loss: 0.00567317335
Iter: 595 loss: 0.00566905
Iter: 596 loss: 0.00569195207
Iter: 597 loss: 0.00566842221
Iter: 598 loss: 0.00566553324
Iter: 599 loss: 0.00566684408
Iter: 600 loss: 0.00566356536
Iter: 601 loss: 0.00566125195
Iter: 602 loss: 0.00569554605
Iter: 603 loss: 0.00566124544
Iter: 604 loss: 0.00566062517
Iter: 605 loss: 0.00566019537
Iter: 606 loss: 0.00565970503
Iter: 607 loss: 0.00565909408
Iter: 608 loss: 0.00565904425
Iter: 609 loss: 0.00565830292
Iter: 610 loss: 0.00565799372
Iter: 611 loss: 0.00565708941
Iter: 612 loss: 0.00566172507
Iter: 613 loss: 0.00565694645
Iter: 614 loss: 0.00565628288
Iter: 615 loss: 0.00565399043
Iter: 616 loss: 0.00565148052
Iter: 617 loss: 0.00565063488
Iter: 618 loss: 0.00565559138
Iter: 619 loss: 0.00564892124
Iter: 620 loss: 0.00564695569
Iter: 621 loss: 0.00564356195
Iter: 622 loss: 0.00564355869
Iter: 623 loss: 0.00563810952
Iter: 624 loss: 0.0057025319
Iter: 625 loss: 0.00563804
Iter: 626 loss: 0.00563624781
Iter: 627 loss: 0.00563612068
Iter: 628 loss: 0.00563468412
Iter: 629 loss: 0.00564575754
Iter: 630 loss: 0.00563457608
Iter: 631 loss: 0.00563392509
Iter: 632 loss: 0.00563506037
Iter: 633 loss: 0.00563363871
Iter: 634 loss: 0.00563297234
Iter: 635 loss: 0.00563815143
Iter: 636 loss: 0.00563292
Iter: 637 loss: 0.00563248154
Iter: 638 loss: 0.00563138537
Iter: 639 loss: 0.00564204808
Iter: 640 loss: 0.00563123776
Iter: 641 loss: 0.00562932249
Iter: 642 loss: 0.00564330211
Iter: 643 loss: 0.00562915206
Iter: 644 loss: 0.00562687218
Iter: 645 loss: 0.00562671386
Iter: 646 loss: 0.00562611874
Iter: 647 loss: 0.00562457554
Iter: 648 loss: 0.00563681172
Iter: 649 loss: 0.00562429
Iter: 650 loss: 0.00562231
Iter: 651 loss: 0.0056296112
Iter: 652 loss: 0.00562181789
Iter: 653 loss: 0.00562085863
Iter: 654 loss: 0.00562039949
Iter: 655 loss: 0.00561992824
Iter: 656 loss: 0.0056173061
Iter: 657 loss: 0.00561427325
Iter: 658 loss: 0.0056139091
Iter: 659 loss: 0.0056095859
Iter: 660 loss: 0.00561146345
Iter: 661 loss: 0.00560663827
Iter: 662 loss: 0.00560304616
Iter: 663 loss: 0.00560155325
Iter: 664 loss: 0.00559965149
Iter: 665 loss: 0.00560436165
Iter: 666 loss: 0.00559860375
Iter: 667 loss: 0.00559808593
Iter: 668 loss: 0.00559972692
Iter: 669 loss: 0.00559793878
Iter: 670 loss: 0.00559619721
Iter: 671 loss: 0.00559614832
Iter: 672 loss: 0.00559407286
Iter: 673 loss: 0.00559416227
Iter: 674 loss: 0.0055924491
Iter: 675 loss: 0.00559183862
Iter: 676 loss: 0.00558988471
Iter: 677 loss: 0.00559151126
Iter: 678 loss: 0.00558826188
Iter: 679 loss: 0.00558619574
Iter: 680 loss: 0.0055860756
Iter: 681 loss: 0.00558487279
Iter: 682 loss: 0.00558475731
Iter: 683 loss: 0.00558387581
Iter: 684 loss: 0.00558176311
Iter: 685 loss: 0.0055772448
Iter: 686 loss: 0.00565108238
Iter: 687 loss: 0.0055771051
Iter: 688 loss: 0.00557209924
Iter: 689 loss: 0.00560985273
Iter: 690 loss: 0.00557171274
Iter: 691 loss: 0.00556884566
Iter: 692 loss: 0.005607903
Iter: 693 loss: 0.0055688275
Iter: 694 loss: 0.00556748
Iter: 695 loss: 0.00556508265
Iter: 696 loss: 0.00562256714
Iter: 697 loss: 0.00556508172
Iter: 698 loss: 0.00556675065
Iter: 699 loss: 0.00556412665
Iter: 700 loss: 0.00556275621
Iter: 701 loss: 0.00556056062
Iter: 702 loss: 0.00556053873
Iter: 703 loss: 0.00555880647
Iter: 704 loss: 0.00556889595
Iter: 705 loss: 0.00555857271
Iter: 706 loss: 0.00555774
Iter: 707 loss: 0.00555734057
Iter: 708 loss: 0.00555690285
Iter: 709 loss: 0.00555688515
Iter: 710 loss: 0.00555654336
Iter: 711 loss: 0.00555376941
Iter: 712 loss: 0.00554934517
Iter: 713 loss: 0.00554930698
Iter: 714 loss: 0.00555153191
Iter: 715 loss: 0.00554823969
Iter: 716 loss: 0.00554744108
Iter: 717 loss: 0.00554712582
Iter: 718 loss: 0.00554669462
Iter: 719 loss: 0.00554440171
Iter: 720 loss: 0.00556288799
Iter: 721 loss: 0.00554422941
Iter: 722 loss: 0.00554273743
Iter: 723 loss: 0.00554134324
Iter: 724 loss: 0.0055409912
Iter: 725 loss: 0.00553810224
Iter: 726 loss: 0.00553687382
Iter: 727 loss: 0.00553534087
Iter: 728 loss: 0.00553409662
Iter: 729 loss: 0.00553101581
Iter: 730 loss: 0.0055619576
Iter: 731 loss: 0.00553062791
Iter: 732 loss: 0.00552837877
Iter: 733 loss: 0.00553965103
Iter: 734 loss: 0.00552800857
Iter: 735 loss: 0.0055369
Iter: 736 loss: 0.00552709401
Iter: 737 loss: 0.00552674104
Iter: 738 loss: 0.00552678388
Iter: 739 loss: 0.00552647701
Iter: 740 loss: 0.0055259089
Iter: 741 loss: 0.00552411
Iter: 742 loss: 0.00552605093
Iter: 743 loss: 0.00552269863
Iter: 744 loss: 0.00551989861
Iter: 745 loss: 0.00555131864
Iter: 746 loss: 0.00551984925
Iter: 747 loss: 0.00551822875
Iter: 748 loss: 0.00551935378
Iter: 749 loss: 0.00551722292
Iter: 750 loss: 0.00551695656
Iter: 751 loss: 0.00551614724
Iter: 752 loss: 0.00551521312
Iter: 753 loss: 0.00551535189
Iter: 754 loss: 0.00551450811
Iter: 755 loss: 0.00551285874
Iter: 756 loss: 0.00551169459
Iter: 757 loss: 0.00551110506
Iter: 758 loss: 0.00551121589
Iter: 759 loss: 0.00550989807
Iter: 760 loss: 0.00550953718
Iter: 761 loss: 0.0055090664
Iter: 762 loss: 0.00550903147
Iter: 763 loss: 0.00550836604
Iter: 764 loss: 0.00550628407
Iter: 765 loss: 0.0055100075
Iter: 766 loss: 0.00550489919
Iter: 767 loss: 0.00550323259
Iter: 768 loss: 0.00551088899
Iter: 769 loss: 0.00550291874
Iter: 770 loss: 0.00550245028
Iter: 771 loss: 0.00550314039
Iter: 772 loss: 0.00550222304
Iter: 773 loss: 0.0055017597
Iter: 774 loss: 0.00550262444
Iter: 775 loss: 0.00550155481
Iter: 776 loss: 0.00550038181
Iter: 777 loss: 0.00549951568
Iter: 778 loss: 0.00549911801
Iter: 779 loss: 0.0054977946
Iter: 780 loss: 0.00549693964
Iter: 781 loss: 0.00549642742
Iter: 782 loss: 0.00549545558
Iter: 783 loss: 0.00549299549
Iter: 784 loss: 0.00551541755
Iter: 785 loss: 0.00549262483
Iter: 786 loss: 0.00550354552
Iter: 787 loss: 0.00549042691
Iter: 788 loss: 0.00548899779
Iter: 789 loss: 0.00549123157
Iter: 790 loss: 0.00548833422
Iter: 791 loss: 0.00548667647
Iter: 792 loss: 0.005485259
Iter: 793 loss: 0.00548480637
Iter: 794 loss: 0.00548519334
Iter: 795 loss: 0.00548382103
Iter: 796 loss: 0.005483157
Iter: 797 loss: 0.00548242358
Iter: 798 loss: 0.00548231415
Iter: 799 loss: 0.00548165943
Iter: 800 loss: 0.00548075605
Iter: 801 loss: 0.00548071321
Iter: 802 loss: 0.00547977816
Iter: 803 loss: 0.00547977397
Iter: 804 loss: 0.00547939027
Iter: 805 loss: 0.00547991972
Iter: 806 loss: 0.00547919609
Iter: 807 loss: 0.00547799841
Iter: 808 loss: 0.00547976652
Iter: 809 loss: 0.00547742518
Iter: 810 loss: 0.00547587126
Iter: 811 loss: 0.00547357555
Iter: 812 loss: 0.0054735234
Iter: 813 loss: 0.00547812413
Iter: 814 loss: 0.00547273271
Iter: 815 loss: 0.00547196763
Iter: 816 loss: 0.00547040906
Iter: 817 loss: 0.00549892057
Iter: 818 loss: 0.00547038857
Iter: 819 loss: 0.00546804816
Iter: 820 loss: 0.00549445767
Iter: 821 loss: 0.00546800718
Iter: 822 loss: 0.0054664
Iter: 823 loss: 0.00546604674
Iter: 824 loss: 0.00546499807
Iter: 825 loss: 0.00546721369
Iter: 826 loss: 0.00546417432
Iter: 827 loss: 0.00546321739
Iter: 828 loss: 0.00546402484
Iter: 829 loss: 0.00546264
Iter: 830 loss: 0.00546196476
Iter: 831 loss: 0.00546142552
Iter: 832 loss: 0.00546122156
Iter: 833 loss: 0.00546035822
Iter: 834 loss: 0.00547388941
Iter: 835 loss: 0.00546035636
Iter: 836 loss: 0.00546001922
Iter: 837 loss: 0.00545945298
Iter: 838 loss: 0.00545944553
Iter: 839 loss: 0.00545766205
Iter: 840 loss: 0.00545523176
Iter: 841 loss: 0.00545511534
Iter: 842 loss: 0.00545181427
Iter: 843 loss: 0.0054987045
Iter: 844 loss: 0.00545180775
Iter: 845 loss: 0.0054505174
Iter: 846 loss: 0.00546562718
Iter: 847 loss: 0.0054505039
Iter: 848 loss: 0.0054488983
Iter: 849 loss: 0.00544739794
Iter: 850 loss: 0.00544701843
Iter: 851 loss: 0.00544594694
Iter: 852 loss: 0.00544418534
Iter: 853 loss: 0.00544418
Iter: 854 loss: 0.00544282794
Iter: 855 loss: 0.00544866454
Iter: 856 loss: 0.00544255599
Iter: 857 loss: 0.00544180814
Iter: 858 loss: 0.00544142956
Iter: 859 loss: 0.00544108031
Iter: 860 loss: 0.00544022955
Iter: 861 loss: 0.00544022024
Iter: 862 loss: 0.00543956319
Iter: 863 loss: 0.00544227613
Iter: 864 loss: 0.00543942396
Iter: 865 loss: 0.005439064
Iter: 866 loss: 0.00543905701
Iter: 867 loss: 0.00543887168
Iter: 868 loss: 0.00543830264
Iter: 869 loss: 0.00543948589
Iter: 870 loss: 0.00543794921
Iter: 871 loss: 0.00543744443
Iter: 872 loss: 0.00543711055
Iter: 873 loss: 0.00543691637
Iter: 874 loss: 0.00543626212
Iter: 875 loss: 0.00543553475
Iter: 876 loss: 0.00543543324
Iter: 877 loss: 0.00543383043
Iter: 878 loss: 0.00543134939
Iter: 879 loss: 0.00543131214
Iter: 880 loss: 0.00542754354
Iter: 881 loss: 0.00543868914
Iter: 882 loss: 0.00542637333
Iter: 883 loss: 0.00542461639
Iter: 884 loss: 0.0054241633
Iter: 885 loss: 0.00542287948
Iter: 886 loss: 0.00542164408
Iter: 887 loss: 0.00542135444
Iter: 888 loss: 0.00542147737
Iter: 889 loss: 0.00542021031
Iter: 890 loss: 0.00541969156
Iter: 891 loss: 0.00541845104
Iter: 892 loss: 0.00543147698
Iter: 893 loss: 0.00541831646
Iter: 894 loss: 0.00541740796
Iter: 895 loss: 0.00542547833
Iter: 896 loss: 0.00541736279
Iter: 897 loss: 0.00541723613
Iter: 898 loss: 0.0054170005
Iter: 899 loss: 0.00542255212
Iter: 900 loss: 0.00541699957
Iter: 901 loss: 0.00541627035
Iter: 902 loss: 0.00542708393
Iter: 903 loss: 0.0054162764
Iter: 904 loss: 0.00541482866
Iter: 905 loss: 0.00542704249
Iter: 906 loss: 0.00541474298
Iter: 907 loss: 0.00541393319
Iter: 908 loss: 0.0054149488
Iter: 909 loss: 0.00541351
Iter: 910 loss: 0.00541205425
Iter: 911 loss: 0.00541558256
Iter: 912 loss: 0.00541152246
Iter: 913 loss: 0.00541039137
Iter: 914 loss: 0.00540957879
Iter: 915 loss: 0.00540918764
Iter: 916 loss: 0.00540655712
Iter: 917 loss: 0.00540672895
Iter: 918 loss: 0.0054044826
Iter: 919 loss: 0.00540207326
Iter: 920 loss: 0.00542220147
Iter: 921 loss: 0.00540192332
Iter: 922 loss: 0.00540101714
Iter: 923 loss: 0.00540087419
Iter: 924 loss: 0.00540061807
Iter: 925 loss: 0.00540030561
Iter: 926 loss: 0.00540005043
Iter: 927 loss: 0.00540179294
Iter: 928 loss: 0.00540002435
Iter: 929 loss: 0.0053997389
Iter: 930 loss: 0.00539879221
Iter: 931 loss: 0.00539867673
Iter: 932 loss: 0.00539777242
Iter: 933 loss: 0.00539715355
Iter: 934 loss: 0.00539921317
Iter: 935 loss: 0.00539698359
Iter: 936 loss: 0.00539637916
Iter: 937 loss: 0.00540570077
Iter: 938 loss: 0.0053963745
Iter: 939 loss: 0.00539607089
Iter: 940 loss: 0.0053952341
Iter: 941 loss: 0.00540021248
Iter: 942 loss: 0.00539500499
Iter: 943 loss: 0.00539236097
Iter: 944 loss: 0.00540148094
Iter: 945 loss: 0.00539165596
Iter: 946 loss: 0.0053892429
Iter: 947 loss: 0.00540263206
Iter: 948 loss: 0.00538888527
Iter: 949 loss: 0.00538712
Iter: 950 loss: 0.00538624357
Iter: 951 loss: 0.00538541097
Iter: 952 loss: 0.00538366102
Iter: 953 loss: 0.00540483
Iter: 954 loss: 0.0053836396
Iter: 955 loss: 0.00538260629
Iter: 956 loss: 0.00538029708
Iter: 957 loss: 0.00541237928
Iter: 958 loss: 0.00538017182
Iter: 959 loss: 0.00538150501
Iter: 960 loss: 0.00537967496
Iter: 961 loss: 0.00537930708
Iter: 962 loss: 0.00538178533
Iter: 963 loss: 0.00537927076
Iter: 964 loss: 0.00537891826
Iter: 965 loss: 0.00537790824
Iter: 966 loss: 0.00538223796
Iter: 967 loss: 0.00537750777
Iter: 968 loss: 0.00537668541
Iter: 969 loss: 0.00537621835
Iter: 970 loss: 0.00537586212
Iter: 971 loss: 0.00537648657
Iter: 972 loss: 0.0053754719
Iter: 973 loss: 0.00537497643
Iter: 974 loss: 0.00537391379
Iter: 975 loss: 0.00539119914
Iter: 976 loss: 0.00537387747
Iter: 977 loss: 0.00537194777
Iter: 978 loss: 0.00537078
Iter: 979 loss: 0.00536999153
Iter: 980 loss: 0.005368168
Iter: 981 loss: 0.00536866393
Iter: 982 loss: 0.00536684971
Iter: 983 loss: 0.00536494516
Iter: 984 loss: 0.00536363944
Iter: 985 loss: 0.00536294095
Iter: 986 loss: 0.00536170695
Iter: 987 loss: 0.00536169857
Iter: 988 loss: 0.00536030065
Iter: 989 loss: 0.00536097772
Iter: 990 loss: 0.00535935629
Iter: 991 loss: 0.0053608669
Iter: 992 loss: 0.00535890507
Iter: 993 loss: 0.00535853766
Iter: 994 loss: 0.00536317565
Iter: 995 loss: 0.00535853114
Iter: 996 loss: 0.00535828108
Iter: 997 loss: 0.00535744661
Iter: 998 loss: 0.00535702892
Iter: 999 loss: 0.00535644591
Iter: 1000 loss: 0.00535558
Iter: 1001 loss: 0.00535718258
Iter: 1002 loss: 0.00535520352
Iter: 1003 loss: 0.00535484729
Iter: 1004 loss: 0.0053553693
Iter: 1005 loss: 0.00535467733
Iter: 1006 loss: 0.00535431365
Iter: 1007 loss: 0.00535341818
Iter: 1008 loss: 0.00536225503
Iter: 1009 loss: 0.00535330549
Iter: 1010 loss: 0.00535186799
Iter: 1011 loss: 0.00536188949
Iter: 1012 loss: 0.00535173248
Iter: 1013 loss: 0.00535105
Iter: 1014 loss: 0.00534961512
Iter: 1015 loss: 0.00537403114
Iter: 1016 loss: 0.0053495774
Iter: 1017 loss: 0.00534884352
Iter: 1018 loss: 0.00534902653
Iter: 1019 loss: 0.00534830336
Iter: 1020 loss: 0.00534787774
Iter: 1021 loss: 0.00534718949
Iter: 1022 loss: 0.00534717925
Iter: 1023 loss: 0.00534641929
Iter: 1024 loss: 0.00534918159
Iter: 1025 loss: 0.00534622278
Iter: 1026 loss: 0.00534554664
Iter: 1027 loss: 0.00534481974
Iter: 1028 loss: 0.00534470379
Iter: 1029 loss: 0.00534423208
Iter: 1030 loss: 0.00534422044
Iter: 1031 loss: 0.00534383394
Iter: 1032 loss: 0.00534458505
Iter: 1033 loss: 0.00534366909
Iter: 1034 loss: 0.00534280622
Iter: 1035 loss: 0.00534617901
Iter: 1036 loss: 0.00534261111
Iter: 1037 loss: 0.00534161041
Iter: 1038 loss: 0.00534160854
Iter: 1039 loss: 0.00534090353
Iter: 1040 loss: 0.00533944974
Iter: 1041 loss: 0.00536561431
Iter: 1042 loss: 0.00533941947
Iter: 1043 loss: 0.0053386786
Iter: 1044 loss: 0.00533756893
Iter: 1045 loss: 0.00533754658
Iter: 1046 loss: 0.00533644948
Iter: 1047 loss: 0.00533635961
Iter: 1048 loss: 0.00533749256
Iter: 1049 loss: 0.00533586368
Iter: 1050 loss: 0.00533572026
Iter: 1051 loss: 0.00533593446
Iter: 1052 loss: 0.00533564389
Iter: 1053 loss: 0.00533522293
Iter: 1054 loss: 0.00533422921
Iter: 1055 loss: 0.00534644257
Iter: 1056 loss: 0.00533414725
Iter: 1057 loss: 0.00533358473
Iter: 1058 loss: 0.00533729373
Iter: 1059 loss: 0.00533352839
Iter: 1060 loss: 0.00533320103
Iter: 1061 loss: 0.00533345062
Iter: 1062 loss: 0.00533300685
Iter: 1063 loss: 0.00533267856
Iter: 1064 loss: 0.0053318697
Iter: 1065 loss: 0.0053398693
Iter: 1066 loss: 0.00533176772
Iter: 1067 loss: 0.00533053465
Iter: 1068 loss: 0.00533022126
Iter: 1069 loss: 0.00533038843
Iter: 1070 loss: 0.00532991486
Iter: 1071 loss: 0.00532975141
Iter: 1072 loss: 0.00532959588
Iter: 1073 loss: 0.00532956049
Iter: 1074 loss: 0.00532919634
Iter: 1075 loss: 0.00532831158
Iter: 1076 loss: 0.0053373524
Iter: 1077 loss: 0.00532821147
Iter: 1078 loss: 0.0053268
Iter: 1079 loss: 0.00533463759
Iter: 1080 loss: 0.005326604
Iter: 1081 loss: 0.00532564335
Iter: 1082 loss: 0.00533171231
Iter: 1083 loss: 0.00532553298
Iter: 1084 loss: 0.00532681867
Iter: 1085 loss: 0.00532537419
Iter: 1086 loss: 0.00532525545
Iter: 1087 loss: 0.00532489829
Iter: 1088 loss: 0.00532598142
Iter: 1089 loss: 0.00532472041
Iter: 1090 loss: 0.00532456627
Iter: 1091 loss: 0.00532448245
Iter: 1092 loss: 0.00532424496
Iter: 1093 loss: 0.00532538
Iter: 1094 loss: 0.005324197
Iter: 1095 loss: 0.00532402284
Iter: 1096 loss: 0.00532359537
Iter: 1097 loss: 0.00532795209
Iter: 1098 loss: 0.00532354647
Iter: 1099 loss: 0.00532324146
Iter: 1100 loss: 0.00532315718
Iter: 1101 loss: 0.00532301096
Iter: 1102 loss: 0.00532300211
Iter: 1103 loss: 0.00532284752
Iter: 1104 loss: 0.00532269944
Iter: 1105 loss: 0.00532266172
Iter: 1106 loss: 0.00532229524
Iter: 1107 loss: 0.00532191666
Iter: 1108 loss: 0.00532184448
Iter: 1109 loss: 0.00532164564
Iter: 1110 loss: 0.00532160513
Iter: 1111 loss: 0.00532138487
Iter: 1112 loss: 0.00532124285
Iter: 1113 loss: 0.0053211581
Iter: 1114 loss: 0.00532063562
Iter: 1115 loss: 0.00532109756
Iter: 1116 loss: 0.00532033248
Iter: 1117 loss: 0.00532015134
Iter: 1118 loss: 0.00532008242
Iter: 1119 loss: 0.00531984
Iter: 1120 loss: 0.00532272831
Iter: 1121 loss: 0.00531983562
Iter: 1122 loss: 0.00531976484
Iter: 1123 loss: 0.0053195497
Iter: 1124 loss: 0.00532044191
Iter: 1125 loss: 0.00531946309
Iter: 1126 loss: 0.00531892339
Iter: 1127 loss: 0.00531844515
Iter: 1128 loss: 0.00531829894
Iter: 1129 loss: 0.00531799
Iter: 1130 loss: 0.00531764887
Iter: 1131 loss: 0.00531759718
Iter: 1132 loss: 0.00531716
Iter: 1133 loss: 0.00531714875
Iter: 1134 loss: 0.00531658903
Iter: 1135 loss: 0.00531971082
Iter: 1136 loss: 0.00531651266
Iter: 1137 loss: 0.00531632081
Iter: 1138 loss: 0.0053160605
Iter: 1139 loss: 0.005316047
Iter: 1140 loss: 0.0053157825
Iter: 1141 loss: 0.00531600975
Iter: 1142 loss: 0.00531562371
Iter: 1143 loss: 0.00531529589
Iter: 1144 loss: 0.00531512219
Iter: 1145 loss: 0.00531497411
Iter: 1146 loss: 0.00531464443
Iter: 1147 loss: 0.00531497039
Iter: 1148 loss: 0.00531446375
Iter: 1149 loss: 0.0053143343
Iter: 1150 loss: 0.00531470124
Iter: 1151 loss: 0.00531429425
Iter: 1152 loss: 0.00531425094
Iter: 1153 loss: 0.00531409122
Iter: 1154 loss: 0.00531392591
Iter: 1155 loss: 0.00531386212
Iter: 1156 loss: 0.00531342346
Iter: 1157 loss: 0.0053127734
Iter: 1158 loss: 0.00531276036
Iter: 1159 loss: 0.00531197339
Iter: 1160 loss: 0.00531188585
Iter: 1161 loss: 0.00531132147
Iter: 1162 loss: 0.00531013589
Iter: 1163 loss: 0.00531563861
Iter: 1164 loss: 0.00530991238
Iter: 1165 loss: 0.00530941784
Iter: 1166 loss: 0.00530919572
Iter: 1167 loss: 0.00530902669
Iter: 1168 loss: 0.00530863
Iter: 1169 loss: 0.00530847861
Iter: 1170 loss: 0.00530801062
Iter: 1171 loss: 0.00530928932
Iter: 1172 loss: 0.00530776754
Iter: 1173 loss: 0.00530711375
Iter: 1174 loss: 0.00530806836
Iter: 1175 loss: 0.00530680083
Iter: 1176 loss: 0.00530647
Iter: 1177 loss: 0.00530595891
Iter: 1178 loss: 0.00530595332
Iter: 1179 loss: 0.00530694891
Iter: 1180 loss: 0.00530574098
Iter: 1181 loss: 0.00530570187
Iter: 1182 loss: 0.00530564692
Iter: 1183 loss: 0.00530556869
Iter: 1184 loss: 0.00530531
Iter: 1185 loss: 0.00530512584
Iter: 1186 loss: 0.00530498195
Iter: 1187 loss: 0.00530396961
Iter: 1188 loss: 0.00531573221
Iter: 1189 loss: 0.00530395471
Iter: 1190 loss: 0.00530337729
Iter: 1191 loss: 0.0053031412
Iter: 1192 loss: 0.00530283386
Iter: 1193 loss: 0.00530242734
Iter: 1194 loss: 0.00530294236
Iter: 1195 loss: 0.00530221779
Iter: 1196 loss: 0.00530205667
Iter: 1197 loss: 0.00530159
Iter: 1198 loss: 0.00530352164
Iter: 1199 loss: 0.00530140661
Iter: 1200 loss: 0.00530143827
Iter: 1201 loss: 0.00530110486
Iter: 1202 loss: 0.00530067598
Iter: 1203 loss: 0.00530173583
Iter: 1204 loss: 0.00530052558
Iter: 1205 loss: 0.00529986341
Iter: 1206 loss: 0.00529981032
Iter: 1207 loss: 0.00529949367
Iter: 1208 loss: 0.0052989386
Iter: 1209 loss: 0.00529893674
Iter: 1210 loss: 0.00529829785
Iter: 1211 loss: 0.00529808737
Iter: 1212 loss: 0.00529771764
Iter: 1213 loss: 0.00529741962
Iter: 1214 loss: 0.00529687386
Iter: 1215 loss: 0.00530948816
Iter: 1216 loss: 0.00529687293
Iter: 1217 loss: 0.0052972259
Iter: 1218 loss: 0.00529653
Iter: 1219 loss: 0.00529641053
Iter: 1220 loss: 0.00529612834
Iter: 1221 loss: 0.00529983453
Iter: 1222 loss: 0.00529611437
Iter: 1223 loss: 0.00529553974
Iter: 1224 loss: 0.00529539958
Iter: 1225 loss: 0.00529503357
Iter: 1226 loss: 0.00529549085
Iter: 1227 loss: 0.00529482681
Iter: 1228 loss: 0.00529470062
Iter: 1229 loss: 0.0052943374
Iter: 1230 loss: 0.00529571716
Iter: 1231 loss: 0.00529417954
Iter: 1232 loss: 0.00529351458
Iter: 1233 loss: 0.00529221725
Iter: 1234 loss: 0.00531854248
Iter: 1235 loss: 0.00529220421
Iter: 1236 loss: 0.0052925637
Iter: 1237 loss: 0.00529185031
Iter: 1238 loss: 0.00529144751
Iter: 1239 loss: 0.00529109128
Iter: 1240 loss: 0.00529098324
Iter: 1241 loss: 0.00529197371
Iter: 1242 loss: 0.0052907588
Iter: 1243 loss: 0.00529042259
Iter: 1244 loss: 0.00529199466
Iter: 1245 loss: 0.00529036205
Iter: 1246 loss: 0.00529026194
Iter: 1247 loss: 0.00528988894
Iter: 1248 loss: 0.00528916344
Iter: 1249 loss: 0.00528915226
Iter: 1250 loss: 0.0052884547
Iter: 1251 loss: 0.00529051572
Iter: 1252 loss: 0.00528824236
Iter: 1253 loss: 0.00528784934
Iter: 1254 loss: 0.00528793409
Iter: 1255 loss: 0.00528755877
Iter: 1256 loss: 0.0052877469
Iter: 1257 loss: 0.00528726168
Iter: 1258 loss: 0.00528709823
Iter: 1259 loss: 0.00528820045
Iter: 1260 loss: 0.00528708333
Iter: 1261 loss: 0.00528685143
Iter: 1262 loss: 0.0052864044
Iter: 1263 loss: 0.00529546151
Iter: 1264 loss: 0.0052864
Iter: 1265 loss: 0.00528592803
Iter: 1266 loss: 0.00528527424
Iter: 1267 loss: 0.00528525189
Iter: 1268 loss: 0.00528460741
Iter: 1269 loss: 0.00528752664
Iter: 1270 loss: 0.0052844868
Iter: 1271 loss: 0.00528397
Iter: 1272 loss: 0.00528445467
Iter: 1273 loss: 0.00528367097
Iter: 1274 loss: 0.00528304745
Iter: 1275 loss: 0.00528304279
Iter: 1276 loss: 0.00528327283
Iter: 1277 loss: 0.00528297201
Iter: 1278 loss: 0.00528293196
Iter: 1279 loss: 0.00528280716
Iter: 1280 loss: 0.0052833287
Iter: 1281 loss: 0.0052827578
Iter: 1282 loss: 0.00528226327
Iter: 1283 loss: 0.00528442
Iter: 1284 loss: 0.00528216828
Iter: 1285 loss: 0.00528174
Iter: 1286 loss: 0.00528107164
Iter: 1287 loss: 0.00528106373
Iter: 1288 loss: 0.00528199784
Iter: 1289 loss: 0.00528083835
Iter: 1290 loss: 0.00528080296
Iter: 1291 loss: 0.00528069213
Iter: 1292 loss: 0.00528060179
Iter: 1293 loss: 0.00528033264
Iter: 1294 loss: 0.00528120622
Iter: 1295 loss: 0.00528020039
Iter: 1296 loss: 0.00527985115
Iter: 1297 loss: 0.00528110284
Iter: 1298 loss: 0.00527976453
Iter: 1299 loss: 0.0052794246
Iter: 1300 loss: 0.00527873123
Iter: 1301 loss: 0.00529100373
Iter: 1302 loss: 0.00527871493
Iter: 1303 loss: 0.00527824229
Iter: 1304 loss: 0.00527818687
Iter: 1305 loss: 0.00527772959
Iter: 1306 loss: 0.00527779199
Iter: 1307 loss: 0.00527737942
Iter: 1308 loss: 0.00527693192
Iter: 1309 loss: 0.00527691375
Iter: 1310 loss: 0.00527639128
Iter: 1311 loss: 0.00527739245
Iter: 1312 loss: 0.00527617475
Iter: 1313 loss: 0.00527606532
Iter: 1314 loss: 0.00527575612
Iter: 1315 loss: 0.00527730957
Iter: 1316 loss: 0.00527565554
Iter: 1317 loss: 0.00527524855
Iter: 1318 loss: 0.00527529139
Iter: 1319 loss: 0.00527493702
Iter: 1320 loss: 0.00527466228
Iter: 1321 loss: 0.00527422689
Iter: 1322 loss: 0.00527422177
Iter: 1323 loss: 0.00527400803
Iter: 1324 loss: 0.0052742213
Iter: 1325 loss: 0.00527388789
Iter: 1326 loss: 0.00527347624
Iter: 1327 loss: 0.00527466647
Iter: 1328 loss: 0.00527334306
Iter: 1329 loss: 0.00527313491
Iter: 1330 loss: 0.0052727391
Iter: 1331 loss: 0.00528172962
Iter: 1332 loss: 0.00527274143
Iter: 1333 loss: 0.00527232792
Iter: 1334 loss: 0.00527324621
Iter: 1335 loss: 0.00527216634
Iter: 1336 loss: 0.00527191209
Iter: 1337 loss: 0.00527136307
Iter: 1338 loss: 0.00527995452
Iter: 1339 loss: 0.00527134538
Iter: 1340 loss: 0.00527102826
Iter: 1341 loss: 0.00527101289
Iter: 1342 loss: 0.00527095795
Iter: 1343 loss: 0.00527089974
Iter: 1344 loss: 0.00527077448
Iter: 1345 loss: 0.00527189206
Iter: 1346 loss: 0.00527077168
Iter: 1347 loss: 0.00527072605
Iter: 1348 loss: 0.00527056493
Iter: 1349 loss: 0.00527011417
Iter: 1350 loss: 0.00527663808
Iter: 1351 loss: 0.00527008623
Iter: 1352 loss: 0.00526959
Iter: 1353 loss: 0.0052713817
Iter: 1354 loss: 0.00526946224
Iter: 1355 loss: 0.00526912417
Iter: 1356 loss: 0.00527240243
Iter: 1357 loss: 0.00526910787
Iter: 1358 loss: 0.00526891649
Iter: 1359 loss: 0.00526909
Iter: 1360 loss: 0.00526880659
Iter: 1361 loss: 0.00526844896
Iter: 1362 loss: 0.00527140778
Iter: 1363 loss: 0.00526843127
Iter: 1364 loss: 0.00526827388
Iter: 1365 loss: 0.00526777096
Iter: 1366 loss: 0.00526832277
Iter: 1367 loss: 0.00526737887
Iter: 1368 loss: 0.00526686
Iter: 1369 loss: 0.00527060777
Iter: 1370 loss: 0.00526682
Iter: 1371 loss: 0.00526667247
Iter: 1372 loss: 0.00526678935
Iter: 1373 loss: 0.00526658818
Iter: 1374 loss: 0.00526643218
Iter: 1375 loss: 0.00526603172
Iter: 1376 loss: 0.00526971929
Iter: 1377 loss: 0.00526597816
Iter: 1378 loss: 0.00526562892
Iter: 1379 loss: 0.0052667358
Iter: 1380 loss: 0.00526552927
Iter: 1381 loss: 0.00526553858
Iter: 1382 loss: 0.00526537793
Iter: 1383 loss: 0.00526532577
Iter: 1384 loss: 0.00526527222
Iter: 1385 loss: 0.00526526431
Iter: 1386 loss: 0.00526514836
Iter: 1387 loss: 0.00526481774
Iter: 1388 loss: 0.00526631251
Iter: 1389 loss: 0.00526470644
Iter: 1390 loss: 0.00526476372
Iter: 1391 loss: 0.00526451413
Iter: 1392 loss: 0.0052644
Iter: 1393 loss: 0.00526434649
Iter: 1394 loss: 0.00526424777
Iter: 1395 loss: 0.00526443636
Iter: 1396 loss: 0.00526420819
Iter: 1397 loss: 0.00526401494
Iter: 1398 loss: 0.00526366569
Iter: 1399 loss: 0.00527209463
Iter: 1400 loss: 0.00526366383
Iter: 1401 loss: 0.00526366383
Iter: 1402 loss: 0.0052635083
Iter: 1403 loss: 0.00526345056
Iter: 1404 loss: 0.00526330806
Iter: 1405 loss: 0.00526459143
Iter: 1406 loss: 0.00526328199
Iter: 1407 loss: 0.00526325032
Iter: 1408 loss: 0.00526313949
Iter: 1409 loss: 0.00526308734
Iter: 1410 loss: 0.00526319956
Iter: 1411 loss: 0.00526306592
Iter: 1412 loss: 0.00526303053
Iter: 1413 loss: 0.00526309386
Iter: 1414 loss: 0.00526302028
Iter: 1415 loss: 0.0052629807
Iter: 1416 loss: 0.00526292156
Iter: 1417 loss: 0.0052642962
Iter: 1418 loss: 0.00526292
Iter: 1419 loss: 0.00526274089
Iter: 1420 loss: 0.0052625509
Iter: 1421 loss: 0.00526251923
Iter: 1422 loss: 0.0052621318
Iter: 1423 loss: 0.00526319
Iter: 1424 loss: 0.00526200514
Iter: 1425 loss: 0.00526180491
Iter: 1426 loss: 0.00526180211
Iter: 1427 loss: 0.00526167266
Iter: 1428 loss: 0.00526167173
Iter: 1429 loss: 0.00526162703
Iter: 1430 loss: 0.00526151061
Iter: 1431 loss: 0.00526239304
Iter: 1432 loss: 0.0052614864
Iter: 1433 loss: 0.00526141841
Iter: 1434 loss: 0.00526141375
Iter: 1435 loss: 0.00526132528
Iter: 1436 loss: 0.00526107661
Iter: 1437 loss: 0.00526182773
Iter: 1438 loss: 0.00526093971
Iter: 1439 loss: 0.00526116369
Iter: 1440 loss: 0.00526084937
Iter: 1441 loss: 0.00526079722
Iter: 1442 loss: 0.00526088942
Iter: 1443 loss: 0.00526077161
Iter: 1444 loss: 0.00526068686
Iter: 1445 loss: 0.00526045216
Iter: 1446 loss: 0.00526184309
Iter: 1447 loss: 0.0052603865
Iter: 1448 loss: 0.0052602347
Iter: 1449 loss: 0.00526019372
Iter: 1450 loss: 0.00526009034
Iter: 1451 loss: 0.00525984075
Iter: 1452 loss: 0.00526238326
Iter: 1453 loss: 0.00525980722
Iter: 1454 loss: 0.00525971875
Iter: 1455 loss: 0.0052601262
Iter: 1456 loss: 0.00525970664
Iter: 1457 loss: 0.00525968615
Iter: 1458 loss: 0.00525963213
Iter: 1459 loss: 0.00525988
Iter: 1460 loss: 0.00525961304
Iter: 1461 loss: 0.00525978953
Iter: 1462 loss: 0.0052595567
Iter: 1463 loss: 0.0052594617
Iter: 1464 loss: 0.0052593546
Iter: 1465 loss: 0.00525933784
Iter: 1466 loss: 0.00525931921
Iter: 1467 loss: 0.00525922701
Iter: 1468 loss: 0.00525910966
Iter: 1469 loss: 0.00525901746
Iter: 1470 loss: 0.00525898533
Iter: 1471 loss: 0.00525890617
Iter: 1472 loss: 0.00525899744
Iter: 1473 loss: 0.00525886472
Iter: 1474 loss: 0.00525884237
Iter: 1475 loss: 0.00525886891
Iter: 1476 loss: 0.00525883213
Iter: 1477 loss: 0.00525875669
Iter: 1478 loss: 0.0052587525
Iter: 1479 loss: 0.00525868172
Iter: 1480 loss: 0.00525868312
Iter: 1481 loss: 0.00525863376
Iter: 1482 loss: 0.00525862537
Iter: 1483 loss: 0.00525859
Iter: 1484 loss: 0.00525833666
Iter: 1485 loss: 0.00526078837
Iter: 1486 loss: 0.00525832828
Iter: 1487 loss: 0.00525803119
Iter: 1488 loss: 0.00525817461
Iter: 1489 loss: 0.00525783049
Iter: 1490 loss: 0.00525754504
Iter: 1491 loss: 0.00525820162
Iter: 1492 loss: 0.00525743933
Iter: 1493 loss: 0.0052572405
Iter: 1494 loss: 0.00526019931
Iter: 1495 loss: 0.00525724236
Iter: 1496 loss: 0.00525708497
Iter: 1497 loss: 0.0052568363
Iter: 1498 loss: 0.00525683118
Iter: 1499 loss: 0.00525653549
Iter: 1500 loss: 0.00526039163
Iter: 1501 loss: 0.00525652757
Iter: 1502 loss: 0.00525672082
Iter: 1503 loss: 0.00525648147
Iter: 1504 loss: 0.00525641721
Iter: 1505 loss: 0.00525626726
Iter: 1506 loss: 0.00525798555
Iter: 1507 loss: 0.00525625236
Iter: 1508 loss: 0.00525616
Iter: 1509 loss: 0.00525599578
Iter: 1510 loss: 0.00526002049
Iter: 1511 loss: 0.00525599718
Iter: 1512 loss: 0.00525607
Iter: 1513 loss: 0.00525587611
Iter: 1514 loss: 0.00525578763
Iter: 1515 loss: 0.00525589567
Iter: 1516 loss: 0.00525573594
Iter: 1517 loss: 0.00525561906
Iter: 1518 loss: 0.00525541278
Iter: 1519 loss: 0.00525541324
Iter: 1520 loss: 0.00525550358
Iter: 1521 loss: 0.00525525026
Iter: 1522 loss: 0.00525514595
Iter: 1523 loss: 0.0052552009
Iter: 1524 loss: 0.0052550789
Iter: 1525 loss: 0.0052549853
Iter: 1526 loss: 0.00525491685
Iter: 1527 loss: 0.00525488472
Iter: 1528 loss: 0.00525479857
Iter: 1529 loss: 0.00525479438
Iter: 1530 loss: 0.00525473
Iter: 1531 loss: 0.00525460392
Iter: 1532 loss: 0.00525476038
Iter: 1533 loss: 0.00525453221
Iter: 1534 loss: 0.00525460485
Iter: 1535 loss: 0.00525450334
Iter: 1536 loss: 0.00525445631
Iter: 1537 loss: 0.00525437854
Iter: 1538 loss: 0.00525438134
Iter: 1539 loss: 0.00525429845
Iter: 1540 loss: 0.00525430497
Iter: 1541 loss: 0.00525423605
Iter: 1542 loss: 0.00525412615
Iter: 1543 loss: 0.00525522511
Iter: 1544 loss: 0.0052541215
Iter: 1545 loss: 0.00525412243
Iter: 1546 loss: 0.00525409728
Iter: 1547 loss: 0.00525407679
Iter: 1548 loss: 0.00525400136
Iter: 1549 loss: 0.00525412895
Iter: 1550 loss: 0.00525394874
Iter: 1551 loss: 0.00525384303
Iter: 1552 loss: 0.00525363628
Iter: 1553 loss: 0.00525755901
Iter: 1554 loss: 0.00525363442
Iter: 1555 loss: 0.00525410939
Iter: 1556 loss: 0.00525355618
Iter: 1557 loss: 0.00525351288
Iter: 1558 loss: 0.00525359903
Iter: 1559 loss: 0.00525349518
Iter: 1560 loss: 0.00525347143
Iter: 1561 loss: 0.00525342952
Iter: 1562 loss: 0.00525343139
Iter: 1563 loss: 0.00525338389
Iter: 1564 loss: 0.0052533159
Iter: 1565 loss: 0.00525331264
Iter: 1566 loss: 0.00525320042
Iter: 1567 loss: 0.00525356643
Iter: 1568 loss: 0.00525316689
Iter: 1569 loss: 0.00525305653
Iter: 1570 loss: 0.00525306351
Iter: 1571 loss: 0.00525300112
Iter: 1572 loss: 0.00525291217
Iter: 1573 loss: 0.00525291357
Iter: 1574 loss: 0.00525283627
Iter: 1575 loss: 0.00525307469
Iter: 1576 loss: 0.00525281206
Iter: 1577 loss: 0.00525277
Iter: 1578 loss: 0.00525282044
Iter: 1579 loss: 0.00525274873
Iter: 1580 loss: 0.00525269285
Iter: 1581 loss: 0.00525263
Iter: 1582 loss: 0.00525262579
Iter: 1583 loss: 0.00525258621
Iter: 1584 loss: 0.00525246933
Iter: 1585 loss: 0.00525314081
Iter: 1586 loss: 0.00525243953
Iter: 1587 loss: 0.00525217969
Iter: 1588 loss: 0.00525326189
Iter: 1589 loss: 0.0052521266
Iter: 1590 loss: 0.00530413166
Iter: 1591 loss: 0.00525207352
Iter: 1592 loss: 0.0052520032
Iter: 1593 loss: 0.00525237434
Iter: 1594 loss: 0.00525199156
Iter: 1595 loss: 0.0052519585
Iter: 1596 loss: 0.00525188446
Iter: 1597 loss: 0.00525332335
Iter: 1598 loss: 0.00525188819
Iter: 1599 loss: 0.00525167258
Iter: 1600 loss: 0.00525311334
Iter: 1601 loss: 0.00525164604
Iter: 1602 loss: 0.00525151519
Iter: 1603 loss: 0.00525156409
Iter: 1604 loss: 0.00525142439
Iter: 1605 loss: 0.00525134197
Iter: 1606 loss: 0.00525126327
Iter: 1607 loss: 0.00525125256
Iter: 1608 loss: 0.00525119621
Iter: 1609 loss: 0.00525111705
Iter: 1610 loss: 0.00525111426
Iter: 1611 loss: 0.00525102066
Iter: 1612 loss: 0.00525090471
Iter: 1613 loss: 0.00525089167
Iter: 1614 loss: 0.00525080971
Iter: 1615 loss: 0.00525176246
Iter: 1616 loss: 0.00525080599
Iter: 1617 loss: 0.00525074732
Iter: 1618 loss: 0.00525060622
Iter: 1619 loss: 0.00525249867
Iter: 1620 loss: 0.00525059691
Iter: 1621 loss: 0.00525035104
Iter: 1622 loss: 0.00525102112
Iter: 1623 loss: 0.00525027141
Iter: 1624 loss: 0.00525185559
Iter: 1625 loss: 0.00525022205
Iter: 1626 loss: 0.00525019411
Iter: 1627 loss: 0.0052502
Iter: 1628 loss: 0.00525017735
Iter: 1629 loss: 0.00525013171
Iter: 1630 loss: 0.00525000365
Iter: 1631 loss: 0.00525059737
Iter: 1632 loss: 0.00524995383
Iter: 1633 loss: 0.00524981227
Iter: 1634 loss: 0.0052497806
Iter: 1635 loss: 0.005249687
Iter: 1636 loss: 0.00524949189
Iter: 1637 loss: 0.00524991099
Iter: 1638 loss: 0.00524941366
Iter: 1639 loss: 0.00524926884
Iter: 1640 loss: 0.00524924882
Iter: 1641 loss: 0.00524920225
Iter: 1642 loss: 0.00524923578
Iter: 1643 loss: 0.00524917478
Iter: 1644 loss: 0.00524907932
Iter: 1645 loss: 0.00524995
Iter: 1646 loss: 0.00524907932
Iter: 1647 loss: 0.00524902344
Iter: 1648 loss: 0.0052497806
Iter: 1649 loss: 0.0052490253
Iter: 1650 loss: 0.00524899
Iter: 1651 loss: 0.00524889212
Iter: 1652 loss: 0.00524914172
Iter: 1653 loss: 0.00524884416
Iter: 1654 loss: 0.00524861459
Iter: 1655 loss: 0.00525013544
Iter: 1656 loss: 0.00524859456
Iter: 1657 loss: 0.00524845952
Iter: 1658 loss: 0.00524967909
Iter: 1659 loss: 0.0052484544
Iter: 1660 loss: 0.00524853263
Iter: 1661 loss: 0.00524840411
Iter: 1662 loss: 0.00524839479
Iter: 1663 loss: 0.0052483594
Iter: 1664 loss: 0.00524841156
Iter: 1665 loss: 0.00524833798
Iter: 1666 loss: 0.00524829561
Iter: 1667 loss: 0.0052483012
Iter: 1668 loss: 0.00524827
Iter: 1669 loss: 0.00524820946
Iter: 1670 loss: 0.00524808
Iter: 1671 loss: 0.00524992682
Iter: 1672 loss: 0.0052480693
Iter: 1673 loss: 0.00524783041
Iter: 1674 loss: 0.00525008654
Iter: 1675 loss: 0.00524782063
Iter: 1676 loss: 0.00524785742
Iter: 1677 loss: 0.00524778338
Iter: 1678 loss: 0.00524774566
Iter: 1679 loss: 0.00524770748
Iter: 1680 loss: 0.00524770096
Iter: 1681 loss: 0.00524764322
Iter: 1682 loss: 0.00524770841
Iter: 1683 loss: 0.00524761155
Iter: 1684 loss: 0.00524756964
Iter: 1685 loss: 0.00524754543
Iter: 1686 loss: 0.00524753
Iter: 1687 loss: 0.00524750538
Iter: 1688 loss: 0.00524750724
Iter: 1689 loss: 0.00524749095
Iter: 1690 loss: 0.00524747092
Iter: 1691 loss: 0.00524743367
Iter: 1692 loss: 0.00524808746
Iter: 1693 loss: 0.00524743274
Iter: 1694 loss: 0.00524736848
Iter: 1695 loss: 0.00524770236
Iter: 1696 loss: 0.00524735777
Iter: 1697 loss: 0.00524722785
Iter: 1698 loss: 0.0052472325
Iter: 1699 loss: 0.00524716172
Iter: 1700 loss: 0.00524715241
Iter: 1701 loss: 0.00524707325
Iter: 1702 loss: 0.00524694659
Iter: 1703 loss: 0.00524694752
Iter: 1704 loss: 0.00524680782
Iter: 1705 loss: 0.00524764974
Iter: 1706 loss: 0.00524678966
Iter: 1707 loss: 0.00524711888
Iter: 1708 loss: 0.00524676032
Iter: 1709 loss: 0.00524674263
Iter: 1710 loss: 0.00524671376
Iter: 1711 loss: 0.00524671422
Iter: 1712 loss: 0.00524663553
Iter: 1713 loss: 0.00524704903
Iter: 1714 loss: 0.00524661923
Iter: 1715 loss: 0.00524658477
Iter: 1716 loss: 0.00524676871
Iter: 1717 loss: 0.00524658058
Iter: 1718 loss: 0.00524656288
Iter: 1719 loss: 0.0052466318
Iter: 1720 loss: 0.0052465573
Iter: 1721 loss: 0.00524654426
Iter: 1722 loss: 0.00524650607
Iter: 1723 loss: 0.00524665276
Iter: 1724 loss: 0.00524648698
Iter: 1725 loss: 0.00524639338
Iter: 1726 loss: 0.00524666719
Iter: 1727 loss: 0.00524636684
Iter: 1728 loss: 0.00524630537
Iter: 1729 loss: 0.00524662761
Iter: 1730 loss: 0.00524629559
Iter: 1731 loss: 0.00524625368
Iter: 1732 loss: 0.00524640596
Iter: 1733 loss: 0.00524623971
Iter: 1734 loss: 0.00524619315
Iter: 1735 loss: 0.00524618383
Iter: 1736 loss: 0.00524615357
Iter: 1737 loss: 0.0052461056
Iter: 1738 loss: 0.00524607208
Iter: 1739 loss: 0.00524606276
Iter: 1740 loss: 0.00524604041
Iter: 1741 loss: 0.00524603669
Iter: 1742 loss: 0.00524601294
Iter: 1743 loss: 0.00524603575
Iter: 1744 loss: 0.00524600036
Iter: 1745 loss: 0.00524597242
Iter: 1746 loss: 0.0052459063
Iter: 1747 loss: 0.00524626859
Iter: 1748 loss: 0.00524588255
Iter: 1749 loss: 0.00524602272
Iter: 1750 loss: 0.00524586812
Iter: 1751 loss: 0.0052458439
Iter: 1752 loss: 0.00524607487
Iter: 1753 loss: 0.0052458467
Iter: 1754 loss: 0.00524583692
Iter: 1755 loss: 0.00524581037
Iter: 1756 loss: 0.00524577592
Iter: 1757 loss: 0.00524577
Iter: 1758 loss: 0.0052457
Iter: 1759 loss: 0.00524570234
Iter: 1760 loss: 0.00524564646
Iter: 1761 loss: 0.00524560641
Iter: 1762 loss: 0.00524560735
Iter: 1763 loss: 0.00524558127
Iter: 1764 loss: 0.00524553237
Iter: 1765 loss: 0.00524553377
Iter: 1766 loss: 0.00524549652
Iter: 1767 loss: 0.00524558499
Iter: 1768 loss: 0.00524548
Iter: 1769 loss: 0.00524543691
Iter: 1770 loss: 0.00524531817
Iter: 1771 loss: 0.00524654938
Iter: 1772 loss: 0.00524530793
Iter: 1773 loss: 0.00524529722
Iter: 1774 loss: 0.00524526462
Iter: 1775 loss: 0.00524521852
Iter: 1776 loss: 0.00524532283
Iter: 1777 loss: 0.0052451985
Iter: 1778 loss: 0.00524514727
Iter: 1779 loss: 0.00524508301
Iter: 1780 loss: 0.00524508068
Iter: 1781 loss: 0.00524505042
Iter: 1782 loss: 0.00524504669
Iter: 1783 loss: 0.00524500199
Iter: 1784 loss: 0.00524542294
Iter: 1785 loss: 0.00524500199
Iter: 1786 loss: 0.00524499407
Iter: 1787 loss: 0.00524495728
Iter: 1788 loss: 0.00524501037
Iter: 1789 loss: 0.00524493586
Iter: 1790 loss: 0.00524488324
Iter: 1791 loss: 0.00524498243
Iter: 1792 loss: 0.00524485949
Iter: 1793 loss: 0.00524482178
Iter: 1794 loss: 0.00524474587
Iter: 1795 loss: 0.00524590164
Iter: 1796 loss: 0.00524474215
Iter: 1797 loss: 0.00524468441
Iter: 1798 loss: 0.00524466485
Iter: 1799 loss: 0.00524463691
Iter: 1800 loss: 0.00524458662
Iter: 1801 loss: 0.00524586113
Iter: 1802 loss: 0.00524458569
Iter: 1803 loss: 0.0052445028
Iter: 1804 loss: 0.00524458848
Iter: 1805 loss: 0.00524446182
Iter: 1806 loss: 0.00524441432
Iter: 1807 loss: 0.00524459407
Iter: 1808 loss: 0.00524441153
Iter: 1809 loss: 0.00524439104
Iter: 1810 loss: 0.00524438
Iter: 1811 loss: 0.00524436124
Iter: 1812 loss: 0.00524431234
Iter: 1813 loss: 0.0052446574
Iter: 1814 loss: 0.00524430396
Iter: 1815 loss: 0.00524427881
Iter: 1816 loss: 0.00524445437
Iter: 1817 loss: 0.00524427276
Iter: 1818 loss: 0.00524426345
Iter: 1819 loss: 0.00524426345
Iter: 1820 loss: 0.00524425879
Iter: 1821 loss: 0.00524424296
Iter: 1822 loss: 0.00524420664
Iter: 1823 loss: 0.00524497125
Iter: 1824 loss: 0.00524420338
Iter: 1825 loss: 0.00524413493
Iter: 1826 loss: 0.00524413818
Iter: 1827 loss: 0.00524405763
Iter: 1828 loss: 0.00524473656
Iter: 1829 loss: 0.00524405204
Iter: 1830 loss: 0.00524402317
Iter: 1831 loss: 0.0052440837
Iter: 1832 loss: 0.00524401758
Iter: 1833 loss: 0.00524398265
Iter: 1834 loss: 0.00524396636
Iter: 1835 loss: 0.00524395145
Iter: 1836 loss: 0.00524391048
Iter: 1837 loss: 0.00524392631
Iter: 1838 loss: 0.00524388487
Iter: 1839 loss: 0.00524383597
Iter: 1840 loss: 0.00524381548
Iter: 1841 loss: 0.00524378754
Iter: 1842 loss: 0.00524376472
Iter: 1843 loss: 0.00524375448
Iter: 1844 loss: 0.00524373213
Iter: 1845 loss: 0.0052437447
Iter: 1846 loss: 0.00524372328
Iter: 1847 loss: 0.00524371
Iter: 1848 loss: 0.00524368137
Iter: 1849 loss: 0.00524417311
Iter: 1850 loss: 0.00524368
Iter: 1851 loss: 0.00524363527
Iter: 1852 loss: 0.00524415914
Iter: 1853 loss: 0.00524363574
Iter: 1854 loss: 0.0052435929
Iter: 1855 loss: 0.00524348719
Iter: 1856 loss: 0.00524449768
Iter: 1857 loss: 0.0052434681
Iter: 1858 loss: 0.00524340291
Iter: 1859 loss: 0.0052433894
Iter: 1860 loss: 0.00524334
Iter: 1861 loss: 0.00524345413
Iter: 1862 loss: 0.00524331722
Iter: 1863 loss: 0.00524323853
Iter: 1864 loss: 0.00524421083
Iter: 1865 loss: 0.00524323666
Iter: 1866 loss: 0.00524320081
Iter: 1867 loss: 0.00524322316
Iter: 1868 loss: 0.00524318265
Iter: 1869 loss: 0.00524315517
Iter: 1870 loss: 0.00524312072
Iter: 1871 loss: 0.00524311792
Iter: 1872 loss: 0.00524308905
Iter: 1873 loss: 0.0052430341
Iter: 1874 loss: 0.00524303317
Iter: 1875 loss: 0.0052429447
Iter: 1876 loss: 0.00524317846
Iter: 1877 loss: 0.00524291676
Iter: 1878 loss: 0.00524313143
Iter: 1879 loss: 0.00524290232
Iter: 1880 loss: 0.00524289254
Iter: 1881 loss: 0.00524286367
Iter: 1882 loss: 0.00524290651
Iter: 1883 loss: 0.00524283759
Iter: 1884 loss: 0.00524280686
Iter: 1885 loss: 0.00524282
Iter: 1886 loss: 0.00524278497
Iter: 1887 loss: 0.00524274167
Iter: 1888 loss: 0.00524267834
Iter: 1889 loss: 0.00524267927
Iter: 1890 loss: 0.00524255
Iter: 1891 loss: 0.00524257775
Iter: 1892 loss: 0.00524245575
Iter: 1893 loss: 0.00524328742
Iter: 1894 loss: 0.00524241058
Iter: 1895 loss: 0.00524236402
Iter: 1896 loss: 0.00524257077
Iter: 1897 loss: 0.00524235424
Iter: 1898 loss: 0.00524233608
Iter: 1899 loss: 0.00524233934
Iter: 1900 loss: 0.00524232769
Iter: 1901 loss: 0.0052422951
Iter: 1902 loss: 0.00524266344
Iter: 1903 loss: 0.00524229696
Iter: 1904 loss: 0.00524223037
Iter: 1905 loss: 0.00524223037
Iter: 1906 loss: 0.00524217263
Iter: 1907 loss: 0.0052422937
Iter: 1908 loss: 0.00524214376
Iter: 1909 loss: 0.00524213491
Iter: 1910 loss: 0.00524212793
Iter: 1911 loss: 0.00524210138
Iter: 1912 loss: 0.00524204364
Iter: 1913 loss: 0.00524269417
Iter: 1914 loss: 0.00524203852
Iter: 1915 loss: 0.00524200033
Iter: 1916 loss: 0.00524197146
Iter: 1917 loss: 0.00524196
Iter: 1918 loss: 0.00524189975
Iter: 1919 loss: 0.00524191279
Iter: 1920 loss: 0.00524185318
Iter: 1921 loss: 0.00524180382
Iter: 1922 loss: 0.00524199847
Iter: 1923 loss: 0.00524179265
Iter: 1924 loss: 0.00524174888
Iter: 1925 loss: 0.00524183549
Iter: 1926 loss: 0.00524173211
Iter: 1927 loss: 0.00524168462
Iter: 1928 loss: 0.0052422
Iter: 1929 loss: 0.00524167903
Iter: 1930 loss: 0.00524165761
Iter: 1931 loss: 0.00524172047
Iter: 1932 loss: 0.00524165202
Iter: 1933 loss: 0.00524161197
Iter: 1934 loss: 0.00524151884
Iter: 1935 loss: 0.00524278497
Iter: 1936 loss: 0.00524151418
Iter: 1937 loss: 0.00524140149
Iter: 1938 loss: 0.00524165
Iter: 1939 loss: 0.00524135539
Iter: 1940 loss: 0.00524126645
Iter: 1941 loss: 0.00524254609
Iter: 1942 loss: 0.00524126738
Iter: 1943 loss: 0.00524120405
Iter: 1944 loss: 0.00524196355
Iter: 1945 loss: 0.0052411966
Iter: 1946 loss: 0.00524127
Iter: 1947 loss: 0.00524118915
Iter: 1948 loss: 0.00524118356
Iter: 1949 loss: 0.00524117239
Iter: 1950 loss: 0.00524115562
Iter: 1951 loss: 0.00524115656
Iter: 1952 loss: 0.00524113
Iter: 1953 loss: 0.00524114911
Iter: 1954 loss: 0.0052411193
Iter: 1955 loss: 0.00524110626
Iter: 1956 loss: 0.00524106948
Iter: 1957 loss: 0.00524130231
Iter: 1958 loss: 0.00524106715
Iter: 1959 loss: 0.005241042
Iter: 1960 loss: 0.00524100708
Iter: 1961 loss: 0.00524100056
Iter: 1962 loss: 0.00524092512
Iter: 1963 loss: 0.00524111092
Iter: 1964 loss: 0.00524089
Iter: 1965 loss: 0.00524085341
Iter: 1966 loss: 0.00524085294
Iter: 1967 loss: 0.00524081895
Iter: 1968 loss: 0.00524080824
Iter: 1969 loss: 0.00524080312
Iter: 1970 loss: 0.00524079055
Iter: 1971 loss: 0.00524103176
Iter: 1972 loss: 0.00524079241
Iter: 1973 loss: 0.00524078123
Iter: 1974 loss: 0.00524078123
Iter: 1975 loss: 0.00524077
Iter: 1976 loss: 0.00524074957
Iter: 1977 loss: 0.00524072675
Iter: 1978 loss: 0.00524072442
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8
+ date
Tue Oct 27 20:53:06 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac180b08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac180b0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac18103d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac180421e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17f95510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17fa6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17f0f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17f3d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17ece6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17eec1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17ece8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17e596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17e59d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17e59620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17e0b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17e0bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17dcf840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17d9f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17dbd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17d9fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17d777b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17d77d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17cf29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17c967b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17c971e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17c96400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17c85950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17c2a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17c2a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17c3fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17bf4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17bae0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17bb2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17bb2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17b10f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fac17b10510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.105341896
Iter: 2 loss: 3.28053522
Iter: 3 loss: 3.25360441
Iter: 4 loss: 1.74309981
Iter: 5 loss: 1.73492575
Iter: 6 loss: 1.06787479
Iter: 7 loss: 1.06375325
Iter: 8 loss: 0.703930497
Iter: 9 loss: 0.701021314
Iter: 10 loss: 0.472577512
Iter: 11 loss: 0.469928563
Iter: 12 loss: 0.314564943
Iter: 13 loss: 0.312084556
Iter: 14 loss: 0.205753371
Iter: 15 loss: 0.203349471
Iter: 16 loss: 0.129555479
Iter: 17 loss: 0.127254263
Iter: 18 loss: 0.0786025226
Iter: 19 loss: 0.0767946616
Iter: 20 loss: 0.0738810748
Iter: 21 loss: 0.0624103956
Iter: 22 loss: 145.797699
Iter: 23 loss: 0.0489639975
Iter: 24 loss: 0.0490339212
Iter: 25 loss: 0.03413238
Iter: 26 loss: 765.291138
Iter: 27 loss: 0.0341323391
Iter: 28 loss: 434.476959
Iter: 29 loss: 0.0340517312
Iter: 30 loss: 1.20862818
Iter: 31 loss: 0.0340441838
Iter: 32 loss: 0.631324887
Iter: 33 loss: 0.0306091942
Iter: 34 loss: 0.0304950848
Iter: 35 loss: 0.0259951055
Iter: 36 loss: 0.0337734446
Iter: 37 loss: 0.0257506408
Iter: 38 loss: 0.0249831453
Iter: 39 loss: 0.0234326664
Iter: 40 loss: 0.0216162987
Iter: 41 loss: 0.109745711
Iter: 42 loss: 0.0216143467
Iter: 43 loss: 0.0196573697
Iter: 44 loss: 0.0252104644
Iter: 45 loss: 0.0194504596
Iter: 46 loss: 0.0182064436
Iter: 47 loss: 0.018826738
Iter: 48 loss: 0.0174280219
Iter: 49 loss: 0.0161027946
Iter: 50 loss: 0.0154199461
Iter: 51 loss: 0.0147363935
Iter: 52 loss: 0.0135539044
Iter: 53 loss: 0.0201881584
Iter: 54 loss: 0.013551902
Iter: 55 loss: 0.013120316
Iter: 56 loss: 0.0132770818
Iter: 57 loss: 0.012775219
Iter: 58 loss: 0.0123271421
Iter: 59 loss: 0.0117782224
Iter: 60 loss: 0.0117467735
Iter: 61 loss: 0.0109309135
Iter: 62 loss: 0.0166646764
Iter: 63 loss: 0.0108340532
Iter: 64 loss: 0.0102162436
Iter: 65 loss: 0.0123472288
Iter: 66 loss: 0.0100445021
Iter: 67 loss: 0.00943036
Iter: 68 loss: 0.0116386786
Iter: 69 loss: 0.00926617719
Iter: 70 loss: 0.00880401
Iter: 71 loss: 0.0100732092
Iter: 72 loss: 0.00864760298
Iter: 73 loss: 0.0082925288
Iter: 74 loss: 0.00830677897
Iter: 75 loss: 0.00800768286
Iter: 76 loss: 0.00762445386
Iter: 77 loss: 0.00748576084
Iter: 78 loss: 0.00727879722
Iter: 79 loss: 0.00703310827
Iter: 80 loss: 0.0107303355
Iter: 81 loss: 0.00703308824
Iter: 82 loss: 0.00682932418
Iter: 83 loss: 0.00696174754
Iter: 84 loss: 0.00670054369
Iter: 85 loss: 0.00664073601
Iter: 86 loss: 0.00661466178
Iter: 87 loss: 0.00653908122
Iter: 88 loss: 0.00680075306
Iter: 89 loss: 0.00651925057
Iter: 90 loss: 0.00633581122
Iter: 91 loss: 0.00676455209
Iter: 92 loss: 0.00626977812
Iter: 93 loss: 0.00615393464
Iter: 94 loss: 0.00623417832
Iter: 95 loss: 0.00608092733
Iter: 96 loss: 0.00598774478
Iter: 97 loss: 0.00668672286
Iter: 98 loss: 0.00597871281
Iter: 99 loss: 0.00588505389
Iter: 100 loss: 0.00600422686
Iter: 101 loss: 0.00583605329
Iter: 102 loss: 0.00577113032
Iter: 103 loss: 0.00607854407
Iter: 104 loss: 0.00575770065
Iter: 105 loss: 0.00571875088
Iter: 106 loss: 0.00568722049
Iter: 107 loss: 0.00567546673
Iter: 108 loss: 0.00562482746
Iter: 109 loss: 0.0062763351
Iter: 110 loss: 0.00562435854
Iter: 111 loss: 0.00558568
Iter: 112 loss: 0.00562349241
Iter: 113 loss: 0.00556345331
Iter: 114 loss: 0.00552561041
Iter: 115 loss: 0.00553787313
Iter: 116 loss: 0.00549892755
Iter: 117 loss: 0.00552516244
Iter: 118 loss: 0.00548870116
Iter: 119 loss: 0.00547759235
Iter: 120 loss: 0.00546863303
Iter: 121 loss: 0.00546534685
Iter: 122 loss: 0.00543342205
Iter: 123 loss: 0.00576121267
Iter: 124 loss: 0.00543258246
Iter: 125 loss: 0.00541222282
Iter: 126 loss: 0.00540485326
Iter: 127 loss: 0.00539345481
Iter: 128 loss: 0.00536520034
Iter: 129 loss: 0.00553186936
Iter: 130 loss: 0.0053612981
Iter: 131 loss: 0.00533656031
Iter: 132 loss: 0.00549718458
Iter: 133 loss: 0.00533383712
Iter: 134 loss: 0.00531355757
Iter: 135 loss: 0.00530537218
Iter: 136 loss: 0.00529465871
Iter: 137 loss: 0.00526795629
Iter: 138 loss: 0.00539814727
Iter: 139 loss: 0.00526323495
Iter: 140 loss: 0.00524931401
Iter: 141 loss: 0.00524920458
Iter: 142 loss: 0.00523735117
Iter: 143 loss: 0.00522730174
Iter: 144 loss: 0.00522391405
Iter: 145 loss: 0.00521261618
Iter: 146 loss: 0.00520254392
Iter: 147 loss: 0.00519966474
Iter: 148 loss: 0.005197349
Iter: 149 loss: 0.00519280555
Iter: 150 loss: 0.00518859318
Iter: 151 loss: 0.00518123526
Iter: 152 loss: 0.00518123712
Iter: 153 loss: 0.00516614132
Iter: 154 loss: 0.00517811486
Iter: 155 loss: 0.00515703484
Iter: 156 loss: 0.00514347
Iter: 157 loss: 0.00525841676
Iter: 158 loss: 0.00514258444
Iter: 159 loss: 0.00513297878
Iter: 160 loss: 0.0051825745
Iter: 161 loss: 0.00513140112
Iter: 162 loss: 0.00512229744
Iter: 163 loss: 0.00511782337
Iter: 164 loss: 0.00511345826
Iter: 165 loss: 0.00510229403
Iter: 166 loss: 0.00518960692
Iter: 167 loss: 0.00510141486
Iter: 168 loss: 0.00509296125
Iter: 169 loss: 0.00509155774
Iter: 170 loss: 0.00508573558
Iter: 171 loss: 0.00507673062
Iter: 172 loss: 0.00515652448
Iter: 173 loss: 0.00507632643
Iter: 174 loss: 0.00506768608
Iter: 175 loss: 0.005063
Iter: 176 loss: 0.00505913887
Iter: 177 loss: 0.00506712217
Iter: 178 loss: 0.00505618099
Iter: 179 loss: 0.00505424105
Iter: 180 loss: 0.00506224483
Iter: 181 loss: 0.00505381
Iter: 182 loss: 0.00505145825
Iter: 183 loss: 0.00504547171
Iter: 184 loss: 0.00509456359
Iter: 185 loss: 0.00504447054
Iter: 186 loss: 0.00503722671
Iter: 187 loss: 0.00506891962
Iter: 188 loss: 0.00503573893
Iter: 189 loss: 0.00502778217
Iter: 190 loss: 0.00503967609
Iter: 191 loss: 0.00502404105
Iter: 192 loss: 0.00501737883
Iter: 193 loss: 0.00502564758
Iter: 194 loss: 0.00501386588
Iter: 195 loss: 0.00500586536
Iter: 196 loss: 0.00503153168
Iter: 197 loss: 0.00500360224
Iter: 198 loss: 0.00499866623
Iter: 199 loss: 0.00505507737
Iter: 200 loss: 0.00499857683
Iter: 201 loss: 0.00499334838
Iter: 202 loss: 0.00498638581
Iter: 203 loss: 0.0049859914
Iter: 204 loss: 0.00497889612
Iter: 205 loss: 0.00500385091
Iter: 206 loss: 0.00497704139
Iter: 207 loss: 0.00497127604
Iter: 208 loss: 0.00500574708
Iter: 209 loss: 0.00497052
Iter: 210 loss: 0.00496770721
Iter: 211 loss: 0.0049895281
Iter: 212 loss: 0.00496751908
Iter: 213 loss: 0.00496602431
Iter: 214 loss: 0.0049645137
Iter: 215 loss: 0.00496420823
Iter: 216 loss: 0.00496064499
Iter: 217 loss: 0.00495664775
Iter: 218 loss: 0.00495612621
Iter: 219 loss: 0.00495244842
Iter: 220 loss: 0.00496741803
Iter: 221 loss: 0.00495161582
Iter: 222 loss: 0.00494820718
Iter: 223 loss: 0.00494315801
Iter: 224 loss: 0.00494304113
Iter: 225 loss: 0.00493728882
Iter: 226 loss: 0.00496476423
Iter: 227 loss: 0.00493619032
Iter: 228 loss: 0.0049312273
Iter: 229 loss: 0.00494533917
Iter: 230 loss: 0.00492964778
Iter: 231 loss: 0.00492614135
Iter: 232 loss: 0.00493392348
Iter: 233 loss: 0.00492480211
Iter: 234 loss: 0.00491971243
Iter: 235 loss: 0.00493128831
Iter: 236 loss: 0.00491779856
Iter: 237 loss: 0.00491292309
Iter: 238 loss: 0.00492328824
Iter: 239 loss: 0.00491099898
Iter: 240 loss: 0.00490740454
Iter: 241 loss: 0.00490864
Iter: 242 loss: 0.00490485597
Iter: 243 loss: 0.00490821432
Iter: 244 loss: 0.00490334211
Iter: 245 loss: 0.0049024988
Iter: 246 loss: 0.00490098586
Iter: 247 loss: 0.00493971538
Iter: 248 loss: 0.00490099
Iter: 249 loss: 0.00489832601
Iter: 250 loss: 0.00490058307
Iter: 251 loss: 0.00489677303
Iter: 252 loss: 0.00489466731
Iter: 253 loss: 0.00489090895
Iter: 254 loss: 0.00498799793
Iter: 255 loss: 0.00489091175
Iter: 256 loss: 0.00488670124
Iter: 257 loss: 0.0048973
Iter: 258 loss: 0.00488524605
Iter: 259 loss: 0.00488198968
Iter: 260 loss: 0.00489090197
Iter: 261 loss: 0.0048809154
Iter: 262 loss: 0.00487792026
Iter: 263 loss: 0.00488251541
Iter: 264 loss: 0.00487650745
Iter: 265 loss: 0.0048741335
Iter: 266 loss: 0.0048716329
Iter: 267 loss: 0.00487120356
Iter: 268 loss: 0.00486812368
Iter: 269 loss: 0.00489044283
Iter: 270 loss: 0.00486784894
Iter: 271 loss: 0.00486602541
Iter: 272 loss: 0.00486560445
Iter: 273 loss: 0.00486444077
Iter: 274 loss: 0.00486244541
Iter: 275 loss: 0.00486172177
Iter: 276 loss: 0.00486061443
Iter: 277 loss: 0.00485924631
Iter: 278 loss: 0.00486676255
Iter: 279 loss: 0.00485905632
Iter: 280 loss: 0.00485782791
Iter: 281 loss: 0.00486782752
Iter: 282 loss: 0.00485774595
Iter: 283 loss: 0.0048568882
Iter: 284 loss: 0.00485610962
Iter: 285 loss: 0.00485589914
Iter: 286 loss: 0.00485456735
Iter: 287 loss: 0.00485306652
Iter: 288 loss: 0.00485286536
Iter: 289 loss: 0.00485130399
Iter: 290 loss: 0.00485524861
Iter: 291 loss: 0.00485076709
Iter: 292 loss: 0.00484884623
Iter: 293 loss: 0.00485015614
Iter: 294 loss: 0.00484763924
Iter: 295 loss: 0.00484554283
Iter: 296 loss: 0.00485639228
Iter: 297 loss: 0.00484520383
Iter: 298 loss: 0.00484350882
Iter: 299 loss: 0.00484893285
Iter: 300 loss: 0.00484302593
Iter: 301 loss: 0.00484179473
Iter: 302 loss: 0.00485775061
Iter: 303 loss: 0.00484178774
Iter: 304 loss: 0.00484085176
Iter: 305 loss: 0.00483924802
Iter: 306 loss: 0.00483924616
Iter: 307 loss: 0.00483814627
Iter: 308 loss: 0.00483812951
Iter: 309 loss: 0.00483768247
Iter: 310 loss: 0.0048366636
Iter: 311 loss: 0.00484999036
Iter: 312 loss: 0.00483659655
Iter: 313 loss: 0.00483655278
Iter: 314 loss: 0.00483599212
Iter: 315 loss: 0.00483526615
Iter: 316 loss: 0.00483605638
Iter: 317 loss: 0.00483486429
Iter: 318 loss: 0.00483416487
Iter: 319 loss: 0.0048324028
Iter: 320 loss: 0.00484848116
Iter: 321 loss: 0.00483214203
Iter: 322 loss: 0.00482969638
Iter: 323 loss: 0.00485000201
Iter: 324 loss: 0.00482954644
Iter: 325 loss: 0.00482796226
Iter: 326 loss: 0.00483527221
Iter: 327 loss: 0.00482766842
Iter: 328 loss: 0.0048261676
Iter: 329 loss: 0.00482760184
Iter: 330 loss: 0.00482530612
Iter: 331 loss: 0.00482336339
Iter: 332 loss: 0.00482571591
Iter: 333 loss: 0.00482233893
Iter: 334 loss: 0.00482107047
Iter: 335 loss: 0.00482103741
Iter: 336 loss: 0.00481998734
Iter: 337 loss: 0.00482211169
Iter: 338 loss: 0.00481956359
Iter: 339 loss: 0.00481886696
Iter: 340 loss: 0.00481885672
Iter: 341 loss: 0.00481829513
Iter: 342 loss: 0.00481697451
Iter: 343 loss: 0.00483277859
Iter: 344 loss: 0.00481685903
Iter: 345 loss: 0.00481519103
Iter: 346 loss: 0.00481489114
Iter: 347 loss: 0.00481375307
Iter: 348 loss: 0.00481738
Iter: 349 loss: 0.00481279194
Iter: 350 loss: 0.00481253723
Iter: 351 loss: 0.00481175
Iter: 352 loss: 0.0048132576
Iter: 353 loss: 0.00481124
Iter: 354 loss: 0.00481013115
Iter: 355 loss: 0.00481055025
Iter: 356 loss: 0.00480936
Iter: 357 loss: 0.00480803568
Iter: 358 loss: 0.00481166411
Iter: 359 loss: 0.00480759842
Iter: 360 loss: 0.00480661
Iter: 361 loss: 0.00480877189
Iter: 362 loss: 0.00480623
Iter: 363 loss: 0.00480533391
Iter: 364 loss: 0.00480626244
Iter: 365 loss: 0.00480483472
Iter: 366 loss: 0.00480386894
Iter: 367 loss: 0.00480421912
Iter: 368 loss: 0.00480319234
Iter: 369 loss: 0.00480239931
Iter: 370 loss: 0.00480238255
Iter: 371 loss: 0.00480180886
Iter: 372 loss: 0.00480826385
Iter: 373 loss: 0.00480179675
Iter: 374 loss: 0.00480139302
Iter: 375 loss: 0.00480004633
Iter: 376 loss: 0.0047996291
Iter: 377 loss: 0.00479851197
Iter: 378 loss: 0.00479688682
Iter: 379 loss: 0.004813537
Iter: 380 loss: 0.00479684258
Iter: 381 loss: 0.00479582744
Iter: 382 loss: 0.00479701627
Iter: 383 loss: 0.00479528261
Iter: 384 loss: 0.0047962
Iter: 385 loss: 0.00479479507
Iter: 386 loss: 0.00479448773
Iter: 387 loss: 0.00479380274
Iter: 388 loss: 0.00480355695
Iter: 389 loss: 0.00479376735
Iter: 390 loss: 0.00479331799
Iter: 391 loss: 0.00479369052
Iter: 392 loss: 0.00479305349
Iter: 393 loss: 0.00479271449
Iter: 394 loss: 0.00479197549
Iter: 395 loss: 0.00480276626
Iter: 396 loss: 0.00479193963
Iter: 397 loss: 0.00479109818
Iter: 398 loss: 0.00479146652
Iter: 399 loss: 0.00479052123
Iter: 400 loss: 0.00479003787
Iter: 401 loss: 0.00478990935
Iter: 402 loss: 0.00478960853
Iter: 403 loss: 0.00478869909
Iter: 404 loss: 0.0047942
Iter: 405 loss: 0.00478859
Iter: 406 loss: 0.00478794379
Iter: 407 loss: 0.00478720572
Iter: 408 loss: 0.00478711259
Iter: 409 loss: 0.004786
Iter: 410 loss: 0.00479037408
Iter: 411 loss: 0.00478574447
Iter: 412 loss: 0.00478449
Iter: 413 loss: 0.0047958605
Iter: 414 loss: 0.00478443131
Iter: 415 loss: 0.00478352839
Iter: 416 loss: 0.00478491466
Iter: 417 loss: 0.00478310231
Iter: 418 loss: 0.00478294212
Iter: 419 loss: 0.00478271814
Iter: 420 loss: 0.00478239
Iter: 421 loss: 0.00478417
Iter: 422 loss: 0.00478234142
Iter: 423 loss: 0.0047821207
Iter: 424 loss: 0.0047819335
Iter: 425 loss: 0.00478187297
Iter: 426 loss: 0.00478132255
Iter: 427 loss: 0.00478285365
Iter: 428 loss: 0.00478114607
Iter: 429 loss: 0.0047808364
Iter: 430 loss: 0.00478066318
Iter: 431 loss: 0.00478052627
Iter: 432 loss: 0.00478010252
Iter: 433 loss: 0.00477961404
Iter: 434 loss: 0.0047795549
Iter: 435 loss: 0.00477888063
Iter: 436 loss: 0.0047863638
Iter: 437 loss: 0.00477886479
Iter: 438 loss: 0.00477823708
Iter: 439 loss: 0.00477838051
Iter: 440 loss: 0.00477777608
Iter: 441 loss: 0.00477708
Iter: 442 loss: 0.00477759354
Iter: 443 loss: 0.00477665383
Iter: 444 loss: 0.00477599446
Iter: 445 loss: 0.00478226179
Iter: 446 loss: 0.00477597024
Iter: 447 loss: 0.00477541564
Iter: 448 loss: 0.00477726851
Iter: 449 loss: 0.00477526523
Iter: 450 loss: 0.00477498
Iter: 451 loss: 0.00477497885
Iter: 452 loss: 0.00477475906
Iter: 453 loss: 0.00477699097
Iter: 454 loss: 0.00477475114
Iter: 455 loss: 0.00477460586
Iter: 456 loss: 0.00477445312
Iter: 457 loss: 0.00477443
Iter: 458 loss: 0.00477410061
Iter: 459 loss: 0.00477546826
Iter: 460 loss: 0.00477402937
Iter: 461 loss: 0.00477381144
Iter: 462 loss: 0.00477340538
Iter: 463 loss: 0.00478257239
Iter: 464 loss: 0.00477340398
Iter: 465 loss: 0.00477291411
Iter: 466 loss: 0.00477295788
Iter: 467 loss: 0.00477253227
Iter: 468 loss: 0.00477185752
Iter: 469 loss: 0.00477520144
Iter: 470 loss: 0.00477174111
Iter: 471 loss: 0.00477112457
Iter: 472 loss: 0.00477445964
Iter: 473 loss: 0.00477103516
Iter: 474 loss: 0.00477063749
Iter: 475 loss: 0.00477041025
Iter: 476 loss: 0.00477024168
Iter: 477 loss: 0.00476974249
Iter: 478 loss: 0.00477097835
Iter: 479 loss: 0.00476956274
Iter: 480 loss: 0.00476913806
Iter: 481 loss: 0.00477425288
Iter: 482 loss: 0.00476913247
Iter: 483 loss: 0.00476874597
Iter: 484 loss: 0.00476950128
Iter: 485 loss: 0.00476858485
Iter: 486 loss: 0.00476820488
Iter: 487 loss: 0.0047682072
Iter: 488 loss: 0.00476798322
Iter: 489 loss: 0.00476800371
Iter: 490 loss: 0.00476781093
Iter: 491 loss: 0.00476752734
Iter: 492 loss: 0.00476985285
Iter: 493 loss: 0.00476751
Iter: 494 loss: 0.00476734294
Iter: 495 loss: 0.00476694759
Iter: 496 loss: 0.00477156695
Iter: 497 loss: 0.00476691313
Iter: 498 loss: 0.00476645632
Iter: 499 loss: 0.00476693595
Iter: 500 loss: 0.00476620113
Iter: 501 loss: 0.00476580532
Iter: 502 loss: 0.00476807449
Iter: 503 loss: 0.00476575224
Iter: 504 loss: 0.00476539088
Iter: 505 loss: 0.00476726796
Iter: 506 loss: 0.00476533128
Iter: 507 loss: 0.00476505142
Iter: 508 loss: 0.00476488378
Iter: 509 loss: 0.00476476364
Iter: 510 loss: 0.00476433896
Iter: 511 loss: 0.00476446841
Iter: 512 loss: 0.00476403628
Iter: 513 loss: 0.00476358645
Iter: 514 loss: 0.00476905098
Iter: 515 loss: 0.00476358226
Iter: 516 loss: 0.00476317666
Iter: 517 loss: 0.0047651995
Iter: 518 loss: 0.00476310682
Iter: 519 loss: 0.00476285303
Iter: 520 loss: 0.00476285024
Iter: 521 loss: 0.0047626989
Iter: 522 loss: 0.00476279203
Iter: 523 loss: 0.00476260204
Iter: 524 loss: 0.0047624358
Iter: 525 loss: 0.00476351287
Iter: 526 loss: 0.00476241764
Iter: 527 loss: 0.00476228865
Iter: 528 loss: 0.00476204045
Iter: 529 loss: 0.00476735737
Iter: 530 loss: 0.00476204045
Iter: 531 loss: 0.00476178387
Iter: 532 loss: 0.00476182811
Iter: 533 loss: 0.00476159435
Iter: 534 loss: 0.00476133823
Iter: 535 loss: 0.00476252241
Iter: 536 loss: 0.00476129074
Iter: 537 loss: 0.0047610458
Iter: 538 loss: 0.00476245862
Iter: 539 loss: 0.00476101227
Iter: 540 loss: 0.004760799
Iter: 541 loss: 0.00476081856
Iter: 542 loss: 0.00476063322
Iter: 543 loss: 0.00476040132
Iter: 544 loss: 0.00476055499
Iter: 545 loss: 0.00476025697
Iter: 546 loss: 0.00475993706
Iter: 547 loss: 0.00476075709
Iter: 548 loss: 0.00475982903
Iter: 549 loss: 0.00475970749
Iter: 550 loss: 0.00475965627
Iter: 551 loss: 0.00475957
Iter: 552 loss: 0.00476072356
Iter: 553 loss: 0.00475956872
Iter: 554 loss: 0.0047595026
Iter: 555 loss: 0.00475957105
Iter: 556 loss: 0.00475946814
Iter: 557 loss: 0.00475939736
Iter: 558 loss: 0.0047596246
Iter: 559 loss: 0.00475937687
Iter: 560 loss: 0.00475929677
Iter: 561 loss: 0.00475921389
Iter: 562 loss: 0.00475919666
Iter: 563 loss: 0.00475908909
Iter: 564 loss: 0.00475895964
Iter: 565 loss: 0.00475894473
Iter: 566 loss: 0.00475875475
Iter: 567 loss: 0.00475902157
Iter: 568 loss: 0.00475866208
Iter: 569 loss: 0.00475845067
Iter: 570 loss: 0.00476053823
Iter: 571 loss: 0.00475844461
Iter: 572 loss: 0.00475825556
Iter: 573 loss: 0.0047581736
Iter: 574 loss: 0.0047580786
Iter: 575 loss: 0.00475782109
Iter: 576 loss: 0.00475847349
Iter: 577 loss: 0.00475773495
Iter: 578 loss: 0.00475750118
Iter: 579 loss: 0.00475735916
Iter: 580 loss: 0.00475726277
Iter: 581 loss: 0.00475734426
Iter: 582 loss: 0.00475713657
Iter: 583 loss: 0.00475706905
Iter: 584 loss: 0.00475807209
Iter: 585 loss: 0.00475707
Iter: 586 loss: 0.0047570141
Iter: 587 loss: 0.00475704623
Iter: 588 loss: 0.00475698
Iter: 589 loss: 0.00475691399
Iter: 590 loss: 0.004757002
Iter: 591 loss: 0.00475687906
Iter: 592 loss: 0.00475677755
Iter: 593 loss: 0.00475676777
Iter: 594 loss: 0.00475669419
Iter: 595 loss: 0.00475659221
Iter: 596 loss: 0.00475653028
Iter: 597 loss: 0.0047564907
Iter: 598 loss: 0.00475633238
Iter: 599 loss: 0.00475621643
Iter: 600 loss: 0.00475616334
Iter: 601 loss: 0.00475595146
Iter: 602 loss: 0.00475595053
Iter: 603 loss: 0.00475578615
Iter: 604 loss: 0.00475599431
Iter: 605 loss: 0.00475569721
Iter: 606 loss: 0.0047555333
Iter: 607 loss: 0.0047558127
Iter: 608 loss: 0.00475546
Iter: 609 loss: 0.00475532189
Iter: 610 loss: 0.00475540105
Iter: 611 loss: 0.00475522969
Iter: 612 loss: 0.00475511048
Iter: 613 loss: 0.00475696381
Iter: 614 loss: 0.00475511141
Iter: 615 loss: 0.00475506112
Iter: 616 loss: 0.00475505
Iter: 617 loss: 0.00475501083
Iter: 618 loss: 0.00475503504
Iter: 619 loss: 0.00475498475
Iter: 620 loss: 0.00475493353
Iter: 621 loss: 0.00475498941
Iter: 622 loss: 0.00475490326
Iter: 623 loss: 0.0047548255
Iter: 624 loss: 0.0047548227
Iter: 625 loss: 0.00475476449
Iter: 626 loss: 0.00475466717
Iter: 627 loss: 0.00475458801
Iter: 628 loss: 0.00475456147
Iter: 629 loss: 0.00475443387
Iter: 630 loss: 0.00475449301
Iter: 631 loss: 0.00475435099
Iter: 632 loss: 0.00475418
Iter: 633 loss: 0.00475482829
Iter: 634 loss: 0.00475414
Iter: 635 loss: 0.00475398451
Iter: 636 loss: 0.00475529348
Iter: 637 loss: 0.00475397334
Iter: 638 loss: 0.00475388113
Iter: 639 loss: 0.0047538206
Iter: 640 loss: 0.00475378847
Iter: 641 loss: 0.00475367
Iter: 642 loss: 0.00475431792
Iter: 643 loss: 0.00475365482
Iter: 644 loss: 0.00475356402
Iter: 645 loss: 0.00475347647
Iter: 646 loss: 0.00475345552
Iter: 647 loss: 0.00475352537
Iter: 648 loss: 0.00475338567
Iter: 649 loss: 0.00475334516
Iter: 650 loss: 0.00475337775
Iter: 651 loss: 0.00475332187
Iter: 652 loss: 0.00475327251
Iter: 653 loss: 0.00475337543
Iter: 654 loss: 0.00475325622
Iter: 655 loss: 0.0047532036
Iter: 656 loss: 0.00475323
Iter: 657 loss: 0.00475316448
Iter: 658 loss: 0.00475309137
Iter: 659 loss: 0.00475301361
Iter: 660 loss: 0.004753
Iter: 661 loss: 0.00475290837
Iter: 662 loss: 0.00475306623
Iter: 663 loss: 0.00475286692
Iter: 664 loss: 0.00475276168
Iter: 665 loss: 0.00475289905
Iter: 666 loss: 0.00475270767
Iter: 667 loss: 0.00475260522
Iter: 668 loss: 0.00475414656
Iter: 669 loss: 0.00475260476
Iter: 670 loss: 0.00475255167
Iter: 671 loss: 0.00475252094
Iter: 672 loss: 0.00475249719
Iter: 673 loss: 0.00475241244
Iter: 674 loss: 0.00475250697
Iter: 675 loss: 0.00475236587
Iter: 676 loss: 0.00475226203
Iter: 677 loss: 0.00475234259
Iter: 678 loss: 0.0047521987
Iter: 679 loss: 0.00475237286
Iter: 680 loss: 0.0047521675
Iter: 681 loss: 0.00475214189
Iter: 682 loss: 0.00475213584
Iter: 683 loss: 0.00475211628
Iter: 684 loss: 0.00475207623
Iter: 685 loss: 0.0047521512
Iter: 686 loss: 0.00475206086
Iter: 687 loss: 0.00475201663
Iter: 688 loss: 0.00475214282
Iter: 689 loss: 0.00475200312
Iter: 690 loss: 0.00475196773
Iter: 691 loss: 0.00475194771
Iter: 692 loss: 0.00475193188
Iter: 693 loss: 0.00475188671
Iter: 694 loss: 0.00475183409
Iter: 695 loss: 0.00475183036
Iter: 696 loss: 0.00475176889
Iter: 697 loss: 0.00475186436
Iter: 698 loss: 0.00475174282
Iter: 699 loss: 0.00475166086
Iter: 700 loss: 0.00475195143
Iter: 701 loss: 0.00475164037
Iter: 702 loss: 0.00475156866
Iter: 703 loss: 0.00475193467
Iter: 704 loss: 0.00475155469
Iter: 705 loss: 0.00475150906
Iter: 706 loss: 0.00475144479
Iter: 707 loss: 0.00475144479
Iter: 708 loss: 0.00475136749
Iter: 709 loss: 0.00475150719
Iter: 710 loss: 0.00475133583
Iter: 711 loss: 0.00475128554
Iter: 712 loss: 0.00475151651
Iter: 713 loss: 0.00475127669
Iter: 714 loss: 0.00475122221
Iter: 715 loss: 0.00475185039
Iter: 716 loss: 0.00475122035
Iter: 717 loss: 0.0047512
Iter: 718 loss: 0.00475120824
Iter: 719 loss: 0.00475118402
Iter: 720 loss: 0.00475116447
Iter: 721 loss: 0.00475133304
Iter: 722 loss: 0.0047511626
Iter: 723 loss: 0.00475114258
Iter: 724 loss: 0.004751103
Iter: 725 loss: 0.00475179125
Iter: 726 loss: 0.00475110207
Iter: 727 loss: 0.00475104526
Iter: 728 loss: 0.00475117
Iter: 729 loss: 0.00475102849
Iter: 730 loss: 0.00475098798
Iter: 731 loss: 0.00475098
Iter: 732 loss: 0.00475095399
Iter: 733 loss: 0.00475088367
Iter: 734 loss: 0.00475108763
Iter: 735 loss: 0.00475086411
Iter: 736 loss: 0.00475080917
Iter: 737 loss: 0.00475141034
Iter: 738 loss: 0.0047508087
Iter: 739 loss: 0.00475077843
Iter: 740 loss: 0.00475071883
Iter: 741 loss: 0.00475204829
Iter: 742 loss: 0.00475071929
Iter: 743 loss: 0.0047506704
Iter: 744 loss: 0.0047506704
Iter: 745 loss: 0.00475063268
Iter: 746 loss: 0.00475060288
Iter: 747 loss: 0.00475059263
Iter: 748 loss: 0.00475066062
Iter: 749 loss: 0.00475057401
Iter: 750 loss: 0.0047505619
Iter: 751 loss: 0.00475053862
Iter: 752 loss: 0.00475099264
Iter: 753 loss: 0.00475053769
Iter: 754 loss: 0.00475051161
Iter: 755 loss: 0.00475055352
Iter: 756 loss: 0.00475049717
Iter: 757 loss: 0.00475046318
Iter: 758 loss: 0.0047505619
Iter: 759 loss: 0.004750452
Iter: 760 loss: 0.00475043431
Iter: 761 loss: 0.00475044642
Iter: 762 loss: 0.00475041848
Iter: 763 loss: 0.00475039845
Iter: 764 loss: 0.00475041755
Iter: 765 loss: 0.00475038774
Iter: 766 loss: 0.00475036
Iter: 767 loss: 0.00475038
Iter: 768 loss: 0.00475033885
Iter: 769 loss: 0.00475030579
Iter: 770 loss: 0.00475044549
Iter: 771 loss: 0.00475029694
Iter: 772 loss: 0.00475024898
Iter: 773 loss: 0.00475026388
Iter: 774 loss: 0.00475021405
Iter: 775 loss: 0.00475016655
Iter: 776 loss: 0.00475017494
Iter: 777 loss: 0.00475013303
Iter: 778 loss: 0.0047500995
Iter: 779 loss: 0.00475009717
Iter: 780 loss: 0.00475009624
Iter: 781 loss: 0.0047500832
Iter: 782 loss: 0.00475007482
Iter: 783 loss: 0.00475005433
Iter: 784 loss: 0.00475035701
Iter: 785 loss: 0.00475005619
Iter: 786 loss: 0.00475003524
Iter: 787 loss: 0.00475018378
Iter: 788 loss: 0.00475003431
Iter: 789 loss: 0.00475002173
Iter: 790 loss: 0.00475004781
Iter: 791 loss: 0.00475001708
Iter: 792 loss: 0.0047500059
Iter: 793 loss: 0.00474999845
Iter: 794 loss: 0.00474999472
Iter: 795 loss: 0.00474997284
Iter: 796 loss: 0.00474994909
Iter: 797 loss: 0.00474994443
Iter: 798 loss: 0.00474990439
Iter: 799 loss: 0.00475004409
Iter: 800 loss: 0.00474989275
Iter: 801 loss: 0.00474984851
Iter: 802 loss: 0.00474992162
Iter: 803 loss: 0.00474982802
Iter: 804 loss: 0.00474979263
Iter: 805 loss: 0.0047497917
Iter: 806 loss: 0.0047497605
Iter: 807 loss: 0.00474973
Iter: 808 loss: 0.00474972418
Iter: 809 loss: 0.00474968832
Iter: 810 loss: 0.0047498825
Iter: 811 loss: 0.00474968087
Iter: 812 loss: 0.00474964827
Iter: 813 loss: 0.00474963151
Iter: 814 loss: 0.00474961428
Iter: 815 loss: 0.0047497293
Iter: 816 loss: 0.00474960636
Iter: 817 loss: 0.00474959891
Iter: 818 loss: 0.00474958401
Iter: 819 loss: 0.00474961847
Iter: 820 loss: 0.00474957563
Iter: 821 loss: 0.00474955235
Iter: 822 loss: 0.00474968599
Iter: 823 loss: 0.00474954816
Iter: 824 loss: 0.00474952906
Iter: 825 loss: 0.0047495123
Iter: 826 loss: 0.00474950438
Iter: 827 loss: 0.00474947924
Iter: 828 loss: 0.00474975351
Iter: 829 loss: 0.00474947598
Iter: 830 loss: 0.00474945735
Iter: 831 loss: 0.00474942289
Iter: 832 loss: 0.00475009
Iter: 833 loss: 0.00474942243
Iter: 834 loss: 0.0047494024
Iter: 835 loss: 0.00474942662
Iter: 836 loss: 0.00474939
Iter: 837 loss: 0.00474938145
Iter: 838 loss: 0.00474936
Iter: 839 loss: 0.00474965
Iter: 840 loss: 0.00474935863
Iter: 841 loss: 0.00474933349
Iter: 842 loss: 0.00474932045
Iter: 843 loss: 0.00474930741
Iter: 844 loss: 0.00474927947
Iter: 845 loss: 0.00474957563
Iter: 846 loss: 0.00474927854
Iter: 847 loss: 0.00474925153
Iter: 848 loss: 0.00474924315
Iter: 849 loss: 0.00474922918
Iter: 850 loss: 0.00474920403
Iter: 851 loss: 0.00474918494
Iter: 852 loss: 0.00474917516
Iter: 853 loss: 0.00474915234
Iter: 854 loss: 0.00474915374
Iter: 855 loss: 0.00474913605
Iter: 856 loss: 0.00474924129
Iter: 857 loss: 0.00474913698
Iter: 858 loss: 0.00474911416
Iter: 859 loss: 0.00474914396
Iter: 860 loss: 0.00474910438
Iter: 861 loss: 0.00474908948
Iter: 862 loss: 0.00474907318
Iter: 863 loss: 0.00474906713
Iter: 864 loss: 0.00474904
Iter: 865 loss: 0.00474909972
Iter: 866 loss: 0.00474903
Iter: 867 loss: 0.00474901032
Iter: 868 loss: 0.00474901637
Iter: 869 loss: 0.00474899635
Iter: 870 loss: 0.00474903826
Iter: 871 loss: 0.00474898843
Iter: 872 loss: 0.00474898657
Iter: 873 loss: 0.004748974
Iter: 874 loss: 0.00474898051
Iter: 875 loss: 0.00474896468
Iter: 876 loss: 0.00474894512
Iter: 877 loss: 0.00474893115
Iter: 878 loss: 0.00474892
Iter: 879 loss: 0.0047488939
Iter: 880 loss: 0.00474909972
Iter: 881 loss: 0.00474888925
Iter: 882 loss: 0.00474885851
Iter: 883 loss: 0.00474892091
Iter: 884 loss: 0.00474884361
Iter: 885 loss: 0.0047488166
Iter: 886 loss: 0.00474881148
Iter: 887 loss: 0.00474879518
Iter: 888 loss: 0.00474877236
Iter: 889 loss: 0.00474887155
Iter: 890 loss: 0.00474876584
Iter: 891 loss: 0.00474877
Iter: 892 loss: 0.0047487542
Iter: 893 loss: 0.00474874862
Iter: 894 loss: 0.00474873465
Iter: 895 loss: 0.00474889576
Iter: 896 loss: 0.00474873325
Iter: 897 loss: 0.00474872068
Iter: 898 loss: 0.00474871183
Iter: 899 loss: 0.00474870857
Iter: 900 loss: 0.00474869786
Iter: 901 loss: 0.00474870857
Iter: 902 loss: 0.00474869413
Iter: 903 loss: 0.00474868249
Iter: 904 loss: 0.00474867178
Iter: 905 loss: 0.00474867132
Iter: 906 loss: 0.00474864943
Iter: 907 loss: 0.00474864803
Iter: 908 loss: 0.00474863127
Iter: 909 loss: 0.00474861264
Iter: 910 loss: 0.00474861544
Iter: 911 loss: 0.004748601
Iter: 912 loss: 0.0047485847
Iter: 913 loss: 0.0047485726
Iter: 914 loss: 0.00474856421
Iter: 915 loss: 0.00474854233
Iter: 916 loss: 0.0047487542
Iter: 917 loss: 0.00474854046
Iter: 918 loss: 0.00474852044
Iter: 919 loss: 0.00474855397
Iter: 920 loss: 0.00474851346
Iter: 921 loss: 0.00474850135
Iter: 922 loss: 0.00474848133
Iter: 923 loss: 0.00474848179
Iter: 924 loss: 0.0047484613
Iter: 925 loss: 0.00474874
Iter: 926 loss: 0.00474846223
Iter: 927 loss: 0.00474845711
Iter: 928 loss: 0.00474845478
Iter: 929 loss: 0.00474844966
Iter: 930 loss: 0.00474845804
Iter: 931 loss: 0.00474844594
Iter: 932 loss: 0.00474844268
Iter: 933 loss: 0.00474843755
Iter: 934 loss: 0.00474843755
Iter: 935 loss: 0.00474842824
Iter: 936 loss: 0.00474844035
Iter: 937 loss: 0.00474842498
Iter: 938 loss: 0.00474841287
Iter: 939 loss: 0.00474843429
Iter: 940 loss: 0.00474840682
Iter: 941 loss: 0.00474840077
Iter: 942 loss: 0.00474839751
Iter: 943 loss: 0.00474839425
Iter: 944 loss: 0.00474837888
Iter: 945 loss: 0.00474839937
Iter: 946 loss: 0.0047483705
Iter: 947 loss: 0.00474835746
Iter: 948 loss: 0.00474843336
Iter: 949 loss: 0.00474835606
Iter: 950 loss: 0.00474834628
Iter: 951 loss: 0.00474837236
Iter: 952 loss: 0.00474833883
Iter: 953 loss: 0.00474832673
Iter: 954 loss: 0.00474831602
Iter: 955 loss: 0.00474831229
Iter: 956 loss: 0.00474828947
Iter: 957 loss: 0.00474837329
Iter: 958 loss: 0.00474828575
Iter: 959 loss: 0.00474826945
Iter: 960 loss: 0.00474827178
Iter: 961 loss: 0.00474825874
Iter: 962 loss: 0.00474833883
Iter: 963 loss: 0.00474825501
Iter: 964 loss: 0.00474824756
Iter: 965 loss: 0.00474823825
Iter: 966 loss: 0.00474823825
Iter: 967 loss: 0.00474822242
Iter: 968 loss: 0.00474822102
Iter: 969 loss: 0.00474820845
Iter: 970 loss: 0.00474818749
Iter: 971 loss: 0.0047483067
Iter: 972 loss: 0.00474818237
Iter: 973 loss: 0.00474816933
Iter: 974 loss: 0.00474815862
Iter: 975 loss: 0.00474815257
Iter: 976 loss: 0.00474813301
Iter: 977 loss: 0.00474827643
Iter: 978 loss: 0.00474813
Iter: 979 loss: 0.00474811718
Iter: 980 loss: 0.00474815024
Iter: 981 loss: 0.00474811
Iter: 982 loss: 0.00474809343
Iter: 983 loss: 0.00474814605
Iter: 984 loss: 0.00474808831
Iter: 985 loss: 0.00474807434
Iter: 986 loss: 0.0047480762
Iter: 987 loss: 0.00474806083
Iter: 988 loss: 0.00474804314
Iter: 989 loss: 0.00474808
Iter: 990 loss: 0.00474803615
Iter: 991 loss: 0.00474802824
Iter: 992 loss: 0.00474802637
Iter: 993 loss: 0.0047480152
Iter: 994 loss: 0.00474809343
Iter: 995 loss: 0.0047480166
Iter: 996 loss: 0.00474801
Iter: 997 loss: 0.0047479989
Iter: 998 loss: 0.00474815257
Iter: 999 loss: 0.00474799704
Iter: 1000 loss: 0.00474798493
Iter: 1001 loss: 0.00474804733
Iter: 1002 loss: 0.00474798214
Iter: 1003 loss: 0.00474797
Iter: 1004 loss: 0.00474802125
Iter: 1005 loss: 0.00474796817
Iter: 1006 loss: 0.00474795746
Iter: 1007 loss: 0.00474794907
Iter: 1008 loss: 0.00474794675
Iter: 1009 loss: 0.00474793557
Iter: 1010 loss: 0.00474802405
Iter: 1011 loss: 0.00474793138
Iter: 1012 loss: 0.00474791694
Iter: 1013 loss: 0.00474795
Iter: 1014 loss: 0.00474791415
Iter: 1015 loss: 0.00474790344
Iter: 1016 loss: 0.00474794488
Iter: 1017 loss: 0.00474790251
Iter: 1018 loss: 0.0047478904
Iter: 1019 loss: 0.00474788155
Iter: 1020 loss: 0.00474787969
Iter: 1021 loss: 0.00474786339
Iter: 1022 loss: 0.00474789366
Iter: 1023 loss: 0.00474785641
Iter: 1024 loss: 0.00474784616
Iter: 1025 loss: 0.00474801334
Iter: 1026 loss: 0.0047478443
Iter: 1027 loss: 0.00474783778
Iter: 1028 loss: 0.00474797282
Iter: 1029 loss: 0.00474783592
Iter: 1030 loss: 0.00474783126
Iter: 1031 loss: 0.00474782195
Iter: 1032 loss: 0.00474795327
Iter: 1033 loss: 0.00474781962
Iter: 1034 loss: 0.00474781077
Iter: 1035 loss: 0.004747862
Iter: 1036 loss: 0.00474781077
Iter: 1037 loss: 0.00474780519
Iter: 1038 loss: 0.0047478145
Iter: 1039 loss: 0.00474780193
Iter: 1040 loss: 0.00474779494
Iter: 1041 loss: 0.00474778656
Iter: 1042 loss: 0.0047477847
Iter: 1043 loss: 0.00474777166
Iter: 1044 loss: 0.00474782521
Iter: 1045 loss: 0.00474776933
Iter: 1046 loss: 0.00474775583
Iter: 1047 loss: 0.00474782335
Iter: 1048 loss: 0.00474775443
Iter: 1049 loss: 0.00474774512
Iter: 1050 loss: 0.00474776141
Iter: 1051 loss: 0.00474774092
Iter: 1052 loss: 0.00474773161
Iter: 1053 loss: 0.00474774791
Iter: 1054 loss: 0.00474772509
Iter: 1055 loss: 0.00474771485
Iter: 1056 loss: 0.0047477
Iter: 1057 loss: 0.0047477
Iter: 1058 loss: 0.00474768551
Iter: 1059 loss: 0.00474768598
Iter: 1060 loss: 0.00474767806
Iter: 1061 loss: 0.00474767806
Iter: 1062 loss: 0.00474767201
Iter: 1063 loss: 0.00474766269
Iter: 1064 loss: 0.00474777166
Iter: 1065 loss: 0.00474766362
Iter: 1066 loss: 0.00474765431
Iter: 1067 loss: 0.00474777
Iter: 1068 loss: 0.00474765385
Iter: 1069 loss: 0.00474764872
Iter: 1070 loss: 0.00474764965
Iter: 1071 loss: 0.0047476436
Iter: 1072 loss: 0.00474763662
Iter: 1073 loss: 0.00474762451
Iter: 1074 loss: 0.00474762451
Iter: 1075 loss: 0.00474761054
Iter: 1076 loss: 0.00474763894
Iter: 1077 loss: 0.00474760355
Iter: 1078 loss: 0.00474758632
Iter: 1079 loss: 0.00474770088
Iter: 1080 loss: 0.004747584
Iter: 1081 loss: 0.00474757049
Iter: 1082 loss: 0.00474758493
Iter: 1083 loss: 0.00474756584
Iter: 1084 loss: 0.00474754395
Iter: 1085 loss: 0.00474758772
Iter: 1086 loss: 0.00474753696
Iter: 1087 loss: 0.00474751834
Iter: 1088 loss: 0.00474753
Iter: 1089 loss: 0.00474750344
Iter: 1090 loss: 0.00474748202
Iter: 1091 loss: 0.00474753417
Iter: 1092 loss: 0.00474747596
Iter: 1093 loss: 0.00474749
Iter: 1094 loss: 0.00474747084
Iter: 1095 loss: 0.00474746712
Iter: 1096 loss: 0.00474745454
Iter: 1097 loss: 0.00474750623
Iter: 1098 loss: 0.00474745035
Iter: 1099 loss: 0.00474743266
Iter: 1100 loss: 0.00474760309
Iter: 1101 loss: 0.00474743266
Iter: 1102 loss: 0.00474742055
Iter: 1103 loss: 0.00474747829
Iter: 1104 loss: 0.00474741869
Iter: 1105 loss: 0.00474741
Iter: 1106 loss: 0.00474739354
Iter: 1107 loss: 0.0047477209
Iter: 1108 loss: 0.00474739447
Iter: 1109 loss: 0.00474737864
Iter: 1110 loss: 0.00474740658
Iter: 1111 loss: 0.00474737119
Iter: 1112 loss: 0.00474735629
Iter: 1113 loss: 0.0047474415
Iter: 1114 loss: 0.00474735722
Iter: 1115 loss: 0.0047473358
Iter: 1116 loss: 0.00474732602
Iter: 1117 loss: 0.00474731717
Iter: 1118 loss: 0.00474730041
Iter: 1119 loss: 0.00474754348
Iter: 1120 loss: 0.00474730041
Iter: 1121 loss: 0.00474728411
Iter: 1122 loss: 0.00474727899
Iter: 1123 loss: 0.00474726781
Iter: 1124 loss: 0.00474725198
Iter: 1125 loss: 0.0047473209
Iter: 1126 loss: 0.00474725
Iter: 1127 loss: 0.00474726
Iter: 1128 loss: 0.0047472436
Iter: 1129 loss: 0.0047472422
Iter: 1130 loss: 0.00474723056
Iter: 1131 loss: 0.00474726735
Iter: 1132 loss: 0.00474722357
Iter: 1133 loss: 0.0047472138
Iter: 1134 loss: 0.00474726968
Iter: 1135 loss: 0.00474721
Iter: 1136 loss: 0.00474719703
Iter: 1137 loss: 0.00474726595
Iter: 1138 loss: 0.00474719703
Iter: 1139 loss: 0.00474718818
Iter: 1140 loss: 0.00474717747
Iter: 1141 loss: 0.00474717421
Iter: 1142 loss: 0.00474715699
Iter: 1143 loss: 0.00474718353
Iter: 1144 loss: 0.00474714534
Iter: 1145 loss: 0.00474712811
Iter: 1146 loss: 0.0047473032
Iter: 1147 loss: 0.00474712625
Iter: 1148 loss: 0.00474710949
Iter: 1149 loss: 0.00474713324
Iter: 1150 loss: 0.0047471039
Iter: 1151 loss: 0.00474708574
Iter: 1152 loss: 0.00474710437
Iter: 1153 loss: 0.00474707596
Iter: 1154 loss: 0.0047470564
Iter: 1155 loss: 0.00474715419
Iter: 1156 loss: 0.0047470564
Iter: 1157 loss: 0.00474704197
Iter: 1158 loss: 0.00474702893
Iter: 1159 loss: 0.00474702474
Iter: 1160 loss: 0.00474706059
Iter: 1161 loss: 0.00474702241
Iter: 1162 loss: 0.00474701636
Iter: 1163 loss: 0.00474700518
Iter: 1164 loss: 0.00474715699
Iter: 1165 loss: 0.00474700285
Iter: 1166 loss: 0.004746994
Iter: 1167 loss: 0.00474699074
Iter: 1168 loss: 0.00474698655
Iter: 1169 loss: 0.00474697212
Iter: 1170 loss: 0.0047470564
Iter: 1171 loss: 0.00474696793
Iter: 1172 loss: 0.00474695256
Iter: 1173 loss: 0.00474693347
Iter: 1174 loss: 0.004746933
Iter: 1175 loss: 0.00474690599
Iter: 1176 loss: 0.00474694138
Iter: 1177 loss: 0.0047468883
Iter: 1178 loss: 0.00474686362
Iter: 1179 loss: 0.00474708108
Iter: 1180 loss: 0.00474686269
Iter: 1181 loss: 0.00474683754
Iter: 1182 loss: 0.00474691205
Iter: 1183 loss: 0.00474683475
Iter: 1184 loss: 0.00474681798
Iter: 1185 loss: 0.00474684499
Iter: 1186 loss: 0.00474681146
Iter: 1187 loss: 0.00474679703
Iter: 1188 loss: 0.00474688597
Iter: 1189 loss: 0.0047467947
Iter: 1190 loss: 0.00474678166
Iter: 1191 loss: 0.00474678259
Iter: 1192 loss: 0.00474677375
Iter: 1193 loss: 0.00474676955
Iter: 1194 loss: 0.00474676583
Iter: 1195 loss: 0.00474675605
Iter: 1196 loss: 0.00474675419
Iter: 1197 loss: 0.00474674907
Iter: 1198 loss: 0.00474674348
Iter: 1199 loss: 0.00474673044
Iter: 1200 loss: 0.00474698888
Iter: 1201 loss: 0.00474672858
Iter: 1202 loss: 0.00474671368
Iter: 1203 loss: 0.00474690087
Iter: 1204 loss: 0.00474671461
Iter: 1205 loss: 0.00474670203
Iter: 1206 loss: 0.00474669086
Iter: 1207 loss: 0.00474668713
Iter: 1208 loss: 0.00474666525
Iter: 1209 loss: 0.0047466578
Iter: 1210 loss: 0.00474664755
Iter: 1211 loss: 0.0047466252
Iter: 1212 loss: 0.00474677142
Iter: 1213 loss: 0.00474662241
Iter: 1214 loss: 0.00474660564
Iter: 1215 loss: 0.00474671274
Iter: 1216 loss: 0.00474660471
Iter: 1217 loss: 0.00474658748
Iter: 1218 loss: 0.00474658282
Iter: 1219 loss: 0.00474657351
Iter: 1220 loss: 0.00474655721
Iter: 1221 loss: 0.00474666944
Iter: 1222 loss: 0.00474655954
Iter: 1223 loss: 0.00474654
Iter: 1224 loss: 0.0047465181
Iter: 1225 loss: 0.00474651903
Iter: 1226 loss: 0.00474649156
Iter: 1227 loss: 0.00474661076
Iter: 1228 loss: 0.00474648923
Iter: 1229 loss: 0.00474647619
Iter: 1230 loss: 0.00474647293
Iter: 1231 loss: 0.00474646874
Iter: 1232 loss: 0.00474645151
Iter: 1233 loss: 0.00474647293
Iter: 1234 loss: 0.00474644033
Iter: 1235 loss: 0.00474642729
Iter: 1236 loss: 0.0047464259
Iter: 1237 loss: 0.00474641565
Iter: 1238 loss: 0.00474642497
Iter: 1239 loss: 0.00474640913
Iter: 1240 loss: 0.00474639796
Iter: 1241 loss: 0.00474641286
Iter: 1242 loss: 0.00474639423
Iter: 1243 loss: 0.00474638259
Iter: 1244 loss: 0.00474637
Iter: 1245 loss: 0.00474636815
Iter: 1246 loss: 0.00474635186
Iter: 1247 loss: 0.00474640913
Iter: 1248 loss: 0.00474634767
Iter: 1249 loss: 0.00474633
Iter: 1250 loss: 0.00474636722
Iter: 1251 loss: 0.00474632345
Iter: 1252 loss: 0.00474630902
Iter: 1253 loss: 0.00474632205
Iter: 1254 loss: 0.00474630436
Iter: 1255 loss: 0.00474629411
Iter: 1256 loss: 0.00474634208
Iter: 1257 loss: 0.00474629272
Iter: 1258 loss: 0.00474629
Iter: 1259 loss: 0.00474629924
Iter: 1260 loss: 0.00474628527
Iter: 1261 loss: 0.00474628434
Iter: 1262 loss: 0.00474628108
Iter: 1263 loss: 0.00474627968
Iter: 1264 loss: 0.00474626943
Iter: 1265 loss: 0.0047463649
Iter: 1266 loss: 0.0047462685
Iter: 1267 loss: 0.00474626198
Iter: 1268 loss: 0.00474625733
Iter: 1269 loss: 0.0047462536
Iter: 1270 loss: 0.0047462387
Iter: 1271 loss: 0.00474629458
Iter: 1272 loss: 0.00474623032
Iter: 1273 loss: 0.00474622287
Iter: 1274 loss: 0.00474624103
Iter: 1275 loss: 0.00474621542
Iter: 1276 loss: 0.00474620331
Iter: 1277 loss: 0.00474618701
Iter: 1278 loss: 0.00474618655
Iter: 1279 loss: 0.00474617071
Iter: 1280 loss: 0.00474631507
Iter: 1281 loss: 0.00474616606
Iter: 1282 loss: 0.00474615768
Iter: 1283 loss: 0.00474631134
Iter: 1284 loss: 0.00474615721
Iter: 1285 loss: 0.0047461479
Iter: 1286 loss: 0.00474613626
Iter: 1287 loss: 0.00474613626
Iter: 1288 loss: 0.00474612694
Iter: 1289 loss: 0.00474619633
Iter: 1290 loss: 0.00474612601
Iter: 1291 loss: 0.00474611949
Iter: 1292 loss: 0.00474611949
Iter: 1293 loss: 0.00474611484
Iter: 1294 loss: 0.00474613439
Iter: 1295 loss: 0.00474611484
Iter: 1296 loss: 0.00474610878
Iter: 1297 loss: 0.0047461
Iter: 1298 loss: 0.004746099
Iter: 1299 loss: 0.00474609202
Iter: 1300 loss: 0.00474609295
Iter: 1301 loss: 0.00474608503
Iter: 1302 loss: 0.00474607805
Iter: 1303 loss: 0.00474618422
Iter: 1304 loss: 0.00474607665
Iter: 1305 loss: 0.0047460706
Iter: 1306 loss: 0.00474606548
Iter: 1307 loss: 0.00474606315
Iter: 1308 loss: 0.0047460529
Iter: 1309 loss: 0.00474607479
Iter: 1310 loss: 0.00474605
Iter: 1311 loss: 0.00474603754
Iter: 1312 loss: 0.00474603288
Iter: 1313 loss: 0.00474603
Iter: 1314 loss: 0.00474602
Iter: 1315 loss: 0.00474602
Iter: 1316 loss: 0.00474601
Iter: 1317 loss: 0.00474601053
Iter: 1318 loss: 0.00474600121
Iter: 1319 loss: 0.00474599609
Iter: 1320 loss: 0.00474601611
Iter: 1321 loss: 0.00474599
Iter: 1322 loss: 0.00474598305
Iter: 1323 loss: 0.00474610273
Iter: 1324 loss: 0.00474598166
Iter: 1325 loss: 0.00474597607
Iter: 1326 loss: 0.00474603707
Iter: 1327 loss: 0.00474597747
Iter: 1328 loss: 0.00474597048
Iter: 1329 loss: 0.00474597234
Iter: 1330 loss: 0.00474596582
Iter: 1331 loss: 0.00474596117
Iter: 1332 loss: 0.00474595465
Iter: 1333 loss: 0.00474595418
Iter: 1334 loss: 0.00474594766
Iter: 1335 loss: 0.00474599516
Iter: 1336 loss: 0.00474594627
Iter: 1337 loss: 0.00474594161
Iter: 1338 loss: 0.00474593416
Iter: 1339 loss: 0.00474593323
Iter: 1340 loss: 0.00474592205
Iter: 1341 loss: 0.00474594673
Iter: 1342 loss: 0.00474591879
Iter: 1343 loss: 0.00474590715
Iter: 1344 loss: 0.00474592531
Iter: 1345 loss: 0.00474590436
Iter: 1346 loss: 0.00474589318
Iter: 1347 loss: 0.00474589551
Iter: 1348 loss: 0.00474588573
Iter: 1349 loss: 0.004745882
Iter: 1350 loss: 0.00474587595
Iter: 1351 loss: 0.00474587223
Iter: 1352 loss: 0.00474586152
Iter: 1353 loss: 0.0047459905
Iter: 1354 loss: 0.00474586152
Iter: 1355 loss: 0.00474585593
Iter: 1356 loss: 0.0047458536
Iter: 1357 loss: 0.00474585127
Iter: 1358 loss: 0.00474585127
Iter: 1359 loss: 0.00474584661
Iter: 1360 loss: 0.00474584801
Iter: 1361 loss: 0.00474584475
Iter: 1362 loss: 0.00474584196
Iter: 1363 loss: 0.00474583684
Iter: 1364 loss: 0.00474583823
Iter: 1365 loss: 0.00474583171
Iter: 1366 loss: 0.00474584755
Iter: 1367 loss: 0.00474582706
Iter: 1368 loss: 0.00474581821
Iter: 1369 loss: 0.00474582613
Iter: 1370 loss: 0.00474581076
Iter: 1371 loss: 0.00474580331
Iter: 1372 loss: 0.0047458238
Iter: 1373 loss: 0.00474580238
Iter: 1374 loss: 0.00474579027
Iter: 1375 loss: 0.0047457912
Iter: 1376 loss: 0.00474578282
Iter: 1377 loss: 0.00474577211
Iter: 1378 loss: 0.00474580377
Iter: 1379 loss: 0.00474576512
Iter: 1380 loss: 0.0047457614
Iter: 1381 loss: 0.00474583171
Iter: 1382 loss: 0.00474575907
Iter: 1383 loss: 0.00474575069
Iter: 1384 loss: 0.00474576
Iter: 1385 loss: 0.00474574696
Iter: 1386 loss: 0.00474574091
Iter: 1387 loss: 0.00474572647
Iter: 1388 loss: 0.00474572601
Iter: 1389 loss: 0.00474571204
Iter: 1390 loss: 0.00474577211
Iter: 1391 loss: 0.00474570878
Iter: 1392 loss: 0.00474574883
Iter: 1393 loss: 0.00474570738
Iter: 1394 loss: 0.00474570412
Iter: 1395 loss: 0.00474570179
Iter: 1396 loss: 0.00474576
Iter: 1397 loss: 0.00474570133
Iter: 1398 loss: 0.00474569527
Iter: 1399 loss: 0.00474568643
Iter: 1400 loss: 0.00474586664
Iter: 1401 loss: 0.00474568643
Iter: 1402 loss: 0.00474568
Iter: 1403 loss: 0.00474568084
Iter: 1404 loss: 0.00474567618
Iter: 1405 loss: 0.00474569388
Iter: 1406 loss: 0.00474567525
Iter: 1407 loss: 0.00474567153
Iter: 1408 loss: 0.00474566687
Iter: 1409 loss: 0.00474576373
Iter: 1410 loss: 0.00474566547
Iter: 1411 loss: 0.00474566
Iter: 1412 loss: 0.00474573
Iter: 1413 loss: 0.00474566175
Iter: 1414 loss: 0.00474565662
Iter: 1415 loss: 0.00474566128
Iter: 1416 loss: 0.0047456529
Iter: 1417 loss: 0.00474564638
Iter: 1418 loss: 0.00474566966
Iter: 1419 loss: 0.00474564824
Iter: 1420 loss: 0.00474564452
Iter: 1421 loss: 0.00474566547
Iter: 1422 loss: 0.00474564405
Iter: 1423 loss: 0.00474563939
Iter: 1424 loss: 0.00474563846
Iter: 1425 loss: 0.00474563707
Iter: 1426 loss: 0.00474563614
Iter: 1427 loss: 0.00474563241
Iter: 1428 loss: 0.00474563055
Iter: 1429 loss: 0.00474562589
Iter: 1430 loss: 0.00474574883
Iter: 1431 loss: 0.00474562589
Iter: 1432 loss: 0.00474562217
Iter: 1433 loss: 0.00474562217
Iter: 1434 loss: 0.00474562123
Iter: 1435 loss: 0.00474561471
Iter: 1436 loss: 0.00474561611
Iter: 1437 loss: 0.00474561052
Iter: 1438 loss: 0.0047456082
Iter: 1439 loss: 0.00474560773
Iter: 1440 loss: 0.00474560633
Iter: 1441 loss: 0.00474560121
Iter: 1442 loss: 0.00474564126
Iter: 1443 loss: 0.00474560168
Iter: 1444 loss: 0.00474559609
Iter: 1445 loss: 0.00474565197
Iter: 1446 loss: 0.00474559795
Iter: 1447 loss: 0.00474559329
Iter: 1448 loss: 0.00474559423
Iter: 1449 loss: 0.00474559236
Iter: 1450 loss: 0.00474558631
Iter: 1451 loss: 0.00474561285
Iter: 1452 loss: 0.00474558864
Iter: 1453 loss: 0.00474558491
Iter: 1454 loss: 0.00474559795
Iter: 1455 loss: 0.00474558212
Iter: 1456 loss: 0.00474558212
Iter: 1457 loss: 0.00474558305
Iter: 1458 loss: 0.00474558
Iter: 1459 loss: 0.00474557886
Iter: 1460 loss: 0.0047456
Iter: 1461 loss: 0.00474557932
Iter: 1462 loss: 0.00474557746
Iter: 1463 loss: 0.00474558305
Iter: 1464 loss: 0.0047455756
Iter: 1465 loss: 0.0047455756
Iter: 1466 loss: 0.00474557281
Iter: 1467 loss: 0.00474557374
Iter: 1468 loss: 0.00474557
Iter: 1469 loss: 0.00474557187
Iter: 1470 loss: 0.00474557
Iter: 1471 loss: 0.00474556908
Iter: 1472 loss: 0.00474556908
Iter: 1473 loss: 0.00474556722
Iter: 1474 loss: 0.00474556396
Iter: 1475 loss: 0.00474558352
Iter: 1476 loss: 0.00474556349
Iter: 1477 loss: 0.0047455621
Iter: 1478 loss: 0.00474557513
Iter: 1479 loss: 0.00474556163
Iter: 1480 loss: 0.00474555837
Iter: 1481 loss: 0.00474556955
Iter: 1482 loss: 0.0047455579
Iter: 1483 loss: 0.00474555418
Iter: 1484 loss: 0.00474556303
Iter: 1485 loss: 0.00474555558
Iter: 1486 loss: 0.00474555604
Iter: 1487 loss: 0.0047455621
Iter: 1488 loss: 0.00474555464
Iter: 1489 loss: 0.00474555045
Iter: 1490 loss: 0.00474556256
Iter: 1491 loss: 0.00474555045
Iter: 1492 loss: 0.00474555092
Iter: 1493 loss: 0.0047455607
Iter: 1494 loss: 0.00474554952
Iter: 1495 loss: 0.00474554859
Iter: 1496 loss: 0.00474555418
Iter: 1497 loss: 0.00474554906
Iter: 1498 loss: 0.00474554719
Iter: 1499 loss: 0.00474554487
Iter: 1500 loss: 0.00474557187
Iter: 1501 loss: 0.00474554719
Iter: 1502 loss: 0.00474554626
Iter: 1503 loss: 0.00474554254
Iter: 1504 loss: 0.00474554067
Iter: 1505 loss: 0.00474554067
Iter: 1506 loss: 0.00474553928
Iter: 1507 loss: 0.00474553509
Iter: 1508 loss: 0.00474553555
Iter: 1509 loss: 0.00474553555
Iter: 1510 loss: 0.00474553369
Iter: 1511 loss: 0.00474553462
Iter: 1512 loss: 0.00474553183
Iter: 1513 loss: 0.00474552717
Iter: 1514 loss: 0.00474554673
Iter: 1515 loss: 0.00474552857
Iter: 1516 loss: 0.00474552531
Iter: 1517 loss: 0.00474554114
Iter: 1518 loss: 0.00474552531
Iter: 1519 loss: 0.00474552438
Iter: 1520 loss: 0.00474552577
Iter: 1521 loss: 0.00474552251
Iter: 1522 loss: 0.00474552112
Iter: 1523 loss: 0.00474555418
Iter: 1524 loss: 0.00474551879
Iter: 1525 loss: 0.00474551925
Iter: 1526 loss: 0.00474551972
Iter: 1527 loss: 0.00474551925
Iter: 1528 loss: 0.00474552065
Iter: 1529 loss: 0.00474551786
Iter: 1530 loss: 0.00474551786
Iter: 1531 loss: 0.00474551786
Iter: 1532 loss: 0.00474553322
Iter: 1533 loss: 0.00474551739
Iter: 1534 loss: 0.00474551227
Iter: 1535 loss: 0.0047455146
Iter: 1536 loss: 0.00474551274
Iter: 1537 loss: 0.0047455118
Iter: 1538 loss: 0.00474552624
Iter: 1539 loss: 0.00474551041
Iter: 1540 loss: 0.00474551134
Iter: 1541 loss: 0.00474551134
Iter: 1542 loss: 0.00474550761
Iter: 1543 loss: 0.00474550761
Iter: 1544 loss: 0.00474550296
Iter: 1545 loss: 0.00474550342
Iter: 1546 loss: 0.00474550296
Iter: 1547 loss: 0.00474552857
Iter: 1548 loss: 0.00474549923
Iter: 1549 loss: 0.0047455
Iter: 1550 loss: 0.00474550528
Iter: 1551 loss: 0.0047454997
Iter: 1552 loss: 0.00474549923
Iter: 1553 loss: 0.00474549644
Iter: 1554 loss: 0.00474549597
Iter: 1555 loss: 0.00474549364
Iter: 1556 loss: 0.00474549178
Iter: 1557 loss: 0.00474549131
Iter: 1558 loss: 0.00474549271
Iter: 1559 loss: 0.00474549
Iter: 1560 loss: 0.00474549225
Iter: 1561 loss: 0.00474549085
Iter: 1562 loss: 0.00474548899
Iter: 1563 loss: 0.00474548619
Iter: 1564 loss: 0.00474553788
Iter: 1565 loss: 0.00474548619
Iter: 1566 loss: 0.00474548293
Iter: 1567 loss: 0.00474548712
Iter: 1568 loss: 0.00474548247
Iter: 1569 loss: 0.00474547874
Iter: 1570 loss: 0.00474548619
Iter: 1571 loss: 0.00474547967
Iter: 1572 loss: 0.00474547688
Iter: 1573 loss: 0.00474548712
Iter: 1574 loss: 0.00474547688
Iter: 1575 loss: 0.00474547548
Iter: 1576 loss: 0.00474547222
Iter: 1577 loss: 0.00474547222
Iter: 1578 loss: 0.0047454685
Iter: 1579 loss: 0.00474549178
Iter: 1580 loss: 0.00474547
Iter: 1581 loss: 0.00474546663
Iter: 1582 loss: 0.00474546757
Iter: 1583 loss: 0.00474546803
Iter: 1584 loss: 0.00474546291
Iter: 1585 loss: 0.00474546384
Iter: 1586 loss: 0.00474545872
Iter: 1587 loss: 0.00474545639
Iter: 1588 loss: 0.00474547362
Iter: 1589 loss: 0.00474545592
Iter: 1590 loss: 0.00474545546
Iter: 1591 loss: 0.0047454536
Iter: 1592 loss: 0.0047454522
Iter: 1593 loss: 0.00474545453
Iter: 1594 loss: 0.0047454508
Iter: 1595 loss: 0.00474544894
Iter: 1596 loss: 0.00474545
Iter: 1597 loss: 0.00474544754
Iter: 1598 loss: 0.00474544475
Iter: 1599 loss: 0.00474544521
Iter: 1600 loss: 0.00474544428
Iter: 1601 loss: 0.00474544335
Iter: 1602 loss: 0.00474544195
Iter: 1603 loss: 0.00474544102
Iter: 1604 loss: 0.00474543683
Iter: 1605 loss: 0.00474545266
Iter: 1606 loss: 0.00474543869
Iter: 1607 loss: 0.00474543404
Iter: 1608 loss: 0.00474543311
Iter: 1609 loss: 0.00474543124
Iter: 1610 loss: 0.00474542845
Iter: 1611 loss: 0.00474544149
Iter: 1612 loss: 0.00474542705
Iter: 1613 loss: 0.00474542147
Iter: 1614 loss: 0.00474543823
Iter: 1615 loss: 0.0047454196
Iter: 1616 loss: 0.00474541495
Iter: 1617 loss: 0.00474544149
Iter: 1618 loss: 0.00474541541
Iter: 1619 loss: 0.00474541169
Iter: 1620 loss: 0.00474541215
Iter: 1621 loss: 0.00474540889
Iter: 1622 loss: 0.00474541122
Iter: 1623 loss: 0.0047454061
Iter: 1624 loss: 0.00474540563
Iter: 1625 loss: 0.00474541262
Iter: 1626 loss: 0.00474540424
Iter: 1627 loss: 0.00474540424
Iter: 1628 loss: 0.00474540936
Iter: 1629 loss: 0.00474540424
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3
+ date
Tue Oct 27 20:59:36 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 3 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7aec081378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7ad00b2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b11968048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7ad0025510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7b11968510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7ad0025950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a4077f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a407b3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a407b3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a407b3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40721a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a406ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a406ceb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a406f17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a4069b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40660598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40663488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40601bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40601c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a405f46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a405f4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a405a4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a4055b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40506730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40505598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a4052a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a404ef488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a404992f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a404b2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a404b2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a403fb7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a404252f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40425ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a404251e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a40425400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7a403b22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0241044052
Iter: 2 loss: 0.67345
Iter: 3 loss: 0.63836956
Iter: 4 loss: 0.400696754
Iter: 5 loss: 0.373029381
Iter: 6 loss: 0.22576195
Iter: 7 loss: 0.201907799
Iter: 8 loss: 0.11239548
Iter: 9 loss: 0.0942406878
Iter: 10 loss: 0.046470724
Iter: 11 loss: 0.0362521745
Iter: 12 loss: 0.0175170451
Iter: 13 loss: 0.0152393682
Iter: 14 loss: 0.0136953397
Iter: 15 loss: 0.0128489034
Iter: 16 loss: 0.0119096963
Iter: 17 loss: 0.0111308536
Iter: 18 loss: 0.0111306617
Iter: 19 loss: 0.0102532897
Iter: 20 loss: 0.00857064407
Iter: 21 loss: 0.0257358141
Iter: 22 loss: 0.00854763575
Iter: 23 loss: 0.0075971405
Iter: 24 loss: 0.00756861363
Iter: 25 loss: 0.00726851635
Iter: 26 loss: 0.00741234049
Iter: 27 loss: 0.00705053
Iter: 28 loss: 0.00687746191
Iter: 29 loss: 0.00703525078
Iter: 30 loss: 0.00678891
Iter: 31 loss: 0.00663989969
Iter: 32 loss: 0.00663230335
Iter: 33 loss: 0.00651829131
Iter: 34 loss: 0.00634834543
Iter: 35 loss: 0.00648558233
Iter: 36 loss: 0.00624500494
Iter: 37 loss: 0.0061332183
Iter: 38 loss: 0.00628872821
Iter: 39 loss: 0.00607644301
Iter: 40 loss: 0.00599082559
Iter: 41 loss: 0.00660432968
Iter: 42 loss: 0.00598424254
Iter: 43 loss: 0.00592518039
Iter: 44 loss: 0.00589967053
Iter: 45 loss: 0.00587002095
Iter: 46 loss: 0.00581063237
Iter: 47 loss: 0.00609689858
Iter: 48 loss: 0.00579904858
Iter: 49 loss: 0.00576366577
Iter: 50 loss: 0.00582080754
Iter: 51 loss: 0.00574723911
Iter: 52 loss: 0.00572062051
Iter: 53 loss: 0.00580470823
Iter: 54 loss: 0.00571354805
Iter: 55 loss: 0.00569763174
Iter: 56 loss: 0.00570263714
Iter: 57 loss: 0.00568636414
Iter: 58 loss: 0.00567367906
Iter: 59 loss: 0.00567303132
Iter: 60 loss: 0.00565902796
Iter: 61 loss: 0.00565899257
Iter: 62 loss: 0.00565485237
Iter: 63 loss: 0.00564644858
Iter: 64 loss: 0.00580150215
Iter: 65 loss: 0.00564631633
Iter: 66 loss: 0.00563586783
Iter: 67 loss: 0.00569135696
Iter: 68 loss: 0.00563420635
Iter: 69 loss: 0.00562636461
Iter: 70 loss: 0.00562442839
Iter: 71 loss: 0.00561944675
Iter: 72 loss: 0.00560838
Iter: 73 loss: 0.00563401263
Iter: 74 loss: 0.00560428714
Iter: 75 loss: 0.00559566263
Iter: 76 loss: 0.00563714514
Iter: 77 loss: 0.00559412874
Iter: 78 loss: 0.00558615383
Iter: 79 loss: 0.00559964264
Iter: 80 loss: 0.00558259105
Iter: 81 loss: 0.00557543617
Iter: 82 loss: 0.00564588513
Iter: 83 loss: 0.00557517
Iter: 84 loss: 0.00557064731
Iter: 85 loss: 0.00558626652
Iter: 86 loss: 0.00556948967
Iter: 87 loss: 0.00556421
Iter: 88 loss: 0.00557703804
Iter: 89 loss: 0.00556228496
Iter: 90 loss: 0.00555912312
Iter: 91 loss: 0.00557033252
Iter: 92 loss: 0.00555832684
Iter: 93 loss: 0.00555592449
Iter: 94 loss: 0.00555585977
Iter: 95 loss: 0.00555425417
Iter: 96 loss: 0.00555237196
Iter: 97 loss: 0.00555216661
Iter: 98 loss: 0.00554995658
Iter: 99 loss: 0.00555169
Iter: 100 loss: 0.00554861967
Iter: 101 loss: 0.00554526318
Iter: 102 loss: 0.00555176521
Iter: 103 loss: 0.00554387737
Iter: 104 loss: 0.00554097863
Iter: 105 loss: 0.0055432776
Iter: 106 loss: 0.00553923752
Iter: 107 loss: 0.00553636
Iter: 108 loss: 0.00555147277
Iter: 109 loss: 0.00553591317
Iter: 110 loss: 0.00553354062
Iter: 111 loss: 0.00553379254
Iter: 112 loss: 0.00553172873
Iter: 113 loss: 0.00552920066
Iter: 114 loss: 0.00554967951
Iter: 115 loss: 0.00552903442
Iter: 116 loss: 0.00552729098
Iter: 117 loss: 0.00552841555
Iter: 118 loss: 0.00552618876
Iter: 119 loss: 0.00552345905
Iter: 120 loss: 0.00555044692
Iter: 121 loss: 0.00552335754
Iter: 122 loss: 0.00552162901
Iter: 123 loss: 0.00553574739
Iter: 124 loss: 0.00552152935
Iter: 125 loss: 0.00552062225
Iter: 126 loss: 0.0055250274
Iter: 127 loss: 0.00552046
Iter: 128 loss: 0.00551959965
Iter: 129 loss: 0.00551880291
Iter: 130 loss: 0.00551859802
Iter: 131 loss: 0.00551711209
Iter: 132 loss: 0.00551745342
Iter: 133 loss: 0.00551602058
Iter: 134 loss: 0.00551428
Iter: 135 loss: 0.00552712288
Iter: 136 loss: 0.00551413745
Iter: 137 loss: 0.00551280938
Iter: 138 loss: 0.00551257795
Iter: 139 loss: 0.00551166851
Iter: 140 loss: 0.0055100834
Iter: 141 loss: 0.00551348599
Iter: 142 loss: 0.00550946081
Iter: 143 loss: 0.00550776627
Iter: 144 loss: 0.00551431533
Iter: 145 loss: 0.00550737511
Iter: 146 loss: 0.00550587522
Iter: 147 loss: 0.00550984265
Iter: 148 loss: 0.00550536858
Iter: 149 loss: 0.00550381467
Iter: 150 loss: 0.00550704449
Iter: 151 loss: 0.00550319673
Iter: 152 loss: 0.00550154317
Iter: 153 loss: 0.00550726242
Iter: 154 loss: 0.005501098
Iter: 155 loss: 0.00550051685
Iter: 156 loss: 0.00550023653
Iter: 157 loss: 0.00549974572
Iter: 158 loss: 0.00550296484
Iter: 159 loss: 0.00549969077
Iter: 160 loss: 0.00549925119
Iter: 161 loss: 0.0054984903
Iter: 162 loss: 0.00549848704
Iter: 163 loss: 0.00549742719
Iter: 164 loss: 0.00549850846
Iter: 165 loss: 0.00549683301
Iter: 166 loss: 0.00549577549
Iter: 167 loss: 0.00550018903
Iter: 168 loss: 0.00549554918
Iter: 169 loss: 0.00549443671
Iter: 170 loss: 0.00549593568
Iter: 171 loss: 0.00549387932
Iter: 172 loss: 0.00549288886
Iter: 173 loss: 0.00549368188
Iter: 174 loss: 0.00549229281
Iter: 175 loss: 0.00549119432
Iter: 176 loss: 0.00549594872
Iter: 177 loss: 0.00549097
Iter: 178 loss: 0.00549003575
Iter: 179 loss: 0.00549435476
Iter: 180 loss: 0.00548985926
Iter: 181 loss: 0.00548907463
Iter: 182 loss: 0.00549206929
Iter: 183 loss: 0.00548889
Iter: 184 loss: 0.00548818568
Iter: 185 loss: 0.00548878219
Iter: 186 loss: 0.00548776612
Iter: 187 loss: 0.00548738
Iter: 188 loss: 0.00548731
Iter: 189 loss: 0.00548700616
Iter: 190 loss: 0.00548939314
Iter: 191 loss: 0.00548698055
Iter: 192 loss: 0.00548671838
Iter: 193 loss: 0.00548620429
Iter: 194 loss: 0.00549629703
Iter: 195 loss: 0.00548620056
Iter: 196 loss: 0.00548556959
Iter: 197 loss: 0.00548694748
Iter: 198 loss: 0.00548532605
Iter: 199 loss: 0.00548469
Iter: 200 loss: 0.00548614562
Iter: 201 loss: 0.00548444968
Iter: 202 loss: 0.00548382523
Iter: 203 loss: 0.0054862937
Iter: 204 loss: 0.0054836832
Iter: 205 loss: 0.00548308156
Iter: 206 loss: 0.00548296794
Iter: 207 loss: 0.00548256654
Iter: 208 loss: 0.00548183918
Iter: 209 loss: 0.00548409205
Iter: 210 loss: 0.00548162963
Iter: 211 loss: 0.00548094232
Iter: 212 loss: 0.00548322359
Iter: 213 loss: 0.00548075698
Iter: 214 loss: 0.00548018655
Iter: 215 loss: 0.00548437657
Iter: 216 loss: 0.00548014138
Iter: 217 loss: 0.00547961844
Iter: 218 loss: 0.00548001425
Iter: 219 loss: 0.0054792976
Iter: 220 loss: 0.00547896791
Iter: 221 loss: 0.00547896139
Iter: 222 loss: 0.00547872065
Iter: 223 loss: 0.0054805153
Iter: 224 loss: 0.00547870062
Iter: 225 loss: 0.00547849108
Iter: 226 loss: 0.00547811342
Iter: 227 loss: 0.00547811482
Iter: 228 loss: 0.00547768548
Iter: 229 loss: 0.005478465
Iter: 230 loss: 0.00547749829
Iter: 231 loss: 0.00547702424
Iter: 232 loss: 0.00547839189
Iter: 233 loss: 0.00547687756
Iter: 234 loss: 0.00547647895
Iter: 235 loss: 0.005478031
Iter: 236 loss: 0.00547638489
Iter: 237 loss: 0.0054759793
Iter: 238 loss: 0.00547613716
Iter: 239 loss: 0.00547570083
Iter: 240 loss: 0.00547525333
Iter: 241 loss: 0.00547623541
Iter: 242 loss: 0.00547508616
Iter: 243 loss: 0.0054746354
Iter: 244 loss: 0.00547575532
Iter: 245 loss: 0.00547447521
Iter: 246 loss: 0.00547405286
Iter: 247 loss: 0.00547666103
Iter: 248 loss: 0.00547400583
Iter: 249 loss: 0.00547361933
Iter: 250 loss: 0.00547462329
Iter: 251 loss: 0.00547348429
Iter: 252 loss: 0.00547324773
Iter: 253 loss: 0.00547669362
Iter: 254 loss: 0.00547324587
Iter: 255 loss: 0.00547307823
Iter: 256 loss: 0.00547466055
Iter: 257 loss: 0.00547307
Iter: 258 loss: 0.00547292829
Iter: 259 loss: 0.00547269313
Iter: 260 loss: 0.00547269452
Iter: 261 loss: 0.0054724291
Iter: 262 loss: 0.00547270942
Iter: 263 loss: 0.00547227962
Iter: 264 loss: 0.00547198625
Iter: 265 loss: 0.00547339395
Iter: 266 loss: 0.0054719327
Iter: 267 loss: 0.00547171
Iter: 268 loss: 0.00547226146
Iter: 269 loss: 0.00547162723
Iter: 270 loss: 0.00547137763
Iter: 271 loss: 0.00547163608
Iter: 272 loss: 0.00547123607
Iter: 273 loss: 0.00547097065
Iter: 274 loss: 0.00547155365
Iter: 275 loss: 0.0054708682
Iter: 276 loss: 0.00547061861
Iter: 277 loss: 0.005470993
Iter: 278 loss: 0.00547049893
Iter: 279 loss: 0.00547026051
Iter: 280 loss: 0.00547219254
Iter: 281 loss: 0.00547024701
Iter: 282 loss: 0.00547002535
Iter: 283 loss: 0.00547048682
Iter: 284 loss: 0.00546993688
Iter: 285 loss: 0.00546979345
Iter: 286 loss: 0.00547197741
Iter: 287 loss: 0.00546979345
Iter: 288 loss: 0.00546969846
Iter: 289 loss: 0.005470776
Iter: 290 loss: 0.00546969892
Iter: 291 loss: 0.00546962116
Iter: 292 loss: 0.00546949171
Iter: 293 loss: 0.00546949031
Iter: 294 loss: 0.00546934176
Iter: 295 loss: 0.00546945166
Iter: 296 loss: 0.00546925142
Iter: 297 loss: 0.00546907773
Iter: 298 loss: 0.00546984328
Iter: 299 loss: 0.00546904281
Iter: 300 loss: 0.00546888914
Iter: 301 loss: 0.00546918809
Iter: 302 loss: 0.00546882488
Iter: 303 loss: 0.00546865957
Iter: 304 loss: 0.00546908379
Iter: 305 loss: 0.00546860136
Iter: 306 loss: 0.00546844862
Iter: 307 loss: 0.00546865538
Iter: 308 loss: 0.00546837272
Iter: 309 loss: 0.00546821952
Iter: 310 loss: 0.00546840718
Iter: 311 loss: 0.00546813756
Iter: 312 loss: 0.00546797598
Iter: 313 loss: 0.00546923559
Iter: 314 loss: 0.00546796201
Iter: 315 loss: 0.00546782697
Iter: 316 loss: 0.00546829449
Iter: 317 loss: 0.00546779204
Iter: 318 loss: 0.00546769798
Iter: 319 loss: 0.00546871591
Iter: 320 loss: 0.00546769798
Iter: 321 loss: 0.00546764303
Iter: 322 loss: 0.00546764489
Iter: 323 loss: 0.00546760298
Iter: 324 loss: 0.00546753407
Iter: 325 loss: 0.005467535
Iter: 326 loss: 0.00546745211
Iter: 327 loss: 0.00546744838
Iter: 328 loss: 0.00546738878
Iter: 329 loss: 0.00546728075
Iter: 330 loss: 0.00546790194
Iter: 331 loss: 0.00546726771
Iter: 332 loss: 0.00546717644
Iter: 333 loss: 0.00546732778
Iter: 334 loss: 0.00546713825
Iter: 335 loss: 0.00546704652
Iter: 336 loss: 0.00546735898
Iter: 337 loss: 0.00546702
Iter: 338 loss: 0.00546694035
Iter: 339 loss: 0.00546704419
Iter: 340 loss: 0.0054669017
Iter: 341 loss: 0.00546681788
Iter: 342 loss: 0.00546691054
Iter: 343 loss: 0.00546677085
Iter: 344 loss: 0.0054666861
Iter: 345 loss: 0.00546724861
Iter: 346 loss: 0.00546667539
Iter: 347 loss: 0.0054666
Iter: 348 loss: 0.00546694174
Iter: 349 loss: 0.00546658272
Iter: 350 loss: 0.00546653615
Iter: 351 loss: 0.0054670251
Iter: 352 loss: 0.00546653382
Iter: 353 loss: 0.00546650402
Iter: 354 loss: 0.00546694733
Iter: 355 loss: 0.00546650449
Iter: 356 loss: 0.00546648353
Iter: 357 loss: 0.00546644209
Iter: 358 loss: 0.00546644116
Iter: 359 loss: 0.00546639459
Iter: 360 loss: 0.00546638574
Iter: 361 loss: 0.00546635408
Iter: 362 loss: 0.00546629
Iter: 363 loss: 0.00546661858
Iter: 364 loss: 0.00546627957
Iter: 365 loss: 0.00546622602
Iter: 366 loss: 0.00546633964
Iter: 367 loss: 0.00546620041
Iter: 368 loss: 0.00546614407
Iter: 369 loss: 0.00546631915
Iter: 370 loss: 0.00546612637
Iter: 371 loss: 0.00546607468
Iter: 372 loss: 0.00546615617
Iter: 373 loss: 0.0054660514
Iter: 374 loss: 0.00546599552
Iter: 375 loss: 0.00546601601
Iter: 376 loss: 0.0054659578
Iter: 377 loss: 0.00546589447
Iter: 378 loss: 0.0054664053
Iter: 379 loss: 0.00546589307
Iter: 380 loss: 0.00546584558
Iter: 381 loss: 0.00546604209
Iter: 382 loss: 0.00546583533
Iter: 383 loss: 0.00546580181
Iter: 384 loss: 0.00546610309
Iter: 385 loss: 0.0054658
Iter: 386 loss: 0.00546578038
Iter: 387 loss: 0.00546578132
Iter: 388 loss: 0.00546576362
Iter: 389 loss: 0.00546573754
Iter: 390 loss: 0.00546573801
Iter: 391 loss: 0.00546570495
Iter: 392 loss: 0.00546569191
Iter: 393 loss: 0.00546567235
Iter: 394 loss: 0.00546562951
Iter: 395 loss: 0.00546593405
Iter: 396 loss: 0.00546562672
Iter: 397 loss: 0.00546559133
Iter: 398 loss: 0.00546564721
Iter: 399 loss: 0.00546557736
Iter: 400 loss: 0.00546553731
Iter: 401 loss: 0.00546566211
Iter: 402 loss: 0.00546552753
Iter: 403 loss: 0.00546549307
Iter: 404 loss: 0.0054655415
Iter: 405 loss: 0.00546547771
Iter: 406 loss: 0.00546544138
Iter: 407 loss: 0.0054654656
Iter: 408 loss: 0.0054654181
Iter: 409 loss: 0.00546537898
Iter: 410 loss: 0.0054656351
Iter: 411 loss: 0.00546537619
Iter: 412 loss: 0.00546534359
Iter: 413 loss: 0.00546549633
Iter: 414 loss: 0.0054653394
Iter: 415 loss: 0.00546531845
Iter: 416 loss: 0.00546548422
Iter: 417 loss: 0.00546531193
Iter: 418 loss: 0.00546530169
Iter: 419 loss: 0.00546530169
Iter: 420 loss: 0.00546529051
Iter: 421 loss: 0.00546527188
Iter: 422 loss: 0.00546527095
Iter: 423 loss: 0.00546524907
Iter: 424 loss: 0.00546524394
Iter: 425 loss: 0.00546523
Iter: 426 loss: 0.0054652025
Iter: 427 loss: 0.00546536222
Iter: 428 loss: 0.00546519924
Iter: 429 loss: 0.00546517223
Iter: 430 loss: 0.00546522252
Iter: 431 loss: 0.00546516571
Iter: 432 loss: 0.00546514057
Iter: 433 loss: 0.00546520157
Iter: 434 loss: 0.00546513
Iter: 435 loss: 0.00546510331
Iter: 436 loss: 0.00546515593
Iter: 437 loss: 0.0054650926
Iter: 438 loss: 0.00546507211
Iter: 439 loss: 0.00546508841
Iter: 440 loss: 0.00546505582
Iter: 441 loss: 0.00546502741
Iter: 442 loss: 0.00546517037
Iter: 443 loss: 0.00546502136
Iter: 444 loss: 0.00546499854
Iter: 445 loss: 0.00546510424
Iter: 446 loss: 0.00546499435
Iter: 447 loss: 0.00546497293
Iter: 448 loss: 0.00546509726
Iter: 449 loss: 0.00546497107
Iter: 450 loss: 0.00546496082
Iter: 451 loss: 0.00546496
Iter: 452 loss: 0.00546495151
Iter: 453 loss: 0.00546493707
Iter: 454 loss: 0.005464938
Iter: 455 loss: 0.00546492077
Iter: 456 loss: 0.00546491146
Iter: 457 loss: 0.00546490401
Iter: 458 loss: 0.00546488119
Iter: 459 loss: 0.00546501111
Iter: 460 loss: 0.00546487793
Iter: 461 loss: 0.00546485838
Iter: 462 loss: 0.0054648933
Iter: 463 loss: 0.00546484906
Iter: 464 loss: 0.00546482624
Iter: 465 loss: 0.00546487607
Iter: 466 loss: 0.00546481786
Iter: 467 loss: 0.00546479691
Iter: 468 loss: 0.00546487328
Iter: 469 loss: 0.00546479039
Iter: 470 loss: 0.00546477176
Iter: 471 loss: 0.00546476617
Iter: 472 loss: 0.00546475453
Iter: 473 loss: 0.00546472892
Iter: 474 loss: 0.00546486769
Iter: 475 loss: 0.0054647252
Iter: 476 loss: 0.00546470331
Iter: 477 loss: 0.00546479505
Iter: 478 loss: 0.00546469819
Iter: 479 loss: 0.00546468096
Iter: 480 loss: 0.00546484813
Iter: 481 loss: 0.0054646791
Iter: 482 loss: 0.00546467351
Iter: 483 loss: 0.00546467304
Iter: 484 loss: 0.00546466559
Iter: 485 loss: 0.00546465488
Iter: 486 loss: 0.00546465535
Iter: 487 loss: 0.00546464045
Iter: 488 loss: 0.00546463672
Iter: 489 loss: 0.00546462834
Iter: 490 loss: 0.00546461204
Iter: 491 loss: 0.00546468701
Iter: 492 loss: 0.00546460599
Iter: 493 loss: 0.00546458922
Iter: 494 loss: 0.00546463486
Iter: 495 loss: 0.0054645855
Iter: 496 loss: 0.00546456967
Iter: 497 loss: 0.00546460552
Iter: 498 loss: 0.00546456268
Iter: 499 loss: 0.00546454731
Iter: 500 loss: 0.0054645855
Iter: 501 loss: 0.00546454079
Iter: 502 loss: 0.00546452496
Iter: 503 loss: 0.00546453893
Iter: 504 loss: 0.00546451611
Iter: 505 loss: 0.00546449888
Iter: 506 loss: 0.00546454592
Iter: 507 loss: 0.00546449237
Iter: 508 loss: 0.00546447746
Iter: 509 loss: 0.00546460319
Iter: 510 loss: 0.00546447467
Iter: 511 loss: 0.00546446396
Iter: 512 loss: 0.00546453428
Iter: 513 loss: 0.0054644607
Iter: 514 loss: 0.00546445698
Iter: 515 loss: 0.00546445511
Iter: 516 loss: 0.00546445139
Iter: 517 loss: 0.00546444487
Iter: 518 loss: 0.00546444301
Iter: 519 loss: 0.00546443369
Iter: 520 loss: 0.00546442904
Iter: 521 loss: 0.00546442391
Iter: 522 loss: 0.00546440948
Iter: 523 loss: 0.00546447467
Iter: 524 loss: 0.00546440715
Iter: 525 loss: 0.00546439551
Iter: 526 loss: 0.00546443835
Iter: 527 loss: 0.00546439411
Iter: 528 loss: 0.00546437828
Iter: 529 loss: 0.00546438713
Iter: 530 loss: 0.00546437316
Iter: 531 loss: 0.00546435826
Iter: 532 loss: 0.00546442717
Iter: 533 loss: 0.00546435546
Iter: 534 loss: 0.00546434196
Iter: 535 loss: 0.00546433777
Iter: 536 loss: 0.00546433404
Iter: 537 loss: 0.00546431681
Iter: 538 loss: 0.0054644
Iter: 539 loss: 0.00546431448
Iter: 540 loss: 0.00546429865
Iter: 541 loss: 0.00546434801
Iter: 542 loss: 0.00546429493
Iter: 543 loss: 0.00546428375
Iter: 544 loss: 0.00546437595
Iter: 545 loss: 0.00546428422
Iter: 546 loss: 0.0054642763
Iter: 547 loss: 0.00546427816
Iter: 548 loss: 0.00546427257
Iter: 549 loss: 0.00546426419
Iter: 550 loss: 0.00546426326
Iter: 551 loss: 0.00546425441
Iter: 552 loss: 0.00546424836
Iter: 553 loss: 0.0054642451
Iter: 554 loss: 0.00546423253
Iter: 555 loss: 0.00546428841
Iter: 556 loss: 0.00546423
Iter: 557 loss: 0.00546421763
Iter: 558 loss: 0.0054642586
Iter: 559 loss: 0.00546421623
Iter: 560 loss: 0.00546420086
Iter: 561 loss: 0.00546421902
Iter: 562 loss: 0.00546419527
Iter: 563 loss: 0.00546418224
Iter: 564 loss: 0.00546422601
Iter: 565 loss: 0.00546418037
Iter: 566 loss: 0.00546417059
Iter: 567 loss: 0.00546417665
Iter: 568 loss: 0.00546415942
Iter: 569 loss: 0.00546414685
Iter: 570 loss: 0.00546417944
Iter: 571 loss: 0.00546414033
Iter: 572 loss: 0.00546412822
Iter: 573 loss: 0.00546424463
Iter: 574 loss: 0.00546412729
Iter: 575 loss: 0.00546412
Iter: 576 loss: 0.00546419621
Iter: 577 loss: 0.00546411797
Iter: 578 loss: 0.00546411239
Iter: 579 loss: 0.00546417944
Iter: 580 loss: 0.00546411285
Iter: 581 loss: 0.00546410866
Iter: 582 loss: 0.00546410354
Iter: 583 loss: 0.00546410307
Iter: 584 loss: 0.00546409376
Iter: 585 loss: 0.0054640919
Iter: 586 loss: 0.00546408724
Iter: 587 loss: 0.00546408072
Iter: 588 loss: 0.00546410168
Iter: 589 loss: 0.00546407327
Iter: 590 loss: 0.00546406209
Iter: 591 loss: 0.00546412636
Iter: 592 loss: 0.00546406
Iter: 593 loss: 0.00546405418
Iter: 594 loss: 0.00546405558
Iter: 595 loss: 0.00546404626
Iter: 596 loss: 0.00546403229
Iter: 597 loss: 0.00546407048
Iter: 598 loss: 0.00546403043
Iter: 599 loss: 0.00546401646
Iter: 600 loss: 0.00546403881
Iter: 601 loss: 0.00546401646
Iter: 602 loss: 0.0054639997
Iter: 603 loss: 0.00546400668
Iter: 604 loss: 0.00546399457
Iter: 605 loss: 0.0054639806
Iter: 606 loss: 0.00546409469
Iter: 607 loss: 0.00546398107
Iter: 608 loss: 0.00546397176
Iter: 609 loss: 0.00546404254
Iter: 610 loss: 0.00546397
Iter: 611 loss: 0.00546396337
Iter: 612 loss: 0.00546396431
Iter: 613 loss: 0.00546396058
Iter: 614 loss: 0.00546395592
Iter: 615 loss: 0.00546395313
Iter: 616 loss: 0.00546394847
Iter: 617 loss: 0.00546394149
Iter: 618 loss: 0.00546394102
Iter: 619 loss: 0.00546393124
Iter: 620 loss: 0.00546396151
Iter: 621 loss: 0.00546392519
Iter: 622 loss: 0.00546391821
Iter: 623 loss: 0.00546396337
Iter: 624 loss: 0.00546391774
Iter: 625 loss: 0.0054639075
Iter: 626 loss: 0.00546391122
Iter: 627 loss: 0.00546390191
Iter: 628 loss: 0.00546389
Iter: 629 loss: 0.0054639522
Iter: 630 loss: 0.00546389073
Iter: 631 loss: 0.00546387956
Iter: 632 loss: 0.00546388794
Iter: 633 loss: 0.00546387769
Iter: 634 loss: 0.00546386791
Iter: 635 loss: 0.00546388747
Iter: 636 loss: 0.00546386186
Iter: 637 loss: 0.00546385348
Iter: 638 loss: 0.00546388375
Iter: 639 loss: 0.00546384975
Iter: 640 loss: 0.00546384184
Iter: 641 loss: 0.00546394428
Iter: 642 loss: 0.00546384323
Iter: 643 loss: 0.00546383904
Iter: 644 loss: 0.0054638884
Iter: 645 loss: 0.00546383858
Iter: 646 loss: 0.00546383671
Iter: 647 loss: 0.00546383485
Iter: 648 loss: 0.00546383066
Iter: 649 loss: 0.00546382647
Iter: 650 loss: 0.00546382368
Iter: 651 loss: 0.00546382181
Iter: 652 loss: 0.00546381483
Iter: 653 loss: 0.00546383113
Iter: 654 loss: 0.00546381203
Iter: 655 loss: 0.00546380412
Iter: 656 loss: 0.00546383392
Iter: 657 loss: 0.00546380365
Iter: 658 loss: 0.00546379667
Iter: 659 loss: 0.00546380971
Iter: 660 loss: 0.00546379108
Iter: 661 loss: 0.00546378549
Iter: 662 loss: 0.0054637976
Iter: 663 loss: 0.00546378
Iter: 664 loss: 0.00546377338
Iter: 665 loss: 0.00546379667
Iter: 666 loss: 0.00546377245
Iter: 667 loss: 0.00546376361
Iter: 668 loss: 0.00546376593
Iter: 669 loss: 0.00546375941
Iter: 670 loss: 0.00546375057
Iter: 671 loss: 0.00546381716
Iter: 672 loss: 0.00546375
Iter: 673 loss: 0.00546374498
Iter: 674 loss: 0.00546380412
Iter: 675 loss: 0.00546374684
Iter: 676 loss: 0.00546374312
Iter: 677 loss: 0.00546377432
Iter: 678 loss: 0.00546374358
Iter: 679 loss: 0.00546373799
Iter: 680 loss: 0.00546374
Iter: 681 loss: 0.00546373846
Iter: 682 loss: 0.00546373334
Iter: 683 loss: 0.00546373054
Iter: 684 loss: 0.00546373
Iter: 685 loss: 0.00546372635
Iter: 686 loss: 0.00546372728
Iter: 687 loss: 0.00546372
Iter: 688 loss: 0.00546371564
Iter: 689 loss: 0.00546376547
Iter: 690 loss: 0.00546371564
Iter: 691 loss: 0.00546371145
Iter: 692 loss: 0.00546371937
Iter: 693 loss: 0.00546370726
Iter: 694 loss: 0.0054637026
Iter: 695 loss: 0.00546371
Iter: 696 loss: 0.0054637
Iter: 697 loss: 0.00546369143
Iter: 698 loss: 0.00546371751
Iter: 699 loss: 0.00546369189
Iter: 700 loss: 0.00546368677
Iter: 701 loss: 0.00546368212
Iter: 702 loss: 0.00546368305
Iter: 703 loss: 0.00546367466
Iter: 704 loss: 0.00546373753
Iter: 705 loss: 0.0054636756
Iter: 706 loss: 0.00546367
Iter: 707 loss: 0.00546371192
Iter: 708 loss: 0.00546366954
Iter: 709 loss: 0.00546366721
Iter: 710 loss: 0.00546370819
Iter: 711 loss: 0.00546366349
Iter: 712 loss: 0.00546366209
Iter: 713 loss: 0.00546366628
Iter: 714 loss: 0.00546366256
Iter: 715 loss: 0.00546366
Iter: 716 loss: 0.00546365604
Iter: 717 loss: 0.00546365883
Iter: 718 loss: 0.00546365045
Iter: 719 loss: 0.00546365883
Iter: 720 loss: 0.00546365
Iter: 721 loss: 0.00546364253
Iter: 722 loss: 0.00546367886
Iter: 723 loss: 0.00546364393
Iter: 724 loss: 0.00546363834
Iter: 725 loss: 0.0054636444
Iter: 726 loss: 0.00546363834
Iter: 727 loss: 0.00546363229
Iter: 728 loss: 0.00546364952
Iter: 729 loss: 0.00546363089
Iter: 730 loss: 0.00546362484
Iter: 731 loss: 0.00546363555
Iter: 732 loss: 0.00546362344
Iter: 733 loss: 0.00546361925
Iter: 734 loss: 0.0054636253
Iter: 735 loss: 0.00546361785
Iter: 736 loss: 0.0054636132
Iter: 737 loss: 0.00546362484
Iter: 738 loss: 0.00546361413
Iter: 739 loss: 0.00546360668
Iter: 740 loss: 0.00546360901
Iter: 741 loss: 0.00546360482
Iter: 742 loss: 0.00546363136
Iter: 743 loss: 0.00546360668
Iter: 744 loss: 0.00546360575
Iter: 745 loss: 0.00546360388
Iter: 746 loss: 0.00546360388
Iter: 747 loss: 0.00546360295
Iter: 748 loss: 0.0054635983
Iter: 749 loss: 0.0054635983
Iter: 750 loss: 0.00546359736
Iter: 751 loss: 0.00546360202
Iter: 752 loss: 0.0054635955
Iter: 753 loss: 0.00546358898
Iter: 754 loss: 0.00546360156
Iter: 755 loss: 0.00546358898
Iter: 756 loss: 0.00546358526
Iter: 757 loss: 0.00546360109
Iter: 758 loss: 0.00546358479
Iter: 759 loss: 0.0054635806
Iter: 760 loss: 0.00546358479
Iter: 761 loss: 0.00546357874
Iter: 762 loss: 0.00546357408
Iter: 763 loss: 0.00546358712
Iter: 764 loss: 0.00546357129
Iter: 765 loss: 0.00546357036
Iter: 766 loss: 0.00546357362
Iter: 767 loss: 0.00546356896
Iter: 768 loss: 0.00546356477
Iter: 769 loss: 0.00546357036
Iter: 770 loss: 0.00546356197
Iter: 771 loss: 0.00546356058
Iter: 772 loss: 0.00546355965
Iter: 773 loss: 0.00546355685
Iter: 774 loss: 0.00546357967
Iter: 775 loss: 0.00546355825
Iter: 776 loss: 0.00546355685
Iter: 777 loss: 0.00546355546
Iter: 778 loss: 0.00546355732
Iter: 779 loss: 0.00546355266
Iter: 780 loss: 0.00546355266
Iter: 781 loss: 0.00546355033
Iter: 782 loss: 0.00546354614
Iter: 783 loss: 0.00546354847
Iter: 784 loss: 0.00546354707
Iter: 785 loss: 0.00546354149
Iter: 786 loss: 0.00546356291
Iter: 787 loss: 0.00546354195
Iter: 788 loss: 0.00546353869
Iter: 789 loss: 0.005463548
Iter: 790 loss: 0.00546353869
Iter: 791 loss: 0.0054635345
Iter: 792 loss: 0.0054635359
Iter: 793 loss: 0.00546353124
Iter: 794 loss: 0.00546352938
Iter: 795 loss: 0.00546355
Iter: 796 loss: 0.00546353031
Iter: 797 loss: 0.00546352379
Iter: 798 loss: 0.00546352472
Iter: 799 loss: 0.00546352332
Iter: 800 loss: 0.0054635182
Iter: 801 loss: 0.00546353031
Iter: 802 loss: 0.0054635182
Iter: 803 loss: 0.00546351541
Iter: 804 loss: 0.00546354195
Iter: 805 loss: 0.00546351308
Iter: 806 loss: 0.00546351261
Iter: 807 loss: 0.00546351308
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/k3
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0
+ date
Tue Oct 27 21:03:04 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef42a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef42d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef42d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef400048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef400268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef400488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef400e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef30a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef3456a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef2bfc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef2bf2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef285c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef285950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef1f4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef285bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef196ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef15b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef15b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef130840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef0ea0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef0ea2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef09abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef0d3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef05ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef05e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef0368c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eeff28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eeffbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef00f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eeff2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9ef00f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eef8ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eef2d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eeed4b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eef2d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc9eee9f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0111998841
Iter: 2 loss: 0.0111505827
Iter: 3 loss: 0.0109937433
Iter: 4 loss: 0.0111781172
Iter: 5 loss: 0.0108735571
Iter: 6 loss: 0.0108590536
Iter: 7 loss: 0.010824386
Iter: 8 loss: 0.010817416
Iter: 9 loss: 0.0108158095
Iter: 10 loss: 0.010811328
Iter: 11 loss: 0.0108106276
Iter: 12 loss: 0.0108103156
Iter: 13 loss: 0.0108098434
Iter: 14 loss: 0.0108125526
Iter: 15 loss: 0.010809781
Iter: 16 loss: 0.0108097252
Iter: 17 loss: 0.0108099068
Iter: 18 loss: 0.0108097065
Iter: 19 loss: 0.0108097047
Iter: 20 loss: 0.0108096963
Iter: 21 loss: 0.0108096953
Iter: 22 loss: 0.0108096944
Iter: 23 loss: 0.0108096926
Iter: 24 loss: 0.0108096916
Iter: 25 loss: 0.0108096916
Iter: 26 loss: 0.0108096916
Iter: 27 loss: 0.0108096916
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4
+ date
Tue Oct 27 21:03:31 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f716782b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f711e32cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f711e32cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f711e2b86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f711e25b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f711e262d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f711e2626a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f82f51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f82f5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f82acbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f82ac840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f8282e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f826d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f81bc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f81f7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f8184e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f819c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f81f7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f8171400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f8134048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f81341e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f8134950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f80a7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f804d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70f804d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e066b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e06a26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e064aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e06a2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e05f2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e061eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e05d8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e05dc1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0581ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e05398c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0546f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0351324156
Iter: 2 loss: 0.0311169177
Iter: 3 loss: 0.0193157922
Iter: 4 loss: 0.0489686
Iter: 5 loss: 0.0129704662
Iter: 6 loss: 0.0121710692
Iter: 7 loss: 0.0120611675
Iter: 8 loss: 0.0117281834
Iter: 9 loss: 0.0163954496
Iter: 10 loss: 0.011724012
Iter: 11 loss: 0.0116587691
Iter: 12 loss: 0.0117802862
Iter: 13 loss: 0.0116310865
Iter: 14 loss: 0.0116216801
Iter: 15 loss: 0.0116120614
Iter: 16 loss: 0.0116041955
Iter: 17 loss: 0.0116218934
Iter: 18 loss: 0.0116012394
Iter: 19 loss: 0.0115996227
Iter: 20 loss: 0.0116105909
Iter: 21 loss: 0.0115994588
Iter: 22 loss: 0.0115992324
Iter: 23 loss: 0.0115991877
Iter: 24 loss: 0.0115991198
Iter: 25 loss: 0.0115993507
Iter: 26 loss: 0.0115991011
Iter: 27 loss: 0.0115990769
Iter: 28 loss: 0.0115991868
Iter: 29 loss: 0.0115990704
Iter: 30 loss: 0.0115990695
Iter: 31 loss: 0.0115990648
Iter: 32 loss: 0.0115990676
Iter: 33 loss: 0.0115990723
Iter: 34 loss: 0.011599062
Iter: 35 loss: 0.0115990648
Iter: 36 loss: 0.0115990676
Iter: 37 loss: 0.011599062
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8
+ date
Tue Oct 27 21:03:59 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc91db1a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc95f807158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc91da89840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc91daa38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc91da16ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc91daa3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc91da16e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8f812b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8f812b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8f80cc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8f808a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8f80438c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8f80432f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e00fb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e0134840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e00c0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e00db378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e00dbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e0047840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e00478c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e0066488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8e00661e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc894753730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8946e9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8946e91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8946aa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8946dc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc894683510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc894683400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc89462c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc89462c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc89460d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc89461b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8945b67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc8945728c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc894592048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0296458751
Iter: 2 loss: 0.0265942775
Iter: 3 loss: 0.0189617053
Iter: 4 loss: 0.447940528
Iter: 5 loss: 0.0188436899
Iter: 6 loss: 0.0141892917
Iter: 7 loss: 0.0688192397
Iter: 8 loss: 0.0140064824
Iter: 9 loss: 0.0133189708
Iter: 10 loss: 0.0132126603
Iter: 11 loss: 0.0130773541
Iter: 12 loss: 0.0136918304
Iter: 13 loss: 0.0130496044
Iter: 14 loss: 0.0129547641
Iter: 15 loss: 0.0132211428
Iter: 16 loss: 0.012923602
Iter: 17 loss: 0.0128755793
Iter: 18 loss: 0.0131516336
Iter: 19 loss: 0.0128693
Iter: 20 loss: 0.012852964
Iter: 21 loss: 0.0129612871
Iter: 22 loss: 0.0128512466
Iter: 23 loss: 0.0128477504
Iter: 24 loss: 0.01284739
Iter: 25 loss: 0.0128464038
Iter: 26 loss: 0.012848367
Iter: 27 loss: 0.0128460005
Iter: 28 loss: 0.0128457854
Iter: 29 loss: 0.0128479209
Iter: 30 loss: 0.0128457751
Iter: 31 loss: 0.0128457276
Iter: 32 loss: 0.012845723
Iter: 33 loss: 0.0128457025
Iter: 34 loss: 0.0128458105
Iter: 35 loss: 0.0128457015
Iter: 36 loss: 0.0128456969
Iter: 37 loss: 0.012845722
Iter: 38 loss: 0.0128456941
Iter: 39 loss: 0.0128456913
Iter: 40 loss: 0.0128457006
Iter: 41 loss: 0.0128456913
Iter: 42 loss: 0.0128456913
Iter: 43 loss: 0.0128456913
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2
+ date
Tue Oct 27 21:04:27 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi0.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45208360d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520836620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45207b88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45207db9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520749b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45207dbea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520749e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45206d8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45206d8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520684488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452063b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45205f1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520601840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45205a7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45205db840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452056ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452058c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452058c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45204f0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452051a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452051a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452051aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45204899d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45204897b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520489ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520489730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520418840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45203c0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45203c0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4520365400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45203650d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f452034a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f45203552f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44fb6897b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44fb63fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44fb66a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0307226107
Iter: 2 loss: 0.0258926079
Iter: 3 loss: 0.0237091761
Iter: 4 loss: 0.0205799863
Iter: 5 loss: 0.0172236934
Iter: 6 loss: 0.082003668
Iter: 7 loss: 0.017111022
Iter: 8 loss: 0.0146904057
Iter: 9 loss: 0.0390677676
Iter: 10 loss: 0.0145897139
Iter: 11 loss: 0.0141471438
Iter: 12 loss: 0.0150241107
Iter: 13 loss: 0.0139566697
Iter: 14 loss: 0.0138150295
Iter: 15 loss: 0.0150520429
Iter: 16 loss: 0.0138069782
Iter: 17 loss: 0.0137285963
Iter: 18 loss: 0.0147231948
Iter: 19 loss: 0.0137278242
Iter: 20 loss: 0.0136690512
Iter: 21 loss: 0.0137355328
Iter: 22 loss: 0.0136373527
Iter: 23 loss: 0.0136143882
Iter: 24 loss: 0.0138266869
Iter: 25 loss: 0.0136133907
Iter: 26 loss: 0.0136066191
Iter: 27 loss: 0.0136682149
Iter: 28 loss: 0.0136063062
Iter: 29 loss: 0.0136043308
Iter: 30 loss: 0.0136255929
Iter: 31 loss: 0.0136042824
Iter: 32 loss: 0.0136036808
Iter: 33 loss: 0.0136081278
Iter: 34 loss: 0.0136036361
Iter: 35 loss: 0.0136034163
Iter: 36 loss: 0.0136045031
Iter: 37 loss: 0.0136033772
Iter: 38 loss: 0.0136033073
Iter: 39 loss: 0.0136038475
Iter: 40 loss: 0.0136033017
Iter: 41 loss: 0.0136032822
Iter: 42 loss: 0.0136032831
Iter: 43 loss: 0.0136032673
Iter: 44 loss: 0.0136032691
Iter: 45 loss: 0.013603257
Iter: 46 loss: 0.0136032514
Iter: 47 loss: 0.0136032803
Iter: 48 loss: 0.0136032496
Iter: 49 loss: 0.0136032468
Iter: 50 loss: 0.0136032747
Iter: 51 loss: 0.0136032458
Iter: 52 loss: 0.0136032458
Iter: 53 loss: 0.0136032552
Iter: 54 loss: 0.0136032468
Iter: 55 loss: 0.0136032449
Iter: 56 loss: 0.0136032458
Iter: 57 loss: 0.0136032449
Iter: 58 loss: 0.0136032458
Iter: 59 loss: 0.0136032449
Iter: 60 loss: 0.0136032496
Iter: 61 loss: 0.0136032486
Iter: 62 loss: 0.0136032458
Iter: 63 loss: 0.013603244
Iter: 64 loss: 0.0136032449
Iter: 65 loss: 0.013603244
Iter: 66 loss: 0.0136032458
Iter: 67 loss: 0.0136032449
Iter: 68 loss: 0.0136032458
Iter: 69 loss: 0.0136032468
Iter: 70 loss: 0.0136032458
Iter: 71 loss: 0.0136032449
Iter: 72 loss: 0.0136032458
Iter: 73 loss: 0.0136032458
Iter: 74 loss: 0.0136032449
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6
+ date
Tue Oct 27 21:04:56 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c45f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c90c63d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c90c637b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c4a5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c3fc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c3fc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c3dac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c39f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c32c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c345400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c2ff378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c2ad8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c2cb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c26bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c2ad400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c2ad158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c231488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c256a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c1ba840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c1babf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c1df598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c1dff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c150950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c0f6598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c0f66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c0a8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c0de840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c0de598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c089510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c02c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6c089950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c507a9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c507b11e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c50752d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c5070aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c5070a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0364053771
Iter: 2 loss: 0.0249667577
Iter: 3 loss: 6.2918973
Iter: 4 loss: 0.0249594301
Iter: 5 loss: 0.0238018073
Iter: 6 loss: 0.0206086524
Iter: 7 loss: 0.0183234736
Iter: 8 loss: 0.0656981543
Iter: 9 loss: 0.0182676427
Iter: 10 loss: 0.0163615346
Iter: 11 loss: 0.0232049134
Iter: 12 loss: 0.015828995
Iter: 13 loss: 0.0150342351
Iter: 14 loss: 0.0163792856
Iter: 15 loss: 0.0146764256
Iter: 16 loss: 0.0143608581
Iter: 17 loss: 0.0173896868
Iter: 18 loss: 0.0143396985
Iter: 19 loss: 0.014259859
Iter: 20 loss: 0.0148717891
Iter: 21 loss: 0.0142527688
Iter: 22 loss: 0.0141986571
Iter: 23 loss: 0.014178751
Iter: 24 loss: 0.0141488397
Iter: 25 loss: 0.0140687991
Iter: 26 loss: 0.0140658766
Iter: 27 loss: 0.0140034985
Iter: 28 loss: 0.0139353611
Iter: 29 loss: 0.0146207269
Iter: 30 loss: 0.0139327617
Iter: 31 loss: 0.0139133958
Iter: 32 loss: 0.0139824385
Iter: 33 loss: 0.0139084626
Iter: 34 loss: 0.0138992798
Iter: 35 loss: 0.0139424652
Iter: 36 loss: 0.0138976
Iter: 37 loss: 0.0138948346
Iter: 38 loss: 0.0139194317
Iter: 39 loss: 0.0138946977
Iter: 40 loss: 0.0138934338
Iter: 41 loss: 0.0139053725
Iter: 42 loss: 0.0138933817
Iter: 43 loss: 0.0138929933
Iter: 44 loss: 0.0138985869
Iter: 45 loss: 0.0138929933
Iter: 46 loss: 0.0138927847
Iter: 47 loss: 0.0138934981
Iter: 48 loss: 0.0138927288
Iter: 49 loss: 0.0138926264
Iter: 50 loss: 0.0138930101
Iter: 51 loss: 0.013892604
Iter: 52 loss: 0.0138925444
Iter: 53 loss: 0.0138929812
Iter: 54 loss: 0.0138925379
Iter: 55 loss: 0.0138924969
Iter: 56 loss: 0.0138926078
Iter: 57 loss: 0.0138924848
Iter: 58 loss: 0.0138924625
Iter: 59 loss: 0.0138925845
Iter: 60 loss: 0.0138924588
Iter: 61 loss: 0.0138924476
Iter: 62 loss: 0.0138925808
Iter: 63 loss: 0.0138924466
Iter: 64 loss: 0.0138924383
Iter: 65 loss: 0.0138924625
Iter: 66 loss: 0.0138924383
Iter: 67 loss: 0.0138924364
Iter: 68 loss: 0.0138924439
Iter: 69 loss: 0.0138924308
Iter: 70 loss: 0.0138924317
Iter: 71 loss: 0.0138924476
Iter: 72 loss: 0.0138924289
Iter: 73 loss: 0.0138924308
Iter: 74 loss: 0.0138924327
Iter: 75 loss: 0.0138924289
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2
+ date
Tue Oct 27 21:05:27 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi1.6/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708abdf2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708ab5cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708ac31950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708ab9a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708aaffd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708aaffbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708aabd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708aa808c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708aa9a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708aa9ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a9f6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a9ae0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708aa9a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a966d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a99f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a926e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a9437b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a99f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a917950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a94fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a8ce620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a887c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a84a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a7f19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a7f1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a823598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a7da8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a77c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a7dab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a79cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a756950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a70f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a7181e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a6b96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a6719d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f708a68f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0493656173
Iter: 2 loss: 0.0559441075
Iter: 3 loss: 0.0396772847
Iter: 4 loss: 617.316162
Iter: 5 loss: 0.0436209105
Iter: 6 loss: 0.0315905586
Iter: 7 loss: 0.127169
Iter: 8 loss: 0.0300529748
Iter: 9 loss: 0.0410510376
Iter: 10 loss: 0.022697147
Iter: 11 loss: 0.0226968117
Iter: 12 loss: 0.0213670619
Iter: 13 loss: 0.0183743238
Iter: 14 loss: 0.107071087
Iter: 15 loss: 0.0183025636
Iter: 16 loss: 0.0170698334
Iter: 17 loss: 0.0168714616
Iter: 18 loss: 0.0160938855
Iter: 19 loss: 0.017004896
Iter: 20 loss: 0.015662659
Iter: 21 loss: 0.0151028978
Iter: 22 loss: 0.0222773366
Iter: 23 loss: 0.0150790587
Iter: 24 loss: 0.0149340946
Iter: 25 loss: 0.0161076412
Iter: 26 loss: 0.0149267819
Iter: 27 loss: 0.0148097575
Iter: 28 loss: 0.0150528233
Iter: 29 loss: 0.0147588365
Iter: 30 loss: 0.0146727059
Iter: 31 loss: 0.014893584
Iter: 32 loss: 0.014643305
Iter: 33 loss: 0.0145830829
Iter: 34 loss: 0.0146892164
Iter: 35 loss: 0.0145560149
Iter: 36 loss: 0.0145149389
Iter: 37 loss: 0.0145595828
Iter: 38 loss: 0.0144919194
Iter: 39 loss: 0.0144338561
Iter: 40 loss: 0.0144604035
Iter: 41 loss: 0.0143941417
Iter: 42 loss: 0.0143155502
Iter: 43 loss: 0.0143736638
Iter: 44 loss: 0.0142669454
Iter: 45 loss: 0.0142312
Iter: 46 loss: 0.014229795
Iter: 47 loss: 0.0142126549
Iter: 48 loss: 0.0142941512
Iter: 49 loss: 0.0142095024
Iter: 50 loss: 0.014199039
Iter: 51 loss: 0.0142805036
Iter: 52 loss: 0.014198279
Iter: 53 loss: 0.0141925095
Iter: 54 loss: 0.0142249558
Iter: 55 loss: 0.0141917197
Iter: 56 loss: 0.0141895954
Iter: 57 loss: 0.0142059103
Iter: 58 loss: 0.0141894314
Iter: 59 loss: 0.014188027
Iter: 60 loss: 0.0141970692
Iter: 61 loss: 0.0141878817
Iter: 62 loss: 0.0141869299
Iter: 63 loss: 0.0141868815
Iter: 64 loss: 0.0141861532
Iter: 65 loss: 0.014185166
Iter: 66 loss: 0.0141896037
Iter: 67 loss: 0.0141849741
Iter: 68 loss: 0.0141843082
Iter: 69 loss: 0.0141871013
Iter: 70 loss: 0.0141841676
Iter: 71 loss: 0.0141837317
Iter: 72 loss: 0.0141847366
Iter: 73 loss: 0.0141835725
Iter: 74 loss: 0.014183295
Iter: 75 loss: 0.0141850784
Iter: 76 loss: 0.0141832624
Iter: 77 loss: 0.0141830957
Iter: 78 loss: 0.0141841145
Iter: 79 loss: 0.0141830668
Iter: 80 loss: 0.0141829811
Iter: 81 loss: 0.0141833909
Iter: 82 loss: 0.0141829662
Iter: 83 loss: 0.0141828954
Iter: 84 loss: 0.0141830323
Iter: 85 loss: 0.0141828675
Iter: 86 loss: 0.0141828191
Iter: 87 loss: 0.0141831664
Iter: 88 loss: 0.0141828153
Iter: 89 loss: 0.0141827967
Iter: 90 loss: 0.0141827948
Iter: 91 loss: 0.0141827818
Iter: 92 loss: 0.0141828749
Iter: 93 loss: 0.0141827799
Iter: 94 loss: 0.0141827688
Iter: 95 loss: 0.0141827594
Iter: 96 loss: 0.0141827567
Iter: 97 loss: 0.0141827408
Iter: 98 loss: 0.0141827734
Iter: 99 loss: 0.0141827334
Iter: 100 loss: 0.0141827231
Iter: 101 loss: 0.0141827846
Iter: 102 loss: 0.0141827203
Iter: 103 loss: 0.0141827166
Iter: 104 loss: 0.0141827315
Iter: 105 loss: 0.014182711
Iter: 106 loss: 0.0141827017
Iter: 107 loss: 0.0141827222
Iter: 108 loss: 0.0141827
Iter: 109 loss: 0.0141826952
Iter: 110 loss: 0.0141827352
Iter: 111 loss: 0.0141826943
Iter: 112 loss: 0.0141826877
Iter: 113 loss: 0.0141826989
Iter: 114 loss: 0.0141826887
Iter: 115 loss: 0.0141826868
Iter: 116 loss: 0.0141827026
Iter: 117 loss: 0.014182684
Iter: 118 loss: 0.0141826849
Iter: 119 loss: 0.0141826877
Iter: 120 loss: 0.0141826803
Iter: 121 loss: 0.0141826812
Iter: 122 loss: 0.0141826831
Iter: 123 loss: 0.0141826803
Iter: 124 loss: 0.0141826803
Iter: 125 loss: 0.0141826775
Iter: 126 loss: 0.0141826803
Iter: 127 loss: 0.0141826831
Iter: 128 loss: 0.0141826775
Iter: 129 loss: 0.0141826803
Iter: 130 loss: 0.0141826784
Iter: 131 loss: 0.0141826812
Iter: 132 loss: 0.0141826794
Iter: 133 loss: 0.0141826784
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4
+ date
Tue Oct 27 21:06:00 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0243d1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe042662f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe042662d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0244180d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024385378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe02439b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0242eb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe02430e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0242eb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0242be378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0242772f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024234510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024234488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0241e4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe02421d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0241add90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0241ca400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe02421d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024132598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024157158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0241572f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024157ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0240cb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024072730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024072400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024023378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe02405d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe024002510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe02400b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe023fa8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe023fd7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe023f8c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe023f911e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe023f36c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe023ee99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe023f0f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.106984966
Iter: 2 loss: 4528.52783
Iter: 3 loss: 0.106984921
Iter: 4 loss: 560.933716
Iter: 5 loss: 0.680023968
Iter: 6 loss: 0.106349543
Iter: 7 loss: 0.0551503897
Iter: 8 loss: 0.0546967
Iter: 9 loss: 0.0353623182
Iter: 10 loss: 0.0366897844
Iter: 11 loss: 805.172363
Iter: 12 loss: 508.033
Iter: 13 loss: 156.457748
Iter: 14 loss: 0.0366823152
Iter: 15 loss: 0.035935156
Iter: 16 loss: 0.0336936191
Iter: 17 loss: 0.0336675458
Iter: 18 loss: 0.0331533775
Iter: 19 loss: 0.0347342268
Iter: 20 loss: 0.0329883061
Iter: 21 loss: 0.0322267823
Iter: 22 loss: 0.0300181918
Iter: 23 loss: 0.0435540415
Iter: 24 loss: 0.0292598512
Iter: 25 loss: 0.0251779556
Iter: 26 loss: 0.0448919386
Iter: 27 loss: 0.0241466314
Iter: 28 loss: 0.0211457815
Iter: 29 loss: 0.0510821044
Iter: 30 loss: 0.0208333582
Iter: 31 loss: 0.0196715314
Iter: 32 loss: 0.0196022335
Iter: 33 loss: 0.0188881047
Iter: 34 loss: 0.0228048097
Iter: 35 loss: 0.0188179389
Iter: 36 loss: 0.0182922762
Iter: 37 loss: 0.0184984431
Iter: 38 loss: 0.0179350581
Iter: 39 loss: 0.0172975436
Iter: 40 loss: 0.0201555118
Iter: 41 loss: 0.0171447471
Iter: 42 loss: 0.0166879147
Iter: 43 loss: 0.0189797059
Iter: 44 loss: 0.0165818874
Iter: 45 loss: 0.0160970129
Iter: 46 loss: 0.0169470906
Iter: 47 loss: 0.015872255
Iter: 48 loss: 0.0160041936
Iter: 49 loss: 0.015752729
Iter: 50 loss: 0.0156204039
Iter: 51 loss: 0.0159858093
Iter: 52 loss: 0.0155769214
Iter: 53 loss: 0.0153910955
Iter: 54 loss: 0.015625719
Iter: 55 loss: 0.0152887153
Iter: 56 loss: 0.0151813328
Iter: 57 loss: 0.0151744
Iter: 58 loss: 0.0150803942
Iter: 59 loss: 0.0154255796
Iter: 60 loss: 0.0150574585
Iter: 61 loss: 0.0149964113
Iter: 62 loss: 0.0150498347
Iter: 63 loss: 0.014960601
Iter: 64 loss: 0.0149326045
Iter: 65 loss: 0.0149690732
Iter: 66 loss: 0.0149182277
Iter: 67 loss: 0.0149051184
Iter: 68 loss: 0.0149068721
Iter: 69 loss: 0.0148950201
Iter: 70 loss: 0.0148866009
Iter: 71 loss: 0.0148825459
Iter: 72 loss: 0.0148784444
Iter: 73 loss: 0.0148713775
Iter: 74 loss: 0.0148626082
Iter: 75 loss: 0.0148618584
Iter: 76 loss: 0.014844954
Iter: 77 loss: 0.0148670375
Iter: 78 loss: 0.0148363076
Iter: 79 loss: 0.0148165422
Iter: 80 loss: 0.0148309041
Iter: 81 loss: 0.0148043698
Iter: 82 loss: 0.0148090161
Iter: 83 loss: 0.0147957802
Iter: 84 loss: 0.0147900721
Iter: 85 loss: 0.0147903953
Iter: 86 loss: 0.0147855887
Iter: 87 loss: 0.0147730103
Iter: 88 loss: 0.0147731826
Iter: 89 loss: 0.014762884
Iter: 90 loss: 0.0147446934
Iter: 91 loss: 0.0147234593
Iter: 92 loss: 0.0147210201
Iter: 93 loss: 0.0146969147
Iter: 94 loss: 0.0149761084
Iter: 95 loss: 0.0146965068
Iter: 96 loss: 0.0146727413
Iter: 97 loss: 0.0146655766
Iter: 98 loss: 0.014651265
Iter: 99 loss: 0.0147169679
Iter: 100 loss: 0.0146411676
Iter: 101 loss: 0.0146328481
Iter: 102 loss: 0.0146652749
Iter: 103 loss: 0.014630856
Iter: 104 loss: 0.0146157909
Iter: 105 loss: 0.0146742212
Iter: 106 loss: 0.0146121262
Iter: 107 loss: 0.014598811
Iter: 108 loss: 0.0145879416
Iter: 109 loss: 0.0145840831
Iter: 110 loss: 0.0145704504
Iter: 111 loss: 0.0145836491
Iter: 112 loss: 0.01456251
Iter: 113 loss: 0.0145559628
Iter: 114 loss: 0.0145369498
Iter: 115 loss: 0.0146189937
Iter: 116 loss: 0.0145294657
Iter: 117 loss: 0.0146000022
Iter: 118 loss: 0.0145226801
Iter: 119 loss: 0.0145100113
Iter: 120 loss: 0.0145006
Iter: 121 loss: 0.0144964438
Iter: 122 loss: 0.0144851208
Iter: 123 loss: 0.0145004522
Iter: 124 loss: 0.0144794043
Iter: 125 loss: 0.0144669581
Iter: 126 loss: 0.0144884735
Iter: 127 loss: 0.0144614177
Iter: 128 loss: 0.0144472495
Iter: 129 loss: 0.0145159289
Iter: 130 loss: 0.0144448429
Iter: 131 loss: 0.0144384885
Iter: 132 loss: 0.014438482
Iter: 133 loss: 0.0144321062
Iter: 134 loss: 0.0144513613
Iter: 135 loss: 0.0144301765
Iter: 136 loss: 0.0144269122
Iter: 137 loss: 0.0144219408
Iter: 138 loss: 0.0144218542
Iter: 139 loss: 0.014419226
Iter: 140 loss: 0.0144543285
Iter: 141 loss: 0.0144192064
Iter: 142 loss: 0.0144161945
Iter: 143 loss: 0.0144167533
Iter: 144 loss: 0.0144139249
Iter: 145 loss: 0.0144109661
Iter: 146 loss: 0.0144072995
Iter: 147 loss: 0.0144069837
Iter: 148 loss: 0.0144006955
Iter: 149 loss: 0.0143969385
Iter: 150 loss: 0.0143943196
Iter: 151 loss: 0.0143914726
Iter: 152 loss: 0.0143907694
Iter: 153 loss: 0.0143881114
Iter: 154 loss: 0.0144003499
Iter: 155 loss: 0.0143876225
Iter: 156 loss: 0.0143858436
Iter: 157 loss: 0.0143831763
Iter: 158 loss: 0.0143831205
Iter: 159 loss: 0.0143806664
Iter: 160 loss: 0.0143882297
Iter: 161 loss: 0.0143799493
Iter: 162 loss: 0.0143788857
Iter: 163 loss: 0.0143787675
Iter: 164 loss: 0.0143782571
Iter: 165 loss: 0.0143781994
Iter: 166 loss: 0.0143776676
Iter: 167 loss: 0.0143770119
Iter: 168 loss: 0.0143769495
Iter: 169 loss: 0.0143762939
Iter: 170 loss: 0.0143789239
Iter: 171 loss: 0.0143761449
Iter: 172 loss: 0.0143753458
Iter: 173 loss: 0.0143770901
Iter: 174 loss: 0.0143750375
Iter: 175 loss: 0.0143743875
Iter: 176 loss: 0.0143748866
Iter: 177 loss: 0.0143739954
Iter: 178 loss: 0.0143731879
Iter: 179 loss: 0.0143757183
Iter: 180 loss: 0.0143729541
Iter: 181 loss: 0.0143724531
Iter: 182 loss: 0.0143758934
Iter: 183 loss: 0.0143724
Iter: 184 loss: 0.0143719567
Iter: 185 loss: 0.0143729886
Iter: 186 loss: 0.0143717825
Iter: 187 loss: 0.0143713932
Iter: 188 loss: 0.0143709946
Iter: 189 loss: 0.0143709164
Iter: 190 loss: 0.0143701909
Iter: 191 loss: 0.0143701155
Iter: 192 loss: 0.0143695883
Iter: 193 loss: 0.0143690966
Iter: 194 loss: 0.0143739209
Iter: 195 loss: 0.0143690798
Iter: 196 loss: 0.0143690836
Iter: 197 loss: 0.014368888
Iter: 198 loss: 0.0143687222
Iter: 199 loss: 0.0143686933
Iter: 200 loss: 0.0143685853
Iter: 201 loss: 0.0143684344
Iter: 202 loss: 0.014368522
Iter: 203 loss: 0.0143683385
Iter: 204 loss: 0.0143681178
Iter: 205 loss: 0.0143688638
Iter: 206 loss: 0.0143680666
Iter: 207 loss: 0.0143679278
Iter: 208 loss: 0.0143677788
Iter: 209 loss: 0.014367763
Iter: 210 loss: 0.0143675348
Iter: 211 loss: 0.0143683879
Iter: 212 loss: 0.0143674798
Iter: 213 loss: 0.0143673467
Iter: 214 loss: 0.0143678458
Iter: 215 loss: 0.0143673038
Iter: 216 loss: 0.014367166
Iter: 217 loss: 0.0143684121
Iter: 218 loss: 0.0143671595
Iter: 219 loss: 0.0143670812
Iter: 220 loss: 0.0143669406
Iter: 221 loss: 0.014366935
Iter: 222 loss: 0.0143667646
Iter: 223 loss: 0.0143671073
Iter: 224 loss: 0.0143666938
Iter: 225 loss: 0.0143665709
Iter: 226 loss: 0.0143669983
Iter: 227 loss: 0.0143665364
Iter: 228 loss: 0.0143666081
Iter: 229 loss: 0.0143664964
Iter: 230 loss: 0.0143664787
Iter: 231 loss: 0.014366515
Iter: 232 loss: 0.0143664554
Iter: 233 loss: 0.0143664293
Iter: 234 loss: 0.0143663874
Iter: 235 loss: 0.0143672451
Iter: 236 loss: 0.0143663939
Iter: 237 loss: 0.0143663492
Iter: 238 loss: 0.0143663418
Iter: 239 loss: 0.014366338
Iter: 240 loss: 0.0143663082
Iter: 241 loss: 0.0143667525
Iter: 242 loss: 0.0143663082
Iter: 243 loss: 0.0143662598
Iter: 244 loss: 0.0143665615
Iter: 245 loss: 0.0143662589
Iter: 246 loss: 0.0143662309
Iter: 247 loss: 0.0143662561
Iter: 248 loss: 0.014366217
Iter: 249 loss: 0.0143661592
Iter: 250 loss: 0.0143664256
Iter: 251 loss: 0.0143661452
Iter: 252 loss: 0.0143661257
Iter: 253 loss: 0.0143660922
Iter: 254 loss: 0.0143660838
Iter: 255 loss: 0.0143660437
Iter: 256 loss: 0.0143660447
Iter: 257 loss: 0.0143660083
Iter: 258 loss: 0.0143659785
Iter: 259 loss: 0.0143660195
Iter: 260 loss: 0.0143659627
Iter: 261 loss: 0.0143659469
Iter: 262 loss: 0.0143659394
Iter: 263 loss: 0.0143659282
Iter: 264 loss: 0.0143659748
Iter: 265 loss: 0.0143659208
Iter: 266 loss: 0.0143659078
Iter: 267 loss: 0.0143658789
Iter: 268 loss: 0.0143663948
Iter: 269 loss: 0.0143658761
Iter: 270 loss: 0.0143658724
Iter: 271 loss: 0.0143658584
Iter: 272 loss: 0.0143658556
Iter: 273 loss: 0.0143658463
Iter: 274 loss: 0.0143659031
Iter: 275 loss: 0.0143658416
Iter: 276 loss: 0.0143658277
Iter: 277 loss: 0.0143658258
Iter: 278 loss: 0.014365809
Iter: 279 loss: 0.0143658519
Iter: 280 loss: 0.0143658062
Iter: 281 loss: 0.0143657923
Iter: 282 loss: 0.0143658407
Iter: 283 loss: 0.0143657941
Iter: 284 loss: 0.0143657932
Iter: 285 loss: 0.0143657904
Iter: 286 loss: 0.0143657913
Iter: 287 loss: 0.0143657811
Iter: 288 loss: 0.0143658035
Iter: 289 loss: 0.0143657792
Iter: 290 loss: 0.0143657718
Iter: 291 loss: 0.0143658
Iter: 292 loss: 0.0143657615
Iter: 293 loss: 0.0143657681
Iter: 294 loss: 0.0143657615
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8
+ date
Tue Oct 27 21:06:44 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404cf6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404cf66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa446a94378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa446a691e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c8d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c9fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c8d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c6ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c39378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c39158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c39d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e04abd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e044a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e03fbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa404c39400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e03c2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e03c20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e03e2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e033c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e033cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e03670d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e0367f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e02d8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e032e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e032e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e02a47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e02726a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e0272510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e0218620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e01c0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e01eb6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e01a4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e01af0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e01afe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e01af2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa3e011aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.096426338
Iter: 2 loss: 1.95681453
Iter: 3 loss: 1.86449528
Iter: 4 loss: 1.0031637
Iter: 5 loss: 0.959442556
Iter: 6 loss: 0.531779766
Iter: 7 loss: 0.507225811
Iter: 8 loss: 0.280928969
Iter: 9 loss: 0.265765399
Iter: 10 loss: 0.142811954
Iter: 11 loss: 0.133422405
Iter: 12 loss: 0.0695801079
Iter: 13 loss: 0.0648811311
Iter: 14 loss: 0.0602857471
Iter: 15 loss: 0.0433805287
Iter: 16 loss: 639.49939
Iter: 17 loss: 0.0561839715
Iter: 18 loss: 0.0538025573
Iter: 19 loss: 0.0358653
Iter: 20 loss: 0.0349167772
Iter: 21 loss: 0.0906141773
Iter: 22 loss: 0.0343734436
Iter: 23 loss: 0.0333714336
Iter: 24 loss: 0.0300729387
Iter: 25 loss: 0.0448229425
Iter: 26 loss: 0.0301156044
Iter: 27 loss: 0.0287966114
Iter: 28 loss: 0.0371943153
Iter: 29 loss: 0.0284841191
Iter: 30 loss: 0.0271354038
Iter: 31 loss: 0.0284927785
Iter: 32 loss: 0.0262494646
Iter: 33 loss: 0.0240150914
Iter: 34 loss: 0.0278308485
Iter: 35 loss: 0.0233151205
Iter: 36 loss: 0.0226138197
Iter: 37 loss: 0.0229336303
Iter: 38 loss: 0.0221163221
Iter: 39 loss: 0.0215519145
Iter: 40 loss: 0.0226235688
Iter: 41 loss: 0.0213009752
Iter: 42 loss: 0.021156067
Iter: 43 loss: 0.0210903101
Iter: 44 loss: 0.0210070461
Iter: 45 loss: 0.0216987766
Iter: 46 loss: 0.0210015438
Iter: 47 loss: 0.0209630802
Iter: 48 loss: 0.0209762231
Iter: 49 loss: 0.0209357403
Iter: 50 loss: 0.0208900571
Iter: 51 loss: 0.0211249553
Iter: 52 loss: 0.0208822135
Iter: 53 loss: 0.0208582077
Iter: 54 loss: 0.0209966525
Iter: 55 loss: 0.0208549257
Iter: 56 loss: 0.020838812
Iter: 57 loss: 0.0210180841
Iter: 58 loss: 0.0208384674
Iter: 59 loss: 0.0208290294
Iter: 60 loss: 0.0209327117
Iter: 61 loss: 0.0208287872
Iter: 62 loss: 0.0208223574
Iter: 63 loss: 0.0208222643
Iter: 64 loss: 0.0208184235
Iter: 65 loss: 0.0208151154
Iter: 66 loss: 0.0208140649
Iter: 67 loss: 0.0208100677
Iter: 68 loss: 0.0208202675
Iter: 69 loss: 0.020808693
Iter: 70 loss: 0.0208049063
Iter: 71 loss: 0.0208093747
Iter: 72 loss: 0.0208028853
Iter: 73 loss: 0.0207980871
Iter: 74 loss: 0.0207995046
Iter: 75 loss: 0.0207946301
Iter: 76 loss: 0.0207883492
Iter: 77 loss: 0.0208169296
Iter: 78 loss: 0.0207871348
Iter: 79 loss: 0.0207816381
Iter: 80 loss: 0.0207885075
Iter: 81 loss: 0.0207787883
Iter: 82 loss: 0.0207732208
Iter: 83 loss: 0.0208048373
Iter: 84 loss: 0.0207724497
Iter: 85 loss: 0.0207671113
Iter: 86 loss: 0.0207665134
Iter: 87 loss: 0.0207626559
Iter: 88 loss: 0.0207577161
Iter: 89 loss: 0.0207911283
Iter: 90 loss: 0.0207572337
Iter: 91 loss: 0.0207540505
Iter: 92 loss: 0.020793695
Iter: 93 loss: 0.0207540207
Iter: 94 loss: 0.0207529757
Iter: 95 loss: 0.0207526665
Iter: 96 loss: 0.0207516216
Iter: 97 loss: 0.0207516663
Iter: 98 loss: 0.0207507964
Iter: 99 loss: 0.0207500011
Iter: 100 loss: 0.0207501836
Iter: 101 loss: 0.0207494125
Iter: 102 loss: 0.0207485259
Iter: 103 loss: 0.0207509063
Iter: 104 loss: 0.0207482334
Iter: 105 loss: 0.0207474064
Iter: 106 loss: 0.0207476169
Iter: 107 loss: 0.0207468048
Iter: 108 loss: 0.0207458399
Iter: 109 loss: 0.0207494535
Iter: 110 loss: 0.0207456015
Iter: 111 loss: 0.0207449552
Iter: 112 loss: 0.0207464118
Iter: 113 loss: 0.0207447093
Iter: 114 loss: 0.020744089
Iter: 115 loss: 0.020745866
Iter: 116 loss: 0.0207438953
Iter: 117 loss: 0.0207434148
Iter: 118 loss: 0.0207480416
Iter: 119 loss: 0.0207434
Iter: 120 loss: 0.0207430795
Iter: 121 loss: 0.0207434539
Iter: 122 loss: 0.0207429081
Iter: 123 loss: 0.0207426082
Iter: 124 loss: 0.020744931
Iter: 125 loss: 0.0207425877
Iter: 126 loss: 0.0207424778
Iter: 127 loss: 0.0207424723
Iter: 128 loss: 0.0207423605
Iter: 129 loss: 0.0207429603
Iter: 130 loss: 0.0207423456
Iter: 131 loss: 0.0207422916
Iter: 132 loss: 0.0207422096
Iter: 133 loss: 0.0207422115
Iter: 134 loss: 0.0207421351
Iter: 135 loss: 0.0207427591
Iter: 136 loss: 0.0207421314
Iter: 137 loss: 0.0207420699
Iter: 138 loss: 0.0207421146
Iter: 139 loss: 0.020742029
Iter: 140 loss: 0.0207419731
Iter: 141 loss: 0.0207420252
Iter: 142 loss: 0.0207419377
Iter: 143 loss: 0.0207418874
Iter: 144 loss: 0.0207421
Iter: 145 loss: 0.0207418744
Iter: 146 loss: 0.0207418315
Iter: 147 loss: 0.0207419787
Iter: 148 loss: 0.0207418259
Iter: 149 loss: 0.0207417924
Iter: 150 loss: 0.0207419246
Iter: 151 loss: 0.0207417868
Iter: 152 loss: 0.0207417607
Iter: 153 loss: 0.0207419097
Iter: 154 loss: 0.020741757
Iter: 155 loss: 0.0207417365
Iter: 156 loss: 0.0207417775
Iter: 157 loss: 0.0207417291
Iter: 158 loss: 0.0207417198
Iter: 159 loss: 0.0207418352
Iter: 160 loss: 0.0207417142
Iter: 161 loss: 0.0207417123
Iter: 162 loss: 0.0207417086
Iter: 163 loss: 0.0207417086
Iter: 164 loss: 0.020741703
Iter: 165 loss: 0.0207417794
Iter: 166 loss: 0.0207417011
Iter: 167 loss: 0.02074169
Iter: 168 loss: 0.0207417198
Iter: 169 loss: 0.02074169
Iter: 170 loss: 0.0207416844
Iter: 171 loss: 0.020741716
Iter: 172 loss: 0.02074169
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3
+ date
Tue Oct 27 21:07:20 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi2.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 3 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfb9e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfbfaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfbfa488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfbdbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfb2f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfb42840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfab16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfadf488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfb2fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfb2fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfa4b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df9f46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df9f48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91dfa15950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df9f40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df986620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df9c79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df9f4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df8fa9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df91b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df91b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df8cff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df888840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df829840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df832598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df8501e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df819510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df7c4268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df7c42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df7cee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df78f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df74c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df74cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df7658c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df765730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91df6d86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.040793255
Iter: 2 loss: 0.423537672
Iter: 3 loss: 0.318608493
Iter: 4 loss: 0.159422785
Iter: 5 loss: 0.113048568
Iter: 6 loss: 0.0534575284
Iter: 7 loss: 0.0396117605
Iter: 8 loss: 0.031727057
Iter: 9 loss: 0.07856296
Iter: 10 loss: 0.0297207478
Iter: 11 loss: 0.0577137917
Iter: 12 loss: 0.0277012587
Iter: 13 loss: 0.0269347206
Iter: 14 loss: 0.0248286501
Iter: 15 loss: 0.0243887212
Iter: 16 loss: 0.0243229698
Iter: 17 loss: 0.0241945703
Iter: 18 loss: 0.0238609295
Iter: 19 loss: 0.0265474916
Iter: 20 loss: 0.0237984248
Iter: 21 loss: 0.0235057883
Iter: 22 loss: 0.0250709709
Iter: 23 loss: 0.023477817
Iter: 24 loss: 0.0234427601
Iter: 25 loss: 0.0233908258
Iter: 26 loss: 0.023389373
Iter: 27 loss: 0.0233573969
Iter: 28 loss: 0.0233981423
Iter: 29 loss: 0.0233412385
Iter: 30 loss: 0.0233192816
Iter: 31 loss: 0.0233782828
Iter: 32 loss: 0.0233119689
Iter: 33 loss: 0.0233041123
Iter: 34 loss: 0.0233291797
Iter: 35 loss: 0.0233018734
Iter: 36 loss: 0.0232954752
Iter: 37 loss: 0.0233238861
Iter: 38 loss: 0.0232942067
Iter: 39 loss: 0.0232893042
Iter: 40 loss: 0.0233147815
Iter: 41 loss: 0.0232885405
Iter: 42 loss: 0.023286052
Iter: 43 loss: 0.0232964959
Iter: 44 loss: 0.0232855268
Iter: 45 loss: 0.0232839901
Iter: 46 loss: 0.0232880227
Iter: 47 loss: 0.0232834686
Iter: 48 loss: 0.0232822858
Iter: 49 loss: 0.023288751
Iter: 50 loss: 0.0232821126
Iter: 51 loss: 0.0232814
Iter: 52 loss: 0.0232833587
Iter: 53 loss: 0.0232811719
Iter: 54 loss: 0.023280587
Iter: 55 loss: 0.0232821386
Iter: 56 loss: 0.0232803971
Iter: 57 loss: 0.0232799053
Iter: 58 loss: 0.0232840441
Iter: 59 loss: 0.0232798681
Iter: 60 loss: 0.0232799295
Iter: 61 loss: 0.0232797302
Iter: 62 loss: 0.0232796296
Iter: 63 loss: 0.0232793353
Iter: 64 loss: 0.0232805721
Iter: 65 loss: 0.0232792199
Iter: 66 loss: 0.0232789516
Iter: 67 loss: 0.0232801214
Iter: 68 loss: 0.0232788883
Iter: 69 loss: 0.0232786685
Iter: 70 loss: 0.0232793596
Iter: 71 loss: 0.0232786052
Iter: 72 loss: 0.0232784152
Iter: 73 loss: 0.0232790951
Iter: 74 loss: 0.0232783724
Iter: 75 loss: 0.0232782196
Iter: 76 loss: 0.0232795179
Iter: 77 loss: 0.0232782178
Iter: 78 loss: 0.0232781135
Iter: 79 loss: 0.0232782513
Iter: 80 loss: 0.023278065
Iter: 81 loss: 0.0232779644
Iter: 82 loss: 0.023278391
Iter: 83 loss: 0.0232779477
Iter: 84 loss: 0.0232778788
Iter: 85 loss: 0.0232782289
Iter: 86 loss: 0.023277862
Iter: 87 loss: 0.0232778117
Iter: 88 loss: 0.0232779309
Iter: 89 loss: 0.0232777968
Iter: 90 loss: 0.0232777484
Iter: 91 loss: 0.0232778657
Iter: 92 loss: 0.0232777353
Iter: 93 loss: 0.0232777297
Iter: 94 loss: 0.0232777148
Iter: 95 loss: 0.0232777055
Iter: 96 loss: 0.0232777093
Iter: 97 loss: 0.0232776925
Iter: 98 loss: 0.023277685
Iter: 99 loss: 0.0232776646
Iter: 100 loss: 0.0232780799
Iter: 101 loss: 0.0232776627
Iter: 102 loss: 0.0232776515
Iter: 103 loss: 0.0232777689
Iter: 104 loss: 0.0232776515
Iter: 105 loss: 0.0232776385
Iter: 106 loss: 0.0232776664
Iter: 107 loss: 0.0232776366
Iter: 108 loss: 0.0232776348
Iter: 109 loss: 0.023277672
Iter: 110 loss: 0.0232776292
Iter: 111 loss: 0.0232776236
Iter: 112 loss: 0.0232776608
Iter: 113 loss: 0.0232776236
Iter: 114 loss: 0.0232776236
Iter: 115 loss: 0.0232776273
Iter: 116 loss: 0.0232776199
Iter: 117 loss: 0.0232776143
Iter: 118 loss: 0.0232776292
Iter: 119 loss: 0.023277618
Iter: 120 loss: 0.0232776143
Iter: 121 loss: 0.023277631
Iter: 122 loss: 0.023277618
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi3_phi3/k2
+ for fn in f1 f2
+ case $fn in
+ OPT=--alpha
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0
+ date
Tue Oct 27 21:07:53 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 2 --alpha 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff295f6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff547fb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff295da488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29632158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff295fb048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff296326a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff2956b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29515730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29515d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff294e3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29515b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff294a7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff294a76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff2940e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff294a7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff293b9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff293ec6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff293ece18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff2938f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff292fcae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff2931d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff292bfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff292bfb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff2929ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff292b3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff292b36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29258a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29231378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29231e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff291ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff291ce378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff291862f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29149488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29149d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff29149840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7eff290bb400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00233044475
Iter: 2 loss: 0.00231998088
Iter: 3 loss: 0.00227895356
Iter: 4 loss: 0.00209374703
Iter: 5 loss: 0.00167412788
Iter: 6 loss: 0.00167407235
Iter: 7 loss: 0.00131531223
Iter: 8 loss: 0.00515940366
Iter: 9 loss: 0.00130112283
Iter: 10 loss: 0.00110761472
Iter: 11 loss: 0.00142831
Iter: 12 loss: 0.00101917365
Iter: 13 loss: 0.000856153667
Iter: 14 loss: 0.00274288794
Iter: 15 loss: 0.00085418782
Iter: 16 loss: 0.000747537182
Iter: 17 loss: 0.000779167574
Iter: 18 loss: 0.000670294161
Iter: 19 loss: 0.000567935174
Iter: 20 loss: 0.000887474744
Iter: 21 loss: 0.000537778833
Iter: 22 loss: 0.000473404303
Iter: 23 loss: 0.000472663494
Iter: 24 loss: 0.000429061
Iter: 25 loss: 0.000399166602
Iter: 26 loss: 0.000383236504
Iter: 27 loss: 0.000334600627
Iter: 28 loss: 0.000463095406
Iter: 29 loss: 0.000318114704
Iter: 30 loss: 0.00028696534
Iter: 31 loss: 0.000776853238
Iter: 32 loss: 0.000286960625
Iter: 33 loss: 0.000261418492
Iter: 34 loss: 0.000319787388
Iter: 35 loss: 0.000251862
Iter: 36 loss: 0.000232679813
Iter: 37 loss: 0.000238564709
Iter: 38 loss: 0.000218968722
Iter: 39 loss: 0.000199618182
Iter: 40 loss: 0.000277305691
Iter: 41 loss: 0.000195243716
Iter: 42 loss: 0.000183102326
Iter: 43 loss: 0.000183090713
Iter: 44 loss: 0.000173187393
Iter: 45 loss: 0.000181020485
Iter: 46 loss: 0.000167207443
Iter: 47 loss: 0.000158215262
Iter: 48 loss: 0.000182890202
Iter: 49 loss: 0.000155263668
Iter: 50 loss: 0.000147074024
Iter: 51 loss: 0.000206518394
Iter: 52 loss: 0.000146406412
Iter: 53 loss: 0.000140981923
Iter: 54 loss: 0.000140017815
Iter: 55 loss: 0.000136336486
Iter: 56 loss: 0.000130946588
Iter: 57 loss: 0.000186010118
Iter: 58 loss: 0.000130787856
Iter: 59 loss: 0.000126401064
Iter: 60 loss: 0.000145146361
Iter: 61 loss: 0.000125493621
Iter: 62 loss: 0.000122351223
Iter: 63 loss: 0.000120924204
Iter: 64 loss: 0.000119352218
Iter: 65 loss: 0.00011616043
Iter: 66 loss: 0.000153596266
Iter: 67 loss: 0.000116113617
Iter: 68 loss: 0.000113362716
Iter: 69 loss: 0.000122676982
Iter: 70 loss: 0.000112622343
Iter: 71 loss: 0.000110657624
Iter: 72 loss: 0.000109264613
Iter: 73 loss: 0.00010857395
Iter: 74 loss: 0.000105972853
Iter: 75 loss: 0.000114730909
Iter: 76 loss: 0.000105267798
Iter: 77 loss: 0.000103092876
Iter: 78 loss: 0.00011202789
Iter: 79 loss: 0.000102618884
Iter: 80 loss: 0.000101149926
Iter: 81 loss: 0.000123729289
Iter: 82 loss: 0.000101149431
Iter: 83 loss: 9.99259792e-05
Iter: 84 loss: 0.000101319849
Iter: 85 loss: 9.92685455e-05
Iter: 86 loss: 9.81451885e-05
Iter: 87 loss: 9.87539242e-05
Iter: 88 loss: 9.7406526e-05
Iter: 89 loss: 9.62753693e-05
Iter: 90 loss: 0.000108428889
Iter: 91 loss: 9.62482882e-05
Iter: 92 loss: 9.52999908e-05
Iter: 93 loss: 9.67107189e-05
Iter: 94 loss: 9.48454544e-05
Iter: 95 loss: 9.39869642e-05
Iter: 96 loss: 9.61601909e-05
Iter: 97 loss: 9.36895522e-05
Iter: 98 loss: 9.27804722e-05
Iter: 99 loss: 9.78197786e-05
Iter: 100 loss: 9.26490175e-05
Iter: 101 loss: 9.19796439e-05
Iter: 102 loss: 9.19139493e-05
Iter: 103 loss: 9.142403e-05
Iter: 104 loss: 9.07046633e-05
Iter: 105 loss: 9.88635e-05
Iter: 106 loss: 9.06920468e-05
Iter: 107 loss: 9.00478335e-05
Iter: 108 loss: 9.05903726e-05
Iter: 109 loss: 8.96654674e-05
Iter: 110 loss: 8.90454103e-05
Iter: 111 loss: 8.9053734e-05
Iter: 112 loss: 8.85519403e-05
Iter: 113 loss: 8.79435684e-05
Iter: 114 loss: 9.70225956e-05
Iter: 115 loss: 8.79429863e-05
Iter: 116 loss: 8.73882236e-05
Iter: 117 loss: 8.79434665e-05
Iter: 118 loss: 8.70762597e-05
Iter: 119 loss: 8.65687762e-05
Iter: 120 loss: 8.64288595e-05
Iter: 121 loss: 8.61176959e-05
Iter: 122 loss: 8.54558311e-05
Iter: 123 loss: 8.77817365e-05
Iter: 124 loss: 8.52842059e-05
Iter: 125 loss: 8.47528718e-05
Iter: 126 loss: 8.87938368e-05
Iter: 127 loss: 8.47121701e-05
Iter: 128 loss: 8.42536e-05
Iter: 129 loss: 8.74490579e-05
Iter: 130 loss: 8.42113222e-05
Iter: 131 loss: 8.38936176e-05
Iter: 132 loss: 8.36718827e-05
Iter: 133 loss: 8.35583414e-05
Iter: 134 loss: 8.31471843e-05
Iter: 135 loss: 8.63260866e-05
Iter: 136 loss: 8.31169527e-05
Iter: 137 loss: 8.27549957e-05
Iter: 138 loss: 8.38818087e-05
Iter: 139 loss: 8.26493779e-05
Iter: 140 loss: 8.23533774e-05
Iter: 141 loss: 8.26150499e-05
Iter: 142 loss: 8.21803624e-05
Iter: 143 loss: 8.18455228e-05
Iter: 144 loss: 8.45949e-05
Iter: 145 loss: 8.18245171e-05
Iter: 146 loss: 8.15704e-05
Iter: 147 loss: 8.14948e-05
Iter: 148 loss: 8.13423685e-05
Iter: 149 loss: 8.10231e-05
Iter: 150 loss: 8.17982655e-05
Iter: 151 loss: 8.09089252e-05
Iter: 152 loss: 8.06563912e-05
Iter: 153 loss: 8.06563e-05
Iter: 154 loss: 8.04640877e-05
Iter: 155 loss: 8.03503935e-05
Iter: 156 loss: 8.02698341e-05
Iter: 157 loss: 8.00284761e-05
Iter: 158 loss: 8.06084136e-05
Iter: 159 loss: 7.99412956e-05
Iter: 160 loss: 7.97430694e-05
Iter: 161 loss: 8.28255143e-05
Iter: 162 loss: 7.97430112e-05
Iter: 163 loss: 7.96021632e-05
Iter: 164 loss: 7.94203661e-05
Iter: 165 loss: 7.94077205e-05
Iter: 166 loss: 7.91841885e-05
Iter: 167 loss: 7.96030654e-05
Iter: 168 loss: 7.90891936e-05
Iter: 169 loss: 7.88755278e-05
Iter: 170 loss: 7.98425608e-05
Iter: 171 loss: 7.88343314e-05
Iter: 172 loss: 7.86848614e-05
Iter: 173 loss: 7.86849e-05
Iter: 174 loss: 7.85670272e-05
Iter: 175 loss: 7.85362499e-05
Iter: 176 loss: 7.84627191e-05
Iter: 177 loss: 7.83304131e-05
Iter: 178 loss: 7.86821911e-05
Iter: 179 loss: 7.8286088e-05
Iter: 180 loss: 7.81633498e-05
Iter: 181 loss: 7.93123545e-05
Iter: 182 loss: 7.81583803e-05
Iter: 183 loss: 7.80690534e-05
Iter: 184 loss: 7.80710761e-05
Iter: 185 loss: 7.79979455e-05
Iter: 186 loss: 7.79003312e-05
Iter: 187 loss: 7.86756282e-05
Iter: 188 loss: 7.78935573e-05
Iter: 189 loss: 7.78071626e-05
Iter: 190 loss: 7.78996036e-05
Iter: 191 loss: 7.77595924e-05
Iter: 192 loss: 7.76802844e-05
Iter: 193 loss: 7.77297464e-05
Iter: 194 loss: 7.76296656e-05
Iter: 195 loss: 7.75591907e-05
Iter: 196 loss: 7.85940938e-05
Iter: 197 loss: 7.75591907e-05
Iter: 198 loss: 7.74969812e-05
Iter: 199 loss: 7.75920635e-05
Iter: 200 loss: 7.746763e-05
Iter: 201 loss: 7.74129439e-05
Iter: 202 loss: 7.74228101e-05
Iter: 203 loss: 7.73719803e-05
Iter: 204 loss: 7.7320452e-05
Iter: 205 loss: 7.80976043e-05
Iter: 206 loss: 7.73205466e-05
Iter: 207 loss: 7.72761414e-05
Iter: 208 loss: 7.73138163e-05
Iter: 209 loss: 7.72498315e-05
Iter: 210 loss: 7.72078638e-05
Iter: 211 loss: 7.72086496e-05
Iter: 212 loss: 7.71744526e-05
Iter: 213 loss: 7.71236446e-05
Iter: 214 loss: 7.73027132e-05
Iter: 215 loss: 7.71103514e-05
Iter: 216 loss: 7.70748e-05
Iter: 217 loss: 7.74478176e-05
Iter: 218 loss: 7.70738188e-05
Iter: 219 loss: 7.70427869e-05
Iter: 220 loss: 7.71803e-05
Iter: 221 loss: 7.70365805e-05
Iter: 222 loss: 7.70142942e-05
Iter: 223 loss: 7.70047845e-05
Iter: 224 loss: 7.69933104e-05
Iter: 225 loss: 7.69690669e-05
Iter: 226 loss: 7.72340645e-05
Iter: 227 loss: 7.69685867e-05
Iter: 228 loss: 7.69475737e-05
Iter: 229 loss: 7.69901235e-05
Iter: 230 loss: 7.69391336e-05
Iter: 231 loss: 7.69213802e-05
Iter: 232 loss: 7.69505568e-05
Iter: 233 loss: 7.69132457e-05
Iter: 234 loss: 7.68943719e-05
Iter: 235 loss: 7.70272818e-05
Iter: 236 loss: 7.68926402e-05
Iter: 237 loss: 7.68788741e-05
Iter: 238 loss: 7.68749451e-05
Iter: 239 loss: 7.6866374e-05
Iter: 240 loss: 7.68498721e-05
Iter: 241 loss: 7.69215694e-05
Iter: 242 loss: 7.6846547e-05
Iter: 243 loss: 7.68334794e-05
Iter: 244 loss: 7.69920662e-05
Iter: 245 loss: 7.68333557e-05
Iter: 246 loss: 7.68243626e-05
Iter: 247 loss: 7.68176687e-05
Iter: 248 loss: 7.68147875e-05
Iter: 249 loss: 7.68032842e-05
Iter: 250 loss: 7.68532045e-05
Iter: 251 loss: 7.68010941e-05
Iter: 252 loss: 7.67917081e-05
Iter: 253 loss: 7.68946484e-05
Iter: 254 loss: 7.67915044e-05
Iter: 255 loss: 7.67853271e-05
Iter: 256 loss: 7.67793754e-05
Iter: 257 loss: 7.67779e-05
Iter: 258 loss: 7.67691527e-05
Iter: 259 loss: 7.67858146e-05
Iter: 260 loss: 7.67655074e-05
Iter: 261 loss: 7.67573802e-05
Iter: 262 loss: 7.6795e-05
Iter: 263 loss: 7.67560123e-05
Iter: 264 loss: 7.67508e-05
Iter: 265 loss: 7.67507154e-05
Iter: 266 loss: 7.67466336e-05
Iter: 267 loss: 7.67452e-05
Iter: 268 loss: 7.67429e-05
Iter: 269 loss: 7.67380407e-05
Iter: 270 loss: 7.67460588e-05
Iter: 271 loss: 7.67358433e-05
Iter: 272 loss: 7.67321253e-05
Iter: 273 loss: 7.67321399e-05
Iter: 274 loss: 7.67292076e-05
Iter: 275 loss: 7.6727767e-05
Iter: 276 loss: 7.67263555e-05
Iter: 277 loss: 7.67230813e-05
Iter: 278 loss: 7.67362e-05
Iter: 279 loss: 7.67222082e-05
Iter: 280 loss: 7.67192396e-05
Iter: 281 loss: 7.67417077e-05
Iter: 282 loss: 7.67189122e-05
Iter: 283 loss: 7.67169404e-05
Iter: 284 loss: 7.67166057e-05
Iter: 285 loss: 7.67151141e-05
Iter: 286 loss: 7.67129823e-05
Iter: 287 loss: 7.67405e-05
Iter: 288 loss: 7.67130696e-05
Iter: 289 loss: 7.67112579e-05
Iter: 290 loss: 7.67127058e-05
Iter: 291 loss: 7.67102e-05
Iter: 292 loss: 7.67086312e-05
Iter: 293 loss: 7.67100573e-05
Iter: 294 loss: 7.67076272e-05
Iter: 295 loss: 7.67062447e-05
Iter: 296 loss: 7.67061938e-05
Iter: 297 loss: 7.67051242e-05
Iter: 298 loss: 7.67048405e-05
Iter: 299 loss: 7.67041347e-05
Iter: 300 loss: 7.67028396e-05
Iter: 301 loss: 7.67036909e-05
Iter: 302 loss: 7.67020319e-05
Iter: 303 loss: 7.6700635e-05
Iter: 304 loss: 7.67052188e-05
Iter: 305 loss: 7.67002639e-05
Iter: 306 loss: 7.66994e-05
Iter: 307 loss: 7.66994199e-05
Iter: 308 loss: 7.66986777e-05
Iter: 309 loss: 7.66987068e-05
Iter: 310 loss: 7.66981393e-05
Iter: 311 loss: 7.6697339e-05
Iter: 312 loss: 7.66981248e-05
Iter: 313 loss: 7.66968296e-05
Iter: 314 loss: 7.6696233e-05
Iter: 315 loss: 7.67064193e-05
Iter: 316 loss: 7.66962621e-05
Iter: 317 loss: 7.66956437e-05
Iter: 318 loss: 7.66961821e-05
Iter: 319 loss: 7.6695389e-05
Iter: 320 loss: 7.66947778e-05
Iter: 321 loss: 7.66952726e-05
Iter: 322 loss: 7.66945668e-05
Iter: 323 loss: 7.6694072e-05
Iter: 324 loss: 7.66974554e-05
Iter: 325 loss: 7.6694e-05
Iter: 326 loss: 7.66936e-05
Iter: 327 loss: 7.66962039e-05
Iter: 328 loss: 7.669349e-05
Iter: 329 loss: 7.66931917e-05
Iter: 330 loss: 7.66933954e-05
Iter: 331 loss: 7.66929879e-05
Iter: 332 loss: 7.66926823e-05
Iter: 333 loss: 7.66954618e-05
Iter: 334 loss: 7.66926169e-05
Iter: 335 loss: 7.66923185e-05
Iter: 336 loss: 7.66924277e-05
Iter: 337 loss: 7.66923113e-05
Iter: 338 loss: 7.6692013e-05
Iter: 339 loss: 7.66937592e-05
Iter: 340 loss: 7.66919838e-05
Iter: 341 loss: 7.66916783e-05
Iter: 342 loss: 7.66921657e-05
Iter: 343 loss: 7.66916201e-05
Iter: 344 loss: 7.66914236e-05
Iter: 345 loss: 7.6691409e-05
Iter: 346 loss: 7.66912417e-05
Iter: 347 loss: 7.66909725e-05
Iter: 348 loss: 7.6692013e-05
Iter: 349 loss: 7.66910234e-05
Iter: 350 loss: 7.66908051e-05
Iter: 351 loss: 7.66908051e-05
Iter: 352 loss: 7.6690696e-05
Iter: 353 loss: 7.66907397e-05
Iter: 354 loss: 7.66906305e-05
Iter: 355 loss: 7.6690485e-05
Iter: 356 loss: 7.66904268e-05
Iter: 357 loss: 7.66903904e-05
Iter: 358 loss: 7.66902667e-05
Iter: 359 loss: 7.66914673e-05
Iter: 360 loss: 7.66902376e-05
Iter: 361 loss: 7.66901867e-05
Iter: 362 loss: 7.66905723e-05
Iter: 363 loss: 7.6690194e-05
Iter: 364 loss: 7.66900048e-05
Iter: 365 loss: 7.66901067e-05
Iter: 366 loss: 7.66899248e-05
Iter: 367 loss: 7.66899393e-05
Iter: 368 loss: 7.66903249e-05
Iter: 369 loss: 7.66899175e-05
Iter: 370 loss: 7.66897574e-05
Iter: 371 loss: 7.66906596e-05
Iter: 372 loss: 7.66897865e-05
Iter: 373 loss: 7.6689852e-05
Iter: 374 loss: 7.66898156e-05
Iter: 375 loss: 7.66897356e-05
Iter: 376 loss: 7.66896555e-05
Iter: 377 loss: 7.66899611e-05
Iter: 378 loss: 7.66896192e-05
Iter: 379 loss: 7.668951e-05
Iter: 380 loss: 7.66898593e-05
Iter: 381 loss: 7.66895828e-05
Iter: 382 loss: 7.66895246e-05
Iter: 383 loss: 7.66895828e-05
Iter: 384 loss: 7.668951e-05
Iter: 385 loss: 7.66894809e-05
Iter: 386 loss: 7.6689983e-05
Iter: 387 loss: 7.66894809e-05
Iter: 388 loss: 7.66893791e-05
Iter: 389 loss: 7.66893791e-05
Iter: 390 loss: 7.66894591e-05
Iter: 391 loss: 7.66893791e-05
Iter: 392 loss: 7.66894736e-05
Iter: 393 loss: 7.66893791e-05
Iter: 394 loss: 7.66892845e-05
Iter: 395 loss: 7.66895246e-05
Iter: 396 loss: 7.66892408e-05
Iter: 397 loss: 7.66893136e-05
Iter: 398 loss: 7.66897647e-05
Iter: 399 loss: 7.66893208e-05
Iter: 400 loss: 7.66892408e-05
Iter: 401 loss: 7.66892554e-05
Iter: 402 loss: 7.66891681e-05
Iter: 403 loss: 7.66892044e-05
Iter: 404 loss: 7.66893354e-05
Iter: 405 loss: 7.66892408e-05
Iter: 406 loss: 7.66891608e-05
Iter: 407 loss: 7.66891899e-05
Iter: 408 loss: 7.66891462e-05
Iter: 409 loss: 7.66892e-05
Iter: 410 loss: 7.66891753e-05
Iter: 411 loss: 7.66891e-05
Iter: 412 loss: 7.66892335e-05
Iter: 413 loss: 7.66892044e-05
Iter: 414 loss: 7.66891462e-05
Iter: 415 loss: 7.66892917e-05
Iter: 416 loss: 7.66891e-05
Iter: 417 loss: 7.66891317e-05
Iter: 418 loss: 7.66891608e-05
Iter: 419 loss: 7.66891317e-05
Iter: 420 loss: 7.6689088e-05
Iter: 421 loss: 7.66891e-05
Iter: 422 loss: 7.66890444e-05
Iter: 423 loss: 7.66890516e-05
Iter: 424 loss: 7.66890444e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.4
+ date
Tue Oct 27 21:13:45 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 2 --alpha 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdffb8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdff6cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdff6c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdff4e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdff4e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdff4eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfe99ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfe6c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfe6d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfe39598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfe39ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfde61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfda6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfda6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfdd2e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfdd2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfd97488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfd519d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfd02730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfd51c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfccd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfccd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfc72d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfc31268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfc4b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfbf1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfbf3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfbf1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfbbb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfbbb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfb88158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfb88400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfb39a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfb39bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfb39f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdbdfb16a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0602035969
Iter: 2 loss: 0.0589810386
Iter: 3 loss: 0.0542740263
Iter: 4 loss: 0.0349971615
Iter: 5 loss: 0.0830576718
Iter: 6 loss: 0.0226923469
Iter: 7 loss: 0.00979506783
Iter: 8 loss: 0.00947288424
Iter: 9 loss: 0.00572339818
Iter: 10 loss: 0.00569025706
Iter: 11 loss: 0.0038834156
Iter: 12 loss: 0.0122798979
Iter: 13 loss: 0.00360498345
Iter: 14 loss: 0.00267133908
Iter: 15 loss: 0.0069684172
Iter: 16 loss: 0.00244762166
Iter: 17 loss: 0.00190016849
Iter: 18 loss: 0.00805567671
Iter: 19 loss: 0.00188803789
Iter: 20 loss: 0.00152560556
Iter: 21 loss: 0.00252760481
Iter: 22 loss: 0.00140903087
Iter: 23 loss: 0.00115997007
Iter: 24 loss: 0.00203897618
Iter: 25 loss: 0.00109296804
Iter: 26 loss: 0.000914419419
Iter: 27 loss: 0.00195406587
Iter: 28 loss: 0.00089307921
Iter: 29 loss: 0.000780784758
Iter: 30 loss: 0.00137779699
Iter: 31 loss: 0.000762263837
Iter: 32 loss: 0.000680816709
Iter: 33 loss: 0.00104154635
Iter: 34 loss: 0.000664488471
Iter: 35 loss: 0.000598414452
Iter: 36 loss: 0.000820347108
Iter: 37 loss: 0.000580992317
Iter: 38 loss: 0.000529747165
Iter: 39 loss: 0.000683136284
Iter: 40 loss: 0.000514072715
Iter: 41 loss: 0.000473410473
Iter: 42 loss: 0.000562270579
Iter: 43 loss: 0.000457609363
Iter: 44 loss: 0.000423869613
Iter: 45 loss: 0.000694309943
Iter: 46 loss: 0.00042170388
Iter: 47 loss: 0.000396993099
Iter: 48 loss: 0.000472350483
Iter: 49 loss: 0.00038963469
Iter: 50 loss: 0.000368930341
Iter: 51 loss: 0.000400823454
Iter: 52 loss: 0.000359044119
Iter: 53 loss: 0.000340079976
Iter: 54 loss: 0.000410593027
Iter: 55 loss: 0.00033550142
Iter: 56 loss: 0.00032084214
Iter: 57 loss: 0.000454819528
Iter: 58 loss: 0.000320154883
Iter: 59 loss: 0.000309062452
Iter: 60 loss: 0.000327727757
Iter: 61 loss: 0.000304042624
Iter: 62 loss: 0.000294407277
Iter: 63 loss: 0.000325928093
Iter: 64 loss: 0.000291704666
Iter: 65 loss: 0.000282812282
Iter: 66 loss: 0.000345841981
Iter: 67 loss: 0.000282033376
Iter: 68 loss: 0.000275422761
Iter: 69 loss: 0.000279012194
Iter: 70 loss: 0.000271051
Iter: 71 loss: 0.000264181523
Iter: 72 loss: 0.000287029659
Iter: 73 loss: 0.000262315094
Iter: 74 loss: 0.000256107509
Iter: 75 loss: 0.000276657316
Iter: 76 loss: 0.000254376151
Iter: 77 loss: 0.000249083
Iter: 78 loss: 0.000273284706
Iter: 79 loss: 0.0002480775
Iter: 80 loss: 0.000243882649
Iter: 81 loss: 0.000260823173
Iter: 82 loss: 0.00024295121
Iter: 83 loss: 0.00023915674
Iter: 84 loss: 0.000247311429
Iter: 85 loss: 0.000237672255
Iter: 86 loss: 0.000234343519
Iter: 87 loss: 0.000240977053
Iter: 88 loss: 0.000232975377
Iter: 89 loss: 0.000229808327
Iter: 90 loss: 0.00024523359
Iter: 91 loss: 0.000229257261
Iter: 92 loss: 0.000226492528
Iter: 93 loss: 0.00023887711
Iter: 94 loss: 0.000225948956
Iter: 95 loss: 0.000223750976
Iter: 96 loss: 0.000225755764
Iter: 97 loss: 0.000222474424
Iter: 98 loss: 0.000220148271
Iter: 99 loss: 0.000229038618
Iter: 100 loss: 0.000219594134
Iter: 101 loss: 0.000217789275
Iter: 102 loss: 0.000235557731
Iter: 103 loss: 0.000217728681
Iter: 104 loss: 0.000216336761
Iter: 105 loss: 0.000217484485
Iter: 106 loss: 0.000215504857
Iter: 107 loss: 0.0002141023
Iter: 108 loss: 0.00021827512
Iter: 109 loss: 0.000213677151
Iter: 110 loss: 0.000212409199
Iter: 111 loss: 0.000220150818
Iter: 112 loss: 0.000212255458
Iter: 113 loss: 0.000211246894
Iter: 114 loss: 0.000211670485
Iter: 115 loss: 0.000210554092
Iter: 116 loss: 0.0002094628
Iter: 117 loss: 0.000211995721
Iter: 118 loss: 0.00020905961
Iter: 119 loss: 0.000208055761
Iter: 120 loss: 0.000213334148
Iter: 121 loss: 0.000207898498
Iter: 122 loss: 0.000207069374
Iter: 123 loss: 0.000211757084
Iter: 124 loss: 0.00020695469
Iter: 125 loss: 0.000206288532
Iter: 126 loss: 0.000207564954
Iter: 127 loss: 0.000206009499
Iter: 128 loss: 0.000205382647
Iter: 129 loss: 0.00020739359
Iter: 130 loss: 0.00020520392
Iter: 131 loss: 0.000204626136
Iter: 132 loss: 0.000205993536
Iter: 133 loss: 0.000204415468
Iter: 134 loss: 0.000203895208
Iter: 135 loss: 0.000205243879
Iter: 136 loss: 0.000203717733
Iter: 137 loss: 0.000203254647
Iter: 138 loss: 0.00020709596
Iter: 139 loss: 0.000203226518
Iter: 140 loss: 0.000202863928
Iter: 141 loss: 0.000203482021
Iter: 142 loss: 0.000202701194
Iter: 143 loss: 0.000202331546
Iter: 144 loss: 0.000203492018
Iter: 145 loss: 0.000202224648
Iter: 146 loss: 0.00020188553
Iter: 147 loss: 0.000203198928
Iter: 148 loss: 0.000201806091
Iter: 149 loss: 0.000201507748
Iter: 150 loss: 0.000201723058
Iter: 151 loss: 0.00020132339
Iter: 152 loss: 0.000201010742
Iter: 153 loss: 0.000202040406
Iter: 154 loss: 0.000200924085
Iter: 155 loss: 0.000200649331
Iter: 156 loss: 0.000202552823
Iter: 157 loss: 0.000200623443
Iter: 158 loss: 0.000200399722
Iter: 159 loss: 0.000200749695
Iter: 160 loss: 0.000200294511
Iter: 161 loss: 0.000200075505
Iter: 162 loss: 0.000200364477
Iter: 163 loss: 0.00019996459
Iter: 164 loss: 0.00019974832
Iter: 165 loss: 0.000200862254
Iter: 166 loss: 0.000199713366
Iter: 167 loss: 0.000199538452
Iter: 168 loss: 0.000200633542
Iter: 169 loss: 0.000199518487
Iter: 170 loss: 0.000199373375
Iter: 171 loss: 0.000199541129
Iter: 172 loss: 0.000199296075
Iter: 173 loss: 0.000199148228
Iter: 174 loss: 0.000199506729
Iter: 175 loss: 0.000199095171
Iter: 176 loss: 0.000198958121
Iter: 177 loss: 0.000199719419
Iter: 178 loss: 0.000198938331
Iter: 179 loss: 0.000198830065
Iter: 180 loss: 0.000199320755
Iter: 181 loss: 0.000198809284
Iter: 182 loss: 0.000198716152
Iter: 183 loss: 0.000198940223
Iter: 184 loss: 0.000198682552
Iter: 185 loss: 0.000198590089
Iter: 186 loss: 0.000198675189
Iter: 187 loss: 0.000198536698
Iter: 188 loss: 0.000198440277
Iter: 189 loss: 0.000198700494
Iter: 190 loss: 0.000198408292
Iter: 191 loss: 0.000198326248
Iter: 192 loss: 0.000199027301
Iter: 193 loss: 0.00019832165
Iter: 194 loss: 0.000198255264
Iter: 195 loss: 0.00019832165
Iter: 196 loss: 0.000198217633
Iter: 197 loss: 0.000198145601
Iter: 198 loss: 0.000198270835
Iter: 199 loss: 0.000198113645
Iter: 200 loss: 0.000198042602
Iter: 201 loss: 0.000198417867
Iter: 202 loss: 0.000198031717
Iter: 203 loss: 0.000197975809
Iter: 204 loss: 0.000198266556
Iter: 205 loss: 0.000197966903
Iter: 206 loss: 0.000197919377
Iter: 207 loss: 0.000197956164
Iter: 208 loss: 0.000197890593
Iter: 209 loss: 0.000197841378
Iter: 210 loss: 0.000198027366
Iter: 211 loss: 0.000197829591
Iter: 212 loss: 0.000197786489
Iter: 213 loss: 0.000198061098
Iter: 214 loss: 0.000197781686
Iter: 215 loss: 0.000197745714
Iter: 216 loss: 0.000197783316
Iter: 217 loss: 0.000197725851
Iter: 218 loss: 0.000197690679
Iter: 219 loss: 0.000197870395
Iter: 220 loss: 0.000197684887
Iter: 221 loss: 0.000197653091
Iter: 222 loss: 0.000197763176
Iter: 223 loss: 0.000197645044
Iter: 224 loss: 0.00019761725
Iter: 225 loss: 0.000197643531
Iter: 226 loss: 0.000197601621
Iter: 227 loss: 0.00019757243
Iter: 228 loss: 0.000197667745
Iter: 229 loss: 0.000197564455
Iter: 230 loss: 0.000197537156
Iter: 231 loss: 0.000197612273
Iter: 232 loss: 0.000197528294
Iter: 233 loss: 0.000197503105
Iter: 234 loss: 0.000197569301
Iter: 235 loss: 0.000197494461
Iter: 236 loss: 0.000197472167
Iter: 237 loss: 0.000197615911
Iter: 238 loss: 0.000197469635
Iter: 239 loss: 0.000197449946
Iter: 240 loss: 0.000197489659
Iter: 241 loss: 0.000197441856
Iter: 242 loss: 0.000197424408
Iter: 243 loss: 0.000197445246
Iter: 244 loss: 0.000197415153
Iter: 245 loss: 0.000197396468
Iter: 246 loss: 0.000197484158
Iter: 247 loss: 0.000197393092
Iter: 248 loss: 0.000197377958
Iter: 249 loss: 0.000197478686
Iter: 250 loss: 0.000197376707
Iter: 251 loss: 0.000197364338
Iter: 252 loss: 0.000197375601
Iter: 253 loss: 0.000197357382
Iter: 254 loss: 0.000197345216
Iter: 255 loss: 0.000197398476
Iter: 256 loss: 0.000197342946
Iter: 257 loss: 0.000197331246
Iter: 258 loss: 0.000197381014
Iter: 259 loss: 0.000197328787
Iter: 260 loss: 0.000197319459
Iter: 261 loss: 0.000197323927
Iter: 262 loss: 0.000197313377
Iter: 263 loss: 0.000197302506
Iter: 264 loss: 0.000197347908
Iter: 265 loss: 0.000197300251
Iter: 266 loss: 0.000197290443
Iter: 267 loss: 0.00019732544
Iter: 268 loss: 0.000197288216
Iter: 269 loss: 0.000197279791
Iter: 270 loss: 0.000197299116
Iter: 271 loss: 0.000197276793
Iter: 272 loss: 0.000197269415
Iter: 273 loss: 0.000197288115
Iter: 274 loss: 0.000197266694
Iter: 275 loss: 0.000197259214
Iter: 276 loss: 0.000197285874
Iter: 277 loss: 0.000197257454
Iter: 278 loss: 0.000197251065
Iter: 279 loss: 0.000197270798
Iter: 280 loss: 0.000197249072
Iter: 281 loss: 0.000197242698
Iter: 282 loss: 0.000197269284
Iter: 283 loss: 0.000197241519
Iter: 284 loss: 0.000197235873
Iter: 285 loss: 0.000197249232
Iter: 286 loss: 0.000197233923
Iter: 287 loss: 0.000197228685
Iter: 288 loss: 0.000197237023
Iter: 289 loss: 0.00019722656
Iter: 290 loss: 0.000197221932
Iter: 291 loss: 0.000197260073
Iter: 292 loss: 0.00019722186
Iter: 293 loss: 0.000197217945
Iter: 294 loss: 0.000197225265
Iter: 295 loss: 0.000197215937
Iter: 296 loss: 0.000197212677
Iter: 297 loss: 0.000197216781
Iter: 298 loss: 0.000197210582
Iter: 299 loss: 0.000197207104
Iter: 300 loss: 0.000197235699
Iter: 301 loss: 0.000197206886
Iter: 302 loss: 0.000197204
Iter: 303 loss: 0.000197205227
Iter: 304 loss: 0.000197202229
Iter: 305 loss: 0.000197198591
Iter: 306 loss: 0.000197206246
Iter: 307 loss: 0.000197197325
Iter: 308 loss: 0.000197194342
Iter: 309 loss: 0.000197203393
Iter: 310 loss: 0.00019719312
Iter: 311 loss: 0.000197190486
Iter: 312 loss: 0.000197206566
Iter: 313 loss: 0.000197190282
Iter: 314 loss: 0.000197187706
Iter: 315 loss: 0.000197194749
Iter: 316 loss: 0.000197187095
Iter: 317 loss: 0.000197184738
Iter: 318 loss: 0.000197190398
Iter: 319 loss: 0.00019718385
Iter: 320 loss: 0.00019718174
Iter: 321 loss: 0.000197188958
Iter: 322 loss: 0.000197181129
Iter: 323 loss: 0.000197179179
Iter: 324 loss: 0.000197185786
Iter: 325 loss: 0.000197178655
Iter: 326 loss: 0.000197177054
Iter: 327 loss: 0.000197183399
Iter: 328 loss: 0.000197176705
Iter: 329 loss: 0.000197174959
Iter: 330 loss: 0.000197179019
Iter: 331 loss: 0.000197174348
Iter: 332 loss: 0.000197172907
Iter: 333 loss: 0.000197177724
Iter: 334 loss: 0.000197172674
Iter: 335 loss: 0.000197171088
Iter: 336 loss: 0.000197176152
Iter: 337 loss: 0.000197170768
Iter: 338 loss: 0.000197169546
Iter: 339 loss: 0.000197170346
Iter: 340 loss: 0.000197168672
Iter: 341 loss: 0.000197167392
Iter: 342 loss: 0.000197172572
Iter: 343 loss: 0.000197167014
Iter: 344 loss: 0.000197166
Iter: 345 loss: 0.000197173445
Iter: 346 loss: 0.000197165806
Iter: 347 loss: 0.000197164991
Iter: 348 loss: 0.00019716598
Iter: 349 loss: 0.000197164467
Iter: 350 loss: 0.000197163376
Iter: 351 loss: 0.000197165078
Iter: 352 loss: 0.000197162823
Iter: 353 loss: 0.000197161833
Iter: 354 loss: 0.000197164714
Iter: 355 loss: 0.000197161717
Iter: 356 loss: 0.000197160698
Iter: 357 loss: 0.000197167785
Iter: 358 loss: 0.000197160698
Iter: 359 loss: 0.000197159912
Iter: 360 loss: 0.000197161586
Iter: 361 loss: 0.000197159708
Iter: 362 loss: 0.000197158981
Iter: 363 loss: 0.000197160785
Iter: 364 loss: 0.000197158748
Iter: 365 loss: 0.000197158122
Iter: 366 loss: 0.000197160407
Iter: 367 loss: 0.000197157948
Iter: 368 loss: 0.000197157526
Iter: 369 loss: 0.000197159505
Iter: 370 loss: 0.000197157409
Iter: 371 loss: 0.000197156944
Iter: 372 loss: 0.000197157991
Iter: 373 loss: 0.000197156827
Iter: 374 loss: 0.000197156187
Iter: 375 loss: 0.000197157
Iter: 376 loss: 0.00019715591
Iter: 377 loss: 0.000197155314
Iter: 378 loss: 0.000197157555
Iter: 379 loss: 0.000197155343
Iter: 380 loss: 0.000197154935
Iter: 381 loss: 0.000197156522
Iter: 382 loss: 0.000197154717
Iter: 383 loss: 0.000197154499
Iter: 384 loss: 0.000197155066
Iter: 385 loss: 0.000197154281
Iter: 386 loss: 0.000197153713
Iter: 387 loss: 0.00019715447
Iter: 388 loss: 0.000197153669
Iter: 389 loss: 0.000197153277
Iter: 390 loss: 0.00019715511
Iter: 391 loss: 0.000197153393
Iter: 392 loss: 0.000197153029
Iter: 393 loss: 0.000197154324
Iter: 394 loss: 0.000197152942
Iter: 395 loss: 0.000197152593
Iter: 396 loss: 0.000197152607
Iter: 397 loss: 0.000197152287
Iter: 398 loss: 0.000197151952
Iter: 399 loss: 0.0001971538
Iter: 400 loss: 0.00019715204
Iter: 401 loss: 0.000197151821
Iter: 402 loss: 0.000197153451
Iter: 403 loss: 0.000197151938
Iter: 404 loss: 0.000197151603
Iter: 405 loss: 0.000197151676
Iter: 406 loss: 0.000197151574
Iter: 407 loss: 0.000197151254
Iter: 408 loss: 0.000197152083
Iter: 409 loss: 0.000197151385
Iter: 410 loss: 0.000197150934
Iter: 411 loss: 0.000197151734
Iter: 412 loss: 0.000197151065
Iter: 413 loss: 0.000197151065
Iter: 414 loss: 0.000197151108
Iter: 415 loss: 0.000197150715
Iter: 416 loss: 0.000197150628
Iter: 417 loss: 0.000197151181
Iter: 418 loss: 0.000197150424
Iter: 419 loss: 0.00019715041
Iter: 420 loss: 0.000197150774
Iter: 421 loss: 0.000197150352
Iter: 422 loss: 0.000197150104
Iter: 423 loss: 0.00019715057
Iter: 424 loss: 0.000197150075
Iter: 425 loss: 0.000197149871
Iter: 426 loss: 0.000197150686
Iter: 427 loss: 0.000197149799
Iter: 428 loss: 0.000197149668
Iter: 429 loss: 0.000197149726
Iter: 430 loss: 0.000197149609
Iter: 431 loss: 0.000197149522
Iter: 432 loss: 0.00019714977
Iter: 433 loss: 0.000197149668
Iter: 434 loss: 0.000197149318
Iter: 435 loss: 0.000197150279
Iter: 436 loss: 0.000197149289
Iter: 437 loss: 0.000197149217
Iter: 438 loss: 0.000197149973
Iter: 439 loss: 0.00019714926
Iter: 440 loss: 0.000197148969
Iter: 441 loss: 0.000197149187
Iter: 442 loss: 0.000197149013
Iter: 443 loss: 0.000197149086
Iter: 444 loss: 0.000197149435
Iter: 445 loss: 0.000197149144
Iter: 446 loss: 0.00019714894
Iter: 447 loss: 0.00019714926
Iter: 448 loss: 0.00019714894
Iter: 449 loss: 0.000197148736
Iter: 450 loss: 0.000197149115
Iter: 451 loss: 0.000197148562
Iter: 452 loss: 0.000197148736
Iter: 453 loss: 0.000197149013
Iter: 454 loss: 0.000197148736
Iter: 455 loss: 0.000197148707
Iter: 456 loss: 0.000197149042
Iter: 457 loss: 0.000197148591
Iter: 458 loss: 0.000197148693
Iter: 459 loss: 0.000197148664
Iter: 460 loss: 0.000197148402
Iter: 461 loss: 0.00019714846
Iter: 462 loss: 0.000197148896
Iter: 463 loss: 0.000197148445
Iter: 464 loss: 0.000197148373
Iter: 465 loss: 0.000197148445
Iter: 466 loss: 0.000197148329
Iter: 467 loss: 0.000197148343
Iter: 468 loss: 0.000197148533
Iter: 469 loss: 0.000197148387
Iter: 470 loss: 0.000197148489
Iter: 471 loss: 0.000197148649
Iter: 472 loss: 0.000197148387
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.8
+ date
Tue Oct 27 21:20:36 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 2 --alpha 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9e0f0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9e0f0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9e0c1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9e0c1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9e0d3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9e06e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9e02f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dfeb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dff1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dfc68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dfc6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dfc6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dfc6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9df23a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dfc6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9def1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9def1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9ded2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9de72268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9ded2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9de211e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dddaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9de05ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9de059d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9ddcc7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dd707b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dd74730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dd70048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dd29488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dd292f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dd70bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dd147b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dcd4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dc9e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dc79e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9dc797b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0386942178
Iter: 2 loss: 0.0373492539
Iter: 3 loss: 0.0323152915
Iter: 4 loss: 0.0215918086
Iter: 5 loss: 0.0211539548
Iter: 6 loss: 0.0133535387
Iter: 7 loss: 0.0133090783
Iter: 8 loss: 0.00813925825
Iter: 9 loss: 0.0717163906
Iter: 10 loss: 0.00792574324
Iter: 11 loss: 0.00587974768
Iter: 12 loss: 0.0190364532
Iter: 13 loss: 0.00567578059
Iter: 14 loss: 0.00431075925
Iter: 15 loss: 0.0112665119
Iter: 16 loss: 0.00398497283
Iter: 17 loss: 0.00308141112
Iter: 18 loss: 0.00975806452
Iter: 19 loss: 0.00298500247
Iter: 20 loss: 0.0024161234
Iter: 21 loss: 0.0059174085
Iter: 22 loss: 0.00232434249
Iter: 23 loss: 0.0019368463
Iter: 24 loss: 0.00567763858
Iter: 25 loss: 0.00192832702
Iter: 26 loss: 0.00169833237
Iter: 27 loss: 0.00258560688
Iter: 28 loss: 0.00163808418
Iter: 29 loss: 0.00145666045
Iter: 30 loss: 0.00184433116
Iter: 31 loss: 0.00138288608
Iter: 32 loss: 0.00123325863
Iter: 33 loss: 0.00170101109
Iter: 34 loss: 0.00118914573
Iter: 35 loss: 0.00108441373
Iter: 36 loss: 0.00197957968
Iter: 37 loss: 0.00107854
Iter: 38 loss: 0.000999208307
Iter: 39 loss: 0.00112476293
Iter: 40 loss: 0.000961685
Iter: 41 loss: 0.000899133447
Iter: 42 loss: 0.00104714255
Iter: 43 loss: 0.000875708531
Iter: 44 loss: 0.000821760448
Iter: 45 loss: 0.00107984617
Iter: 46 loss: 0.000812418293
Iter: 47 loss: 0.000767887163
Iter: 48 loss: 0.000891431642
Iter: 49 loss: 0.000753365573
Iter: 50 loss: 0.000716969487
Iter: 51 loss: 0.000885545567
Iter: 52 loss: 0.000709945161
Iter: 53 loss: 0.000680642202
Iter: 54 loss: 0.000884399575
Iter: 55 loss: 0.000677945558
Iter: 56 loss: 0.000655634387
Iter: 57 loss: 0.000685114181
Iter: 58 loss: 0.000644520624
Iter: 59 loss: 0.000622836582
Iter: 60 loss: 0.000690113637
Iter: 61 loss: 0.00061619177
Iter: 62 loss: 0.000597439357
Iter: 63 loss: 0.000712526205
Iter: 64 loss: 0.000595340913
Iter: 65 loss: 0.000580002728
Iter: 66 loss: 0.000606450136
Iter: 67 loss: 0.000573157798
Iter: 68 loss: 0.000558873522
Iter: 69 loss: 0.000587867
Iter: 70 loss: 0.000553044
Iter: 71 loss: 0.000539335946
Iter: 72 loss: 0.00057962467
Iter: 73 loss: 0.000535135856
Iter: 74 loss: 0.000522632326
Iter: 75 loss: 0.000572873105
Iter: 76 loss: 0.000519776135
Iter: 77 loss: 0.000509466394
Iter: 78 loss: 0.000546762254
Iter: 79 loss: 0.000506864279
Iter: 80 loss: 0.000497570378
Iter: 81 loss: 0.000528828125
Iter: 82 loss: 0.000495068554
Iter: 83 loss: 0.00048739952
Iter: 84 loss: 0.000523130526
Iter: 85 loss: 0.000485937402
Iter: 86 loss: 0.000479479437
Iter: 87 loss: 0.000487860234
Iter: 88 loss: 0.000476189831
Iter: 89 loss: 0.000470129133
Iter: 90 loss: 0.000516752829
Iter: 91 loss: 0.000469677208
Iter: 92 loss: 0.000464380078
Iter: 93 loss: 0.000480110757
Iter: 94 loss: 0.000462780852
Iter: 95 loss: 0.000458315597
Iter: 96 loss: 0.00046233437
Iter: 97 loss: 0.000455695466
Iter: 98 loss: 0.000450973865
Iter: 99 loss: 0.000491768355
Iter: 100 loss: 0.000450740685
Iter: 101 loss: 0.000447092461
Iter: 102 loss: 0.000447229133
Iter: 103 loss: 0.000444214587
Iter: 104 loss: 0.000439781958
Iter: 105 loss: 0.000449837273
Iter: 106 loss: 0.000438109069
Iter: 107 loss: 0.000434075657
Iter: 108 loss: 0.000454815396
Iter: 109 loss: 0.000433433539
Iter: 110 loss: 0.000429949258
Iter: 111 loss: 0.000438079587
Iter: 112 loss: 0.000428656174
Iter: 113 loss: 0.000425558857
Iter: 114 loss: 0.000436487608
Iter: 115 loss: 0.000424757047
Iter: 116 loss: 0.000421964738
Iter: 117 loss: 0.000435287802
Iter: 118 loss: 0.000421469158
Iter: 119 loss: 0.000418986805
Iter: 120 loss: 0.000424166035
Iter: 121 loss: 0.00041799419
Iter: 122 loss: 0.000415722898
Iter: 123 loss: 0.000422014622
Iter: 124 loss: 0.000414990296
Iter: 125 loss: 0.000412845489
Iter: 126 loss: 0.000427586725
Iter: 127 loss: 0.000412637775
Iter: 128 loss: 0.0004109242
Iter: 129 loss: 0.000413574744
Iter: 130 loss: 0.000410122477
Iter: 131 loss: 0.000408452179
Iter: 132 loss: 0.000413378759
Iter: 133 loss: 0.000407936
Iter: 134 loss: 0.000406252861
Iter: 135 loss: 0.000412328285
Iter: 136 loss: 0.000405832252
Iter: 137 loss: 0.000404389342
Iter: 138 loss: 0.000406776264
Iter: 139 loss: 0.000403732
Iter: 140 loss: 0.000402232166
Iter: 141 loss: 0.000404030667
Iter: 142 loss: 0.000401441066
Iter: 143 loss: 0.000399927638
Iter: 144 loss: 0.000408164866
Iter: 145 loss: 0.000399704702
Iter: 146 loss: 0.000398328935
Iter: 147 loss: 0.000400841178
Iter: 148 loss: 0.000397734111
Iter: 149 loss: 0.000396505755
Iter: 150 loss: 0.000400552759
Iter: 151 loss: 0.000396166055
Iter: 152 loss: 0.000395089271
Iter: 153 loss: 0.000403086451
Iter: 154 loss: 0.000395003299
Iter: 155 loss: 0.000394140778
Iter: 156 loss: 0.00039480257
Iter: 157 loss: 0.00039361458
Iter: 158 loss: 0.000392735441
Iter: 159 loss: 0.000397953787
Iter: 160 loss: 0.000392624235
Iter: 161 loss: 0.0003918609
Iter: 162 loss: 0.000395121373
Iter: 163 loss: 0.000391701702
Iter: 164 loss: 0.000391071022
Iter: 165 loss: 0.000391481
Iter: 166 loss: 0.000390672445
Iter: 167 loss: 0.000389970257
Iter: 168 loss: 0.000394530187
Iter: 169 loss: 0.000389893888
Iter: 170 loss: 0.000389303605
Iter: 171 loss: 0.000389832043
Iter: 172 loss: 0.000388960529
Iter: 173 loss: 0.000388295914
Iter: 174 loss: 0.00038987273
Iter: 175 loss: 0.000388053653
Iter: 176 loss: 0.000387393055
Iter: 177 loss: 0.000388893299
Iter: 178 loss: 0.000387144479
Iter: 179 loss: 0.000386494969
Iter: 180 loss: 0.000388889894
Iter: 181 loss: 0.000386334897
Iter: 182 loss: 0.000385769294
Iter: 183 loss: 0.000387398468
Iter: 184 loss: 0.00038559211
Iter: 185 loss: 0.000385067891
Iter: 186 loss: 0.000386674452
Iter: 187 loss: 0.000384912215
Iter: 188 loss: 0.000384432
Iter: 189 loss: 0.000387287932
Iter: 190 loss: 0.00038437132
Iter: 191 loss: 0.000383976556
Iter: 192 loss: 0.000384498446
Iter: 193 loss: 0.000383776554
Iter: 194 loss: 0.000383400882
Iter: 195 loss: 0.000386163767
Iter: 196 loss: 0.000383369887
Iter: 197 loss: 0.00038303918
Iter: 198 loss: 0.000383429375
Iter: 199 loss: 0.000382863131
Iter: 200 loss: 0.000382519182
Iter: 201 loss: 0.000383447565
Iter: 202 loss: 0.000382405648
Iter: 203 loss: 0.000382068858
Iter: 204 loss: 0.00038345193
Iter: 205 loss: 0.000381995109
Iter: 206 loss: 0.000381690741
Iter: 207 loss: 0.000382019207
Iter: 208 loss: 0.000381524616
Iter: 209 loss: 0.000381205464
Iter: 210 loss: 0.000381925493
Iter: 211 loss: 0.000381085381
Iter: 212 loss: 0.00038074964
Iter: 213 loss: 0.000382057478
Iter: 214 loss: 0.000380671583
Iter: 215 loss: 0.000380392186
Iter: 216 loss: 0.000380744052
Iter: 217 loss: 0.00038024789
Iter: 218 loss: 0.000379949168
Iter: 219 loss: 0.000381416525
Iter: 220 loss: 0.000379898236
Iter: 221 loss: 0.000379656558
Iter: 222 loss: 0.000380834448
Iter: 223 loss: 0.000379614416
Iter: 224 loss: 0.000379405334
Iter: 225 loss: 0.000379944599
Iter: 226 loss: 0.000379333593
Iter: 227 loss: 0.000379135832
Iter: 228 loss: 0.000379823032
Iter: 229 loss: 0.000379083853
Iter: 230 loss: 0.00037889817
Iter: 231 loss: 0.000379729201
Iter: 232 loss: 0.000378862
Iter: 233 loss: 0.000378701428
Iter: 234 loss: 0.000378814177
Iter: 235 loss: 0.000378601311
Iter: 236 loss: 0.000378420926
Iter: 237 loss: 0.000379318721
Iter: 238 loss: 0.000378390367
Iter: 239 loss: 0.000378239754
Iter: 240 loss: 0.000378652912
Iter: 241 loss: 0.000378190016
Iter: 242 loss: 0.000378045981
Iter: 243 loss: 0.000378139579
Iter: 244 loss: 0.00037795445
Iter: 245 loss: 0.000377790246
Iter: 246 loss: 0.000378594297
Iter: 247 loss: 0.000377762277
Iter: 248 loss: 0.000377619639
Iter: 249 loss: 0.00037786708
Iter: 250 loss: 0.000377556571
Iter: 251 loss: 0.00037741338
Iter: 252 loss: 0.000377725839
Iter: 253 loss: 0.000377358316
Iter: 254 loss: 0.000377229793
Iter: 255 loss: 0.00037799828
Iter: 256 loss: 0.000377214077
Iter: 257 loss: 0.000377100834
Iter: 258 loss: 0.000377514632
Iter: 259 loss: 0.000377072836
Iter: 260 loss: 0.000376969314
Iter: 261 loss: 0.000377197692
Iter: 262 loss: 0.000376929354
Iter: 263 loss: 0.000376831042
Iter: 264 loss: 0.000377393502
Iter: 265 loss: 0.000376817421
Iter: 266 loss: 0.000376732176
Iter: 267 loss: 0.000376854907
Iter: 268 loss: 0.000376690383
Iter: 269 loss: 0.00037660508
Iter: 270 loss: 0.000376839802
Iter: 271 loss: 0.000376577285
Iter: 272 loss: 0.000376491487
Iter: 273 loss: 0.000376774551
Iter: 274 loss: 0.000376468059
Iter: 275 loss: 0.0003763891
Iter: 276 loss: 0.000376562239
Iter: 277 loss: 0.000376358978
Iter: 278 loss: 0.000376285
Iter: 279 loss: 0.000376420794
Iter: 280 loss: 0.000376253098
Iter: 281 loss: 0.000376173499
Iter: 282 loss: 0.000376437034
Iter: 283 loss: 0.000376151816
Iter: 284 loss: 0.000376081385
Iter: 285 loss: 0.000376225624
Iter: 286 loss: 0.000376053387
Iter: 287 loss: 0.000375985
Iter: 288 loss: 0.000376212352
Iter: 289 loss: 0.000375965756
Iter: 290 loss: 0.000375905336
Iter: 291 loss: 0.000376242155
Iter: 292 loss: 0.000375896576
Iter: 293 loss: 0.000375842035
Iter: 294 loss: 0.000376010401
Iter: 295 loss: 0.000375826057
Iter: 296 loss: 0.000375781441
Iter: 297 loss: 0.000375955336
Iter: 298 loss: 0.00037577108
Iter: 299 loss: 0.000375727308
Iter: 300 loss: 0.000375853066
Iter: 301 loss: 0.000375713222
Iter: 302 loss: 0.000375672185
Iter: 303 loss: 0.000375720672
Iter: 304 loss: 0.000375650736
Iter: 305 loss: 0.000375605479
Iter: 306 loss: 0.00037580778
Iter: 307 loss: 0.000375596748
Iter: 308 loss: 0.000375556876
Iter: 309 loss: 0.000375635223
Iter: 310 loss: 0.000375540927
Iter: 311 loss: 0.0003755012
Iter: 312 loss: 0.000375599542
Iter: 313 loss: 0.000375487463
Iter: 314 loss: 0.000375449308
Iter: 315 loss: 0.000375560427
Iter: 316 loss: 0.000375437725
Iter: 317 loss: 0.000375402393
Iter: 318 loss: 0.000375461765
Iter: 319 loss: 0.000375386211
Iter: 320 loss: 0.000375350239
Iter: 321 loss: 0.00037546159
Iter: 322 loss: 0.000375339587
Iter: 323 loss: 0.00037530571
Iter: 324 loss: 0.000375435746
Iter: 325 loss: 0.000375297474
Iter: 326 loss: 0.000375268923
Iter: 327 loss: 0.000375461823
Iter: 328 loss: 0.000375266129
Iter: 329 loss: 0.000375242264
Iter: 330 loss: 0.000375277246
Iter: 331 loss: 0.000375231553
Iter: 332 loss: 0.000375205709
Iter: 333 loss: 0.000375326577
Iter: 334 loss: 0.000375201023
Iter: 335 loss: 0.000375178759
Iter: 336 loss: 0.000375216594
Iter: 337 loss: 0.000375168747
Iter: 338 loss: 0.000375146687
Iter: 339 loss: 0.00037520047
Iter: 340 loss: 0.000375138654
Iter: 341 loss: 0.000375116622
Iter: 342 loss: 0.00037521284
Iter: 343 loss: 0.000375112169
Iter: 344 loss: 0.000375094358
Iter: 345 loss: 0.000375116069
Iter: 346 loss: 0.000375084492
Iter: 347 loss: 0.000375065254
Iter: 348 loss: 0.000375141157
Iter: 349 loss: 0.000375060481
Iter: 350 loss: 0.000375042553
Iter: 351 loss: 0.000375064556
Iter: 352 loss: 0.000375033
Iter: 353 loss: 0.000375013798
Iter: 354 loss: 0.000375065138
Iter: 355 loss: 0.000375007658
Iter: 356 loss: 0.000374989904
Iter: 357 loss: 0.000375063333
Iter: 358 loss: 0.000374985859
Iter: 359 loss: 0.000374970259
Iter: 360 loss: 0.00037504849
Iter: 361 loss: 0.000374968
Iter: 362 loss: 0.000374954194
Iter: 363 loss: 0.000374999392
Iter: 364 loss: 0.000374950498
Iter: 365 loss: 0.000374938536
Iter: 366 loss: 0.000374980504
Iter: 367 loss: 0.000374935335
Iter: 368 loss: 0.000374924
Iter: 369 loss: 0.000374949886
Iter: 370 loss: 0.00037491988
Iter: 371 loss: 0.000374908093
Iter: 372 loss: 0.000374928291
Iter: 373 loss: 0.000374903408
Iter: 374 loss: 0.000374891883
Iter: 375 loss: 0.000374940748
Iter: 376 loss: 0.000374889234
Iter: 377 loss: 0.000374879019
Iter: 378 loss: 0.000374898897
Iter: 379 loss: 0.000374874566
Iter: 380 loss: 0.000374864554
Iter: 381 loss: 0.000374888856
Iter: 382 loss: 0.000374860654
Iter: 383 loss: 0.000374850235
Iter: 384 loss: 0.000374880969
Iter: 385 loss: 0.000374847063
Iter: 386 loss: 0.000374837022
Iter: 387 loss: 0.000374847441
Iter: 388 loss: 0.000374831754
Iter: 389 loss: 0.000374821015
Iter: 390 loss: 0.000374859752
Iter: 391 loss: 0.000374818279
Iter: 392 loss: 0.000374809286
Iter: 393 loss: 0.000374863535
Iter: 394 loss: 0.00037480786
Iter: 395 loss: 0.000374800875
Iter: 396 loss: 0.000374832511
Iter: 397 loss: 0.000374799041
Iter: 398 loss: 0.000374792609
Iter: 399 loss: 0.000374808296
Iter: 400 loss: 0.000374789874
Iter: 401 loss: 0.000374783616
Iter: 402 loss: 0.000374807452
Iter: 403 loss: 0.000374781666
Iter: 404 loss: 0.000374775875
Iter: 405 loss: 0.000374784751
Iter: 406 loss: 0.000374772819
Iter: 407 loss: 0.00037476662
Iter: 408 loss: 0.000374785624
Iter: 409 loss: 0.000374764553
Iter: 410 loss: 0.000374758616
Iter: 411 loss: 0.000374779105
Iter: 412 loss: 0.000374756666
Iter: 413 loss: 0.000374751166
Iter: 414 loss: 0.000374759838
Iter: 415 loss: 0.000374748663
Iter: 416 loss: 0.0003747429
Iter: 417 loss: 0.000374766038
Iter: 418 loss: 0.000374741678
Iter: 419 loss: 0.000374736381
Iter: 420 loss: 0.000374743191
Iter: 421 loss: 0.000374733936
Iter: 422 loss: 0.000374728319
Iter: 423 loss: 0.000374743191
Iter: 424 loss: 0.000374726485
Iter: 425 loss: 0.000374721654
Iter: 426 loss: 0.000374741154
Iter: 427 loss: 0.000374720141
Iter: 428 loss: 0.000374715775
Iter: 429 loss: 0.000374745956
Iter: 430 loss: 0.000374715368
Iter: 431 loss: 0.000374711934
Iter: 432 loss: 0.000374719704
Iter: 433 loss: 0.000374710595
Iter: 434 loss: 0.000374706782
Iter: 435 loss: 0.000374721712
Iter: 436 loss: 0.000374706375
Iter: 437 loss: 0.000374703086
Iter: 438 loss: 0.000374706229
Iter: 439 loss: 0.00037470166
Iter: 440 loss: 0.000374697789
Iter: 441 loss: 0.000374710478
Iter: 442 loss: 0.00037469712
Iter: 443 loss: 0.000374693947
Iter: 444 loss: 0.000374703202
Iter: 445 loss: 0.000374692958
Iter: 446 loss: 0.000374689815
Iter: 447 loss: 0.000374695
Iter: 448 loss: 0.000374688534
Iter: 449 loss: 0.000374685449
Iter: 450 loss: 0.000374695286
Iter: 451 loss: 0.00037468446
Iter: 452 loss: 0.000374681491
Iter: 453 loss: 0.000374689349
Iter: 454 loss: 0.000374680385
Iter: 455 loss: 0.000374677649
Iter: 456 loss: 0.000374681142
Iter: 457 loss: 0.00037467631
Iter: 458 loss: 0.000374673342
Iter: 459 loss: 0.000374687486
Iter: 460 loss: 0.000374672643
Iter: 461 loss: 0.000374670431
Iter: 462 loss: 0.000374682597
Iter: 463 loss: 0.000374669849
Iter: 464 loss: 0.000374668365
Iter: 465 loss: 0.000374675816
Iter: 466 loss: 0.000374667638
Iter: 467 loss: 0.000374665775
Iter: 468 loss: 0.000374671421
Iter: 469 loss: 0.000374665251
Iter: 470 loss: 0.000374663854
Iter: 471 loss: 0.000374667521
Iter: 472 loss: 0.000374662981
Iter: 473 loss: 0.000374661497
Iter: 474 loss: 0.00037466397
Iter: 475 loss: 0.000374660536
Iter: 476 loss: 0.000374658877
Iter: 477 loss: 0.000374665367
Iter: 478 loss: 0.000374658324
Iter: 479 loss: 0.000374656753
Iter: 480 loss: 0.000374660071
Iter: 481 loss: 0.000374656403
Iter: 482 loss: 0.000374654424
Iter: 483 loss: 0.000374659256
Iter: 484 loss: 0.00037465393
Iter: 485 loss: 0.000374652736
Iter: 486 loss: 0.000374656083
Iter: 487 loss: 0.00037465198
Iter: 488 loss: 0.00037465035
Iter: 489 loss: 0.000374653027
Iter: 490 loss: 0.000374649768
Iter: 491 loss: 0.000374648022
Iter: 492 loss: 0.000374653609
Iter: 493 loss: 0.00037464773
Iter: 494 loss: 0.000374646334
Iter: 495 loss: 0.000374651834
Iter: 496 loss: 0.000374646042
Iter: 497 loss: 0.000374644704
Iter: 498 loss: 0.000374652533
Iter: 499 loss: 0.000374644529
Iter: 500 loss: 0.000374643481
Iter: 501 loss: 0.000374645519
Iter: 502 loss: 0.000374643103
Iter: 503 loss: 0.000374642026
Iter: 504 loss: 0.000374645402
Iter: 505 loss: 0.000374641968
Iter: 506 loss: 0.000374640833
Iter: 507 loss: 0.000374642259
Iter: 508 loss: 0.000374640571
Iter: 509 loss: 0.000374639523
Iter: 510 loss: 0.000374642143
Iter: 511 loss: 0.00037463929
Iter: 512 loss: 0.000374638039
Iter: 513 loss: 0.000374641066
Iter: 514 loss: 0.000374637719
Iter: 515 loss: 0.000374637049
Iter: 516 loss: 0.000374638825
Iter: 517 loss: 0.000374636787
Iter: 518 loss: 0.000374635565
Iter: 519 loss: 0.000374638359
Iter: 520 loss: 0.000374635594
Iter: 521 loss: 0.000374634401
Iter: 522 loss: 0.000374636031
Iter: 523 loss: 0.000374634401
Iter: 524 loss: 0.000374633557
Iter: 525 loss: 0.000374635332
Iter: 526 loss: 0.000374632917
Iter: 527 loss: 0.000374632
Iter: 528 loss: 0.000374635682
Iter: 529 loss: 0.000374631927
Iter: 530 loss: 0.000374631491
Iter: 531 loss: 0.000374636205
Iter: 532 loss: 0.000374631491
Iter: 533 loss: 0.000374630734
Iter: 534 loss: 0.000374632247
Iter: 535 loss: 0.000374630792
Iter: 536 loss: 0.000374630123
Iter: 537 loss: 0.000374631607
Iter: 538 loss: 0.000374629861
Iter: 539 loss: 0.000374629279
Iter: 540 loss: 0.00037463021
Iter: 541 loss: 0.00037462922
Iter: 542 loss: 0.000374628522
Iter: 543 loss: 0.000374630152
Iter: 544 loss: 0.000374628406
Iter: 545 loss: 0.000374627765
Iter: 546 loss: 0.000374629686
Iter: 547 loss: 0.000374627853
Iter: 548 loss: 0.0003746273
Iter: 549 loss: 0.00037462794
Iter: 550 loss: 0.000374627096
Iter: 551 loss: 0.000374626543
Iter: 552 loss: 0.000374628056
Iter: 553 loss: 0.000374626485
Iter: 554 loss: 0.000374626135
Iter: 555 loss: 0.000374627067
Iter: 556 loss: 0.000374625786
Iter: 557 loss: 0.000374625291
Iter: 558 loss: 0.000374625844
Iter: 559 loss: 0.000374625146
Iter: 560 loss: 0.000374624709
Iter: 561 loss: 0.000374626339
Iter: 562 loss: 0.000374624506
Iter: 563 loss: 0.000374624447
Iter: 564 loss: 0.000374627329
Iter: 565 loss: 0.000374624098
Iter: 566 loss: 0.000374623749
Iter: 567 loss: 0.000374624797
Iter: 568 loss: 0.00037462404
Iter: 569 loss: 0.000374623429
Iter: 570 loss: 0.000374624069
Iter: 571 loss: 0.0003746234
Iter: 572 loss: 0.000374623225
Iter: 573 loss: 0.000374623749
Iter: 574 loss: 0.000374622876
Iter: 575 loss: 0.000374622818
Iter: 576 loss: 0.000374623487
Iter: 577 loss: 0.000374622701
Iter: 578 loss: 0.000374622119
Iter: 579 loss: 0.000374623691
Iter: 580 loss: 0.000374622
Iter: 581 loss: 0.000374622061
Iter: 582 loss: 0.000374622527
Iter: 583 loss: 0.000374622061
Iter: 584 loss: 0.000374621246
Iter: 585 loss: 0.00037462209
Iter: 586 loss: 0.000374621275
Iter: 587 loss: 0.000374621188
Iter: 588 loss: 0.000374622032
Iter: 589 loss: 0.000374620955
Iter: 590 loss: 0.000374620839
Iter: 591 loss: 0.000374621333
Iter: 592 loss: 0.000374620897
Iter: 593 loss: 0.000374620751
Iter: 594 loss: 0.000374621392
Iter: 595 loss: 0.000374620431
Iter: 596 loss: 0.000374620431
Iter: 597 loss: 0.000374621595
Iter: 598 loss: 0.000374620373
Iter: 599 loss: 0.000374620024
Iter: 600 loss: 0.000374621362
Iter: 601 loss: 0.000374620198
Iter: 602 loss: 0.000374619849
Iter: 603 loss: 0.000374620256
Iter: 604 loss: 0.000374619849
Iter: 605 loss: 0.000374619791
Iter: 606 loss: 0.000374620402
Iter: 607 loss: 0.000374619383
Iter: 608 loss: 0.000374619558
Iter: 609 loss: 0.000374619616
Iter: 610 loss: 0.000374619354
Iter: 611 loss: 0.000374619325
Iter: 612 loss: 0.000374619965
Iter: 613 loss: 0.000374619034
Iter: 614 loss: 0.000374619238
Iter: 615 loss: 0.000374619267
Iter: 616 loss: 0.000374619121
Iter: 617 loss: 0.000374618918
Iter: 618 loss: 0.000374619121
Iter: 619 loss: 0.000374618859
Iter: 620 loss: 0.000374618539
Iter: 621 loss: 0.000374619092
Iter: 622 loss: 0.000374618656
Iter: 623 loss: 0.000374618423
Iter: 624 loss: 0.000374618859
Iter: 625 loss: 0.000374618161
Iter: 626 loss: 0.000374618277
Iter: 627 loss: 0.000374618452
Iter: 628 loss: 0.000374618307
Iter: 629 loss: 0.000374618103
Iter: 630 loss: 0.000374618656
Iter: 631 loss: 0.000374617754
Iter: 632 loss: 0.000374617841
Iter: 633 loss: 0.000374619034
Iter: 634 loss: 0.000374617957
Iter: 635 loss: 0.000374617957
Iter: 636 loss: 0.000374617899
Iter: 637 loss: 0.000374617754
Iter: 638 loss: 0.000374617841
Iter: 639 loss: 0.000374618074
Iter: 640 loss: 0.000374617754
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi1.2
+ date
Tue Oct 27 21:29:33 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 2 --alpha 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi2_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd56e5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd56e58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd56a7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd56a7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd56b1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5647400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5647158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd55e1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd55e5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd55ad9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd55ad8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd55adae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd555eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd55111e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd55ad1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5545840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd54938c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd54bdd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5470400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5470950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd54702f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5445510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd53f5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd53986a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5388510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd53c0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd5364268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd53c0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd53c0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd53451e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd52ee950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd52ee378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bb98deb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bd52ee2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bb98cdc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7bb98cd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.028483158
Iter: 2 loss: 0.0261681303
Iter: 3 loss: 0.0187693406
Iter: 4 loss: 27361.4688
Iter: 5 loss: 0.0193922557
Iter: 6 loss: 0.0172335133
Iter: 7 loss: 0.0126177184
Iter: 8 loss: 0.0120657776
Iter: 9 loss: 0.00858482
Iter: 10 loss: 0.13003768
Iter: 11 loss: 0.00856737699
Iter: 12 loss: 0.00654102443
Iter: 13 loss: 0.0348175578
Iter: 14 loss: 0.00653056428
Iter: 15 loss: 0.00529320445
Iter: 16 loss: 0.00859545171
Iter: 17 loss: 0.00498410314
Iter: 18 loss: 0.004060545
Iter: 19 loss: 0.00685041
Iter: 20 loss: 0.00369328586
Iter: 21 loss: 0.00315984502
Iter: 22 loss: 0.00788317528
Iter: 23 loss: 0.00312789949
Iter: 24 loss: 0.00271427445
Iter: 25 loss: 0.00454103714
Iter: 26 loss: 0.00262520951
Iter: 27 loss: 0.00234079012
Iter: 28 loss: 0.00313740969
Iter: 29 loss: 0.00225286465
Iter: 30 loss: 0.00201564468
Iter: 31 loss: 0.0026023
Iter: 32 loss: 0.00192179356
Iter: 33 loss: 0.0017609701
Iter: 34 loss: 0.00202437607
Iter: 35 loss: 0.00168558222
Iter: 36 loss: 0.00153198256
Iter: 37 loss: 0.00291481987
Iter: 38 loss: 0.00152407924
Iter: 39 loss: 0.00141461333
Iter: 40 loss: 0.00200998923
Iter: 41 loss: 0.00140063302
Iter: 42 loss: 0.00132262649
Iter: 43 loss: 0.00149519765
Iter: 44 loss: 0.00129076431
Iter: 45 loss: 0.00122142921
Iter: 46 loss: 0.0017134787
Iter: 47 loss: 0.00121508329
Iter: 48 loss: 0.00115811347
Iter: 49 loss: 0.00128878898
Iter: 50 loss: 0.00113724545
Iter: 51 loss: 0.00108563458
Iter: 52 loss: 0.00137143058
Iter: 53 loss: 0.00107789855
Iter: 54 loss: 0.00103994692
Iter: 55 loss: 0.00117406936
Iter: 56 loss: 0.00102995709
Iter: 57 loss: 0.000997345
Iter: 58 loss: 0.00108124223
Iter: 59 loss: 0.000985954888
Iter: 60 loss: 0.000954956806
Iter: 61 loss: 0.00108208018
Iter: 62 loss: 0.000948141154
Iter: 63 loss: 0.000921984727
Iter: 64 loss: 0.000974806491
Iter: 65 loss: 0.000911299721
Iter: 66 loss: 0.000886062044
Iter: 67 loss: 0.000962953782
Iter: 68 loss: 0.000878570485
Iter: 69 loss: 0.000855899649
Iter: 70 loss: 0.000981714
Iter: 71 loss: 0.000852499274
Iter: 72 loss: 0.000835253042
Iter: 73 loss: 0.000895536446
Iter: 74 loss: 0.000830898178
Iter: 75 loss: 0.000816419837
Iter: 76 loss: 0.00082115503
Iter: 77 loss: 0.000805985415
Iter: 78 loss: 0.000788231846
Iter: 79 loss: 0.000852003752
Iter: 80 loss: 0.000783828786
Iter: 81 loss: 0.00076887972
Iter: 82 loss: 0.000815625768
Iter: 83 loss: 0.000764480093
Iter: 84 loss: 0.0007507829
Iter: 85 loss: 0.000840606168
Iter: 86 loss: 0.000749311177
Iter: 87 loss: 0.000739342941
Iter: 88 loss: 0.000755818211
Iter: 89 loss: 0.000734794186
Iter: 90 loss: 0.000724916637
Iter: 91 loss: 0.000786521
Iter: 92 loss: 0.000723745441
Iter: 93 loss: 0.000715416
Iter: 94 loss: 0.000731153879
Iter: 95 loss: 0.000711901346
Iter: 96 loss: 0.000703740283
Iter: 97 loss: 0.00072566123
Iter: 98 loss: 0.000701032113
Iter: 99 loss: 0.000692875241
Iter: 100 loss: 0.000713140529
Iter: 101 loss: 0.000689985
Iter: 102 loss: 0.000682206824
Iter: 103 loss: 0.000700002187
Iter: 104 loss: 0.000679297722
Iter: 105 loss: 0.000672124792
Iter: 106 loss: 0.00072008319
Iter: 107 loss: 0.000671421178
Iter: 108 loss: 0.000665689702
Iter: 109 loss: 0.000681435107
Iter: 110 loss: 0.00066378
Iter: 111 loss: 0.000658291916
Iter: 112 loss: 0.00066447258
Iter: 113 loss: 0.000655358541
Iter: 114 loss: 0.00064931449
Iter: 115 loss: 0.000666474807
Iter: 116 loss: 0.000647380366
Iter: 117 loss: 0.000641866296
Iter: 118 loss: 0.000659481331
Iter: 119 loss: 0.000640298938
Iter: 120 loss: 0.000635292497
Iter: 121 loss: 0.0006524091
Iter: 122 loss: 0.000633954653
Iter: 123 loss: 0.000629167131
Iter: 124 loss: 0.000649887719
Iter: 125 loss: 0.000628181093
Iter: 126 loss: 0.000624374719
Iter: 127 loss: 0.000643457228
Iter: 128 loss: 0.000623733911
Iter: 129 loss: 0.000620305887
Iter: 130 loss: 0.000624312088
Iter: 131 loss: 0.000618479797
Iter: 132 loss: 0.000614712
Iter: 133 loss: 0.000627871254
Iter: 134 loss: 0.000613732613
Iter: 135 loss: 0.000610476476
Iter: 136 loss: 0.000615868368
Iter: 137 loss: 0.000608993229
Iter: 138 loss: 0.000605369452
Iter: 139 loss: 0.000613782206
Iter: 140 loss: 0.000604028406
Iter: 141 loss: 0.000600855506
Iter: 142 loss: 0.000626250869
Iter: 143 loss: 0.000600632513
Iter: 144 loss: 0.000597926672
Iter: 145 loss: 0.000600653177
Iter: 146 loss: 0.000596416823
Iter: 147 loss: 0.000593559351
Iter: 148 loss: 0.000602829852
Iter: 149 loss: 0.000592746306
Iter: 150 loss: 0.000590033771
Iter: 151 loss: 0.000596499478
Iter: 152 loss: 0.000589059084
Iter: 153 loss: 0.000586390845
Iter: 154 loss: 0.000591232092
Iter: 155 loss: 0.000585231814
Iter: 156 loss: 0.000582885463
Iter: 157 loss: 0.000594286947
Iter: 158 loss: 0.00058247475
Iter: 159 loss: 0.000580188353
Iter: 160 loss: 0.00058862759
Iter: 161 loss: 0.000579628511
Iter: 162 loss: 0.000577683561
Iter: 163 loss: 0.000585164351
Iter: 164 loss: 0.000577226572
Iter: 165 loss: 0.00057541288
Iter: 166 loss: 0.000577799859
Iter: 167 loss: 0.00057449477
Iter: 168 loss: 0.000572531135
Iter: 169 loss: 0.000578642532
Iter: 170 loss: 0.000571957324
Iter: 171 loss: 0.000570205913
Iter: 172 loss: 0.000573503552
Iter: 173 loss: 0.000569466269
Iter: 174 loss: 0.000567711657
Iter: 175 loss: 0.000574094825
Iter: 176 loss: 0.000567271607
Iter: 177 loss: 0.000565627706
Iter: 178 loss: 0.000574746169
Iter: 179 loss: 0.000565395
Iter: 180 loss: 0.000564011
Iter: 181 loss: 0.000565156806
Iter: 182 loss: 0.000563182053
Iter: 183 loss: 0.000561696244
Iter: 184 loss: 0.000568870339
Iter: 185 loss: 0.000561439898
Iter: 186 loss: 0.000560162764
Iter: 187 loss: 0.000561148
Iter: 188 loss: 0.000559384935
Iter: 189 loss: 0.000558003783
Iter: 190 loss: 0.0005626239
Iter: 191 loss: 0.000557629333
Iter: 192 loss: 0.000556320359
Iter: 193 loss: 0.00056322047
Iter: 194 loss: 0.000556115585
Iter: 195 loss: 0.000555069884
Iter: 196 loss: 0.000558926142
Iter: 197 loss: 0.000554811209
Iter: 198 loss: 0.00055382523
Iter: 199 loss: 0.000556477229
Iter: 200 loss: 0.000553498801
Iter: 201 loss: 0.000552531565
Iter: 202 loss: 0.000554187689
Iter: 203 loss: 0.0005520985
Iter: 204 loss: 0.000551125384
Iter: 205 loss: 0.000553160557
Iter: 206 loss: 0.000550739118
Iter: 207 loss: 0.00054968812
Iter: 208 loss: 0.000552701065
Iter: 209 loss: 0.00054935785
Iter: 210 loss: 0.000548404932
Iter: 211 loss: 0.000552702928
Iter: 212 loss: 0.000548220123
Iter: 213 loss: 0.000547382282
Iter: 214 loss: 0.000550490106
Iter: 215 loss: 0.000547174714
Iter: 216 loss: 0.000546401367
Iter: 217 loss: 0.000547504
Iter: 218 loss: 0.000546024
Iter: 219 loss: 0.000545222
Iter: 220 loss: 0.000547505158
Iter: 221 loss: 0.000544967
Iter: 222 loss: 0.000544180104
Iter: 223 loss: 0.000546257361
Iter: 224 loss: 0.000543916598
Iter: 225 loss: 0.000543187081
Iter: 226 loss: 0.000545542105
Iter: 227 loss: 0.000542981434
Iter: 228 loss: 0.000542275724
Iter: 229 loss: 0.00054460438
Iter: 230 loss: 0.000542081194
Iter: 231 loss: 0.000541447895
Iter: 232 loss: 0.000545015908
Iter: 233 loss: 0.000541359419
Iter: 234 loss: 0.000540834153
Iter: 235 loss: 0.00054145616
Iter: 236 loss: 0.000540555513
Iter: 237 loss: 0.000539971457
Iter: 238 loss: 0.000540956389
Iter: 239 loss: 0.000539708417
Iter: 240 loss: 0.000539095141
Iter: 241 loss: 0.000541450514
Iter: 242 loss: 0.000538950146
Iter: 243 loss: 0.000538399036
Iter: 244 loss: 0.000539596542
Iter: 245 loss: 0.000538186403
Iter: 246 loss: 0.000537678716
Iter: 247 loss: 0.000540543348
