+ RUN=0
+ export CUDA_VISIBLE_DEVICES=0
+ CUDA_VISIBLE_DEVICES=0
+ LAYERS=300_300_300_1
+ case $RUN in
+ PSI='0 2'
+ OPTIONS='			 --optimizer adam 				 --n_pairs 50000 				 --batch_size 5000 				 --max_epochs 200 				 --learning_rate 0.001 				 --decay_rate 0.98 				 --loss_func weighted_MSE 
'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output80
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output81
+ for fn in f1
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL='--load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0
+ date
Sun Nov  1 21:32:45 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b704a4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b704961e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b704a2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b704756a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70387158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b7036ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b703d4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b703da0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70248ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b7023a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70138048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70147a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b7053f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b700edf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b701d29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b701cf488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70055ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b7008e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b7001f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70041d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70270840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b702882f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70150d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b702d17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b702ee268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b702d9c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b24744730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b246c61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b246eebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b700b96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b7009b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b701b9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b70199620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b246240d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b24634ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4b245c5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 1.382591e-06
test_loss: 1.4435659e-06
train_loss: 1.2623251e-06
test_loss: 1.2128752e-06
train_loss: 1.1947109e-06
test_loss: 1.2554851e-06
train_loss: 1.3745185e-06
test_loss: 1.2602534e-06
train_loss: 1.1741254e-06
test_loss: 1.2280374e-06
train_loss: 1.022989e-06
test_loss: 1.1736827e-06
train_loss: 1.1301499e-06
test_loss: 1.1696196e-06
train_loss: 9.820733e-07
test_loss: 1.0468428e-06
train_loss: 1.0174872e-06
test_loss: 9.862712e-07
train_loss: 9.423553e-07
test_loss: 9.723113e-07
train_loss: 8.1587314e-07
test_loss: 9.63782e-07
train_loss: 9.290201e-07
test_loss: 9.095789e-07
train_loss: 8.7051194e-07
test_loss: 9.379662e-07
train_loss: 9.321188e-07
test_loss: 9.2228925e-07
train_loss: 8.500453e-07
test_loss: 8.9205133e-07
train_loss: 7.594899e-07
test_loss: 8.845652e-07
train_loss: 7.756062e-07
test_loss: 8.739042e-07
train_loss: 7.8946744e-07
test_loss: 8.535733e-07
train_loss: 7.8936495e-07
test_loss: 8.261528e-07
train_loss: 7.3366766e-07
test_loss: 8.390482e-07
train_loss: 7.5008586e-07
test_loss: 8.392159e-07
train_loss: 7.83149e-07
test_loss: 8.254931e-07
train_loss: 7.4014383e-07
test_loss: 8.00644e-07
train_loss: 7.4595334e-07
test_loss: 8.010251e-07
train_loss: 6.811957e-07
test_loss: 7.8996504e-07
train_loss: 7.273268e-07
test_loss: 7.867002e-07
train_loss: 7.0684894e-07
test_loss: 7.831878e-07
train_loss: 7.178186e-07
test_loss: 7.770377e-07
train_loss: 7.140335e-07
test_loss: 7.7599134e-07
train_loss: 6.9434e-07
test_loss: 7.811101e-07
train_loss: 6.7964515e-07
test_loss: 7.668305e-07
train_loss: 6.871979e-07
test_loss: 7.742685e-07
train_loss: 7.201161e-07
test_loss: 7.619812e-07
train_loss: 6.8930655e-07
test_loss: 7.6280855e-07
train_loss: 6.6404345e-07
test_loss: 7.6539584e-07
train_loss: 6.988871e-07
test_loss: 7.607246e-07
train_loss: 7.028418e-07
test_loss: 7.603438e-07
train_loss: 7.073072e-07
test_loss: 7.565749e-07
train_loss: 6.915101e-07
test_loss: 7.584719e-07
train_loss: 7.1182143e-07
test_loss: 7.550313e-07
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 0 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a1d67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b946d7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b946b4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a215730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a1611e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a16bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a1ac6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a1b7158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b341ccb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b341c9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b341b80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b341b7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b34168598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b34114048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b34133a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b340df510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b340fcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a141950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a125400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b5a134e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b3407d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b207eb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b207d3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b20799840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b207b62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b3407cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b207317b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b20723268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b20730c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b20759730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b206f11e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b206e7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b206696a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b2066b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b20658b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8b20696620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.75419869e-07
Iter: 2 loss: 6.68645725e-07
Iter: 3 loss: 6.68618e-07
Iter: 4 loss: 6.66191681e-07
Iter: 5 loss: 6.88873115e-07
Iter: 6 loss: 6.66085384e-07
Iter: 7 loss: 6.65280936e-07
Iter: 8 loss: 6.66716119e-07
Iter: 9 loss: 6.64924414e-07
Iter: 10 loss: 6.64294816e-07
Iter: 11 loss: 6.72119143e-07
Iter: 12 loss: 6.64302149e-07
Iter: 13 loss: 6.63993546e-07
Iter: 14 loss: 6.63502192e-07
Iter: 15 loss: 6.63489e-07
Iter: 16 loss: 6.63406411e-07
Iter: 17 loss: 6.63393052e-07
Iter: 18 loss: 6.6325731e-07
Iter: 19 loss: 6.62982643e-07
Iter: 20 loss: 6.67811435e-07
Iter: 21 loss: 6.62983041e-07
Iter: 22 loss: 6.62718207e-07
Iter: 23 loss: 6.62435582e-07
Iter: 24 loss: 6.62391926e-07
Iter: 25 loss: 6.62318143e-07
Iter: 26 loss: 6.62208777e-07
Iter: 27 loss: 6.62011303e-07
Iter: 28 loss: 6.62260561e-07
Iter: 29 loss: 6.61922172e-07
Iter: 30 loss: 6.61817296e-07
Iter: 31 loss: 6.61674846e-07
Iter: 32 loss: 6.61674278e-07
Iter: 33 loss: 6.61563263e-07
Iter: 34 loss: 6.61963668e-07
Iter: 35 loss: 6.61549734e-07
Iter: 36 loss: 6.6149164e-07
Iter: 37 loss: 6.61481579e-07
Iter: 38 loss: 6.6143e-07
Iter: 39 loss: 6.61394665e-07
Iter: 40 loss: 6.6137045e-07
Iter: 41 loss: 6.61302863e-07
Iter: 42 loss: 6.6210896e-07
Iter: 43 loss: 6.61296724e-07
Iter: 44 loss: 6.61246645e-07
Iter: 45 loss: 6.6140808e-07
Iter: 46 loss: 6.61219e-07
Iter: 47 loss: 6.61179911e-07
Iter: 48 loss: 6.61108686e-07
Iter: 49 loss: 6.61112722e-07
Iter: 50 loss: 6.61049057e-07
Iter: 51 loss: 6.61825311e-07
Iter: 52 loss: 6.61050478e-07
Iter: 53 loss: 6.60973853e-07
Iter: 54 loss: 6.60946398e-07
Iter: 55 loss: 6.60904675e-07
Iter: 56 loss: 6.60849764e-07
Iter: 57 loss: 6.60699243e-07
Iter: 58 loss: 6.62244133e-07
Iter: 59 loss: 6.60689693e-07
Iter: 60 loss: 6.60598971e-07
Iter: 61 loss: 6.60566172e-07
Iter: 62 loss: 6.60443e-07
Iter: 63 loss: 6.60589535e-07
Iter: 64 loss: 6.60388594e-07
Iter: 65 loss: 6.6035841e-07
Iter: 66 loss: 6.60360286e-07
Iter: 67 loss: 6.60327714e-07
Iter: 68 loss: 6.60296337e-07
Iter: 69 loss: 6.60422074e-07
Iter: 70 loss: 6.60287412e-07
Iter: 71 loss: 6.60257911e-07
Iter: 72 loss: 6.60302e-07
Iter: 73 loss: 6.60242563e-07
Iter: 74 loss: 6.6019993e-07
Iter: 75 loss: 6.60154797e-07
Iter: 76 loss: 6.60142e-07
Iter: 77 loss: 6.60095225e-07
Iter: 78 loss: 6.60008311e-07
Iter: 79 loss: 6.60008197e-07
Iter: 80 loss: 6.59838747e-07
Iter: 81 loss: 6.60152295e-07
Iter: 82 loss: 6.59781904e-07
Iter: 83 loss: 6.59641159e-07
Iter: 84 loss: 6.5987706e-07
Iter: 85 loss: 6.59584259e-07
Iter: 86 loss: 6.59600914e-07
Iter: 87 loss: 6.5952338e-07
Iter: 88 loss: 6.59502e-07
Iter: 89 loss: 6.59440161e-07
Iter: 90 loss: 6.60246e-07
Iter: 91 loss: 6.59436523e-07
Iter: 92 loss: 6.59390707e-07
Iter: 93 loss: 6.59350235e-07
Iter: 94 loss: 6.59334148e-07
Iter: 95 loss: 6.5928532e-07
Iter: 96 loss: 6.59292709e-07
Iter: 97 loss: 6.59233422e-07
Iter: 98 loss: 6.59269915e-07
Iter: 99 loss: 6.5919653e-07
Iter: 100 loss: 6.5914827e-07
Iter: 101 loss: 6.59046407e-07
Iter: 102 loss: 6.60944124e-07
Iter: 103 loss: 6.59031e-07
Iter: 104 loss: 6.5894244e-07
Iter: 105 loss: 6.58944714e-07
Iter: 106 loss: 6.5891436e-07
Iter: 107 loss: 6.59002126e-07
Iter: 108 loss: 6.58895488e-07
Iter: 109 loss: 6.58850922e-07
Iter: 110 loss: 6.58772137e-07
Iter: 111 loss: 6.60386434e-07
Iter: 112 loss: 6.5876975e-07
Iter: 113 loss: 6.58684939e-07
Iter: 114 loss: 6.5920608e-07
Iter: 115 loss: 6.58678e-07
Iter: 116 loss: 6.58606155e-07
Iter: 117 loss: 6.58584327e-07
Iter: 118 loss: 6.5854033e-07
Iter: 119 loss: 6.58505087e-07
Iter: 120 loss: 6.58491786e-07
Iter: 121 loss: 6.5845245e-07
Iter: 122 loss: 6.58483259e-07
Iter: 123 loss: 6.58423971e-07
Iter: 124 loss: 6.58396289e-07
Iter: 125 loss: 6.58329782e-07
Iter: 126 loss: 6.59655825e-07
Iter: 127 loss: 6.58336376e-07
Iter: 128 loss: 6.58275098e-07
Iter: 129 loss: 6.58535214e-07
Iter: 130 loss: 6.58257534e-07
Iter: 131 loss: 6.58193358e-07
Iter: 132 loss: 6.58222064e-07
Iter: 133 loss: 6.5814919e-07
Iter: 134 loss: 6.58046758e-07
Iter: 135 loss: 6.59194598e-07
Iter: 136 loss: 6.58049032e-07
Iter: 137 loss: 6.57988096e-07
Iter: 138 loss: 6.57909652e-07
Iter: 139 loss: 6.57909482e-07
Iter: 140 loss: 6.5783604e-07
Iter: 141 loss: 6.57836608e-07
Iter: 142 loss: 6.57801536e-07
Iter: 143 loss: 6.57805572e-07
Iter: 144 loss: 6.57770784e-07
Iter: 145 loss: 6.5773213e-07
Iter: 146 loss: 6.57842406e-07
Iter: 147 loss: 6.57710871e-07
Iter: 148 loss: 6.57647604e-07
Iter: 149 loss: 6.57681426e-07
Iter: 150 loss: 6.5760571e-07
Iter: 151 loss: 6.57533292e-07
Iter: 152 loss: 6.57885778e-07
Iter: 153 loss: 6.57531473e-07
Iter: 154 loss: 6.57492762e-07
Iter: 155 loss: 6.57886176e-07
Iter: 156 loss: 6.57491796e-07
Iter: 157 loss: 6.57447345e-07
Iter: 158 loss: 6.57335249e-07
Iter: 159 loss: 6.58484737e-07
Iter: 160 loss: 6.57322062e-07
Iter: 161 loss: 6.57234636e-07
Iter: 162 loss: 6.5754017e-07
Iter: 163 loss: 6.5720269e-07
Iter: 164 loss: 6.57118449e-07
Iter: 165 loss: 6.57163923e-07
Iter: 166 loss: 6.57067631e-07
Iter: 167 loss: 6.56918701e-07
Iter: 168 loss: 6.56827297e-07
Iter: 169 loss: 6.56774773e-07
Iter: 170 loss: 6.57071e-07
Iter: 171 loss: 6.56707925e-07
Iter: 172 loss: 6.56677344e-07
Iter: 173 loss: 6.56587702e-07
Iter: 174 loss: 6.56851455e-07
Iter: 175 loss: 6.56525117e-07
Iter: 176 loss: 6.5644565e-07
Iter: 177 loss: 6.57488556e-07
Iter: 178 loss: 6.5644565e-07
Iter: 179 loss: 6.56417228e-07
Iter: 180 loss: 6.56422912e-07
Iter: 181 loss: 6.56379711e-07
Iter: 182 loss: 6.5630968e-07
Iter: 183 loss: 6.57940802e-07
Iter: 184 loss: 6.56313034e-07
Iter: 185 loss: 6.56268071e-07
Iter: 186 loss: 6.56367149e-07
Iter: 187 loss: 6.5623442e-07
Iter: 188 loss: 6.56131306e-07
Iter: 189 loss: 6.56279553e-07
Iter: 190 loss: 6.56086399e-07
Iter: 191 loss: 6.55992153e-07
Iter: 192 loss: 6.56291661e-07
Iter: 193 loss: 6.55969529e-07
Iter: 194 loss: 6.55893302e-07
Iter: 195 loss: 6.56315251e-07
Iter: 196 loss: 6.55889494e-07
Iter: 197 loss: 6.55832253e-07
Iter: 198 loss: 6.55929512e-07
Iter: 199 loss: 6.55807867e-07
Iter: 200 loss: 6.55749318e-07
Iter: 201 loss: 6.55709e-07
Iter: 202 loss: 6.55696567e-07
Iter: 203 loss: 6.55652343e-07
Iter: 204 loss: 6.55713848e-07
Iter: 205 loss: 6.55634267e-07
Iter: 206 loss: 6.55547069e-07
Iter: 207 loss: 6.56494535e-07
Iter: 208 loss: 6.55543317e-07
Iter: 209 loss: 6.55512338e-07
Iter: 210 loss: 6.55434633e-07
Iter: 211 loss: 6.56597479e-07
Iter: 212 loss: 6.55446911e-07
Iter: 213 loss: 6.5538535e-07
Iter: 214 loss: 6.55460497e-07
Iter: 215 loss: 6.55337942e-07
Iter: 216 loss: 6.55382337e-07
Iter: 217 loss: 6.55320321e-07
Iter: 218 loss: 6.5530503e-07
Iter: 219 loss: 6.55240228e-07
Iter: 220 loss: 6.55274789e-07
Iter: 221 loss: 6.5519032e-07
Iter: 222 loss: 6.55072427e-07
Iter: 223 loss: 6.55348e-07
Iter: 224 loss: 6.55030249e-07
Iter: 225 loss: 6.5493947e-07
Iter: 226 loss: 6.54934411e-07
Iter: 227 loss: 6.54891096e-07
Iter: 228 loss: 6.5480242e-07
Iter: 229 loss: 6.54801568e-07
Iter: 230 loss: 6.54786959e-07
Iter: 231 loss: 6.54765302e-07
Iter: 232 loss: 6.5474228e-07
Iter: 233 loss: 6.54739551e-07
Iter: 234 loss: 6.5473e-07
Iter: 235 loss: 6.546951e-07
Iter: 236 loss: 6.54693906e-07
Iter: 237 loss: 6.54667531e-07
Iter: 238 loss: 6.54634619e-07
Iter: 239 loss: 6.54575729e-07
Iter: 240 loss: 6.54584596e-07
Iter: 241 loss: 6.54495e-07
Iter: 242 loss: 6.54781843e-07
Iter: 243 loss: 6.54476594e-07
Iter: 244 loss: 6.5437132e-07
Iter: 245 loss: 6.55381768e-07
Iter: 246 loss: 6.54370695e-07
Iter: 247 loss: 6.54316295e-07
Iter: 248 loss: 6.54253768e-07
Iter: 249 loss: 6.54249845e-07
Iter: 250 loss: 6.54121436e-07
Iter: 251 loss: 6.5507038e-07
Iter: 252 loss: 6.54125529e-07
Iter: 253 loss: 6.54083806e-07
Iter: 254 loss: 6.54014457e-07
Iter: 255 loss: 6.55351187e-07
Iter: 256 loss: 6.54010705e-07
Iter: 257 loss: 6.5398217e-07
Iter: 258 loss: 6.53974666e-07
Iter: 259 loss: 6.53935899e-07
Iter: 260 loss: 6.53842903e-07
Iter: 261 loss: 6.55146664e-07
Iter: 262 loss: 6.53830512e-07
Iter: 263 loss: 6.53805046e-07
Iter: 264 loss: 6.5380334e-07
Iter: 265 loss: 6.53771849e-07
Iter: 266 loss: 6.54136e-07
Iter: 267 loss: 6.53770655e-07
Iter: 268 loss: 6.53750647e-07
Iter: 269 loss: 6.53710231e-07
Iter: 270 loss: 6.54386668e-07
Iter: 271 loss: 6.53710117e-07
Iter: 272 loss: 6.53657196e-07
Iter: 273 loss: 6.53769916e-07
Iter: 274 loss: 6.53629627e-07
Iter: 275 loss: 6.53584493e-07
Iter: 276 loss: 6.5351162e-07
Iter: 277 loss: 6.53504742e-07
Iter: 278 loss: 6.53499e-07
Iter: 279 loss: 6.5345796e-07
Iter: 280 loss: 6.53405095e-07
Iter: 281 loss: 6.53369113e-07
Iter: 282 loss: 6.53352913e-07
Iter: 283 loss: 6.53330972e-07
Iter: 284 loss: 6.533283e-07
Iter: 285 loss: 6.53299082e-07
Iter: 286 loss: 6.53243831e-07
Iter: 287 loss: 6.53686527e-07
Iter: 288 loss: 6.53252812e-07
Iter: 289 loss: 6.53225129e-07
Iter: 290 loss: 6.53219786e-07
Iter: 291 loss: 6.5320296e-07
Iter: 292 loss: 6.5323286e-07
Iter: 293 loss: 6.53192615e-07
Iter: 294 loss: 6.53168627e-07
Iter: 295 loss: 6.53206712e-07
Iter: 296 loss: 6.53146685e-07
Iter: 297 loss: 6.53119855e-07
Iter: 298 loss: 6.53363145e-07
Iter: 299 loss: 6.53113602e-07
Iter: 300 loss: 6.53088478e-07
Iter: 301 loss: 6.53008385e-07
Iter: 302 loss: 6.53840061e-07
Iter: 303 loss: 6.52996619e-07
Iter: 304 loss: 6.52915787e-07
Iter: 305 loss: 6.53481152e-07
Iter: 306 loss: 6.52903452e-07
Iter: 307 loss: 6.52843426e-07
Iter: 308 loss: 6.5280733e-07
Iter: 309 loss: 6.52773849e-07
Iter: 310 loss: 6.5273241e-07
Iter: 311 loss: 6.52728147e-07
Iter: 312 loss: 6.52666472e-07
Iter: 313 loss: 6.52782205e-07
Iter: 314 loss: 6.52650215e-07
Iter: 315 loss: 6.52617814e-07
Iter: 316 loss: 6.52968197e-07
Iter: 317 loss: 6.52616052e-07
Iter: 318 loss: 6.52586039e-07
Iter: 319 loss: 6.52511062e-07
Iter: 320 loss: 6.53506959e-07
Iter: 321 loss: 6.52507651e-07
Iter: 322 loss: 6.52468316e-07
Iter: 323 loss: 6.52468486e-07
Iter: 324 loss: 6.52442e-07
Iter: 325 loss: 6.52404424e-07
Iter: 326 loss: 6.52408517e-07
Iter: 327 loss: 6.52366396e-07
Iter: 328 loss: 6.52435801e-07
Iter: 329 loss: 6.5233985e-07
Iter: 330 loss: 6.52305459e-07
Iter: 331 loss: 6.52353719e-07
Iter: 332 loss: 6.52288406e-07
Iter: 333 loss: 6.52235883e-07
Iter: 334 loss: 6.52549829e-07
Iter: 335 loss: 6.52226504e-07
Iter: 336 loss: 6.52200299e-07
Iter: 337 loss: 6.52138965e-07
Iter: 338 loss: 6.52905669e-07
Iter: 339 loss: 6.52135384e-07
Iter: 340 loss: 6.52044776e-07
Iter: 341 loss: 6.52428298e-07
Iter: 342 loss: 6.52015274e-07
Iter: 343 loss: 6.519561e-07
Iter: 344 loss: 6.52130041e-07
Iter: 345 loss: 6.51921312e-07
Iter: 346 loss: 6.51888513e-07
Iter: 347 loss: 6.51869925e-07
Iter: 348 loss: 6.5184463e-07
Iter: 349 loss: 6.51884932e-07
Iter: 350 loss: 6.51830817e-07
Iter: 351 loss: 6.51788127e-07
Iter: 352 loss: 6.51814219e-07
Iter: 353 loss: 6.51762207e-07
Iter: 354 loss: 6.51724235e-07
Iter: 355 loss: 6.51720939e-07
Iter: 356 loss: 6.5169894e-07
Iter: 357 loss: 6.51638516e-07
Iter: 358 loss: 6.51932851e-07
Iter: 359 loss: 6.51625498e-07
Iter: 360 loss: 6.51596508e-07
Iter: 361 loss: 6.51600942e-07
Iter: 362 loss: 6.51575306e-07
Iter: 363 loss: 6.51538699e-07
Iter: 364 loss: 6.51495498e-07
Iter: 365 loss: 6.51492428e-07
Iter: 366 loss: 6.51460425e-07
Iter: 367 loss: 6.51452297e-07
Iter: 368 loss: 6.51431606e-07
Iter: 369 loss: 6.51373227e-07
Iter: 370 loss: 6.51760729e-07
Iter: 371 loss: 6.51359414e-07
Iter: 372 loss: 6.51253231e-07
Iter: 373 loss: 6.51418645e-07
Iter: 374 loss: 6.51195137e-07
Iter: 375 loss: 6.51096116e-07
Iter: 376 loss: 6.52572226e-07
Iter: 377 loss: 6.51093274e-07
Iter: 378 loss: 6.5104166e-07
Iter: 379 loss: 6.51710479e-07
Iter: 380 loss: 6.5104507e-07
Iter: 381 loss: 6.51011476e-07
Iter: 382 loss: 6.51133178e-07
Iter: 383 loss: 6.50994934e-07
Iter: 384 loss: 6.50970833e-07
Iter: 385 loss: 6.51199571e-07
Iter: 386 loss: 6.50968502e-07
Iter: 387 loss: 6.509581e-07
Iter: 388 loss: 6.509282e-07
Iter: 389 loss: 6.51162168e-07
Iter: 390 loss: 6.50918309e-07
Iter: 391 loss: 6.50904894e-07
Iter: 392 loss: 6.50898585e-07
Iter: 393 loss: 6.50885e-07
Iter: 394 loss: 6.50845095e-07
Iter: 395 loss: 6.51138294e-07
Iter: 396 loss: 6.50846744e-07
Iter: 397 loss: 6.50807692e-07
Iter: 398 loss: 6.51048e-07
Iter: 399 loss: 6.50803145e-07
Iter: 400 loss: 6.50767e-07
Iter: 401 loss: 6.50950483e-07
Iter: 402 loss: 6.5075568e-07
Iter: 403 loss: 6.50708614e-07
Iter: 404 loss: 6.50665129e-07
Iter: 405 loss: 6.5066115e-07
Iter: 406 loss: 6.50597258e-07
Iter: 407 loss: 6.50546269e-07
Iter: 408 loss: 6.50530126e-07
Iter: 409 loss: 6.50453103e-07
Iter: 410 loss: 6.51400569e-07
Iter: 411 loss: 6.50456172e-07
Iter: 412 loss: 6.50401489e-07
Iter: 413 loss: 6.50921947e-07
Iter: 414 loss: 6.50405354e-07
Iter: 415 loss: 6.50369316e-07
Iter: 416 loss: 6.50536549e-07
Iter: 417 loss: 6.50359766e-07
Iter: 418 loss: 6.50340837e-07
Iter: 419 loss: 6.50492439e-07
Iter: 420 loss: 6.50342713e-07
Iter: 421 loss: 6.50318668e-07
Iter: 422 loss: 6.50277798e-07
Iter: 423 loss: 6.5072112e-07
Iter: 424 loss: 6.50268248e-07
Iter: 425 loss: 6.50260631e-07
Iter: 426 loss: 6.50249319e-07
Iter: 427 loss: 6.50229367e-07
Iter: 428 loss: 6.50188952e-07
Iter: 429 loss: 6.50879656e-07
Iter: 430 loss: 6.50185e-07
Iter: 431 loss: 6.50122615e-07
Iter: 432 loss: 6.5011676e-07
Iter: 433 loss: 6.50079301e-07
Iter: 434 loss: 6.50023651e-07
Iter: 435 loss: 6.50014385e-07
Iter: 436 loss: 6.49974538e-07
Iter: 437 loss: 6.49964534e-07
Iter: 438 loss: 6.49937419e-07
Iter: 439 loss: 6.49885123e-07
Iter: 440 loss: 6.49882963e-07
Iter: 441 loss: 6.49842718e-07
Iter: 442 loss: 6.49781555e-07
Iter: 443 loss: 6.49747619e-07
Iter: 444 loss: 6.49720391e-07
Iter: 445 loss: 6.49716412e-07
Iter: 446 loss: 6.49677531e-07
Iter: 447 loss: 6.49632511e-07
Iter: 448 loss: 6.49664116e-07
Iter: 449 loss: 6.49626713e-07
Iter: 450 loss: 6.49581636e-07
Iter: 451 loss: 6.49878928e-07
Iter: 452 loss: 6.49571689e-07
Iter: 453 loss: 6.49537299e-07
Iter: 454 loss: 6.49553442e-07
Iter: 455 loss: 6.49521098e-07
Iter: 456 loss: 6.49483468e-07
Iter: 457 loss: 6.49466074e-07
Iter: 458 loss: 6.49456581e-07
Iter: 459 loss: 6.49424919e-07
Iter: 460 loss: 6.49418894e-07
Iter: 461 loss: 6.49401898e-07
Iter: 462 loss: 6.49349658e-07
Iter: 463 loss: 6.49638878e-07
Iter: 464 loss: 6.4933181e-07
Iter: 465 loss: 6.49257402e-07
Iter: 466 loss: 6.49561912e-07
Iter: 467 loss: 6.49235858e-07
Iter: 468 loss: 6.49169237e-07
Iter: 469 loss: 6.50238348e-07
Iter: 470 loss: 6.49173614e-07
Iter: 471 loss: 6.49142919e-07
Iter: 472 loss: 6.4908761e-07
Iter: 473 loss: 6.5005139e-07
Iter: 474 loss: 6.49085507e-07
Iter: 475 loss: 6.49007802e-07
Iter: 476 loss: 6.49148774e-07
Iter: 477 loss: 6.48983189e-07
Iter: 478 loss: 6.48923788e-07
Iter: 479 loss: 6.49095e-07
Iter: 480 loss: 6.48904916e-07
Iter: 481 loss: 6.48859498e-07
Iter: 482 loss: 6.49081301e-07
Iter: 483 loss: 6.48854723e-07
Iter: 484 loss: 6.4884e-07
Iter: 485 loss: 6.48828063e-07
Iter: 486 loss: 6.48817945e-07
Iter: 487 loss: 6.48819082e-07
Iter: 488 loss: 6.48800324e-07
Iter: 489 loss: 6.48770367e-07
Iter: 490 loss: 6.48913e-07
Iter: 491 loss: 6.48763603e-07
Iter: 492 loss: 6.48738876e-07
Iter: 493 loss: 6.48797709e-07
Iter: 494 loss: 6.48731884e-07
Iter: 495 loss: 6.48713694e-07
Iter: 496 loss: 6.48641162e-07
Iter: 497 loss: 6.48923276e-07
Iter: 498 loss: 6.48618766e-07
Iter: 499 loss: 6.48593755e-07
Iter: 500 loss: 6.48581135e-07
Iter: 501 loss: 6.48531341e-07
Iter: 502 loss: 6.48440164e-07
Iter: 503 loss: 6.49962772e-07
Iter: 504 loss: 6.48428227e-07
Iter: 505 loss: 6.48367177e-07
Iter: 506 loss: 6.48626894e-07
Iter: 507 loss: 6.48353819e-07
Iter: 508 loss: 6.48343644e-07
Iter: 509 loss: 6.48332218e-07
Iter: 510 loss: 6.48317268e-07
Iter: 511 loss: 6.48273272e-07
Iter: 512 loss: 6.4899757e-07
Iter: 513 loss: 6.48270259e-07
Iter: 514 loss: 6.4824593e-07
Iter: 515 loss: 6.48293792e-07
Iter: 516 loss: 6.48236608e-07
Iter: 517 loss: 6.48199148e-07
Iter: 518 loss: 6.48177092e-07
Iter: 519 loss: 6.48171465e-07
Iter: 520 loss: 6.48128434e-07
Iter: 521 loss: 6.4813247e-07
Iter: 522 loss: 6.48090293e-07
Iter: 523 loss: 6.48121045e-07
Iter: 524 loss: 6.48081823e-07
Iter: 525 loss: 6.4805e-07
Iter: 526 loss: 6.48221715e-07
Iter: 527 loss: 6.48050275e-07
Iter: 528 loss: 6.48031346e-07
Iter: 529 loss: 6.48004118e-07
Iter: 530 loss: 6.47998434e-07
Iter: 531 loss: 6.47966317e-07
Iter: 532 loss: 6.48091259e-07
Iter: 533 loss: 6.47956597e-07
Iter: 534 loss: 6.47900606e-07
Iter: 535 loss: 6.47982802e-07
Iter: 536 loss: 6.47883326e-07
Iter: 537 loss: 6.47836828e-07
Iter: 538 loss: 6.47778961e-07
Iter: 539 loss: 6.47778847e-07
Iter: 540 loss: 6.47691934e-07
Iter: 541 loss: 6.47757247e-07
Iter: 542 loss: 6.47651291e-07
Iter: 543 loss: 6.47696822e-07
Iter: 544 loss: 6.47623551e-07
Iter: 545 loss: 6.4760161e-07
Iter: 546 loss: 6.47606271e-07
Iter: 547 loss: 6.47575803e-07
Iter: 548 loss: 6.47559546e-07
Iter: 549 loss: 6.47561933e-07
Iter: 550 loss: 6.47538059e-07
Iter: 551 loss: 6.47505829e-07
Iter: 552 loss: 6.47687784e-07
Iter: 553 loss: 6.47494e-07
Iter: 554 loss: 6.47460297e-07
Iter: 555 loss: 6.47478942e-07
Iter: 556 loss: 6.47424827e-07
Iter: 557 loss: 6.47383615e-07
Iter: 558 loss: 6.47684828e-07
Iter: 559 loss: 6.47382194e-07
Iter: 560 loss: 6.47342063e-07
Iter: 561 loss: 6.47315119e-07
Iter: 562 loss: 6.47303921e-07
Iter: 563 loss: 6.47241734e-07
Iter: 564 loss: 6.47281581e-07
Iter: 565 loss: 6.47198135e-07
Iter: 566 loss: 6.47168349e-07
Iter: 567 loss: 6.47170395e-07
Iter: 568 loss: 6.47131174e-07
Iter: 569 loss: 6.47073875e-07
Iter: 570 loss: 6.48515e-07
Iter: 571 loss: 6.47076718e-07
Iter: 572 loss: 6.47034426e-07
Iter: 573 loss: 6.47008335e-07
Iter: 574 loss: 6.4698088e-07
Iter: 575 loss: 6.46901185e-07
Iter: 576 loss: 6.47170225e-07
Iter: 577 loss: 6.4687822e-07
Iter: 578 loss: 6.46890783e-07
Iter: 579 loss: 6.46841499e-07
Iter: 580 loss: 6.46830131e-07
Iter: 581 loss: 6.4678477e-07
Iter: 582 loss: 6.47642764e-07
Iter: 583 loss: 6.4678909e-07
Iter: 584 loss: 6.46768626e-07
Iter: 585 loss: 6.47108664e-07
Iter: 586 loss: 6.46760441e-07
Iter: 587 loss: 6.46740375e-07
Iter: 588 loss: 6.46783349e-07
Iter: 589 loss: 6.46732929e-07
Iter: 590 loss: 6.46704734e-07
Iter: 591 loss: 6.46713602e-07
Iter: 592 loss: 6.46687283e-07
Iter: 593 loss: 6.46657497e-07
Iter: 594 loss: 6.47108834e-07
Iter: 595 loss: 6.46661192e-07
Iter: 596 loss: 6.46633339e-07
Iter: 597 loss: 6.4658e-07
Iter: 598 loss: 6.46980254e-07
Iter: 599 loss: 6.46578883e-07
Iter: 600 loss: 6.4651158e-07
Iter: 601 loss: 6.4727908e-07
Iter: 602 loss: 6.46497597e-07
Iter: 603 loss: 6.46455476e-07
Iter: 604 loss: 6.46516924e-07
Iter: 605 loss: 6.46413696e-07
Iter: 606 loss: 6.46381807e-07
Iter: 607 loss: 6.463506e-07
Iter: 608 loss: 6.46345313e-07
Iter: 609 loss: 6.46294779e-07
Iter: 610 loss: 6.46220712e-07
Iter: 611 loss: 6.46218382e-07
Iter: 612 loss: 6.46131866e-07
Iter: 613 loss: 6.46681e-07
Iter: 614 loss: 6.46130047e-07
Iter: 615 loss: 6.46079229e-07
Iter: 616 loss: 6.46063711e-07
Iter: 617 loss: 6.46036312e-07
Iter: 618 loss: 6.4599476e-07
Iter: 619 loss: 6.46618e-07
Iter: 620 loss: 6.4598305e-07
Iter: 621 loss: 6.45941611e-07
Iter: 622 loss: 6.46496915e-07
Iter: 623 loss: 6.45938201e-07
Iter: 624 loss: 6.45909495e-07
Iter: 625 loss: 6.46369756e-07
Iter: 626 loss: 6.45909779e-07
Iter: 627 loss: 6.45892726e-07
Iter: 628 loss: 6.45874422e-07
Iter: 629 loss: 6.45862883e-07
Iter: 630 loss: 6.45826503e-07
Iter: 631 loss: 6.45982539e-07
Iter: 632 loss: 6.45813884e-07
Iter: 633 loss: 6.45769035e-07
Iter: 634 loss: 6.45702357e-07
Iter: 635 loss: 6.45696616e-07
Iter: 636 loss: 6.45678142e-07
Iter: 637 loss: 6.45651653e-07
Iter: 638 loss: 6.45623345e-07
Iter: 639 loss: 6.45579121e-07
Iter: 640 loss: 6.45585715e-07
Iter: 641 loss: 6.45543878e-07
Iter: 642 loss: 6.45599357e-07
Iter: 643 loss: 6.45540638e-07
Iter: 644 loss: 6.45510511e-07
Iter: 645 loss: 6.45494538e-07
Iter: 646 loss: 6.45470038e-07
Iter: 647 loss: 6.45423825e-07
Iter: 648 loss: 6.4553285e-07
Iter: 649 loss: 6.45403475e-07
Iter: 650 loss: 6.45390628e-07
Iter: 651 loss: 6.45378066e-07
Iter: 652 loss: 6.45350781e-07
Iter: 653 loss: 6.45271655e-07
Iter: 654 loss: 6.46335366e-07
Iter: 655 loss: 6.45270177e-07
Iter: 656 loss: 6.45263071e-07
Iter: 657 loss: 6.45240675e-07
Iter: 658 loss: 6.45225612e-07
Iter: 659 loss: 6.45211e-07
Iter: 660 loss: 6.45200032e-07
Iter: 661 loss: 6.45181728e-07
Iter: 662 loss: 6.45559908e-07
Iter: 663 loss: 6.4517792e-07
Iter: 664 loss: 6.45164619e-07
Iter: 665 loss: 6.45116529e-07
Iter: 666 loss: 6.4544065e-07
Iter: 667 loss: 6.45101636e-07
Iter: 668 loss: 6.45055138e-07
Iter: 669 loss: 6.45603222e-07
Iter: 670 loss: 6.45051216e-07
Iter: 671 loss: 6.45015348e-07
Iter: 672 loss: 6.45149953e-07
Iter: 673 loss: 6.45013529e-07
Iter: 674 loss: 6.44981242e-07
Iter: 675 loss: 6.44914394e-07
Iter: 676 loss: 6.46211902e-07
Iter: 677 loss: 6.44914508e-07
Iter: 678 loss: 6.44829868e-07
Iter: 679 loss: 6.44857664e-07
Iter: 680 loss: 6.44781494e-07
Iter: 681 loss: 6.4469765e-07
Iter: 682 loss: 6.44947875e-07
Iter: 683 loss: 6.44676277e-07
Iter: 684 loss: 6.44575493e-07
Iter: 685 loss: 6.44916781e-07
Iter: 686 loss: 6.44553495e-07
Iter: 687 loss: 6.4443941e-07
Iter: 688 loss: 6.45333728e-07
Iter: 689 loss: 6.44430656e-07
Iter: 690 loss: 6.44382851e-07
Iter: 691 loss: 6.4446408e-07
Iter: 692 loss: 6.44357556e-07
Iter: 693 loss: 6.44301394e-07
Iter: 694 loss: 6.44781608e-07
Iter: 695 loss: 6.44293095e-07
Iter: 696 loss: 6.44275929e-07
Iter: 697 loss: 6.44385352e-07
Iter: 698 loss: 6.44262514e-07
Iter: 699 loss: 6.44246143e-07
Iter: 700 loss: 6.44208967e-07
Iter: 701 loss: 6.44208399e-07
Iter: 702 loss: 6.44166e-07
Iter: 703 loss: 6.44180659e-07
Iter: 704 loss: 6.441403e-07
Iter: 705 loss: 6.44090392e-07
Iter: 706 loss: 6.44098691e-07
Iter: 707 loss: 6.44068336e-07
Iter: 708 loss: 6.44012232e-07
Iter: 709 loss: 6.44011948e-07
Iter: 710 loss: 6.43933618e-07
Iter: 711 loss: 6.44015699e-07
Iter: 712 loss: 6.43891156e-07
Iter: 713 loss: 6.43818794e-07
Iter: 714 loss: 6.43869214e-07
Iter: 715 loss: 6.43777412e-07
Iter: 716 loss: 6.43712269e-07
Iter: 717 loss: 6.43934072e-07
Iter: 718 loss: 6.43688111e-07
Iter: 719 loss: 6.43647581e-07
Iter: 720 loss: 6.43648832e-07
Iter: 721 loss: 6.43596536e-07
Iter: 722 loss: 6.43525937e-07
Iter: 723 loss: 6.43527301e-07
Iter: 724 loss: 6.43510703e-07
Iter: 725 loss: 6.43502801e-07
Iter: 726 loss: 6.43478131e-07
Iter: 727 loss: 6.4344971e-07
Iter: 728 loss: 6.43431235e-07
Iter: 729 loss: 6.43423448e-07
Iter: 730 loss: 6.43424073e-07
Iter: 731 loss: 6.43408669e-07
Iter: 732 loss: 6.43374335e-07
Iter: 733 loss: 6.43599378e-07
Iter: 734 loss: 6.43368594e-07
Iter: 735 loss: 6.43344492e-07
Iter: 736 loss: 6.43495582e-07
Iter: 737 loss: 6.43340741e-07
Iter: 738 loss: 6.43299586e-07
Iter: 739 loss: 6.43516955e-07
Iter: 740 loss: 6.43303395e-07
Iter: 741 loss: 6.43263434e-07
Iter: 742 loss: 6.43218641e-07
Iter: 743 loss: 6.44309353e-07
Iter: 744 loss: 6.43220233e-07
Iter: 745 loss: 6.43154806e-07
Iter: 746 loss: 6.43221426e-07
Iter: 747 loss: 6.43120416e-07
Iter: 748 loss: 6.43048338e-07
Iter: 749 loss: 6.43361659e-07
Iter: 750 loss: 6.43036572e-07
Iter: 751 loss: 6.43014971e-07
Iter: 752 loss: 6.43014744e-07
Iter: 753 loss: 6.42987914e-07
Iter: 754 loss: 6.42982229e-07
Iter: 755 loss: 6.42978421e-07
Iter: 756 loss: 6.42960686e-07
Iter: 757 loss: 6.43058854e-07
Iter: 758 loss: 6.42954205e-07
Iter: 759 loss: 6.42924761e-07
Iter: 760 loss: 6.4295142e-07
Iter: 761 loss: 6.42917144e-07
Iter: 762 loss: 6.42888949e-07
Iter: 763 loss: 6.42904524e-07
Iter: 764 loss: 6.42860186e-07
Iter: 765 loss: 6.4280124e-07
Iter: 766 loss: 6.42746159e-07
Iter: 767 loss: 6.42739337e-07
Iter: 768 loss: 6.42672887e-07
Iter: 769 loss: 6.42944769e-07
Iter: 770 loss: 6.42664531e-07
Iter: 771 loss: 6.42630653e-07
Iter: 772 loss: 6.42625082e-07
Iter: 773 loss: 6.42589612e-07
Iter: 774 loss: 6.42552891e-07
Iter: 775 loss: 6.42552607e-07
Iter: 776 loss: 6.42492864e-07
Iter: 777 loss: 6.4254084e-07
Iter: 778 loss: 6.42461487e-07
Iter: 779 loss: 6.42392251e-07
Iter: 780 loss: 6.42462851e-07
Iter: 781 loss: 6.42361044e-07
Iter: 782 loss: 6.42329e-07
Iter: 783 loss: 6.42320515e-07
Iter: 784 loss: 6.42285954e-07
Iter: 785 loss: 6.42251507e-07
Iter: 786 loss: 6.42238774e-07
Iter: 787 loss: 6.42219675e-07
Iter: 788 loss: 6.42475925e-07
Iter: 789 loss: 6.42216264e-07
Iter: 790 loss: 6.42187388e-07
Iter: 791 loss: 6.4244125e-07
Iter: 792 loss: 6.42186478e-07
Iter: 793 loss: 6.42171e-07
Iter: 794 loss: 6.42139867e-07
Iter: 795 loss: 6.42130772e-07
Iter: 796 loss: 6.42095529e-07
Iter: 797 loss: 6.42199609e-07
Iter: 798 loss: 6.42083478e-07
Iter: 799 loss: 6.420658e-07
Iter: 800 loss: 6.42006398e-07
Iter: 801 loss: 6.42003727e-07
Iter: 802 loss: 6.41975589e-07
Iter: 803 loss: 6.41967176e-07
Iter: 804 loss: 6.41922384e-07
Iter: 805 loss: 6.41887482e-07
Iter: 806 loss: 6.41879694e-07
Iter: 807 loss: 6.41812335e-07
Iter: 808 loss: 6.41926704e-07
Iter: 809 loss: 6.41795339e-07
Iter: 810 loss: 6.41725535e-07
Iter: 811 loss: 6.42081204e-07
Iter: 812 loss: 6.41714621e-07
Iter: 813 loss: 6.41672102e-07
Iter: 814 loss: 6.41769248e-07
Iter: 815 loss: 6.41656811e-07
Iter: 816 loss: 6.41638053e-07
Iter: 817 loss: 6.41625718e-07
Iter: 818 loss: 6.41612075e-07
Iter: 819 loss: 6.41580471e-07
Iter: 820 loss: 6.41580641e-07
Iter: 821 loss: 6.415504e-07
Iter: 822 loss: 6.41649535e-07
Iter: 823 loss: 6.41541362e-07
Iter: 824 loss: 6.41506631e-07
Iter: 825 loss: 6.41503675e-07
Iter: 826 loss: 6.41489351e-07
Iter: 827 loss: 6.41477754e-07
Iter: 828 loss: 6.41470081e-07
Iter: 829 loss: 6.41435804e-07
Iter: 830 loss: 6.4155563e-07
Iter: 831 loss: 6.41433587e-07
Iter: 832 loss: 6.41414204e-07
Iter: 833 loss: 6.41362e-07
Iter: 834 loss: 6.41364181e-07
Iter: 835 loss: 6.41341558e-07
Iter: 836 loss: 6.41334054e-07
Iter: 837 loss: 6.41306201e-07
Iter: 838 loss: 6.41255554e-07
Iter: 839 loss: 6.42316e-07
Iter: 840 loss: 6.41252427e-07
Iter: 841 loss: 6.41224233e-07
Iter: 842 loss: 6.41266354e-07
Iter: 843 loss: 6.41220254e-07
Iter: 844 loss: 6.41171255e-07
Iter: 845 loss: 6.41170971e-07
Iter: 846 loss: 6.4115477e-07
Iter: 847 loss: 6.41120153e-07
Iter: 848 loss: 6.41564782e-07
Iter: 849 loss: 6.41121574e-07
Iter: 850 loss: 6.41099518e-07
Iter: 851 loss: 6.41305178e-07
Iter: 852 loss: 6.41092242e-07
Iter: 853 loss: 6.41084e-07
Iter: 854 loss: 6.41060637e-07
Iter: 855 loss: 6.41462464e-07
Iter: 856 loss: 6.41060922e-07
Iter: 857 loss: 6.41011e-07
Iter: 858 loss: 6.41295685e-07
Iter: 859 loss: 6.41015447e-07
Iter: 860 loss: 6.40970313e-07
Iter: 861 loss: 6.41115889e-07
Iter: 862 loss: 6.40961048e-07
Iter: 863 loss: 6.40934957e-07
Iter: 864 loss: 6.40963606e-07
Iter: 865 loss: 6.40915232e-07
Iter: 866 loss: 6.40881069e-07
Iter: 867 loss: 6.40995268e-07
Iter: 868 loss: 6.40862e-07
Iter: 869 loss: 6.4084486e-07
Iter: 870 loss: 6.40814676e-07
Iter: 871 loss: 6.40806e-07
Iter: 872 loss: 6.40818e-07
Iter: 873 loss: 6.40802796e-07
Iter: 874 loss: 6.40796202e-07
Iter: 875 loss: 6.40761e-07
Iter: 876 loss: 6.41047109e-07
Iter: 877 loss: 6.40766871e-07
Iter: 878 loss: 6.40719634e-07
Iter: 879 loss: 6.40713097e-07
Iter: 880 loss: 6.40676376e-07
Iter: 881 loss: 6.40618964e-07
Iter: 882 loss: 6.41353665e-07
Iter: 883 loss: 6.40613337e-07
Iter: 884 loss: 6.40583096e-07
Iter: 885 loss: 6.40768576e-07
Iter: 886 loss: 6.40573489e-07
Iter: 887 loss: 6.40528469e-07
Iter: 888 loss: 6.40580765e-07
Iter: 889 loss: 6.40500218e-07
Iter: 890 loss: 6.40465203e-07
Iter: 891 loss: 6.40439623e-07
Iter: 892 loss: 6.40434109e-07
Iter: 893 loss: 6.40426265e-07
Iter: 894 loss: 6.4041626e-07
Iter: 895 loss: 6.40403357e-07
Iter: 896 loss: 6.40395683e-07
Iter: 897 loss: 6.40380904e-07
Iter: 898 loss: 6.40362259e-07
Iter: 899 loss: 6.40563712e-07
Iter: 900 loss: 6.40366352e-07
Iter: 901 loss: 6.40348048e-07
Iter: 902 loss: 6.40333155e-07
Iter: 903 loss: 6.40898293e-07
Iter: 904 loss: 6.4033037e-07
Iter: 905 loss: 6.40286771e-07
Iter: 906 loss: 6.40606345e-07
Iter: 907 loss: 6.40276767e-07
Iter: 908 loss: 6.40253575e-07
Iter: 909 loss: 6.40219866e-07
Iter: 910 loss: 6.40217422e-07
Iter: 911 loss: 6.40184453e-07
Iter: 912 loss: 6.40168309e-07
Iter: 913 loss: 6.40154951e-07
Iter: 914 loss: 6.40119197e-07
Iter: 915 loss: 6.40072869e-07
Iter: 916 loss: 6.40065082e-07
Iter: 917 loss: 6.40025519e-07
Iter: 918 loss: 6.40370331e-07
Iter: 919 loss: 6.40019664e-07
Iter: 920 loss: 6.39992322e-07
Iter: 921 loss: 6.40141366e-07
Iter: 922 loss: 6.39993686e-07
Iter: 923 loss: 6.39949747e-07
Iter: 924 loss: 6.40032738e-07
Iter: 925 loss: 6.39942812e-07
Iter: 926 loss: 6.39913878e-07
Iter: 927 loss: 6.40008579e-07
Iter: 928 loss: 6.39903874e-07
Iter: 929 loss: 6.39889208e-07
Iter: 930 loss: 6.39868176e-07
Iter: 931 loss: 6.39857888e-07
Iter: 932 loss: 6.39822531e-07
Iter: 933 loss: 6.39882046e-07
Iter: 934 loss: 6.39807467e-07
Iter: 935 loss: 6.39774612e-07
Iter: 936 loss: 6.39773418e-07
Iter: 937 loss: 6.39756877e-07
Iter: 938 loss: 6.39724306e-07
Iter: 939 loss: 6.40084863e-07
Iter: 940 loss: 6.39736527e-07
Iter: 941 loss: 6.39703e-07
Iter: 942 loss: 6.39703e-07
Iter: 943 loss: 6.39664449e-07
Iter: 944 loss: 6.39604821e-07
Iter: 945 loss: 6.39609254e-07
Iter: 946 loss: 6.39548546e-07
Iter: 947 loss: 6.39551217e-07
Iter: 948 loss: 6.39520522e-07
Iter: 949 loss: 6.3947607e-07
Iter: 950 loss: 6.39461291e-07
Iter: 951 loss: 6.39422e-07
Iter: 952 loss: 6.39428379e-07
Iter: 953 loss: 6.3938171e-07
Iter: 954 loss: 6.39380289e-07
Iter: 955 loss: 6.39373411e-07
Iter: 956 loss: 6.39362042e-07
Iter: 957 loss: 6.39358348e-07
Iter: 958 loss: 6.39354312e-07
Iter: 959 loss: 6.39337145e-07
Iter: 960 loss: 6.3941161e-07
Iter: 961 loss: 6.39317136e-07
Iter: 962 loss: 6.39303721e-07
Iter: 963 loss: 6.39288942e-07
Iter: 964 loss: 6.39282234e-07
Iter: 965 loss: 6.39256427e-07
Iter: 966 loss: 6.39567e-07
Iter: 967 loss: 6.39250402e-07
Iter: 968 loss: 6.39221469e-07
Iter: 969 loss: 6.3917912e-07
Iter: 970 loss: 6.39183213e-07
Iter: 971 loss: 6.39138136e-07
Iter: 972 loss: 6.3923369e-07
Iter: 973 loss: 6.3912e-07
Iter: 974 loss: 6.39060545e-07
Iter: 975 loss: 6.39296786e-07
Iter: 976 loss: 6.39053724e-07
Iter: 977 loss: 6.39026439e-07
Iter: 978 loss: 6.38989036e-07
Iter: 979 loss: 6.38983806e-07
Iter: 980 loss: 6.38933273e-07
Iter: 981 loss: 6.3907e-07
Iter: 982 loss: 6.38915367e-07
Iter: 983 loss: 6.38876e-07
Iter: 984 loss: 6.38870858e-07
Iter: 985 loss: 6.38845336e-07
Iter: 986 loss: 6.38809411e-07
Iter: 987 loss: 6.3881123e-07
Iter: 988 loss: 6.38743131e-07
Iter: 989 loss: 6.39069242e-07
Iter: 990 loss: 6.38751544e-07
Iter: 991 loss: 6.38713971e-07
Iter: 992 loss: 6.38836241e-07
Iter: 993 loss: 6.38701067e-07
Iter: 994 loss: 6.38671622e-07
Iter: 995 loss: 6.38687936e-07
Iter: 996 loss: 6.38657809e-07
Iter: 997 loss: 6.38641382e-07
Iter: 998 loss: 6.38815322e-07
Iter: 999 loss: 6.38639e-07
Iter: 1000 loss: 6.38610743e-07
Iter: 1001 loss: 6.38577831e-07
Iter: 1002 loss: 6.38577376e-07
Iter: 1003 loss: 6.38546908e-07
Iter: 1004 loss: 6.38529968e-07
Iter: 1005 loss: 6.38506435e-07
Iter: 1006 loss: 6.38473921e-07
Iter: 1007 loss: 6.38470055e-07
Iter: 1008 loss: 6.38431118e-07
Iter: 1009 loss: 6.38339202e-07
Iter: 1010 loss: 6.38961126e-07
Iter: 1011 loss: 6.38318056e-07
Iter: 1012 loss: 6.38247684e-07
Iter: 1013 loss: 6.38797417e-07
Iter: 1014 loss: 6.38237736e-07
Iter: 1015 loss: 6.38197434e-07
Iter: 1016 loss: 6.38223241e-07
Iter: 1017 loss: 6.38178392e-07
Iter: 1018 loss: 6.38147355e-07
Iter: 1019 loss: 6.3813809e-07
Iter: 1020 loss: 6.3812405e-07
Iter: 1021 loss: 6.38112056e-07
Iter: 1022 loss: 6.38108531e-07
Iter: 1023 loss: 6.38071356e-07
Iter: 1024 loss: 6.38205222e-07
Iter: 1025 loss: 6.38044469e-07
Iter: 1026 loss: 6.38042252e-07
Iter: 1027 loss: 6.38042877e-07
Iter: 1028 loss: 6.38004281e-07
Iter: 1029 loss: 6.37959033e-07
Iter: 1030 loss: 6.37908101e-07
Iter: 1031 loss: 6.37905941e-07
Iter: 1032 loss: 6.3791191e-07
Iter: 1033 loss: 6.37883943e-07
Iter: 1034 loss: 6.37868879e-07
Iter: 1035 loss: 6.37839e-07
Iter: 1036 loss: 6.38594315e-07
Iter: 1037 loss: 6.37838241e-07
Iter: 1038 loss: 6.37817152e-07
Iter: 1039 loss: 6.38013944e-07
Iter: 1040 loss: 6.37808057e-07
Iter: 1041 loss: 6.37773155e-07
Iter: 1042 loss: 6.37768835e-07
Iter: 1043 loss: 6.37742687e-07
Iter: 1044 loss: 6.37719836e-07
Iter: 1045 loss: 6.3771779e-07
Iter: 1046 loss: 6.37697326e-07
Iter: 1047 loss: 6.37653272e-07
Iter: 1048 loss: 6.37847677e-07
Iter: 1049 loss: 6.37654e-07
Iter: 1050 loss: 6.37630933e-07
Iter: 1051 loss: 6.37631047e-07
Iter: 1052 loss: 6.37620929e-07
Iter: 1053 loss: 6.3761297e-07
Iter: 1054 loss: 6.37594553e-07
Iter: 1055 loss: 6.37595463e-07
Iter: 1056 loss: 6.375883e-07
Iter: 1057 loss: 6.37591086e-07
Iter: 1058 loss: 6.3759262e-07
Iter: 1059 loss: 6.37591711e-07
Iter: 1060 loss: 6.37594042e-07
Iter: 1061 loss: 6.37589039e-07
Iter: 1062 loss: 6.37587277e-07
Iter: 1063 loss: 6.37593928e-07
Iter: 1064 loss: 6.37592393e-07
Iter: 1065 loss: 6.37590347e-07
Iter: 1066 loss: 6.37591597e-07
Iter: 1067 loss: 6.37593416e-07
Iter: 1068 loss: 6.37593359e-07
Iter: 1069 loss: 6.3759262e-07
Iter: 1070 loss: 6.37592564e-07
Iter: 1071 loss: 6.37595349e-07
Iter: 1072 loss: 6.37595292e-07
Iter: 1073 loss: 6.37592393e-07
Iter: 1074 loss: 6.37595178e-07
Iter: 1075 loss: 6.37595463e-07
Iter: 1076 loss: 6.37595235e-07
Iter: 1077 loss: 6.37595122e-07
Iter: 1078 loss: 6.37595178e-07
Iter: 1079 loss: 6.37595178e-07
Iter: 1080 loss: 6.37595235e-07
Iter: 1081 loss: 6.37576932e-07
Iter: 1082 loss: 6.37557946e-07
Iter: 1083 loss: 6.37835797e-07
Iter: 1084 loss: 6.37559083e-07
Iter: 1085 loss: 6.37514063e-07
Iter: 1086 loss: 6.37518554e-07
Iter: 1087 loss: 6.37495759e-07
Iter: 1088 loss: 6.37436642e-07
Iter: 1089 loss: 6.37788503e-07
Iter: 1090 loss: 6.37426183e-07
Iter: 1091 loss: 6.37369737e-07
Iter: 1092 loss: 6.37497521e-07
Iter: 1093 loss: 6.37345067e-07
Iter: 1094 loss: 6.37286689e-07
Iter: 1095 loss: 6.3738139e-07
Iter: 1096 loss: 6.37286803e-07
Iter: 1097 loss: 6.37248604e-07
Iter: 1098 loss: 6.37262247e-07
Iter: 1099 loss: 6.37236212e-07
Iter: 1100 loss: 6.3719574e-07
Iter: 1101 loss: 6.37578808e-07
Iter: 1102 loss: 6.37198696e-07
Iter: 1103 loss: 6.37185167e-07
Iter: 1104 loss: 6.37155438e-07
Iter: 1105 loss: 6.37605e-07
Iter: 1106 loss: 6.37162543e-07
Iter: 1107 loss: 6.37136338e-07
Iter: 1108 loss: 6.37346943e-07
Iter: 1109 loss: 6.37135e-07
Iter: 1110 loss: 6.37116045e-07
Iter: 1111 loss: 6.37180733e-07
Iter: 1112 loss: 6.3710695e-07
Iter: 1113 loss: 6.37070229e-07
Iter: 1114 loss: 6.37055166e-07
Iter: 1115 loss: 6.37042945e-07
Iter: 1116 loss: 6.37016e-07
Iter: 1117 loss: 6.37223536e-07
Iter: 1118 loss: 6.37009634e-07
Iter: 1119 loss: 6.36976893e-07
Iter: 1120 loss: 6.37007133e-07
Iter: 1121 loss: 6.36973255e-07
Iter: 1122 loss: 6.3693426e-07
Iter: 1123 loss: 6.36929826e-07
Iter: 1124 loss: 6.36890036e-07
Iter: 1125 loss: 6.36832908e-07
Iter: 1126 loss: 6.37574885e-07
Iter: 1127 loss: 6.36831544e-07
Iter: 1128 loss: 6.36786581e-07
Iter: 1129 loss: 6.36839218e-07
Iter: 1130 loss: 6.36769244e-07
Iter: 1131 loss: 6.36723541e-07
Iter: 1132 loss: 6.36741561e-07
Iter: 1133 loss: 6.36684319e-07
Iter: 1134 loss: 6.36628442e-07
Iter: 1135 loss: 6.37053461e-07
Iter: 1136 loss: 6.36627703e-07
Iter: 1137 loss: 6.36583707e-07
Iter: 1138 loss: 6.36691482e-07
Iter: 1139 loss: 6.3656131e-07
Iter: 1140 loss: 6.36534651e-07
Iter: 1141 loss: 6.36526579e-07
Iter: 1142 loss: 6.36518621e-07
Iter: 1143 loss: 6.36506e-07
Iter: 1144 loss: 6.36490938e-07
Iter: 1145 loss: 6.36480877e-07
Iter: 1146 loss: 6.36429945e-07
Iter: 1147 loss: 6.36492132e-07
Iter: 1148 loss: 6.36396294e-07
Iter: 1149 loss: 6.36340644e-07
Iter: 1150 loss: 6.3634559e-07
Iter: 1151 loss: 6.36311597e-07
Iter: 1152 loss: 6.36452114e-07
Iter: 1153 loss: 6.36311597e-07
Iter: 1154 loss: 6.36281072e-07
Iter: 1155 loss: 6.36249524e-07
Iter: 1156 loss: 6.36252139e-07
Iter: 1157 loss: 6.36194954e-07
Iter: 1158 loss: 6.36832908e-07
Iter: 1159 loss: 6.36198195e-07
Iter: 1160 loss: 6.36158461e-07
Iter: 1161 loss: 6.36230311e-07
Iter: 1162 loss: 6.3615073e-07
Iter: 1163 loss: 6.3611526e-07
Iter: 1164 loss: 6.36242419e-07
Iter: 1165 loss: 6.36112e-07
Iter: 1166 loss: 6.36078425e-07
Iter: 1167 loss: 6.3607115e-07
Iter: 1168 loss: 6.36053642e-07
Iter: 1169 loss: 6.36015955e-07
Iter: 1170 loss: 6.3654e-07
Iter: 1171 loss: 6.36016068e-07
Iter: 1172 loss: 6.35995036e-07
Iter: 1173 loss: 6.3594365e-07
Iter: 1174 loss: 6.35944843e-07
Iter: 1175 loss: 6.35908123e-07
Iter: 1176 loss: 6.35916422e-07
Iter: 1177 loss: 6.35894196e-07
Iter: 1178 loss: 6.35928e-07
Iter: 1179 loss: 6.35882e-07
Iter: 1180 loss: 6.35867423e-07
Iter: 1181 loss: 6.35831441e-07
Iter: 1182 loss: 6.3590528e-07
Iter: 1183 loss: 6.35796198e-07
Iter: 1184 loss: 6.35726e-07
Iter: 1185 loss: 6.35989693e-07
Iter: 1186 loss: 6.35708091e-07
Iter: 1187 loss: 6.35611855e-07
Iter: 1188 loss: 6.36402e-07
Iter: 1189 loss: 6.35603328e-07
Iter: 1190 loss: 6.35543529e-07
Iter: 1191 loss: 6.35434e-07
Iter: 1192 loss: 6.35444394e-07
Iter: 1193 loss: 6.35374477e-07
Iter: 1194 loss: 6.3536811e-07
Iter: 1195 loss: 6.3532525e-07
Iter: 1196 loss: 6.35492086e-07
Iter: 1197 loss: 6.35309e-07
Iter: 1198 loss: 6.35288131e-07
Iter: 1199 loss: 6.35327865e-07
Iter: 1200 loss: 6.35268862e-07
Iter: 1201 loss: 6.35230776e-07
Iter: 1202 loss: 6.35309448e-07
Iter: 1203 loss: 6.35226229e-07
Iter: 1204 loss: 6.35187689e-07
Iter: 1205 loss: 6.35459685e-07
Iter: 1206 loss: 6.35182118e-07
Iter: 1207 loss: 6.35158813e-07
Iter: 1208 loss: 6.35084518e-07
Iter: 1209 loss: 6.35770846e-07
Iter: 1210 loss: 6.35081392e-07
Iter: 1211 loss: 6.35046717e-07
Iter: 1212 loss: 6.35046945e-07
Iter: 1213 loss: 6.34997832e-07
Iter: 1214 loss: 6.34932576e-07
Iter: 1215 loss: 6.34913249e-07
Iter: 1216 loss: 6.34855212e-07
Iter: 1217 loss: 6.34796493e-07
Iter: 1218 loss: 6.34780804e-07
Iter: 1219 loss: 6.34702474e-07
Iter: 1220 loss: 6.3469912e-07
Iter: 1221 loss: 6.34638354e-07
Iter: 1222 loss: 6.34925868e-07
Iter: 1223 loss: 6.34631533e-07
Iter: 1224 loss: 6.34572132e-07
Iter: 1225 loss: 6.34545415e-07
Iter: 1226 loss: 6.34515e-07
Iter: 1227 loss: 6.34436731e-07
Iter: 1228 loss: 6.3443963e-07
Iter: 1229 loss: 6.34391313e-07
Iter: 1230 loss: 6.34351181e-07
Iter: 1231 loss: 6.34338846e-07
Iter: 1232 loss: 6.34286266e-07
Iter: 1233 loss: 6.35000788e-07
Iter: 1234 loss: 6.34281776e-07
Iter: 1235 loss: 6.34257503e-07
Iter: 1236 loss: 6.34270634e-07
Iter: 1237 loss: 6.34226808e-07
Iter: 1238 loss: 6.34182186e-07
Iter: 1239 loss: 6.34360561e-07
Iter: 1240 loss: 6.34169396e-07
Iter: 1241 loss: 6.34140406e-07
Iter: 1242 loss: 6.34053208e-07
Iter: 1243 loss: 6.34646426e-07
Iter: 1244 loss: 6.34031494e-07
Iter: 1245 loss: 6.34030073e-07
Iter: 1246 loss: 6.33978573e-07
Iter: 1247 loss: 6.33926106e-07
Iter: 1248 loss: 6.33813613e-07
Iter: 1249 loss: 6.34805815e-07
Iter: 1250 loss: 6.33794855e-07
Iter: 1251 loss: 6.33704417e-07
Iter: 1252 loss: 6.34394041e-07
Iter: 1253 loss: 6.33700211e-07
Iter: 1254 loss: 6.33655645e-07
Iter: 1255 loss: 6.34308037e-07
Iter: 1256 loss: 6.33646039e-07
Iter: 1257 loss: 6.33611194e-07
Iter: 1258 loss: 6.33626e-07
Iter: 1259 loss: 6.33595505e-07
Iter: 1260 loss: 6.33556624e-07
Iter: 1261 loss: 6.33717605e-07
Iter: 1262 loss: 6.33549917e-07
Iter: 1263 loss: 6.33510808e-07
Iter: 1264 loss: 6.33471586e-07
Iter: 1265 loss: 6.33468062e-07
Iter: 1266 loss: 6.33427248e-07
Iter: 1267 loss: 6.33998695e-07
Iter: 1268 loss: 6.33424634e-07
Iter: 1269 loss: 6.33397235e-07
Iter: 1270 loss: 6.33421337e-07
Iter: 1271 loss: 6.33385639e-07
Iter: 1272 loss: 6.33348236e-07
Iter: 1273 loss: 6.33661386e-07
Iter: 1274 loss: 6.3334096e-07
Iter: 1275 loss: 6.3331936e-07
Iter: 1276 loss: 6.33270702e-07
Iter: 1277 loss: 6.34121079e-07
Iter: 1278 loss: 6.33269678e-07
Iter: 1279 loss: 6.33209197e-07
Iter: 1280 loss: 6.33152354e-07
Iter: 1281 loss: 6.3313621e-07
Iter: 1282 loss: 6.33179866e-07
Iter: 1283 loss: 6.33099717e-07
Iter: 1284 loss: 6.33065667e-07
Iter: 1285 loss: 6.32957551e-07
Iter: 1286 loss: 6.33718173e-07
Iter: 1287 loss: 6.32922138e-07
Iter: 1288 loss: 6.32866943e-07
Iter: 1289 loss: 6.32867113e-07
Iter: 1290 loss: 6.32831814e-07
Iter: 1291 loss: 6.3297432e-07
Iter: 1292 loss: 6.32812771e-07
Iter: 1293 loss: 6.3278992e-07
Iter: 1294 loss: 6.32758315e-07
Iter: 1295 loss: 6.32752858e-07
Iter: 1296 loss: 6.3272887e-07
Iter: 1297 loss: 6.32730803e-07
Iter: 1298 loss: 6.32704257e-07
Iter: 1299 loss: 6.32695105e-07
Iter: 1300 loss: 6.32683395e-07
Iter: 1301 loss: 6.32651108e-07
Iter: 1302 loss: 6.32680553e-07
Iter: 1303 loss: 6.32638546e-07
Iter: 1304 loss: 6.32593583e-07
Iter: 1305 loss: 6.32845342e-07
Iter: 1306 loss: 6.32586762e-07
Iter: 1307 loss: 6.32565047e-07
Iter: 1308 loss: 6.32648266e-07
Iter: 1309 loss: 6.32534807e-07
Iter: 1310 loss: 6.32509057e-07
Iter: 1311 loss: 6.32461592e-07
Iter: 1312 loss: 6.32466879e-07
Iter: 1313 loss: 6.32413617e-07
Iter: 1314 loss: 6.32527e-07
Iter: 1315 loss: 6.32390311e-07
Iter: 1316 loss: 6.32360866e-07
Iter: 1317 loss: 6.32356318e-07
Iter: 1318 loss: 6.32332444e-07
Iter: 1319 loss: 6.32292085e-07
Iter: 1320 loss: 6.32755132e-07
Iter: 1321 loss: 6.32288675e-07
Iter: 1322 loss: 6.32236947e-07
Iter: 1323 loss: 6.32231888e-07
Iter: 1324 loss: 6.3220034e-07
Iter: 1325 loss: 6.32222736e-07
Iter: 1326 loss: 6.32180672e-07
Iter: 1327 loss: 6.32147874e-07
Iter: 1328 loss: 6.32492458e-07
Iter: 1329 loss: 6.32160209e-07
Iter: 1330 loss: 6.32126444e-07
Iter: 1331 loss: 6.32142473e-07
Iter: 1332 loss: 6.32115871e-07
Iter: 1333 loss: 6.32087676e-07
Iter: 1334 loss: 6.32195906e-07
Iter: 1335 loss: 6.3208131e-07
Iter: 1336 loss: 6.32058914e-07
Iter: 1337 loss: 6.32023045e-07
Iter: 1338 loss: 6.32024296e-07
Iter: 1339 loss: 6.31970238e-07
Iter: 1340 loss: 6.32243484e-07
Iter: 1341 loss: 6.31963303e-07
Iter: 1342 loss: 6.31905664e-07
Iter: 1343 loss: 6.31808291e-07
Iter: 1344 loss: 6.33727382e-07
Iter: 1345 loss: 6.31807438e-07
Iter: 1346 loss: 6.31720468e-07
Iter: 1347 loss: 6.31691137e-07
Iter: 1348 loss: 6.31641342e-07
Iter: 1349 loss: 6.31582168e-07
Iter: 1350 loss: 6.32046579e-07
Iter: 1351 loss: 6.31570174e-07
Iter: 1352 loss: 6.3152288e-07
Iter: 1353 loss: 6.31736725e-07
Iter: 1354 loss: 6.31497869e-07
Iter: 1355 loss: 6.31468708e-07
Iter: 1356 loss: 6.31378498e-07
Iter: 1357 loss: 6.32898264e-07
Iter: 1358 loss: 6.31382477e-07
Iter: 1359 loss: 6.31324269e-07
Iter: 1360 loss: 6.31963758e-07
Iter: 1361 loss: 6.3132245e-07
Iter: 1362 loss: 6.31289481e-07
Iter: 1363 loss: 6.31478372e-07
Iter: 1364 loss: 6.31276464e-07
Iter: 1365 loss: 6.31255659e-07
Iter: 1366 loss: 6.31364514e-07
Iter: 1367 loss: 6.31255318e-07
Iter: 1368 loss: 6.31225873e-07
Iter: 1369 loss: 6.31254125e-07
Iter: 1370 loss: 6.31204e-07
Iter: 1371 loss: 6.3118739e-07
Iter: 1372 loss: 6.31443299e-07
Iter: 1373 loss: 6.31183752e-07
Iter: 1374 loss: 6.31165676e-07
Iter: 1375 loss: 6.31135094e-07
Iter: 1376 loss: 6.31447563e-07
Iter: 1377 loss: 6.31131172e-07
Iter: 1378 loss: 6.31067337e-07
Iter: 1379 loss: 6.31236048e-07
Iter: 1380 loss: 6.31045339e-07
Iter: 1381 loss: 6.30966781e-07
Iter: 1382 loss: 6.31574267e-07
Iter: 1383 loss: 6.30975592e-07
Iter: 1384 loss: 6.3091818e-07
Iter: 1385 loss: 6.30859404e-07
Iter: 1386 loss: 6.30847637e-07
Iter: 1387 loss: 6.30780619e-07
Iter: 1388 loss: 6.31314151e-07
Iter: 1389 loss: 6.30780164e-07
Iter: 1390 loss: 6.30749128e-07
Iter: 1391 loss: 6.31303692e-07
Iter: 1392 loss: 6.30750435e-07
Iter: 1393 loss: 6.30719512e-07
Iter: 1394 loss: 6.30699333e-07
Iter: 1395 loss: 6.30702971e-07
Iter: 1396 loss: 6.3066858e-07
Iter: 1397 loss: 6.30742079e-07
Iter: 1398 loss: 6.30656075e-07
Iter: 1399 loss: 6.30612931e-07
Iter: 1400 loss: 6.30993668e-07
Iter: 1401 loss: 6.30614068e-07
Iter: 1402 loss: 6.30587806e-07
Iter: 1403 loss: 6.30552563e-07
Iter: 1404 loss: 6.30552734e-07
Iter: 1405 loss: 6.30522436e-07
Iter: 1406 loss: 6.30512773e-07
Iter: 1407 loss: 6.30503166e-07
Iter: 1408 loss: 6.30476165e-07
Iter: 1409 loss: 6.31128273e-07
Iter: 1410 loss: 6.30471163e-07
Iter: 1411 loss: 6.3043467e-07
Iter: 1412 loss: 6.30938359e-07
Iter: 1413 loss: 6.30431316e-07
Iter: 1414 loss: 6.30408636e-07
Iter: 1415 loss: 6.30370835e-07
Iter: 1416 loss: 6.30366173e-07
Iter: 1417 loss: 6.30314332e-07
Iter: 1418 loss: 6.30323711e-07
Iter: 1419 loss: 6.30290742e-07
Iter: 1420 loss: 6.30248792e-07
Iter: 1421 loss: 6.30615659e-07
Iter: 1422 loss: 6.30244e-07
Iter: 1423 loss: 6.30202692e-07
Iter: 1424 loss: 6.30167278e-07
Iter: 1425 loss: 6.30161708e-07
Iter: 1426 loss: 6.30098498e-07
Iter: 1427 loss: 6.30219233e-07
Iter: 1428 loss: 6.30088834e-07
Iter: 1429 loss: 6.30031252e-07
Iter: 1430 loss: 6.30343607e-07
Iter: 1431 loss: 6.30033696e-07
Iter: 1432 loss: 6.30004763e-07
Iter: 1433 loss: 6.30139198e-07
Iter: 1434 loss: 6.30001125e-07
Iter: 1435 loss: 6.29979411e-07
Iter: 1436 loss: 6.29947294e-07
Iter: 1437 loss: 6.29947863e-07
Iter: 1438 loss: 6.29925125e-07
Iter: 1439 loss: 6.29922056e-07
Iter: 1440 loss: 6.29897386e-07
Iter: 1441 loss: 6.29850433e-07
Iter: 1442 loss: 6.30683644e-07
Iter: 1443 loss: 6.2984526e-07
Iter: 1444 loss: 6.29800411e-07
Iter: 1445 loss: 6.29800809e-07
Iter: 1446 loss: 6.29752208e-07
Iter: 1447 loss: 6.29703834e-07
Iter: 1448 loss: 6.29693659e-07
Iter: 1449 loss: 6.29638635e-07
Iter: 1450 loss: 6.29923591e-07
Iter: 1451 loss: 6.29631813e-07
Iter: 1452 loss: 6.29600152e-07
Iter: 1453 loss: 6.29979297e-07
Iter: 1454 loss: 6.29599526e-07
Iter: 1455 loss: 6.29571105e-07
Iter: 1456 loss: 6.2957082e-07
Iter: 1457 loss: 6.29546662e-07
Iter: 1458 loss: 6.29532963e-07
Iter: 1459 loss: 6.29740384e-07
Iter: 1460 loss: 6.29523299e-07
Iter: 1461 loss: 6.29499709e-07
Iter: 1462 loss: 6.29527506e-07
Iter: 1463 loss: 6.29485726e-07
Iter: 1464 loss: 6.29456736e-07
Iter: 1465 loss: 6.29443548e-07
Iter: 1466 loss: 6.2942e-07
Iter: 1467 loss: 6.29379713e-07
Iter: 1468 loss: 6.29509202e-07
Iter: 1469 loss: 6.29353167e-07
Iter: 1470 loss: 6.29310364e-07
Iter: 1471 loss: 6.29246642e-07
Iter: 1472 loss: 6.29249882e-07
Iter: 1473 loss: 6.29159445e-07
Iter: 1474 loss: 6.29455201e-07
Iter: 1475 loss: 6.29146655e-07
Iter: 1476 loss: 6.29108456e-07
Iter: 1477 loss: 6.29095e-07
Iter: 1478 loss: 6.29062697e-07
Iter: 1479 loss: 6.29006308e-07
Iter: 1480 loss: 6.29012e-07
Iter: 1481 loss: 6.28961288e-07
Iter: 1482 loss: 6.29601345e-07
Iter: 1483 loss: 6.28953444e-07
Iter: 1484 loss: 6.28921271e-07
Iter: 1485 loss: 6.28909333e-07
Iter: 1486 loss: 6.28881651e-07
Iter: 1487 loss: 6.28836631e-07
Iter: 1488 loss: 6.29124e-07
Iter: 1489 loss: 6.2883214e-07
Iter: 1490 loss: 6.28789962e-07
Iter: 1491 loss: 6.29174792e-07
Iter: 1492 loss: 6.28793373e-07
Iter: 1493 loss: 6.2877109e-07
Iter: 1494 loss: 6.28757562e-07
Iter: 1495 loss: 6.28739826e-07
Iter: 1496 loss: 6.28723797e-07
Iter: 1497 loss: 6.29057467e-07
Iter: 1498 loss: 6.28726184e-07
Iter: 1499 loss: 6.28713053e-07
Iter: 1500 loss: 6.28687417e-07
Iter: 1501 loss: 6.28683949e-07
Iter: 1502 loss: 6.28643534e-07
Iter: 1503 loss: 6.28636371e-07
Iter: 1504 loss: 6.2862739e-07
Iter: 1505 loss: 6.28544853e-07
Iter: 1506 loss: 6.28575435e-07
Iter: 1507 loss: 6.2849665e-07
Iter: 1508 loss: 6.28420139e-07
Iter: 1509 loss: 6.28566738e-07
Iter: 1510 loss: 6.28386772e-07
Iter: 1511 loss: 6.28379098e-07
Iter: 1512 loss: 6.28339535e-07
Iter: 1513 loss: 6.28321686e-07
Iter: 1514 loss: 6.28293549e-07
Iter: 1515 loss: 6.28294913e-07
Iter: 1516 loss: 6.28269618e-07
Iter: 1517 loss: 6.28702537e-07
Iter: 1518 loss: 6.28270925e-07
Iter: 1519 loss: 6.28261546e-07
Iter: 1520 loss: 6.28256203e-07
Iter: 1521 loss: 6.28243583e-07
Iter: 1522 loss: 6.28221756e-07
Iter: 1523 loss: 6.28360453e-07
Iter: 1524 loss: 6.28225564e-07
Iter: 1525 loss: 6.28204873e-07
Iter: 1526 loss: 6.28203168e-07
Iter: 1527 loss: 6.28194243e-07
Iter: 1528 loss: 6.2817918e-07
Iter: 1529 loss: 6.2817378e-07
Iter: 1530 loss: 6.2815883e-07
Iter: 1531 loss: 6.28111366e-07
Iter: 1532 loss: 6.28263763e-07
Iter: 1533 loss: 6.28107841e-07
Iter: 1534 loss: 6.28076521e-07
Iter: 1535 loss: 6.28032353e-07
Iter: 1536 loss: 6.28034513e-07
Iter: 1537 loss: 6.28006831e-07
Iter: 1538 loss: 6.28425e-07
Iter: 1539 loss: 6.2800143e-07
Iter: 1540 loss: 6.27979148e-07
Iter: 1541 loss: 6.28029966e-07
Iter: 1542 loss: 6.27971076e-07
Iter: 1543 loss: 6.27958741e-07
Iter: 1544 loss: 6.27952886e-07
Iter: 1545 loss: 6.2794777e-07
Iter: 1546 loss: 6.2793697e-07
Iter: 1547 loss: 6.27935322e-07
Iter: 1548 loss: 6.2791861e-07
Iter: 1549 loss: 6.27894e-07
Iter: 1550 loss: 6.28303042e-07
Iter: 1551 loss: 6.27895247e-07
Iter: 1552 loss: 6.2787e-07
Iter: 1553 loss: 6.28163889e-07
Iter: 1554 loss: 6.27869326e-07
Iter: 1555 loss: 6.27864154e-07
Iter: 1556 loss: 6.27857958e-07
Iter: 1557 loss: 6.27858128e-07
Iter: 1558 loss: 6.27836357e-07
Iter: 1559 loss: 6.2802e-07
Iter: 1560 loss: 6.27837721e-07
Iter: 1561 loss: 6.27821919e-07
Iter: 1562 loss: 6.27832378e-07
Iter: 1563 loss: 6.27818451e-07
Iter: 1564 loss: 6.27801683e-07
Iter: 1565 loss: 6.27924408e-07
Iter: 1566 loss: 6.27798613e-07
Iter: 1567 loss: 6.27787585e-07
Iter: 1568 loss: 6.27792133e-07
Iter: 1569 loss: 6.27770419e-07
Iter: 1570 loss: 6.27747113e-07
Iter: 1571 loss: 6.27730287e-07
Iter: 1572 loss: 6.27732277e-07
Iter: 1573 loss: 6.27698057e-07
Iter: 1574 loss: 6.27998816e-07
Iter: 1575 loss: 6.27700786e-07
Iter: 1576 loss: 6.27669124e-07
Iter: 1577 loss: 6.27699e-07
Iter: 1578 loss: 6.27649513e-07
Iter: 1579 loss: 6.27632403e-07
Iter: 1580 loss: 6.27729605e-07
Iter: 1581 loss: 6.27635472e-07
Iter: 1582 loss: 6.27611541e-07
Iter: 1583 loss: 6.27613e-07
Iter: 1584 loss: 6.27597274e-07
Iter: 1585 loss: 6.27592726e-07
Iter: 1586 loss: 6.27597046e-07
Iter: 1587 loss: 6.2757772e-07
Iter: 1588 loss: 6.27616487e-07
Iter: 1589 loss: 6.27573513e-07
Iter: 1590 loss: 6.27553504e-07
Iter: 1591 loss: 6.27554641e-07
Iter: 1592 loss: 6.27541681e-07
Iter: 1593 loss: 6.27526e-07
Iter: 1594 loss: 6.27702889e-07
Iter: 1595 loss: 6.27516442e-07
Iter: 1596 loss: 6.27495865e-07
Iter: 1597 loss: 6.27486088e-07
Iter: 1598 loss: 6.27473582e-07
Iter: 1599 loss: 6.27437771e-07
Iter: 1600 loss: 6.27580391e-07
Iter: 1601 loss: 6.27434133e-07
Iter: 1602 loss: 6.27413044e-07
Iter: 1603 loss: 6.27442432e-07
Iter: 1604 loss: 6.27409236e-07
Iter: 1605 loss: 6.27379222e-07
Iter: 1606 loss: 6.27368877e-07
Iter: 1607 loss: 6.2734739e-07
Iter: 1608 loss: 6.27332668e-07
Iter: 1609 loss: 6.27553959e-07
Iter: 1610 loss: 6.27328575e-07
Iter: 1611 loss: 6.27296686e-07
Iter: 1612 loss: 6.27317036e-07
Iter: 1613 loss: 6.27282589e-07
Iter: 1614 loss: 6.27249e-07
Iter: 1615 loss: 6.27440954e-07
Iter: 1616 loss: 6.27254451e-07
Iter: 1617 loss: 6.27239331e-07
Iter: 1618 loss: 6.27442887e-07
Iter: 1619 loss: 6.27234954e-07
Iter: 1620 loss: 6.27225916e-07
Iter: 1621 loss: 6.27235067e-07
Iter: 1622 loss: 6.27220629e-07
Iter: 1623 loss: 6.27212955e-07
Iter: 1624 loss: 6.27203917e-07
Iter: 1625 loss: 6.27197608e-07
Iter: 1626 loss: 6.27178906e-07
Iter: 1627 loss: 6.27181748e-07
Iter: 1628 loss: 6.27164184e-07
Iter: 1629 loss: 6.27142526e-07
Iter: 1630 loss: 6.27357281e-07
Iter: 1631 loss: 6.27134568e-07
Iter: 1632 loss: 6.27126497e-07
Iter: 1633 loss: 6.27115242e-07
Iter: 1634 loss: 6.27107056e-07
Iter: 1635 loss: 6.27073689e-07
Iter: 1636 loss: 6.27204145e-07
Iter: 1637 loss: 6.27062e-07
Iter: 1638 loss: 6.27037537e-07
Iter: 1639 loss: 6.27077497e-07
Iter: 1640 loss: 6.27027589e-07
Iter: 1641 loss: 6.26993653e-07
Iter: 1642 loss: 6.26999622e-07
Iter: 1643 loss: 6.26972e-07
Iter: 1644 loss: 6.26948122e-07
Iter: 1645 loss: 6.27095233e-07
Iter: 1646 loss: 6.26942096e-07
Iter: 1647 loss: 6.26933456e-07
Iter: 1648 loss: 6.27002237e-07
Iter: 1649 loss: 6.26935957e-07
Iter: 1650 loss: 6.26902477e-07
Iter: 1651 loss: 6.26909809e-07
Iter: 1652 loss: 6.26906115e-07
Iter: 1653 loss: 6.26879455e-07
Iter: 1654 loss: 6.27116208e-07
Iter: 1655 loss: 6.26876499e-07
Iter: 1656 loss: 6.26858309e-07
Iter: 1657 loss: 6.26834662e-07
Iter: 1658 loss: 6.26826591e-07
Iter: 1659 loss: 6.26782253e-07
Iter: 1660 loss: 6.26999849e-07
Iter: 1661 loss: 6.26770543e-07
Iter: 1662 loss: 6.26740871e-07
Iter: 1663 loss: 6.26681413e-07
Iter: 1664 loss: 6.28046109e-07
Iter: 1665 loss: 6.26680503e-07
Iter: 1666 loss: 6.26668225e-07
Iter: 1667 loss: 6.26655265e-07
Iter: 1668 loss: 6.26644351e-07
Iter: 1669 loss: 6.26690223e-07
Iter: 1670 loss: 6.2663463e-07
Iter: 1671 loss: 6.2660672e-07
Iter: 1672 loss: 6.26658846e-07
Iter: 1673 loss: 6.26603764e-07
Iter: 1674 loss: 6.26562496e-07
Iter: 1675 loss: 6.2663878e-07
Iter: 1676 loss: 6.26556812e-07
Iter: 1677 loss: 6.26535893e-07
Iter: 1678 loss: 6.26682379e-07
Iter: 1679 loss: 6.2653e-07
Iter: 1680 loss: 6.26512644e-07
Iter: 1681 loss: 6.2647166e-07
Iter: 1682 loss: 6.27125246e-07
Iter: 1683 loss: 6.26470637e-07
Iter: 1684 loss: 6.26440908e-07
Iter: 1685 loss: 6.26441704e-07
Iter: 1686 loss: 6.26424e-07
Iter: 1687 loss: 6.26426527e-07
Iter: 1688 loss: 6.26400492e-07
Iter: 1689 loss: 6.26389351e-07
Iter: 1690 loss: 6.2667732e-07
Iter: 1691 loss: 6.26395774e-07
Iter: 1692 loss: 6.2637082e-07
Iter: 1693 loss: 6.26373549e-07
Iter: 1694 loss: 6.26368831e-07
Iter: 1695 loss: 6.26336941e-07
Iter: 1696 loss: 6.26408962e-07
Iter: 1697 loss: 6.26320798e-07
Iter: 1698 loss: 6.26289761e-07
Iter: 1699 loss: 6.26251108e-07
Iter: 1700 loss: 6.26251e-07
Iter: 1701 loss: 6.26199949e-07
Iter: 1702 loss: 6.26476208e-07
Iter: 1703 loss: 6.26193128e-07
Iter: 1704 loss: 6.26154531e-07
Iter: 1705 loss: 6.2615652e-07
Iter: 1706 loss: 6.26145265e-07
Iter: 1707 loss: 6.26164763e-07
Iter: 1708 loss: 6.26127076e-07
Iter: 1709 loss: 6.26117924e-07
Iter: 1710 loss: 6.26226779e-07
Iter: 1711 loss: 6.26123e-07
Iter: 1712 loss: 6.26106043e-07
Iter: 1713 loss: 6.26130372e-07
Iter: 1714 loss: 6.2610809e-07
Iter: 1715 loss: 6.2610178e-07
Iter: 1716 loss: 6.2607262e-07
Iter: 1717 loss: 6.26073188e-07
Iter: 1718 loss: 6.26053293e-07
Iter: 1719 loss: 6.26028e-07
Iter: 1720 loss: 6.26025098e-07
Iter: 1721 loss: 6.25976611e-07
Iter: 1722 loss: 6.26243946e-07
Iter: 1723 loss: 6.25972859e-07
Iter: 1724 loss: 6.25928692e-07
Iter: 1725 loss: 6.26056419e-07
Iter: 1726 loss: 6.25917721e-07
Iter: 1727 loss: 6.25896e-07
Iter: 1728 loss: 6.26308861e-07
Iter: 1729 loss: 6.25894529e-07
Iter: 1730 loss: 6.25878101e-07
Iter: 1731 loss: 6.2583473e-07
Iter: 1732 loss: 6.26482e-07
Iter: 1733 loss: 6.25836492e-07
Iter: 1734 loss: 6.25815119e-07
Iter: 1735 loss: 6.25819496e-07
Iter: 1736 loss: 6.25789198e-07
Iter: 1737 loss: 6.25781e-07
Iter: 1738 loss: 6.25776352e-07
Iter: 1739 loss: 6.25756911e-07
Iter: 1740 loss: 6.25979112e-07
Iter: 1741 loss: 6.25756797e-07
Iter: 1742 loss: 6.25739631e-07
Iter: 1743 loss: 6.25731104e-07
Iter: 1744 loss: 6.25722123e-07
Iter: 1745 loss: 6.25707344e-07
Iter: 1746 loss: 6.25841267e-07
Iter: 1747 loss: 6.2569876e-07
Iter: 1748 loss: 6.25679377e-07
Iter: 1749 loss: 6.25672328e-07
Iter: 1750 loss: 6.25666189e-07
Iter: 1751 loss: 6.25640496e-07
Iter: 1752 loss: 6.25685232e-07
Iter: 1753 loss: 6.25631628e-07
Iter: 1754 loss: 6.25623954e-07
Iter: 1755 loss: 6.25585074e-07
Iter: 1756 loss: 6.25589e-07
Iter: 1757 loss: 6.25546704e-07
Iter: 1758 loss: 6.25966663e-07
Iter: 1759 loss: 6.25548068e-07
Iter: 1760 loss: 6.25495431e-07
Iter: 1761 loss: 6.25723828e-07
Iter: 1762 loss: 6.25486109e-07
Iter: 1763 loss: 6.25446148e-07
Iter: 1764 loss: 6.2562242e-07
Iter: 1765 loss: 6.25441146e-07
Iter: 1766 loss: 6.25405164e-07
Iter: 1767 loss: 6.25406187e-07
Iter: 1768 loss: 6.25392488e-07
Iter: 1769 loss: 6.25374241e-07
Iter: 1770 loss: 6.25549319e-07
Iter: 1771 loss: 6.25368102e-07
Iter: 1772 loss: 6.25351561e-07
Iter: 1773 loss: 6.25391692e-07
Iter: 1774 loss: 6.25330301e-07
Iter: 1775 loss: 6.25319558e-07
Iter: 1776 loss: 6.25365715e-07
Iter: 1777 loss: 6.25317227e-07
Iter: 1778 loss: 6.25303471e-07
Iter: 1779 loss: 6.25275334e-07
Iter: 1780 loss: 6.25270332e-07
Iter: 1781 loss: 6.25249243e-07
Iter: 1782 loss: 6.25596215e-07
Iter: 1783 loss: 6.25242762e-07
Iter: 1784 loss: 6.25218263e-07
Iter: 1785 loss: 6.2517006e-07
Iter: 1786 loss: 6.25636972e-07
Iter: 1787 loss: 6.251679e-07
Iter: 1788 loss: 6.25092412e-07
Iter: 1789 loss: 6.25313533e-07
Iter: 1790 loss: 6.2507678e-07
Iter: 1791 loss: 6.25025791e-07
Iter: 1792 loss: 6.25202e-07
Iter: 1793 loss: 6.25014422e-07
Iter: 1794 loss: 6.24982874e-07
Iter: 1795 loss: 6.25323764e-07
Iter: 1796 loss: 6.2498242e-07
Iter: 1797 loss: 6.24949053e-07
Iter: 1798 loss: 6.25024086e-07
Iter: 1799 loss: 6.2494837e-07
Iter: 1800 loss: 6.24937456e-07
Iter: 1801 loss: 6.25044493e-07
Iter: 1802 loss: 6.2492586e-07
Iter: 1803 loss: 6.24914037e-07
Iter: 1804 loss: 6.24888173e-07
Iter: 1805 loss: 6.24883455e-07
Iter: 1806 loss: 6.24862935e-07
Iter: 1807 loss: 6.24863048e-07
Iter: 1808 loss: 6.248452e-07
Iter: 1809 loss: 6.24882e-07
Iter: 1810 loss: 6.24839572e-07
Iter: 1811 loss: 6.24826725e-07
Iter: 1812 loss: 6.24958773e-07
Iter: 1813 loss: 6.24826555e-07
Iter: 1814 loss: 6.24812287e-07
Iter: 1815 loss: 6.24783183e-07
Iter: 1816 loss: 6.24928589e-07
Iter: 1817 loss: 6.24791255e-07
Iter: 1818 loss: 6.2474362e-07
Iter: 1819 loss: 6.2474885e-07
Iter: 1820 loss: 6.247177e-07
Iter: 1821 loss: 6.24706558e-07
Iter: 1822 loss: 6.24688482e-07
Iter: 1823 loss: 6.24682343e-07
Iter: 1824 loss: 6.24650909e-07
Iter: 1825 loss: 6.24807512e-07
Iter: 1826 loss: 6.24636414e-07
Iter: 1827 loss: 6.24601171e-07
Iter: 1828 loss: 6.24695701e-07
Iter: 1829 loss: 6.2459759e-07
Iter: 1830 loss: 6.24588097e-07
Iter: 1831 loss: 6.24578206e-07
Iter: 1832 loss: 6.24565303e-07
Iter: 1833 loss: 6.24546374e-07
Iter: 1834 loss: 6.25081498e-07
Iter: 1835 loss: 6.24540576e-07
Iter: 1836 loss: 6.24519714e-07
Iter: 1837 loss: 6.24783297e-07
Iter: 1838 loss: 6.24513177e-07
Iter: 1839 loss: 6.24496465e-07
Iter: 1840 loss: 6.24492088e-07
Iter: 1841 loss: 6.24485551e-07
Iter: 1842 loss: 6.2447026e-07
Iter: 1843 loss: 6.24466907e-07
Iter: 1844 loss: 6.24447352e-07
Iter: 1845 loss: 6.24424388e-07
Iter: 1846 loss: 6.24920062e-07
Iter: 1847 loss: 6.24414497e-07
Iter: 1848 loss: 6.24388917e-07
Iter: 1849 loss: 6.24364247e-07
Iter: 1850 loss: 6.24362542e-07
Iter: 1851 loss: 6.24326901e-07
Iter: 1852 loss: 6.24713778e-07
Iter: 1853 loss: 6.24327186e-07
Iter: 1854 loss: 6.24294671e-07
Iter: 1855 loss: 6.24351799e-07
Iter: 1856 loss: 6.24267102e-07
Iter: 1857 loss: 6.24243057e-07
Iter: 1858 loss: 6.24284098e-07
Iter: 1859 loss: 6.24237032e-07
Iter: 1860 loss: 6.24209747e-07
Iter: 1861 loss: 6.24324798e-07
Iter: 1862 loss: 6.2420429e-07
Iter: 1863 loss: 6.24192637e-07
Iter: 1864 loss: 6.2418485e-07
Iter: 1865 loss: 6.24182803e-07
Iter: 1866 loss: 6.24159952e-07
Iter: 1867 loss: 6.24216682e-07
Iter: 1868 loss: 6.24155746e-07
Iter: 1869 loss: 6.24143865e-07
Iter: 1870 loss: 6.24129598e-07
Iter: 1871 loss: 6.24590484e-07
Iter: 1872 loss: 6.2412289e-07
Iter: 1873 loss: 6.24091911e-07
Iter: 1874 loss: 6.24090376e-07
Iter: 1875 loss: 6.24052404e-07
Iter: 1876 loss: 6.24131076e-07
Iter: 1877 loss: 6.24034385e-07
Iter: 1878 loss: 6.23998176e-07
Iter: 1879 loss: 6.24285121e-07
Iter: 1880 loss: 6.24002951e-07
Iter: 1881 loss: 6.23969356e-07
Iter: 1882 loss: 6.23924905e-07
Iter: 1883 loss: 6.24995721e-07
Iter: 1884 loss: 6.23929566e-07
Iter: 1885 loss: 6.23937694e-07
Iter: 1886 loss: 6.23907738e-07
Iter: 1887 loss: 6.23896199e-07
Iter: 1888 loss: 6.23973165e-07
Iter: 1889 loss: 6.23893e-07
Iter: 1890 loss: 6.23880396e-07
Iter: 1891 loss: 6.23852e-07
Iter: 1892 loss: 6.2418394e-07
Iter: 1893 loss: 6.23865844e-07
Iter: 1894 loss: 6.23841288e-07
Iter: 1895 loss: 6.24071163e-07
Iter: 1896 loss: 6.23841856e-07
Iter: 1897 loss: 6.23835206e-07
Iter: 1898 loss: 6.23802748e-07
Iter: 1899 loss: 6.23807125e-07
Iter: 1900 loss: 6.23779101e-07
Iter: 1901 loss: 6.23993969e-07
Iter: 1902 loss: 6.23782455e-07
Iter: 1903 loss: 6.23767392e-07
Iter: 1904 loss: 6.23724e-07
Iter: 1905 loss: 6.24458039e-07
Iter: 1906 loss: 6.23727487e-07
Iter: 1907 loss: 6.23694064e-07
Iter: 1908 loss: 6.2392246e-07
Iter: 1909 loss: 6.23694405e-07
Iter: 1910 loss: 6.23674964e-07
Iter: 1911 loss: 6.23665812e-07
Iter: 1912 loss: 6.23654046e-07
Iter: 1913 loss: 6.23629035e-07
Iter: 1914 loss: 6.23760286e-07
Iter: 1915 loss: 6.23623237e-07
Iter: 1916 loss: 6.23590381e-07
Iter: 1917 loss: 6.2389779e-07
Iter: 1918 loss: 6.23590267e-07
Iter: 1919 loss: 6.23563e-07
Iter: 1920 loss: 6.23551784e-07
Iter: 1921 loss: 6.23548e-07
Iter: 1922 loss: 6.23531719e-07
Iter: 1923 loss: 6.23528877e-07
Iter: 1924 loss: 6.23520691e-07
Iter: 1925 loss: 6.23495225e-07
Iter: 1926 loss: 6.23883693e-07
Iter: 1927 loss: 6.23498295e-07
Iter: 1928 loss: 6.23483231e-07
Iter: 1929 loss: 6.234784e-07
Iter: 1930 loss: 6.23468168e-07
Iter: 1931 loss: 6.23451456e-07
Iter: 1932 loss: 6.23453957e-07
Iter: 1933 loss: 6.23432754e-07
Iter: 1934 loss: 6.23601522e-07
Iter: 1935 loss: 6.23434062e-07
Iter: 1936 loss: 6.2342508e-07
Iter: 1937 loss: 6.23397113e-07
Iter: 1938 loss: 6.23771371e-07
Iter: 1939 loss: 6.23393817e-07
Iter: 1940 loss: 6.23356073e-07
Iter: 1941 loss: 6.23376536e-07
Iter: 1942 loss: 6.23330948e-07
Iter: 1943 loss: 6.23303322e-07
Iter: 1944 loss: 6.23303549e-07
Iter: 1945 loss: 6.23294795e-07
Iter: 1946 loss: 6.23251651e-07
Iter: 1947 loss: 6.23551387e-07
Iter: 1948 loss: 6.23248411e-07
Iter: 1949 loss: 6.23200094e-07
Iter: 1950 loss: 6.23198844e-07
Iter: 1951 loss: 6.23161441e-07
Iter: 1952 loss: 6.23137907e-07
Iter: 1953 loss: 6.23132337e-07
Iter: 1954 loss: 6.23121593e-07
Iter: 1955 loss: 6.23158769e-07
Iter: 1956 loss: 6.23105961e-07
Iter: 1957 loss: 6.23090614e-07
Iter: 1958 loss: 6.23166216e-07
Iter: 1959 loss: 6.23085327e-07
Iter: 1960 loss: 6.23075664e-07
Iter: 1961 loss: 6.23159451e-07
Iter: 1962 loss: 6.23069297e-07
Iter: 1963 loss: 6.23057e-07
Iter: 1964 loss: 6.23036613e-07
Iter: 1965 loss: 6.23038432e-07
Iter: 1966 loss: 6.23027177e-07
Iter: 1967 loss: 6.23018082e-07
Iter: 1968 loss: 6.23003473e-07
Iter: 1969 loss: 6.22978064e-07
Iter: 1970 loss: 6.23261656e-07
Iter: 1971 loss: 6.22973516e-07
Iter: 1972 loss: 6.22958169e-07
Iter: 1973 loss: 6.2290718e-07
Iter: 1974 loss: 6.2300478e-07
Iter: 1975 loss: 6.22881771e-07
Iter: 1976 loss: 6.22817709e-07
Iter: 1977 loss: 6.232126e-07
Iter: 1978 loss: 6.22810319e-07
Iter: 1979 loss: 6.22805487e-07
Iter: 1980 loss: 6.22799178e-07
Iter: 1981 loss: 6.22767857e-07
Iter: 1982 loss: 6.2276348e-07
Iter: 1983 loss: 6.22750463e-07
Iter: 1984 loss: 6.22724542e-07
Iter: 1985 loss: 6.22759899e-07
Iter: 1986 loss: 6.2271e-07
Iter: 1987 loss: 6.22695097e-07
Iter: 1988 loss: 6.22757796e-07
Iter: 1989 loss: 6.22681739e-07
Iter: 1990 loss: 6.22664288e-07
Iter: 1991 loss: 6.22886887e-07
Iter: 1992 loss: 6.22673042e-07
Iter: 1993 loss: 6.22654738e-07
Iter: 1994 loss: 6.22661616e-07
Iter: 1995 loss: 6.22646439e-07
Iter: 1996 loss: 6.22627169e-07
Iter: 1997 loss: 6.22670143e-07
Iter: 1998 loss: 6.2263166e-07
Iter: 1999 loss: 6.22614323e-07
Iter: 2000 loss: 6.22715561e-07
Iter: 2001 loss: 6.22609036e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4
+ date
Sun Nov  1 22:44:46 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4400228a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4400231730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440013cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44002ba950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44002ba6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44002ba730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4400137730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4400070840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44000702f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c7e9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c7d2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c7e9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c7e9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c6cb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c6de7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440008b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f43b0080a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44000dfea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44000dad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44000df2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c7ac0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c5f7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c7aca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c680c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c680950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c53cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c548d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c53c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c590158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c7690d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c587400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c4db158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c4db510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c750ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c42e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f439c669c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 3.0363834e-05
test_loss: 3.1310625e-05
train_loss: 9.8827095e-06
test_loss: 1.0176564e-05
train_loss: 5.1138622e-06
test_loss: 5.515479e-06
train_loss: 3.6596543e-06
test_loss: 4.068096e-06
train_loss: 3.25936e-06
test_loss: 3.2843946e-06
train_loss: 2.7782366e-06
test_loss: 2.855516e-06
train_loss: 2.3410612e-06
test_loss: 2.5535876e-06
train_loss: 2.498085e-06
test_loss: 2.3921532e-06
train_loss: 2.1150947e-06
test_loss: 2.3003622e-06
train_loss: 2.1150306e-06
test_loss: 2.2507415e-06
train_loss: 2.1661901e-06
test_loss: 2.127416e-06
train_loss: 1.8776209e-06
test_loss: 2.048944e-06
train_loss: 1.9338058e-06
test_loss: 1.9715806e-06
train_loss: 1.9455774e-06
test_loss: 1.9396143e-06
train_loss: 1.8575032e-06
test_loss: 1.9029831e-06
train_loss: 1.8029181e-06
test_loss: 1.8773277e-06
train_loss: 1.7560827e-06
test_loss: 1.8320437e-06
train_loss: 1.7975273e-06
test_loss: 1.8568109e-06
train_loss: 1.7669402e-06
test_loss: 1.8378728e-06
train_loss: 1.652772e-06
test_loss: 1.786956e-06
train_loss: 1.5953332e-06
test_loss: 1.7337037e-06
train_loss: 1.6486325e-06
test_loss: 1.7321362e-06
train_loss: 1.605176e-06
test_loss: 1.6914233e-06
train_loss: 1.5730755e-06
test_loss: 1.7042177e-06
train_loss: 1.5883571e-06
test_loss: 1.6706655e-06
train_loss: 1.596764e-06
test_loss: 1.6314345e-06
train_loss: 1.5736158e-06
test_loss: 1.6682836e-06
train_loss: 1.4916147e-06
test_loss: 1.6225276e-06
train_loss: 1.6047059e-06
test_loss: 1.6191879e-06
train_loss: 1.5613825e-06
test_loss: 1.6184981e-06
train_loss: 1.5769991e-06
test_loss: 1.6110731e-06
train_loss: 1.4976941e-06
test_loss: 1.6034671e-06
train_loss: 1.462491e-06
test_loss: 1.6181227e-06
train_loss: 1.4592617e-06
test_loss: 1.5762996e-06
train_loss: 1.4432381e-06
test_loss: 1.5659555e-06
train_loss: 1.4603754e-06
test_loss: 1.5627429e-06
train_loss: 1.4528208e-06
test_loss: 1.5455233e-06
train_loss: 1.4232021e-06
test_loss: 1.552463e-06
train_loss: 1.5413063e-06
test_loss: 1.5557218e-06
train_loss: 1.5003388e-06
test_loss: 1.5347491e-06
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 16000 --load_model /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.4/300_300_300_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.4/ --save_name 300_300_300_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6bdb4bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6bdbc7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69841c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6983b9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6983b9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6983b9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6983b92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6983081e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698308158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69832a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69832a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6982c3ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698267d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6982141e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698205f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698288d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698277d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698207510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698167d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698277d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698106950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698106d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb698106488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69809db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69809dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69809d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69806bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb69806b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6980be488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6800f22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6800d4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb680102f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb680040730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb6800f21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb680040d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb63474bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.43912894e-06
Iter: 2 loss: 1.4307808e-06
Iter: 3 loss: 1.55090083e-06
Iter: 4 loss: 1.43076261e-06
Iter: 5 loss: 1.42568854e-06
Iter: 6 loss: 1.44494402e-06
Iter: 7 loss: 1.42449687e-06
Iter: 8 loss: 1.42330828e-06
Iter: 9 loss: 1.4303879e-06
Iter: 10 loss: 1.42316389e-06
Iter: 11 loss: 1.42182762e-06
Iter: 12 loss: 1.4215284e-06
Iter: 13 loss: 1.42066688e-06
Iter: 14 loss: 1.42007207e-06
Iter: 15 loss: 1.42591864e-06
Iter: 16 loss: 1.42005524e-06
Iter: 17 loss: 1.41951125e-06
Iter: 18 loss: 1.42111958e-06
Iter: 19 loss: 1.41934288e-06
Iter: 20 loss: 1.41891428e-06
Iter: 21 loss: 1.41818032e-06
Iter: 22 loss: 1.41817941e-06
Iter: 23 loss: 1.41696626e-06
Iter: 24 loss: 1.41889223e-06
Iter: 25 loss: 1.416396e-06
Iter: 26 loss: 1.41629334e-06
Iter: 27 loss: 1.41598639e-06
Iter: 28 loss: 1.41563453e-06
Iter: 29 loss: 1.41496344e-06
Iter: 30 loss: 1.42813451e-06
Iter: 31 loss: 1.41495673e-06
Iter: 32 loss: 1.41453279e-06
Iter: 33 loss: 1.41569353e-06
Iter: 34 loss: 1.41437943e-06
Iter: 35 loss: 1.41408418e-06
Iter: 36 loss: 1.41452938e-06
Iter: 37 loss: 1.41393025e-06
Iter: 38 loss: 1.41358259e-06
Iter: 39 loss: 1.41493479e-06
Iter: 40 loss: 1.41350711e-06
Iter: 41 loss: 1.41344481e-06
Iter: 42 loss: 1.41334158e-06
Iter: 43 loss: 1.41319231e-06
Iter: 44 loss: 1.41289479e-06
Iter: 45 loss: 1.41647592e-06
Iter: 46 loss: 1.41287569e-06
Iter: 47 loss: 1.41284795e-06
Iter: 48 loss: 1.41273188e-06
Iter: 49 loss: 1.41264445e-06
Iter: 50 loss: 1.41236353e-06
Iter: 51 loss: 1.41298642e-06
Iter: 52 loss: 1.41220119e-06
Iter: 53 loss: 1.41210103e-06
Iter: 54 loss: 1.41199303e-06
Iter: 55 loss: 1.4118358e-06
Iter: 56 loss: 1.41161354e-06
Iter: 57 loss: 1.41161377e-06
Iter: 58 loss: 1.41134456e-06
Iter: 59 loss: 1.41359897e-06
Iter: 60 loss: 1.41134194e-06
Iter: 61 loss: 1.41118653e-06
Iter: 62 loss: 1.41101214e-06
Iter: 63 loss: 1.41099451e-06
Iter: 64 loss: 1.4107618e-06
Iter: 65 loss: 1.41113946e-06
Iter: 66 loss: 1.41063629e-06
Iter: 67 loss: 1.41049577e-06
Iter: 68 loss: 1.41019655e-06
Iter: 69 loss: 1.41548253e-06
Iter: 70 loss: 1.41018734e-06
Iter: 71 loss: 1.40990642e-06
Iter: 72 loss: 1.40990483e-06
Iter: 73 loss: 1.40966665e-06
Iter: 74 loss: 1.40934e-06
Iter: 75 loss: 1.41121791e-06
Iter: 76 loss: 1.40930774e-06
Iter: 77 loss: 1.40901534e-06
Iter: 78 loss: 1.40930536e-06
Iter: 79 loss: 1.40883617e-06
Iter: 80 loss: 1.40856332e-06
Iter: 81 loss: 1.40951079e-06
Iter: 82 loss: 1.40851921e-06
Iter: 83 loss: 1.40829343e-06
Iter: 84 loss: 1.40830036e-06
Iter: 85 loss: 1.40813393e-06
Iter: 86 loss: 1.40787222e-06
Iter: 87 loss: 1.4078712e-06
Iter: 88 loss: 1.40769589e-06
Iter: 89 loss: 1.40763336e-06
Iter: 90 loss: 1.40754219e-06
Iter: 91 loss: 1.4072923e-06
Iter: 92 loss: 1.4103988e-06
Iter: 93 loss: 1.40728412e-06
Iter: 94 loss: 1.40723751e-06
Iter: 95 loss: 1.40715235e-06
Iter: 96 loss: 1.40708914e-06
Iter: 97 loss: 1.40686825e-06
Iter: 98 loss: 1.4082334e-06
Iter: 99 loss: 1.40683392e-06
Iter: 100 loss: 1.40659336e-06
Iter: 101 loss: 1.40875113e-06
Iter: 102 loss: 1.40658506e-06
Iter: 103 loss: 1.40637121e-06
Iter: 104 loss: 1.40636917e-06
Iter: 105 loss: 1.40621853e-06
Iter: 106 loss: 1.40606619e-06
Iter: 107 loss: 1.40605971e-06
Iter: 108 loss: 1.40588895e-06
Iter: 109 loss: 1.40569216e-06
Iter: 110 loss: 1.4056709e-06
Iter: 111 loss: 1.40540646e-06
Iter: 112 loss: 1.40629936e-06
Iter: 113 loss: 1.40534655e-06
Iter: 114 loss: 1.40522957e-06
Iter: 115 loss: 1.40521684e-06
Iter: 116 loss: 1.40511384e-06
Iter: 117 loss: 1.40536918e-06
Iter: 118 loss: 1.40508337e-06
Iter: 119 loss: 1.40499174e-06
Iter: 120 loss: 1.4051775e-06
Iter: 121 loss: 1.40496695e-06
Iter: 122 loss: 1.4048353e-06
Iter: 123 loss: 1.40521342e-06
Iter: 124 loss: 1.40481939e-06
Iter: 125 loss: 1.40473469e-06
Iter: 126 loss: 1.4048361e-06
Iter: 127 loss: 1.40468035e-06
Iter: 128 loss: 1.40457928e-06
Iter: 129 loss: 1.40514612e-06
Iter: 130 loss: 1.40456689e-06
Iter: 131 loss: 1.40442944e-06
Iter: 132 loss: 1.40430802e-06
Iter: 133 loss: 1.40429233e-06
Iter: 134 loss: 1.40413113e-06
Iter: 135 loss: 1.40392183e-06
Iter: 136 loss: 1.40389841e-06
Iter: 137 loss: 1.40381758e-06
Iter: 138 loss: 1.40374073e-06
Iter: 139 loss: 1.40362772e-06
Iter: 140 loss: 1.40379348e-06
Iter: 141 loss: 1.40355792e-06
Iter: 142 loss: 1.40339864e-06
Iter: 143 loss: 1.40351972e-06
Iter: 144 loss: 1.40329689e-06
Iter: 145 loss: 1.40314319e-06
Iter: 146 loss: 1.40316524e-06
Iter: 147 loss: 1.4030619e-06
Iter: 148 loss: 1.40292343e-06
Iter: 149 loss: 1.40292241e-06
Iter: 150 loss: 1.40281418e-06
Iter: 151 loss: 1.4028999e-06
Iter: 152 loss: 1.40277075e-06
Iter: 153 loss: 1.40263455e-06
Iter: 154 loss: 1.4032222e-06
Iter: 155 loss: 1.40263592e-06
Iter: 156 loss: 1.40250893e-06
Iter: 157 loss: 1.40244799e-06
Iter: 158 loss: 1.40243435e-06
Iter: 159 loss: 1.40227542e-06
Iter: 160 loss: 1.40376392e-06
Iter: 161 loss: 1.40227087e-06
Iter: 162 loss: 1.40216696e-06
Iter: 163 loss: 1.40230543e-06
Iter: 164 loss: 1.40211171e-06
Iter: 165 loss: 1.40198483e-06
Iter: 166 loss: 1.40175791e-06
Iter: 167 loss: 1.4071635e-06
Iter: 168 loss: 1.40175473e-06
Iter: 169 loss: 1.40155385e-06
Iter: 170 loss: 1.40331326e-06
Iter: 171 loss: 1.40151917e-06
Iter: 172 loss: 1.40136649e-06
Iter: 173 loss: 1.40334635e-06
Iter: 174 loss: 1.40136785e-06
Iter: 175 loss: 1.40126281e-06
Iter: 176 loss: 1.40173256e-06
Iter: 177 loss: 1.40123416e-06
Iter: 178 loss: 1.40118925e-06
Iter: 179 loss: 1.40114241e-06
Iter: 180 loss: 1.4011157e-06
Iter: 181 loss: 1.40101e-06
Iter: 182 loss: 1.40164605e-06
Iter: 183 loss: 1.4009895e-06
Iter: 184 loss: 1.40090162e-06
Iter: 185 loss: 1.40109205e-06
Iter: 186 loss: 1.40087764e-06
Iter: 187 loss: 1.40079078e-06
Iter: 188 loss: 1.40141242e-06
Iter: 189 loss: 1.4007901e-06
Iter: 190 loss: 1.40069892e-06
Iter: 191 loss: 1.40058933e-06
Iter: 192 loss: 1.40058592e-06
Iter: 193 loss: 1.4004579e-06
Iter: 194 loss: 1.4016581e-06
Iter: 195 loss: 1.40043608e-06
Iter: 196 loss: 1.40032751e-06
Iter: 197 loss: 1.40069096e-06
Iter: 198 loss: 1.40028078e-06
Iter: 199 loss: 1.40018665e-06
Iter: 200 loss: 1.40018938e-06
Iter: 201 loss: 1.40010616e-06
Iter: 202 loss: 1.39998747e-06
Iter: 203 loss: 1.39997542e-06
Iter: 204 loss: 1.39989504e-06
Iter: 205 loss: 1.39980989e-06
Iter: 206 loss: 1.39978226e-06
Iter: 207 loss: 1.39972383e-06
Iter: 208 loss: 1.39972292e-06
Iter: 209 loss: 1.39966892e-06
Iter: 210 loss: 1.39952988e-06
Iter: 211 loss: 1.39972599e-06
Iter: 212 loss: 1.39949464e-06
Iter: 213 loss: 1.39941153e-06
Iter: 214 loss: 1.39956842e-06
Iter: 215 loss: 1.39937629e-06
Iter: 216 loss: 1.39926192e-06
Iter: 217 loss: 1.39989106e-06
Iter: 218 loss: 1.39925544e-06
Iter: 219 loss: 1.39918e-06
Iter: 220 loss: 1.3994345e-06
Iter: 221 loss: 1.39914778e-06
Iter: 222 loss: 1.39907115e-06
Iter: 223 loss: 1.3991e-06
Iter: 224 loss: 1.39901408e-06
Iter: 225 loss: 1.39892609e-06
Iter: 226 loss: 1.3991305e-06
Iter: 227 loss: 1.39889335e-06
Iter: 228 loss: 1.3987775e-06
Iter: 229 loss: 1.39915039e-06
Iter: 230 loss: 1.39874987e-06
Iter: 231 loss: 1.39865244e-06
Iter: 232 loss: 1.39867473e-06
Iter: 233 loss: 1.39857752e-06
Iter: 234 loss: 1.39846713e-06
Iter: 235 loss: 1.39846713e-06
Iter: 236 loss: 1.3983796e-06
Iter: 237 loss: 1.39827523e-06
Iter: 238 loss: 1.39827375e-06
Iter: 239 loss: 1.39819213e-06
Iter: 240 loss: 1.39822373e-06
Iter: 241 loss: 1.39813812e-06
Iter: 242 loss: 1.39803876e-06
Iter: 243 loss: 1.39880399e-06
Iter: 244 loss: 1.39802773e-06
Iter: 245 loss: 1.39797703e-06
Iter: 246 loss: 1.39798772e-06
Iter: 247 loss: 1.39793474e-06
Iter: 248 loss: 1.39786687e-06
Iter: 249 loss: 1.39830877e-06
Iter: 250 loss: 1.39785664e-06
Iter: 251 loss: 1.3978015e-06
Iter: 252 loss: 1.39783515e-06
Iter: 253 loss: 1.39776967e-06
Iter: 254 loss: 1.39765575e-06
Iter: 255 loss: 1.39791382e-06
Iter: 256 loss: 1.39762597e-06
Iter: 257 loss: 1.39756537e-06
Iter: 258 loss: 1.3975723e-06
Iter: 259 loss: 1.39750932e-06
Iter: 260 loss: 1.39740177e-06
Iter: 261 loss: 1.39834356e-06
Iter: 262 loss: 1.39739791e-06
Iter: 263 loss: 1.39730605e-06
Iter: 264 loss: 1.39723147e-06
Iter: 265 loss: 1.39721476e-06
Iter: 266 loss: 1.39708447e-06
Iter: 267 loss: 1.39728968e-06
Iter: 268 loss: 1.39703343e-06
Iter: 269 loss: 1.39693191e-06
Iter: 270 loss: 1.39799386e-06
Iter: 271 loss: 1.39694873e-06
Iter: 272 loss: 1.39685449e-06
Iter: 273 loss: 1.39697613e-06
Iter: 274 loss: 1.3968106e-06
Iter: 275 loss: 1.39671954e-06
Iter: 276 loss: 1.3971179e-06
Iter: 277 loss: 1.39670874e-06
Iter: 278 loss: 1.39663894e-06
Iter: 279 loss: 1.39668225e-06
Iter: 280 loss: 1.39657027e-06
Iter: 281 loss: 1.39651058e-06
Iter: 282 loss: 1.39696579e-06
Iter: 283 loss: 1.39650092e-06
Iter: 284 loss: 1.39641327e-06
Iter: 285 loss: 1.39651308e-06
Iter: 286 loss: 1.39638053e-06
Iter: 287 loss: 1.39628071e-06
Iter: 288 loss: 1.39672716e-06
Iter: 289 loss: 1.39626536e-06
Iter: 290 loss: 1.39618362e-06
Iter: 291 loss: 1.39612189e-06
Iter: 292 loss: 1.396117e-06
Iter: 293 loss: 1.39605334e-06
Iter: 294 loss: 1.39603617e-06
Iter: 295 loss: 1.39598581e-06
Iter: 296 loss: 1.39592089e-06
Iter: 297 loss: 1.39591521e-06
Iter: 298 loss: 1.39579902e-06
Iter: 299 loss: 1.39580084e-06
Iter: 300 loss: 1.39571114e-06
Iter: 301 loss: 1.39556846e-06
Iter: 302 loss: 1.39620647e-06
Iter: 303 loss: 1.39555596e-06
Iter: 304 loss: 1.39543477e-06
Iter: 305 loss: 1.39684948e-06
Iter: 306 loss: 1.39544738e-06
Iter: 307 loss: 1.39538656e-06
Iter: 308 loss: 1.39544204e-06
Iter: 309 loss: 1.39535678e-06
Iter: 310 loss: 1.39525832e-06
Iter: 311 loss: 1.39541135e-06
Iter: 312 loss: 1.39523786e-06
Iter: 313 loss: 1.39517113e-06
Iter: 314 loss: 1.39533483e-06
Iter: 315 loss: 1.39514361e-06
Iter: 316 loss: 1.39504903e-06
Iter: 317 loss: 1.39530687e-06
Iter: 318 loss: 1.39502629e-06
Iter: 319 loss: 1.39494421e-06
Iter: 320 loss: 1.39527435e-06
Iter: 321 loss: 1.39494421e-06
Iter: 322 loss: 1.39485724e-06
Iter: 323 loss: 1.39474753e-06
Iter: 324 loss: 1.39473673e-06
Iter: 325 loss: 1.39464441e-06
Iter: 326 loss: 1.39462747e-06
Iter: 327 loss: 1.39453232e-06
Iter: 328 loss: 1.39452e-06
Iter: 329 loss: 1.39444489e-06
Iter: 330 loss: 1.39433109e-06
Iter: 331 loss: 1.39449685e-06
Iter: 332 loss: 1.39426675e-06
Iter: 333 loss: 1.39416477e-06
Iter: 334 loss: 1.394523e-06
Iter: 335 loss: 1.39411168e-06
Iter: 336 loss: 1.39403573e-06
Iter: 337 loss: 1.39403187e-06
Iter: 338 loss: 1.39399845e-06
Iter: 339 loss: 1.39398094e-06
Iter: 340 loss: 1.39394376e-06
Iter: 341 loss: 1.39386862e-06
Iter: 342 loss: 1.39413703e-06
Iter: 343 loss: 1.39385543e-06
Iter: 344 loss: 1.39380222e-06
Iter: 345 loss: 1.39373958e-06
Iter: 346 loss: 1.3937065e-06
Iter: 347 loss: 1.39359099e-06
Iter: 348 loss: 1.39429289e-06
Iter: 349 loss: 1.39356951e-06
Iter: 350 loss: 1.39345707e-06
Iter: 351 loss: 1.3936974e-06
Iter: 352 loss: 1.39343467e-06
Iter: 353 loss: 1.39332872e-06
Iter: 354 loss: 1.39326653e-06
Iter: 355 loss: 1.39320241e-06
Iter: 356 loss: 1.39310191e-06
Iter: 357 loss: 1.39448389e-06
Iter: 358 loss: 1.39310168e-06
Iter: 359 loss: 1.39298936e-06
Iter: 360 loss: 1.39306258e-06
Iter: 361 loss: 1.39291706e-06
Iter: 362 loss: 1.39280837e-06
Iter: 363 loss: 1.3928792e-06
Iter: 364 loss: 1.3927297e-06
Iter: 365 loss: 1.39262e-06
Iter: 366 loss: 1.39285737e-06
Iter: 367 loss: 1.39256963e-06
Iter: 368 loss: 1.39247504e-06
Iter: 369 loss: 1.39246799e-06
Iter: 370 loss: 1.39239512e-06
Iter: 371 loss: 1.39230383e-06
Iter: 372 loss: 1.39229098e-06
Iter: 373 loss: 1.39218309e-06
Iter: 374 loss: 1.39364602e-06
Iter: 375 loss: 1.39216922e-06
Iter: 376 loss: 1.39210101e-06
Iter: 377 loss: 1.39201131e-06
Iter: 378 loss: 1.39200324e-06
Iter: 379 loss: 1.39186727e-06
Iter: 380 loss: 1.39306155e-06
Iter: 381 loss: 1.39186488e-06
Iter: 382 loss: 1.39177848e-06
Iter: 383 loss: 1.39193014e-06
Iter: 384 loss: 1.39172948e-06
Iter: 385 loss: 1.3916233e-06
Iter: 386 loss: 1.39170106e-06
Iter: 387 loss: 1.39155077e-06
Iter: 388 loss: 1.39145254e-06
Iter: 389 loss: 1.39188069e-06
Iter: 390 loss: 1.39140275e-06
Iter: 391 loss: 1.39126678e-06
Iter: 392 loss: 1.39154815e-06
Iter: 393 loss: 1.3912113e-06
Iter: 394 loss: 1.39107692e-06
Iter: 395 loss: 1.39107715e-06
Iter: 396 loss: 1.39097438e-06
Iter: 397 loss: 1.3908068e-06
Iter: 398 loss: 1.39127019e-06
Iter: 399 loss: 1.3907686e-06
Iter: 400 loss: 1.39066242e-06
Iter: 401 loss: 1.39065924e-06
Iter: 402 loss: 1.39056783e-06
Iter: 403 loss: 1.39054964e-06
Iter: 404 loss: 1.39050826e-06
Iter: 405 loss: 1.39041117e-06
Iter: 406 loss: 1.39149529e-06
Iter: 407 loss: 1.39041856e-06
Iter: 408 loss: 1.39034046e-06
Iter: 409 loss: 1.39026588e-06
Iter: 410 loss: 1.39026815e-06
Iter: 411 loss: 1.39018709e-06
Iter: 412 loss: 1.39128019e-06
Iter: 413 loss: 1.39017493e-06
Iter: 414 loss: 1.39011138e-06
Iter: 415 loss: 1.39010717e-06
Iter: 416 loss: 1.39007579e-06
Iter: 417 loss: 1.38993494e-06
Iter: 418 loss: 1.39000451e-06
Iter: 419 loss: 1.3898532e-06
Iter: 420 loss: 1.38972e-06
Iter: 421 loss: 1.39006806e-06
Iter: 422 loss: 1.38966607e-06
Iter: 423 loss: 1.38951191e-06
Iter: 424 loss: 1.3905368e-06
Iter: 425 loss: 1.38949258e-06
Iter: 426 loss: 1.38938617e-06
Iter: 427 loss: 1.38929113e-06
Iter: 428 loss: 1.38925395e-06
Iter: 429 loss: 1.38912469e-06
Iter: 430 loss: 1.38951964e-06
Iter: 431 loss: 1.38905921e-06
Iter: 432 loss: 1.38898963e-06
Iter: 433 loss: 1.38897667e-06
Iter: 434 loss: 1.38891096e-06
Iter: 435 loss: 1.38889573e-06
Iter: 436 loss: 1.38883297e-06
Iter: 437 loss: 1.38874543e-06
Iter: 438 loss: 1.38932705e-06
Iter: 439 loss: 1.38872963e-06
Iter: 440 loss: 1.38866051e-06
Iter: 441 loss: 1.38855876e-06
Iter: 442 loss: 1.38852306e-06
Iter: 443 loss: 1.3884079e-06
Iter: 444 loss: 1.38966618e-06
Iter: 445 loss: 1.38840426e-06
Iter: 446 loss: 1.38829887e-06
Iter: 447 loss: 1.38845394e-06
Iter: 448 loss: 1.38820474e-06
Iter: 449 loss: 1.38809105e-06
Iter: 450 loss: 1.38830092e-06
Iter: 451 loss: 1.38805444e-06
Iter: 452 loss: 1.38790506e-06
Iter: 453 loss: 1.38810321e-06
Iter: 454 loss: 1.38784526e-06
Iter: 455 loss: 1.38772486e-06
Iter: 456 loss: 1.38949827e-06
Iter: 457 loss: 1.38773385e-06
Iter: 458 loss: 1.3876745e-06
Iter: 459 loss: 1.38759071e-06
Iter: 460 loss: 1.38757537e-06
Iter: 461 loss: 1.38746464e-06
Iter: 462 loss: 1.38761743e-06
Iter: 463 loss: 1.38743167e-06
Iter: 464 loss: 1.38731025e-06
Iter: 465 loss: 1.38845587e-06
Iter: 466 loss: 1.38730229e-06
Iter: 467 loss: 1.38721884e-06
Iter: 468 loss: 1.38730968e-06
Iter: 469 loss: 1.38713312e-06
Iter: 470 loss: 1.38702512e-06
Iter: 471 loss: 1.38731548e-06
Iter: 472 loss: 1.38699522e-06
Iter: 473 loss: 1.38680343e-06
Iter: 474 loss: 1.38684049e-06
Iter: 475 loss: 1.3866852e-06
Iter: 476 loss: 1.38651649e-06
Iter: 477 loss: 1.38745008e-06
Iter: 478 loss: 1.38648215e-06
Iter: 479 loss: 1.38633027e-06
Iter: 480 loss: 1.38687597e-06
Iter: 481 loss: 1.38627456e-06
Iter: 482 loss: 1.38613711e-06
Iter: 483 loss: 1.38640803e-06
Iter: 484 loss: 1.38608755e-06
Iter: 485 loss: 1.3859642e-06
Iter: 486 loss: 1.38614678e-06
Iter: 487 loss: 1.38590417e-06
Iter: 488 loss: 1.38580322e-06
Iter: 489 loss: 1.38580435e-06
Iter: 490 loss: 1.38573569e-06
Iter: 491 loss: 1.38561199e-06
Iter: 492 loss: 1.38869029e-06
Iter: 493 loss: 1.38561541e-06
Iter: 494 loss: 1.38547648e-06
Iter: 495 loss: 1.38581163e-06
Iter: 496 loss: 1.38539212e-06
Iter: 497 loss: 1.38526127e-06
Iter: 498 loss: 1.3861295e-06
Iter: 499 loss: 1.38523387e-06
Iter: 500 loss: 1.38508403e-06
Iter: 501 loss: 1.38556129e-06
Iter: 502 loss: 1.38502241e-06
Iter: 503 loss: 1.38489304e-06
Iter: 504 loss: 1.38509392e-06
Iter: 505 loss: 1.38483915e-06
Iter: 506 loss: 1.38467169e-06
Iter: 507 loss: 1.38528435e-06
Iter: 508 loss: 1.38461792e-06
Iter: 509 loss: 1.38451924e-06
Iter: 510 loss: 1.38464043e-06
Iter: 511 loss: 1.38446876e-06
Iter: 512 loss: 1.38432051e-06
Iter: 513 loss: 1.38511291e-06
Iter: 514 loss: 1.38429618e-06
Iter: 515 loss: 1.38420796e-06
Iter: 516 loss: 1.38429641e-06
Iter: 517 loss: 1.38415635e-06
Iter: 518 loss: 1.38405437e-06
Iter: 519 loss: 1.38416885e-06
Iter: 520 loss: 1.38398923e-06
Iter: 521 loss: 1.38388009e-06
Iter: 522 loss: 1.3853172e-06
Iter: 523 loss: 1.38387395e-06
Iter: 524 loss: 1.38380904e-06
Iter: 525 loss: 1.38364067e-06
Iter: 526 loss: 1.38764244e-06
Iter: 527 loss: 1.38364112e-06
Iter: 528 loss: 1.38345763e-06
Iter: 529 loss: 1.38391647e-06
Iter: 530 loss: 1.38339647e-06
Iter: 531 loss: 1.38324822e-06
Iter: 532 loss: 1.3839433e-06
Iter: 533 loss: 1.3832049e-06
Iter: 534 loss: 1.38304495e-06
Iter: 535 loss: 1.38438315e-06
Iter: 536 loss: 1.38303903e-06
Iter: 537 loss: 1.38290704e-06
Iter: 538 loss: 1.38290216e-06
Iter: 539 loss: 1.38282712e-06
Iter: 540 loss: 1.38270741e-06
Iter: 541 loss: 1.38405221e-06
Iter: 542 loss: 1.38267774e-06
Iter: 543 loss: 1.38259441e-06
Iter: 544 loss: 1.38254336e-06
Iter: 545 loss: 1.38250209e-06
Iter: 546 loss: 1.38237215e-06
Iter: 547 loss: 1.38369228e-06
Iter: 548 loss: 1.38236078e-06
Iter: 549 loss: 1.38226665e-06
Iter: 550 loss: 1.38228029e-06
Iter: 551 loss: 1.38217911e-06
Iter: 552 loss: 1.38206246e-06
Iter: 553 loss: 1.38228688e-06
Iter: 554 loss: 1.38200107e-06
Iter: 555 loss: 1.38188602e-06
Iter: 556 loss: 1.38311077e-06
Iter: 557 loss: 1.38190921e-06
Iter: 558 loss: 1.38178677e-06
Iter: 559 loss: 1.38169685e-06
Iter: 560 loss: 1.38167741e-06
Iter: 561 loss: 1.38153473e-06
Iter: 562 loss: 1.38166479e-06
Iter: 563 loss: 1.38144878e-06
Iter: 564 loss: 1.38127712e-06
Iter: 565 loss: 1.38179939e-06
Iter: 566 loss: 1.3812346e-06
Iter: 567 loss: 1.38110295e-06
Iter: 568 loss: 1.38110192e-06
Iter: 569 loss: 1.3809962e-06
Iter: 570 loss: 1.38084374e-06
Iter: 571 loss: 1.3808467e-06
Iter: 572 loss: 1.38071312e-06
Iter: 573 loss: 1.38071312e-06
Iter: 574 loss: 1.38061887e-06
Iter: 575 loss: 1.38049177e-06
Iter: 576 loss: 1.3804879e-06
Iter: 577 loss: 1.38034886e-06
Iter: 578 loss: 1.38034841e-06
Iter: 579 loss: 1.38027008e-06
Iter: 580 loss: 1.38022108e-06
Iter: 581 loss: 1.38018117e-06
Iter: 582 loss: 1.38003293e-06
Iter: 583 loss: 1.38043174e-06
Iter: 584 loss: 1.37999132e-06
Iter: 585 loss: 1.37987331e-06
Iter: 586 loss: 1.38076257e-06
Iter: 587 loss: 1.37988013e-06
Iter: 588 loss: 1.37976519e-06
Iter: 589 loss: 1.37981078e-06
Iter: 590 loss: 1.37968618e-06
Iter: 591 loss: 1.37957386e-06
Iter: 592 loss: 1.37944835e-06
Iter: 593 loss: 1.37941856e-06
Iter: 594 loss: 1.37920244e-06
Iter: 595 loss: 1.37995085e-06
Iter: 596 loss: 1.37914276e-06
Iter: 597 loss: 1.37900474e-06
Iter: 598 loss: 1.37900338e-06
Iter: 599 loss: 1.37888981e-06
Iter: 600 loss: 1.37874224e-06
Iter: 601 loss: 1.3787253e-06
Iter: 602 loss: 1.37858683e-06
Iter: 603 loss: 1.37859297e-06
Iter: 604 loss: 1.37849747e-06
Iter: 605 loss: 1.37840379e-06
Iter: 606 loss: 1.37837276e-06
Iter: 607 loss: 1.37828283e-06
Iter: 608 loss: 1.37829124e-06
Iter: 609 loss: 1.37822e-06
Iter: 610 loss: 1.37816687e-06
Iter: 611 loss: 1.37812867e-06
Iter: 612 loss: 1.3780209e-06
Iter: 613 loss: 1.37822553e-06
Iter: 614 loss: 1.37797167e-06
Iter: 615 loss: 1.3778473e-06
Iter: 616 loss: 1.37852317e-06
Iter: 617 loss: 1.37783502e-06
Iter: 618 loss: 1.37768984e-06
Iter: 619 loss: 1.37798338e-06
Iter: 620 loss: 1.37766278e-06
Iter: 621 loss: 1.37751249e-06
Iter: 622 loss: 1.37736947e-06
Iter: 623 loss: 1.37736913e-06
Iter: 624 loss: 1.37714324e-06
Iter: 625 loss: 1.37794973e-06
Iter: 626 loss: 1.37709708e-06
Iter: 627 loss: 1.37697384e-06
Iter: 628 loss: 1.37696065e-06
Iter: 629 loss: 1.37683435e-06
Iter: 630 loss: 1.37685e-06
Iter: 631 loss: 1.37675329e-06
Iter: 632 loss: 1.37664006e-06
Iter: 633 loss: 1.37757183e-06
Iter: 634 loss: 1.37664165e-06
Iter: 635 loss: 1.37656048e-06
Iter: 636 loss: 1.37649738e-06
Iter: 637 loss: 1.37646202e-06
Iter: 638 loss: 1.37637778e-06
Iter: 639 loss: 1.37752454e-06
Iter: 640 loss: 1.37637289e-06
Iter: 641 loss: 1.37627239e-06
Iter: 642 loss: 1.37628717e-06
Iter: 643 loss: 1.37620009e-06
Iter: 644 loss: 1.3760739e-06
Iter: 645 loss: 1.37605718e-06
Iter: 646 loss: 1.37596976e-06
Iter: 647 loss: 1.37579207e-06
Iter: 648 loss: 1.37638494e-06
Iter: 649 loss: 1.37573181e-06
Iter: 650 loss: 1.37550342e-06
Iter: 651 loss: 1.37674238e-06
Iter: 652 loss: 1.37549148e-06
Iter: 653 loss: 1.37533834e-06
Iter: 654 loss: 1.3752242e-06
Iter: 655 loss: 1.37518282e-06
Iter: 656 loss: 1.37497318e-06
Iter: 657 loss: 1.37557447e-06
Iter: 658 loss: 1.37491577e-06
Iter: 659 loss: 1.37478037e-06
Iter: 660 loss: 1.37478128e-06
Iter: 661 loss: 1.37465452e-06
Iter: 662 loss: 1.37486245e-06
Iter: 663 loss: 1.3746145e-06
Iter: 664 loss: 1.37453094e-06
Iter: 665 loss: 1.37477787e-06
Iter: 666 loss: 1.37450013e-06
Iter: 667 loss: 1.37438883e-06
Iter: 668 loss: 1.37444931e-06
Iter: 669 loss: 1.37431152e-06
Iter: 670 loss: 1.37418351e-06
Iter: 671 loss: 1.37458483e-06
Iter: 672 loss: 1.37415486e-06
Iter: 673 loss: 1.37401753e-06
Iter: 674 loss: 1.37434029e-06
Iter: 675 loss: 1.37395023e-06
Iter: 676 loss: 1.37383313e-06
Iter: 677 loss: 1.37384427e-06
Iter: 678 loss: 1.3737216e-06
Iter: 679 loss: 1.37359029e-06
Iter: 680 loss: 1.37426741e-06
Iter: 681 loss: 1.37356665e-06
Iter: 682 loss: 1.37341135e-06
Iter: 683 loss: 1.37466054e-06
Iter: 684 loss: 1.37342522e-06
Iter: 685 loss: 1.37333859e-06
Iter: 686 loss: 1.37325014e-06
Iter: 687 loss: 1.37322377e-06
Iter: 688 loss: 1.37309348e-06
Iter: 689 loss: 1.37320239e-06
Iter: 690 loss: 1.37302357e-06
Iter: 691 loss: 1.37288055e-06
Iter: 692 loss: 1.3744675e-06
Iter: 693 loss: 1.37286634e-06
Iter: 694 loss: 1.37272161e-06
Iter: 695 loss: 1.37309462e-06
Iter: 696 loss: 1.37266647e-06
Iter: 697 loss: 1.37256734e-06
Iter: 698 loss: 1.37257484e-06
Iter: 699 loss: 1.37248423e-06
Iter: 700 loss: 1.37228062e-06
Iter: 701 loss: 1.37312418e-06
Iter: 702 loss: 1.37226129e-06
Iter: 703 loss: 1.37212612e-06
Iter: 704 loss: 1.37223049e-06
Iter: 705 loss: 1.37206325e-06
Iter: 706 loss: 1.37190568e-06
Iter: 707 loss: 1.3731044e-06
Iter: 708 loss: 1.37188567e-06
Iter: 709 loss: 1.37178063e-06
Iter: 710 loss: 1.371689e-06
Iter: 711 loss: 1.37165989e-06
Iter: 712 loss: 1.37151255e-06
Iter: 713 loss: 1.37241955e-06
Iter: 714 loss: 1.37149266e-06
Iter: 715 loss: 1.37136954e-06
Iter: 716 loss: 1.37240818e-06
Iter: 717 loss: 1.37136237e-06
Iter: 718 loss: 1.37123379e-06
Iter: 719 loss: 1.37109305e-06
Iter: 720 loss: 1.37108589e-06
Iter: 721 loss: 1.37092707e-06
Iter: 722 loss: 1.37119832e-06
Iter: 723 loss: 1.3708493e-06
Iter: 724 loss: 1.37069833e-06
Iter: 725 loss: 1.37199083e-06
Iter: 726 loss: 1.37068218e-06
Iter: 727 loss: 1.37054849e-06
Iter: 728 loss: 1.37126221e-06
Iter: 729 loss: 1.37051336e-06
Iter: 730 loss: 1.37040524e-06
Iter: 731 loss: 1.37036125e-06
Iter: 732 loss: 1.37031e-06
Iter: 733 loss: 1.37016059e-06
Iter: 734 loss: 1.37196309e-06
Iter: 735 loss: 1.37016877e-06
Iter: 736 loss: 1.37010204e-06
Iter: 737 loss: 1.37001837e-06
Iter: 738 loss: 1.36998847e-06
Iter: 739 loss: 1.36986057e-06
Iter: 740 loss: 1.36987057e-06
Iter: 741 loss: 1.36977769e-06
Iter: 742 loss: 1.3695942e-06
Iter: 743 loss: 1.37302027e-06
Iter: 744 loss: 1.36957988e-06
Iter: 745 loss: 1.36939207e-06
Iter: 746 loss: 1.37078598e-06
Iter: 747 loss: 1.36937e-06
Iter: 748 loss: 1.36925337e-06
Iter: 749 loss: 1.37057566e-06
Iter: 750 loss: 1.36924587e-06
Iter: 751 loss: 1.36911956e-06
Iter: 752 loss: 1.36910819e-06
Iter: 753 loss: 1.36900371e-06
Iter: 754 loss: 1.36887695e-06
Iter: 755 loss: 1.36901417e-06
Iter: 756 loss: 1.36881147e-06
Iter: 757 loss: 1.3687e-06
Iter: 758 loss: 1.36939025e-06
Iter: 759 loss: 1.36866333e-06
Iter: 760 loss: 1.36854555e-06
Iter: 761 loss: 1.36950155e-06
Iter: 762 loss: 1.36854294e-06
Iter: 763 loss: 1.36846745e-06
Iter: 764 loss: 1.36836059e-06
Iter: 765 loss: 1.36834524e-06
Iter: 766 loss: 1.36824383e-06
Iter: 767 loss: 1.36823394e-06
Iter: 768 loss: 1.36815629e-06
Iter: 769 loss: 1.36799213e-06
Iter: 770 loss: 1.3713917e-06
Iter: 771 loss: 1.36799781e-06
Iter: 772 loss: 1.36786389e-06
Iter: 773 loss: 1.36787162e-06
Iter: 774 loss: 1.36775679e-06
Iter: 775 loss: 1.36753943e-06
Iter: 776 loss: 1.36754329e-06
Iter: 777 loss: 1.36731853e-06
Iter: 778 loss: 1.36836604e-06
Iter: 779 loss: 1.36730773e-06
Iter: 780 loss: 1.36716653e-06
Iter: 781 loss: 1.36900485e-06
Iter: 782 loss: 1.36716335e-06
Iter: 783 loss: 1.3670558e-06
Iter: 784 loss: 1.3672261e-06
Iter: 785 loss: 1.36701124e-06
Iter: 786 loss: 1.36690824e-06
Iter: 787 loss: 1.36688959e-06
Iter: 788 loss: 1.36680546e-06
Iter: 789 loss: 1.36669269e-06
Iter: 790 loss: 1.3671588e-06
Iter: 791 loss: 1.36665426e-06
Iter: 792 loss: 1.36656945e-06
Iter: 793 loss: 1.36774383e-06
Iter: 794 loss: 1.36656377e-06
Iter: 795 loss: 1.36647895e-06
Iter: 796 loss: 1.36633821e-06
Iter: 797 loss: 1.36634117e-06
Iter: 798 loss: 1.36620145e-06
Iter: 799 loss: 1.3680193e-06
Iter: 800 loss: 1.36618723e-06
Iter: 801 loss: 1.36609128e-06
Iter: 802 loss: 1.36597544e-06
Iter: 803 loss: 1.36595645e-06
Iter: 804 loss: 1.36583139e-06
Iter: 805 loss: 1.36768176e-06
Iter: 806 loss: 1.36583435e-06
Iter: 807 loss: 1.36570156e-06
Iter: 808 loss: 1.36566359e-06
Iter: 809 loss: 1.36560732e-06
Iter: 810 loss: 1.3654543e-06
Iter: 811 loss: 1.36551557e-06
Iter: 812 loss: 1.36536914e-06
Iter: 813 loss: 1.36524488e-06
Iter: 814 loss: 1.36686958e-06
Iter: 815 loss: 1.36524045e-06
Iter: 816 loss: 1.36513268e-06
Iter: 817 loss: 1.36534481e-06
Iter: 818 loss: 1.36508015e-06
Iter: 819 loss: 1.36497874e-06
Iter: 820 loss: 1.36493395e-06
Iter: 821 loss: 1.3648712e-06
Iter: 822 loss: 1.36473784e-06
Iter: 823 loss: 1.36514791e-06
Iter: 824 loss: 1.36468861e-06
Iter: 825 loss: 1.36457732e-06
Iter: 826 loss: 1.3663896e-06
Iter: 827 loss: 1.36457334e-06
Iter: 828 loss: 1.36446431e-06
Iter: 829 loss: 1.36437234e-06
Iter: 830 loss: 1.36434653e-06
Iter: 831 loss: 1.36420499e-06
Iter: 832 loss: 1.36521021e-06
Iter: 833 loss: 1.3641926e-06
Iter: 834 loss: 1.36401638e-06
Iter: 835 loss: 1.36400638e-06
Iter: 836 loss: 1.36387939e-06
Iter: 837 loss: 1.36372296e-06
Iter: 838 loss: 1.36458323e-06
Iter: 839 loss: 1.36371466e-06
Iter: 840 loss: 1.36354026e-06
Iter: 841 loss: 1.3640813e-06
Iter: 842 loss: 1.36348024e-06
Iter: 843 loss: 1.36339008e-06
Iter: 844 loss: 1.36325366e-06
Iter: 845 loss: 1.36324149e-06
Iter: 846 loss: 1.36310041e-06
Iter: 847 loss: 1.36537687e-06
Iter: 848 loss: 1.36309006e-06
Iter: 849 loss: 1.36298036e-06
Iter: 850 loss: 1.36324945e-06
Iter: 851 loss: 1.36292579e-06
Iter: 852 loss: 1.36281869e-06
Iter: 853 loss: 1.36281665e-06
Iter: 854 loss: 1.36270921e-06
Iter: 855 loss: 1.36255176e-06
Iter: 856 loss: 1.36268841e-06
Iter: 857 loss: 1.36247206e-06
Iter: 858 loss: 1.36230665e-06
Iter: 859 loss: 1.36483357e-06
Iter: 860 loss: 1.36229869e-06
Iter: 861 loss: 1.36213748e-06
Iter: 862 loss: 1.36206927e-06
Iter: 863 loss: 1.36201288e-06
Iter: 864 loss: 1.36182746e-06
Iter: 865 loss: 1.36259541e-06
Iter: 866 loss: 1.36178551e-06
Iter: 867 loss: 1.36155859e-06
Iter: 868 loss: 1.36195933e-06
Iter: 869 loss: 1.36146411e-06
Iter: 870 loss: 1.36129336e-06
Iter: 871 loss: 1.36157109e-06
Iter: 872 loss: 1.36122264e-06
Iter: 873 loss: 1.36103358e-06
Iter: 874 loss: 1.36292374e-06
Iter: 875 loss: 1.36104188e-06
Iter: 876 loss: 1.36095105e-06
Iter: 877 loss: 1.36075903e-06
Iter: 878 loss: 1.36456993e-06
Iter: 879 loss: 1.36076164e-06
Iter: 880 loss: 1.36064148e-06
Iter: 881 loss: 1.36269239e-06
Iter: 882 loss: 1.36064443e-06
Iter: 883 loss: 1.36050949e-06
Iter: 884 loss: 1.36080212e-06
Iter: 885 loss: 1.36047174e-06
Iter: 886 loss: 1.36032838e-06
Iter: 887 loss: 1.36042593e-06
Iter: 888 loss: 1.3602662e-06
Iter: 889 loss: 1.36012295e-06
Iter: 890 loss: 1.36018502e-06
Iter: 891 loss: 1.36002598e-06
Iter: 892 loss: 1.35984692e-06
Iter: 893 loss: 1.36183826e-06
Iter: 894 loss: 1.35985965e-06
Iter: 895 loss: 1.35970959e-06
Iter: 896 loss: 1.35977882e-06
Iter: 897 loss: 1.35959499e-06
Iter: 898 loss: 1.3594431e-06
Iter: 899 loss: 1.35994355e-06
Iter: 900 loss: 1.35940775e-06
Iter: 901 loss: 1.35922755e-06
Iter: 902 loss: 1.35986306e-06
Iter: 903 loss: 1.3592105e-06
Iter: 904 loss: 1.35909238e-06
Iter: 905 loss: 1.35906964e-06
Iter: 906 loss: 1.35898961e-06
Iter: 907 loss: 1.35885944e-06
Iter: 908 loss: 1.35886012e-06
Iter: 909 loss: 1.35879304e-06
Iter: 910 loss: 1.35862774e-06
Iter: 911 loss: 1.36072879e-06
Iter: 912 loss: 1.35860728e-06
Iter: 913 loss: 1.35846199e-06
Iter: 914 loss: 1.35998039e-06
Iter: 915 loss: 1.35846972e-06
Iter: 916 loss: 1.35831738e-06
Iter: 917 loss: 1.35889434e-06
Iter: 918 loss: 1.35829282e-06
Iter: 919 loss: 1.35815469e-06
Iter: 920 loss: 1.3581639e-06
Iter: 921 loss: 1.35806567e-06
Iter: 922 loss: 1.35785717e-06
Iter: 923 loss: 1.35804248e-06
Iter: 924 loss: 1.35776077e-06
Iter: 925 loss: 1.35757523e-06
Iter: 926 loss: 1.35923597e-06
Iter: 927 loss: 1.35757523e-06
Iter: 928 loss: 1.35740891e-06
Iter: 929 loss: 1.3577702e-06
Iter: 930 loss: 1.35733205e-06
Iter: 931 loss: 1.35720666e-06
Iter: 932 loss: 1.35736775e-06
Iter: 933 loss: 1.35713219e-06
Iter: 934 loss: 1.35698247e-06
Iter: 935 loss: 1.35815208e-06
Iter: 936 loss: 1.35698019e-06
Iter: 937 loss: 1.35686992e-06
Iter: 938 loss: 1.35677078e-06
Iter: 939 loss: 1.35673758e-06
Iter: 940 loss: 1.35661776e-06
Iter: 941 loss: 1.35660935e-06
Iter: 942 loss: 1.35652965e-06
Iter: 943 loss: 1.35630489e-06
Iter: 944 loss: 1.35908965e-06
Iter: 945 loss: 1.35630034e-06
Iter: 946 loss: 1.35610958e-06
Iter: 947 loss: 1.35702612e-06
Iter: 948 loss: 1.35607593e-06
Iter: 949 loss: 1.35585822e-06
Iter: 950 loss: 1.35766254e-06
Iter: 951 loss: 1.35584605e-06
Iter: 952 loss: 1.35569428e-06
Iter: 953 loss: 1.3556745e-06
Iter: 954 loss: 1.35557138e-06
Iter: 955 loss: 1.35538176e-06
Iter: 956 loss: 1.35584753e-06
Iter: 957 loss: 1.35531059e-06
Iter: 958 loss: 1.35514983e-06
Iter: 959 loss: 1.35570167e-06
Iter: 960 loss: 1.35510709e-06
Iter: 961 loss: 1.35492041e-06
Iter: 962 loss: 1.35611617e-06
Iter: 963 loss: 1.35488108e-06
Iter: 964 loss: 1.35477512e-06
Iter: 965 loss: 1.35470123e-06
Iter: 966 loss: 1.35464734e-06
Iter: 967 loss: 1.35448386e-06
Iter: 968 loss: 1.35663163e-06
Iter: 969 loss: 1.35448727e-06
Iter: 970 loss: 1.35437847e-06
Iter: 971 loss: 1.35423534e-06
Iter: 972 loss: 1.35420646e-06
Iter: 973 loss: 1.35408948e-06
Iter: 974 loss: 1.35407095e-06
Iter: 975 loss: 1.35397045e-06
Iter: 976 loss: 1.35379537e-06
Iter: 977 loss: 1.35378514e-06
Iter: 978 loss: 1.35364883e-06
Iter: 979 loss: 1.35401137e-06
Iter: 980 loss: 1.35357107e-06
Iter: 981 loss: 1.35341293e-06
Iter: 982 loss: 1.35566745e-06
Iter: 983 loss: 1.35340906e-06
Iter: 984 loss: 1.35329788e-06
Iter: 985 loss: 1.35322875e-06
Iter: 986 loss: 1.35318032e-06
Iter: 987 loss: 1.35302048e-06
Iter: 988 loss: 1.35376945e-06
Iter: 989 loss: 1.35299433e-06
Iter: 990 loss: 1.35282448e-06
Iter: 991 loss: 1.3530622e-06
Iter: 992 loss: 1.35274763e-06
Iter: 993 loss: 1.35258938e-06
Iter: 994 loss: 1.35454252e-06
Iter: 995 loss: 1.35259654e-06
Iter: 996 loss: 1.35249479e-06
Iter: 997 loss: 1.35237644e-06
Iter: 998 loss: 1.35235825e-06
Iter: 999 loss: 1.35223183e-06
Iter: 1000 loss: 1.35411904e-06
Iter: 1001 loss: 1.35222626e-06
Iter: 1002 loss: 1.35213202e-06
Iter: 1003 loss: 1.35200912e-06
Iter: 1004 loss: 1.35202424e-06
Iter: 1005 loss: 1.35192431e-06
Iter: 1006 loss: 1.3519192e-06
Iter: 1007 loss: 1.35184371e-06
Iter: 1008 loss: 1.35169216e-06
Iter: 1009 loss: 1.35169807e-06
Iter: 1010 loss: 1.35153937e-06
Iter: 1011 loss: 1.35152959e-06
Iter: 1012 loss: 1.35140726e-06
Iter: 1013 loss: 1.35127289e-06
Iter: 1014 loss: 1.3512672e-06
Iter: 1015 loss: 1.35110577e-06
Iter: 1016 loss: 1.35097719e-06
Iter: 1017 loss: 1.35094274e-06
Iter: 1018 loss: 1.3507522e-06
Iter: 1019 loss: 1.35143591e-06
Iter: 1020 loss: 1.35069763e-06
Iter: 1021 loss: 1.35052505e-06
Iter: 1022 loss: 1.35075629e-06
Iter: 1023 loss: 1.35042797e-06
Iter: 1024 loss: 1.35031735e-06
Iter: 1025 loss: 1.35031564e-06
Iter: 1026 loss: 1.35022754e-06
Iter: 1027 loss: 1.3500993e-06
Iter: 1028 loss: 1.35010214e-06
Iter: 1029 loss: 1.34995094e-06
Iter: 1030 loss: 1.35167079e-06
Iter: 1031 loss: 1.3499598e-06
Iter: 1032 loss: 1.34985339e-06
Iter: 1033 loss: 1.34966524e-06
Iter: 1034 loss: 1.3496641e-06
Iter: 1035 loss: 1.34947459e-06
Iter: 1036 loss: 1.35214941e-06
Iter: 1037 loss: 1.34948618e-06
Iter: 1038 loss: 1.34929633e-06
Iter: 1039 loss: 1.34917411e-06
Iter: 1040 loss: 1.34912398e-06
Iter: 1041 loss: 1.34887455e-06
Iter: 1042 loss: 1.34886261e-06
Iter: 1043 loss: 1.34866036e-06
Iter: 1044 loss: 1.34850336e-06
Iter: 1045 loss: 1.34851541e-06
Iter: 1046 loss: 1.34837012e-06
Iter: 1047 loss: 1.34848733e-06
Iter: 1048 loss: 1.34829e-06
Iter: 1049 loss: 1.34818094e-06
Iter: 1050 loss: 1.34832567e-06
Iter: 1051 loss: 1.34813808e-06
Iter: 1052 loss: 1.34798734e-06
Iter: 1053 loss: 1.34815423e-06
Iter: 1054 loss: 1.34789946e-06
Iter: 1055 loss: 1.34776008e-06
Iter: 1056 loss: 1.34923744e-06
Iter: 1057 loss: 1.34777758e-06
Iter: 1058 loss: 1.34764332e-06
Iter: 1059 loss: 1.34753191e-06
Iter: 1060 loss: 1.34749507e-06
Iter: 1061 loss: 1.34730658e-06
Iter: 1062 loss: 1.34873744e-06
Iter: 1063 loss: 1.34730055e-06
Iter: 1064 loss: 1.34715344e-06
Iter: 1065 loss: 1.34702827e-06
Iter: 1066 loss: 1.34697916e-06
Iter: 1067 loss: 1.34679431e-06
Iter: 1068 loss: 1.34833374e-06
Iter: 1069 loss: 1.3467934e-06
Iter: 1070 loss: 1.34662355e-06
Iter: 1071 loss: 1.34700053e-06
Iter: 1072 loss: 1.34656239e-06
Iter: 1073 loss: 1.34646496e-06
Iter: 1074 loss: 1.34640925e-06
Iter: 1075 loss: 1.34635297e-06
Iter: 1076 loss: 1.34621541e-06
Iter: 1077 loss: 1.34761945e-06
Iter: 1078 loss: 1.34621803e-06
Iter: 1079 loss: 1.34610639e-06
Iter: 1080 loss: 1.34632273e-06
Iter: 1081 loss: 1.34606103e-06
Iter: 1082 loss: 1.34596178e-06
Iter: 1083 loss: 1.34593552e-06
Iter: 1084 loss: 1.34586412e-06
Iter: 1085 loss: 1.34569007e-06
Iter: 1086 loss: 1.34601771e-06
Iter: 1087 loss: 1.34562686e-06
Iter: 1088 loss: 1.34547827e-06
Iter: 1089 loss: 1.34654147e-06
Iter: 1090 loss: 1.34545587e-06
Iter: 1091 loss: 1.34527579e-06
Iter: 1092 loss: 1.34560196e-06
Iter: 1093 loss: 1.34520599e-06
Iter: 1094 loss: 1.34509469e-06
Iter: 1095 loss: 1.34559343e-06
Iter: 1096 loss: 1.34507218e-06
Iter: 1097 loss: 1.34492916e-06
Iter: 1098 loss: 1.34504216e-06
Iter: 1099 loss: 1.34485617e-06
Iter: 1100 loss: 1.34472396e-06
Iter: 1101 loss: 1.34497839e-06
Iter: 1102 loss: 1.34469519e-06
Iter: 1103 loss: 1.34453921e-06
Iter: 1104 loss: 1.34543041e-06
Iter: 1105 loss: 1.34451875e-06
Iter: 1106 loss: 1.34443439e-06
Iter: 1107 loss: 1.34430081e-06
Iter: 1108 loss: 1.34783568e-06
Iter: 1109 loss: 1.34428933e-06
Iter: 1110 loss: 1.34410493e-06
Iter: 1111 loss: 1.34584457e-06
Iter: 1112 loss: 1.34411175e-06
Iter: 1113 loss: 1.34396009e-06
Iter: 1114 loss: 1.34449397e-06
Iter: 1115 loss: 1.34392542e-06
Iter: 1116 loss: 1.34379991e-06
Iter: 1117 loss: 1.34382321e-06
Iter: 1118 loss: 1.34367804e-06
Iter: 1119 loss: 1.34354605e-06
Iter: 1120 loss: 1.3442318e-06
Iter: 1121 loss: 1.34351535e-06
Iter: 1122 loss: 1.34336301e-06
Iter: 1123 loss: 1.34375114e-06
Iter: 1124 loss: 1.34333504e-06
Iter: 1125 loss: 1.34318009e-06
Iter: 1126 loss: 1.34391269e-06
Iter: 1127 loss: 1.34317406e-06
Iter: 1128 loss: 1.34305424e-06
Iter: 1129 loss: 1.34319896e-06
Iter: 1130 loss: 1.34301672e-06
Iter: 1131 loss: 1.34284107e-06
Iter: 1132 loss: 1.34311017e-06
Iter: 1133 loss: 1.34278162e-06
Iter: 1134 loss: 1.3426436e-06
Iter: 1135 loss: 1.34260029e-06
Iter: 1136 loss: 1.342529e-06
Iter: 1137 loss: 1.34232e-06
Iter: 1138 loss: 1.34501693e-06
Iter: 1139 loss: 1.34233028e-06
Iter: 1140 loss: 1.34220841e-06
Iter: 1141 loss: 1.34197217e-06
Iter: 1142 loss: 1.346001e-06
Iter: 1143 loss: 1.34197592e-06
Iter: 1144 loss: 1.34178572e-06
Iter: 1145 loss: 1.34438369e-06
Iter: 1146 loss: 1.34178822e-06
Iter: 1147 loss: 1.34162008e-06
Iter: 1148 loss: 1.34276945e-06
Iter: 1149 loss: 1.3416045e-06
Iter: 1150 loss: 1.34150366e-06
Iter: 1151 loss: 1.34141601e-06
Iter: 1152 loss: 1.34139304e-06
Iter: 1153 loss: 1.34122615e-06
Iter: 1154 loss: 1.34203947e-06
Iter: 1155 loss: 1.34117977e-06
Iter: 1156 loss: 1.34104812e-06
Iter: 1157 loss: 1.34123388e-06
Iter: 1158 loss: 1.3409641e-06
Iter: 1159 loss: 1.34079926e-06
Iter: 1160 loss: 1.34239065e-06
Iter: 1161 loss: 1.34077777e-06
Iter: 1162 loss: 1.34066363e-06
Iter: 1163 loss: 1.34071911e-06
Iter: 1164 loss: 1.34056086e-06
Iter: 1165 loss: 1.34041738e-06
Iter: 1166 loss: 1.34121501e-06
Iter: 1167 loss: 1.34037987e-06
Iter: 1168 loss: 1.34026084e-06
Iter: 1169 loss: 1.34022389e-06
Iter: 1170 loss: 1.34018205e-06
Iter: 1171 loss: 1.34004836e-06
Iter: 1172 loss: 1.34006655e-06
Iter: 1173 loss: 1.33999129e-06
Iter: 1174 loss: 1.33985213e-06
Iter: 1175 loss: 1.34193988e-06
Iter: 1176 loss: 1.339851e-06
Iter: 1177 loss: 1.33970116e-06
Iter: 1178 loss: 1.34043762e-06
Iter: 1179 loss: 1.3396849e-06
Iter: 1180 loss: 1.33954291e-06
Iter: 1181 loss: 1.34070069e-06
Iter: 1182 loss: 1.33953517e-06
Iter: 1183 loss: 1.33942126e-06
Iter: 1184 loss: 1.33927563e-06
Iter: 1185 loss: 1.3392663e-06
Iter: 1186 loss: 1.33907133e-06
Iter: 1187 loss: 1.34017102e-06
Iter: 1188 loss: 1.33902972e-06
Iter: 1189 loss: 1.33885396e-06
Iter: 1190 loss: 1.33908429e-06
Iter: 1191 loss: 1.33875471e-06
Iter: 1192 loss: 1.33861045e-06
Iter: 1193 loss: 1.33861727e-06
Iter: 1194 loss: 1.33849289e-06
Iter: 1195 loss: 1.33845879e-06
Iter: 1196 loss: 1.33840456e-06
Iter: 1197 loss: 1.3382521e-06
Iter: 1198 loss: 1.3394158e-06
Iter: 1199 loss: 1.33822641e-06
Iter: 1200 loss: 1.3381524e-06
Iter: 1201 loss: 1.33804872e-06
Iter: 1202 loss: 1.33803405e-06
Iter: 1203 loss: 1.33794265e-06
Iter: 1204 loss: 1.33794526e-06
Iter: 1205 loss: 1.33787103e-06
Iter: 1206 loss: 1.33768663e-06
Iter: 1207 loss: 1.34017773e-06
Iter: 1208 loss: 1.33766855e-06
Iter: 1209 loss: 1.33750609e-06
Iter: 1210 loss: 1.3379854e-06
Iter: 1211 loss: 1.33744118e-06
Iter: 1212 loss: 1.3372719e-06
Iter: 1213 loss: 1.33956314e-06
Iter: 1214 loss: 1.33727713e-06
Iter: 1215 loss: 1.33714184e-06
Iter: 1216 loss: 1.33700792e-06
Iter: 1217 loss: 1.33698609e-06
Iter: 1218 loss: 1.33679646e-06
Iter: 1219 loss: 1.33806589e-06
Iter: 1220 loss: 1.33679714e-06
Iter: 1221 loss: 1.33665048e-06
Iter: 1222 loss: 1.33706817e-06
Iter: 1223 loss: 1.33658637e-06
Iter: 1224 loss: 1.33648746e-06
Iter: 1225 loss: 1.33777394e-06
Iter: 1226 loss: 1.33647984e-06
Iter: 1227 loss: 1.33638412e-06
Iter: 1228 loss: 1.33629476e-06
Iter: 1229 loss: 1.33627759e-06
Iter: 1230 loss: 1.33613526e-06
Iter: 1231 loss: 1.33745402e-06
Iter: 1232 loss: 1.33612264e-06
Iter: 1233 loss: 1.3360127e-06
Iter: 1234 loss: 1.33580579e-06
Iter: 1235 loss: 1.3401974e-06
Iter: 1236 loss: 1.33579681e-06
Iter: 1237 loss: 1.33565186e-06
Iter: 1238 loss: 1.33563958e-06
Iter: 1239 loss: 1.33552862e-06
Iter: 1240 loss: 1.3353158e-06
Iter: 1241 loss: 1.34073969e-06
Iter: 1242 loss: 1.33531705e-06
Iter: 1243 loss: 1.3351e-06
Iter: 1244 loss: 1.33556694e-06
Iter: 1245 loss: 1.33504307e-06
Iter: 1246 loss: 1.33487231e-06
Iter: 1247 loss: 1.33485696e-06
Iter: 1248 loss: 1.33475896e-06
Iter: 1249 loss: 1.33464459e-06
Iter: 1250 loss: 1.33462754e-06
Iter: 1251 loss: 1.33445678e-06
Iter: 1252 loss: 1.33505114e-06
Iter: 1253 loss: 1.33441472e-06
Iter: 1254 loss: 1.33424226e-06
Iter: 1255 loss: 1.33551612e-06
Iter: 1256 loss: 1.33424101e-06
Iter: 1257 loss: 1.3340989e-06
Iter: 1258 loss: 1.33486674e-06
Iter: 1259 loss: 1.33408048e-06
Iter: 1260 loss: 1.33397498e-06
Iter: 1261 loss: 1.33394872e-06
Iter: 1262 loss: 1.33387198e-06
Iter: 1263 loss: 1.33373e-06
Iter: 1264 loss: 1.3352186e-06
Iter: 1265 loss: 1.33373089e-06
Iter: 1266 loss: 1.33362e-06
Iter: 1267 loss: 1.33342894e-06
Iter: 1268 loss: 1.33343292e-06
Iter: 1269 loss: 1.33334129e-06
Iter: 1270 loss: 1.33333492e-06
Iter: 1271 loss: 1.33324113e-06
Iter: 1272 loss: 1.33309561e-06
Iter: 1273 loss: 1.33309027e-06
Iter: 1274 loss: 1.33294725e-06
Iter: 1275 loss: 1.33323715e-06
Iter: 1276 loss: 1.3328812e-06
Iter: 1277 loss: 1.33277956e-06
Iter: 1278 loss: 1.33277297e-06
Iter: 1279 loss: 1.33268713e-06
Iter: 1280 loss: 1.332534e-06
Iter: 1281 loss: 1.33604567e-06
Iter: 1282 loss: 1.33252888e-06
Iter: 1283 loss: 1.33234016e-06
Iter: 1284 loss: 1.33263677e-06
Iter: 1285 loss: 1.33226763e-06
Iter: 1286 loss: 1.33209869e-06
Iter: 1287 loss: 1.33445917e-06
Iter: 1288 loss: 1.33209176e-06
Iter: 1289 loss: 1.33196124e-06
Iter: 1290 loss: 1.33245771e-06
Iter: 1291 loss: 1.33194885e-06
Iter: 1292 loss: 1.33182141e-06
Iter: 1293 loss: 1.33193919e-06
Iter: 1294 loss: 1.3317366e-06
Iter: 1295 loss: 1.33163871e-06
Iter: 1296 loss: 1.33257197e-06
Iter: 1297 loss: 1.33162519e-06
Iter: 1298 loss: 1.33152184e-06
Iter: 1299 loss: 1.3313828e-06
Iter: 1300 loss: 1.33138144e-06
Iter: 1301 loss: 1.33128265e-06
Iter: 1302 loss: 1.33127708e-06
Iter: 1303 loss: 1.33117749e-06
Iter: 1304 loss: 1.33100866e-06
Iter: 1305 loss: 1.33522849e-06
Iter: 1306 loss: 1.33100048e-06
Iter: 1307 loss: 1.33079811e-06
Iter: 1308 loss: 1.33077674e-06
Iter: 1309 loss: 1.33065964e-06
Iter: 1310 loss: 1.33052686e-06
Iter: 1311 loss: 1.33047706e-06
Iter: 1312 loss: 1.33037008e-06
Iter: 1313 loss: 1.33022559e-06
Iter: 1314 loss: 1.33020353e-06
Iter: 1315 loss: 1.33003755e-06
Iter: 1316 loss: 1.3302224e-06
Iter: 1317 loss: 1.32995183e-06
Iter: 1318 loss: 1.32984019e-06
Iter: 1319 loss: 1.32984349e-06
Iter: 1320 loss: 1.32971911e-06
Iter: 1321 loss: 1.33008052e-06
Iter: 1322 loss: 1.32970251e-06
Iter: 1323 loss: 1.32960758e-06
Iter: 1324 loss: 1.32970956e-06
Iter: 1325 loss: 1.32955461e-06
Iter: 1326 loss: 1.32945479e-06
Iter: 1327 loss: 1.32992079e-06
Iter: 1328 loss: 1.32943171e-06
Iter: 1329 loss: 1.32932109e-06
Iter: 1330 loss: 1.32920059e-06
Iter: 1331 loss: 1.32917546e-06
Iter: 1332 loss: 1.32903665e-06
Iter: 1333 loss: 1.3307731e-06
Iter: 1334 loss: 1.32902949e-06
Iter: 1335 loss: 1.32888772e-06
Iter: 1336 loss: 1.32879813e-06
Iter: 1337 loss: 1.32873515e-06
Iter: 1338 loss: 1.32856781e-06
Iter: 1339 loss: 1.32852551e-06
Iter: 1340 loss: 1.32840364e-06
Iter: 1341 loss: 1.32831406e-06
Iter: 1342 loss: 1.32828234e-06
Iter: 1343 loss: 1.32816626e-06
Iter: 1344 loss: 1.32817013e-06
Iter: 1345 loss: 1.32807713e-06
Iter: 1346 loss: 1.32792024e-06
Iter: 1347 loss: 1.32780428e-06
Iter: 1348 loss: 1.32777495e-06
Iter: 1349 loss: 1.32757032e-06
Iter: 1350 loss: 1.32934883e-06
Iter: 1351 loss: 1.32756008e-06
Iter: 1352 loss: 1.32735261e-06
Iter: 1353 loss: 1.32827074e-06
Iter: 1354 loss: 1.32734101e-06
Iter: 1355 loss: 1.3271557e-06
Iter: 1356 loss: 1.3275851e-06
Iter: 1357 loss: 1.32709636e-06
Iter: 1358 loss: 1.32696209e-06
Iter: 1359 loss: 1.32739774e-06
Iter: 1360 loss: 1.32690855e-06
Iter: 1361 loss: 1.32673495e-06
Iter: 1362 loss: 1.32692185e-06
Iter: 1363 loss: 1.32662171e-06
Iter: 1364 loss: 1.32652985e-06
Iter: 1365 loss: 1.32711216e-06
Iter: 1366 loss: 1.32651155e-06
Iter: 1367 loss: 1.32637592e-06
Iter: 1368 loss: 1.32675984e-06
Iter: 1369 loss: 1.32634591e-06
Iter: 1370 loss: 1.32626838e-06
Iter: 1371 loss: 1.32611399e-06
Iter: 1372 loss: 1.32910839e-06
Iter: 1373 loss: 1.32611376e-06
Iter: 1374 loss: 1.32593425e-06
Iter: 1375 loss: 1.32803029e-06
Iter: 1376 loss: 1.32593618e-06
Iter: 1377 loss: 1.32576611e-06
Iter: 1378 loss: 1.32591333e-06
Iter: 1379 loss: 1.32564992e-06
Iter: 1380 loss: 1.32546984e-06
Iter: 1381 loss: 1.32524156e-06
Iter: 1382 loss: 1.32521473e-06
Iter: 1383 loss: 1.32495074e-06
Iter: 1384 loss: 1.32833475e-06
Iter: 1385 loss: 1.32492846e-06
Iter: 1386 loss: 1.32475122e-06
Iter: 1387 loss: 1.32616208e-06
Iter: 1388 loss: 1.32472633e-06
Iter: 1389 loss: 1.32454886e-06
Iter: 1390 loss: 1.32512548e-06
Iter: 1391 loss: 1.32452249e-06
Iter: 1392 loss: 1.32442131e-06
Iter: 1393 loss: 1.32462549e-06
Iter: 1394 loss: 1.32436617e-06
Iter: 1395 loss: 1.32423656e-06
Iter: 1396 loss: 1.32468222e-06
Iter: 1397 loss: 1.32420064e-06
Iter: 1398 loss: 1.3241098e-06
Iter: 1399 loss: 1.32408809e-06
Iter: 1400 loss: 1.32402693e-06
Iter: 1401 loss: 1.32386663e-06
Iter: 1402 loss: 1.32488037e-06
Iter: 1403 loss: 1.32384548e-06
Iter: 1404 loss: 1.32375465e-06
Iter: 1405 loss: 1.32353853e-06
Iter: 1406 loss: 1.32631124e-06
Iter: 1407 loss: 1.32354035e-06
Iter: 1408 loss: 1.32332843e-06
Iter: 1409 loss: 1.32589128e-06
Iter: 1410 loss: 1.32332275e-06
Iter: 1411 loss: 1.32315245e-06
Iter: 1412 loss: 1.32418336e-06
Iter: 1413 loss: 1.32311084e-06
Iter: 1414 loss: 1.32301295e-06
Iter: 1415 loss: 1.32288528e-06
Iter: 1416 loss: 1.32287403e-06
Iter: 1417 loss: 1.32275704e-06
Iter: 1418 loss: 1.32356786e-06
Iter: 1419 loss: 1.32273135e-06
Iter: 1420 loss: 1.32259379e-06
Iter: 1421 loss: 1.32332434e-06
Iter: 1422 loss: 1.32258901e-06
Iter: 1423 loss: 1.32246191e-06
Iter: 1424 loss: 1.32271884e-06
Iter: 1425 loss: 1.32243144e-06
Iter: 1426 loss: 1.3223023e-06
Iter: 1427 loss: 1.32232458e-06
Iter: 1428 loss: 1.32220703e-06
Iter: 1429 loss: 1.32201967e-06
Iter: 1430 loss: 1.32297043e-06
Iter: 1431 loss: 1.32198693e-06
Iter: 1432 loss: 1.32183095e-06
Iter: 1433 loss: 1.32163746e-06
Iter: 1434 loss: 1.32161813e-06
Iter: 1435 loss: 1.32143032e-06
Iter: 1436 loss: 1.32144157e-06
Iter: 1437 loss: 1.32130083e-06
Iter: 1438 loss: 1.32106322e-06
Iter: 1439 loss: 1.32466198e-06
Iter: 1440 loss: 1.32104117e-06
Iter: 1441 loss: 1.32082221e-06
Iter: 1442 loss: 1.32207128e-06
Iter: 1443 loss: 1.32080493e-06
Iter: 1444 loss: 1.32065929e-06
Iter: 1445 loss: 1.32066509e-06
Iter: 1446 loss: 1.32056834e-06
Iter: 1447 loss: 1.3203944e-06
Iter: 1448 loss: 1.32349703e-06
Iter: 1449 loss: 1.3204085e-06
Iter: 1450 loss: 1.32021523e-06
Iter: 1451 loss: 1.32064793e-06
Iter: 1452 loss: 1.32013429e-06
Iter: 1453 loss: 1.31993033e-06
Iter: 1454 loss: 1.32207629e-06
Iter: 1455 loss: 1.31990919e-06
Iter: 1456 loss: 1.31977822e-06
Iter: 1457 loss: 1.32057221e-06
Iter: 1458 loss: 1.31974207e-06
Iter: 1459 loss: 1.31962679e-06
Iter: 1460 loss: 1.31967522e-06
Iter: 1461 loss: 1.31954471e-06
Iter: 1462 loss: 1.31941658e-06
Iter: 1463 loss: 1.3204367e-06
Iter: 1464 loss: 1.31942147e-06
Iter: 1465 loss: 1.31932745e-06
Iter: 1466 loss: 1.3191941e-06
Iter: 1467 loss: 1.31920035e-06
Iter: 1468 loss: 1.31909246e-06
Iter: 1469 loss: 1.31908928e-06
Iter: 1470 loss: 1.31902686e-06
Iter: 1471 loss: 1.31887418e-06
Iter: 1472 loss: 1.32130458e-06
Iter: 1473 loss: 1.31884826e-06
Iter: 1474 loss: 1.31870036e-06
Iter: 1475 loss: 1.31871207e-06
Iter: 1476 loss: 1.31856882e-06
Iter: 1477 loss: 1.31856882e-06
Iter: 1478 loss: 1.31845525e-06
Iter: 1479 loss: 1.31839431e-06
Iter: 1480 loss: 1.31820684e-06
Iter: 1481 loss: 1.32079742e-06
Iter: 1482 loss: 1.31819343e-06
Iter: 1483 loss: 1.31801664e-06
Iter: 1484 loss: 1.31833576e-06
Iter: 1485 loss: 1.31796151e-06
Iter: 1486 loss: 1.3177962e-06
Iter: 1487 loss: 1.31999354e-06
Iter: 1488 loss: 1.31778279e-06
Iter: 1489 loss: 1.31767501e-06
Iter: 1490 loss: 1.31826914e-06
Iter: 1491 loss: 1.31765501e-06
Iter: 1492 loss: 1.31754291e-06
Iter: 1493 loss: 1.31768456e-06
Iter: 1494 loss: 1.31750312e-06
Iter: 1495 loss: 1.31739989e-06
Iter: 1496 loss: 1.31786237e-06
Iter: 1497 loss: 1.31738204e-06
Iter: 1498 loss: 1.31728416e-06
Iter: 1499 loss: 1.31715183e-06
Iter: 1500 loss: 1.31713591e-06
Iter: 1501 loss: 1.31704235e-06
Iter: 1502 loss: 1.3170436e-06
Iter: 1503 loss: 1.31693514e-06
Iter: 1504 loss: 1.31680986e-06
Iter: 1505 loss: 1.3167986e-06
Iter: 1506 loss: 1.31666081e-06
Iter: 1507 loss: 1.31655247e-06
Iter: 1508 loss: 1.31650575e-06
Iter: 1509 loss: 1.31642196e-06
Iter: 1510 loss: 1.316404e-06
Iter: 1511 loss: 1.3162728e-06
Iter: 1512 loss: 1.31629463e-06
Iter: 1513 loss: 1.31619095e-06
Iter: 1514 loss: 1.31608522e-06
Iter: 1515 loss: 1.31600223e-06
Iter: 1516 loss: 1.31596266e-06
Iter: 1517 loss: 1.31583374e-06
Iter: 1518 loss: 1.31758406e-06
Iter: 1519 loss: 1.31582556e-06
Iter: 1520 loss: 1.31572529e-06
Iter: 1521 loss: 1.31604907e-06
Iter: 1522 loss: 1.31569914e-06
Iter: 1523 loss: 1.31558295e-06
Iter: 1524 loss: 1.31598574e-06
Iter: 1525 loss: 1.31553213e-06
Iter: 1526 loss: 1.3154654e-06
Iter: 1527 loss: 1.31557533e-06
Iter: 1528 loss: 1.31542265e-06
Iter: 1529 loss: 1.31529714e-06
Iter: 1530 loss: 1.31551553e-06
Iter: 1531 loss: 1.31524655e-06
Iter: 1532 loss: 1.31514707e-06
Iter: 1533 loss: 1.3152877e-06
Iter: 1534 loss: 1.3151066e-06
Iter: 1535 loss: 1.31496199e-06
Iter: 1536 loss: 1.31569709e-06
Iter: 1537 loss: 1.31495153e-06
Iter: 1538 loss: 1.31488844e-06
Iter: 1539 loss: 1.31473507e-06
Iter: 1540 loss: 1.31716683e-06
Iter: 1541 loss: 1.31473087e-06
Iter: 1542 loss: 1.31456204e-06
Iter: 1543 loss: 1.3151091e-06
Iter: 1544 loss: 1.31453089e-06
Iter: 1545 loss: 1.3144288e-06
Iter: 1546 loss: 1.31440879e-06
Iter: 1547 loss: 1.31437014e-06
Iter: 1548 loss: 1.31421427e-06
Iter: 1549 loss: 1.31561092e-06
Iter: 1550 loss: 1.3142112e-06
Iter: 1551 loss: 1.31410434e-06
Iter: 1552 loss: 1.31505703e-06
Iter: 1553 loss: 1.31406546e-06
Iter: 1554 loss: 1.31396973e-06
Iter: 1555 loss: 1.31477509e-06
Iter: 1556 loss: 1.31395154e-06
Iter: 1557 loss: 1.31388128e-06
Iter: 1558 loss: 1.31440106e-06
Iter: 1559 loss: 1.31386923e-06
Iter: 1560 loss: 1.31381375e-06
Iter: 1561 loss: 1.31379807e-06
Iter: 1562 loss: 1.31376305e-06
Iter: 1563 loss: 1.31368984e-06
Iter: 1564 loss: 1.31406034e-06
Iter: 1565 loss: 1.31367165e-06
Iter: 1566 loss: 1.31361651e-06
Iter: 1567 loss: 1.31355796e-06
Iter: 1568 loss: 1.31354e-06
Iter: 1569 loss: 1.31346462e-06
Iter: 1570 loss: 1.31346565e-06
Iter: 1571 loss: 1.31339084e-06
Iter: 1572 loss: 1.31324873e-06
Iter: 1573 loss: 1.31436627e-06
Iter: 1574 loss: 1.31320473e-06
Iter: 1575 loss: 1.31302431e-06
Iter: 1576 loss: 1.31349623e-06
Iter: 1577 loss: 1.31296815e-06
Iter: 1578 loss: 1.31302136e-06
Iter: 1579 loss: 1.3128722e-06
Iter: 1580 loss: 1.31281854e-06
Iter: 1581 loss: 1.31269576e-06
Iter: 1582 loss: 1.31449679e-06
Iter: 1583 loss: 1.31267461e-06
Iter: 1584 loss: 1.31257252e-06
Iter: 1585 loss: 1.31289858e-06
Iter: 1586 loss: 1.31252386e-06
Iter: 1587 loss: 1.31244838e-06
Iter: 1588 loss: 1.31387151e-06
Iter: 1589 loss: 1.31244587e-06
Iter: 1590 loss: 1.31238096e-06
Iter: 1591 loss: 1.31250169e-06
Iter: 1592 loss: 1.31234253e-06
Iter: 1593 loss: 1.31224886e-06
Iter: 1594 loss: 1.31230399e-06
Iter: 1595 loss: 1.31217882e-06
Iter: 1596 loss: 1.31207162e-06
Iter: 1597 loss: 1.3124486e-06
Iter: 1598 loss: 1.31203797e-06
Iter: 1599 loss: 1.31190268e-06
Iter: 1600 loss: 1.31182924e-06
Iter: 1601 loss: 1.31177785e-06
Iter: 1602 loss: 1.31167462e-06
Iter: 1603 loss: 1.31166757e-06
Iter: 1604 loss: 1.31157628e-06
Iter: 1605 loss: 1.31143361e-06
Iter: 1606 loss: 1.31515731e-06
Iter: 1607 loss: 1.3114327e-06
Iter: 1608 loss: 1.31130435e-06
Iter: 1609 loss: 1.3113347e-06
Iter: 1610 loss: 1.31124739e-06
Iter: 1611 loss: 1.31110426e-06
Iter: 1612 loss: 1.3123821e-06
Iter: 1613 loss: 1.31109766e-06
Iter: 1614 loss: 1.31097056e-06
Iter: 1615 loss: 1.31171555e-06
Iter: 1616 loss: 1.31095362e-06
Iter: 1617 loss: 1.3109011e-06
Iter: 1618 loss: 1.31075535e-06
Iter: 1619 loss: 1.3128838e-06
Iter: 1620 loss: 1.3107599e-06
Iter: 1621 loss: 1.31067668e-06
Iter: 1622 loss: 1.31066463e-06
Iter: 1623 loss: 1.31057845e-06
Iter: 1624 loss: 1.31067793e-06
Iter: 1625 loss: 1.31053503e-06
Iter: 1626 loss: 1.3104243e-06
Iter: 1627 loss: 1.31111028e-06
Iter: 1628 loss: 1.31043066e-06
Iter: 1629 loss: 1.31034028e-06
Iter: 1630 loss: 1.31034892e-06
Iter: 1631 loss: 1.31028844e-06
Iter: 1632 loss: 1.31017259e-06
Iter: 1633 loss: 1.31047921e-06
Iter: 1634 loss: 1.31013019e-06
Iter: 1635 loss: 1.31005527e-06
Iter: 1636 loss: 1.31035858e-06
Iter: 1637 loss: 1.31002639e-06
Iter: 1638 loss: 1.3099002e-06
Iter: 1639 loss: 1.31002446e-06
Iter: 1640 loss: 1.30983744e-06
Iter: 1641 loss: 1.30974263e-06
Iter: 1642 loss: 1.30963281e-06
Iter: 1643 loss: 1.3096153e-06
Iter: 1644 loss: 1.30949797e-06
Iter: 1645 loss: 1.30967101e-06
Iter: 1646 loss: 1.30944113e-06
Iter: 1647 loss: 1.30945546e-06
Iter: 1648 loss: 1.30937474e-06
Iter: 1649 loss: 1.30933427e-06
Iter: 1650 loss: 1.30924582e-06
Iter: 1651 loss: 1.31080094e-06
Iter: 1652 loss: 1.30924877e-06
Iter: 1653 loss: 1.30915441e-06
Iter: 1654 loss: 1.30921853e-06
Iter: 1655 loss: 1.30909871e-06
Iter: 1656 loss: 1.3090206e-06
Iter: 1657 loss: 1.30902492e-06
Iter: 1658 loss: 1.30896808e-06
Iter: 1659 loss: 1.30901685e-06
Iter: 1660 loss: 1.30893864e-06
Iter: 1661 loss: 1.30884382e-06
Iter: 1662 loss: 1.30908802e-06
Iter: 1663 loss: 1.30882563e-06
Iter: 1664 loss: 1.30876e-06
Iter: 1665 loss: 1.30883427e-06
Iter: 1666 loss: 1.30871035e-06
Iter: 1667 loss: 1.30863214e-06
Iter: 1668 loss: 1.30866272e-06
Iter: 1669 loss: 1.3085828e-06
Iter: 1670 loss: 1.30851538e-06
Iter: 1671 loss: 1.30850708e-06
Iter: 1672 loss: 1.30846422e-06
Iter: 1673 loss: 1.30835508e-06
Iter: 1674 loss: 1.30972239e-06
Iter: 1675 loss: 1.30835042e-06
Iter: 1676 loss: 1.30824151e-06
Iter: 1677 loss: 1.30826197e-06
Iter: 1678 loss: 1.30815567e-06
Iter: 1679 loss: 1.30801425e-06
Iter: 1680 loss: 1.30897092e-06
Iter: 1681 loss: 1.30800561e-06
Iter: 1682 loss: 1.30791557e-06
Iter: 1683 loss: 1.30791454e-06
Iter: 1684 loss: 1.30787066e-06
Iter: 1685 loss: 1.30775879e-06
Iter: 1686 loss: 1.30842227e-06
Iter: 1687 loss: 1.3077198e-06
Iter: 1688 loss: 1.30763226e-06
Iter: 1689 loss: 1.30760986e-06
Iter: 1690 loss: 1.30754415e-06
Iter: 1691 loss: 1.30766239e-06
Iter: 1692 loss: 1.30750368e-06
Iter: 1693 loss: 1.30744752e-06
Iter: 1694 loss: 1.30799162e-06
Iter: 1695 loss: 1.30743138e-06
Iter: 1696 loss: 1.30738204e-06
Iter: 1697 loss: 1.30731883e-06
Iter: 1698 loss: 1.30730939e-06
Iter: 1699 loss: 1.30723458e-06
Iter: 1700 loss: 1.30770661e-06
Iter: 1701 loss: 1.30721241e-06
Iter: 1702 loss: 1.30714398e-06
Iter: 1703 loss: 1.30736157e-06
Iter: 1704 loss: 1.30713852e-06
Iter: 1705 loss: 1.30703779e-06
Iter: 1706 loss: 1.30723106e-06
Iter: 1707 loss: 1.30702051e-06
Iter: 1708 loss: 1.30696276e-06
Iter: 1709 loss: 1.30679894e-06
Iter: 1710 loss: 1.30825015e-06
Iter: 1711 loss: 1.30676926e-06
Iter: 1712 loss: 1.30659816e-06
Iter: 1713 loss: 1.30778494e-06
Iter: 1714 loss: 1.30660862e-06
Iter: 1715 loss: 1.30649755e-06
Iter: 1716 loss: 1.30753619e-06
Iter: 1717 loss: 1.30650164e-06
Iter: 1718 loss: 1.30640308e-06
Iter: 1719 loss: 1.30671492e-06
Iter: 1720 loss: 1.30638273e-06
Iter: 1721 loss: 1.30633418e-06
Iter: 1722 loss: 1.3062247e-06
Iter: 1723 loss: 1.30787942e-06
Iter: 1724 loss: 1.3062305e-06
Iter: 1725 loss: 1.30614922e-06
Iter: 1726 loss: 1.30615012e-06
Iter: 1727 loss: 1.30606929e-06
Iter: 1728 loss: 1.30603098e-06
Iter: 1729 loss: 1.30599437e-06
Iter: 1730 loss: 1.30591798e-06
Iter: 1731 loss: 1.30592684e-06
Iter: 1732 loss: 1.30586443e-06
Iter: 1733 loss: 1.30574654e-06
Iter: 1734 loss: 1.30759463e-06
Iter: 1735 loss: 1.30574733e-06
Iter: 1736 loss: 1.30562967e-06
Iter: 1737 loss: 1.30613091e-06
Iter: 1738 loss: 1.3056017e-06
Iter: 1739 loss: 1.30554554e-06
Iter: 1740 loss: 1.30582123e-06
Iter: 1741 loss: 1.30553883e-06
Iter: 1742 loss: 1.30546448e-06
Iter: 1743 loss: 1.30534818e-06
Iter: 1744 loss: 1.30806666e-06
Iter: 1745 loss: 1.30535238e-06
Iter: 1746 loss: 1.3052304e-06
Iter: 1747 loss: 1.3058575e-06
Iter: 1748 loss: 1.30521107e-06
Iter: 1749 loss: 1.30511421e-06
Iter: 1750 loss: 1.3051731e-06
Iter: 1751 loss: 1.30505578e-06
Iter: 1752 loss: 1.30500769e-06
Iter: 1753 loss: 1.30498813e-06
Iter: 1754 loss: 1.30494857e-06
Iter: 1755 loss: 1.30486524e-06
Iter: 1756 loss: 1.30613125e-06
Iter: 1757 loss: 1.30486683e-06
Iter: 1758 loss: 1.30479361e-06
Iter: 1759 loss: 1.30478293e-06
Iter: 1760 loss: 1.30472199e-06
Iter: 1761 loss: 1.30461592e-06
Iter: 1762 loss: 1.30562194e-06
Iter: 1763 loss: 1.30461126e-06
Iter: 1764 loss: 1.30451372e-06
Iter: 1765 loss: 1.30431704e-06
Iter: 1766 loss: 1.30733042e-06
Iter: 1767 loss: 1.30431954e-06
Iter: 1768 loss: 1.30419789e-06
Iter: 1769 loss: 1.30418448e-06
Iter: 1770 loss: 1.30410183e-06
Iter: 1771 loss: 1.30399576e-06
Iter: 1772 loss: 1.30397871e-06
Iter: 1773 loss: 1.30382296e-06
Iter: 1774 loss: 1.30406249e-06
Iter: 1775 loss: 1.30373371e-06
Iter: 1776 loss: 1.30369199e-06
Iter: 1777 loss: 1.3036672e-06
Iter: 1778 loss: 1.30361923e-06
Iter: 1779 loss: 1.30361036e-06
Iter: 1780 loss: 1.30355886e-06
Iter: 1781 loss: 1.30350315e-06
Iter: 1782 loss: 1.30340902e-06
Iter: 1783 loss: 1.30342301e-06
Iter: 1784 loss: 1.30328203e-06
Iter: 1785 loss: 1.30348735e-06
Iter: 1786 loss: 1.30320677e-06
Iter: 1787 loss: 1.30312367e-06
Iter: 1788 loss: 1.30309718e-06
Iter: 1789 loss: 1.30305602e-06
Iter: 1790 loss: 1.30295962e-06
Iter: 1791 loss: 1.30295939e-06
Iter: 1792 loss: 1.30285935e-06
Iter: 1793 loss: 1.30360991e-06
Iter: 1794 loss: 1.30285446e-06
Iter: 1795 loss: 1.3027493e-06
Iter: 1796 loss: 1.30281182e-06
Iter: 1797 loss: 1.30269655e-06
Iter: 1798 loss: 1.3026156e-06
Iter: 1799 loss: 1.30323804e-06
Iter: 1800 loss: 1.30260776e-06
Iter: 1801 loss: 1.30254807e-06
Iter: 1802 loss: 1.30261515e-06
Iter: 1803 loss: 1.30251306e-06
Iter: 1804 loss: 1.30245837e-06
Iter: 1805 loss: 1.30235617e-06
Iter: 1806 loss: 1.30236322e-06
Iter: 1807 loss: 1.30225635e-06
Iter: 1808 loss: 1.30318301e-06
Iter: 1809 loss: 1.30227022e-06
Iter: 1810 loss: 1.30217927e-06
Iter: 1811 loss: 1.30278352e-06
Iter: 1812 loss: 1.30217961e-06
Iter: 1813 loss: 1.30210378e-06
Iter: 1814 loss: 1.30222634e-06
Iter: 1815 loss: 1.30205353e-06
Iter: 1816 loss: 1.30197839e-06
Iter: 1817 loss: 1.30182866e-06
Iter: 1818 loss: 1.30183366e-06
Iter: 1819 loss: 1.301682e-06
Iter: 1820 loss: 1.30248827e-06
Iter: 1821 loss: 1.30166472e-06
Iter: 1822 loss: 1.30153558e-06
Iter: 1823 loss: 1.30310684e-06
Iter: 1824 loss: 1.30152944e-06
Iter: 1825 loss: 1.30148669e-06
Iter: 1826 loss: 1.3014261e-06
Iter: 1827 loss: 1.3014153e-06
Iter: 1828 loss: 1.30136686e-06
Iter: 1829 loss: 1.30135936e-06
Iter: 1830 loss: 1.30132753e-06
Iter: 1831 loss: 1.30124249e-06
Iter: 1832 loss: 1.30212447e-06
Iter: 1833 loss: 1.30125227e-06
Iter: 1834 loss: 1.30118326e-06
Iter: 1835 loss: 1.30118883e-06
Iter: 1836 loss: 1.30114927e-06
Iter: 1837 loss: 1.30102967e-06
Iter: 1838 loss: 1.30164369e-06
Iter: 1839 loss: 1.30101171e-06
Iter: 1840 loss: 1.30088142e-06
Iter: 1841 loss: 1.30097374e-06
Iter: 1842 loss: 1.30079957e-06
Iter: 1843 loss: 1.30069066e-06
Iter: 1844 loss: 1.30071214e-06
Iter: 1845 loss: 1.30060732e-06
Iter: 1846 loss: 1.3004875e-06
Iter: 1847 loss: 1.30048295e-06
Iter: 1848 loss: 1.30039689e-06
Iter: 1849 loss: 1.30109584e-06
Iter: 1850 loss: 1.30039234e-06
Iter: 1851 loss: 1.30035914e-06
Iter: 1852 loss: 1.30047874e-06
Iter: 1853 loss: 1.30032777e-06
Iter: 1854 loss: 1.30030128e-06
Iter: 1855 loss: 1.30022408e-06
Iter: 1856 loss: 1.30209912e-06
Iter: 1857 loss: 1.30021158e-06
Iter: 1858 loss: 1.3001395e-06
Iter: 1859 loss: 1.30013245e-06
Iter: 1860 loss: 1.30009153e-06
Iter: 1861 loss: 1.29999808e-06
Iter: 1862 loss: 1.30221633e-06
Iter: 1863 loss: 1.29998716e-06
Iter: 1864 loss: 1.29990474e-06
Iter: 1865 loss: 1.29991463e-06
Iter: 1866 loss: 1.29985028e-06
Iter: 1867 loss: 1.29975615e-06
Iter: 1868 loss: 1.3016479e-06
Iter: 1869 loss: 1.29975206e-06
Iter: 1870 loss: 1.299725e-06
Iter: 1871 loss: 1.2996793e-06
Iter: 1872 loss: 1.29963041e-06
Iter: 1873 loss: 1.29953901e-06
Iter: 1874 loss: 1.30168382e-06
Iter: 1875 loss: 1.29953696e-06
Iter: 1876 loss: 1.29942418e-06
Iter: 1877 loss: 1.29940702e-06
Iter: 1878 loss: 1.29932118e-06
Iter: 1879 loss: 1.29918544e-06
Iter: 1880 loss: 1.29907812e-06
Iter: 1881 loss: 1.29905254e-06
Iter: 1882 loss: 1.29899558e-06
Iter: 1883 loss: 1.29895147e-06
Iter: 1884 loss: 1.29886882e-06
Iter: 1885 loss: 1.29889145e-06
Iter: 1886 loss: 1.29880073e-06
Iter: 1887 loss: 1.29874456e-06
Iter: 1888 loss: 1.29888826e-06
Iter: 1889 loss: 1.2987083e-06
Iter: 1890 loss: 1.29862531e-06
Iter: 1891 loss: 1.29890054e-06
Iter: 1892 loss: 1.29862315e-06
Iter: 1893 loss: 1.29852322e-06
Iter: 1894 loss: 1.29846057e-06
Iter: 1895 loss: 1.29842113e-06
Iter: 1896 loss: 1.29832461e-06
Iter: 1897 loss: 1.29901116e-06
Iter: 1898 loss: 1.29829709e-06
Iter: 1899 loss: 1.29820614e-06
Iter: 1900 loss: 1.29864782e-06
Iter: 1901 loss: 1.29818e-06
Iter: 1902 loss: 1.29809428e-06
Iter: 1903 loss: 1.29824537e-06
Iter: 1904 loss: 1.29807609e-06
Iter: 1905 loss: 1.29795808e-06
Iter: 1906 loss: 1.29812679e-06
Iter: 1907 loss: 1.29789373e-06
Iter: 1908 loss: 1.29779653e-06
Iter: 1909 loss: 1.29774435e-06
Iter: 1910 loss: 1.29771536e-06
Iter: 1911 loss: 1.29760451e-06
Iter: 1912 loss: 1.2984558e-06
Iter: 1913 loss: 1.29759371e-06
Iter: 1914 loss: 1.29751106e-06
Iter: 1915 loss: 1.29757e-06
Iter: 1916 loss: 1.2974383e-06
Iter: 1917 loss: 1.29737532e-06
Iter: 1918 loss: 1.29737123e-06
Iter: 1919 loss: 1.29732348e-06
Iter: 1920 loss: 1.29723719e-06
Iter: 1921 loss: 1.29722298e-06
Iter: 1922 loss: 1.29717387e-06
Iter: 1923 loss: 1.29716977e-06
Iter: 1924 loss: 1.29712407e-06
Iter: 1925 loss: 1.29710088e-06
Iter: 1926 loss: 1.29706279e-06
Iter: 1927 loss: 1.2969947e-06
Iter: 1928 loss: 1.29702983e-06
Iter: 1929 loss: 1.29694263e-06
Iter: 1930 loss: 1.29684804e-06
Iter: 1931 loss: 1.29793182e-06
Iter: 1932 loss: 1.29685441e-06
Iter: 1933 loss: 1.29679916e-06
Iter: 1934 loss: 1.29673822e-06
Iter: 1935 loss: 1.29670752e-06
Iter: 1936 loss: 1.29661134e-06
Iter: 1937 loss: 1.29660953e-06
Iter: 1938 loss: 1.29653949e-06
Iter: 1939 loss: 1.29641023e-06
Iter: 1940 loss: 1.29858631e-06
Iter: 1941 loss: 1.29640216e-06
Iter: 1942 loss: 1.29629984e-06
Iter: 1943 loss: 1.29705938e-06
Iter: 1944 loss: 1.29629768e-06
Iter: 1945 loss: 1.29619e-06
Iter: 1946 loss: 1.29624357e-06
Iter: 1947 loss: 1.29609862e-06
Iter: 1948 loss: 1.29601563e-06
Iter: 1949 loss: 1.2960088e-06
Iter: 1950 loss: 1.2959058e-06
Iter: 1951 loss: 1.29589262e-06
Iter: 1952 loss: 1.29584168e-06
Iter: 1953 loss: 1.29574687e-06
Iter: 1954 loss: 1.29609043e-06
Iter: 1955 loss: 1.29571526e-06
Iter: 1956 loss: 1.295635e-06
Iter: 1957 loss: 1.29603291e-06
Iter: 1958 loss: 1.29561477e-06
Iter: 1959 loss: 1.29552495e-06
Iter: 1960 loss: 1.29556054e-06
Iter: 1961 loss: 1.29546379e-06
Iter: 1962 loss: 1.29539558e-06
Iter: 1963 loss: 1.29627892e-06
Iter: 1964 loss: 1.29539421e-06
Iter: 1965 loss: 1.29530304e-06
Iter: 1966 loss: 1.29521209e-06
Iter: 1967 loss: 1.29520413e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script80
+ '[' -r STOP.script80 ']'
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8 /home/mrdouglas/Manifold/experiments.final/output81/f1_psi0_phi0.8
+ date
Sun Nov  1 23:53:55 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/300_300_300_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_300_300_1 --function f1 --psi 0 --phi 0.8 --layers 300_300_300_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output80/f1_psi0_phi0.8/ --save_name 300_300_300_1 --optimizer adam --n_pairs 50000 --batch_size 5000 --max_epochs 200 --learning_rate 0.001 --decay_rate 0.98 --loss_func weighted_MSE
Processing model: 300_300_300_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7120114d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71201ec9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7120264b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71201ca730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71201ca2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7120264400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7120264268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71200bea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71200be620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7120033048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71200338c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7120077ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71200772f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d46cb048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d46caf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d465a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d4586bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d45fef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d4601d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d45fe2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d475b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d468c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d475ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d47dfea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d47e36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d45f3ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d44986a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d45f3048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d44ed158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d45310d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d44bc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d43c9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d43c9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d4513ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d47971e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70d477e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
train_loss: 8.216926e-05
test_loss: 7.9119265e-05
train_loss: 2.7157625e-05
test_loss: 2.6379157e-05
train_loss: 1.4953286e-05
test_loss: 1.4993718e-05
train_loss: 1.05363615e-05
test_loss: 1.0222612e-05
train_loss: 7.1873988e-06
test_loss: 7.733457e-06
train_loss: 6.15719e-06
test_loss: 6.1828973e-06
train_loss: 5.1035304e-06
test_loss: 5.3403587e-06
train_loss: 4.720052e-06