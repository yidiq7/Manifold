+ RUN=2
+ export CUDA_VISIBLE_DEVICES=2
+ CUDA_VISIBLE_DEVICES=2
+ LAYERS=300_100_100_100_1
+ case $RUN in
+ PSI='0 1'
+ OPTIONS='				 --optimizer adam 				 --n_pairs 20000 				 --batch_size 5000 				 --max_epochs 400 				 --loss_func weighted_MAPE 
'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output120
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output121
+ for fn in f1 f2
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0
+ date
Sat Nov  7 18:02:29 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1 --function f1 --psi 0 --phi 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f62c77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f6371268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f636ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f63be730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f63971e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f63a4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f62f46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f623d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f620db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f625f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f614c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f6159ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f610d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f6117048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f6114a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f60de510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f60d3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f60a4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f607d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f6056e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f6361840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f61ef378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f61ebd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f61c1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1e642f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1e72d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1dde7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1e0c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1d69c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1d74730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1d581e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1d57bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1dd16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1c9e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1c9ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb3f1c7a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0014022897
test_loss: 0.0012390342
train_loss: 0.0012046505
test_loss: 0.0013208846
train_loss: 0.0011142113
test_loss: 0.0012389485
train_loss: 0.0013460538
test_loss: 0.001090409
train_loss: 0.0010151342
test_loss: 0.0011049967
train_loss: 0.0011758669
test_loss: 0.0010562948
train_loss: 0.0011730627
test_loss: 0.0011628703
train_loss: 0.0011858831
test_loss: 0.001111874
train_loss: 0.0010284178
test_loss: 0.0011410792
train_loss: 0.0010865777
test_loss: 0.0013150134
train_loss: 0.0015192451
test_loss: 0.001209545
train_loss: 0.0011380619
test_loss: 0.0011266685
train_loss: 0.0010626767
test_loss: 0.0011148388
train_loss: 0.0010200052
test_loss: 0.0011731571
train_loss: 0.0012415318
test_loss: 0.0015412924
train_loss: 0.0013004516
test_loss: 0.0018018484
train_loss: 0.0013408831
test_loss: 0.0014606683
train_loss: 0.0009813419
test_loss: 0.0012422481
train_loss: 0.001060466
test_loss: 0.001141796
train_loss: 0.0010849719
test_loss: 0.000978933
train_loss: 0.0010485165
test_loss: 0.0010330302
train_loss: 0.0017149766
test_loss: 0.0014554177
train_loss: 0.0015085529
test_loss: 0.0012871634
train_loss: 0.0012799595
test_loss: 0.0012200273
train_loss: 0.00095884706
test_loss: 0.0009590124
train_loss: 0.0011437346
test_loss: 0.0013673215
train_loss: 0.0011016161
test_loss: 0.0010593917
train_loss: 0.0016589838
test_loss: 0.0013304816
train_loss: 0.00096222735
test_loss: 0.0010385734
train_loss: 0.0011649712
test_loss: 0.0012819828
train_loss: 0.0009803349
test_loss: 0.00095470913
train_loss: 0.0011907606
test_loss: 0.0010814973
train_loss: 0.00096874643
test_loss: 0.0010059638
train_loss: 0.0014068612
test_loss: 0.0010586386
train_loss: 0.0010530493
test_loss: 0.0010745558
train_loss: 0.0010966549
test_loss: 0.001195819
train_loss: 0.0014441088
test_loss: 0.0014423736
train_loss: 0.0012066761
test_loss: 0.0013078479
train_loss: 0.0009729052
test_loss: 0.0010853867
train_loss: 0.0014415116
test_loss: 0.0010845357
train_loss: 0.00095510087
test_loss: 0.0011639359
train_loss: 0.001002776
test_loss: 0.0010379603
train_loss: 0.00096599804
test_loss: 0.001154971
train_loss: 0.0012373243
test_loss: 0.0010699758
train_loss: 0.0013253198
test_loss: 0.0010669718
train_loss: 0.0010426473
test_loss: 0.0010606769
train_loss: 0.0010645309
test_loss: 0.0009507927
train_loss: 0.001061948
test_loss: 0.0012182568
train_loss: 0.0010696665
test_loss: 0.0012699175
train_loss: 0.0009909568
test_loss: 0.00097179716
train_loss: 0.001064603
test_loss: 0.0009315667
train_loss: 0.0010232538
test_loss: 0.0009299922
train_loss: 0.0014591384
test_loss: 0.0010829681
train_loss: 0.0014114004
test_loss: 0.0012284812
train_loss: 0.0012025057
test_loss: 0.0011942593
train_loss: 0.0010247205
test_loss: 0.0009837688
train_loss: 0.0011301914
test_loss: 0.0009521506
train_loss: 0.0012963848
test_loss: 0.0011280476
train_loss: 0.0011338524
test_loss: 0.0010399828
train_loss: 0.00097207027
test_loss: 0.0009979912
train_loss: 0.0011382567
test_loss: 0.0011281058
train_loss: 0.0011007689
test_loss: 0.0010191972
train_loss: 0.0010020584
test_loss: 0.0010493898
train_loss: 0.001403687
test_loss: 0.001599938
train_loss: 0.0011864988
test_loss: 0.0010984077
train_loss: 0.00096232997
test_loss: 0.0008901825
train_loss: 0.00089592254
test_loss: 0.0009314168
train_loss: 0.0015087374
test_loss: 0.0011966634
train_loss: 0.0011961459
test_loss: 0.0013651
train_loss: 0.00094979664
test_loss: 0.001351831
train_loss: 0.0012552952
test_loss: 0.0010339725
train_loss: 0.0009653497
test_loss: 0.0011428416
train_loss: 0.00095947547
test_loss: 0.0011240579
train_loss: 0.0010611948
test_loss: 0.0009780228
train_loss: 0.00090440706
test_loss: 0.00090520247
train_loss: 0.0009372317
test_loss: 0.001277108
train_loss: 0.0010825503
test_loss: 0.0011718968
train_loss: 0.0009191668
test_loss: 0.0011580384
train_loss: 0.0011082259
test_loss: 0.0012027096
train_loss: 0.000983165
test_loss: 0.0010966051
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e254f97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e254ff268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e255b8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e25598730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e2560d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e255eebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e255396a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e254a0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e254c9b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e25478620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e254110d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e2542eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e253f0598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e253fc048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e253fda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e253c6510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e253c3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e25387950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e2532c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e2533ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e252dc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e252fd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e25297d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e252c8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a9112f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a925d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a8d97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a878268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a88ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a82d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e254dc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a7f8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a81c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a7b4158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a7d1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1e1a77d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.74429101e-06
Iter: 2 loss: 9.95104529e-06
Iter: 3 loss: 1.05110098e-06
Iter: 4 loss: 9.26226221e-07
Iter: 5 loss: 8.61825242e-07
Iter: 6 loss: 8.03976945e-07
Iter: 7 loss: 7.52473056e-07
Iter: 8 loss: 1.34724223e-06
Iter: 9 loss: 7.51654852e-07
Iter: 10 loss: 6.9326677e-07
Iter: 11 loss: 6.63360765e-07
Iter: 12 loss: 6.36239236e-07
Iter: 13 loss: 6.16118e-07
Iter: 14 loss: 6.14439728e-07
Iter: 15 loss: 6.02070088e-07
Iter: 16 loss: 6.55199528e-07
Iter: 17 loss: 5.99517193e-07
Iter: 18 loss: 5.95677761e-07
Iter: 19 loss: 5.883212e-07
Iter: 20 loss: 7.43396413e-07
Iter: 21 loss: 5.88275157e-07
Iter: 22 loss: 5.8919494e-07
Iter: 23 loss: 5.86507497e-07
Iter: 24 loss: 5.84795e-07
Iter: 25 loss: 5.8553286e-07
Iter: 26 loss: 5.83614224e-07
Iter: 27 loss: 5.82425344e-07
Iter: 28 loss: 5.82566031e-07
Iter: 29 loss: 5.81521476e-07
Iter: 30 loss: 5.80668939e-07
Iter: 31 loss: 5.80613573e-07
Iter: 32 loss: 5.79945379e-07
Iter: 33 loss: 5.79013e-07
Iter: 34 loss: 5.77122307e-07
Iter: 35 loss: 6.15034082e-07
Iter: 36 loss: 5.77119295e-07
Iter: 37 loss: 5.75464e-07
Iter: 38 loss: 5.78587333e-07
Iter: 39 loss: 5.7474756e-07
Iter: 40 loss: 5.72783108e-07
Iter: 41 loss: 5.85477778e-07
Iter: 42 loss: 5.72559202e-07
Iter: 43 loss: 5.71530563e-07
Iter: 44 loss: 5.83609847e-07
Iter: 45 loss: 5.71529199e-07
Iter: 46 loss: 5.70063776e-07
Iter: 47 loss: 5.68243081e-07
Iter: 48 loss: 5.68117116e-07
Iter: 49 loss: 5.67248321e-07
Iter: 50 loss: 5.67212339e-07
Iter: 51 loss: 5.66430117e-07
Iter: 52 loss: 5.66520839e-07
Iter: 53 loss: 5.65828316e-07
Iter: 54 loss: 5.64877098e-07
Iter: 55 loss: 5.624712e-07
Iter: 56 loss: 5.86198269e-07
Iter: 57 loss: 5.62165383e-07
Iter: 58 loss: 5.61494403e-07
Iter: 59 loss: 5.61074444e-07
Iter: 60 loss: 5.602908e-07
Iter: 61 loss: 5.68498194e-07
Iter: 62 loss: 5.6028091e-07
Iter: 63 loss: 5.59796e-07
Iter: 64 loss: 5.5916e-07
Iter: 65 loss: 5.59125112e-07
Iter: 66 loss: 5.59193495e-07
Iter: 67 loss: 5.58854595e-07
Iter: 68 loss: 5.58725901e-07
Iter: 69 loss: 5.582923e-07
Iter: 70 loss: 5.59432067e-07
Iter: 71 loss: 5.5802991e-07
Iter: 72 loss: 5.57407304e-07
Iter: 73 loss: 5.59383125e-07
Iter: 74 loss: 5.57186468e-07
Iter: 75 loss: 5.56528278e-07
Iter: 76 loss: 5.55530846e-07
Iter: 77 loss: 5.55493841e-07
Iter: 78 loss: 5.55577458e-07
Iter: 79 loss: 5.54830194e-07
Iter: 80 loss: 5.5438818e-07
Iter: 81 loss: 5.53385576e-07
Iter: 82 loss: 5.6542774e-07
Iter: 83 loss: 5.53283257e-07
Iter: 84 loss: 5.52252e-07
Iter: 85 loss: 5.51904122e-07
Iter: 86 loss: 5.51296807e-07
Iter: 87 loss: 5.50815514e-07
Iter: 88 loss: 5.5311159e-07
Iter: 89 loss: 5.5072644e-07
Iter: 90 loss: 5.50388108e-07
Iter: 91 loss: 5.52598522e-07
Iter: 92 loss: 5.50378843e-07
Iter: 93 loss: 5.50031359e-07
Iter: 94 loss: 5.49629135e-07
Iter: 95 loss: 5.49605261e-07
Iter: 96 loss: 5.493049e-07
Iter: 97 loss: 5.51621611e-07
Iter: 98 loss: 5.49282163e-07
Iter: 99 loss: 5.49087758e-07
Iter: 100 loss: 5.48470553e-07
Iter: 101 loss: 5.5085269e-07
Iter: 102 loss: 5.48197875e-07
Iter: 103 loss: 5.48067192e-07
Iter: 104 loss: 5.47784907e-07
Iter: 105 loss: 5.47422644e-07
Iter: 106 loss: 5.49606739e-07
Iter: 107 loss: 5.47404909e-07
Iter: 108 loss: 5.47093862e-07
Iter: 109 loss: 5.46469721e-07
Iter: 110 loss: 5.55103952e-07
Iter: 111 loss: 5.4644039e-07
Iter: 112 loss: 5.4576708e-07
Iter: 113 loss: 5.46752233e-07
Iter: 114 loss: 5.45478713e-07
Iter: 115 loss: 5.45243722e-07
Iter: 116 loss: 5.45032265e-07
Iter: 117 loss: 5.44700356e-07
Iter: 118 loss: 5.44192062e-07
Iter: 119 loss: 5.44139709e-07
Iter: 120 loss: 5.43715828e-07
Iter: 121 loss: 5.43647502e-07
Iter: 122 loss: 5.43342e-07
Iter: 123 loss: 5.43078045e-07
Iter: 124 loss: 5.42958617e-07
Iter: 125 loss: 5.42810767e-07
Iter: 126 loss: 5.42835437e-07
Iter: 127 loss: 5.4273346e-07
Iter: 128 loss: 5.42595046e-07
Iter: 129 loss: 5.43744932e-07
Iter: 130 loss: 5.4260147e-07
Iter: 131 loss: 5.42455552e-07
Iter: 132 loss: 5.42263535e-07
Iter: 133 loss: 5.42254611e-07
Iter: 134 loss: 5.42106704e-07
Iter: 135 loss: 5.42123189e-07
Iter: 136 loss: 5.42020302e-07
Iter: 137 loss: 5.41792588e-07
Iter: 138 loss: 5.42484372e-07
Iter: 139 loss: 5.41739269e-07
Iter: 140 loss: 5.41541112e-07
Iter: 141 loss: 5.41533041e-07
Iter: 142 loss: 5.41426743e-07
Iter: 143 loss: 5.41086e-07
Iter: 144 loss: 5.42252053e-07
Iter: 145 loss: 5.40973588e-07
Iter: 146 loss: 5.40383496e-07
Iter: 147 loss: 5.43652618e-07
Iter: 148 loss: 5.40344672e-07
Iter: 149 loss: 5.39971325e-07
Iter: 150 loss: 5.39983944e-07
Iter: 151 loss: 5.39788061e-07
Iter: 152 loss: 5.39375264e-07
Iter: 153 loss: 5.42107e-07
Iter: 154 loss: 5.39255382e-07
Iter: 155 loss: 5.39128e-07
Iter: 156 loss: 5.39026075e-07
Iter: 157 loss: 5.3882161e-07
Iter: 158 loss: 5.38984864e-07
Iter: 159 loss: 5.38719064e-07
Iter: 160 loss: 5.38516417e-07
Iter: 161 loss: 5.38887775e-07
Iter: 162 loss: 5.38468498e-07
Iter: 163 loss: 5.38290692e-07
Iter: 164 loss: 5.38302345e-07
Iter: 165 loss: 5.38264e-07
Iter: 166 loss: 5.38127e-07
Iter: 167 loss: 5.39224e-07
Iter: 168 loss: 5.38103109e-07
Iter: 169 loss: 5.37890287e-07
Iter: 170 loss: 5.38119707e-07
Iter: 171 loss: 5.37784388e-07
Iter: 172 loss: 5.37735843e-07
Iter: 173 loss: 5.37727146e-07
Iter: 174 loss: 5.37602091e-07
Iter: 175 loss: 5.37484368e-07
Iter: 176 loss: 5.37483402e-07
Iter: 177 loss: 5.37348e-07
Iter: 178 loss: 5.37302185e-07
Iter: 179 loss: 5.37241476e-07
Iter: 180 loss: 5.37151152e-07
Iter: 181 loss: 5.37100334e-07
Iter: 182 loss: 5.37034509e-07
Iter: 183 loss: 5.36754101e-07
Iter: 184 loss: 5.38962e-07
Iter: 185 loss: 5.36714083e-07
Iter: 186 loss: 5.36491712e-07
Iter: 187 loss: 5.36772916e-07
Iter: 188 loss: 5.36367452e-07
Iter: 189 loss: 5.36122457e-07
Iter: 190 loss: 5.3909929e-07
Iter: 191 loss: 5.36124162e-07
Iter: 192 loss: 5.35984498e-07
Iter: 193 loss: 5.35945048e-07
Iter: 194 loss: 5.3587155e-07
Iter: 195 loss: 5.35770369e-07
Iter: 196 loss: 5.35765139e-07
Iter: 197 loss: 5.35653896e-07
Iter: 198 loss: 5.35641846e-07
Iter: 199 loss: 5.35549646e-07
Iter: 200 loss: 5.35488766e-07
Iter: 201 loss: 5.35567949e-07
Iter: 202 loss: 5.35420327e-07
Iter: 203 loss: 5.35339268e-07
Iter: 204 loss: 5.35402592e-07
Iter: 205 loss: 5.35315166e-07
Iter: 206 loss: 5.35213132e-07
Iter: 207 loss: 5.3614292e-07
Iter: 208 loss: 5.3520921e-07
Iter: 209 loss: 5.35151116e-07
Iter: 210 loss: 5.35080915e-07
Iter: 211 loss: 5.35095637e-07
Iter: 212 loss: 5.34979904e-07
Iter: 213 loss: 5.35256731e-07
Iter: 214 loss: 5.34939943e-07
Iter: 215 loss: 5.34765604e-07
Iter: 216 loss: 5.34882417e-07
Iter: 217 loss: 5.34665844e-07
Iter: 218 loss: 5.34524474e-07
Iter: 219 loss: 5.34349056e-07
Iter: 220 loss: 5.34343485e-07
Iter: 221 loss: 5.34233209e-07
Iter: 222 loss: 5.34188e-07
Iter: 223 loss: 5.34089509e-07
Iter: 224 loss: 5.33919433e-07
Iter: 225 loss: 5.33915227e-07
Iter: 226 loss: 5.3375868e-07
Iter: 227 loss: 5.35987738e-07
Iter: 228 loss: 5.33763853e-07
Iter: 229 loss: 5.33635614e-07
Iter: 230 loss: 5.33810862e-07
Iter: 231 loss: 5.33580931e-07
Iter: 232 loss: 5.335e-07
Iter: 233 loss: 5.33572631e-07
Iter: 234 loss: 5.33461105e-07
Iter: 235 loss: 5.33361685e-07
Iter: 236 loss: 5.33365892e-07
Iter: 237 loss: 5.33279433e-07
Iter: 238 loss: 5.33178763e-07
Iter: 239 loss: 5.34439e-07
Iter: 240 loss: 5.3318e-07
Iter: 241 loss: 5.33132493e-07
Iter: 242 loss: 5.33082357e-07
Iter: 243 loss: 5.33048933e-07
Iter: 244 loss: 5.32955482e-07
Iter: 245 loss: 5.33016077e-07
Iter: 246 loss: 5.32890965e-07
Iter: 247 loss: 5.32817239e-07
Iter: 248 loss: 5.32795241e-07
Iter: 249 loss: 5.32751301e-07
Iter: 250 loss: 5.32655235e-07
Iter: 251 loss: 5.32892727e-07
Iter: 252 loss: 5.32592708e-07
Iter: 253 loss: 5.3250352e-07
Iter: 254 loss: 5.32483057e-07
Iter: 255 loss: 5.32391823e-07
Iter: 256 loss: 5.32411036e-07
Iter: 257 loss: 5.32327363e-07
Iter: 258 loss: 5.32227659e-07
Iter: 259 loss: 5.3261e-07
Iter: 260 loss: 5.32221861e-07
Iter: 261 loss: 5.32077593e-07
Iter: 262 loss: 5.32176e-07
Iter: 263 loss: 5.32024046e-07
Iter: 264 loss: 5.31874889e-07
Iter: 265 loss: 5.32178319e-07
Iter: 266 loss: 5.31789567e-07
Iter: 267 loss: 5.31639387e-07
Iter: 268 loss: 5.31704472e-07
Iter: 269 loss: 5.31541048e-07
Iter: 270 loss: 5.31323906e-07
Iter: 271 loss: 5.32710942e-07
Iter: 272 loss: 5.31327146e-07
Iter: 273 loss: 5.31180774e-07
Iter: 274 loss: 5.31061687e-07
Iter: 275 loss: 5.31034e-07
Iter: 276 loss: 5.30879163e-07
Iter: 277 loss: 5.31647402e-07
Iter: 278 loss: 5.30847501e-07
Iter: 279 loss: 5.30835393e-07
Iter: 280 loss: 5.30786338e-07
Iter: 281 loss: 5.30778323e-07
Iter: 282 loss: 5.3067356e-07
Iter: 283 loss: 5.31683952e-07
Iter: 284 loss: 5.30650823e-07
Iter: 285 loss: 5.30579484e-07
Iter: 286 loss: 5.31547528e-07
Iter: 287 loss: 5.30566467e-07
Iter: 288 loss: 5.30536624e-07
Iter: 289 loss: 5.30936347e-07
Iter: 290 loss: 5.30511215e-07
Iter: 291 loss: 5.3048069e-07
Iter: 292 loss: 5.3049007e-07
Iter: 293 loss: 5.30476541e-07
Iter: 294 loss: 5.30420323e-07
Iter: 295 loss: 5.30585908e-07
Iter: 296 loss: 5.30395141e-07
Iter: 297 loss: 5.30370244e-07
Iter: 298 loss: 5.30437148e-07
Iter: 299 loss: 5.3034762e-07
Iter: 300 loss: 5.30284296e-07
Iter: 301 loss: 5.30308171e-07
Iter: 302 loss: 5.30256841e-07
Iter: 303 loss: 5.30224838e-07
Iter: 304 loss: 5.30539467e-07
Iter: 305 loss: 5.30186753e-07
Iter: 306 loss: 5.30129057e-07
Iter: 307 loss: 5.30133377e-07
Iter: 308 loss: 5.30093303e-07
Iter: 309 loss: 5.30020543e-07
Iter: 310 loss: 5.29952842e-07
Iter: 311 loss: 5.29925842e-07
Iter: 312 loss: 5.29881618e-07
Iter: 313 loss: 5.29880424e-07
Iter: 314 loss: 5.29803401e-07
Iter: 315 loss: 5.29719102e-07
Iter: 316 loss: 5.29712622e-07
Iter: 317 loss: 5.29588874e-07
Iter: 318 loss: 5.29771e-07
Iter: 319 loss: 5.29528791e-07
Iter: 320 loss: 5.29437955e-07
Iter: 321 loss: 5.29441763e-07
Iter: 322 loss: 5.29383044e-07
Iter: 323 loss: 5.29281294e-07
Iter: 324 loss: 5.29300166e-07
Iter: 325 loss: 5.29223428e-07
Iter: 326 loss: 5.29215e-07
Iter: 327 loss: 5.29162776e-07
Iter: 328 loss: 5.29244176e-07
Iter: 329 loss: 5.29133104e-07
Iter: 330 loss: 5.29078079e-07
Iter: 331 loss: 5.29073645e-07
Iter: 332 loss: 5.29011572e-07
Iter: 333 loss: 5.28943247e-07
Iter: 334 loss: 5.29341492e-07
Iter: 335 loss: 5.2897542e-07
Iter: 336 loss: 5.28871965e-07
Iter: 337 loss: 5.28984117e-07
Iter: 338 loss: 5.28834846e-07
Iter: 339 loss: 5.28768112e-07
Iter: 340 loss: 5.28700696e-07
Iter: 341 loss: 5.28689213e-07
Iter: 342 loss: 5.28626458e-07
Iter: 343 loss: 5.28606392e-07
Iter: 344 loss: 5.28553755e-07
Iter: 345 loss: 5.28539488e-07
Iter: 346 loss: 5.28502312e-07
Iter: 347 loss: 5.28431883e-07
Iter: 348 loss: 5.28323653e-07
Iter: 349 loss: 5.28304497e-07
Iter: 350 loss: 5.28272267e-07
Iter: 351 loss: 5.28231681e-07
Iter: 352 loss: 5.28169664e-07
Iter: 353 loss: 5.28013857e-07
Iter: 354 loss: 5.30021566e-07
Iter: 355 loss: 5.279785e-07
Iter: 356 loss: 5.27913755e-07
Iter: 357 loss: 5.27868565e-07
Iter: 358 loss: 5.27834e-07
Iter: 359 loss: 5.27862767e-07
Iter: 360 loss: 5.27785801e-07
Iter: 361 loss: 5.27689849e-07
Iter: 362 loss: 5.27695647e-07
Iter: 363 loss: 5.27608108e-07
Iter: 364 loss: 5.27504199e-07
Iter: 365 loss: 5.28715816e-07
Iter: 366 loss: 5.27529323e-07
Iter: 367 loss: 5.27416375e-07
Iter: 368 loss: 5.27521195e-07
Iter: 369 loss: 5.27363e-07
Iter: 370 loss: 5.27270686e-07
Iter: 371 loss: 5.27191332e-07
Iter: 372 loss: 5.2715842e-07
Iter: 373 loss: 5.27128464e-07
Iter: 374 loss: 5.27121074e-07
Iter: 375 loss: 5.27080658e-07
Iter: 376 loss: 5.2723766e-07
Iter: 377 loss: 5.27079237e-07
Iter: 378 loss: 5.27034445e-07
Iter: 379 loss: 5.26976692e-07
Iter: 380 loss: 5.27934617e-07
Iter: 381 loss: 5.26971462e-07
Iter: 382 loss: 5.26982831e-07
Iter: 383 loss: 5.2697095e-07
Iter: 384 loss: 5.26951453e-07
Iter: 385 loss: 5.26906604e-07
Iter: 386 loss: 5.26925533e-07
Iter: 387 loss: 5.26882047e-07
Iter: 388 loss: 5.27036377e-07
Iter: 389 loss: 5.26876647e-07
Iter: 390 loss: 5.26850499e-07
Iter: 391 loss: 5.26853114e-07
Iter: 392 loss: 5.26828899e-07
Iter: 393 loss: 5.26760516e-07
Iter: 394 loss: 5.26682072e-07
Iter: 395 loss: 5.26672522e-07
Iter: 396 loss: 5.26571398e-07
Iter: 397 loss: 5.27528584e-07
Iter: 398 loss: 5.26571398e-07
Iter: 399 loss: 5.26444467e-07
Iter: 400 loss: 5.26672125e-07
Iter: 401 loss: 5.26429233e-07
Iter: 402 loss: 5.26344309e-07
Iter: 403 loss: 5.26258475e-07
Iter: 404 loss: 5.26260351e-07
Iter: 405 loss: 5.2613359e-07
Iter: 406 loss: 5.26706e-07
Iter: 407 loss: 5.26132339e-07
Iter: 408 loss: 5.26090389e-07
Iter: 409 loss: 5.26070892e-07
Iter: 410 loss: 5.26070323e-07
Iter: 411 loss: 5.25982955e-07
Iter: 412 loss: 5.27105385e-07
Iter: 413 loss: 5.25991254e-07
Iter: 414 loss: 5.25960218e-07
Iter: 415 loss: 5.26308099e-07
Iter: 416 loss: 5.25973178e-07
Iter: 417 loss: 5.259148e-07
Iter: 418 loss: 5.26047415e-07
Iter: 419 loss: 5.25931569e-07
Iter: 420 loss: 5.25905762e-07
Iter: 421 loss: 5.25901271e-07
Iter: 422 loss: 5.25915e-07
Iter: 423 loss: 5.25877283e-07
Iter: 424 loss: 5.26200381e-07
Iter: 425 loss: 5.25850851e-07
Iter: 426 loss: 5.25851647e-07
Iter: 427 loss: 5.25868586e-07
Iter: 428 loss: 5.25863584e-07
Iter: 429 loss: 5.25848e-07
Iter: 430 loss: 5.25856649e-07
Iter: 431 loss: 5.25868927e-07
Iter: 432 loss: 5.25860173e-07
Iter: 433 loss: 5.25877226e-07
Iter: 434 loss: 5.25867847e-07
Iter: 435 loss: 5.25859889e-07
Iter: 436 loss: 5.25858468e-07
Iter: 437 loss: 5.2585807e-07
Iter: 438 loss: 5.25857786e-07
Iter: 439 loss: 5.25854261e-07
Iter: 440 loss: 5.25853579e-07
Iter: 441 loss: 5.25850737e-07
Iter: 442 loss: 5.25851419e-07
Iter: 443 loss: 5.25852158e-07
Iter: 444 loss: 5.25851817e-07
Iter: 445 loss: 5.25851e-07
Iter: 446 loss: 5.25851874e-07
Iter: 447 loss: 5.25851874e-07
Iter: 448 loss: 5.25851476e-07
Iter: 449 loss: 5.25851e-07
Iter: 450 loss: 5.25851e-07
Iter: 451 loss: 5.25851476e-07
Iter: 452 loss: 5.25851e-07
Iter: 453 loss: 5.25851476e-07
Iter: 454 loss: 5.25781729e-07
Iter: 455 loss: 5.26810823e-07
Iter: 456 loss: 5.25782866e-07
Iter: 457 loss: 5.25734265e-07
Iter: 458 loss: 5.25851419e-07
Iter: 459 loss: 5.25719429e-07
Iter: 460 loss: 5.25669179e-07
Iter: 461 loss: 5.2631782e-07
Iter: 462 loss: 5.25659971e-07
Iter: 463 loss: 5.25637461e-07
Iter: 464 loss: 5.25569533e-07
Iter: 465 loss: 5.25557198e-07
Iter: 466 loss: 5.25535768e-07
Iter: 467 loss: 5.2552366e-07
Iter: 468 loss: 5.25489497e-07
Iter: 469 loss: 5.2547631e-07
Iter: 470 loss: 5.25469545e-07
Iter: 471 loss: 5.2540571e-07
Iter: 472 loss: 5.25665087e-07
Iter: 473 loss: 5.25413043e-07
Iter: 474 loss: 5.25355119e-07
Iter: 475 loss: 5.25458233e-07
Iter: 476 loss: 5.25334258e-07
Iter: 477 loss: 5.25270536e-07
Iter: 478 loss: 5.25303e-07
Iter: 479 loss: 5.25218525e-07
Iter: 480 loss: 5.25171572e-07
Iter: 481 loss: 5.25177256e-07
Iter: 482 loss: 5.25142411e-07
Iter: 483 loss: 5.2513e-07
Iter: 484 loss: 5.25115581e-07
Iter: 485 loss: 5.25076757e-07
Iter: 486 loss: 5.25031e-07
Iter: 487 loss: 5.2654508e-07
Iter: 488 loss: 5.25040264e-07
Iter: 489 loss: 5.24959319e-07
Iter: 490 loss: 5.25141331e-07
Iter: 491 loss: 5.24951247e-07
Iter: 492 loss: 5.24881159e-07
Iter: 493 loss: 5.25035603e-07
Iter: 494 loss: 5.24865641e-07
Iter: 495 loss: 5.2484711e-07
Iter: 496 loss: 5.24839038e-07
Iter: 497 loss: 5.248055e-07
Iter: 498 loss: 5.24763266e-07
Iter: 499 loss: 5.25384166e-07
Iter: 500 loss: 5.24759969e-07
Iter: 501 loss: 5.24700908e-07
Iter: 502 loss: 5.2487735e-07
Iter: 503 loss: 5.24690904e-07
Iter: 504 loss: 5.24578638e-07
Iter: 505 loss: 5.24601148e-07
Iter: 506 loss: 5.24512473e-07
Iter: 507 loss: 5.2444426e-07
Iter: 508 loss: 5.24767188e-07
Iter: 509 loss: 5.24457164e-07
Iter: 510 loss: 5.24401571e-07
Iter: 511 loss: 5.24458642e-07
Iter: 512 loss: 5.24351549e-07
Iter: 513 loss: 5.24313577e-07
Iter: 514 loss: 5.24238828e-07
Iter: 515 loss: 5.24252528e-07
Iter: 516 loss: 5.24244399e-07
Iter: 517 loss: 5.2421359e-07
Iter: 518 loss: 5.24172606e-07
Iter: 519 loss: 5.24128041e-07
Iter: 520 loss: 5.24122811e-07
Iter: 521 loss: 5.24087739e-07
Iter: 522 loss: 5.24176471e-07
Iter: 523 loss: 5.24059374e-07
Iter: 524 loss: 5.24038398e-07
Iter: 525 loss: 5.24047891e-07
Iter: 526 loss: 5.24046754e-07
Iter: 527 loss: 5.23991616e-07
Iter: 528 loss: 5.24164932e-07
Iter: 529 loss: 5.23984909e-07
Iter: 530 loss: 5.23962854e-07
Iter: 531 loss: 5.2395967e-07
Iter: 532 loss: 5.23946142e-07
Iter: 533 loss: 5.23918061e-07
Iter: 534 loss: 5.23908227e-07
Iter: 535 loss: 5.23912661e-07
Iter: 536 loss: 5.23906863e-07
Iter: 537 loss: 5.23913059e-07
Iter: 538 loss: 5.23906579e-07
Iter: 539 loss: 5.2391789e-07
Iter: 540 loss: 5.2393176e-07
Iter: 541 loss: 5.23915446e-07
Iter: 542 loss: 5.23913343e-07
Iter: 543 loss: 5.23913059e-07
Iter: 544 loss: 5.23914537e-07
Iter: 545 loss: 5.23904873e-07
Iter: 546 loss: 5.23920448e-07
Iter: 547 loss: 5.23912945e-07
Iter: 548 loss: 5.2390476e-07
Iter: 549 loss: 5.239e-07
Iter: 550 loss: 5.23912206e-07
Iter: 551 loss: 5.23899757e-07
Iter: 552 loss: 5.23897086e-07
Iter: 553 loss: 5.23910614e-07
Iter: 554 loss: 5.23910217e-07
Iter: 555 loss: 5.23910444e-07
Iter: 556 loss: 5.23910444e-07
Iter: 557 loss: 5.23901349e-07
Iter: 558 loss: 5.2391e-07
Iter: 559 loss: 5.23911183e-07
Iter: 560 loss: 5.23911297e-07
Iter: 561 loss: 5.23911297e-07
Iter: 562 loss: 5.23901349e-07
Iter: 563 loss: 5.23804545e-07
Iter: 564 loss: 5.24498887e-07
Iter: 565 loss: 5.2383524e-07
Iter: 566 loss: 5.23835581e-07
Iter: 567 loss: 5.2384263e-07
Iter: 568 loss: 5.23821541e-07
Iter: 569 loss: 5.23823871e-07
Iter: 570 loss: 5.23826202e-07
Iter: 571 loss: 5.23839788e-07
Iter: 572 loss: 5.23824e-07
Iter: 573 loss: 5.2382336e-07
Iter: 574 loss: 5.23820404e-07
Iter: 575 loss: 5.2382552e-07
Iter: 576 loss: 5.23819722e-07
Iter: 577 loss: 5.23819892e-07
Iter: 578 loss: 5.23829044e-07
Iter: 579 loss: 5.23837912e-07
Iter: 580 loss: 5.23830181e-07
Iter: 581 loss: 5.23834274e-07
Iter: 582 loss: 5.23836093e-07
Iter: 583 loss: 5.23834842e-07
Iter: 584 loss: 5.23836661e-07
Iter: 585 loss: 5.23837e-07
Iter: 586 loss: 5.2383507e-07
Iter: 587 loss: 5.23836718e-07
Iter: 588 loss: 5.23836093e-07
Iter: 589 loss: 5.23836093e-07
Iter: 590 loss: 5.23835752e-07
Iter: 591 loss: 5.23835752e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.4 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.4
+ date
Sat Nov  7 18:36:27 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0/300_100_100_100_1 --function f1 --psi 0 --phi 0.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.4/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8beede18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bee9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8be277b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bf45378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8be27268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8be27158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0ba6865048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bd18a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bd18d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8be01d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bd642f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d2bcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d2b08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d2761e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d27d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bd7b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bd07840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d266ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bd18c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d266158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bccb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bca7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b8bccbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d171ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d12d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d126ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d15c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d126158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d051158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d0300d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d02a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d1fe158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d1fe400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d221ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d0cc1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0b7d00c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.005655831
test_loss: 0.0056222924
train_loss: 0.002268137
test_loss: 0.0023670231
train_loss: 0.002011494
test_loss: 0.0022115307
train_loss: 0.0017725189
test_loss: 0.0016684704
train_loss: 0.0015665467
test_loss: 0.0016274059
train_loss: 0.0015189776
test_loss: 0.001774133
train_loss: 0.001495025
test_loss: 0.0013989214
train_loss: 0.0014555112
test_loss: 0.0017215798
train_loss: 0.0014740425
test_loss: 0.0016380805
train_loss: 0.0014505961
test_loss: 0.001457682
train_loss: 0.0015383032
test_loss: 0.0014759136
train_loss: 0.0014363141
test_loss: 0.0014399422
train_loss: 0.0013820106
test_loss: 0.0015170824
train_loss: 0.001334582
test_loss: 0.0013283307
train_loss: 0.0012753789
test_loss: 0.0013290877
train_loss: 0.0014600193
test_loss: 0.0015235173
train_loss: 0.0014166881
test_loss: 0.0016323298
train_loss: 0.0013165644
test_loss: 0.0016363366
train_loss: 0.001390994
test_loss: 0.0015318864
train_loss: 0.0012735991
test_loss: 0.0013253522
train_loss: 0.0013710172
test_loss: 0.001619757
train_loss: 0.0014603075
test_loss: 0.0021530546
train_loss: 0.0014086732
test_loss: 0.0014334765
train_loss: 0.0012601325
test_loss: 0.0014819206
train_loss: 0.0015219239
test_loss: 0.0013663364
train_loss: 0.0012558431
test_loss: 0.0014399749
train_loss: 0.0012439245
test_loss: 0.0012741834
train_loss: 0.0013512401
test_loss: 0.0011924735
train_loss: 0.0013863833
test_loss: 0.0016045739
train_loss: 0.0014573634
test_loss: 0.0012838341
train_loss: 0.0014711303
test_loss: 0.0013038247
train_loss: 0.0013234103
test_loss: 0.0014101408
train_loss: 0.0014638883
test_loss: 0.0013210289
train_loss: 0.0013505518
test_loss: 0.0013825792
train_loss: 0.0012430563
test_loss: 0.0012653297
train_loss: 0.0013206764
test_loss: 0.0015907956
train_loss: 0.0012411824
test_loss: 0.001411939
train_loss: 0.0012569295
test_loss: 0.001193967
train_loss: 0.0012227499
test_loss: 0.0013002935
train_loss: 0.0011308768
test_loss: 0.0012270781
train_loss: 0.0013570073
test_loss: 0.0014170425
train_loss: 0.001538039
test_loss: 0.0013461572
train_loss: 0.0015347523
test_loss: 0.0013902393
train_loss: 0.0013184594
test_loss: 0.0013269746
train_loss: 0.0012647461
test_loss: 0.0011179785
train_loss: 0.0012404067
test_loss: 0.0010873595
train_loss: 0.0014596579
test_loss: 0.0014614526
train_loss: 0.0010917061
test_loss: 0.0013118999
train_loss: 0.0013691967
test_loss: 0.0012531687
train_loss: 0.0014219867
test_loss: 0.0012026345
train_loss: 0.0011529173
test_loss: 0.0012760684
train_loss: 0.001292758
test_loss: 0.0013054195
train_loss: 0.0012832048
test_loss: 0.0013696542
train_loss: 0.0013894704
test_loss: 0.0013989916
train_loss: 0.0013507082
test_loss: 0.0012375239
train_loss: 0.0012831789
test_loss: 0.0013559597
train_loss: 0.0011618542
test_loss: 0.0010836356
train_loss: 0.0012015064
test_loss: 0.001447658
train_loss: 0.0012925108
test_loss: 0.0011660939
train_loss: 0.0012299806
test_loss: 0.0012281074
train_loss: 0.001166084
test_loss: 0.0011778576
train_loss: 0.0015548471
test_loss: 0.0017955038
train_loss: 0.0013050647
test_loss: 0.0012996718
train_loss: 0.001304957
test_loss: 0.0011988927
train_loss: 0.0013338285
test_loss: 0.0015101086
train_loss: 0.0013535556
test_loss: 0.0012256542
train_loss: 0.0012129886
test_loss: 0.0014369134
train_loss: 0.0010360546
test_loss: 0.0011404202
train_loss: 0.001065675
test_loss: 0.0012438972
train_loss: 0.0012999187
test_loss: 0.001441504
train_loss: 0.0012208429
test_loss: 0.0012129217
train_loss: 0.001138233
test_loss: 0.0010627625
train_loss: 0.0011686734
test_loss: 0.0011426257
train_loss: 0.0014096077
test_loss: 0.0015143101
train_loss: 0.0013708769
test_loss: 0.0011069026
train_loss: 0.0010654891
test_loss: 0.0011166754
train_loss: 0.0011035805
test_loss: 0.0011410139
train_loss: 0.0011808159
test_loss: 0.0010501894
train_loss: 0.0012489846
test_loss: 0.0010778533
train_loss: 0.0012783749
test_loss: 0.0011649503
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.4/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.4/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f88ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f8498c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f8e4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f85fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f7d4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f8e42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f76c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f7ba1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f7bf7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f6d30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f6d3950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f6e8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f6e8400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f66f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f679620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f6e8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f62dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c9f6809d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c85144b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c8513b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c850ff048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c8509f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c850b06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c85067e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c85067d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c8504bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c600d3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c850671e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6009e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c600ce0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c600b9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c600861e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6008d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c600199d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c400a8268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c400c3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.07140374e-06
Iter: 2 loss: 6.12834629e-06
Iter: 3 loss: 1.51674033e-06
Iter: 4 loss: 1.30879721e-06
Iter: 5 loss: 1.40862937e-06
Iter: 6 loss: 1.16903766e-06
Iter: 7 loss: 1.09481459e-06
Iter: 8 loss: 1.78907749e-06
Iter: 9 loss: 1.0917189e-06
Iter: 10 loss: 1.01152796e-06
Iter: 11 loss: 9.72773364e-07
Iter: 12 loss: 9.34010814e-07
Iter: 13 loss: 8.82413644e-07
Iter: 14 loss: 1.35249047e-06
Iter: 15 loss: 8.80082325e-07
Iter: 16 loss: 8.55493056e-07
Iter: 17 loss: 8.55469409e-07
Iter: 18 loss: 8.48103582e-07
Iter: 19 loss: 8.29518967e-07
Iter: 20 loss: 9.98212613e-07
Iter: 21 loss: 8.26706298e-07
Iter: 22 loss: 8.25742177e-07
Iter: 23 loss: 8.18799379e-07
Iter: 24 loss: 8.11498808e-07
Iter: 25 loss: 8.05826119e-07
Iter: 26 loss: 8.0353351e-07
Iter: 27 loss: 7.94407242e-07
Iter: 28 loss: 7.87192448e-07
Iter: 29 loss: 7.84398594e-07
Iter: 30 loss: 7.71863938e-07
Iter: 31 loss: 8.16644501e-07
Iter: 32 loss: 7.68696395e-07
Iter: 33 loss: 7.55143788e-07
Iter: 34 loss: 7.77505761e-07
Iter: 35 loss: 7.489827e-07
Iter: 36 loss: 7.48908462e-07
Iter: 37 loss: 7.42414045e-07
Iter: 38 loss: 7.39190909e-07
Iter: 39 loss: 7.33759805e-07
Iter: 40 loss: 7.33715751e-07
Iter: 41 loss: 7.28999396e-07
Iter: 42 loss: 7.98566646e-07
Iter: 43 loss: 7.28982343e-07
Iter: 44 loss: 7.24350741e-07
Iter: 45 loss: 7.21786137e-07
Iter: 46 loss: 7.19719537e-07
Iter: 47 loss: 7.16089858e-07
Iter: 48 loss: 7.29285716e-07
Iter: 49 loss: 7.15154442e-07
Iter: 50 loss: 7.1015404e-07
Iter: 51 loss: 7.2292903e-07
Iter: 52 loss: 7.0847733e-07
Iter: 53 loss: 7.05981961e-07
Iter: 54 loss: 7.06890887e-07
Iter: 55 loss: 7.04214301e-07
Iter: 56 loss: 7.0319129e-07
Iter: 57 loss: 7.02909233e-07
Iter: 58 loss: 7.01667886e-07
Iter: 59 loss: 6.99204236e-07
Iter: 60 loss: 7.52439405e-07
Iter: 61 loss: 6.99169959e-07
Iter: 62 loss: 6.97666508e-07
Iter: 63 loss: 7.05353841e-07
Iter: 64 loss: 6.97439418e-07
Iter: 65 loss: 6.96146571e-07
Iter: 66 loss: 6.94355379e-07
Iter: 67 loss: 6.94304333e-07
Iter: 68 loss: 6.91668617e-07
Iter: 69 loss: 7.11898281e-07
Iter: 70 loss: 6.91461423e-07
Iter: 71 loss: 6.89959904e-07
Iter: 72 loss: 6.89877254e-07
Iter: 73 loss: 6.88636931e-07
Iter: 74 loss: 6.85355246e-07
Iter: 75 loss: 7.12287488e-07
Iter: 76 loss: 6.84750376e-07
Iter: 77 loss: 6.83567919e-07
Iter: 78 loss: 6.82783252e-07
Iter: 79 loss: 6.81239158e-07
Iter: 80 loss: 6.79036248e-07
Iter: 81 loss: 6.7898975e-07
Iter: 82 loss: 6.76258196e-07
Iter: 83 loss: 6.80554e-07
Iter: 84 loss: 6.75008039e-07
Iter: 85 loss: 6.71252167e-07
Iter: 86 loss: 6.96444545e-07
Iter: 87 loss: 6.70900931e-07
Iter: 88 loss: 6.69703e-07
Iter: 89 loss: 6.68325242e-07
Iter: 90 loss: 6.68163e-07
Iter: 91 loss: 6.66163828e-07
Iter: 92 loss: 6.69326312e-07
Iter: 93 loss: 6.65207835e-07
Iter: 94 loss: 6.65292873e-07
Iter: 95 loss: 6.64318463e-07
Iter: 96 loss: 6.63712285e-07
Iter: 97 loss: 6.6196742e-07
Iter: 98 loss: 6.6936957e-07
Iter: 99 loss: 6.61352885e-07
Iter: 100 loss: 6.58807949e-07
Iter: 101 loss: 6.67491065e-07
Iter: 102 loss: 6.58136173e-07
Iter: 103 loss: 6.56427403e-07
Iter: 104 loss: 6.58997351e-07
Iter: 105 loss: 6.55598512e-07
Iter: 106 loss: 6.54405426e-07
Iter: 107 loss: 6.54339601e-07
Iter: 108 loss: 6.53234906e-07
Iter: 109 loss: 6.61031777e-07
Iter: 110 loss: 6.5314407e-07
Iter: 111 loss: 6.52653853e-07
Iter: 112 loss: 6.5216193e-07
Iter: 113 loss: 6.52045287e-07
Iter: 114 loss: 6.51284779e-07
Iter: 115 loss: 6.51299388e-07
Iter: 116 loss: 6.50940365e-07
Iter: 117 loss: 6.50138361e-07
Iter: 118 loss: 6.60947592e-07
Iter: 119 loss: 6.5010056e-07
Iter: 120 loss: 6.4944129e-07
Iter: 121 loss: 6.49443678e-07
Iter: 122 loss: 6.48741604e-07
Iter: 123 loss: 6.47427385e-07
Iter: 124 loss: 6.78271931e-07
Iter: 125 loss: 6.47427726e-07
Iter: 126 loss: 6.46437456e-07
Iter: 127 loss: 6.47868205e-07
Iter: 128 loss: 6.4590057e-07
Iter: 129 loss: 6.44459135e-07
Iter: 130 loss: 6.48005312e-07
Iter: 131 loss: 6.43965e-07
Iter: 132 loss: 6.43293333e-07
Iter: 133 loss: 6.43089265e-07
Iter: 134 loss: 6.4271677e-07
Iter: 135 loss: 6.4185167e-07
Iter: 136 loss: 6.53111e-07
Iter: 137 loss: 6.4177982e-07
Iter: 138 loss: 6.40731855e-07
Iter: 139 loss: 6.40737198e-07
Iter: 140 loss: 6.4015893e-07
Iter: 141 loss: 6.40140968e-07
Iter: 142 loss: 6.39846121e-07
Iter: 143 loss: 6.39411383e-07
Iter: 144 loss: 6.39417067e-07
Iter: 145 loss: 6.38956749e-07
Iter: 146 loss: 6.41016754e-07
Iter: 147 loss: 6.38859433e-07
Iter: 148 loss: 6.382067e-07
Iter: 149 loss: 6.39254665e-07
Iter: 150 loss: 6.37891162e-07
Iter: 151 loss: 6.37511107e-07
Iter: 152 loss: 6.37889798e-07
Iter: 153 loss: 6.37312e-07
Iter: 154 loss: 6.36982065e-07
Iter: 155 loss: 6.42223881e-07
Iter: 156 loss: 6.36966e-07
Iter: 157 loss: 6.36669824e-07
Iter: 158 loss: 6.35877313e-07
Iter: 159 loss: 6.42601208e-07
Iter: 160 loss: 6.35741515e-07
Iter: 161 loss: 6.34984417e-07
Iter: 162 loss: 6.38935603e-07
Iter: 163 loss: 6.3484174e-07
Iter: 164 loss: 6.34295247e-07
Iter: 165 loss: 6.4028643e-07
Iter: 166 loss: 6.34282799e-07
Iter: 167 loss: 6.33585444e-07
Iter: 168 loss: 6.33621937e-07
Iter: 169 loss: 6.33071693e-07
Iter: 170 loss: 6.32531169e-07
Iter: 171 loss: 6.32402589e-07
Iter: 172 loss: 6.32074091e-07
Iter: 173 loss: 6.31499e-07
Iter: 174 loss: 6.31516968e-07
Iter: 175 loss: 6.31105308e-07
Iter: 176 loss: 6.34239143e-07
Iter: 177 loss: 6.31072169e-07
Iter: 178 loss: 6.3090539e-07
Iter: 179 loss: 6.30469799e-07
Iter: 180 loss: 6.37560447e-07
Iter: 181 loss: 6.3047969e-07
Iter: 182 loss: 6.30184672e-07
Iter: 183 loss: 6.30142779e-07
Iter: 184 loss: 6.29911369e-07
Iter: 185 loss: 6.29846227e-07
Iter: 186 loss: 6.2974533e-07
Iter: 187 loss: 6.29576277e-07
Iter: 188 loss: 6.30306886e-07
Iter: 189 loss: 6.29533531e-07
Iter: 190 loss: 6.29260853e-07
Iter: 191 loss: 6.2925767e-07
Iter: 192 loss: 6.2906679e-07
Iter: 193 loss: 6.28804173e-07
Iter: 194 loss: 6.28961175e-07
Iter: 195 loss: 6.28618295e-07
Iter: 196 loss: 6.28411669e-07
Iter: 197 loss: 6.29074862e-07
Iter: 198 loss: 6.28337716e-07
Iter: 199 loss: 6.28047701e-07
Iter: 200 loss: 6.29459691e-07
Iter: 201 loss: 6.2800666e-07
Iter: 202 loss: 6.27744612e-07
Iter: 203 loss: 6.2748785e-07
Iter: 204 loss: 6.27445843e-07
Iter: 205 loss: 6.27140651e-07
Iter: 206 loss: 6.27213694e-07
Iter: 207 loss: 6.26918961e-07
Iter: 208 loss: 6.26643555e-07
Iter: 209 loss: 6.266215e-07
Iter: 210 loss: 6.26393216e-07
Iter: 211 loss: 6.26188239e-07
Iter: 212 loss: 6.26091378e-07
Iter: 213 loss: 6.25911809e-07
Iter: 214 loss: 6.27969484e-07
Iter: 215 loss: 6.2590243e-07
Iter: 216 loss: 6.25713255e-07
Iter: 217 loss: 6.25524308e-07
Iter: 218 loss: 6.25468942e-07
Iter: 219 loss: 6.25168354e-07
Iter: 220 loss: 6.25219172e-07
Iter: 221 loss: 6.24962581e-07
Iter: 222 loss: 6.24767608e-07
Iter: 223 loss: 6.24753795e-07
Iter: 224 loss: 6.24522727e-07
Iter: 225 loss: 6.24073664e-07
Iter: 226 loss: 6.32988133e-07
Iter: 227 loss: 6.24087306e-07
Iter: 228 loss: 6.23681e-07
Iter: 229 loss: 6.25247822e-07
Iter: 230 loss: 6.2357276e-07
Iter: 231 loss: 6.23241817e-07
Iter: 232 loss: 6.24618735e-07
Iter: 233 loss: 6.23178835e-07
Iter: 234 loss: 6.22661958e-07
Iter: 235 loss: 6.23265919e-07
Iter: 236 loss: 6.22410198e-07
Iter: 237 loss: 6.21968923e-07
Iter: 238 loss: 6.21490585e-07
Iter: 239 loss: 6.21469383e-07
Iter: 240 loss: 6.20792207e-07
Iter: 241 loss: 6.23194e-07
Iter: 242 loss: 6.20659591e-07
Iter: 243 loss: 6.20659534e-07
Iter: 244 loss: 6.20445462e-07
Iter: 245 loss: 6.20300625e-07
Iter: 246 loss: 6.19970933e-07
Iter: 247 loss: 6.23804567e-07
Iter: 248 loss: 6.19947855e-07
Iter: 249 loss: 6.19802449e-07
Iter: 250 loss: 6.19788409e-07
Iter: 251 loss: 6.19624416e-07
Iter: 252 loss: 6.19471621e-07
Iter: 253 loss: 6.1945e-07
Iter: 254 loss: 6.19286652e-07
Iter: 255 loss: 6.19364414e-07
Iter: 256 loss: 6.1919e-07
Iter: 257 loss: 6.18995159e-07
Iter: 258 loss: 6.19030288e-07
Iter: 259 loss: 6.18914157e-07
Iter: 260 loss: 6.18778586e-07
Iter: 261 loss: 6.187596e-07
Iter: 262 loss: 6.18532283e-07
Iter: 263 loss: 6.18299055e-07
Iter: 264 loss: 6.18291324e-07
Iter: 265 loss: 6.17917863e-07
Iter: 266 loss: 6.23143421e-07
Iter: 267 loss: 6.17901719e-07
Iter: 268 loss: 6.17601074e-07
Iter: 269 loss: 6.17322598e-07
Iter: 270 loss: 6.17242677e-07
Iter: 271 loss: 6.16988245e-07
Iter: 272 loss: 6.16695104e-07
Iter: 273 loss: 6.16622344e-07
Iter: 274 loss: 6.16357113e-07
Iter: 275 loss: 6.19773346e-07
Iter: 276 loss: 6.16355521e-07
Iter: 277 loss: 6.16073862e-07
Iter: 278 loss: 6.17703222e-07
Iter: 279 loss: 6.1605715e-07
Iter: 280 loss: 6.15925444e-07
Iter: 281 loss: 6.15683348e-07
Iter: 282 loss: 6.15679e-07
Iter: 283 loss: 6.15648219e-07
Iter: 284 loss: 6.15571082e-07
Iter: 285 loss: 6.15496106e-07
Iter: 286 loss: 6.15378099e-07
Iter: 287 loss: 6.15326599e-07
Iter: 288 loss: 6.15192334e-07
Iter: 289 loss: 6.15003216e-07
Iter: 290 loss: 6.14995486e-07
Iter: 291 loss: 6.14714168e-07
Iter: 292 loss: 6.16418447e-07
Iter: 293 loss: 6.14673922e-07
Iter: 294 loss: 6.14485771e-07
Iter: 295 loss: 6.17552814e-07
Iter: 296 loss: 6.1449208e-07
Iter: 297 loss: 6.14347869e-07
Iter: 298 loss: 6.1409844e-07
Iter: 299 loss: 6.14083319e-07
Iter: 300 loss: 6.13907105e-07
Iter: 301 loss: 6.15057047e-07
Iter: 302 loss: 6.13865097e-07
Iter: 303 loss: 6.13632039e-07
Iter: 304 loss: 6.14811484e-07
Iter: 305 loss: 6.13567408e-07
Iter: 306 loss: 6.13400857e-07
Iter: 307 loss: 6.13221573e-07
Iter: 308 loss: 6.13183829e-07
Iter: 309 loss: 6.12990561e-07
Iter: 310 loss: 6.12986582e-07
Iter: 311 loss: 6.12774215e-07
Iter: 312 loss: 6.12599933e-07
Iter: 313 loss: 6.12580493e-07
Iter: 314 loss: 6.12238864e-07
Iter: 315 loss: 6.12414397e-07
Iter: 316 loss: 6.12047245e-07
Iter: 317 loss: 6.12060944e-07
Iter: 318 loss: 6.11913094e-07
Iter: 319 loss: 6.11837095e-07
Iter: 320 loss: 6.11650194e-07
Iter: 321 loss: 6.14474175e-07
Iter: 322 loss: 6.11581356e-07
Iter: 323 loss: 6.11387e-07
Iter: 324 loss: 6.11926907e-07
Iter: 325 loss: 6.11339317e-07
Iter: 326 loss: 6.11254e-07
Iter: 327 loss: 6.11233e-07
Iter: 328 loss: 6.11157304e-07
Iter: 329 loss: 6.1121375e-07
Iter: 330 loss: 6.11110522e-07
Iter: 331 loss: 6.11013434e-07
Iter: 332 loss: 6.1093948e-07
Iter: 333 loss: 6.10910092e-07
Iter: 334 loss: 6.10811924e-07
Iter: 335 loss: 6.10808058e-07
Iter: 336 loss: 6.10705854e-07
Iter: 337 loss: 6.10581196e-07
Iter: 338 loss: 6.10591087e-07
Iter: 339 loss: 6.10399127e-07
Iter: 340 loss: 6.11290716e-07
Iter: 341 loss: 6.1037241e-07
Iter: 342 loss: 6.10204e-07
Iter: 343 loss: 6.11636437e-07
Iter: 344 loss: 6.10211487e-07
Iter: 345 loss: 6.10136226e-07
Iter: 346 loss: 6.09960921e-07
Iter: 347 loss: 6.12492727e-07
Iter: 348 loss: 6.09990536e-07
Iter: 349 loss: 6.09774361e-07
Iter: 350 loss: 6.11348355e-07
Iter: 351 loss: 6.09756057e-07
Iter: 352 loss: 6.09560345e-07
Iter: 353 loss: 6.10919074e-07
Iter: 354 loss: 6.09543633e-07
Iter: 355 loss: 6.09458652e-07
Iter: 356 loss: 6.09365e-07
Iter: 357 loss: 6.09348092e-07
Iter: 358 loss: 6.09233609e-07
Iter: 359 loss: 6.09451433e-07
Iter: 360 loss: 6.09161589e-07
Iter: 361 loss: 6.09174833e-07
Iter: 362 loss: 6.09111453e-07
Iter: 363 loss: 6.09054268e-07
Iter: 364 loss: 6.08951382e-07
Iter: 365 loss: 6.10771963e-07
Iter: 366 loss: 6.08931714e-07
Iter: 367 loss: 6.08855089e-07
Iter: 368 loss: 6.09737697e-07
Iter: 369 loss: 6.0884156e-07
Iter: 370 loss: 6.08763401e-07
Iter: 371 loss: 6.0943222e-07
Iter: 372 loss: 6.08773576e-07
Iter: 373 loss: 6.08694677e-07
Iter: 374 loss: 6.0863249e-07
Iter: 375 loss: 6.10867687e-07
Iter: 376 loss: 6.08641187e-07
Iter: 377 loss: 6.0856155e-07
Iter: 378 loss: 6.08542791e-07
Iter: 379 loss: 6.0849726e-07
Iter: 380 loss: 6.08466621e-07
Iter: 381 loss: 6.08445589e-07
Iter: 382 loss: 6.08378798e-07
Iter: 383 loss: 6.08304163e-07
Iter: 384 loss: 6.08292453e-07
Iter: 385 loss: 6.08210257e-07
Iter: 386 loss: 6.08212247e-07
Iter: 387 loss: 6.08149946e-07
Iter: 388 loss: 6.08114135e-07
Iter: 389 loss: 6.08063374e-07
Iter: 390 loss: 6.08028245e-07
Iter: 391 loss: 6.07890911e-07
Iter: 392 loss: 6.07890797e-07
Iter: 393 loss: 6.07774837e-07
Iter: 394 loss: 6.09334961e-07
Iter: 395 loss: 6.0775227e-07
Iter: 396 loss: 6.07673087e-07
Iter: 397 loss: 6.07826337e-07
Iter: 398 loss: 6.07619427e-07
Iter: 399 loss: 6.07531661e-07
Iter: 400 loss: 6.07402171e-07
Iter: 401 loss: 6.07368747e-07
Iter: 402 loss: 6.07252332e-07
Iter: 403 loss: 6.08503569e-07
Iter: 404 loss: 6.07231e-07
Iter: 405 loss: 6.07138588e-07
Iter: 406 loss: 6.0846105e-07
Iter: 407 loss: 6.07115e-07
Iter: 408 loss: 6.07057e-07
Iter: 409 loss: 6.0708328e-07
Iter: 410 loss: 6.06980507e-07
Iter: 411 loss: 6.06877052e-07
Iter: 412 loss: 6.06918604e-07
Iter: 413 loss: 6.06804349e-07
Iter: 414 loss: 6.06658887e-07
Iter: 415 loss: 6.08587584e-07
Iter: 416 loss: 6.06678441e-07
Iter: 417 loss: 6.06586127e-07
Iter: 418 loss: 6.06366768e-07
Iter: 419 loss: 6.08448204e-07
Iter: 420 loss: 6.06346e-07
Iter: 421 loss: 6.06279798e-07
Iter: 422 loss: 6.0623637e-07
Iter: 423 loss: 6.06141327e-07
Iter: 424 loss: 6.06090339e-07
Iter: 425 loss: 6.06016442e-07
Iter: 426 loss: 6.05917421e-07
Iter: 427 loss: 6.0627724e-07
Iter: 428 loss: 6.05867854e-07
Iter: 429 loss: 6.05770651e-07
Iter: 430 loss: 6.06558331e-07
Iter: 431 loss: 6.05771334e-07
Iter: 432 loss: 6.05668788e-07
Iter: 433 loss: 6.05499054e-07
Iter: 434 loss: 6.08554842e-07
Iter: 435 loss: 6.0552884e-07
Iter: 436 loss: 6.05377579e-07
Iter: 437 loss: 6.05975401e-07
Iter: 438 loss: 6.05373828e-07
Iter: 439 loss: 6.05242121e-07
Iter: 440 loss: 6.0496518e-07
Iter: 441 loss: 6.09762083e-07
Iter: 442 loss: 6.0494807e-07
Iter: 443 loss: 6.04683692e-07
Iter: 444 loss: 6.04704667e-07
Iter: 445 loss: 6.0454704e-07
Iter: 446 loss: 6.06228696e-07
Iter: 447 loss: 6.04529532e-07
Iter: 448 loss: 6.04414e-07
Iter: 449 loss: 6.0403886e-07
Iter: 450 loss: 6.05792252e-07
Iter: 451 loss: 6.03958e-07
Iter: 452 loss: 6.03979174e-07
Iter: 453 loss: 6.03799947e-07
Iter: 454 loss: 6.03633623e-07
Iter: 455 loss: 6.03562057e-07
Iter: 456 loss: 6.03481453e-07
Iter: 457 loss: 6.03376861e-07
Iter: 458 loss: 6.03569674e-07
Iter: 459 loss: 6.03267836e-07
Iter: 460 loss: 6.03108219e-07
Iter: 461 loss: 6.05292712e-07
Iter: 462 loss: 6.03151193e-07
Iter: 463 loss: 6.03084573e-07
Iter: 464 loss: 6.03009084e-07
Iter: 465 loss: 6.03017156e-07
Iter: 466 loss: 6.02878799e-07
Iter: 467 loss: 6.02895796e-07
Iter: 468 loss: 6.02846853e-07
Iter: 469 loss: 6.02712703e-07
Iter: 470 loss: 6.03931653e-07
Iter: 471 loss: 6.0268917e-07
Iter: 472 loss: 6.02629882e-07
Iter: 473 loss: 6.03309218e-07
Iter: 474 loss: 6.02615614e-07
Iter: 475 loss: 6.02547289e-07
Iter: 476 loss: 6.02392504e-07
Iter: 477 loss: 6.02378691e-07
Iter: 478 loss: 6.02276032e-07
Iter: 479 loss: 6.02304112e-07
Iter: 480 loss: 6.02173884e-07
Iter: 481 loss: 6.02155296e-07
Iter: 482 loss: 6.02077705e-07
Iter: 483 loss: 6.01921101e-07
Iter: 484 loss: 6.01653824e-07
Iter: 485 loss: 6.01670763e-07
Iter: 486 loss: 6.01868464e-07
Iter: 487 loss: 6.01554e-07
Iter: 488 loss: 6.01478689e-07
Iter: 489 loss: 6.01368356e-07
Iter: 490 loss: 6.03307342e-07
Iter: 491 loss: 6.01320039e-07
Iter: 492 loss: 6.01123588e-07
Iter: 493 loss: 6.00986311e-07
Iter: 494 loss: 6.0094203e-07
Iter: 495 loss: 6.0100092e-07
Iter: 496 loss: 6.00843919e-07
Iter: 497 loss: 6.00768544e-07
Iter: 498 loss: 6.00689532e-07
Iter: 499 loss: 6.00666453e-07
Iter: 500 loss: 6.00568569e-07
Iter: 501 loss: 6.00624844e-07
Iter: 502 loss: 6.0050229e-07
Iter: 503 loss: 6.00453802e-07
Iter: 504 loss: 6.01142631e-07
Iter: 505 loss: 6.00463522e-07
Iter: 506 loss: 6.00379735e-07
Iter: 507 loss: 6.00481826e-07
Iter: 508 loss: 6.00347505e-07
Iter: 509 loss: 6.00282647e-07
Iter: 510 loss: 6.00236262e-07
Iter: 511 loss: 6.0020227e-07
Iter: 512 loss: 6.00109956e-07
Iter: 513 loss: 6.00100577e-07
Iter: 514 loss: 6.00043677e-07
Iter: 515 loss: 5.99906684e-07
Iter: 516 loss: 6.01792124e-07
Iter: 517 loss: 5.99911687e-07
Iter: 518 loss: 5.99695056e-07
Iter: 519 loss: 6.00065562e-07
Iter: 520 loss: 5.99565567e-07
Iter: 521 loss: 5.9943136e-07
Iter: 522 loss: 5.99393957e-07
Iter: 523 loss: 5.99347061e-07
Iter: 524 loss: 5.99088821e-07
Iter: 525 loss: 6.00334886e-07
Iter: 526 loss: 5.99037662e-07
Iter: 527 loss: 5.98854456e-07
Iter: 528 loss: 6.01302588e-07
Iter: 529 loss: 5.98849624e-07
Iter: 530 loss: 5.98750205e-07
Iter: 531 loss: 5.99005716e-07
Iter: 532 loss: 5.98672102e-07
Iter: 533 loss: 5.9860929e-07
Iter: 534 loss: 5.98590304e-07
Iter: 535 loss: 5.98545398e-07
Iter: 536 loss: 5.98468546e-07
Iter: 537 loss: 6.00165549e-07
Iter: 538 loss: 5.98484689e-07
Iter: 539 loss: 5.98432791e-07
Iter: 540 loss: 5.99184546e-07
Iter: 541 loss: 5.984366e-07
Iter: 542 loss: 5.98313306e-07
Iter: 543 loss: 5.98366228e-07
Iter: 544 loss: 5.98239694e-07
Iter: 545 loss: 5.98191718e-07
Iter: 546 loss: 5.98173472e-07
Iter: 547 loss: 5.98098666e-07
Iter: 548 loss: 5.9796e-07
Iter: 549 loss: 5.98017436e-07
Iter: 550 loss: 5.97902329e-07
Iter: 551 loss: 5.97881751e-07
Iter: 552 loss: 5.97800351e-07
Iter: 553 loss: 5.97791939e-07
Iter: 554 loss: 5.97662506e-07
Iter: 555 loss: 5.99392e-07
Iter: 556 loss: 5.97670351e-07
Iter: 557 loss: 5.97584631e-07
Iter: 558 loss: 5.98753559e-07
Iter: 559 loss: 5.97536712e-07
Iter: 560 loss: 5.9746867e-07
Iter: 561 loss: 5.97333042e-07
Iter: 562 loss: 5.97335088e-07
Iter: 563 loss: 5.97195e-07
Iter: 564 loss: 5.97055475e-07
Iter: 565 loss: 5.97033136e-07
Iter: 566 loss: 5.96942868e-07
Iter: 567 loss: 5.969207e-07
Iter: 568 loss: 5.96807695e-07
Iter: 569 loss: 5.96818666e-07
Iter: 570 loss: 5.96728739e-07
Iter: 571 loss: 5.96607265e-07
Iter: 572 loss: 5.96613859e-07
Iter: 573 loss: 5.96512791e-07
Iter: 574 loss: 5.96469761e-07
Iter: 575 loss: 5.96422e-07
Iter: 576 loss: 5.96335667e-07
Iter: 577 loss: 5.96263e-07
Iter: 578 loss: 5.96235338e-07
Iter: 579 loss: 5.96149903e-07
Iter: 580 loss: 5.96108066e-07
Iter: 581 loss: 5.96043435e-07
Iter: 582 loss: 5.95938445e-07
Iter: 583 loss: 5.97369706e-07
Iter: 584 loss: 5.95946346e-07
Iter: 585 loss: 5.95853578e-07
Iter: 586 loss: 5.96068219e-07
Iter: 587 loss: 5.95826521e-07
Iter: 588 loss: 5.95742222e-07
Iter: 589 loss: 5.95836582e-07
Iter: 590 loss: 5.9570641e-07
Iter: 591 loss: 5.9559693e-07
Iter: 592 loss: 5.95591132e-07
Iter: 593 loss: 5.95554866e-07
Iter: 594 loss: 5.95483129e-07
Iter: 595 loss: 5.96435427e-07
Iter: 596 loss: 5.95460222e-07
Iter: 597 loss: 5.95394e-07
Iter: 598 loss: 5.96094878e-07
Iter: 599 loss: 5.95366089e-07
Iter: 600 loss: 5.95289862e-07
Iter: 601 loss: 5.96321058e-07
Iter: 602 loss: 5.95304414e-07
Iter: 603 loss: 5.9528054e-07
Iter: 604 loss: 5.9519175e-07
Iter: 605 loss: 5.95807705e-07
Iter: 606 loss: 5.95176402e-07
Iter: 607 loss: 5.95044696e-07
Iter: 608 loss: 5.9538263e-07
Iter: 609 loss: 5.95017e-07
Iter: 610 loss: 5.94981429e-07
Iter: 611 loss: 5.94973187e-07
Iter: 612 loss: 5.94933283e-07
Iter: 613 loss: 5.9471563e-07
Iter: 614 loss: 5.95692882e-07
Iter: 615 loss: 5.94686639e-07
Iter: 616 loss: 5.94467281e-07
Iter: 617 loss: 5.95797e-07
Iter: 618 loss: 5.9445739e-07
Iter: 619 loss: 5.94363314e-07
Iter: 620 loss: 5.95543099e-07
Iter: 621 loss: 5.94361609e-07
Iter: 622 loss: 5.94214498e-07
Iter: 623 loss: 5.94329094e-07
Iter: 624 loss: 5.94188464e-07
Iter: 625 loss: 5.94081484e-07
Iter: 626 loss: 5.94427433e-07
Iter: 627 loss: 5.94042035e-07
Iter: 628 loss: 5.9396433e-07
Iter: 629 loss: 5.95072606e-07
Iter: 630 loss: 5.9397928e-07
Iter: 631 loss: 5.93946595e-07
Iter: 632 loss: 5.9388168e-07
Iter: 633 loss: 5.94417656e-07
Iter: 634 loss: 5.93859454e-07
Iter: 635 loss: 5.93766458e-07
Iter: 636 loss: 5.94624794e-07
Iter: 637 loss: 5.93761456e-07
Iter: 638 loss: 5.9366e-07
Iter: 639 loss: 5.94276855e-07
Iter: 640 loss: 5.93640607e-07
Iter: 641 loss: 5.93640948e-07
Iter: 642 loss: 5.93560571e-07
Iter: 643 loss: 5.94695962e-07
Iter: 644 loss: 5.93518166e-07
Iter: 645 loss: 5.93425e-07
Iter: 646 loss: 5.94258552e-07
Iter: 647 loss: 5.93416871e-07
Iter: 648 loss: 5.93347636e-07
Iter: 649 loss: 5.94022708e-07
Iter: 650 loss: 5.93333539e-07
Iter: 651 loss: 5.93268169e-07
Iter: 652 loss: 5.93190521e-07
Iter: 653 loss: 5.94993594e-07
Iter: 654 loss: 5.93166305e-07
Iter: 655 loss: 5.93103e-07
Iter: 656 loss: 5.94035782e-07
Iter: 657 loss: 5.93041364e-07
Iter: 658 loss: 5.92972242e-07
Iter: 659 loss: 5.94140033e-07
Iter: 660 loss: 5.92965137e-07
Iter: 661 loss: 5.92899e-07
Iter: 662 loss: 5.92789888e-07
Iter: 663 loss: 5.95264794e-07
Iter: 664 loss: 5.92781419e-07
Iter: 665 loss: 5.92689616e-07
Iter: 666 loss: 5.92679442e-07
Iter: 667 loss: 5.92636354e-07
Iter: 668 loss: 5.92586503e-07
Iter: 669 loss: 5.92535116e-07
Iter: 670 loss: 5.92463266e-07
Iter: 671 loss: 5.9239494e-07
Iter: 672 loss: 5.92368451e-07
Iter: 673 loss: 5.92413471e-07
Iter: 674 loss: 5.92339916e-07
Iter: 675 loss: 5.92288586e-07
Iter: 676 loss: 5.92270396e-07
Iter: 677 loss: 5.92232254e-07
Iter: 678 loss: 5.92194169e-07
Iter: 679 loss: 5.92139543e-07
Iter: 680 loss: 5.92132722e-07
Iter: 681 loss: 5.92062406e-07
Iter: 682 loss: 5.92035519e-07
Iter: 683 loss: 5.9197248e-07
Iter: 684 loss: 5.92101173e-07
Iter: 685 loss: 5.9194781e-07
Iter: 686 loss: 5.91891308e-07
Iter: 687 loss: 5.91764206e-07
Iter: 688 loss: 5.91764092e-07
Iter: 689 loss: 5.91654498e-07
Iter: 690 loss: 5.9265767e-07
Iter: 691 loss: 5.91632556e-07
Iter: 692 loss: 5.91608455e-07
Iter: 693 loss: 5.91599132e-07
Iter: 694 loss: 5.91556045e-07
Iter: 695 loss: 5.91431046e-07
Iter: 696 loss: 5.93663799e-07
Iter: 697 loss: 5.9145151e-07
Iter: 698 loss: 5.91444632e-07
Iter: 699 loss: 5.91388243e-07
Iter: 700 loss: 5.91382445e-07
Iter: 701 loss: 5.91331741e-07
Iter: 702 loss: 5.91366586e-07
Iter: 703 loss: 5.91306446e-07
Iter: 704 loss: 5.91248693e-07
Iter: 705 loss: 5.91250057e-07
Iter: 706 loss: 5.91200319e-07
Iter: 707 loss: 5.91997264e-07
Iter: 708 loss: 5.91199239e-07
Iter: 709 loss: 5.91132107e-07
Iter: 710 loss: 5.91342882e-07
Iter: 711 loss: 5.91136427e-07
Iter: 712 loss: 5.91080152e-07
Iter: 713 loss: 5.90972661e-07
Iter: 714 loss: 5.92774654e-07
Iter: 715 loss: 5.91012281e-07
Iter: 716 loss: 5.90942e-07
Iter: 717 loss: 5.90924174e-07
Iter: 718 loss: 5.90875061e-07
Iter: 719 loss: 5.90921047e-07
Iter: 720 loss: 5.90849424e-07
Iter: 721 loss: 5.90781099e-07
Iter: 722 loss: 5.90732895e-07
Iter: 723 loss: 5.90654906e-07
Iter: 724 loss: 5.90657e-07
Iter: 725 loss: 5.90653826e-07
Iter: 726 loss: 5.90634954e-07
Iter: 727 loss: 5.906561e-07
Iter: 728 loss: 5.90638479e-07
Iter: 729 loss: 5.9066673e-07
Iter: 730 loss: 5.906561e-07
Iter: 731 loss: 5.90637228e-07
Iter: 732 loss: 5.90648142e-07
Iter: 733 loss: 5.90645755e-07
Iter: 734 loss: 5.90639502e-07
Iter: 735 loss: 5.90644277e-07
Iter: 736 loss: 5.9063791e-07
Iter: 737 loss: 5.90642117e-07
Iter: 738 loss: 5.90647403e-07
Iter: 739 loss: 5.90654565e-07
Iter: 740 loss: 5.9065303e-07
Iter: 741 loss: 5.90652803e-07
Iter: 742 loss: 5.90653485e-07
Iter: 743 loss: 5.90656271e-07
Iter: 744 loss: 5.90656271e-07
Iter: 745 loss: 5.90654281e-07
Iter: 746 loss: 5.90656612e-07
Iter: 747 loss: 5.90656555e-07
Iter: 748 loss: 5.90654281e-07
Iter: 749 loss: 5.90656555e-07
Iter: 750 loss: 5.90570096e-07
Iter: 751 loss: 5.90711124e-07
Iter: 752 loss: 5.90561285e-07
Iter: 753 loss: 5.90518653e-07
Iter: 754 loss: 5.91118749e-07
Iter: 755 loss: 5.90522234e-07
Iter: 756 loss: 5.90456352e-07
Iter: 757 loss: 5.90727211e-07
Iter: 758 loss: 5.90444472e-07
Iter: 759 loss: 5.90436571e-07
Iter: 760 loss: 5.90373361e-07
Iter: 761 loss: 5.91080436e-07
Iter: 762 loss: 5.90378e-07
Iter: 763 loss: 5.90281047e-07
Iter: 764 loss: 5.90711068e-07
Iter: 765 loss: 5.90286163e-07
Iter: 766 loss: 5.90267177e-07
Iter: 767 loss: 5.90268542e-07
Iter: 768 loss: 5.90161108e-07
Iter: 769 loss: 5.90184811e-07
Iter: 770 loss: 5.90193622e-07
Iter: 771 loss: 5.9015224e-07
Iter: 772 loss: 5.90122227e-07
Iter: 773 loss: 5.9008795e-07
Iter: 774 loss: 5.90016384e-07
Iter: 775 loss: 5.90620743e-07
Iter: 776 loss: 5.90034745e-07
Iter: 777 loss: 5.89946126e-07
Iter: 778 loss: 5.8990679e-07
Iter: 779 loss: 5.89880415e-07
Iter: 780 loss: 5.89832268e-07
Iter: 781 loss: 5.89920546e-07
Iter: 782 loss: 5.89788954e-07
Iter: 783 loss: 5.89741205e-07
Iter: 784 loss: 5.90566628e-07
Iter: 785 loss: 5.8975354e-07
Iter: 786 loss: 5.89661909e-07
Iter: 787 loss: 5.894791e-07
Iter: 788 loss: 5.90273e-07
Iter: 789 loss: 5.89445847e-07
Iter: 790 loss: 5.89584033e-07
Iter: 791 loss: 5.89403498e-07
Iter: 792 loss: 5.89346769e-07
Iter: 793 loss: 5.89271849e-07
Iter: 794 loss: 5.89271167e-07
Iter: 795 loss: 5.89189085e-07
Iter: 796 loss: 5.89122806e-07
Iter: 797 loss: 5.89109504e-07
Iter: 798 loss: 5.89052e-07
Iter: 799 loss: 5.89581475e-07
Iter: 800 loss: 5.89044362e-07
Iter: 801 loss: 5.88997125e-07
Iter: 802 loss: 5.88996272e-07
Iter: 803 loss: 5.8896228e-07
Iter: 804 loss: 5.88873206e-07
Iter: 805 loss: 5.88878322e-07
Iter: 806 loss: 5.8883478e-07
Iter: 807 loss: 5.88784133e-07
Iter: 808 loss: 5.88836542e-07
Iter: 809 loss: 5.88742182e-07
Iter: 810 loss: 5.88715636e-07
Iter: 811 loss: 5.88691194e-07
Iter: 812 loss: 5.8863634e-07
Iter: 813 loss: 5.88593e-07
Iter: 814 loss: 5.88599278e-07
Iter: 815 loss: 5.88534817e-07
Iter: 816 loss: 5.8875753e-07
Iter: 817 loss: 5.88473085e-07
Iter: 818 loss: 5.88386797e-07
Iter: 819 loss: 5.8841988e-07
Iter: 820 loss: 5.88295848e-07
Iter: 821 loss: 5.88240368e-07
Iter: 822 loss: 5.88567559e-07
Iter: 823 loss: 5.88219393e-07
Iter: 824 loss: 5.88138846e-07
Iter: 825 loss: 5.88100193e-07
Iter: 826 loss: 5.88089108e-07
Iter: 827 loss: 5.8801777e-07
Iter: 828 loss: 5.88020157e-07
Iter: 829 loss: 5.87981788e-07
Iter: 830 loss: 5.87850082e-07
Iter: 831 loss: 5.89804358e-07
Iter: 832 loss: 5.87854629e-07
Iter: 833 loss: 5.87772547e-07
Iter: 834 loss: 5.8843807e-07
Iter: 835 loss: 5.87789714e-07
Iter: 836 loss: 5.87681654e-07
Iter: 837 loss: 5.87770785e-07
Iter: 838 loss: 5.87639363e-07
Iter: 839 loss: 5.87553245e-07
Iter: 840 loss: 5.87725424e-07
Iter: 841 loss: 5.87538125e-07
Iter: 842 loss: 5.87438194e-07
Iter: 843 loss: 5.87539205e-07
Iter: 844 loss: 5.87418754e-07
Iter: 845 loss: 5.87265845e-07
Iter: 846 loss: 5.87748616e-07
Iter: 847 loss: 5.87238219e-07
Iter: 848 loss: 5.87180239e-07
Iter: 849 loss: 5.87696604e-07
Iter: 850 loss: 5.87148406e-07
Iter: 851 loss: 5.87128284e-07
Iter: 852 loss: 5.87292561e-07
Iter: 853 loss: 5.87095e-07
Iter: 854 loss: 5.87068e-07
Iter: 855 loss: 5.87004479e-07
Iter: 856 loss: 5.87027671e-07
Iter: 857 loss: 5.86970202e-07
Iter: 858 loss: 5.87262662e-07
Iter: 859 loss: 5.8692e-07
Iter: 860 loss: 5.86868623e-07
Iter: 861 loss: 5.86885335e-07
Iter: 862 loss: 5.86850092e-07
Iter: 863 loss: 5.86801434e-07
Iter: 864 loss: 5.86792453e-07
Iter: 865 loss: 5.86719352e-07
Iter: 866 loss: 5.86886244e-07
Iter: 867 loss: 5.86702299e-07
Iter: 868 loss: 5.86597139e-07
Iter: 869 loss: 5.8722037e-07
Iter: 870 loss: 5.86606461e-07
Iter: 871 loss: 5.86583496e-07
Iter: 872 loss: 5.86486465e-07
Iter: 873 loss: 5.88043861e-07
Iter: 874 loss: 5.86490557e-07
Iter: 875 loss: 5.86388524e-07
Iter: 876 loss: 5.87729801e-07
Iter: 877 loss: 5.86369936e-07
Iter: 878 loss: 5.86287456e-07
Iter: 879 loss: 5.86799047e-07
Iter: 880 loss: 5.86306726e-07
Iter: 881 loss: 5.86230499e-07
Iter: 882 loss: 5.86318e-07
Iter: 883 loss: 5.86224701e-07
Iter: 884 loss: 5.86174565e-07
Iter: 885 loss: 5.86266538e-07
Iter: 886 loss: 5.86106182e-07
Iter: 887 loss: 5.86055364e-07
Iter: 888 loss: 5.861246e-07
Iter: 889 loss: 5.86038311e-07
Iter: 890 loss: 5.85976522e-07
Iter: 891 loss: 5.86024726e-07
Iter: 892 loss: 5.85943042e-07
Iter: 893 loss: 5.85870453e-07
Iter: 894 loss: 5.86451222e-07
Iter: 895 loss: 5.85876592e-07
Iter: 896 loss: 5.85835608e-07
Iter: 897 loss: 5.86354e-07
Iter: 898 loss: 5.85824807e-07
Iter: 899 loss: 5.85770806e-07
Iter: 900 loss: 5.85760631e-07
Iter: 901 loss: 5.86283704e-07
Iter: 902 loss: 5.85746307e-07
Iter: 903 loss: 5.85703901e-07
Iter: 904 loss: 5.85717373e-07
Iter: 905 loss: 5.85690259e-07
Iter: 906 loss: 5.85627959e-07
Iter: 907 loss: 5.85642397e-07
Iter: 908 loss: 5.8557896e-07
Iter: 909 loss: 5.85667806e-07
Iter: 910 loss: 5.85564635e-07
Iter: 911 loss: 5.85502e-07
Iter: 912 loss: 5.85599935e-07
Iter: 913 loss: 5.85462431e-07
Iter: 914 loss: 5.85397856e-07
Iter: 915 loss: 5.85544626e-07
Iter: 916 loss: 5.85393309e-07
Iter: 917 loss: 5.85340331e-07
Iter: 918 loss: 5.85612611e-07
Iter: 919 loss: 5.853164e-07
Iter: 920 loss: 5.85276837e-07
Iter: 921 loss: 5.85289058e-07
Iter: 922 loss: 5.85204305e-07
Iter: 923 loss: 5.85142402e-07
Iter: 924 loss: 5.85250177e-07
Iter: 925 loss: 5.8513524e-07
Iter: 926 loss: 5.85125065e-07
Iter: 927 loss: 5.84996258e-07
Iter: 928 loss: 5.84991199e-07
Iter: 929 loss: 5.85024793e-07
Iter: 930 loss: 5.84951181e-07
Iter: 931 loss: 5.84923271e-07
Iter: 932 loss: 5.84936572e-07
Iter: 933 loss: 5.84888937e-07
Iter: 934 loss: 5.84866143e-07
Iter: 935 loss: 5.84771328e-07
Iter: 936 loss: 5.86391707e-07
Iter: 937 loss: 5.84799409e-07
Iter: 938 loss: 5.84719601e-07
Iter: 939 loss: 5.84708e-07
Iter: 940 loss: 5.84657414e-07
Iter: 941 loss: 5.84641555e-07
Iter: 942 loss: 5.84614781e-07
Iter: 943 loss: 5.84561e-07
Iter: 944 loss: 5.84784914e-07
Iter: 945 loss: 5.84556062e-07
Iter: 946 loss: 5.84508882e-07
Iter: 947 loss: 5.84430609e-07
Iter: 948 loss: 5.84444763e-07
Iter: 949 loss: 5.84338e-07
Iter: 950 loss: 5.85265127e-07
Iter: 951 loss: 5.84345855e-07
Iter: 952 loss: 5.84275824e-07
Iter: 953 loss: 5.84299471e-07
Iter: 954 loss: 5.84254053e-07
Iter: 955 loss: 5.84188285e-07
Iter: 956 loss: 5.84098927e-07
Iter: 957 loss: 5.84103304e-07
Iter: 958 loss: 5.83985354e-07
Iter: 959 loss: 5.84058682e-07
Iter: 960 loss: 5.83948349e-07
Iter: 961 loss: 5.83873373e-07
Iter: 962 loss: 5.84137581e-07
Iter: 963 loss: 5.83884912e-07
Iter: 964 loss: 5.83826136e-07
Iter: 965 loss: 5.83838812e-07
Iter: 966 loss: 5.83781684e-07
Iter: 967 loss: 5.83742349e-07
Iter: 968 loss: 5.83779524e-07
Iter: 969 loss: 5.83732e-07
Iter: 970 loss: 5.8367965e-07
Iter: 971 loss: 5.83694316e-07
Iter: 972 loss: 5.83683118e-07
Iter: 973 loss: 5.83628e-07
Iter: 974 loss: 5.83942949e-07
Iter: 975 loss: 5.83639064e-07
Iter: 976 loss: 5.8359069e-07
Iter: 977 loss: 5.83512417e-07
Iter: 978 loss: 5.83525718e-07
Iter: 979 loss: 5.83469898e-07
Iter: 980 loss: 5.83649921e-07
Iter: 981 loss: 5.83448241e-07
Iter: 982 loss: 5.8337389e-07
Iter: 983 loss: 5.83860128e-07
Iter: 984 loss: 5.8332995e-07
Iter: 985 loss: 5.83267251e-07
Iter: 986 loss: 5.83206656e-07
Iter: 987 loss: 5.8319597e-07
Iter: 988 loss: 5.83087342e-07
Iter: 989 loss: 5.8311e-07
Iter: 990 loss: 5.83077338e-07
Iter: 991 loss: 5.83001338e-07
Iter: 992 loss: 5.8299662e-07
Iter: 993 loss: 5.82922496e-07
Iter: 994 loss: 5.83496217e-07
Iter: 995 loss: 5.82911809e-07
Iter: 996 loss: 5.82845132e-07
Iter: 997 loss: 5.82806933e-07
Iter: 998 loss: 5.82775272e-07
Iter: 999 loss: 5.82736e-07
Iter: 1000 loss: 5.82768337e-07
Iter: 1001 loss: 5.82682844e-07
Iter: 1002 loss: 5.82753046e-07
Iter: 1003 loss: 5.82691939e-07
Iter: 1004 loss: 5.82631912e-07
Iter: 1005 loss: 5.82589507e-07
Iter: 1006 loss: 5.82585244e-07
Iter: 1007 loss: 5.82486564e-07
Iter: 1008 loss: 5.83123494e-07
Iter: 1009 loss: 5.82501627e-07
Iter: 1010 loss: 5.82462576e-07
Iter: 1011 loss: 5.82623102e-07
Iter: 1012 loss: 5.82440236e-07
Iter: 1013 loss: 5.82389134e-07
Iter: 1014 loss: 5.82397e-07
Iter: 1015 loss: 5.82362418e-07
Iter: 1016 loss: 5.82324788e-07
Iter: 1017 loss: 5.82598886e-07
Iter: 1018 loss: 5.82327743e-07
Iter: 1019 loss: 5.82289942e-07
Iter: 1020 loss: 5.82506289e-07
Iter: 1021 loss: 5.82274765e-07
Iter: 1022 loss: 5.82253278e-07
Iter: 1023 loss: 5.82219172e-07
Iter: 1024 loss: 5.82209e-07
Iter: 1025 loss: 5.82158748e-07
Iter: 1026 loss: 5.82339396e-07
Iter: 1027 loss: 5.82162e-07
Iter: 1028 loss: 5.82103894e-07
Iter: 1029 loss: 5.82104121e-07
Iter: 1030 loss: 5.82027383e-07
Iter: 1031 loss: 5.81984523e-07
Iter: 1032 loss: 5.82080247e-07
Iter: 1033 loss: 5.81982306e-07
Iter: 1034 loss: 5.8189039e-07
Iter: 1035 loss: 5.8275117e-07
Iter: 1036 loss: 5.81881693e-07
Iter: 1037 loss: 5.81839402e-07
Iter: 1038 loss: 5.81831273e-07
Iter: 1039 loss: 5.81815e-07
Iter: 1040 loss: 5.8171895e-07
Iter: 1041 loss: 5.81871348e-07
Iter: 1042 loss: 5.81725e-07
Iter: 1043 loss: 5.81632548e-07
Iter: 1044 loss: 5.82164603e-07
Iter: 1045 loss: 5.8165142e-07
Iter: 1046 loss: 5.81576671e-07
Iter: 1047 loss: 5.81669156e-07
Iter: 1048 loss: 5.81561892e-07
Iter: 1049 loss: 5.8149169e-07
Iter: 1050 loss: 5.81899769e-07
Iter: 1051 loss: 5.81513632e-07
Iter: 1052 loss: 5.81476343e-07
Iter: 1053 loss: 5.81523864e-07
Iter: 1054 loss: 5.81449967e-07
Iter: 1055 loss: 5.81435188e-07
Iter: 1056 loss: 5.81487029e-07
Iter: 1057 loss: 5.81399377e-07
Iter: 1058 loss: 5.814004e-07
Iter: 1059 loss: 5.81379368e-07
Iter: 1060 loss: 5.8138744e-07
Iter: 1061 loss: 5.81376412e-07
Iter: 1062 loss: 5.81396e-07
Iter: 1063 loss: 5.81400855e-07
Iter: 1064 loss: 5.81385734e-07
Iter: 1065 loss: 5.81397671e-07
Iter: 1066 loss: 5.8139176e-07
Iter: 1067 loss: 5.81392158e-07
Iter: 1068 loss: 5.81405e-07
Iter: 1069 loss: 5.81396819e-07
Iter: 1070 loss: 5.81403242e-07
Iter: 1071 loss: 5.81406084e-07
Iter: 1072 loss: 5.81401764e-07
Iter: 1073 loss: 5.81397217e-07
Iter: 1074 loss: 5.81402333e-07
Iter: 1075 loss: 5.81398865e-07
Iter: 1076 loss: 5.8140165e-07
Iter: 1077 loss: 5.81398922e-07
Iter: 1078 loss: 5.81399604e-07
Iter: 1079 loss: 5.81401594e-07
Iter: 1080 loss: 5.8140165e-07
Iter: 1081 loss: 5.81399604e-07
Iter: 1082 loss: 5.81399604e-07
Iter: 1083 loss: 5.8140165e-07
Iter: 1084 loss: 5.81349582e-07
Iter: 1085 loss: 5.81463269e-07
Iter: 1086 loss: 5.81345148e-07
Iter: 1087 loss: 5.81273184e-07
Iter: 1088 loss: 5.81327924e-07
Iter: 1089 loss: 5.81294955e-07
Iter: 1090 loss: 5.81265908e-07
Iter: 1091 loss: 5.81266079e-07
Iter: 1092 loss: 5.8119042e-07
Iter: 1093 loss: 5.8129217e-07
Iter: 1094 loss: 5.81188033e-07
Iter: 1095 loss: 5.8115188e-07
Iter: 1096 loss: 5.81149436e-07
Iter: 1097 loss: 5.81147958e-07
Iter: 1098 loss: 5.81104075e-07
Iter: 1099 loss: 5.8110777e-07
Iter: 1100 loss: 5.81071106e-07
Iter: 1101 loss: 5.80999085e-07
Iter: 1102 loss: 5.81465088e-07
Iter: 1103 loss: 5.81005679e-07
Iter: 1104 loss: 5.80993856e-07
Iter: 1105 loss: 5.80925303e-07
Iter: 1106 loss: 5.80932e-07
Iter: 1107 loss: 5.80873348e-07
Iter: 1108 loss: 5.81125448e-07
Iter: 1109 loss: 5.80875565e-07
Iter: 1110 loss: 5.80802237e-07
Iter: 1111 loss: 5.80885171e-07
Iter: 1112 loss: 5.80764038e-07
Iter: 1113 loss: 5.80724645e-07
Iter: 1114 loss: 5.80612607e-07
Iter: 1115 loss: 5.80618291e-07
Iter: 1116 loss: 5.80519838e-07
Iter: 1117 loss: 5.80537346e-07
Iter: 1118 loss: 5.80469077e-07
Iter: 1119 loss: 5.80363121e-07
Iter: 1120 loss: 5.80372102e-07
Iter: 1121 loss: 5.80301105e-07
Iter: 1122 loss: 5.80966457e-07
Iter: 1123 loss: 5.80312644e-07
Iter: 1124 loss: 5.80227038e-07
Iter: 1125 loss: 5.80653e-07
Iter: 1126 loss: 5.80214078e-07
Iter: 1127 loss: 5.80183496e-07
Iter: 1128 loss: 5.80445374e-07
Iter: 1129 loss: 5.80179574e-07
Iter: 1130 loss: 5.80147116e-07
Iter: 1131 loss: 5.80101869e-07
Iter: 1132 loss: 5.80125857e-07
Iter: 1133 loss: 5.80086294e-07
Iter: 1134 loss: 5.80252049e-07
Iter: 1135 loss: 5.80065887e-07
Iter: 1136 loss: 5.80013307e-07
Iter: 1137 loss: 5.80297637e-07
Iter: 1138 loss: 5.80039739e-07
Iter: 1139 loss: 5.79984658e-07
Iter: 1140 loss: 5.80006088e-07
Iter: 1141 loss: 5.79980167e-07
Iter: 1142 loss: 5.79978177e-07
Iter: 1143 loss: 5.801366e-07
Iter: 1144 loss: 5.79941627e-07
Iter: 1145 loss: 5.79864377e-07
Iter: 1146 loss: 5.79914797e-07
Iter: 1147 loss: 5.79845107e-07
Iter: 1148 loss: 5.79781783e-07
Iter: 1149 loss: 5.79699417e-07
Iter: 1150 loss: 5.79691459e-07
Iter: 1151 loss: 5.79632456e-07
Iter: 1152 loss: 5.80462938e-07
Iter: 1153 loss: 5.7963365e-07
Iter: 1154 loss: 5.7954469e-07
Iter: 1155 loss: 5.79901837e-07
Iter: 1156 loss: 5.7952343e-07
Iter: 1157 loss: 5.79458856e-07
Iter: 1158 loss: 5.79865969e-07
Iter: 1159 loss: 5.79486141e-07
Iter: 1160 loss: 5.79436914e-07
Iter: 1161 loss: 5.79596588e-07
Iter: 1162 loss: 5.79434072e-07
Iter: 1163 loss: 5.7939036e-07
Iter: 1164 loss: 5.79415428e-07
Iter: 1165 loss: 5.79351195e-07
Iter: 1166 loss: 5.79326525e-07
Iter: 1167 loss: 5.79347784e-07
Iter: 1168 loss: 5.79309642e-07
Iter: 1169 loss: 5.79263826e-07
Iter: 1170 loss: 5.79239725e-07
Iter: 1171 loss: 5.79220568e-07
Iter: 1172 loss: 5.79197774e-07
Iter: 1173 loss: 5.8000262e-07
Iter: 1174 loss: 5.79178163e-07
Iter: 1175 loss: 5.79113e-07
Iter: 1176 loss: 5.79292e-07
Iter: 1177 loss: 5.79087441e-07
Iter: 1178 loss: 5.7904191e-07
Iter: 1179 loss: 5.80109941e-07
Iter: 1180 loss: 5.79017069e-07
Iter: 1181 loss: 5.78954541e-07
Iter: 1182 loss: 5.7887371e-07
Iter: 1183 loss: 5.78872971e-07
Iter: 1184 loss: 5.78802371e-07
Iter: 1185 loss: 5.78980121e-07
Iter: 1186 loss: 5.78791401e-07
Iter: 1187 loss: 5.78729669e-07
Iter: 1188 loss: 5.78764912e-07
Iter: 1189 loss: 5.78735637e-07
Iter: 1190 loss: 5.78717959e-07
Iter: 1191 loss: 5.78678964e-07
Iter: 1192 loss: 5.78620075e-07
Iter: 1193 loss: 5.79032076e-07
Iter: 1194 loss: 5.78645711e-07
Iter: 1195 loss: 5.78615641e-07
Iter: 1196 loss: 5.78588697e-07
Iter: 1197 loss: 5.78570962e-07
Iter: 1198 loss: 5.78517358e-07
Iter: 1199 loss: 5.78745244e-07
Iter: 1200 loss: 5.78543506e-07
Iter: 1201 loss: 5.78494962e-07
Iter: 1202 loss: 5.78566414e-07
Iter: 1203 loss: 5.78489789e-07
Iter: 1204 loss: 5.78422146e-07
Iter: 1205 loss: 5.78341826e-07
Iter: 1206 loss: 5.78368258e-07
Iter: 1207 loss: 5.78250706e-07
Iter: 1208 loss: 5.78485469e-07
Iter: 1209 loss: 5.78215861e-07
Iter: 1210 loss: 5.78211655e-07
Iter: 1211 loss: 5.78222739e-07
Iter: 1212 loss: 5.78229e-07
Iter: 1213 loss: 5.78223421e-07
Iter: 1214 loss: 5.78232346e-07
Iter: 1215 loss: 5.78216486e-07
Iter: 1216 loss: 5.7821137e-07
Iter: 1217 loss: 5.78216714e-07
Iter: 1218 loss: 5.78204038e-07
Iter: 1219 loss: 5.78216486e-07
Iter: 1220 loss: 5.78216714e-07
Iter: 1221 loss: 5.78223251e-07
Iter: 1222 loss: 5.78217509e-07
Iter: 1223 loss: 5.78217168e-07
Iter: 1224 loss: 5.78204492e-07
Iter: 1225 loss: 5.78211029e-07
Iter: 1226 loss: 5.78210461e-07
Iter: 1227 loss: 5.78216884e-07
Iter: 1228 loss: 5.78212564e-07
Iter: 1229 loss: 5.78213758e-07
Iter: 1230 loss: 5.78216543e-07
Iter: 1231 loss: 5.78214497e-07
Iter: 1232 loss: 5.78215236e-07
Iter: 1233 loss: 5.78216088e-07
Iter: 1234 loss: 5.78217e-07
Iter: 1235 loss: 5.78216088e-07
Iter: 1236 loss: 5.78216259e-07
Iter: 1237 loss: 5.78216259e-07
Iter: 1238 loss: 5.78216884e-07
Iter: 1239 loss: 5.78216884e-07
Iter: 1240 loss: 5.78216259e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.4/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.8 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.8
+ date
Sat Nov  7 19:13:13 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.4/300_100_100_100_1 --function f1 --psi 0 --phi 0.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.8/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbe8922ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbe89279d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbe89dd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc63e97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc63e9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbe89177b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc63c5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc631dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc631dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc631d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc630a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc6314bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0337f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba034f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0337950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc630e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbc6369c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba03588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba03cbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba03a6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba02a37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba02122f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba02276a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0228f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba024e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0200f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba020a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0200378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba00ce1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba00d50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba00da510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba01ac1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba01c2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba00569d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0155268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0175f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0018071246
test_loss: 0.0018112774
train_loss: 0.001593529
test_loss: 0.0018767166
train_loss: 0.0014146558
test_loss: 0.001426021
train_loss: 0.0014529487
test_loss: 0.0013962229
train_loss: 0.001594832
test_loss: 0.0014317858
train_loss: 0.0013529025
test_loss: 0.0014265012
train_loss: 0.00126349
test_loss: 0.001344056
train_loss: 0.0014479072
test_loss: 0.0014322834
train_loss: 0.001442088
test_loss: 0.0015810106
train_loss: 0.001500871
test_loss: 0.0015431191
train_loss: 0.0012356936
test_loss: 0.001387333
train_loss: 0.0013843764
test_loss: 0.0013760935
train_loss: 0.001388513
test_loss: 0.0012391012
train_loss: 0.0013734893
test_loss: 0.0013403168
train_loss: 0.0012226149
test_loss: 0.0013166585
train_loss: 0.0012233404
test_loss: 0.001594142
train_loss: 0.001288019
test_loss: 0.0013516318
train_loss: 0.0013902525
test_loss: 0.0015830206
train_loss: 0.0012262362
test_loss: 0.0012847399
train_loss: 0.0012708772
test_loss: 0.0014952817
train_loss: 0.0014169016
test_loss: 0.0013044415
train_loss: 0.001406559
test_loss: 0.0014322344
train_loss: 0.0011706705
test_loss: 0.0014967838
train_loss: 0.0012459474
test_loss: 0.0013273603
train_loss: 0.0012918019
test_loss: 0.0013249461
train_loss: 0.0012854927
test_loss: 0.0013156082
train_loss: 0.0011412437
test_loss: 0.001190017
train_loss: 0.0011208912
test_loss: 0.0014633198
train_loss: 0.0010964444
test_loss: 0.0013563815
train_loss: 0.001263058
test_loss: 0.001352161
train_loss: 0.0010957285
test_loss: 0.0011693372
train_loss: 0.0012836679
test_loss: 0.0012578121
train_loss: 0.001147213
test_loss: 0.0014500808
train_loss: 0.0013323321
test_loss: 0.0017920057
train_loss: 0.0017632698
test_loss: 0.0012577838
train_loss: 0.001426968
test_loss: 0.0013268741
train_loss: 0.0013470228
test_loss: 0.0012979152
train_loss: 0.0011502969
test_loss: 0.0012417771
train_loss: 0.001580632
test_loss: 0.0013838982
train_loss: 0.0015190018
test_loss: 0.0014240602
train_loss: 0.0014491549
test_loss: 0.0012609505
train_loss: 0.0012134549
test_loss: 0.0010770719
train_loss: 0.0012582451
test_loss: 0.0013752171
train_loss: 0.0012218802
test_loss: 0.001322751
train_loss: 0.0011929702
test_loss: 0.0012141708
train_loss: 0.001328608
test_loss: 0.0014457095
train_loss: 0.001201442
test_loss: 0.0013250643
train_loss: 0.0011206581
test_loss: 0.0014456764
train_loss: 0.0012061321
test_loss: 0.0013944414
train_loss: 0.0011064137
test_loss: 0.0013561734
train_loss: 0.0010415263
test_loss: 0.001188412
train_loss: 0.0012667746
test_loss: 0.0014106237
train_loss: 0.0011539019
test_loss: 0.0012534535
train_loss: 0.0013394863
test_loss: 0.0012208788
train_loss: 0.001178057
test_loss: 0.0012187741
train_loss: 0.0012274836
test_loss: 0.0011953071
train_loss: 0.0013178329
test_loss: 0.0013122807
train_loss: 0.0012619757
test_loss: 0.0014141168
train_loss: 0.0013269177
test_loss: 0.0014198725
train_loss: 0.0014960002
test_loss: 0.0012596804
train_loss: 0.001149091
test_loss: 0.0011263937
train_loss: 0.0015095889
test_loss: 0.0013180124
train_loss: 0.0012530065
test_loss: 0.0011529216
train_loss: 0.0014033278
test_loss: 0.0012249419
train_loss: 0.0010891357
test_loss: 0.0013544102
train_loss: 0.0011930199
test_loss: 0.0012390458
train_loss: 0.0013250767
test_loss: 0.0016436483
train_loss: 0.0011741924
test_loss: 0.0011810815
train_loss: 0.0010928039
test_loss: 0.0012900766
train_loss: 0.0013973111
test_loss: 0.0012475321
train_loss: 0.0011183064
test_loss: 0.0010748539
train_loss: 0.0010868831
test_loss: 0.0013078499
train_loss: 0.0013056444
test_loss: 0.0013859714
train_loss: 0.0014383132
test_loss: 0.0013672452
train_loss: 0.0012499864
test_loss: 0.0012896275
train_loss: 0.0012644478
test_loss: 0.0012626167
train_loss: 0.00129379
test_loss: 0.0012580823
train_loss: 0.0010625406
test_loss: 0.0011966439
train_loss: 0.0012622025
test_loss: 0.0012581936
train_loss: 0.0010878819
test_loss: 0.0011315418
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.8/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi0.8/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c045b99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c045ea8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4005e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04585620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c045850d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c4005e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c045466a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c044a3840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c044a3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04462158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c044629d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04416e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04447d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c043f01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04404f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c043beb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c043be840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c043be598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c043379d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c042cba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c042f0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c0428f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c042906a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c042c4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c0425e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04242f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04215620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04242378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c041921e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c041c70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c041c1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c0417f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c0416d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04131598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c040dc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2c04104f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.97930945e-06
Iter: 2 loss: 8.28039265e-06
Iter: 3 loss: 1.33798108e-06
Iter: 4 loss: 1.1553816e-06
Iter: 5 loss: 1.21439291e-06
Iter: 6 loss: 1.02567401e-06
Iter: 7 loss: 9.42299835e-07
Iter: 8 loss: 9.41501241e-07
Iter: 9 loss: 8.93139372e-07
Iter: 10 loss: 8.52133326e-07
Iter: 11 loss: 8.38686901e-07
Iter: 12 loss: 7.91357365e-07
Iter: 13 loss: 9.8322289e-07
Iter: 14 loss: 7.80856908e-07
Iter: 15 loss: 7.5100445e-07
Iter: 16 loss: 7.50508093e-07
Iter: 17 loss: 7.41113922e-07
Iter: 18 loss: 7.29602e-07
Iter: 19 loss: 7.28581654e-07
Iter: 20 loss: 7.24107736e-07
Iter: 21 loss: 7.22323e-07
Iter: 22 loss: 7.1615267e-07
Iter: 23 loss: 7.06004698e-07
Iter: 24 loss: 7.0594831e-07
Iter: 25 loss: 6.95430458e-07
Iter: 26 loss: 7.0803037e-07
Iter: 27 loss: 6.89909257e-07
Iter: 28 loss: 6.80919243e-07
Iter: 29 loss: 6.86333919e-07
Iter: 30 loss: 6.75102058e-07
Iter: 31 loss: 6.65366827e-07
Iter: 32 loss: 7.46154683e-07
Iter: 33 loss: 6.64793959e-07
Iter: 34 loss: 6.58144188e-07
Iter: 35 loss: 6.58056194e-07
Iter: 36 loss: 6.5422762e-07
Iter: 37 loss: 6.55796271e-07
Iter: 38 loss: 6.51506525e-07
Iter: 39 loss: 6.48533501e-07
Iter: 40 loss: 6.88396199e-07
Iter: 41 loss: 6.48485184e-07
Iter: 42 loss: 6.459926e-07
Iter: 43 loss: 6.41255724e-07
Iter: 44 loss: 7.45280033e-07
Iter: 45 loss: 6.41233555e-07
Iter: 46 loss: 6.38603524e-07
Iter: 47 loss: 6.3858738e-07
Iter: 48 loss: 6.36502932e-07
Iter: 49 loss: 6.47111847e-07
Iter: 50 loss: 6.36155335e-07
Iter: 51 loss: 6.34555818e-07
Iter: 52 loss: 6.32113711e-07
Iter: 53 loss: 6.32089382e-07
Iter: 54 loss: 6.30455929e-07
Iter: 55 loss: 6.30282614e-07
Iter: 56 loss: 6.28443672e-07
Iter: 57 loss: 6.26197391e-07
Iter: 58 loss: 6.26025724e-07
Iter: 59 loss: 6.23326855e-07
Iter: 60 loss: 6.19940067e-07
Iter: 61 loss: 6.19698881e-07
Iter: 62 loss: 6.14966211e-07
Iter: 63 loss: 6.35286654e-07
Iter: 64 loss: 6.14043643e-07
Iter: 65 loss: 6.08704795e-07
Iter: 66 loss: 6.13182237e-07
Iter: 67 loss: 6.05584091e-07
Iter: 68 loss: 6.04619686e-07
Iter: 69 loss: 6.03328772e-07
Iter: 70 loss: 6.01195e-07
Iter: 71 loss: 6.04456659e-07
Iter: 72 loss: 6.00184308e-07
Iter: 73 loss: 5.98778684e-07
Iter: 74 loss: 6.03685635e-07
Iter: 75 loss: 5.98460645e-07
Iter: 76 loss: 5.96583391e-07
Iter: 77 loss: 5.96500513e-07
Iter: 78 loss: 5.95091535e-07
Iter: 79 loss: 5.93550908e-07
Iter: 80 loss: 5.97439e-07
Iter: 81 loss: 5.93022946e-07
Iter: 82 loss: 5.91912055e-07
Iter: 83 loss: 5.96524501e-07
Iter: 84 loss: 5.9166689e-07
Iter: 85 loss: 5.90593118e-07
Iter: 86 loss: 6.03067406e-07
Iter: 87 loss: 5.90601758e-07
Iter: 88 loss: 5.90167133e-07
Iter: 89 loss: 5.89418164e-07
Iter: 90 loss: 6.07263814e-07
Iter: 91 loss: 5.89454714e-07
Iter: 92 loss: 5.88844841e-07
Iter: 93 loss: 5.88785156e-07
Iter: 94 loss: 5.8825708e-07
Iter: 95 loss: 5.87176771e-07
Iter: 96 loss: 6.07508923e-07
Iter: 97 loss: 5.87113163e-07
Iter: 98 loss: 5.85856696e-07
Iter: 99 loss: 5.87559839e-07
Iter: 100 loss: 5.85262057e-07
Iter: 101 loss: 5.8402054e-07
Iter: 102 loss: 5.84253542e-07
Iter: 103 loss: 5.83115e-07
Iter: 104 loss: 5.81262839e-07
Iter: 105 loss: 5.870873e-07
Iter: 106 loss: 5.8066712e-07
Iter: 107 loss: 5.80695826e-07
Iter: 108 loss: 5.79903769e-07
Iter: 109 loss: 5.79334824e-07
Iter: 110 loss: 5.78203299e-07
Iter: 111 loss: 6.00498197e-07
Iter: 112 loss: 5.78193863e-07
Iter: 113 loss: 5.77339563e-07
Iter: 114 loss: 5.89023102e-07
Iter: 115 loss: 5.77307e-07
Iter: 116 loss: 5.76582693e-07
Iter: 117 loss: 5.77615879e-07
Iter: 118 loss: 5.76214234e-07
Iter: 119 loss: 5.75603906e-07
Iter: 120 loss: 5.74546448e-07
Iter: 121 loss: 5.74566e-07
Iter: 122 loss: 5.74469198e-07
Iter: 123 loss: 5.74108185e-07
Iter: 124 loss: 5.73639852e-07
Iter: 125 loss: 5.72865929e-07
Iter: 126 loss: 5.93356845e-07
Iter: 127 loss: 5.7285115e-07
Iter: 128 loss: 5.72271233e-07
Iter: 129 loss: 5.7224463e-07
Iter: 130 loss: 5.71736393e-07
Iter: 131 loss: 5.7211048e-07
Iter: 132 loss: 5.71392093e-07
Iter: 133 loss: 5.70940699e-07
Iter: 134 loss: 5.70157056e-07
Iter: 135 loss: 5.70134944e-07
Iter: 136 loss: 5.69084477e-07
Iter: 137 loss: 5.70798875e-07
Iter: 138 loss: 5.68602218e-07
Iter: 139 loss: 5.67740187e-07
Iter: 140 loss: 5.719005e-07
Iter: 141 loss: 5.67559653e-07
Iter: 142 loss: 5.66809945e-07
Iter: 143 loss: 5.70914153e-07
Iter: 144 loss: 5.66723088e-07
Iter: 145 loss: 5.66384358e-07
Iter: 146 loss: 5.66321205e-07
Iter: 147 loss: 5.66011181e-07
Iter: 148 loss: 5.65625442e-07
Iter: 149 loss: 5.65608389e-07
Iter: 150 loss: 5.65214236e-07
Iter: 151 loss: 5.67490872e-07
Iter: 152 loss: 5.65139089e-07
Iter: 153 loss: 5.64671495e-07
Iter: 154 loss: 5.64799507e-07
Iter: 155 loss: 5.64310881e-07
Iter: 156 loss: 5.63983633e-07
Iter: 157 loss: 5.64718448e-07
Iter: 158 loss: 5.63853348e-07
Iter: 159 loss: 5.63511435e-07
Iter: 160 loss: 5.66867413e-07
Iter: 161 loss: 5.63521894e-07
Iter: 162 loss: 5.63186632e-07
Iter: 163 loss: 5.62463072e-07
Iter: 164 loss: 5.74108867e-07
Iter: 165 loss: 5.62441755e-07
Iter: 166 loss: 5.62123773e-07
Iter: 167 loss: 5.6201003e-07
Iter: 168 loss: 5.61695401e-07
Iter: 169 loss: 5.61190291e-07
Iter: 170 loss: 5.61201773e-07
Iter: 171 loss: 5.60645731e-07
Iter: 172 loss: 5.60365436e-07
Iter: 173 loss: 5.60125159e-07
Iter: 174 loss: 5.59520402e-07
Iter: 175 loss: 5.63590845e-07
Iter: 176 loss: 5.59441219e-07
Iter: 177 loss: 5.58977149e-07
Iter: 178 loss: 5.59773071e-07
Iter: 179 loss: 5.58739828e-07
Iter: 180 loss: 5.58518082e-07
Iter: 181 loss: 5.5849722e-07
Iter: 182 loss: 5.5818623e-07
Iter: 183 loss: 5.58387512e-07
Iter: 184 loss: 5.58058787e-07
Iter: 185 loss: 5.57834483e-07
Iter: 186 loss: 5.58569752e-07
Iter: 187 loss: 5.57743817e-07
Iter: 188 loss: 5.57546343e-07
Iter: 189 loss: 5.57906787e-07
Iter: 190 loss: 5.57391729e-07
Iter: 191 loss: 5.57140083e-07
Iter: 192 loss: 5.57081421e-07
Iter: 193 loss: 5.5689469e-07
Iter: 194 loss: 5.565945e-07
Iter: 195 loss: 5.56589725e-07
Iter: 196 loss: 5.56359964e-07
Iter: 197 loss: 5.56128498e-07
Iter: 198 loss: 5.56091948e-07
Iter: 199 loss: 5.55892029e-07
Iter: 200 loss: 5.55859287e-07
Iter: 201 loss: 5.55701206e-07
Iter: 202 loss: 5.55464624e-07
Iter: 203 loss: 5.55477698e-07
Iter: 204 loss: 5.55222414e-07
Iter: 205 loss: 5.55488327e-07
Iter: 206 loss: 5.5510418e-07
Iter: 207 loss: 5.54769485e-07
Iter: 208 loss: 5.55324334e-07
Iter: 209 loss: 5.54656822e-07
Iter: 210 loss: 5.54433313e-07
Iter: 211 loss: 5.57246e-07
Iter: 212 loss: 5.54416147e-07
Iter: 213 loss: 5.54187181e-07
Iter: 214 loss: 5.54793871e-07
Iter: 215 loss: 5.54107316e-07
Iter: 216 loss: 5.53896371e-07
Iter: 217 loss: 5.54099358e-07
Iter: 218 loss: 5.53794052e-07
Iter: 219 loss: 5.53463224e-07
Iter: 220 loss: 5.54812573e-07
Iter: 221 loss: 5.53455209e-07
Iter: 222 loss: 5.53203961e-07
Iter: 223 loss: 5.52849e-07
Iter: 224 loss: 5.5287336e-07
Iter: 225 loss: 5.5260125e-07
Iter: 226 loss: 5.52555548e-07
Iter: 227 loss: 5.52410597e-07
Iter: 228 loss: 5.52739039e-07
Iter: 229 loss: 5.52303732e-07
Iter: 230 loss: 5.52068286e-07
Iter: 231 loss: 5.52472102e-07
Iter: 232 loss: 5.5202031e-07
Iter: 233 loss: 5.51704886e-07
Iter: 234 loss: 5.51902929e-07
Iter: 235 loss: 5.51461426e-07
Iter: 236 loss: 5.51174253e-07
Iter: 237 loss: 5.51037601e-07
Iter: 238 loss: 5.50910215e-07
Iter: 239 loss: 5.50492814e-07
Iter: 240 loss: 5.51085861e-07
Iter: 241 loss: 5.50281413e-07
Iter: 242 loss: 5.49864581e-07
Iter: 243 loss: 5.52447716e-07
Iter: 244 loss: 5.49797051e-07
Iter: 245 loss: 5.49636866e-07
Iter: 246 loss: 5.49608615e-07
Iter: 247 loss: 5.49462811e-07
Iter: 248 loss: 5.4916427e-07
Iter: 249 loss: 5.55557108e-07
Iter: 250 loss: 5.49166941e-07
Iter: 251 loss: 5.48968103e-07
Iter: 252 loss: 5.48939795e-07
Iter: 253 loss: 5.48808657e-07
Iter: 254 loss: 5.48776711e-07
Iter: 255 loss: 5.48677349e-07
Iter: 256 loss: 5.48500623e-07
Iter: 257 loss: 5.49049389e-07
Iter: 258 loss: 5.48481466e-07
Iter: 259 loss: 5.48248238e-07
Iter: 260 loss: 5.48916319e-07
Iter: 261 loss: 5.48159448e-07
Iter: 262 loss: 5.47998184e-07
Iter: 263 loss: 5.48487606e-07
Iter: 264 loss: 5.47909451e-07
Iter: 265 loss: 5.47749664e-07
Iter: 266 loss: 5.48954347e-07
Iter: 267 loss: 5.4770635e-07
Iter: 268 loss: 5.47600621e-07
Iter: 269 loss: 5.47247112e-07
Iter: 270 loss: 5.51362234e-07
Iter: 271 loss: 5.47199193e-07
Iter: 272 loss: 5.46871433e-07
Iter: 273 loss: 5.48265916e-07
Iter: 274 loss: 5.46759338e-07
Iter: 275 loss: 5.46454146e-07
Iter: 276 loss: 5.47781781e-07
Iter: 277 loss: 5.46374338e-07
Iter: 278 loss: 5.46238425e-07
Iter: 279 loss: 5.46210799e-07
Iter: 280 loss: 5.46004685e-07
Iter: 281 loss: 5.45859905e-07
Iter: 282 loss: 5.45827e-07
Iter: 283 loss: 5.45646799e-07
Iter: 284 loss: 5.47126206e-07
Iter: 285 loss: 5.4563111e-07
Iter: 286 loss: 5.45468311e-07
Iter: 287 loss: 5.45625312e-07
Iter: 288 loss: 5.45371734e-07
Iter: 289 loss: 5.45236446e-07
Iter: 290 loss: 5.45348826e-07
Iter: 291 loss: 5.45136345e-07
Iter: 292 loss: 5.44988552e-07
Iter: 293 loss: 5.472113e-07
Iter: 294 loss: 5.4497815e-07
Iter: 295 loss: 5.44821546e-07
Iter: 296 loss: 5.44775048e-07
Iter: 297 loss: 5.44715135e-07
Iter: 298 loss: 5.44454394e-07
Iter: 299 loss: 5.46442323e-07
Iter: 300 loss: 5.44473096e-07
Iter: 301 loss: 5.44329509e-07
Iter: 302 loss: 5.44136753e-07
Iter: 303 loss: 5.44100203e-07
Iter: 304 loss: 5.43901137e-07
Iter: 305 loss: 5.44039949e-07
Iter: 306 loss: 5.43799217e-07
Iter: 307 loss: 5.4349448e-07
Iter: 308 loss: 5.44505212e-07
Iter: 309 loss: 5.43402564e-07
Iter: 310 loss: 5.43291094e-07
Iter: 311 loss: 5.43271597e-07
Iter: 312 loss: 5.43171382e-07
Iter: 313 loss: 5.43555302e-07
Iter: 314 loss: 5.43093165e-07
Iter: 315 loss: 5.4298755e-07
Iter: 316 loss: 5.42941166e-07
Iter: 317 loss: 5.42907969e-07
Iter: 318 loss: 5.42767e-07
Iter: 319 loss: 5.44909199e-07
Iter: 320 loss: 5.42756311e-07
Iter: 321 loss: 5.426906e-07
Iter: 322 loss: 5.42524447e-07
Iter: 323 loss: 5.42517114e-07
Iter: 324 loss: 5.4237e-07
Iter: 325 loss: 5.43813826e-07
Iter: 326 loss: 5.42342946e-07
Iter: 327 loss: 5.42226189e-07
Iter: 328 loss: 5.42416444e-07
Iter: 329 loss: 5.42134671e-07
Iter: 330 loss: 5.42014561e-07
Iter: 331 loss: 5.42901489e-07
Iter: 332 loss: 5.42000066e-07
Iter: 333 loss: 5.41904399e-07
Iter: 334 loss: 5.41777e-07
Iter: 335 loss: 5.41733186e-07
Iter: 336 loss: 5.41538213e-07
Iter: 337 loss: 5.41623763e-07
Iter: 338 loss: 5.41433906e-07
Iter: 339 loss: 5.41241434e-07
Iter: 340 loss: 5.41849033e-07
Iter: 341 loss: 5.41202e-07
Iter: 342 loss: 5.41012128e-07
Iter: 343 loss: 5.42404791e-07
Iter: 344 loss: 5.40983535e-07
Iter: 345 loss: 5.40856377e-07
Iter: 346 loss: 5.42081352e-07
Iter: 347 loss: 5.40882411e-07
Iter: 348 loss: 5.40782708e-07
Iter: 349 loss: 5.4064941e-07
Iter: 350 loss: 5.40656117e-07
Iter: 351 loss: 5.40559029e-07
Iter: 352 loss: 5.40550957e-07
Iter: 353 loss: 5.4048536e-07
Iter: 354 loss: 5.40316364e-07
Iter: 355 loss: 5.43362489e-07
Iter: 356 loss: 5.40265546e-07
Iter: 357 loss: 5.40125143e-07
Iter: 358 loss: 5.4014248e-07
Iter: 359 loss: 5.4003408e-07
Iter: 360 loss: 5.40472115e-07
Iter: 361 loss: 5.40008728e-07
Iter: 362 loss: 5.39945745e-07
Iter: 363 loss: 5.40115252e-07
Iter: 364 loss: 5.39901237e-07
Iter: 365 loss: 5.39772259e-07
Iter: 366 loss: 5.39739858e-07
Iter: 367 loss: 5.39671589e-07
Iter: 368 loss: 5.39545113e-07
Iter: 369 loss: 5.39715302e-07
Iter: 370 loss: 5.39492646e-07
Iter: 371 loss: 5.3934366e-07
Iter: 372 loss: 5.39435916e-07
Iter: 373 loss: 5.39254643e-07
Iter: 374 loss: 5.39085477e-07
Iter: 375 loss: 5.40103542e-07
Iter: 376 loss: 5.39093094e-07
Iter: 377 loss: 5.39003622e-07
Iter: 378 loss: 5.38985546e-07
Iter: 379 loss: 5.3893217e-07
Iter: 380 loss: 5.38864924e-07
Iter: 381 loss: 5.38853101e-07
Iter: 382 loss: 5.38707866e-07
Iter: 383 loss: 5.39733378e-07
Iter: 384 loss: 5.38717813e-07
Iter: 385 loss: 5.38565359e-07
Iter: 386 loss: 5.38712584e-07
Iter: 387 loss: 5.38535119e-07
Iter: 388 loss: 5.38436609e-07
Iter: 389 loss: 5.38500103e-07
Iter: 390 loss: 5.38363e-07
Iter: 391 loss: 5.38232257e-07
Iter: 392 loss: 5.39177051e-07
Iter: 393 loss: 5.38202528e-07
Iter: 394 loss: 5.38070424e-07
Iter: 395 loss: 5.38210656e-07
Iter: 396 loss: 5.38019549e-07
Iter: 397 loss: 5.37855385e-07
Iter: 398 loss: 5.38424558e-07
Iter: 399 loss: 5.37827873e-07
Iter: 400 loss: 5.3774113e-07
Iter: 401 loss: 5.376545e-07
Iter: 402 loss: 5.37598e-07
Iter: 403 loss: 5.37437472e-07
Iter: 404 loss: 5.3756537e-07
Iter: 405 loss: 5.37343e-07
Iter: 406 loss: 5.37146661e-07
Iter: 407 loss: 5.38190648e-07
Iter: 408 loss: 5.37146093e-07
Iter: 409 loss: 5.37034111e-07
Iter: 410 loss: 5.38244592e-07
Iter: 411 loss: 5.37042411e-07
Iter: 412 loss: 5.36911e-07
Iter: 413 loss: 5.36958566e-07
Iter: 414 loss: 5.36821858e-07
Iter: 415 loss: 5.36729544e-07
Iter: 416 loss: 5.36957259e-07
Iter: 417 loss: 5.36659172e-07
Iter: 418 loss: 5.36604034e-07
Iter: 419 loss: 5.37611299e-07
Iter: 420 loss: 5.36597781e-07
Iter: 421 loss: 5.36547702e-07
Iter: 422 loss: 5.3640639e-07
Iter: 423 loss: 5.38905851e-07
Iter: 424 loss: 5.36439757e-07
Iter: 425 loss: 5.36314928e-07
Iter: 426 loss: 5.37858796e-07
Iter: 427 loss: 5.36272e-07
Iter: 428 loss: 5.3621136e-07
Iter: 429 loss: 5.3637666e-07
Iter: 430 loss: 5.36203629e-07
Iter: 431 loss: 5.36090624e-07
Iter: 432 loss: 5.36573111e-07
Iter: 433 loss: 5.36058792e-07
Iter: 434 loss: 5.35990353e-07
Iter: 435 loss: 5.35896049e-07
Iter: 436 loss: 5.35856088e-07
Iter: 437 loss: 5.35732966e-07
Iter: 438 loss: 5.35989784e-07
Iter: 439 loss: 5.35691925e-07
Iter: 440 loss: 5.35561526e-07
Iter: 441 loss: 5.35742856e-07
Iter: 442 loss: 5.35499339e-07
Iter: 443 loss: 5.352627e-07
Iter: 444 loss: 5.35233539e-07
Iter: 445 loss: 5.35069091e-07
Iter: 446 loss: 5.35081085e-07
Iter: 447 loss: 5.34971434e-07
Iter: 448 loss: 5.34875142e-07
Iter: 449 loss: 5.34803746e-07
Iter: 450 loss: 5.34798687e-07
Iter: 451 loss: 5.34674655e-07
Iter: 452 loss: 5.34910441e-07
Iter: 453 loss: 5.34650439e-07
Iter: 454 loss: 5.34556534e-07
Iter: 455 loss: 5.35374e-07
Iter: 456 loss: 5.34531694e-07
Iter: 457 loss: 5.34465812e-07
Iter: 458 loss: 5.34334504e-07
Iter: 459 loss: 5.34318247e-07
Iter: 460 loss: 5.34252194e-07
Iter: 461 loss: 5.34251569e-07
Iter: 462 loss: 5.34147432e-07
Iter: 463 loss: 5.34301762e-07
Iter: 464 loss: 5.34110654e-07
Iter: 465 loss: 5.34070807e-07
Iter: 466 loss: 5.34398851e-07
Iter: 467 loss: 5.34029482e-07
Iter: 468 loss: 5.33915454e-07
Iter: 469 loss: 5.33882826e-07
Iter: 470 loss: 5.33882883e-07
Iter: 471 loss: 5.33725029e-07
Iter: 472 loss: 5.3378767e-07
Iter: 473 loss: 5.33664547e-07
Iter: 474 loss: 5.3350459e-07
Iter: 475 loss: 5.34318701e-07
Iter: 476 loss: 5.33474463e-07
Iter: 477 loss: 5.33376124e-07
Iter: 478 loss: 5.34191258e-07
Iter: 479 loss: 5.333942e-07
Iter: 480 loss: 5.33353e-07
Iter: 481 loss: 5.33352818e-07
Iter: 482 loss: 5.33330649e-07
Iter: 483 loss: 5.33232537e-07
Iter: 484 loss: 5.34599053e-07
Iter: 485 loss: 5.332368e-07
Iter: 486 loss: 5.3316e-07
Iter: 487 loss: 5.33552452e-07
Iter: 488 loss: 5.33164723e-07
Iter: 489 loss: 5.33100376e-07
Iter: 490 loss: 5.33313766e-07
Iter: 491 loss: 5.33050411e-07
Iter: 492 loss: 5.32998513e-07
Iter: 493 loss: 5.32955937e-07
Iter: 494 loss: 5.32957358e-07
Iter: 495 loss: 5.32858394e-07
Iter: 496 loss: 5.33651587e-07
Iter: 497 loss: 5.32867091e-07
Iter: 498 loss: 5.327596e-07
Iter: 499 loss: 5.32726915e-07
Iter: 500 loss: 5.32674e-07
Iter: 501 loss: 5.32556953e-07
Iter: 502 loss: 5.33692855e-07
Iter: 503 loss: 5.32556214e-07
Iter: 504 loss: 5.32478055e-07
Iter: 505 loss: 5.32364481e-07
Iter: 506 loss: 5.32417857e-07
Iter: 507 loss: 5.32228626e-07
Iter: 508 loss: 5.32195884e-07
Iter: 509 loss: 5.3215e-07
Iter: 510 loss: 5.31961234e-07
Iter: 511 loss: 5.32894092e-07
Iter: 512 loss: 5.31955e-07
Iter: 513 loss: 5.31861929e-07
Iter: 514 loss: 5.32664671e-07
Iter: 515 loss: 5.31837202e-07
Iter: 516 loss: 5.31748924e-07
Iter: 517 loss: 5.31999206e-07
Iter: 518 loss: 5.31699811e-07
Iter: 519 loss: 5.31634043e-07
Iter: 520 loss: 5.31488638e-07
Iter: 521 loss: 5.34778565e-07
Iter: 522 loss: 5.3147744e-07
Iter: 523 loss: 5.3134238e-07
Iter: 524 loss: 5.32209754e-07
Iter: 525 loss: 5.31324304e-07
Iter: 526 loss: 5.31199078e-07
Iter: 527 loss: 5.31319472e-07
Iter: 528 loss: 5.31135e-07
Iter: 529 loss: 5.31029286e-07
Iter: 530 loss: 5.31023716e-07
Iter: 531 loss: 5.30939417e-07
Iter: 532 loss: 5.31097953e-07
Iter: 533 loss: 5.30898546e-07
Iter: 534 loss: 5.30824252e-07
Iter: 535 loss: 5.31190835e-07
Iter: 536 loss: 5.30768943e-07
Iter: 537 loss: 5.30750413e-07
Iter: 538 loss: 5.30963916e-07
Iter: 539 loss: 5.30712782e-07
Iter: 540 loss: 5.3067663e-07
Iter: 541 loss: 5.30572095e-07
Iter: 542 loss: 5.32654383e-07
Iter: 543 loss: 5.30578745e-07
Iter: 544 loss: 5.30486659e-07
Iter: 545 loss: 5.30504508e-07
Iter: 546 loss: 5.30407306e-07
Iter: 547 loss: 5.30365696e-07
Iter: 548 loss: 5.30373e-07
Iter: 549 loss: 5.30302e-07
Iter: 550 loss: 5.3093e-07
Iter: 551 loss: 5.30250304e-07
Iter: 552 loss: 5.30151169e-07
Iter: 553 loss: 5.30265652e-07
Iter: 554 loss: 5.3010865e-07
Iter: 555 loss: 5.30052091e-07
Iter: 556 loss: 5.29931413e-07
Iter: 557 loss: 5.29959493e-07
Iter: 558 loss: 5.29789e-07
Iter: 559 loss: 5.29999909e-07
Iter: 560 loss: 5.29723479e-07
Iter: 561 loss: 5.29628664e-07
Iter: 562 loss: 5.30031684e-07
Iter: 563 loss: 5.29566478e-07
Iter: 564 loss: 5.29460408e-07
Iter: 565 loss: 5.29666067e-07
Iter: 566 loss: 5.29407771e-07
Iter: 567 loss: 5.29335466e-07
Iter: 568 loss: 5.29299e-07
Iter: 569 loss: 5.29238e-07
Iter: 570 loss: 5.29151578e-07
Iter: 571 loss: 5.31118872e-07
Iter: 572 loss: 5.29146234e-07
Iter: 573 loss: 5.29053409e-07
Iter: 574 loss: 5.29059378e-07
Iter: 575 loss: 5.28956662e-07
Iter: 576 loss: 5.28819442e-07
Iter: 577 loss: 5.28835244e-07
Iter: 578 loss: 5.28686314e-07
Iter: 579 loss: 5.29661918e-07
Iter: 580 loss: 5.28718147e-07
Iter: 581 loss: 5.28576493e-07
Iter: 582 loss: 5.29192448e-07
Iter: 583 loss: 5.28563419e-07
Iter: 584 loss: 5.28492137e-07
Iter: 585 loss: 5.28490148e-07
Iter: 586 loss: 5.28448e-07
Iter: 587 loss: 5.28378905e-07
Iter: 588 loss: 5.2972473e-07
Iter: 589 loss: 5.28371629e-07
Iter: 590 loss: 5.2834514e-07
Iter: 591 loss: 5.2821747e-07
Iter: 592 loss: 5.29252e-07
Iter: 593 loss: 5.28224e-07
Iter: 594 loss: 5.28177793e-07
Iter: 595 loss: 5.28445071e-07
Iter: 596 loss: 5.28172166e-07
Iter: 597 loss: 5.28098042e-07
Iter: 598 loss: 5.28088719e-07
Iter: 599 loss: 5.28041e-07
Iter: 600 loss: 5.27958662e-07
Iter: 601 loss: 5.28435578e-07
Iter: 602 loss: 5.279785e-07
Iter: 603 loss: 5.27890109e-07
Iter: 604 loss: 5.28127657e-07
Iter: 605 loss: 5.27913699e-07
Iter: 606 loss: 5.27816837e-07
Iter: 607 loss: 5.27844691e-07
Iter: 608 loss: 5.27775796e-07
Iter: 609 loss: 5.27689735e-07
Iter: 610 loss: 5.28321209e-07
Iter: 611 loss: 5.27672796e-07
Iter: 612 loss: 5.27580369e-07
Iter: 613 loss: 5.27444172e-07
Iter: 614 loss: 5.27430302e-07
Iter: 615 loss: 5.27381644e-07
Iter: 616 loss: 5.28761461e-07
Iter: 617 loss: 5.27377608e-07
Iter: 618 loss: 5.27304849e-07
Iter: 619 loss: 5.27538759e-07
Iter: 620 loss: 5.27267048e-07
Iter: 621 loss: 5.27201109e-07
Iter: 622 loss: 5.27264319e-07
Iter: 623 loss: 5.27160068e-07
Iter: 624 loss: 5.27081e-07
Iter: 625 loss: 5.27446446e-07
Iter: 626 loss: 5.27071336e-07
Iter: 627 loss: 5.27021939e-07
Iter: 628 loss: 5.27011935e-07
Iter: 629 loss: 5.26961514e-07
Iter: 630 loss: 5.26922804e-07
Iter: 631 loss: 5.26991471e-07
Iter: 632 loss: 5.26890688e-07
Iter: 633 loss: 5.26816052e-07
Iter: 634 loss: 5.27195766e-07
Iter: 635 loss: 5.26807298e-07
Iter: 636 loss: 5.26748124e-07
Iter: 637 loss: 5.27208954e-07
Iter: 638 loss: 5.26739427e-07
Iter: 639 loss: 5.26702422e-07
Iter: 640 loss: 5.2666644e-07
Iter: 641 loss: 5.26653935e-07
Iter: 642 loss: 5.26598569e-07
Iter: 643 loss: 5.26988686e-07
Iter: 644 loss: 5.2656992e-07
Iter: 645 loss: 5.26498411e-07
Iter: 646 loss: 5.26555937e-07
Iter: 647 loss: 5.264734e-07
Iter: 648 loss: 5.26374663e-07
Iter: 649 loss: 5.26432473e-07
Iter: 650 loss: 5.26347e-07
Iter: 651 loss: 5.26293547e-07
Iter: 652 loss: 5.26998e-07
Iter: 653 loss: 5.26259555e-07
Iter: 654 loss: 5.26251767e-07
Iter: 655 loss: 5.26274221e-07
Iter: 656 loss: 5.26187478e-07
Iter: 657 loss: 5.26164285e-07
Iter: 658 loss: 5.26146891e-07
Iter: 659 loss: 5.26135182e-07
Iter: 660 loss: 5.26066856e-07
Iter: 661 loss: 5.26949066e-07
Iter: 662 loss: 5.26093061e-07
Iter: 663 loss: 5.26006261e-07
Iter: 664 loss: 5.26198619e-07
Iter: 665 loss: 5.25984e-07
Iter: 666 loss: 5.25933388e-07
Iter: 667 loss: 5.26158715e-07
Iter: 668 loss: 5.25895757e-07
Iter: 669 loss: 5.25886e-07
Iter: 670 loss: 5.26182362e-07
Iter: 671 loss: 5.25932762e-07
Iter: 672 loss: 5.25919859e-07
Iter: 673 loss: 5.25917471e-07
Iter: 674 loss: 5.25896e-07
Iter: 675 loss: 5.25914e-07
Iter: 676 loss: 5.25896553e-07
Iter: 677 loss: 5.25889448e-07
Iter: 678 loss: 5.25899281e-07
Iter: 679 loss: 5.25902e-07
Iter: 680 loss: 5.25903602e-07
Iter: 681 loss: 5.25908945e-07
Iter: 682 loss: 5.25916505e-07
Iter: 683 loss: 5.25920882e-07
Iter: 684 loss: 5.25898201e-07
Iter: 685 loss: 5.25889391e-07
Iter: 686 loss: 5.25899736e-07
Iter: 687 loss: 5.25894734e-07
Iter: 688 loss: 5.25897462e-07
Iter: 689 loss: 5.25896326e-07
Iter: 690 loss: 5.25895757e-07
Iter: 691 loss: 5.25895416e-07
Iter: 692 loss: 5.258957e-07
Iter: 693 loss: 5.25896041e-07
Iter: 694 loss: 5.25896326e-07
Iter: 695 loss: 5.25896098e-07
Iter: 696 loss: 5.25896098e-07
Iter: 697 loss: 5.25896326e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.8/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.2 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.2
+ date
Sat Nov  7 19:46:53 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi0.8/300_100_100_100_1 --function f1 --psi 0 --phi 1.2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.2/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f993d37a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f993d41da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f993d3b47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918e55620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918e55268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f993d3b4268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f993d337f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918d4f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918d4fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918d4f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918da42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918d8df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f45bea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f4617268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f462a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918d87488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918dd4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f458ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9918d7fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f458f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f4512598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f4508268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f4512d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f44ddea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f44546a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f43fbea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f43f97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f43fb158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f4335158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f43570d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f4369400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f431f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f431f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f4324ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f42dd1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98f42cec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0018639299
test_loss: 0.0017726222
train_loss: 0.0015656673
test_loss: 0.0017809367
train_loss: 0.0019321255
test_loss: 0.0013806229
train_loss: 0.0015576656
test_loss: 0.0015536044
train_loss: 0.0014806055
test_loss: 0.0015107894
train_loss: 0.002265349
test_loss: 0.0017450099
train_loss: 0.0013444826
test_loss: 0.0013938025
train_loss: 0.0014226884
test_loss: 0.0014111708
train_loss: 0.0014588439
test_loss: 0.0016241001
train_loss: 0.0014536495
test_loss: 0.0015017728
train_loss: 0.0013478608
test_loss: 0.0012727806
train_loss: 0.0013216926
test_loss: 0.001481956
train_loss: 0.0012950645
test_loss: 0.0013611085
train_loss: 0.0012928788
test_loss: 0.0012753772
train_loss: 0.0014090426
test_loss: 0.0013288064
train_loss: 0.0014641656
test_loss: 0.0013999671
train_loss: 0.0013502236
test_loss: 0.0011632178
train_loss: 0.0011021139
test_loss: 0.0011241899
train_loss: 0.0012537059
test_loss: 0.0014878485
train_loss: 0.00126905
test_loss: 0.0012289175
train_loss: 0.0013445785
test_loss: 0.0016293059
train_loss: 0.001152402
test_loss: 0.001556291
train_loss: 0.0011398179
test_loss: 0.0013901691
train_loss: 0.0012798914
test_loss: 0.0012486528
train_loss: 0.0011214607
test_loss: 0.0012444549
train_loss: 0.0013079161
test_loss: 0.0012031578
train_loss: 0.0012856432
test_loss: 0.0013165144
train_loss: 0.001110567
test_loss: 0.0013566648
train_loss: 0.0014442683
test_loss: 0.0013332329
train_loss: 0.0014569188
test_loss: 0.0013694555
train_loss: 0.0012743197
test_loss: 0.0012683771
train_loss: 0.0013111607
test_loss: 0.0011798238
train_loss: 0.0012079206
test_loss: 0.001127469
train_loss: 0.0015835421
test_loss: 0.0013391029
train_loss: 0.0012298606
test_loss: 0.0012366693
train_loss: 0.0010788166
test_loss: 0.0012095214
train_loss: 0.0012697858
test_loss: 0.0012156903
train_loss: 0.001153189
test_loss: 0.0014503553
train_loss: 0.0010290953
test_loss: 0.0011244756
train_loss: 0.0015390954
test_loss: 0.0012716131
train_loss: 0.0015270945
test_loss: 0.0011936135
train_loss: 0.0011919468
test_loss: 0.0012249094
train_loss: 0.0013533777
test_loss: 0.0011761555
train_loss: 0.0010807324
test_loss: 0.0012043644
train_loss: 0.001379899
test_loss: 0.0015361635
train_loss: 0.0014316998
test_loss: 0.0012904984
train_loss: 0.0013309224
test_loss: 0.0011003799
train_loss: 0.0011234595
test_loss: 0.0013929671
train_loss: 0.0012257952
test_loss: 0.0015178467
train_loss: 0.0010775115
test_loss: 0.0012528924
train_loss: 0.001277774
test_loss: 0.0012127819
train_loss: 0.001147796
test_loss: 0.0010717417
train_loss: 0.0015501259
test_loss: 0.0015222062
train_loss: 0.0014546508
test_loss: 0.0015637251
train_loss: 0.0010511606
test_loss: 0.0011539838
train_loss: 0.0022628005
test_loss: 0.0014783628
train_loss: 0.001342573
test_loss: 0.0011215544
train_loss: 0.0011739188
test_loss: 0.0011438065
train_loss: 0.0011852174
test_loss: 0.0010719665
train_loss: 0.0013492876
test_loss: 0.0012920274
train_loss: 0.0011763609
test_loss: 0.0010058424
train_loss: 0.0010765855
test_loss: 0.0011760673
train_loss: 0.0010262022
test_loss: 0.0011394718
train_loss: 0.0011349802
test_loss: 0.0011348401
train_loss: 0.0010824009
test_loss: 0.0011920936
train_loss: 0.001149291
test_loss: 0.0011247848
train_loss: 0.001183159
test_loss: 0.0013197444
train_loss: 0.0019349072
test_loss: 0.0015363414
train_loss: 0.0013417235
test_loss: 0.0012638029
train_loss: 0.0013297922
test_loss: 0.0010566495
train_loss: 0.0012700248
test_loss: 0.0012557217
train_loss: 0.0010810769
test_loss: 0.0012448484
train_loss: 0.0011601554
test_loss: 0.0012061202
train_loss: 0.0012387532
test_loss: 0.0013689861
train_loss: 0.0011295145
test_loss: 0.0012580995
train_loss: 0.0014023418
test_loss: 0.0012064372
train_loss: 0.0012888408
test_loss: 0.0012226555
train_loss: 0.0012529063
test_loss: 0.0012651335
train_loss: 0.0013242267
test_loss: 0.0012666368
train_loss: 0.0011155705
test_loss: 0.0013470037
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.2/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.2/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c49aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c4508c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c50d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c3fd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c3fd158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c50d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c375510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c343840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c343268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c2fc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c2fc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c2bce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c2dbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c28e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c29ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c29e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c25abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c1e5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c25aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c1cb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c18d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c1462f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c12d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c13cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c0f3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c0e0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c0b0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c0e0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c02e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c0500d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f960c04a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f95f00c11e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f95f00b66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f95f00629d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f95f0019268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f95947c9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.74959871e-06
Iter: 2 loss: 1.88576687e-05
Iter: 3 loss: 1.50286303e-06
Iter: 4 loss: 1.27047474e-06
Iter: 5 loss: 2.07788162e-06
Iter: 6 loss: 1.20962204e-06
Iter: 7 loss: 1.09062216e-06
Iter: 8 loss: 1.73938906e-06
Iter: 9 loss: 1.07315009e-06
Iter: 10 loss: 9.9563e-07
Iter: 11 loss: 8.89564149e-07
Iter: 12 loss: 8.84573069e-07
Iter: 13 loss: 8.76639433e-07
Iter: 14 loss: 8.33896934e-07
Iter: 15 loss: 8.12517e-07
Iter: 16 loss: 7.79017569e-07
Iter: 17 loss: 7.78629e-07
Iter: 18 loss: 7.63423714e-07
Iter: 19 loss: 7.61300271e-07
Iter: 20 loss: 7.50858533e-07
Iter: 21 loss: 7.41246e-07
Iter: 22 loss: 7.38672327e-07
Iter: 23 loss: 7.21604749e-07
Iter: 24 loss: 7.28954433e-07
Iter: 25 loss: 7.09970664e-07
Iter: 26 loss: 6.93588e-07
Iter: 27 loss: 7.33004185e-07
Iter: 28 loss: 6.87697138e-07
Iter: 29 loss: 6.74427667e-07
Iter: 30 loss: 7.49246624e-07
Iter: 31 loss: 6.72567126e-07
Iter: 32 loss: 6.61658873e-07
Iter: 33 loss: 7.22367076e-07
Iter: 34 loss: 6.60065325e-07
Iter: 35 loss: 6.53440793e-07
Iter: 36 loss: 6.59933903e-07
Iter: 37 loss: 6.49684409e-07
Iter: 38 loss: 6.4459e-07
Iter: 39 loss: 6.4373296e-07
Iter: 40 loss: 6.41148574e-07
Iter: 41 loss: 6.41267889e-07
Iter: 42 loss: 6.3906765e-07
Iter: 43 loss: 6.35288302e-07
Iter: 44 loss: 6.48791115e-07
Iter: 45 loss: 6.3434527e-07
Iter: 46 loss: 6.31244404e-07
Iter: 47 loss: 6.31200237e-07
Iter: 48 loss: 6.28749092e-07
Iter: 49 loss: 6.25563e-07
Iter: 50 loss: 6.25546249e-07
Iter: 51 loss: 6.23660583e-07
Iter: 52 loss: 6.19437287e-07
Iter: 53 loss: 6.77351693e-07
Iter: 54 loss: 6.19116463e-07
Iter: 55 loss: 6.15669819e-07
Iter: 56 loss: 6.15663e-07
Iter: 57 loss: 6.12486e-07
Iter: 58 loss: 6.10910831e-07
Iter: 59 loss: 6.09350252e-07
Iter: 60 loss: 6.06046342e-07
Iter: 61 loss: 6.08578375e-07
Iter: 62 loss: 6.0399384e-07
Iter: 63 loss: 5.99121961e-07
Iter: 64 loss: 6.05681635e-07
Iter: 65 loss: 5.96638358e-07
Iter: 66 loss: 5.91792684e-07
Iter: 67 loss: 5.96616474e-07
Iter: 68 loss: 5.89015258e-07
Iter: 69 loss: 5.87339173e-07
Iter: 70 loss: 5.86558031e-07
Iter: 71 loss: 5.84935663e-07
Iter: 72 loss: 6.04703e-07
Iter: 73 loss: 5.84934583e-07
Iter: 74 loss: 5.83821361e-07
Iter: 75 loss: 5.8248753e-07
Iter: 76 loss: 5.82301652e-07
Iter: 77 loss: 5.80775577e-07
Iter: 78 loss: 5.98850193e-07
Iter: 79 loss: 5.8077876e-07
Iter: 80 loss: 5.79523089e-07
Iter: 81 loss: 5.77304263e-07
Iter: 82 loss: 6.2905815e-07
Iter: 83 loss: 5.77314495e-07
Iter: 84 loss: 5.75993226e-07
Iter: 85 loss: 5.75772617e-07
Iter: 86 loss: 5.74728915e-07
Iter: 87 loss: 5.72255374e-07
Iter: 88 loss: 6.01207603e-07
Iter: 89 loss: 5.72017029e-07
Iter: 90 loss: 5.71213377e-07
Iter: 91 loss: 5.70926943e-07
Iter: 92 loss: 5.69912459e-07
Iter: 93 loss: 5.68350288e-07
Iter: 94 loss: 5.6832306e-07
Iter: 95 loss: 5.66425683e-07
Iter: 96 loss: 5.71135047e-07
Iter: 97 loss: 5.65741516e-07
Iter: 98 loss: 5.64446452e-07
Iter: 99 loss: 5.62979835e-07
Iter: 100 loss: 5.62859e-07
Iter: 101 loss: 5.61441539e-07
Iter: 102 loss: 5.61459217e-07
Iter: 103 loss: 5.60535227e-07
Iter: 104 loss: 5.61110483e-07
Iter: 105 loss: 5.59994362e-07
Iter: 106 loss: 5.59084185e-07
Iter: 107 loss: 5.72565909e-07
Iter: 108 loss: 5.59099476e-07
Iter: 109 loss: 5.5838558e-07
Iter: 110 loss: 5.58242107e-07
Iter: 111 loss: 5.5780572e-07
Iter: 112 loss: 5.56727741e-07
Iter: 113 loss: 5.61476895e-07
Iter: 114 loss: 5.56508326e-07
Iter: 115 loss: 5.55713541e-07
Iter: 116 loss: 5.57042483e-07
Iter: 117 loss: 5.55340193e-07
Iter: 118 loss: 5.54685073e-07
Iter: 119 loss: 5.62315563e-07
Iter: 120 loss: 5.54688427e-07
Iter: 121 loss: 5.54208611e-07
Iter: 122 loss: 5.53074642e-07
Iter: 123 loss: 5.6805527e-07
Iter: 124 loss: 5.53002849e-07
Iter: 125 loss: 5.51906282e-07
Iter: 126 loss: 5.60240437e-07
Iter: 127 loss: 5.51796859e-07
Iter: 128 loss: 5.50963932e-07
Iter: 129 loss: 5.59321165e-07
Iter: 130 loss: 5.50889126e-07
Iter: 131 loss: 5.50449158e-07
Iter: 132 loss: 5.49480376e-07
Iter: 133 loss: 5.63413e-07
Iter: 134 loss: 5.49435583e-07
Iter: 135 loss: 5.48434855e-07
Iter: 136 loss: 5.59541263e-07
Iter: 137 loss: 5.48407058e-07
Iter: 138 loss: 5.47935656e-07
Iter: 139 loss: 5.51326536e-07
Iter: 140 loss: 5.47937134e-07
Iter: 141 loss: 5.47528884e-07
Iter: 142 loss: 5.50774303e-07
Iter: 143 loss: 5.47512172e-07
Iter: 144 loss: 5.47169918e-07
Iter: 145 loss: 5.47435e-07
Iter: 146 loss: 5.46968e-07
Iter: 147 loss: 5.46645083e-07
Iter: 148 loss: 5.482284e-07
Iter: 149 loss: 5.46577e-07
Iter: 150 loss: 5.46240585e-07
Iter: 151 loss: 5.46292881e-07
Iter: 152 loss: 5.46028957e-07
Iter: 153 loss: 5.45675448e-07
Iter: 154 loss: 5.48723506e-07
Iter: 155 loss: 5.45662829e-07
Iter: 156 loss: 5.45380431e-07
Iter: 157 loss: 5.4536406e-07
Iter: 158 loss: 5.45096782e-07
Iter: 159 loss: 5.44789827e-07
Iter: 160 loss: 5.44752879e-07
Iter: 161 loss: 5.44501859e-07
Iter: 162 loss: 5.44071327e-07
Iter: 163 loss: 5.47117111e-07
Iter: 164 loss: 5.43982765e-07
Iter: 165 loss: 5.43485612e-07
Iter: 166 loss: 5.44022441e-07
Iter: 167 loss: 5.43148872e-07
Iter: 168 loss: 5.42683892e-07
Iter: 169 loss: 5.41919349e-07
Iter: 170 loss: 5.41919349e-07
Iter: 171 loss: 5.41061183e-07
Iter: 172 loss: 5.4888568e-07
Iter: 173 loss: 5.41011e-07
Iter: 174 loss: 5.40505823e-07
Iter: 175 loss: 5.40470865e-07
Iter: 176 loss: 5.4006523e-07
Iter: 177 loss: 5.40027258e-07
Iter: 178 loss: 5.39692621e-07
Iter: 179 loss: 5.39198197e-07
Iter: 180 loss: 5.4112428e-07
Iter: 181 loss: 5.3910486e-07
Iter: 182 loss: 5.38536597e-07
Iter: 183 loss: 5.39840585e-07
Iter: 184 loss: 5.38364475e-07
Iter: 185 loss: 5.37942924e-07
Iter: 186 loss: 5.39230484e-07
Iter: 187 loss: 5.37830601e-07
Iter: 188 loss: 5.37399217e-07
Iter: 189 loss: 5.38955362e-07
Iter: 190 loss: 5.37278652e-07
Iter: 191 loss: 5.36859147e-07
Iter: 192 loss: 5.36740231e-07
Iter: 193 loss: 5.36511e-07
Iter: 194 loss: 5.36175605e-07
Iter: 195 loss: 5.37748406e-07
Iter: 196 loss: 5.36102789e-07
Iter: 197 loss: 5.35732283e-07
Iter: 198 loss: 5.38433142e-07
Iter: 199 loss: 5.35701872e-07
Iter: 200 loss: 5.35487629e-07
Iter: 201 loss: 5.35196136e-07
Iter: 202 loss: 5.35176298e-07
Iter: 203 loss: 5.34760147e-07
Iter: 204 loss: 5.35505251e-07
Iter: 205 loss: 5.34584842e-07
Iter: 206 loss: 5.34297101e-07
Iter: 207 loss: 5.37014444e-07
Iter: 208 loss: 5.34232129e-07
Iter: 209 loss: 5.33926141e-07
Iter: 210 loss: 5.36837717e-07
Iter: 211 loss: 5.33910338e-07
Iter: 212 loss: 5.33787e-07
Iter: 213 loss: 5.3356365e-07
Iter: 214 loss: 5.33548132e-07
Iter: 215 loss: 5.33167565e-07
Iter: 216 loss: 5.34850756e-07
Iter: 217 loss: 5.33083494e-07
Iter: 218 loss: 5.32780689e-07
Iter: 219 loss: 5.33244531e-07
Iter: 220 loss: 5.32618685e-07
Iter: 221 loss: 5.3235749e-07
Iter: 222 loss: 5.34633557e-07
Iter: 223 loss: 5.32306444e-07
Iter: 224 loss: 5.32079071e-07
Iter: 225 loss: 5.31672583e-07
Iter: 226 loss: 5.31667183e-07
Iter: 227 loss: 5.31260469e-07
Iter: 228 loss: 5.33169668e-07
Iter: 229 loss: 5.31176624e-07
Iter: 230 loss: 5.30904288e-07
Iter: 231 loss: 5.34074388e-07
Iter: 232 loss: 5.30908267e-07
Iter: 233 loss: 5.30698856e-07
Iter: 234 loss: 5.30765419e-07
Iter: 235 loss: 5.30542877e-07
Iter: 236 loss: 5.30272359e-07
Iter: 237 loss: 5.29983e-07
Iter: 238 loss: 5.29895033e-07
Iter: 239 loss: 5.29568183e-07
Iter: 240 loss: 5.32538138e-07
Iter: 241 loss: 5.29504177e-07
Iter: 242 loss: 5.29511226e-07
Iter: 243 loss: 5.29430736e-07
Iter: 244 loss: 5.29326769e-07
Iter: 245 loss: 5.2912651e-07
Iter: 246 loss: 5.31519277e-07
Iter: 247 loss: 5.29094677e-07
Iter: 248 loss: 5.2880614e-07
Iter: 249 loss: 5.30385364e-07
Iter: 250 loss: 5.28781925e-07
Iter: 251 loss: 5.28502596e-07
Iter: 252 loss: 5.2890681e-07
Iter: 253 loss: 5.28371686e-07
Iter: 254 loss: 5.28242936e-07
Iter: 255 loss: 5.29829833e-07
Iter: 256 loss: 5.28238388e-07
Iter: 257 loss: 5.28037162e-07
Iter: 258 loss: 5.27910572e-07
Iter: 259 loss: 5.27841848e-07
Iter: 260 loss: 5.27645852e-07
Iter: 261 loss: 5.27753912e-07
Iter: 262 loss: 5.27476175e-07
Iter: 263 loss: 5.27218731e-07
Iter: 264 loss: 5.2976128e-07
Iter: 265 loss: 5.27243685e-07
Iter: 266 loss: 5.27099e-07
Iter: 267 loss: 5.27627094e-07
Iter: 268 loss: 5.27058148e-07
Iter: 269 loss: 5.26924225e-07
Iter: 270 loss: 5.26754e-07
Iter: 271 loss: 5.267446e-07
Iter: 272 loss: 5.26525355e-07
Iter: 273 loss: 5.26899157e-07
Iter: 274 loss: 5.2642423e-07
Iter: 275 loss: 5.26279791e-07
Iter: 276 loss: 5.26272743e-07
Iter: 277 loss: 5.26118356e-07
Iter: 278 loss: 5.26029282e-07
Iter: 279 loss: 5.2596863e-07
Iter: 280 loss: 5.25772236e-07
Iter: 281 loss: 5.26455949e-07
Iter: 282 loss: 5.25727614e-07
Iter: 283 loss: 5.25512405e-07
Iter: 284 loss: 5.25947144e-07
Iter: 285 loss: 5.25412304e-07
Iter: 286 loss: 5.25258713e-07
Iter: 287 loss: 5.25279575e-07
Iter: 288 loss: 5.25124733e-07
Iter: 289 loss: 5.24798509e-07
Iter: 290 loss: 5.26623126e-07
Iter: 291 loss: 5.24779466e-07
Iter: 292 loss: 5.24658503e-07
Iter: 293 loss: 5.24377924e-07
Iter: 294 loss: 5.24348252e-07
Iter: 295 loss: 5.24071311e-07
Iter: 296 loss: 5.26362328e-07
Iter: 297 loss: 5.24074835e-07
Iter: 298 loss: 5.23870881e-07
Iter: 299 loss: 5.25449536e-07
Iter: 300 loss: 5.23823701e-07
Iter: 301 loss: 5.23685401e-07
Iter: 302 loss: 5.23470703e-07
Iter: 303 loss: 5.23423864e-07
Iter: 304 loss: 5.23244807e-07
Iter: 305 loss: 5.24035443e-07
Iter: 306 loss: 5.23197684e-07
Iter: 307 loss: 5.22929042e-07
Iter: 308 loss: 5.24720406e-07
Iter: 309 loss: 5.22968207e-07
Iter: 310 loss: 5.22792391e-07
Iter: 311 loss: 5.2471205e-07
Iter: 312 loss: 5.22780795e-07
Iter: 313 loss: 5.22696496e-07
Iter: 314 loss: 5.22599407e-07
Iter: 315 loss: 5.22584628e-07
Iter: 316 loss: 5.22443088e-07
Iter: 317 loss: 5.2440123e-07
Iter: 318 loss: 5.22447237e-07
Iter: 319 loss: 5.22358732e-07
Iter: 320 loss: 5.22264315e-07
Iter: 321 loss: 5.22226685e-07
Iter: 322 loss: 5.22101914e-07
Iter: 323 loss: 5.23856556e-07
Iter: 324 loss: 5.2211351e-07
Iter: 325 loss: 5.21988454e-07
Iter: 326 loss: 5.21903701e-07
Iter: 327 loss: 5.21863285e-07
Iter: 328 loss: 5.21758125e-07
Iter: 329 loss: 5.21983679e-07
Iter: 330 loss: 5.21688492e-07
Iter: 331 loss: 5.21523248e-07
Iter: 332 loss: 5.23351673e-07
Iter: 333 loss: 5.2153058e-07
Iter: 334 loss: 5.21425306e-07
Iter: 335 loss: 5.21300478e-07
Iter: 336 loss: 5.21291156e-07
Iter: 337 loss: 5.21052e-07
Iter: 338 loss: 5.21086463e-07
Iter: 339 loss: 5.20899789e-07
Iter: 340 loss: 5.20582432e-07
Iter: 341 loss: 5.22362257e-07
Iter: 342 loss: 5.20532069e-07
Iter: 343 loss: 5.20443621e-07
Iter: 344 loss: 5.20432081e-07
Iter: 345 loss: 5.20292872e-07
Iter: 346 loss: 5.20027584e-07
Iter: 347 loss: 5.22683195e-07
Iter: 348 loss: 5.19978471e-07
Iter: 349 loss: 5.19812659e-07
Iter: 350 loss: 5.19803848e-07
Iter: 351 loss: 5.19690502e-07
Iter: 352 loss: 5.19480466e-07
Iter: 353 loss: 5.19472337e-07
Iter: 354 loss: 5.19273499e-07
Iter: 355 loss: 5.21836e-07
Iter: 356 loss: 5.19279354e-07
Iter: 357 loss: 5.19146681e-07
Iter: 358 loss: 5.19104958e-07
Iter: 359 loss: 5.19021739e-07
Iter: 360 loss: 5.18822276e-07
Iter: 361 loss: 5.18943182e-07
Iter: 362 loss: 5.18662432e-07
Iter: 363 loss: 5.1854812e-07
Iter: 364 loss: 5.1853408e-07
Iter: 365 loss: 5.18379807e-07
Iter: 366 loss: 5.18397542e-07
Iter: 367 loss: 5.1832177e-07
Iter: 368 loss: 5.18095703e-07
Iter: 369 loss: 5.18308866e-07
Iter: 370 loss: 5.18007653e-07
Iter: 371 loss: 5.17826606e-07
Iter: 372 loss: 5.18182446e-07
Iter: 373 loss: 5.17760213e-07
Iter: 374 loss: 5.17687454e-07
Iter: 375 loss: 5.17667445e-07
Iter: 376 loss: 5.1755967e-07
Iter: 377 loss: 5.1756308e-07
Iter: 378 loss: 5.17484523e-07
Iter: 379 loss: 5.1741489e-07
Iter: 380 loss: 5.17647e-07
Iter: 381 loss: 5.17346905e-07
Iter: 382 loss: 5.17214346e-07
Iter: 383 loss: 5.17852641e-07
Iter: 384 loss: 5.17178421e-07
Iter: 385 loss: 5.17107821e-07
Iter: 386 loss: 5.1712766e-07
Iter: 387 loss: 5.17008459e-07
Iter: 388 loss: 5.16880107e-07
Iter: 389 loss: 5.17291539e-07
Iter: 390 loss: 5.16804448e-07
Iter: 391 loss: 5.16726686e-07
Iter: 392 loss: 5.16489649e-07
Iter: 393 loss: 5.21506195e-07
Iter: 394 loss: 5.16511875e-07
Iter: 395 loss: 5.16341345e-07
Iter: 396 loss: 5.16354589e-07
Iter: 397 loss: 5.16177693e-07
Iter: 398 loss: 5.16471232e-07
Iter: 399 loss: 5.16106297e-07
Iter: 400 loss: 5.15971578e-07
Iter: 401 loss: 5.16012e-07
Iter: 402 loss: 5.15852719e-07
Iter: 403 loss: 5.15667523e-07
Iter: 404 loss: 5.1568253e-07
Iter: 405 loss: 5.15567137e-07
Iter: 406 loss: 5.15402e-07
Iter: 407 loss: 5.15398938e-07
Iter: 408 loss: 5.15277634e-07
Iter: 409 loss: 5.16862542e-07
Iter: 410 loss: 5.15296108e-07
Iter: 411 loss: 5.15218517e-07
Iter: 412 loss: 5.15101533e-07
Iter: 413 loss: 5.17378396e-07
Iter: 414 loss: 5.15094541e-07
Iter: 415 loss: 5.15030877e-07
Iter: 416 loss: 5.15022293e-07
Iter: 417 loss: 5.14969e-07
Iter: 418 loss: 5.14877797e-07
Iter: 419 loss: 5.1487433e-07
Iter: 420 loss: 5.14820556e-07
Iter: 421 loss: 5.14816236e-07
Iter: 422 loss: 5.14779401e-07
Iter: 423 loss: 5.14707267e-07
Iter: 424 loss: 5.1471909e-07
Iter: 425 loss: 5.14603812e-07
Iter: 426 loss: 5.14845283e-07
Iter: 427 loss: 5.14577607e-07
Iter: 428 loss: 5.14456076e-07
Iter: 429 loss: 5.15857664e-07
Iter: 430 loss: 5.14436692e-07
Iter: 431 loss: 5.14407077e-07
Iter: 432 loss: 5.14266958e-07
Iter: 433 loss: 5.14307658e-07
Iter: 434 loss: 5.14133717e-07
Iter: 435 loss: 5.14284068e-07
Iter: 436 loss: 5.14078238e-07
Iter: 437 loss: 5.13893951e-07
Iter: 438 loss: 5.14508031e-07
Iter: 439 loss: 5.13825285e-07
Iter: 440 loss: 5.13720238e-07
Iter: 441 loss: 5.13715236e-07
Iter: 442 loss: 5.13601321e-07
Iter: 443 loss: 5.13395662e-07
Iter: 444 loss: 5.17856051e-07
Iter: 445 loss: 5.1340345e-07
Iter: 446 loss: 5.13276632e-07
Iter: 447 loss: 5.14980115e-07
Iter: 448 loss: 5.13249802e-07
Iter: 449 loss: 5.13109057e-07
Iter: 450 loss: 5.13436817e-07
Iter: 451 loss: 5.13042892e-07
Iter: 452 loss: 5.12988834e-07
Iter: 453 loss: 5.13207453e-07
Iter: 454 loss: 5.12934776e-07
Iter: 455 loss: 5.12858264e-07
Iter: 456 loss: 5.13654641e-07
Iter: 457 loss: 5.12855138e-07
Iter: 458 loss: 5.12786187e-07
Iter: 459 loss: 5.12675e-07
Iter: 460 loss: 5.14477676e-07
Iter: 461 loss: 5.1264027e-07
Iter: 462 loss: 5.12556198e-07
Iter: 463 loss: 5.13467342e-07
Iter: 464 loss: 5.12550173e-07
Iter: 465 loss: 5.12493102e-07
Iter: 466 loss: 5.12490374e-07
Iter: 467 loss: 5.12425572e-07
Iter: 468 loss: 5.12366967e-07
Iter: 469 loss: 5.12358497e-07
Iter: 470 loss: 5.12263796e-07
Iter: 471 loss: 5.1225561e-07
Iter: 472 loss: 5.12193196e-07
Iter: 473 loss: 5.1210759e-07
Iter: 474 loss: 5.12084398e-07
Iter: 475 loss: 5.12051599e-07
Iter: 476 loss: 5.11965595e-07
Iter: 477 loss: 5.11934161e-07
Iter: 478 loss: 5.11842813e-07
Iter: 479 loss: 5.11976396e-07
Iter: 480 loss: 5.11783355e-07
Iter: 481 loss: 5.11726398e-07
Iter: 482 loss: 5.11744304e-07
Iter: 483 loss: 5.11642043e-07
Iter: 484 loss: 5.11591111e-07
Iter: 485 loss: 5.11577923e-07
Iter: 486 loss: 5.11446274e-07
Iter: 487 loss: 5.12615884e-07
Iter: 488 loss: 5.11503117e-07
Iter: 489 loss: 5.11391193e-07
Iter: 490 loss: 5.11285123e-07
Iter: 491 loss: 5.14398948e-07
Iter: 492 loss: 5.11301948e-07
Iter: 493 loss: 5.11127951e-07
Iter: 494 loss: 5.11434e-07
Iter: 495 loss: 5.11047404e-07
Iter: 496 loss: 5.10943e-07
Iter: 497 loss: 5.11721396e-07
Iter: 498 loss: 5.10940083e-07
Iter: 499 loss: 5.10810594e-07
Iter: 500 loss: 5.11996859e-07
Iter: 501 loss: 5.10820826e-07
Iter: 502 loss: 5.10739e-07
Iter: 503 loss: 5.10547e-07
Iter: 504 loss: 5.12346e-07
Iter: 505 loss: 5.10535187e-07
Iter: 506 loss: 5.10485e-07
Iter: 507 loss: 5.10433779e-07
Iter: 508 loss: 5.10358404e-07
Iter: 509 loss: 5.10380517e-07
Iter: 510 loss: 5.10285247e-07
Iter: 511 loss: 5.10196344e-07
Iter: 512 loss: 5.10191455e-07
Iter: 513 loss: 5.10106247e-07
Iter: 514 loss: 5.09992958e-07
Iter: 515 loss: 5.10746759e-07
Iter: 516 loss: 5.09925769e-07
Iter: 517 loss: 5.0983266e-07
Iter: 518 loss: 5.10003076e-07
Iter: 519 loss: 5.09753932e-07
Iter: 520 loss: 5.0963871e-07
Iter: 521 loss: 5.10191114e-07
Iter: 522 loss: 5.09604206e-07
Iter: 523 loss: 5.09524057e-07
Iter: 524 loss: 5.10039968e-07
Iter: 525 loss: 5.09492565e-07
Iter: 526 loss: 5.0939218e-07
Iter: 527 loss: 5.09358131e-07
Iter: 528 loss: 5.09378822e-07
Iter: 529 loss: 5.0929e-07
Iter: 530 loss: 5.09391384e-07
Iter: 531 loss: 5.0924541e-07
Iter: 532 loss: 5.09168842e-07
Iter: 533 loss: 5.0915537e-07
Iter: 534 loss: 5.09088295e-07
Iter: 535 loss: 5.09071469e-07
Iter: 536 loss: 5.09056918e-07
Iter: 537 loss: 5.09012295e-07
Iter: 538 loss: 5.0924757e-07
Iter: 539 loss: 5.08982453e-07
Iter: 540 loss: 5.08933226e-07
Iter: 541 loss: 5.09575102e-07
Iter: 542 loss: 5.08932089e-07
Iter: 543 loss: 5.08898e-07
Iter: 544 loss: 5.08846881e-07
Iter: 545 loss: 5.09999e-07
Iter: 546 loss: 5.08874791e-07
Iter: 547 loss: 5.08808796e-07
Iter: 548 loss: 5.09081417e-07
Iter: 549 loss: 5.08775315e-07
Iter: 550 loss: 5.08682831e-07
Iter: 551 loss: 5.09003371e-07
Iter: 552 loss: 5.08689141e-07
Iter: 553 loss: 5.08632411e-07
Iter: 554 loss: 5.08610924e-07
Iter: 555 loss: 5.08534129e-07
Iter: 556 loss: 5.08467451e-07
Iter: 557 loss: 5.09041456e-07
Iter: 558 loss: 5.08442952e-07
Iter: 559 loss: 5.08354e-07
Iter: 560 loss: 5.08227629e-07
Iter: 561 loss: 5.08201765e-07
Iter: 562 loss: 5.08111157e-07
Iter: 563 loss: 5.08097173e-07
Iter: 564 loss: 5.07961829e-07
Iter: 565 loss: 5.07859113e-07
Iter: 566 loss: 5.08927258e-07
Iter: 567 loss: 5.07834784e-07
Iter: 568 loss: 5.0771996e-07
Iter: 569 loss: 5.08930668e-07
Iter: 570 loss: 5.07702907e-07
Iter: 571 loss: 5.07648281e-07
Iter: 572 loss: 5.07581603e-07
Iter: 573 loss: 5.0757177e-07
Iter: 574 loss: 5.07511913e-07
Iter: 575 loss: 5.07527147e-07
Iter: 576 loss: 5.07452569e-07
Iter: 577 loss: 5.07345e-07
Iter: 578 loss: 5.07346954e-07
Iter: 579 loss: 5.0726203e-07
Iter: 580 loss: 5.07385323e-07
Iter: 581 loss: 5.07258051e-07
Iter: 582 loss: 5.07157154e-07
Iter: 583 loss: 5.07169034e-07
Iter: 584 loss: 5.07105e-07
Iter: 585 loss: 5.07058189e-07
Iter: 586 loss: 5.07047901e-07
Iter: 587 loss: 5.06973265e-07
Iter: 588 loss: 5.07268851e-07
Iter: 589 loss: 5.06927449e-07
Iter: 590 loss: 5.0682263e-07
Iter: 591 loss: 5.07020616e-07
Iter: 592 loss: 5.0681092e-07
Iter: 593 loss: 5.0669064e-07
Iter: 594 loss: 5.06662559e-07
Iter: 595 loss: 5.06629306e-07
Iter: 596 loss: 5.06506694e-07
Iter: 597 loss: 5.06609524e-07
Iter: 598 loss: 5.0641097e-07
Iter: 599 loss: 5.06271363e-07
Iter: 600 loss: 5.07360596e-07
Iter: 601 loss: 5.06265678e-07
Iter: 602 loss: 5.06203151e-07
Iter: 603 loss: 5.06205879e-07
Iter: 604 loss: 5.06109473e-07
Iter: 605 loss: 5.06010622e-07
Iter: 606 loss: 5.0817124e-07
Iter: 607 loss: 5.06017898e-07
Iter: 608 loss: 5.06026254e-07
Iter: 609 loss: 5.05985099e-07
Iter: 610 loss: 5.05918479e-07
Iter: 611 loss: 5.05837647e-07
Iter: 612 loss: 5.07317168e-07
Iter: 613 loss: 5.0588244e-07
Iter: 614 loss: 5.05759942e-07
Iter: 615 loss: 5.06139202e-07
Iter: 616 loss: 5.05748631e-07
Iter: 617 loss: 5.05638809e-07
Iter: 618 loss: 5.05857486e-07
Iter: 619 loss: 5.05564742e-07
Iter: 620 loss: 5.05482546e-07
Iter: 621 loss: 5.05612e-07
Iter: 622 loss: 5.05411037e-07
Iter: 623 loss: 5.05304683e-07
Iter: 624 loss: 5.05518074e-07
Iter: 625 loss: 5.0525864e-07
Iter: 626 loss: 5.05197931e-07
Iter: 627 loss: 5.05288256e-07
Iter: 628 loss: 5.05100274e-07
Iter: 629 loss: 5.05013361e-07
Iter: 630 loss: 5.05337596e-07
Iter: 631 loss: 5.0500438e-07
Iter: 632 loss: 5.04867728e-07
Iter: 633 loss: 5.04954187e-07
Iter: 634 loss: 5.04855507e-07
Iter: 635 loss: 5.0471192e-07
Iter: 636 loss: 5.0555559e-07
Iter: 637 loss: 5.04713796e-07
Iter: 638 loss: 5.04657578e-07
Iter: 639 loss: 5.05512389e-07
Iter: 640 loss: 5.04649847e-07
Iter: 641 loss: 5.04573336e-07
Iter: 642 loss: 5.04496654e-07
Iter: 643 loss: 5.07157665e-07
Iter: 644 loss: 5.04479203e-07
Iter: 645 loss: 5.04435661e-07
Iter: 646 loss: 5.04425429e-07
Iter: 647 loss: 5.04346e-07
Iter: 648 loss: 5.04357786e-07
Iter: 649 loss: 5.04267632e-07
Iter: 650 loss: 5.0419527e-07
Iter: 651 loss: 5.04131208e-07
Iter: 652 loss: 5.04098352e-07
Iter: 653 loss: 5.04006152e-07
Iter: 654 loss: 5.04653485e-07
Iter: 655 loss: 5.03966248e-07
Iter: 656 loss: 5.03872229e-07
Iter: 657 loss: 5.04551e-07
Iter: 658 loss: 5.03905483e-07
Iter: 659 loss: 5.03796514e-07
Iter: 660 loss: 5.03773435e-07
Iter: 661 loss: 5.03774288e-07
Iter: 662 loss: 5.03646902e-07
Iter: 663 loss: 5.04198965e-07
Iter: 664 loss: 5.03648039e-07
Iter: 665 loss: 5.03555043e-07
Iter: 666 loss: 5.03910712e-07
Iter: 667 loss: 5.03532533e-07
Iter: 668 loss: 5.03448064e-07
Iter: 669 loss: 5.03547824e-07
Iter: 670 loss: 5.03399065e-07
Iter: 671 loss: 5.03347e-07
Iter: 672 loss: 5.03310162e-07
Iter: 673 loss: 5.0328407e-07
Iter: 674 loss: 5.03149408e-07
Iter: 675 loss: 5.03705451e-07
Iter: 676 loss: 5.03181809e-07
Iter: 677 loss: 5.03060505e-07
Iter: 678 loss: 5.03848696e-07
Iter: 679 loss: 5.03072727e-07
Iter: 680 loss: 5.02999114e-07
Iter: 681 loss: 5.02993316e-07
Iter: 682 loss: 5.02962962e-07
Iter: 683 loss: 5.02870535e-07
Iter: 684 loss: 5.02904129e-07
Iter: 685 loss: 5.02836542e-07
Iter: 686 loss: 5.0270728e-07
Iter: 687 loss: 5.03538956e-07
Iter: 688 loss: 5.02704381e-07
Iter: 689 loss: 5.02623152e-07
Iter: 690 loss: 5.03149465e-07
Iter: 691 loss: 5.02596379e-07
Iter: 692 loss: 5.02497073e-07
Iter: 693 loss: 5.02828e-07
Iter: 694 loss: 5.02449325e-07
Iter: 695 loss: 5.0238566e-07
Iter: 696 loss: 5.03065849e-07
Iter: 697 loss: 5.02395778e-07
Iter: 698 loss: 5.02312901e-07
Iter: 699 loss: 5.02260605e-07
Iter: 700 loss: 5.02229568e-07
Iter: 701 loss: 5.02115199e-07
Iter: 702 loss: 5.02137482e-07
Iter: 703 loss: 5.02101216e-07
Iter: 704 loss: 5.02066541e-07
Iter: 705 loss: 5.02020725e-07
Iter: 706 loss: 5.01928071e-07
Iter: 707 loss: 5.01889e-07
Iter: 708 loss: 5.01837235e-07
Iter: 709 loss: 5.01708712e-07
Iter: 710 loss: 5.02339049e-07
Iter: 711 loss: 5.0169524e-07
Iter: 712 loss: 5.01586555e-07
Iter: 713 loss: 5.02738317e-07
Iter: 714 loss: 5.01601e-07
Iter: 715 loss: 5.0150328e-07
Iter: 716 loss: 5.01502427e-07
Iter: 717 loss: 5.01449165e-07
Iter: 718 loss: 5.01340367e-07
Iter: 719 loss: 5.02616217e-07
Iter: 720 loss: 5.01329964e-07
Iter: 721 loss: 5.01255101e-07
Iter: 722 loss: 5.01293357e-07
Iter: 723 loss: 5.01208092e-07
Iter: 724 loss: 5.01138516e-07
Iter: 725 loss: 5.01007662e-07
Iter: 726 loss: 5.01032957e-07
Iter: 727 loss: 5.00859244e-07
Iter: 728 loss: 5.01737e-07
Iter: 729 loss: 5.00841622e-07
Iter: 730 loss: 5.00747e-07
Iter: 731 loss: 5.0185713e-07
Iter: 732 loss: 5.00734473e-07
Iter: 733 loss: 5.00622832e-07
Iter: 734 loss: 5.00874137e-07
Iter: 735 loss: 5.00603e-07
Iter: 736 loss: 5.00573e-07
Iter: 737 loss: 5.0085589e-07
Iter: 738 loss: 5.00522e-07
Iter: 739 loss: 5.0044514e-07
Iter: 740 loss: 5.00441843e-07
Iter: 741 loss: 5.00387728e-07
Iter: 742 loss: 5.00309e-07
Iter: 743 loss: 5.00378178e-07
Iter: 744 loss: 5.00217652e-07
Iter: 745 loss: 5.00227202e-07
Iter: 746 loss: 5.00216743e-07
Iter: 747 loss: 5.0021174e-07
Iter: 748 loss: 5.00201054e-07
Iter: 749 loss: 5.00215833e-07
Iter: 750 loss: 5.00204919e-07
Iter: 751 loss: 5.00230726e-07
Iter: 752 loss: 5.00215151e-07
Iter: 753 loss: 5.0021265e-07
Iter: 754 loss: 5.00224e-07
Iter: 755 loss: 5.00214355e-07
Iter: 756 loss: 5.00222541e-07
Iter: 757 loss: 5.00218675e-07
Iter: 758 loss: 5.00213e-07
Iter: 759 loss: 5.00216231e-07
Iter: 760 loss: 5.00224928e-07
Iter: 761 loss: 5.00220779e-07
Iter: 762 loss: 5.00218562e-07
Iter: 763 loss: 5.00219585e-07
Iter: 764 loss: 5.00219244e-07
Iter: 765 loss: 5.00217652e-07
Iter: 766 loss: 5.00218562e-07
Iter: 767 loss: 5.00217652e-07
Iter: 768 loss: 5.00218562e-07
Iter: 769 loss: 5.00218562e-07
Iter: 770 loss: 5.00217652e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.2/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.6
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.6
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.6 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.6
+ date
Sat Nov  7 20:21:04 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.6/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.2/300_100_100_100_1 --function f1 --psi 0 --phi 1.6 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.6/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e5203e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51fb5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e52055b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e52103620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e52055598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e52055730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e520557b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51f2a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51f24950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51f4c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51e61488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51e01378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51f24158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51e3d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51f248c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51f24ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51f09a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51e3d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c396d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e51ea59d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c359950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c3c5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c3c1158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c3e9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c41e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c26be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c26b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c2950d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c2b0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c2d6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c2aa598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c307268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c2f3840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c194a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c1522f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e4c132c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.002463316
test_loss: 0.0021641764
train_loss: 0.0014880934
test_loss: 0.0014903465
train_loss: 0.0017140469
test_loss: 0.0016782669
train_loss: 0.0017252355
test_loss: 0.0013913
train_loss: 0.0016978905
test_loss: 0.0014432938
train_loss: 0.0012808576
test_loss: 0.0015524456
train_loss: 0.0013608703
test_loss: 0.0015627888
train_loss: 0.0013869924
test_loss: 0.0013887
train_loss: 0.0012805325
test_loss: 0.0012705713
train_loss: 0.0017933107
test_loss: 0.001324003
train_loss: 0.001434829
test_loss: 0.0016694433
train_loss: 0.0012393744
test_loss: 0.0016054828
train_loss: 0.001297232
test_loss: 0.0014490654
train_loss: 0.0017943797
test_loss: 0.0017913287
train_loss: 0.0015672478
test_loss: 0.0014758719
train_loss: 0.0014667164
test_loss: 0.0013097591
train_loss: 0.0013382259
test_loss: 0.0012447046
train_loss: 0.0013102638
test_loss: 0.0014003012
train_loss: 0.0012755473
test_loss: 0.0013149626
train_loss: 0.001382438
test_loss: 0.001484344
train_loss: 0.0012000536
test_loss: 0.0011860814
train_loss: 0.0014290347
test_loss: 0.0012907499
train_loss: 0.0014027369
test_loss: 0.0012336577
train_loss: 0.0013262411
test_loss: 0.001269823
train_loss: 0.0013507074
test_loss: 0.0011714341
train_loss: 0.0014700925
test_loss: 0.001256211
train_loss: 0.0012510417
test_loss: 0.001288112
train_loss: 0.0013549126
test_loss: 0.001128148
train_loss: 0.0011339565
test_loss: 0.0012010344
train_loss: 0.0014322717
test_loss: 0.0012058994
train_loss: 0.0013466487
test_loss: 0.0012349022
train_loss: 0.0013833181
test_loss: 0.0015356892
train_loss: 0.0013513316
test_loss: 0.0013681689
train_loss: 0.001252823
test_loss: 0.0012124866
train_loss: 0.0013231538
test_loss: 0.0011928525
train_loss: 0.0013679708
test_loss: 0.0014932641
train_loss: 0.0013701287
test_loss: 0.0016184001
train_loss: 0.0016493779
test_loss: 0.001358333
train_loss: 0.0014505633
test_loss: 0.0014420016
train_loss: 0.0014029002
test_loss: 0.0018885041
train_loss: 0.0012649698
test_loss: 0.0011937141
train_loss: 0.0011584205
test_loss: 0.0012749133
train_loss: 0.0013506332
test_loss: 0.0013338712
train_loss: 0.0011891113
test_loss: 0.0013433829
train_loss: 0.001318465
test_loss: 0.0013016223
train_loss: 0.0012586655
test_loss: 0.0014818546
train_loss: 0.001126305
test_loss: 0.001274752
train_loss: 0.0012249489
test_loss: 0.001085725
train_loss: 0.001262725
test_loss: 0.0013322405
train_loss: 0.0015390225
test_loss: 0.0013415825
train_loss: 0.0013263968
test_loss: 0.0012479855
train_loss: 0.0014130084
test_loss: 0.0011284244
train_loss: 0.0012918158
test_loss: 0.0013582685
train_loss: 0.0014645751
test_loss: 0.0016381656
train_loss: 0.0014612558
test_loss: 0.0011721207
train_loss: 0.00134389
test_loss: 0.0013424361
train_loss: 0.0011320683
test_loss: 0.0013645921
train_loss: 0.0012591752
test_loss: 0.0011957862
train_loss: 0.0012552444
test_loss: 0.0011344597
train_loss: 0.0013173069
test_loss: 0.0011766868
train_loss: 0.0014026396
test_loss: 0.0016823746
train_loss: 0.0011329583
test_loss: 0.0012887436
train_loss: 0.0012023182
test_loss: 0.0013524502
train_loss: 0.0011047765
test_loss: 0.0011686424
train_loss: 0.0013994866
test_loss: 0.0014313072
train_loss: 0.0011935467
test_loss: 0.0015698852
train_loss: 0.0015325604
test_loss: 0.0012605448
train_loss: 0.0013560351
test_loss: 0.0011986058
train_loss: 0.0013102189
test_loss: 0.0011524805
train_loss: 0.0013271759
test_loss: 0.0014605859
train_loss: 0.0014128287
test_loss: 0.0012729764
train_loss: 0.0012038448
test_loss: 0.0011961681
train_loss: 0.0014987444
test_loss: 0.001645136
train_loss: 0.0012970315
test_loss: 0.0012891141
train_loss: 0.001277161
test_loss: 0.001188747
train_loss: 0.0014648798
test_loss: 0.0013542584
train_loss: 0.0014101724
test_loss: 0.0011240781
train_loss: 0.0012333946
test_loss: 0.0013105719
train_loss: 0.0014248043
test_loss: 0.0015568472
train_loss: 0.001224763
test_loss: 0.0012063639
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.6/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.6/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi1.6/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57f04d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57f35950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57fb5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57ec0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57ec0b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57ec0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57e4c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57e90e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57df8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57db1158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57db19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57d62ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57d85d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57d441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57d55f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57d557b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57d0ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57caf840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57d0e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57c831e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57c42048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57be22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57c046a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57babe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57babea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57b95f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18e85e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f57bab950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18e451e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18e610d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18e64510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18e0d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18e266a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18dca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8f18d91268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8ef4643f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.15524369e-06
Iter: 2 loss: 4.5098941e-06
Iter: 3 loss: 1.43047896e-06
Iter: 4 loss: 1.13948647e-06
Iter: 5 loss: 2.95874111e-06
Iter: 6 loss: 1.10588985e-06
Iter: 7 loss: 9.9760382e-07
Iter: 8 loss: 1.50939957e-06
Iter: 9 loss: 9.7783709e-07
Iter: 10 loss: 8.66339178e-07
Iter: 11 loss: 1.18025196e-06
Iter: 12 loss: 8.30719728e-07
Iter: 13 loss: 7.88459261e-07
Iter: 14 loss: 9.34350794e-07
Iter: 15 loss: 7.77387413e-07
Iter: 16 loss: 7.33564605e-07
Iter: 17 loss: 7.01663396e-07
Iter: 18 loss: 6.86666283e-07
Iter: 19 loss: 6.59157365e-07
Iter: 20 loss: 8.95168e-07
Iter: 21 loss: 6.57627822e-07
Iter: 22 loss: 6.3577e-07
Iter: 23 loss: 7.79573099e-07
Iter: 24 loss: 6.33531386e-07
Iter: 25 loss: 6.21890763e-07
Iter: 26 loss: 6.47630941e-07
Iter: 27 loss: 6.17424405e-07
Iter: 28 loss: 6.06981246e-07
Iter: 29 loss: 6.04724448e-07
Iter: 30 loss: 5.97891813e-07
Iter: 31 loss: 5.89161175e-07
Iter: 32 loss: 6.35381468e-07
Iter: 33 loss: 5.8777016e-07
Iter: 34 loss: 5.79783659e-07
Iter: 35 loss: 6.16816578e-07
Iter: 36 loss: 5.78271795e-07
Iter: 37 loss: 5.73181865e-07
Iter: 38 loss: 5.89274521e-07
Iter: 39 loss: 5.71615544e-07
Iter: 40 loss: 5.67853135e-07
Iter: 41 loss: 5.85643647e-07
Iter: 42 loss: 5.67131792e-07
Iter: 43 loss: 5.63554067e-07
Iter: 44 loss: 5.75254603e-07
Iter: 45 loss: 5.62621494e-07
Iter: 46 loss: 5.5964108e-07
Iter: 47 loss: 5.58374552e-07
Iter: 48 loss: 5.56831537e-07
Iter: 49 loss: 5.53093912e-07
Iter: 50 loss: 5.53045254e-07
Iter: 51 loss: 5.49843321e-07
Iter: 52 loss: 5.73399291e-07
Iter: 53 loss: 5.49538754e-07
Iter: 54 loss: 5.4808595e-07
Iter: 55 loss: 5.45083253e-07
Iter: 56 loss: 5.99725922e-07
Iter: 57 loss: 5.45083e-07
Iter: 58 loss: 5.40700455e-07
Iter: 59 loss: 5.71553642e-07
Iter: 60 loss: 5.40345e-07
Iter: 61 loss: 5.38241693e-07
Iter: 62 loss: 5.33927505e-07
Iter: 63 loss: 6.00434191e-07
Iter: 64 loss: 5.33786761e-07
Iter: 65 loss: 5.3281741e-07
Iter: 66 loss: 5.31958449e-07
Iter: 67 loss: 5.30061925e-07
Iter: 68 loss: 5.25547478e-07
Iter: 69 loss: 5.75546153e-07
Iter: 70 loss: 5.25110352e-07
Iter: 71 loss: 5.22460596e-07
Iter: 72 loss: 5.22412392e-07
Iter: 73 loss: 5.20321123e-07
Iter: 74 loss: 5.21823267e-07
Iter: 75 loss: 5.18972286e-07
Iter: 76 loss: 5.15442593e-07
Iter: 77 loss: 5.23965923e-07
Iter: 78 loss: 5.14118426e-07
Iter: 79 loss: 5.12136e-07
Iter: 80 loss: 5.12192855e-07
Iter: 81 loss: 5.10637051e-07
Iter: 82 loss: 5.08213247e-07
Iter: 83 loss: 5.2649e-07
Iter: 84 loss: 5.08003211e-07
Iter: 85 loss: 5.07274422e-07
Iter: 86 loss: 5.07086156e-07
Iter: 87 loss: 5.06095489e-07
Iter: 88 loss: 5.04344939e-07
Iter: 89 loss: 5.48648131e-07
Iter: 90 loss: 5.04279e-07
Iter: 91 loss: 5.03104388e-07
Iter: 92 loss: 5.05961509e-07
Iter: 93 loss: 5.02656576e-07
Iter: 94 loss: 5.00892043e-07
Iter: 95 loss: 5.07958759e-07
Iter: 96 loss: 5.00468332e-07
Iter: 97 loss: 4.99514044e-07
Iter: 98 loss: 5.01763679e-07
Iter: 99 loss: 4.99180487e-07
Iter: 100 loss: 4.98560894e-07
Iter: 101 loss: 4.9950637e-07
Iter: 102 loss: 4.98215798e-07
Iter: 103 loss: 4.97194321e-07
Iter: 104 loss: 4.99410476e-07
Iter: 105 loss: 4.96768507e-07
Iter: 106 loss: 4.96041253e-07
Iter: 107 loss: 4.96584903e-07
Iter: 108 loss: 4.9559776e-07
Iter: 109 loss: 4.94583105e-07
Iter: 110 loss: 4.96691939e-07
Iter: 111 loss: 4.94138703e-07
Iter: 112 loss: 4.93638254e-07
Iter: 113 loss: 4.93666789e-07
Iter: 114 loss: 4.93117511e-07
Iter: 115 loss: 4.92164531e-07
Iter: 116 loss: 5.08114567e-07
Iter: 117 loss: 4.92156914e-07
Iter: 118 loss: 4.91241053e-07
Iter: 119 loss: 4.96951657e-07
Iter: 120 loss: 4.91135154e-07
Iter: 121 loss: 4.9049271e-07
Iter: 122 loss: 4.9450307e-07
Iter: 123 loss: 4.90420121e-07
Iter: 124 loss: 4.89960144e-07
Iter: 125 loss: 4.89959518e-07
Iter: 126 loss: 4.89734816e-07
Iter: 127 loss: 4.88923206e-07
Iter: 128 loss: 4.91339847e-07
Iter: 129 loss: 4.88462e-07
Iter: 130 loss: 4.88434694e-07
Iter: 131 loss: 4.88129899e-07
Iter: 132 loss: 4.87845512e-07
Iter: 133 loss: 4.87437717e-07
Iter: 134 loss: 4.87405714e-07
Iter: 135 loss: 4.86791237e-07
Iter: 136 loss: 4.87293221e-07
Iter: 137 loss: 4.86440968e-07
Iter: 138 loss: 4.85922783e-07
Iter: 139 loss: 4.9251264e-07
Iter: 140 loss: 4.85933924e-07
Iter: 141 loss: 4.85486453e-07
Iter: 142 loss: 4.85702515e-07
Iter: 143 loss: 4.85197e-07
Iter: 144 loss: 4.84786938e-07
Iter: 145 loss: 4.84694453e-07
Iter: 146 loss: 4.84458e-07
Iter: 147 loss: 4.83738063e-07
Iter: 148 loss: 4.87295893e-07
Iter: 149 loss: 4.83635745e-07
Iter: 150 loss: 4.83192366e-07
Iter: 151 loss: 4.85068426e-07
Iter: 152 loss: 4.83143197e-07
Iter: 153 loss: 4.82565611e-07
Iter: 154 loss: 4.82719599e-07
Iter: 155 loss: 4.82146e-07
Iter: 156 loss: 4.81813458e-07
Iter: 157 loss: 4.82594146e-07
Iter: 158 loss: 4.81694826e-07
Iter: 159 loss: 4.8131767e-07
Iter: 160 loss: 4.87397415e-07
Iter: 161 loss: 4.81287088e-07
Iter: 162 loss: 4.80997301e-07
Iter: 163 loss: 4.8061662e-07
Iter: 164 loss: 4.80692734e-07
Iter: 165 loss: 4.80425797e-07
Iter: 166 loss: 4.80437791e-07
Iter: 167 loss: 4.80190295e-07
Iter: 168 loss: 4.79936546e-07
Iter: 169 loss: 4.79960477e-07
Iter: 170 loss: 4.79620326e-07
Iter: 171 loss: 4.80094457e-07
Iter: 172 loss: 4.79477194e-07
Iter: 173 loss: 4.79090545e-07
Iter: 174 loss: 4.8013e-07
Iter: 175 loss: 4.78976574e-07
Iter: 176 loss: 4.78638299e-07
Iter: 177 loss: 4.79277446e-07
Iter: 178 loss: 4.78520633e-07
Iter: 179 loss: 4.78049913e-07
Iter: 180 loss: 4.77247625e-07
Iter: 181 loss: 4.96371968e-07
Iter: 182 loss: 4.77248307e-07
Iter: 183 loss: 4.76600121e-07
Iter: 184 loss: 4.76604612e-07
Iter: 185 loss: 4.76136904e-07
Iter: 186 loss: 4.76737284e-07
Iter: 187 loss: 4.75866216e-07
Iter: 188 loss: 4.75472689e-07
Iter: 189 loss: 4.75474707e-07
Iter: 190 loss: 4.75208509e-07
Iter: 191 loss: 4.74839453e-07
Iter: 192 loss: 4.74810236e-07
Iter: 193 loss: 4.74845365e-07
Iter: 194 loss: 4.74725823e-07
Iter: 195 loss: 4.74570271e-07
Iter: 196 loss: 4.7464124e-07
Iter: 197 loss: 4.7446872e-07
Iter: 198 loss: 4.74375753e-07
Iter: 199 loss: 4.74693195e-07
Iter: 200 loss: 4.74302681e-07
Iter: 201 loss: 4.74145679e-07
Iter: 202 loss: 4.74452293e-07
Iter: 203 loss: 4.74122032e-07
Iter: 204 loss: 4.73967958e-07
Iter: 205 loss: 4.73747775e-07
Iter: 206 loss: 4.73709378e-07
Iter: 207 loss: 4.73567866e-07
Iter: 208 loss: 4.73574858e-07
Iter: 209 loss: 4.73479417e-07
Iter: 210 loss: 4.73270688e-07
Iter: 211 loss: 4.76860805e-07
Iter: 212 loss: 4.73264464e-07
Iter: 213 loss: 4.72912404e-07
Iter: 214 loss: 4.73722167e-07
Iter: 215 loss: 4.72783341e-07
Iter: 216 loss: 4.72452427e-07
Iter: 217 loss: 4.73140915e-07
Iter: 218 loss: 4.72270301e-07
Iter: 219 loss: 4.71984379e-07
Iter: 220 loss: 4.74914088e-07
Iter: 221 loss: 4.71993928e-07
Iter: 222 loss: 4.71673275e-07
Iter: 223 loss: 4.72460073e-07
Iter: 224 loss: 4.71549185e-07
Iter: 225 loss: 4.71328519e-07
Iter: 226 loss: 4.71566977e-07
Iter: 227 loss: 4.71137866e-07
Iter: 228 loss: 4.709633e-07
Iter: 229 loss: 4.70929649e-07
Iter: 230 loss: 4.70743515e-07
Iter: 231 loss: 4.70305167e-07
Iter: 232 loss: 4.77274057e-07
Iter: 233 loss: 4.70299653e-07
Iter: 234 loss: 4.70014498e-07
Iter: 235 loss: 4.71259739e-07
Iter: 236 loss: 4.70026635e-07
Iter: 237 loss: 4.69823533e-07
Iter: 238 loss: 4.7021814e-07
Iter: 239 loss: 4.69763165e-07
Iter: 240 loss: 4.69487702e-07
Iter: 241 loss: 4.71961243e-07
Iter: 242 loss: 4.69483695e-07
Iter: 243 loss: 4.69314358e-07
Iter: 244 loss: 4.69071892e-07
Iter: 245 loss: 4.74247599e-07
Iter: 246 loss: 4.69126689e-07
Iter: 247 loss: 4.68988901e-07
Iter: 248 loss: 4.68960309e-07
Iter: 249 loss: 4.68817461e-07
Iter: 250 loss: 4.68655116e-07
Iter: 251 loss: 4.73110106e-07
Iter: 252 loss: 4.68622403e-07
Iter: 253 loss: 4.68381813e-07
Iter: 254 loss: 4.69931791e-07
Iter: 255 loss: 4.68358763e-07
Iter: 256 loss: 4.6822754e-07
Iter: 257 loss: 4.68720657e-07
Iter: 258 loss: 4.68161659e-07
Iter: 259 loss: 4.67937127e-07
Iter: 260 loss: 4.6818468e-07
Iter: 261 loss: 4.67845894e-07
Iter: 262 loss: 4.67673e-07
Iter: 263 loss: 4.69050292e-07
Iter: 264 loss: 4.67677438e-07
Iter: 265 loss: 4.67499319e-07
Iter: 266 loss: 4.69099376e-07
Iter: 267 loss: 4.67502474e-07
Iter: 268 loss: 4.67386315e-07
Iter: 269 loss: 4.67227835e-07
Iter: 270 loss: 4.70845606e-07
Iter: 271 loss: 4.67241819e-07
Iter: 272 loss: 4.67064552e-07
Iter: 273 loss: 4.67047812e-07
Iter: 274 loss: 4.6695996e-07
Iter: 275 loss: 4.66884615e-07
Iter: 276 loss: 4.6681788e-07
Iter: 277 loss: 4.66719058e-07
Iter: 278 loss: 4.66760326e-07
Iter: 279 loss: 4.6663709e-07
Iter: 280 loss: 4.66540797e-07
Iter: 281 loss: 4.66374615e-07
Iter: 282 loss: 4.66377713e-07
Iter: 283 loss: 4.6620903e-07
Iter: 284 loss: 4.66167251e-07
Iter: 285 loss: 4.66079626e-07
Iter: 286 loss: 4.6584546e-07
Iter: 287 loss: 4.69821657e-07
Iter: 288 loss: 4.65802401e-07
Iter: 289 loss: 4.65593e-07
Iter: 290 loss: 4.67780723e-07
Iter: 291 loss: 4.65561925e-07
Iter: 292 loss: 4.65344812e-07
Iter: 293 loss: 4.65927315e-07
Iter: 294 loss: 4.65352258e-07
Iter: 295 loss: 4.65136e-07
Iter: 296 loss: 4.65329038e-07
Iter: 297 loss: 4.65015319e-07
Iter: 298 loss: 4.64942673e-07
Iter: 299 loss: 4.64890519e-07
Iter: 300 loss: 4.64829782e-07
Iter: 301 loss: 4.64676333e-07
Iter: 302 loss: 4.646717e-07
Iter: 303 loss: 4.64545849e-07
Iter: 304 loss: 4.64549856e-07
Iter: 305 loss: 4.64359857e-07
Iter: 306 loss: 4.64231022e-07
Iter: 307 loss: 4.64780896e-07
Iter: 308 loss: 4.64149252e-07
Iter: 309 loss: 4.64062396e-07
Iter: 310 loss: 4.6404773e-07
Iter: 311 loss: 4.64001857e-07
Iter: 312 loss: 4.63935095e-07
Iter: 313 loss: 4.63903461e-07
Iter: 314 loss: 4.63790855e-07
Iter: 315 loss: 4.63861909e-07
Iter: 316 loss: 4.63726479e-07
Iter: 317 loss: 4.63684529e-07
Iter: 318 loss: 4.63672905e-07
Iter: 319 loss: 4.63606511e-07
Iter: 320 loss: 4.63509934e-07
Iter: 321 loss: 4.63509195e-07
Iter: 322 loss: 4.63389966e-07
Iter: 323 loss: 4.63454967e-07
Iter: 324 loss: 4.63331958e-07
Iter: 325 loss: 4.63146193e-07
Iter: 326 loss: 4.65170075e-07
Iter: 327 loss: 4.63153981e-07
Iter: 328 loss: 4.6310376e-07
Iter: 329 loss: 4.63243282e-07
Iter: 330 loss: 4.63040095e-07
Iter: 331 loss: 4.63027732e-07
Iter: 332 loss: 4.63806032e-07
Iter: 333 loss: 4.62959576e-07
Iter: 334 loss: 4.62885652e-07
Iter: 335 loss: 4.62728792e-07
Iter: 336 loss: 4.64366593e-07
Iter: 337 loss: 4.62668851e-07
Iter: 338 loss: 4.62499059e-07
Iter: 339 loss: 4.62641481e-07
Iter: 340 loss: 4.62407058e-07
Iter: 341 loss: 4.62321793e-07
Iter: 342 loss: 4.62300875e-07
Iter: 343 loss: 4.62200262e-07
Iter: 344 loss: 4.62217145e-07
Iter: 345 loss: 4.62127275e-07
Iter: 346 loss: 4.61988378e-07
Iter: 347 loss: 4.61928181e-07
Iter: 348 loss: 4.61868098e-07
Iter: 349 loss: 4.61731361e-07
Iter: 350 loss: 4.62319122e-07
Iter: 351 loss: 4.61680912e-07
Iter: 352 loss: 4.61498217e-07
Iter: 353 loss: 4.62350783e-07
Iter: 354 loss: 4.61433928e-07
Iter: 355 loss: 4.61313562e-07
Iter: 356 loss: 4.61633192e-07
Iter: 357 loss: 4.61336072e-07
Iter: 358 loss: 4.61218832e-07
Iter: 359 loss: 4.61277466e-07
Iter: 360 loss: 4.61142037e-07
Iter: 361 loss: 4.61020733e-07
Iter: 362 loss: 4.62186165e-07
Iter: 363 loss: 4.6103105e-07
Iter: 364 loss: 4.60893546e-07
Iter: 365 loss: 4.61390727e-07
Iter: 366 loss: 4.60875327e-07
Iter: 367 loss: 4.60748367e-07
Iter: 368 loss: 4.6143515e-07
Iter: 369 loss: 4.60710027e-07
Iter: 370 loss: 4.60680553e-07
Iter: 371 loss: 4.60533e-07
Iter: 372 loss: 4.63011645e-07
Iter: 373 loss: 4.60543703e-07
Iter: 374 loss: 4.60379937e-07
Iter: 375 loss: 4.60639342e-07
Iter: 376 loss: 4.60292114e-07
Iter: 377 loss: 4.60238113e-07
Iter: 378 loss: 4.60234958e-07
Iter: 379 loss: 4.60153416e-07
Iter: 380 loss: 4.59992378e-07
Iter: 381 loss: 4.62874539e-07
Iter: 382 loss: 4.60039871e-07
Iter: 383 loss: 4.59960859e-07
Iter: 384 loss: 4.60524888e-07
Iter: 385 loss: 4.5988881e-07
Iter: 386 loss: 4.59757302e-07
Iter: 387 loss: 4.60150943e-07
Iter: 388 loss: 4.5972385e-07
Iter: 389 loss: 4.59674055e-07
Iter: 390 loss: 4.60088927e-07
Iter: 391 loss: 4.59613943e-07
Iter: 392 loss: 4.59541781e-07
Iter: 393 loss: 4.5948e-07
Iter: 394 loss: 4.59464161e-07
Iter: 395 loss: 4.59341067e-07
Iter: 396 loss: 4.60294814e-07
Iter: 397 loss: 4.59345614e-07
Iter: 398 loss: 4.59212259e-07
Iter: 399 loss: 4.59359285e-07
Iter: 400 loss: 4.59199384e-07
Iter: 401 loss: 4.59088511e-07
Iter: 402 loss: 4.60113199e-07
Iter: 403 loss: 4.5906134e-07
Iter: 404 loss: 4.58967691e-07
Iter: 405 loss: 4.58981248e-07
Iter: 406 loss: 4.58956777e-07
Iter: 407 loss: 4.58822e-07
Iter: 408 loss: 4.58734803e-07
Iter: 409 loss: 4.58746143e-07
Iter: 410 loss: 4.58622594e-07
Iter: 411 loss: 4.59877299e-07
Iter: 412 loss: 4.58586925e-07
Iter: 413 loss: 4.58533123e-07
Iter: 414 loss: 4.58785308e-07
Iter: 415 loss: 4.58463603e-07
Iter: 416 loss: 4.58392805e-07
Iter: 417 loss: 4.58271813e-07
Iter: 418 loss: 4.58267e-07
Iter: 419 loss: 4.5811808e-07
Iter: 420 loss: 4.59063415e-07
Iter: 421 loss: 4.58129193e-07
Iter: 422 loss: 4.58024346e-07
Iter: 423 loss: 4.58679921e-07
Iter: 424 loss: 4.57969918e-07
Iter: 425 loss: 4.57957924e-07
Iter: 426 loss: 4.58015307e-07
Iter: 427 loss: 4.57881697e-07
Iter: 428 loss: 4.57823319e-07
Iter: 429 loss: 4.57769119e-07
Iter: 430 loss: 4.57737769e-07
Iter: 431 loss: 4.57615215e-07
Iter: 432 loss: 4.57601914e-07
Iter: 433 loss: 4.57557633e-07
Iter: 434 loss: 4.57963637e-07
Iter: 435 loss: 4.57504939e-07
Iter: 436 loss: 4.57453837e-07
Iter: 437 loss: 4.5751608e-07
Iter: 438 loss: 4.5742263e-07
Iter: 439 loss: 4.57361068e-07
Iter: 440 loss: 4.5740785e-07
Iter: 441 loss: 4.57321221e-07
Iter: 442 loss: 4.57216e-07
Iter: 443 loss: 4.57545127e-07
Iter: 444 loss: 4.57215549e-07
Iter: 445 loss: 4.57130852e-07
Iter: 446 loss: 4.57465774e-07
Iter: 447 loss: 4.57112719e-07
Iter: 448 loss: 4.57054398e-07
Iter: 449 loss: 4.57012732e-07
Iter: 450 loss: 4.5704968e-07
Iter: 451 loss: 4.56923232e-07
Iter: 452 loss: 4.57141482e-07
Iter: 453 loss: 4.56915245e-07
Iter: 454 loss: 4.5685556e-07
Iter: 455 loss: 4.5740606e-07
Iter: 456 loss: 4.56856554e-07
Iter: 457 loss: 4.56750399e-07
Iter: 458 loss: 4.56768248e-07
Iter: 459 loss: 4.56682301e-07
Iter: 460 loss: 4.56640407e-07
Iter: 461 loss: 4.56840667e-07
Iter: 462 loss: 4.56645978e-07
Iter: 463 loss: 4.5652888e-07
Iter: 464 loss: 4.5682512e-07
Iter: 465 loss: 4.56524504e-07
Iter: 466 loss: 4.56493041e-07
Iter: 467 loss: 4.57261223e-07
Iter: 468 loss: 4.56500743e-07
Iter: 469 loss: 4.56447253e-07
Iter: 470 loss: 4.56585553e-07
Iter: 471 loss: 4.56408912e-07
Iter: 472 loss: 4.56371254e-07
Iter: 473 loss: 4.56273028e-07
Iter: 474 loss: 4.57631756e-07
Iter: 475 loss: 4.56271437e-07
Iter: 476 loss: 4.56194471e-07
Iter: 477 loss: 4.57029614e-07
Iter: 478 loss: 4.56154282e-07
Iter: 479 loss: 4.56120659e-07
Iter: 480 loss: 4.56380462e-07
Iter: 481 loss: 4.56049833e-07
Iter: 482 loss: 4.55954904e-07
Iter: 483 loss: 4.55898e-07
Iter: 484 loss: 4.55890842e-07
Iter: 485 loss: 4.55733328e-07
Iter: 486 loss: 4.5596434e-07
Iter: 487 loss: 4.5563911e-07
Iter: 488 loss: 4.55480063e-07
Iter: 489 loss: 4.56757363e-07
Iter: 490 loss: 4.55532359e-07
Iter: 491 loss: 4.5539025e-07
Iter: 492 loss: 4.56152179e-07
Iter: 493 loss: 4.55343496e-07
Iter: 494 loss: 4.55315018e-07
Iter: 495 loss: 4.55259141e-07
Iter: 496 loss: 4.5522566e-07
Iter: 497 loss: 4.55171573e-07
Iter: 498 loss: 4.55787898e-07
Iter: 499 loss: 4.55143891e-07
Iter: 500 loss: 4.55077128e-07
Iter: 501 loss: 4.55654231e-07
Iter: 502 loss: 4.55031568e-07
Iter: 503 loss: 4.55003374e-07
Iter: 504 loss: 4.5562436e-07
Iter: 505 loss: 4.55009058e-07
Iter: 506 loss: 4.54954602e-07
Iter: 507 loss: 4.54909127e-07
Iter: 508 loss: 4.54919245e-07
Iter: 509 loss: 4.54856547e-07
Iter: 510 loss: 4.54836112e-07
Iter: 511 loss: 4.54845974e-07
Iter: 512 loss: 4.54777052e-07
Iter: 513 loss: 4.54763921e-07
Iter: 514 loss: 4.54731548e-07
Iter: 515 loss: 4.54682493e-07
Iter: 516 loss: 4.54703581e-07
Iter: 517 loss: 4.54599814e-07
Iter: 518 loss: 4.54683658e-07
Iter: 519 loss: 4.54570795e-07
Iter: 520 loss: 4.54481039e-07
Iter: 521 loss: 4.54566475e-07
Iter: 522 loss: 4.54408564e-07
Iter: 523 loss: 4.54354478e-07
Iter: 524 loss: 4.54343137e-07
Iter: 525 loss: 4.54323157e-07
Iter: 526 loss: 4.54331371e-07
Iter: 527 loss: 4.54265546e-07
Iter: 528 loss: 4.54161579e-07
Iter: 529 loss: 4.54113831e-07
Iter: 530 loss: 4.54056135e-07
Iter: 531 loss: 4.53945518e-07
Iter: 532 loss: 4.53968767e-07
Iter: 533 loss: 4.53876766e-07
Iter: 534 loss: 4.54370507e-07
Iter: 535 loss: 4.53919682e-07
Iter: 536 loss: 4.53773538e-07
Iter: 537 loss: 4.53869035e-07
Iter: 538 loss: 4.53747361e-07
Iter: 539 loss: 4.53697453e-07
Iter: 540 loss: 4.53742928e-07
Iter: 541 loss: 4.53661784e-07
Iter: 542 loss: 4.53572625e-07
Iter: 543 loss: 4.54060171e-07
Iter: 544 loss: 4.53579e-07
Iter: 545 loss: 4.53530589e-07
Iter: 546 loss: 4.5371084e-07
Iter: 547 loss: 4.5349077e-07
Iter: 548 loss: 4.53425969e-07
Iter: 549 loss: 4.53306683e-07
Iter: 550 loss: 4.53282553e-07
Iter: 551 loss: 4.5319814e-07
Iter: 552 loss: 4.53763647e-07
Iter: 553 loss: 4.53214398e-07
Iter: 554 loss: 4.53122e-07
Iter: 555 loss: 4.53163466e-07
Iter: 556 loss: 4.53078798e-07
Iter: 557 loss: 4.52981595e-07
Iter: 558 loss: 4.54268246e-07
Iter: 559 loss: 4.52987109e-07
Iter: 560 loss: 4.52926201e-07
Iter: 561 loss: 4.52850315e-07
Iter: 562 loss: 4.52848781e-07
Iter: 563 loss: 4.52794183e-07
Iter: 564 loss: 4.52814419e-07
Iter: 565 loss: 4.52724635e-07
Iter: 566 loss: 4.52630758e-07
Iter: 567 loss: 4.5288769e-07
Iter: 568 loss: 4.52649488e-07
Iter: 569 loss: 4.52549983e-07
Iter: 570 loss: 4.53093918e-07
Iter: 571 loss: 4.52532049e-07
Iter: 572 loss: 4.52487569e-07
Iter: 573 loss: 4.52720599e-07
Iter: 574 loss: 4.52485693e-07
Iter: 575 loss: 4.52484727e-07
Iter: 576 loss: 4.52408926e-07
Iter: 577 loss: 4.53686198e-07
Iter: 578 loss: 4.52398609e-07
Iter: 579 loss: 4.52354385e-07
Iter: 580 loss: 4.52325139e-07
Iter: 581 loss: 4.52284894e-07
Iter: 582 loss: 4.52250219e-07
Iter: 583 loss: 4.52238282e-07
Iter: 584 loss: 4.52147049e-07
Iter: 585 loss: 4.52145713e-07
Iter: 586 loss: 4.52117e-07
Iter: 587 loss: 4.52012671e-07
Iter: 588 loss: 4.52741062e-07
Iter: 589 loss: 4.51983055e-07
Iter: 590 loss: 4.51927633e-07
Iter: 591 loss: 4.51967082e-07
Iter: 592 loss: 4.51862235e-07
Iter: 593 loss: 4.51769409e-07
Iter: 594 loss: 4.51764294e-07
Iter: 595 loss: 4.517062e-07
Iter: 596 loss: 4.51553262e-07
Iter: 597 loss: 4.53829273e-07
Iter: 598 loss: 4.51556701e-07
Iter: 599 loss: 4.51394101e-07
Iter: 600 loss: 4.51784729e-07
Iter: 601 loss: 4.51348e-07
Iter: 602 loss: 4.51274644e-07
Iter: 603 loss: 4.51284194e-07
Iter: 604 loss: 4.5123457e-07
Iter: 605 loss: 4.51356414e-07
Iter: 606 loss: 4.5121061e-07
Iter: 607 loss: 4.51128273e-07
Iter: 608 loss: 4.51125317e-07
Iter: 609 loss: 4.51050141e-07
Iter: 610 loss: 4.50989546e-07
Iter: 611 loss: 4.51542661e-07
Iter: 612 loss: 4.50986562e-07
Iter: 613 loss: 4.50923551e-07
Iter: 614 loss: 4.51024391e-07
Iter: 615 loss: 4.50885068e-07
Iter: 616 loss: 4.50845675e-07
Iter: 617 loss: 4.50823336e-07
Iter: 618 loss: 4.5078383e-07
Iter: 619 loss: 4.50690948e-07
Iter: 620 loss: 4.50793721e-07
Iter: 621 loss: 4.5067091e-07
Iter: 622 loss: 4.50615232e-07
Iter: 623 loss: 4.50971044e-07
Iter: 624 loss: 4.50555603e-07
Iter: 625 loss: 4.50491115e-07
Iter: 626 loss: 4.50565864e-07
Iter: 627 loss: 4.50432196e-07
Iter: 628 loss: 4.50388086e-07
Iter: 629 loss: 4.51415133e-07
Iter: 630 loss: 4.50395618e-07
Iter: 631 loss: 4.50304356e-07
Iter: 632 loss: 4.50335563e-07
Iter: 633 loss: 4.50267464e-07
Iter: 634 loss: 4.50189134e-07
Iter: 635 loss: 4.50348836e-07
Iter: 636 loss: 4.50192971e-07
Iter: 637 loss: 4.50107365e-07
Iter: 638 loss: 4.50135047e-07
Iter: 639 loss: 4.50085707e-07
Iter: 640 loss: 4.5006044e-07
Iter: 641 loss: 4.50019058e-07
Iter: 642 loss: 4.49958435e-07
Iter: 643 loss: 4.50133939e-07
Iter: 644 loss: 4.4999382e-07
Iter: 645 loss: 4.49916399e-07
Iter: 646 loss: 4.505346e-07
Iter: 647 loss: 4.49932315e-07
Iter: 648 loss: 4.49884851e-07
Iter: 649 loss: 4.49897755e-07
Iter: 650 loss: 4.49873596e-07
Iter: 651 loss: 4.49807715e-07
Iter: 652 loss: 4.49764912e-07
Iter: 653 loss: 4.49752e-07
Iter: 654 loss: 4.49678737e-07
Iter: 655 loss: 4.49698746e-07
Iter: 656 loss: 4.49584576e-07
Iter: 657 loss: 4.49492177e-07
Iter: 658 loss: 4.50191692e-07
Iter: 659 loss: 4.49521792e-07
Iter: 660 loss: 4.49472452e-07
Iter: 661 loss: 4.49521849e-07
Iter: 662 loss: 4.49443917e-07
Iter: 663 loss: 4.49317326e-07
Iter: 664 loss: 4.50042592e-07
Iter: 665 loss: 4.49290383e-07
Iter: 666 loss: 4.49253378e-07
Iter: 667 loss: 4.49205231e-07
Iter: 668 loss: 4.4920364e-07
Iter: 669 loss: 4.4912565e-07
Iter: 670 loss: 4.49123263e-07
Iter: 671 loss: 4.49027226e-07
Iter: 672 loss: 4.49110303e-07
Iter: 673 loss: 4.49026487e-07
Iter: 674 loss: 4.4897439e-07
Iter: 675 loss: 4.48972145e-07
Iter: 676 loss: 4.48956456e-07
Iter: 677 loss: 4.48893047e-07
Iter: 678 loss: 4.49168112e-07
Iter: 679 loss: 4.48862977e-07
Iter: 680 loss: 4.48827308e-07
Iter: 681 loss: 4.49295214e-07
Iter: 682 loss: 4.48834214e-07
Iter: 683 loss: 4.48851551e-07
Iter: 684 loss: 4.48836545e-07
Iter: 685 loss: 4.48824721e-07
Iter: 686 loss: 4.48800961e-07
Iter: 687 loss: 4.48839813e-07
Iter: 688 loss: 4.4881395e-07
Iter: 689 loss: 4.48809686e-07
Iter: 690 loss: 4.48824835e-07
Iter: 691 loss: 4.48816678e-07
Iter: 692 loss: 4.48813239e-07
Iter: 693 loss: 4.48831088e-07
Iter: 694 loss: 4.4883177e-07
Iter: 695 loss: 4.48837568e-07
Iter: 696 loss: 4.48841e-07
Iter: 697 loss: 4.48839444e-07
Iter: 698 loss: 4.48828956e-07
Iter: 699 loss: 4.48834413e-07
Iter: 700 loss: 4.4883663e-07
Iter: 701 loss: 4.48835578e-07
Iter: 702 loss: 4.48835124e-07
Iter: 703 loss: 4.48835038e-07
Iter: 704 loss: 4.48834612e-07
Iter: 705 loss: 4.4883447e-07
Iter: 706 loss: 4.48835067e-07
Iter: 707 loss: 4.48835067e-07
Iter: 708 loss: 4.48834726e-07
Iter: 709 loss: 4.4883447e-07
Iter: 710 loss: 4.48684631e-07
Iter: 711 loss: 4.50035344e-07
Iter: 712 loss: 4.48688809e-07
Iter: 713 loss: 4.48616277e-07
Iter: 714 loss: 4.48719959e-07
Iter: 715 loss: 4.48581062e-07
Iter: 716 loss: 4.48576458e-07
Iter: 717 loss: 4.48903e-07
Iter: 718 loss: 4.48525668e-07
Iter: 719 loss: 4.48469336e-07
Iter: 720 loss: 4.48411242e-07
Iter: 721 loss: 4.48415818e-07
Iter: 722 loss: 4.48320264e-07
Iter: 723 loss: 4.48728315e-07
Iter: 724 loss: 4.48318247e-07
Iter: 725 loss: 4.48299232e-07
Iter: 726 loss: 4.48503016e-07
Iter: 727 loss: 4.48305741e-07
Iter: 728 loss: 4.48214621e-07
Iter: 729 loss: 4.48346896e-07
Iter: 730 loss: 4.48200495e-07
Iter: 731 loss: 4.48165707e-07
Iter: 732 loss: 4.48465045e-07
Iter: 733 loss: 4.48179861e-07
Iter: 734 loss: 4.48131914e-07
Iter: 735 loss: 4.47995262e-07
Iter: 736 loss: 4.49161803e-07
Iter: 737 loss: 4.48022575e-07
Iter: 738 loss: 4.47937964e-07
Iter: 739 loss: 4.48583592e-07
Iter: 740 loss: 4.47938902e-07
Iter: 741 loss: 4.47889761e-07
Iter: 742 loss: 4.47961895e-07
Iter: 743 loss: 4.47866029e-07
Iter: 744 loss: 4.47739978e-07
Iter: 745 loss: 4.4807939e-07
Iter: 746 loss: 4.47736852e-07
Iter: 747 loss: 4.47701154e-07
Iter: 748 loss: 4.47760385e-07
Iter: 749 loss: 4.47656674e-07
Iter: 750 loss: 4.47620636e-07
Iter: 751 loss: 4.47645078e-07
Iter: 752 loss: 4.47567e-07
Iter: 753 loss: 4.47537104e-07
Iter: 754 loss: 4.47651047e-07
Iter: 755 loss: 4.47514708e-07
Iter: 756 loss: 4.47435411e-07
Iter: 757 loss: 4.47667247e-07
Iter: 758 loss: 4.47376834e-07
Iter: 759 loss: 4.47330791e-07
Iter: 760 loss: 4.47702462e-07
Iter: 761 loss: 4.47343552e-07
Iter: 762 loss: 4.47305496e-07
Iter: 763 loss: 4.47551827e-07
Iter: 764 loss: 4.47306746e-07
Iter: 765 loss: 4.47251978e-07
Iter: 766 loss: 4.47251921e-07
Iter: 767 loss: 4.47228729e-07
Iter: 768 loss: 4.47188256e-07
Iter: 769 loss: 4.47916022e-07
Iter: 770 loss: 4.47188569e-07
Iter: 771 loss: 4.47142611e-07
Iter: 772 loss: 4.47239529e-07
Iter: 773 loss: 4.47130873e-07
Iter: 774 loss: 4.47074626e-07
Iter: 775 loss: 4.47342131e-07
Iter: 776 loss: 4.47086052e-07
Iter: 777 loss: 4.47009711e-07
Iter: 778 loss: 4.47098699e-07
Iter: 779 loss: 4.47005505e-07
Iter: 780 loss: 4.47008802e-07
Iter: 781 loss: 4.46989958e-07
Iter: 782 loss: 4.46975349e-07
Iter: 783 loss: 4.46980181e-07
Iter: 784 loss: 4.47015395e-07
Iter: 785 loss: 4.46976287e-07
Iter: 786 loss: 4.46997547e-07
Iter: 787 loss: 4.46993425e-07
Iter: 788 loss: 4.46993255e-07
Iter: 789 loss: 4.47015225e-07
Iter: 790 loss: 4.47011502e-07
Iter: 791 loss: 4.47004481e-07
Iter: 792 loss: 4.46999906e-07
Iter: 793 loss: 4.46987144e-07
Iter: 794 loss: 4.47010223e-07
Iter: 795 loss: 4.47018579e-07
Iter: 796 loss: 4.46988025e-07
Iter: 797 loss: 4.47018834e-07
Iter: 798 loss: 4.47017726e-07
Iter: 799 loss: 4.46988e-07
Iter: 800 loss: 4.47018181e-07
Iter: 801 loss: 4.47018e-07
Iter: 802 loss: 4.4698794e-07
Iter: 803 loss: 4.46986661e-07
Iter: 804 loss: 4.46986661e-07
Iter: 805 loss: 4.47018e-07
Iter: 806 loss: 4.46935587e-07
Iter: 807 loss: 4.47055442e-07
Iter: 808 loss: 4.46985098e-07
Iter: 809 loss: 4.46905858e-07
Iter: 810 loss: 4.46860497e-07
Iter: 811 loss: 4.46852852e-07
Iter: 812 loss: 4.46782593e-07
Iter: 813 loss: 4.46795354e-07
Iter: 814 loss: 4.46767331e-07
Iter: 815 loss: 4.46685135e-07
Iter: 816 loss: 4.47083067e-07
Iter: 817 loss: 4.46672658e-07
Iter: 818 loss: 4.46648187e-07
Iter: 819 loss: 4.47271447e-07
Iter: 820 loss: 4.46638154e-07
Iter: 821 loss: 4.4659464e-07
Iter: 822 loss: 4.46540582e-07
Iter: 823 loss: 4.46539275e-07
Iter: 824 loss: 4.46494198e-07
Iter: 825 loss: 4.46758406e-07
Iter: 826 loss: 4.46436e-07
Iter: 827 loss: 4.46366016e-07
Iter: 828 loss: 4.46337936e-07
Iter: 829 loss: 4.46315795e-07
Iter: 830 loss: 4.46221293e-07
Iter: 831 loss: 4.47056266e-07
Iter: 832 loss: 4.46194662e-07
Iter: 833 loss: 4.46165302e-07
Iter: 834 loss: 4.46165132e-07
Iter: 835 loss: 4.46112381e-07
Iter: 836 loss: 4.46033141e-07
Iter: 837 loss: 4.45885576e-07
Iter: 838 loss: 4.45853971e-07
Iter: 839 loss: 4.45808041e-07
Iter: 840 loss: 4.45794115e-07
Iter: 841 loss: 4.45727721e-07
Iter: 842 loss: 4.45780216e-07
Iter: 843 loss: 4.45678324e-07
Iter: 844 loss: 4.45632054e-07
Iter: 845 loss: 4.45820945e-07
Iter: 846 loss: 4.45633304e-07
Iter: 847 loss: 4.45574386e-07
Iter: 848 loss: 4.45819722e-07
Iter: 849 loss: 4.45569896e-07
Iter: 850 loss: 4.45549404e-07
Iter: 851 loss: 4.45963877e-07
Iter: 852 loss: 4.45542412e-07
Iter: 853 loss: 4.45507624e-07
Iter: 854 loss: 4.45497875e-07
Iter: 855 loss: 4.45497676e-07
Iter: 856 loss: 4.45454418e-07
Iter: 857 loss: 4.45806222e-07
Iter: 858 loss: 4.45433955e-07
Iter: 859 loss: 4.45396381e-07
Iter: 860 loss: 4.45339197e-07
Iter: 861 loss: 4.45367618e-07
Iter: 862 loss: 4.45324844e-07
Iter: 863 loss: 4.45485739e-07
Iter: 864 loss: 4.45309382e-07
Iter: 865 loss: 4.45272775e-07
Iter: 866 loss: 4.4546448e-07
Iter: 867 loss: 4.45249384e-07
Iter: 868 loss: 4.45236708e-07
Iter: 869 loss: 4.45155166e-07
Iter: 870 loss: 4.45150363e-07
Iter: 871 loss: 4.45017605e-07
Iter: 872 loss: 4.45325441e-07
Iter: 873 loss: 4.45014251e-07
Iter: 874 loss: 4.44927934e-07
Iter: 875 loss: 4.46005885e-07
Iter: 876 loss: 4.44931089e-07
Iter: 877 loss: 4.44885984e-07
Iter: 878 loss: 4.44888542e-07
Iter: 879 loss: 4.44852333e-07
Iter: 880 loss: 4.44804385e-07
Iter: 881 loss: 4.44721223e-07
Iter: 882 loss: 4.44762406e-07
Iter: 883 loss: 4.44671343e-07
Iter: 884 loss: 4.44663584e-07
Iter: 885 loss: 4.44609043e-07
Iter: 886 loss: 4.44995663e-07
Iter: 887 loss: 4.44628057e-07
Iter: 888 loss: 4.44567462e-07
Iter: 889 loss: 4.4460495e-07
Iter: 890 loss: 4.44560385e-07
Iter: 891 loss: 4.44501666e-07
Iter: 892 loss: 4.44631553e-07
Iter: 893 loss: 4.44523607e-07
Iter: 894 loss: 4.44481856e-07
Iter: 895 loss: 4.44445789e-07
Iter: 896 loss: 4.4445386e-07
Iter: 897 loss: 4.44375473e-07
Iter: 898 loss: 4.44365241e-07
Iter: 899 loss: 4.44359216e-07
Iter: 900 loss: 4.44304e-07
Iter: 901 loss: 4.44293107e-07
Iter: 902 loss: 4.4421563e-07
Iter: 903 loss: 4.44287934e-07
Iter: 904 loss: 4.44167256e-07
Iter: 905 loss: 4.44142074e-07
Iter: 906 loss: 4.44107883e-07
Iter: 907 loss: 4.44103677e-07
Iter: 908 loss: 4.44024124e-07
Iter: 909 loss: 4.44015598e-07
Iter: 910 loss: 4.43947641e-07
Iter: 911 loss: 4.43929679e-07
Iter: 912 loss: 4.43873091e-07
Iter: 913 loss: 4.43835489e-07
Iter: 914 loss: 4.44043508e-07
Iter: 915 loss: 4.43870761e-07
Iter: 916 loss: 4.43747155e-07
Iter: 917 loss: 4.43728283e-07
Iter: 918 loss: 4.4367593e-07
Iter: 919 loss: 4.43652965e-07
Iter: 920 loss: 4.43628551e-07
Iter: 921 loss: 4.43569945e-07
Iter: 922 loss: 4.43649498e-07
Iter: 923 loss: 4.43569149e-07
Iter: 924 loss: 4.43527767e-07
Iter: 925 loss: 4.43626675e-07
Iter: 926 loss: 4.43515376e-07
Iter: 927 loss: 4.4344867e-07
Iter: 928 loss: 4.43491587e-07
Iter: 929 loss: 4.43443213e-07
Iter: 930 loss: 4.4338e-07
Iter: 931 loss: 4.43378099e-07
Iter: 932 loss: 4.43323955e-07
Iter: 933 loss: 4.43332e-07
Iter: 934 loss: 4.43289423e-07
Iter: 935 loss: 4.43264128e-07
Iter: 936 loss: 4.43171587e-07
Iter: 937 loss: 4.44126e-07
Iter: 938 loss: 4.4315891e-07
Iter: 939 loss: 4.43084758e-07
Iter: 940 loss: 4.43448698e-07
Iter: 941 loss: 4.43079273e-07
Iter: 942 loss: 4.43031354e-07
Iter: 943 loss: 4.43378383e-07
Iter: 944 loss: 4.43028966e-07
Iter: 945 loss: 4.42983321e-07
Iter: 946 loss: 4.43145211e-07
Iter: 947 loss: 4.42956775e-07
Iter: 948 loss: 4.42947794e-07
Iter: 949 loss: 4.42868156e-07
Iter: 950 loss: 4.42903939e-07
Iter: 951 loss: 4.42785e-07
Iter: 952 loss: 4.42989631e-07
Iter: 953 loss: 4.42799887e-07
Iter: 954 loss: 4.42786757e-07
Iter: 955 loss: 4.42782095e-07
Iter: 956 loss: 4.42747591e-07
Iter: 957 loss: 4.42707915e-07
Iter: 958 loss: 4.43508867e-07
Iter: 959 loss: 4.4266838e-07
Iter: 960 loss: 4.42658347e-07
Iter: 961 loss: 4.43094308e-07
Iter: 962 loss: 4.42617136e-07
Iter: 963 loss: 4.42613043e-07
Iter: 964 loss: 4.42616169e-07
Iter: 965 loss: 4.42607814e-07
Iter: 966 loss: 4.425616e-07
Iter: 967 loss: 4.42697143e-07
Iter: 968 loss: 4.42538237e-07
Iter: 969 loss: 4.42477443e-07
Iter: 970 loss: 4.4261958e-07
Iter: 971 loss: 4.4248128e-07
Iter: 972 loss: 4.42453256e-07
Iter: 973 loss: 4.4244274e-07
Iter: 974 loss: 4.42410567e-07
Iter: 975 loss: 4.42342582e-07
Iter: 976 loss: 4.42351677e-07
Iter: 977 loss: 4.42335079e-07
Iter: 978 loss: 4.42256038e-07
Iter: 979 loss: 4.42797926e-07
Iter: 980 loss: 4.42248961e-07
Iter: 981 loss: 4.42143119e-07
Iter: 982 loss: 4.42596615e-07
Iter: 983 loss: 4.42171086e-07
Iter: 984 loss: 4.42123394e-07
Iter: 985 loss: 4.42104636e-07
Iter: 986 loss: 4.4211464e-07
Iter: 987 loss: 4.42014652e-07
Iter: 988 loss: 4.42175093e-07
Iter: 989 loss: 4.42016983e-07
Iter: 990 loss: 4.41963863e-07
Iter: 991 loss: 4.41996036e-07
Iter: 992 loss: 4.41977761e-07
Iter: 993 loss: 4.41960253e-07
Iter: 994 loss: 4.4192285e-07
Iter: 995 loss: 4.41891615e-07
Iter: 996 loss: 4.41924612e-07
Iter: 997 loss: 4.41865154e-07
Iter: 998 loss: 4.41814365e-07
Iter: 999 loss: 4.42121461e-07
Iter: 1000 loss: 4.4178114e-07
Iter: 1001 loss: 4.41727224e-07
Iter: 1002 loss: 4.41865041e-07
Iter: 1003 loss: 4.41736034e-07
Iter: 1004 loss: 4.41663303e-07
Iter: 1005 loss: 4.41733846e-07
Iter: 1006 loss: 4.41691327e-07
Iter: 1007 loss: 4.41581818e-07
Iter: 1008 loss: 4.41635e-07
Iter: 1009 loss: 4.41600292e-07
Iter: 1010 loss: 4.41540692e-07
Iter: 1011 loss: 4.41493597e-07
Iter: 1012 loss: 4.41439e-07
Iter: 1013 loss: 4.41358111e-07
Iter: 1014 loss: 4.42479575e-07
Iter: 1015 loss: 4.41379598e-07
Iter: 1016 loss: 4.4128663e-07
Iter: 1017 loss: 4.41462703e-07
Iter: 1018 loss: 4.41289274e-07
Iter: 1019 loss: 4.41219271e-07
Iter: 1020 loss: 4.41529039e-07
Iter: 1021 loss: 4.41245049e-07
Iter: 1022 loss: 4.41224245e-07
Iter: 1023 loss: 4.41358196e-07
Iter: 1024 loss: 4.41190821e-07
Iter: 1025 loss: 4.41143072e-07
Iter: 1026 loss: 4.4120867e-07
Iter: 1027 loss: 4.41138525e-07
Iter: 1028 loss: 4.41099274e-07
Iter: 1029 loss: 4.41241212e-07
Iter: 1030 loss: 4.41097484e-07
Iter: 1031 loss: 4.4105451e-07
Iter: 1032 loss: 4.41058887e-07
Iter: 1033 loss: 4.41027055e-07
Iter: 1034 loss: 4.40985644e-07
Iter: 1035 loss: 4.41803053e-07
Iter: 1036 loss: 4.41004289e-07
Iter: 1037 loss: 4.40932297e-07
Iter: 1038 loss: 4.41181044e-07
Iter: 1039 loss: 4.40936731e-07
Iter: 1040 loss: 4.40890176e-07
Iter: 1041 loss: 4.40890062e-07
Iter: 1042 loss: 4.40888783e-07
Iter: 1043 loss: 4.408422e-07
Iter: 1044 loss: 4.41057921e-07
Iter: 1045 loss: 4.40783822e-07
Iter: 1046 loss: 4.4070282e-07
Iter: 1047 loss: 4.40951851e-07
Iter: 1048 loss: 4.40714302e-07
Iter: 1049 loss: 4.40658766e-07
Iter: 1050 loss: 4.40572393e-07
Iter: 1051 loss: 4.40552839e-07
Iter: 1052 loss: 4.40468511e-07
Iter: 1053 loss: 4.41204691e-07
Iter: 1054 loss: 4.40468938e-07
Iter: 1055 loss: 4.40417921e-07
Iter: 1056 loss: 4.40465641e-07
Iter: 1057 loss: 4.40429403e-07
Iter: 1058 loss: 4.4029531e-07
Iter: 1059 loss: 4.41077248e-07
Iter: 1060 loss: 4.40280331e-07
Iter: 1061 loss: 4.40239717e-07
Iter: 1062 loss: 4.40257708e-07
Iter: 1063 loss: 4.40210215e-07
Iter: 1064 loss: 4.40196374e-07
Iter: 1065 loss: 4.40449583e-07
Iter: 1066 loss: 4.40187875e-07
Iter: 1067 loss: 4.40171732e-07
Iter: 1068 loss: 4.40147801e-07
Iter: 1069 loss: 4.40118015e-07
Iter: 1070 loss: 4.40054521e-07
Iter: 1071 loss: 4.40998292e-07
Iter: 1072 loss: 4.40073308e-07
Iter: 1073 loss: 4.40003021e-07
Iter: 1074 loss: 4.40540134e-07
Iter: 1075 loss: 4.40015583e-07
Iter: 1076 loss: 4.399933e-07
Iter: 1077 loss: 4.40023513e-07
Iter: 1078 loss: 4.39996029e-07
Iter: 1079 loss: 4.39924577e-07
Iter: 1080 loss: 4.40093487e-07
Iter: 1081 loss: 4.39928527e-07
Iter: 1082 loss: 4.39918097e-07
Iter: 1083 loss: 4.39952089e-07
Iter: 1084 loss: 4.39883536e-07
Iter: 1085 loss: 4.39865033e-07
Iter: 1086 loss: 4.39831297e-07
Iter: 1087 loss: 4.39811885e-07
Iter: 1088 loss: 4.39780962e-07
Iter: 1089 loss: 4.40053299e-07
Iter: 1090 loss: 4.39791108e-07
Iter: 1091 loss: 4.39660255e-07
Iter: 1092 loss: 4.39719088e-07
Iter: 1093 loss: 4.39622426e-07
Iter: 1094 loss: 4.3959821e-07
Iter: 1095 loss: 4.39591901e-07
Iter: 1096 loss: 4.39578798e-07
Iter: 1097 loss: 4.3951573e-07
Iter: 1098 loss: 4.39483784e-07
Iter: 1099 loss: 4.39461246e-07
Iter: 1100 loss: 4.39433734e-07
Iter: 1101 loss: 4.39429101e-07
Iter: 1102 loss: 4.39443085e-07
Iter: 1103 loss: 4.39424383e-07
Iter: 1104 loss: 4.39344035e-07
Iter: 1105 loss: 4.39350572e-07
Iter: 1106 loss: 4.39325419e-07
Iter: 1107 loss: 4.39291853e-07
Iter: 1108 loss: 4.39660738e-07
Iter: 1109 loss: 4.39256667e-07
Iter: 1110 loss: 4.39239898e-07
Iter: 1111 loss: 4.39211561e-07
Iter: 1112 loss: 4.39165518e-07
Iter: 1113 loss: 4.39078576e-07
Iter: 1114 loss: 4.39859122e-07
Iter: 1115 loss: 4.39098528e-07
Iter: 1116 loss: 4.39067e-07
Iter: 1117 loss: 4.39057828e-07
Iter: 1118 loss: 4.39023665e-07
Iter: 1119 loss: 4.38944909e-07
Iter: 1120 loss: 4.39031254e-07
Iter: 1121 loss: 4.38893181e-07
Iter: 1122 loss: 4.38879312e-07
Iter: 1123 loss: 4.38939793e-07
Iter: 1124 loss: 4.38833638e-07
Iter: 1125 loss: 4.38733139e-07
Iter: 1126 loss: 4.39549069e-07
Iter: 1127 loss: 4.38765284e-07
Iter: 1128 loss: 4.38697441e-07
Iter: 1129 loss: 4.38769518e-07
Iter: 1130 loss: 4.3872393e-07
Iter: 1131 loss: 4.38659981e-07
Iter: 1132 loss: 4.38947723e-07
Iter: 1133 loss: 4.38632583e-07
Iter: 1134 loss: 4.3860814e-07
Iter: 1135 loss: 4.38764403e-07
Iter: 1136 loss: 4.38615189e-07
Iter: 1137 loss: 4.38528559e-07
Iter: 1138 loss: 4.3887178e-07
Iter: 1139 loss: 4.38514405e-07
Iter: 1140 loss: 4.38528588e-07
Iter: 1141 loss: 4.38519237e-07
Iter: 1142 loss: 4.38514661e-07
Iter: 1143 loss: 4.38536631e-07
Iter: 1144 loss: 4.38540638e-07
Iter: 1145 loss: 4.38551467e-07
Iter: 1146 loss: 4.38522733e-07
Iter: 1147 loss: 4.38518896e-07
Iter: 1148 loss: 4.38519237e-07
Iter: 1149 loss: 4.38524381e-07
Iter: 1150 loss: 4.38512473e-07
Iter: 1151 loss: 4.38524609e-07
Iter: 1152 loss: 4.38519436e-07
Iter: 1153 loss: 4.38515258e-07
Iter: 1154 loss: 4.38509943e-07
Iter: 1155 loss: 4.38513553e-07
Iter: 1156 loss: 4.38512302e-07
Iter: 1157 loss: 4.38514604e-07
Iter: 1158 loss: 4.38514945e-07
Iter: 1159 loss: 4.38513894e-07
Iter: 1160 loss: 4.38514348e-07
Iter: 1161 loss: 4.38514945e-07
Iter: 1162 loss: 4.38514348e-07
Iter: 1163 loss: 4.38514348e-07
Iter: 1164 loss: 4.38514348e-07
Iter: 1165 loss: 4.38514945e-07
Iter: 1166 loss: 4.38514348e-07
Iter: 1167 loss: 4.38472767e-07
Iter: 1168 loss: 4.39425179e-07
Iter: 1169 loss: 4.38443976e-07
Iter: 1170 loss: 4.38411e-07
Iter: 1171 loss: 4.3854547e-07
Iter: 1172 loss: 4.38408847e-07
Iter: 1173 loss: 4.38385172e-07
Iter: 1174 loss: 4.38597851e-07
Iter: 1175 loss: 4.38351094e-07
Iter: 1176 loss: 4.38314032e-07
Iter: 1177 loss: 4.38331028e-07
Iter: 1178 loss: 4.38297207e-07
Iter: 1179 loss: 4.3826185e-07
Iter: 1180 loss: 4.38367806e-07
Iter: 1181 loss: 4.38222457e-07
Iter: 1182 loss: 4.38196764e-07
Iter: 1183 loss: 4.38609732e-07
Iter: 1184 loss: 4.3822e-07
Iter: 1185 loss: 4.38172776e-07
Iter: 1186 loss: 4.38203472e-07
Iter: 1187 loss: 4.39135675e-07
Iter: 1188 loss: 4.38146458e-07
Iter: 1189 loss: 4.38070572e-07
Iter: 1190 loss: 4.3825213e-07
Iter: 1191 loss: 4.38039564e-07
Iter: 1192 loss: 4.37987381e-07
Iter: 1193 loss: 4.38330289e-07
Iter: 1194 loss: 4.3795302e-07
Iter: 1195 loss: 4.37891174e-07
Iter: 1196 loss: 4.38166978e-07
Iter: 1197 loss: 4.37878839e-07
Iter: 1198 loss: 4.37833137e-07
Iter: 1199 loss: 4.38228369e-07
Iter: 1200 loss: 4.37850588e-07
Iter: 1201 loss: 4.37826174e-07
Iter: 1202 loss: 4.37772258e-07
Iter: 1203 loss: 4.38865357e-07
Iter: 1204 loss: 4.37783086e-07
Iter: 1205 loss: 4.377045e-07
Iter: 1206 loss: 4.37785388e-07
Iter: 1207 loss: 4.37697565e-07
Iter: 1208 loss: 4.37631087e-07
Iter: 1209 loss: 4.37828731e-07
Iter: 1210 loss: 4.37617018e-07
Iter: 1211 loss: 4.37552501e-07
Iter: 1212 loss: 4.38008158e-07
Iter: 1213 loss: 4.37545737e-07
Iter: 1214 loss: 4.37474512e-07
Iter: 1215 loss: 4.37528257e-07
Iter: 1216 loss: 4.37485568e-07
Iter: 1217 loss: 4.37449444e-07
Iter: 1218 loss: 4.37375689e-07
Iter: 1219 loss: 4.37357187e-07
Iter: 1220 loss: 4.37356874e-07
Iter: 1221 loss: 4.3730833e-07
Iter: 1222 loss: 4.37326378e-07
Iter: 1223 loss: 4.37312679e-07
Iter: 1224 loss: 4.37312e-07
Iter: 1225 loss: 4.37306852e-07
Iter: 1226 loss: 4.37319272e-07
Iter: 1227 loss: 4.37319471e-07
Iter: 1228 loss: 4.37321773e-07
Iter: 1229 loss: 4.37329049e-07
Iter: 1230 loss: 4.37293636e-07
Iter: 1231 loss: 4.37302901e-07
Iter: 1232 loss: 4.37309097e-07
Iter: 1233 loss: 4.37301878e-07
Iter: 1234 loss: 4.37294261e-07
Iter: 1235 loss: 4.37292584e-07
Iter: 1236 loss: 4.37294489e-07
Iter: 1237 loss: 4.37303783e-07
Iter: 1238 loss: 4.37309893e-07
Iter: 1239 loss: 4.37309438e-07
Iter: 1240 loss: 4.37302816e-07
Iter: 1241 loss: 4.37303612e-07
Iter: 1242 loss: 4.3730887e-07
Iter: 1243 loss: 4.37305403e-07
Iter: 1244 loss: 4.37305516e-07
Iter: 1245 loss: 4.37305516e-07
Iter: 1246 loss: 4.37308813e-07
Iter: 1247 loss: 4.37305516e-07
Iter: 1248 loss: 4.37308813e-07
Iter: 1249 loss: 4.37305516e-07
Iter: 1250 loss: 4.3721019e-07
Iter: 1251 loss: 4.38876043e-07
Iter: 1252 loss: 4.37193876e-07
Iter: 1253 loss: 4.37146099e-07
Iter: 1254 loss: 4.37519418e-07
Iter: 1255 loss: 4.37177192e-07
Iter: 1256 loss: 4.37138937e-07
Iter: 1257 loss: 4.37133338e-07
Iter: 1258 loss: 4.37072799e-07
Iter: 1259 loss: 4.37094968e-07
Iter: 1260 loss: 4.37084736e-07
Iter: 1261 loss: 4.37041138e-07
Iter: 1262 loss: 4.37037841e-07
Iter: 1263 loss: 4.37003024e-07
Iter: 1264 loss: 4.37008e-07
Iter: 1265 loss: 4.37009504e-07
Iter: 1266 loss: 4.37002797e-07
Iter: 1267 loss: 4.37006804e-07
Iter: 1268 loss: 4.36993446e-07
Iter: 1269 loss: 4.36987023e-07
Iter: 1270 loss: 4.36995322e-07
Iter: 1271 loss: 4.36986227e-07
Iter: 1272 loss: 4.37004019e-07
Iter: 1273 loss: 4.36986511e-07
Iter: 1274 loss: 4.36995776e-07
Iter: 1275 loss: 4.3699788e-07
Iter: 1276 loss: 4.36999414e-07
Iter: 1277 loss: 4.37007941e-07
Iter: 1278 loss: 4.37004815e-07
Iter: 1279 loss: 4.37000779e-07
Iter: 1280 loss: 4.37006292e-07
Iter: 1281 loss: 4.37001916e-07
Iter: 1282 loss: 4.37000637e-07
Iter: 1283 loss: 4.37003678e-07
Iter: 1284 loss: 4.37003735e-07
Iter: 1285 loss: 4.37001233e-07
Iter: 1286 loss: 4.37003791e-07
Iter: 1287 loss: 4.37001461e-07
Iter: 1288 loss: 4.37003791e-07
Iter: 1289 loss: 4.37001461e-07
Iter: 1290 loss: 4.37003791e-07
Iter: 1291 loss: 4.36943509e-07
Iter: 1292 loss: 4.37697963e-07
Iter: 1293 loss: 4.36965166e-07
Iter: 1294 loss: 4.36900848e-07
Iter: 1295 loss: 4.36894481e-07
Iter: 1296 loss: 4.36878111e-07
Iter: 1297 loss: 4.36794522e-07
Iter: 1298 loss: 4.36799809e-07
Iter: 1299 loss: 4.36772325e-07
Iter: 1300 loss: 4.36860546e-07
Iter: 1301 loss: 4.36685667e-07
Iter: 1302 loss: 4.36658979e-07
Iter: 1303 loss: 4.37243557e-07
Iter: 1304 loss: 4.36677084e-07
Iter: 1305 loss: 4.36655455e-07
Iter: 1306 loss: 4.36639027e-07
Iter: 1307 loss: 4.3663087e-07
Iter: 1308 loss: 4.36586674e-07
Iter: 1309 loss: 4.36539665e-07
Iter: 1310 loss: 4.36533725e-07
Iter: 1311 loss: 4.36513119e-07
Iter: 1312 loss: 4.36515535e-07
Iter: 1313 loss: 4.36477166e-07
Iter: 1314 loss: 4.36444395e-07
Iter: 1315 loss: 4.36439905e-07
Iter: 1316 loss: 4.36371806e-07
Iter: 1317 loss: 4.36528978e-07
Iter: 1318 loss: 4.36391645e-07
Iter: 1319 loss: 4.36327696e-07
Iter: 1320 loss: 4.36460198e-07
Iter: 1321 loss: 4.36318658e-07
Iter: 1322 loss: 4.36265367e-07
Iter: 1323 loss: 4.36226912e-07
Iter: 1324 loss: 4.37508504e-07
Iter: 1325 loss: 4.36216794e-07
Iter: 1326 loss: 4.36185928e-07
Iter: 1327 loss: 4.36894538e-07
Iter: 1328 loss: 4.36188742e-07
Iter: 1329 loss: 4.36157052e-07
Iter: 1330 loss: 4.36330424e-07
Iter: 1331 loss: 4.36131842e-07
Iter: 1332 loss: 4.36065e-07
Iter: 1333 loss: 4.3640398e-07
Iter: 1334 loss: 4.36073321e-07
Iter: 1335 loss: 4.36076505e-07
Iter: 1336 loss: 4.36088726e-07
Iter: 1337 loss: 4.36090914e-07
Iter: 1338 loss: 4.36079574e-07
Iter: 1339 loss: 4.36068547e-07
Iter: 1340 loss: 4.36082502e-07
Iter: 1341 loss: 4.36051323e-07
Iter: 1342 loss: 4.36090289e-07
Iter: 1343 loss: 4.36084406e-07
Iter: 1344 loss: 4.36072298e-07
Iter: 1345 loss: 4.36077585e-07
Iter: 1346 loss: 4.36080768e-07
Iter: 1347 loss: 4.36075084e-07
Iter: 1348 loss: 4.36069797e-07
Iter: 1349 loss: 4.36066671e-07
Iter: 1350 loss: 4.36073947e-07
Iter: 1351 loss: 4.36071e-07
Iter: 1352 loss: 4.36073719e-07
Iter: 1353 loss: 4.36073236e-07
Iter: 1354 loss: 4.36073321e-07
Iter: 1355 loss: 4.36073663e-07
Iter: 1356 loss: 4.36073975e-07
Iter: 1357 loss: 4.36073776e-07
Iter: 1358 loss: 4.36073634e-07
Iter: 1359 loss: 4.36073634e-07
Iter: 1360 loss: 4.36073776e-07
Iter: 1361 loss: 4.36073861e-07
Iter: 1362 loss: 4.36073776e-07
Iter: 1363 loss: 4.36073634e-07
Iter: 1364 loss: 4.36017672e-07
Iter: 1365 loss: 4.35973902e-07
Iter: 1366 loss: 4.35907424e-07
Iter: 1367 loss: 4.3639011e-07
Iter: 1368 loss: 4.35935561e-07
Iter: 1369 loss: 4.35876814e-07
Iter: 1370 loss: 4.36009657e-07
Iter: 1371 loss: 4.35874853e-07
Iter: 1372 loss: 4.35861693e-07
Iter: 1373 loss: 4.35847966e-07
Iter: 1374 loss: 4.35812694e-07
Iter: 1375 loss: 4.3583492e-07
Iter: 1376 loss: 4.3581224e-07
Iter: 1377 loss: 4.35788024e-07
Iter: 1378 loss: 4.35781715e-07
Iter: 1379 loss: 4.35756789e-07
Iter: 1380 loss: 4.35719386e-07
Iter: 1381 loss: 4.35713758e-07
Iter: 1382 loss: 4.35695597e-07
Iter: 1383 loss: 4.35636736e-07
Iter: 1384 loss: 4.35669e-07
Iter: 1385 loss: 4.35620166e-07
Iter: 1386 loss: 4.35598565e-07
Iter: 1387 loss: 4.36110469e-07
Iter: 1388 loss: 4.35589868e-07
Iter: 1389 loss: 4.35569405e-07
Iter: 1390 loss: 4.35516085e-07
Iter: 1391 loss: 4.36574595e-07
Iter: 1392 loss: 4.35531831e-07
Iter: 1393 loss: 4.35476977e-07
Iter: 1394 loss: 4.35803258e-07
Iter: 1395 loss: 4.35463392e-07
Iter: 1396 loss: 4.35452336e-07
Iter: 1397 loss: 4.35413057e-07
Iter: 1398 loss: 4.35368577e-07
Iter: 1399 loss: 4.3534493e-07
Iter: 1400 loss: 4.3534277e-07
Iter: 1401 loss: 4.35285699e-07
Iter: 1402 loss: 4.35344589e-07
Iter: 1403 loss: 4.35291668e-07
Iter: 1404 loss: 4.3524841e-07
Iter: 1405 loss: 4.35245113e-07
Iter: 1406 loss: 4.35160018e-07
Iter: 1407 loss: 4.35130346e-07
Iter: 1408 loss: 4.35389182e-07
Iter: 1409 loss: 4.35122672e-07
Iter: 1410 loss: 4.35070547e-07
Iter: 1411 loss: 4.35045934e-07
Iter: 1412 loss: 4.35020723e-07
Iter: 1413 loss: 4.34963852e-07
Iter: 1414 loss: 4.36076363e-07
Iter: 1415 loss: 4.3497181e-07
Iter: 1416 loss: 4.3497289e-07
Iter: 1417 loss: 4.34981331e-07
Iter: 1418 loss: 4.3501467e-07
Iter: 1419 loss: 4.35001255e-07
Iter: 1420 loss: 4.3497181e-07
Iter: 1421 loss: 4.34970445e-07
Iter: 1422 loss: 4.35016688e-07
Iter: 1423 loss: 4.34984145e-07
Iter: 1424 loss: 4.34993808e-07
Iter: 1425 loss: 4.34986134e-07
Iter: 1426 loss: 4.34987385e-07
Iter: 1427 loss: 4.34977892e-07
Iter: 1428 loss: 4.34970588e-07
Iter: 1429 loss: 4.34991875e-07
Iter: 1430 loss: 4.34988749e-07
Iter: 1431 loss: 4.34975902e-07
Iter: 1432 loss: 4.34977e-07
Iter: 1433 loss: 4.3497181e-07
Iter: 1434 loss: 4.3497198e-07
Iter: 1435 loss: 4.34974964e-07
Iter: 1436 loss: 4.34972776e-07
Iter: 1437 loss: 4.34971895e-07
Iter: 1438 loss: 4.34971923e-07
Iter: 1439 loss: 4.34972037e-07
Iter: 1440 loss: 4.34972293e-07
Iter: 1441 loss: 4.34972037e-07
Iter: 1442 loss: 4.34972037e-07
Iter: 1443 loss: 4.34972293e-07
Iter: 1444 loss: 4.34972037e-07
Iter: 1445 loss: 4.34900755e-07
Iter: 1446 loss: 4.35817611e-07
Iter: 1447 loss: 4.34902262e-07
Iter: 1448 loss: 4.34872049e-07
Iter: 1449 loss: 4.34986362e-07
Iter: 1450 loss: 4.34839734e-07
Iter: 1451 loss: 4.34845248e-07
Iter: 1452 loss: 4.34853547e-07
Iter: 1453 loss: 4.34863466e-07
Iter: 1454 loss: 4.34872391e-07
Iter: 1455 loss: 4.34882026e-07
Iter: 1456 loss: 4.34867275e-07
Iter: 1457 loss: 4.34849085e-07
Iter: 1458 loss: 4.34837659e-07
Iter: 1459 loss: 4.34850392e-07
Iter: 1460 loss: 4.34845361e-07
Iter: 1461 loss: 4.34848687e-07
Iter: 1462 loss: 4.34863779e-07
Iter: 1463 loss: 4.34837176e-07
Iter: 1464 loss: 4.34847351e-07
Iter: 1465 loss: 4.34843969e-07
Iter: 1466 loss: 4.34836409e-07
Iter: 1467 loss: 4.34836835e-07
Iter: 1468 loss: 4.34837489e-07
Iter: 1469 loss: 4.34841809e-07
Iter: 1470 loss: 4.34840132e-07
Iter: 1471 loss: 4.348434e-07
Iter: 1472 loss: 4.3484053e-07
Iter: 1473 loss: 4.34840132e-07
Iter: 1474 loss: 4.34840018e-07
Iter: 1475 loss: 4.3484053e-07
Iter: 1476 loss: 4.3484053e-07
Iter: 1477 loss: 4.34840615e-07
Iter: 1478 loss: 4.34840018e-07
Iter: 1479 loss: 4.34840018e-07
Iter: 1480 loss: 4.34839933e-07
Iter: 1481 loss: 4.34840615e-07
Iter: 1482 loss: 4.34839933e-07
Iter: 1483 loss: 4.3482305e-07
Iter: 1484 loss: 4.34825608e-07
Iter: 1485 loss: 4.34763223e-07
Iter: 1486 loss: 4.34878274e-07
Iter: 1487 loss: 4.34761489e-07
Iter: 1488 loss: 4.34733749e-07
Iter: 1489 loss: 4.34778826e-07
Iter: 1490 loss: 4.34710273e-07
Iter: 1491 loss: 4.34703963e-07
Iter: 1492 loss: 4.34910561e-07
Iter: 1493 loss: 4.34726417e-07
Iter: 1494 loss: 4.3472258e-07
Iter: 1495 loss: 4.34693277e-07
Iter: 1496 loss: 4.34718601e-07
Iter: 1497 loss: 4.34697682e-07
Iter: 1498 loss: 4.34716696e-07
Iter: 1499 loss: 4.34706521e-07
Iter: 1500 loss: 4.34684779e-07
Iter: 1501 loss: 4.34706635e-07
Iter: 1502 loss: 4.34735057e-07
Iter: 1503 loss: 4.34713542e-07
Iter: 1504 loss: 4.34710415e-07
Iter: 1505 loss: 4.34715133e-07
Iter: 1506 loss: 4.34726672e-07
Iter: 1507 loss: 4.34720334e-07
Iter: 1508 loss: 4.34716611e-07
Iter: 1509 loss: 4.34714821e-07
Iter: 1510 loss: 4.34708795e-07
Iter: 1511 loss: 4.34709648e-07
Iter: 1512 loss: 4.34711296e-07
Iter: 1513 loss: 4.34710671e-07
Iter: 1514 loss: 4.34710614e-07
Iter: 1515 loss: 4.34710728e-07
Iter: 1516 loss: 4.34710614e-07
Iter: 1517 loss: 4.34710728e-07
Iter: 1518 loss: 4.34710614e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.6/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2
+ date
Sat Nov  7 20:58:05 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi1.6/300_100_100_100_1 --function f1 --psi 0 --phi 2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713ebf840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713eee9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713ead9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713e5ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713dc4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713d9e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713cba8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713d38ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713d382f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713d1cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713d1c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713d1ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713c2e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6ee7291e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6ee71f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713ca19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713c8ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713c3af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713d181e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff713c3a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6ee692598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6ee6d5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6ee692d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6ee6abea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c85806a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c852bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c8599510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c852b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c84a40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c84a20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c84bf400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c84050d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c84056a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c83efae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c846a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff6c84fa598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.003626369
test_loss: 0.0038617533
train_loss: 0.0024323866
test_loss: 0.002140519
train_loss: 0.001963618
test_loss: 0.0020892592
train_loss: 0.0017502167
test_loss: 0.0018458932
train_loss: 0.001895041
test_loss: 0.0016878734
train_loss: 0.001962976
test_loss: 0.0017668516
train_loss: 0.0018944065
test_loss: 0.0016679171
train_loss: 0.0016586035
test_loss: 0.0015737457
train_loss: 0.0015519393
test_loss: 0.0018764766
train_loss: 0.001813072
test_loss: 0.0018099833
train_loss: 0.001576084
test_loss: 0.0017999053
train_loss: 0.0016514626
test_loss: 0.0019029739
train_loss: 0.0015201819
test_loss: 0.001465325
train_loss: 0.0015909667
test_loss: 0.0015116594
train_loss: 0.001644603
test_loss: 0.0016369721
train_loss: 0.0017470748
test_loss: 0.001809588
train_loss: 0.0020534967
test_loss: 0.0016845629
train_loss: 0.0015407379
test_loss: 0.0014804304
train_loss: 0.0014563156
test_loss: 0.002126662
train_loss: 0.0016061912
test_loss: 0.0019265588
train_loss: 0.0018284984
test_loss: 0.0014247805
train_loss: 0.0028310213
test_loss: 0.0031331808
train_loss: 0.0015546819
test_loss: 0.0014640583
train_loss: 0.0016076689
test_loss: 0.0015950282
train_loss: 0.0017852105
test_loss: 0.0016859894
train_loss: 0.0020370425
test_loss: 0.0015447454
train_loss: 0.00174428
test_loss: 0.0021065783
train_loss: 0.0017759755
test_loss: 0.0018461426
train_loss: 0.00206161
test_loss: 0.0018140452
train_loss: 0.001812606
test_loss: 0.0017316433
train_loss: 0.0031543516
test_loss: 0.002782746
train_loss: 0.0016794789
test_loss: 0.0020537549
train_loss: 0.0013195302
test_loss: 0.001457317
train_loss: 0.0015811528
test_loss: 0.0015590457
train_loss: 0.0014769405
test_loss: 0.0017505138
train_loss: 0.0017378696
test_loss: 0.0014896443
train_loss: 0.0015681081
test_loss: 0.0017771465
train_loss: 0.0013152014
test_loss: 0.0015171058
train_loss: 0.0014516218
test_loss: 0.002411087
train_loss: 0.0015250354
test_loss: 0.0016326555
train_loss: 0.001741526
test_loss: 0.0014979712
train_loss: 0.0016038793
test_loss: 0.0015025162
train_loss: 0.0018504474
test_loss: 0.0015694844
train_loss: 0.0018259131
test_loss: 0.0015739411
train_loss: 0.0015481564
test_loss: 0.0015602695
train_loss: 0.0020728863
test_loss: 0.0014825349
train_loss: 0.0017987008
test_loss: 0.0017832234
train_loss: 0.0017763139
test_loss: 0.0016223782
train_loss: 0.0013273789
test_loss: 0.0013761412
train_loss: 0.0016584052
test_loss: 0.001766233
train_loss: 0.0013827382
test_loss: 0.0016815664
train_loss: 0.001624088
test_loss: 0.0015626828
train_loss: 0.001419756
test_loss: 0.0016755469
train_loss: 0.00162816
test_loss: 0.0016069495
train_loss: 0.0016184013
test_loss: 0.0018235529
train_loss: 0.0018297399
test_loss: 0.001581289
train_loss: 0.0015273994
test_loss: 0.0018899422
train_loss: 0.0019695447
test_loss: 0.0018808991
train_loss: 0.0016716565
test_loss: 0.0016869508
train_loss: 0.0016795195
test_loss: 0.0016610336
train_loss: 0.0021242553
test_loss: 0.0017858322
train_loss: 0.0027286666
test_loss: 0.0027004697
train_loss: 0.0026729957
test_loss: 0.0021829195
train_loss: 0.0014187867
test_loss: 0.0017566453
train_loss: 0.0013288977
test_loss: 0.0016562835
train_loss: 0.0016644136
test_loss: 0.0013793343
train_loss: 0.0015985614
test_loss: 0.001537984
train_loss: 0.0015793027
test_loss: 0.001535096
train_loss: 0.001538995
test_loss: 0.0014554587
train_loss: 0.002045521
test_loss: 0.0021935261
train_loss: 0.0017092235
test_loss: 0.0016175344
train_loss: 0.0014139625
test_loss: 0.0015408972
train_loss: 0.0014773256
test_loss: 0.0015171433
train_loss: 0.0016507395
test_loss: 0.0015015627
train_loss: 0.0015396569
test_loss: 0.0017235241
train_loss: 0.0016242164
test_loss: 0.0013413273
train_loss: 0.0017443703
test_loss: 0.0015909197
train_loss: 0.002433967
test_loss: 0.0026319243
train_loss: 0.0016122612
test_loss: 0.0019063837
train_loss: 0.0016758644
test_loss: 0.001941267
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d489598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d440950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d3dfb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d4dc7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d4dc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d4dc510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d3638c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d3b0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d32c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d2c1158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d2c19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d28bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d2a5d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d2591e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d2080d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d208e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f394d26aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3936013f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3936017a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f39360132f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935ff36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935faa268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935ff3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935fbeea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935f536a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935f46ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935f16510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935f46268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935e910d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935eb20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935eab400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935e620d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935e627b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935e64ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935de01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3935e05f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.89667843e-06
Iter: 2 loss: 7.61223855e-05
Iter: 3 loss: 3.10871451e-06
Iter: 4 loss: 2.26179759e-06
Iter: 5 loss: 5.80037795e-06
Iter: 6 loss: 2.08005576e-06
Iter: 7 loss: 1.73394506e-06
Iter: 8 loss: 2.34672552e-06
Iter: 9 loss: 1.58215789e-06
Iter: 10 loss: 1.36547715e-06
Iter: 11 loss: 1.25919314e-06
Iter: 12 loss: 1.15554826e-06
Iter: 13 loss: 9.771e-07
Iter: 14 loss: 3.82712506e-06
Iter: 15 loss: 9.77078e-07
Iter: 16 loss: 9.15717806e-07
Iter: 17 loss: 8.93507035e-07
Iter: 18 loss: 8.59351474e-07
Iter: 19 loss: 7.86564897e-07
Iter: 20 loss: 1.14569525e-06
Iter: 21 loss: 7.7416928e-07
Iter: 22 loss: 7.32677108e-07
Iter: 23 loss: 1.03781485e-06
Iter: 24 loss: 7.29245755e-07
Iter: 25 loss: 7.04052297e-07
Iter: 26 loss: 9.60439138e-07
Iter: 27 loss: 7.03275475e-07
Iter: 28 loss: 6.88394948e-07
Iter: 29 loss: 6.97667701e-07
Iter: 30 loss: 6.78965762e-07
Iter: 31 loss: 6.64750246e-07
Iter: 32 loss: 7.02438683e-07
Iter: 33 loss: 6.59927196e-07
Iter: 34 loss: 6.5041263e-07
Iter: 35 loss: 6.65394111e-07
Iter: 36 loss: 6.45898638e-07
Iter: 37 loss: 6.5042866e-07
Iter: 38 loss: 6.42212683e-07
Iter: 39 loss: 6.39453674e-07
Iter: 40 loss: 6.36436653e-07
Iter: 41 loss: 6.35996344e-07
Iter: 42 loss: 6.31477519e-07
Iter: 43 loss: 6.47567731e-07
Iter: 44 loss: 6.30418867e-07
Iter: 45 loss: 6.26189262e-07
Iter: 46 loss: 6.22236712e-07
Iter: 47 loss: 6.21264348e-07
Iter: 48 loss: 6.16637635e-07
Iter: 49 loss: 6.45631246e-07
Iter: 50 loss: 6.16119678e-07
Iter: 51 loss: 6.12115855e-07
Iter: 52 loss: 6.24094241e-07
Iter: 53 loss: 6.10916e-07
Iter: 54 loss: 6.06935373e-07
Iter: 55 loss: 5.99773898e-07
Iter: 56 loss: 7.74179284e-07
Iter: 57 loss: 5.99815394e-07
Iter: 58 loss: 5.96201403e-07
Iter: 59 loss: 5.9600319e-07
Iter: 60 loss: 5.92555466e-07
Iter: 61 loss: 6.00216367e-07
Iter: 62 loss: 5.9122533e-07
Iter: 63 loss: 5.87316094e-07
Iter: 64 loss: 6.04535785e-07
Iter: 65 loss: 5.86548538e-07
Iter: 66 loss: 5.83567612e-07
Iter: 67 loss: 5.81048482e-07
Iter: 68 loss: 5.80259837e-07
Iter: 69 loss: 5.76883735e-07
Iter: 70 loss: 6.14977466e-07
Iter: 71 loss: 5.76730486e-07
Iter: 72 loss: 5.7627534e-07
Iter: 73 loss: 5.75687579e-07
Iter: 74 loss: 5.74509386e-07
Iter: 75 loss: 5.71739122e-07
Iter: 76 loss: 6.13973782e-07
Iter: 77 loss: 5.71667e-07
Iter: 78 loss: 5.70405859e-07
Iter: 79 loss: 5.7040603e-07
Iter: 80 loss: 5.6927496e-07
Iter: 81 loss: 5.67051814e-07
Iter: 82 loss: 6.15734564e-07
Iter: 83 loss: 5.67040559e-07
Iter: 84 loss: 5.64456172e-07
Iter: 85 loss: 5.74575438e-07
Iter: 86 loss: 5.63878871e-07
Iter: 87 loss: 5.62371611e-07
Iter: 88 loss: 5.71888222e-07
Iter: 89 loss: 5.62231548e-07
Iter: 90 loss: 5.60584624e-07
Iter: 91 loss: 5.613133e-07
Iter: 92 loss: 5.59633577e-07
Iter: 93 loss: 5.57865292e-07
Iter: 94 loss: 5.61957449e-07
Iter: 95 loss: 5.57155204e-07
Iter: 96 loss: 5.5537663e-07
Iter: 97 loss: 5.59797627e-07
Iter: 98 loss: 5.54726512e-07
Iter: 99 loss: 5.53300652e-07
Iter: 100 loss: 5.6453797e-07
Iter: 101 loss: 5.53210327e-07
Iter: 102 loss: 5.51882181e-07
Iter: 103 loss: 5.55758106e-07
Iter: 104 loss: 5.51525602e-07
Iter: 105 loss: 5.50159825e-07
Iter: 106 loss: 5.4812449e-07
Iter: 107 loss: 5.48096068e-07
Iter: 108 loss: 5.50106279e-07
Iter: 109 loss: 5.47142236e-07
Iter: 110 loss: 5.46625358e-07
Iter: 111 loss: 5.45499e-07
Iter: 112 loss: 5.60029e-07
Iter: 113 loss: 5.45463251e-07
Iter: 114 loss: 5.4434804e-07
Iter: 115 loss: 5.44349575e-07
Iter: 116 loss: 5.43368117e-07
Iter: 117 loss: 5.41356599e-07
Iter: 118 loss: 5.56108489e-07
Iter: 119 loss: 5.41223756e-07
Iter: 120 loss: 5.40476947e-07
Iter: 121 loss: 5.39147095e-07
Iter: 122 loss: 5.68579253e-07
Iter: 123 loss: 5.39184e-07
Iter: 124 loss: 5.37771825e-07
Iter: 125 loss: 5.45600699e-07
Iter: 126 loss: 5.37576e-07
Iter: 127 loss: 5.36554e-07
Iter: 128 loss: 5.39232644e-07
Iter: 129 loss: 5.36249161e-07
Iter: 130 loss: 5.35492e-07
Iter: 131 loss: 5.40015435e-07
Iter: 132 loss: 5.35435902e-07
Iter: 133 loss: 5.3474821e-07
Iter: 134 loss: 5.35471031e-07
Iter: 135 loss: 5.34471269e-07
Iter: 136 loss: 5.33783407e-07
Iter: 137 loss: 5.37556048e-07
Iter: 138 loss: 5.33749756e-07
Iter: 139 loss: 5.33149318e-07
Iter: 140 loss: 5.3243582e-07
Iter: 141 loss: 5.32381705e-07
Iter: 142 loss: 5.31224316e-07
Iter: 143 loss: 5.35273443e-07
Iter: 144 loss: 5.30945272e-07
Iter: 145 loss: 5.30119394e-07
Iter: 146 loss: 5.31089199e-07
Iter: 147 loss: 5.29727345e-07
Iter: 148 loss: 5.29622184e-07
Iter: 149 loss: 5.29211093e-07
Iter: 150 loss: 5.28710757e-07
Iter: 151 loss: 5.2859167e-07
Iter: 152 loss: 5.2830643e-07
Iter: 153 loss: 5.27922566e-07
Iter: 154 loss: 5.27252723e-07
Iter: 155 loss: 5.43366582e-07
Iter: 156 loss: 5.27251132e-07
Iter: 157 loss: 5.26344138e-07
Iter: 158 loss: 5.37452365e-07
Iter: 159 loss: 5.26333736e-07
Iter: 160 loss: 5.25736425e-07
Iter: 161 loss: 5.24918391e-07
Iter: 162 loss: 5.24880761e-07
Iter: 163 loss: 5.24007191e-07
Iter: 164 loss: 5.26615281e-07
Iter: 165 loss: 5.23707854e-07
Iter: 166 loss: 5.22731114e-07
Iter: 167 loss: 5.2568987e-07
Iter: 168 loss: 5.2243945e-07
Iter: 169 loss: 5.2170185e-07
Iter: 170 loss: 5.26644e-07
Iter: 171 loss: 5.21703214e-07
Iter: 172 loss: 5.21081688e-07
Iter: 173 loss: 5.2061057e-07
Iter: 174 loss: 5.20447884e-07
Iter: 175 loss: 5.19651508e-07
Iter: 176 loss: 5.19690559e-07
Iter: 177 loss: 5.19375476e-07
Iter: 178 loss: 5.19241439e-07
Iter: 179 loss: 5.18966431e-07
Iter: 180 loss: 5.18427726e-07
Iter: 181 loss: 5.19855917e-07
Iter: 182 loss: 5.18285219e-07
Iter: 183 loss: 5.18609113e-07
Iter: 184 loss: 5.18144532e-07
Iter: 185 loss: 5.18022944e-07
Iter: 186 loss: 5.17670173e-07
Iter: 187 loss: 5.20670483e-07
Iter: 188 loss: 5.17682338e-07
Iter: 189 loss: 5.17384478e-07
Iter: 190 loss: 5.17601507e-07
Iter: 191 loss: 5.17174556e-07
Iter: 192 loss: 5.1696793e-07
Iter: 193 loss: 5.16970772e-07
Iter: 194 loss: 5.16687237e-07
Iter: 195 loss: 5.16179966e-07
Iter: 196 loss: 5.25299129e-07
Iter: 197 loss: 5.16098567e-07
Iter: 198 loss: 5.15678551e-07
Iter: 199 loss: 5.15443276e-07
Iter: 200 loss: 5.15154056e-07
Iter: 201 loss: 5.14317946e-07
Iter: 202 loss: 5.19988134e-07
Iter: 203 loss: 5.14199201e-07
Iter: 204 loss: 5.13694317e-07
Iter: 205 loss: 5.16957812e-07
Iter: 206 loss: 5.13664816e-07
Iter: 207 loss: 5.13059319e-07
Iter: 208 loss: 5.1327504e-07
Iter: 209 loss: 5.12681595e-07
Iter: 210 loss: 5.12282099e-07
Iter: 211 loss: 5.17135675e-07
Iter: 212 loss: 5.12319502e-07
Iter: 213 loss: 5.11837698e-07
Iter: 214 loss: 5.11407734e-07
Iter: 215 loss: 5.11325538e-07
Iter: 216 loss: 5.10709242e-07
Iter: 217 loss: 5.1383654e-07
Iter: 218 loss: 5.10669452e-07
Iter: 219 loss: 5.10607265e-07
Iter: 220 loss: 5.10492782e-07
Iter: 221 loss: 5.10276095e-07
Iter: 222 loss: 5.09676227e-07
Iter: 223 loss: 5.13354451e-07
Iter: 224 loss: 5.09545941e-07
Iter: 225 loss: 5.09200618e-07
Iter: 226 loss: 5.09516724e-07
Iter: 227 loss: 5.08957e-07
Iter: 228 loss: 5.08625703e-07
Iter: 229 loss: 5.08555217e-07
Iter: 230 loss: 5.08375308e-07
Iter: 231 loss: 5.09520532e-07
Iter: 232 loss: 5.08232063e-07
Iter: 233 loss: 5.08096662e-07
Iter: 234 loss: 5.07571258e-07
Iter: 235 loss: 5.12064958e-07
Iter: 236 loss: 5.07590642e-07
Iter: 237 loss: 5.07124923e-07
Iter: 238 loss: 5.12667327e-07
Iter: 239 loss: 5.07200411e-07
Iter: 240 loss: 5.06835818e-07
Iter: 241 loss: 5.07342293e-07
Iter: 242 loss: 5.06678248e-07
Iter: 243 loss: 5.06320134e-07
Iter: 244 loss: 5.08845801e-07
Iter: 245 loss: 5.06390336e-07
Iter: 246 loss: 5.06066328e-07
Iter: 247 loss: 5.06042966e-07
Iter: 248 loss: 5.05811045e-07
Iter: 249 loss: 5.05465664e-07
Iter: 250 loss: 5.07312848e-07
Iter: 251 loss: 5.05399157e-07
Iter: 252 loss: 5.05091691e-07
Iter: 253 loss: 5.0548789e-07
Iter: 254 loss: 5.04949639e-07
Iter: 255 loss: 5.04715899e-07
Iter: 256 loss: 5.047591e-07
Iter: 257 loss: 5.045801e-07
Iter: 258 loss: 5.04209879e-07
Iter: 259 loss: 5.06263234e-07
Iter: 260 loss: 5.04134505e-07
Iter: 261 loss: 5.0363019e-07
Iter: 262 loss: 5.05252387e-07
Iter: 263 loss: 5.03472279e-07
Iter: 264 loss: 5.03139e-07
Iter: 265 loss: 5.04612785e-07
Iter: 266 loss: 5.03091769e-07
Iter: 267 loss: 5.02750368e-07
Iter: 268 loss: 5.03415492e-07
Iter: 269 loss: 5.02608373e-07
Iter: 270 loss: 5.02338e-07
Iter: 271 loss: 5.02500939e-07
Iter: 272 loss: 5.02059379e-07
Iter: 273 loss: 5.01719569e-07
Iter: 274 loss: 5.01957061e-07
Iter: 275 loss: 5.01464797e-07
Iter: 276 loss: 5.0100823e-07
Iter: 277 loss: 5.02705689e-07
Iter: 278 loss: 5.00998794e-07
Iter: 279 loss: 5.00586e-07
Iter: 280 loss: 5.02427611e-07
Iter: 281 loss: 5.00446731e-07
Iter: 282 loss: 5.00273927e-07
Iter: 283 loss: 5.02735361e-07
Iter: 284 loss: 5.00252497e-07
Iter: 285 loss: 5.00012561e-07
Iter: 286 loss: 4.99930366e-07
Iter: 287 loss: 4.99810085e-07
Iter: 288 loss: 4.9968537e-07
Iter: 289 loss: 4.9966809e-07
Iter: 290 loss: 4.99583962e-07
Iter: 291 loss: 4.999e-07
Iter: 292 loss: 4.9952024e-07
Iter: 293 loss: 4.99476414e-07
Iter: 294 loss: 4.99253531e-07
Iter: 295 loss: 5.00764031e-07
Iter: 296 loss: 4.99138309e-07
Iter: 297 loss: 4.98897066e-07
Iter: 298 loss: 5.00834688e-07
Iter: 299 loss: 4.98875465e-07
Iter: 300 loss: 4.98654344e-07
Iter: 301 loss: 4.99634893e-07
Iter: 302 loss: 4.98659915e-07
Iter: 303 loss: 4.98405257e-07
Iter: 304 loss: 4.98226257e-07
Iter: 305 loss: 4.98206703e-07
Iter: 306 loss: 4.97913561e-07
Iter: 307 loss: 4.99141038e-07
Iter: 308 loss: 4.97865699e-07
Iter: 309 loss: 4.97652138e-07
Iter: 310 loss: 4.9737497e-07
Iter: 311 loss: 4.97414248e-07
Iter: 312 loss: 4.97057954e-07
Iter: 313 loss: 5.01529485e-07
Iter: 314 loss: 4.97016117e-07
Iter: 315 loss: 4.96834105e-07
Iter: 316 loss: 4.97743429e-07
Iter: 317 loss: 4.96701e-07
Iter: 318 loss: 4.96533062e-07
Iter: 319 loss: 4.96978089e-07
Iter: 320 loss: 4.9640721e-07
Iter: 321 loss: 4.96244411e-07
Iter: 322 loss: 4.98821805e-07
Iter: 323 loss: 4.962601e-07
Iter: 324 loss: 4.96014707e-07
Iter: 325 loss: 4.97134351e-07
Iter: 326 loss: 4.96034318e-07
Iter: 327 loss: 4.95956556e-07
Iter: 328 loss: 4.95874701e-07
Iter: 329 loss: 4.95819791e-07
Iter: 330 loss: 4.95616575e-07
Iter: 331 loss: 4.95599352e-07
Iter: 332 loss: 4.95461677e-07
Iter: 333 loss: 4.95285178e-07
Iter: 334 loss: 4.97992119e-07
Iter: 335 loss: 4.95238282e-07
Iter: 336 loss: 4.95140227e-07
Iter: 337 loss: 4.95340942e-07
Iter: 338 loss: 4.95053769e-07
Iter: 339 loss: 4.94867209e-07
Iter: 340 loss: 4.94745677e-07
Iter: 341 loss: 4.94720155e-07
Iter: 342 loss: 4.94478684e-07
Iter: 343 loss: 4.96198822e-07
Iter: 344 loss: 4.94464416e-07
Iter: 345 loss: 4.94239941e-07
Iter: 346 loss: 4.94210781e-07
Iter: 347 loss: 4.94148082e-07
Iter: 348 loss: 4.93966695e-07
Iter: 349 loss: 4.9550664e-07
Iter: 350 loss: 4.93910647e-07
Iter: 351 loss: 4.93715561e-07
Iter: 352 loss: 4.93934408e-07
Iter: 353 loss: 4.93595621e-07
Iter: 354 loss: 4.93297307e-07
Iter: 355 loss: 4.95180529e-07
Iter: 356 loss: 4.93329e-07
Iter: 357 loss: 4.93205e-07
Iter: 358 loss: 4.93190555e-07
Iter: 359 loss: 4.9311052e-07
Iter: 360 loss: 4.92817094e-07
Iter: 361 loss: 4.98361771e-07
Iter: 362 loss: 4.92836648e-07
Iter: 363 loss: 4.92496554e-07
Iter: 364 loss: 4.93313451e-07
Iter: 365 loss: 4.92467e-07
Iter: 366 loss: 4.92170443e-07
Iter: 367 loss: 4.92788e-07
Iter: 368 loss: 4.92066192e-07
Iter: 369 loss: 4.91833e-07
Iter: 370 loss: 4.93260359e-07
Iter: 371 loss: 4.91936134e-07
Iter: 372 loss: 4.9165061e-07
Iter: 373 loss: 4.91842798e-07
Iter: 374 loss: 4.91584728e-07
Iter: 375 loss: 4.91379637e-07
Iter: 376 loss: 4.91329388e-07
Iter: 377 loss: 4.91196261e-07
Iter: 378 loss: 4.90931029e-07
Iter: 379 loss: 4.92621723e-07
Iter: 380 loss: 4.90933303e-07
Iter: 381 loss: 4.90730486e-07
Iter: 382 loss: 4.90666309e-07
Iter: 383 loss: 4.90533807e-07
Iter: 384 loss: 4.90323259e-07
Iter: 385 loss: 4.92958463e-07
Iter: 386 loss: 4.90309731e-07
Iter: 387 loss: 4.90173875e-07
Iter: 388 loss: 4.90591844e-07
Iter: 389 loss: 4.90121636e-07
Iter: 390 loss: 4.89991862e-07
Iter: 391 loss: 4.9078642e-07
Iter: 392 loss: 4.89959575e-07
Iter: 393 loss: 4.89903584e-07
Iter: 394 loss: 4.89842876e-07
Iter: 395 loss: 4.89839067e-07
Iter: 396 loss: 4.89658532e-07
Iter: 397 loss: 4.90704338e-07
Iter: 398 loss: 4.89610784e-07
Iter: 399 loss: 4.89395234e-07
Iter: 400 loss: 4.90735374e-07
Iter: 401 loss: 4.89369143e-07
Iter: 402 loss: 4.89317529e-07
Iter: 403 loss: 4.89527451e-07
Iter: 404 loss: 4.89233798e-07
Iter: 405 loss: 4.89060938e-07
Iter: 406 loss: 4.89778358e-07
Iter: 407 loss: 4.88985847e-07
Iter: 408 loss: 4.88893193e-07
Iter: 409 loss: 4.88642797e-07
Iter: 410 loss: 4.88608066e-07
Iter: 411 loss: 4.88362957e-07
Iter: 412 loss: 4.88908199e-07
Iter: 413 loss: 4.88254216e-07
Iter: 414 loss: 4.87982e-07
Iter: 415 loss: 4.88248816e-07
Iter: 416 loss: 4.87814532e-07
Iter: 417 loss: 4.87498482e-07
Iter: 418 loss: 4.8869407e-07
Iter: 419 loss: 4.87360751e-07
Iter: 420 loss: 4.87070054e-07
Iter: 421 loss: 4.87146508e-07
Iter: 422 loss: 4.86849444e-07
Iter: 423 loss: 4.86623549e-07
Iter: 424 loss: 4.86599902e-07
Iter: 425 loss: 4.86464e-07
Iter: 426 loss: 4.86964268e-07
Iter: 427 loss: 4.86443355e-07
Iter: 428 loss: 4.86223598e-07
Iter: 429 loss: 4.86863087e-07
Iter: 430 loss: 4.86229396e-07
Iter: 431 loss: 4.85986789e-07
Iter: 432 loss: 4.8605159e-07
Iter: 433 loss: 4.86050453e-07
Iter: 434 loss: 4.85829332e-07
Iter: 435 loss: 4.86431304e-07
Iter: 436 loss: 4.85812336e-07
Iter: 437 loss: 4.85543865e-07
Iter: 438 loss: 4.87594036e-07
Iter: 439 loss: 4.85515272e-07
Iter: 440 loss: 4.85404769e-07
Iter: 441 loss: 4.85810574e-07
Iter: 442 loss: 4.85381065e-07
Iter: 443 loss: 4.85272437e-07
Iter: 444 loss: 4.85369071e-07
Iter: 445 loss: 4.85157443e-07
Iter: 446 loss: 4.85003568e-07
Iter: 447 loss: 4.85147325e-07
Iter: 448 loss: 4.8494752e-07
Iter: 449 loss: 4.84783698e-07
Iter: 450 loss: 4.84771135e-07
Iter: 451 loss: 4.84628799e-07
Iter: 452 loss: 4.84490158e-07
Iter: 453 loss: 4.85032274e-07
Iter: 454 loss: 4.84376073e-07
Iter: 455 loss: 4.84138525e-07
Iter: 456 loss: 4.84947805e-07
Iter: 457 loss: 4.84109592e-07
Iter: 458 loss: 4.83876136e-07
Iter: 459 loss: 4.8456485e-07
Iter: 460 loss: 4.83919962e-07
Iter: 461 loss: 4.83751705e-07
Iter: 462 loss: 4.837e-07
Iter: 463 loss: 4.83560086e-07
Iter: 464 loss: 4.84391762e-07
Iter: 465 loss: 4.8359135e-07
Iter: 466 loss: 4.83439635e-07
Iter: 467 loss: 4.83287579e-07
Iter: 468 loss: 4.83312249e-07
Iter: 469 loss: 4.83102724e-07
Iter: 470 loss: 4.83504778e-07
Iter: 471 loss: 4.83097949e-07
Iter: 472 loss: 4.82844712e-07
Iter: 473 loss: 4.83275699e-07
Iter: 474 loss: 4.82787527e-07
Iter: 475 loss: 4.82649568e-07
Iter: 476 loss: 4.84693714e-07
Iter: 477 loss: 4.8269618e-07
Iter: 478 loss: 4.82619669e-07
Iter: 479 loss: 4.8256328e-07
Iter: 480 loss: 4.82462326e-07
Iter: 481 loss: 4.82377402e-07
Iter: 482 loss: 4.82154064e-07
Iter: 483 loss: 4.82143491e-07
Iter: 484 loss: 4.81887923e-07
Iter: 485 loss: 4.82797077e-07
Iter: 486 loss: 4.81957841e-07
Iter: 487 loss: 4.81680445e-07
Iter: 488 loss: 4.81896336e-07
Iter: 489 loss: 4.81659e-07
Iter: 490 loss: 4.81454606e-07
Iter: 491 loss: 4.81974155e-07
Iter: 492 loss: 4.81424e-07
Iter: 493 loss: 4.81274697e-07
Iter: 494 loss: 4.81947723e-07
Iter: 495 loss: 4.81202051e-07
Iter: 496 loss: 4.81104166e-07
Iter: 497 loss: 4.81071424e-07
Iter: 498 loss: 4.80964e-07
Iter: 499 loss: 4.81289e-07
Iter: 500 loss: 4.80986387e-07
Iter: 501 loss: 4.80876224e-07
Iter: 502 loss: 4.80797723e-07
Iter: 503 loss: 4.80756626e-07
Iter: 504 loss: 4.80732865e-07
Iter: 505 loss: 4.80769074e-07
Iter: 506 loss: 4.80567394e-07
Iter: 507 loss: 4.8045689e-07
Iter: 508 loss: 4.80538517e-07
Iter: 509 loss: 4.80290339e-07
Iter: 510 loss: 4.80108497e-07
Iter: 511 loss: 4.83359941e-07
Iter: 512 loss: 4.8012032e-07
Iter: 513 loss: 4.80050403e-07
Iter: 514 loss: 4.80192625e-07
Iter: 515 loss: 4.79959681e-07
Iter: 516 loss: 4.79847813e-07
Iter: 517 loss: 4.7967194e-07
Iter: 518 loss: 4.84134432e-07
Iter: 519 loss: 4.79612e-07
Iter: 520 loss: 4.79473329e-07
Iter: 521 loss: 4.80832114e-07
Iter: 522 loss: 4.7951329e-07
Iter: 523 loss: 4.79315645e-07
Iter: 524 loss: 4.79455e-07
Iter: 525 loss: 4.79194796e-07
Iter: 526 loss: 4.79097309e-07
Iter: 527 loss: 4.79163418e-07
Iter: 528 loss: 4.78952245e-07
Iter: 529 loss: 4.78783363e-07
Iter: 530 loss: 4.80237873e-07
Iter: 531 loss: 4.78770517e-07
Iter: 532 loss: 4.78669392e-07
Iter: 533 loss: 4.78711172e-07
Iter: 534 loss: 4.78621359e-07
Iter: 535 loss: 4.78490563e-07
Iter: 536 loss: 4.78442189e-07
Iter: 537 loss: 4.78390405e-07
Iter: 538 loss: 4.78897618e-07
Iter: 539 loss: 4.78358402e-07
Iter: 540 loss: 4.78276206e-07
Iter: 541 loss: 4.78040533e-07
Iter: 542 loss: 4.82096368e-07
Iter: 543 loss: 4.78075606e-07
Iter: 544 loss: 4.77918206e-07
Iter: 545 loss: 4.77999322e-07
Iter: 546 loss: 4.77875e-07
Iter: 547 loss: 4.78202764e-07
Iter: 548 loss: 4.7789996e-07
Iter: 549 loss: 4.77882793e-07
Iter: 550 loss: 4.77788603e-07
Iter: 551 loss: 4.77749e-07
Iter: 552 loss: 4.77574417e-07
Iter: 553 loss: 4.78108234e-07
Iter: 554 loss: 4.77613412e-07
Iter: 555 loss: 4.77509047e-07
Iter: 556 loss: 4.77304525e-07
Iter: 557 loss: 4.81918732e-07
Iter: 558 loss: 4.77309868e-07
Iter: 559 loss: 4.77153208e-07
Iter: 560 loss: 4.77806338e-07
Iter: 561 loss: 4.77013373e-07
Iter: 562 loss: 4.76818173e-07
Iter: 563 loss: 4.78177185e-07
Iter: 564 loss: 4.76740865e-07
Iter: 565 loss: 4.76660716e-07
Iter: 566 loss: 4.76655543e-07
Iter: 567 loss: 4.76539185e-07
Iter: 568 loss: 4.76620755e-07
Iter: 569 loss: 4.76520768e-07
Iter: 570 loss: 4.7634623e-07
Iter: 571 loss: 4.763898e-07
Iter: 572 loss: 4.76271566e-07
Iter: 573 loss: 4.76186358e-07
Iter: 574 loss: 4.76641446e-07
Iter: 575 loss: 4.76119851e-07
Iter: 576 loss: 4.75981182e-07
Iter: 577 loss: 4.76177718e-07
Iter: 578 loss: 4.75908394e-07
Iter: 579 loss: 4.75790529e-07
Iter: 580 loss: 4.75802096e-07
Iter: 581 loss: 4.7563239e-07
Iter: 582 loss: 4.75675876e-07
Iter: 583 loss: 4.75627928e-07
Iter: 584 loss: 4.7556361e-07
Iter: 585 loss: 4.7552021e-07
Iter: 586 loss: 4.75473428e-07
Iter: 587 loss: 4.75423e-07
Iter: 588 loss: 4.7547303e-07
Iter: 589 loss: 4.75337345e-07
Iter: 590 loss: 4.75222862e-07
Iter: 591 loss: 4.75374293e-07
Iter: 592 loss: 4.75118583e-07
Iter: 593 loss: 4.7498952e-07
Iter: 594 loss: 4.7542116e-07
Iter: 595 loss: 4.74979657e-07
Iter: 596 loss: 4.74856364e-07
Iter: 597 loss: 4.7482564e-07
Iter: 598 loss: 4.74739579e-07
Iter: 599 loss: 4.75087461e-07
Iter: 600 loss: 4.74736396e-07
Iter: 601 loss: 4.74680689e-07
Iter: 602 loss: 4.74539377e-07
Iter: 603 loss: 4.75084335e-07
Iter: 604 loss: 4.74486626e-07
Iter: 605 loss: 4.74381579e-07
Iter: 606 loss: 4.74855824e-07
Iter: 607 loss: 4.74379874e-07
Iter: 608 loss: 4.74226113e-07
Iter: 609 loss: 4.74454396e-07
Iter: 610 loss: 4.74213778e-07
Iter: 611 loss: 4.74064194e-07
Iter: 612 loss: 4.74054048e-07
Iter: 613 loss: 4.73958863e-07
Iter: 614 loss: 4.73816385e-07
Iter: 615 loss: 4.74477304e-07
Iter: 616 loss: 4.73794586e-07
Iter: 617 loss: 4.73628035e-07
Iter: 618 loss: 4.74318597e-07
Iter: 619 loss: 4.73633e-07
Iter: 620 loss: 4.73608907e-07
Iter: 621 loss: 4.73754227e-07
Iter: 622 loss: 4.73503121e-07
Iter: 623 loss: 4.735125e-07
Iter: 624 loss: 4.73494424e-07
Iter: 625 loss: 4.7347848e-07
Iter: 626 loss: 4.73438178e-07
Iter: 627 loss: 4.73461171e-07
Iter: 628 loss: 4.73480213e-07
Iter: 629 loss: 4.73504087e-07
Iter: 630 loss: 4.73493344e-07
Iter: 631 loss: 4.73478252e-07
Iter: 632 loss: 4.73484732e-07
Iter: 633 loss: 4.73524153e-07
Iter: 634 loss: 4.73491667e-07
Iter: 635 loss: 4.73493287e-07
Iter: 636 loss: 4.73487916e-07
Iter: 637 loss: 4.73535067e-07
Iter: 638 loss: 4.73526597e-07
Iter: 639 loss: 4.73491525e-07
Iter: 640 loss: 4.73494822e-07
Iter: 641 loss: 4.73492264e-07
Iter: 642 loss: 4.73525461e-07
Iter: 643 loss: 4.73521766e-07
Iter: 644 loss: 4.73521879e-07
Iter: 645 loss: 4.73492605e-07
Iter: 646 loss: 4.73521766e-07
Iter: 647 loss: 4.73521226e-07
Iter: 648 loss: 4.73492605e-07
Iter: 649 loss: 4.73255909e-07
Iter: 650 loss: 4.75085812e-07
Iter: 651 loss: 4.73246416e-07
Iter: 652 loss: 4.73128409e-07
Iter: 653 loss: 4.73084498e-07
Iter: 654 loss: 4.72996732e-07
Iter: 655 loss: 4.7318747e-07
Iter: 656 loss: 4.72977604e-07
Iter: 657 loss: 4.72920959e-07
Iter: 658 loss: 4.72926843e-07
Iter: 659 loss: 4.72957538e-07
Iter: 660 loss: 4.72940172e-07
Iter: 661 loss: 4.72892452e-07
Iter: 662 loss: 4.72882675e-07
Iter: 663 loss: 4.72895579e-07
Iter: 664 loss: 4.72928832e-07
Iter: 665 loss: 4.72927496e-07
Iter: 666 loss: 4.72894754e-07
Iter: 667 loss: 4.72936847e-07
Iter: 668 loss: 4.72900354e-07
Iter: 669 loss: 4.72926047e-07
Iter: 670 loss: 4.72905185e-07
Iter: 671 loss: 4.72907857e-07
Iter: 672 loss: 4.72918799e-07
Iter: 673 loss: 4.72926786e-07
Iter: 674 loss: 4.72945715e-07
Iter: 675 loss: 4.72934119e-07
Iter: 676 loss: 4.72936222e-07
Iter: 677 loss: 4.7293517e-07
Iter: 678 loss: 4.72927496e-07
Iter: 679 loss: 4.72926757e-07
Iter: 680 loss: 4.7292761e-07
Iter: 681 loss: 4.7292761e-07
Iter: 682 loss: 4.7292761e-07
Iter: 683 loss: 4.72926757e-07
Iter: 684 loss: 4.72926871e-07
Iter: 685 loss: 4.7292761e-07
Iter: 686 loss: 4.72671644e-07
Iter: 687 loss: 4.74496318e-07
Iter: 688 loss: 4.72726981e-07
Iter: 689 loss: 4.72678778e-07
Iter: 690 loss: 4.73010289e-07
Iter: 691 loss: 4.72618723e-07
Iter: 692 loss: 4.72521918e-07
Iter: 693 loss: 4.72619547e-07
Iter: 694 loss: 4.7246877e-07
Iter: 695 loss: 4.72290651e-07
Iter: 696 loss: 4.72859938e-07
Iter: 697 loss: 4.72317055e-07
Iter: 698 loss: 4.72229289e-07
Iter: 699 loss: 4.72119638e-07
Iter: 700 loss: 4.75020244e-07
Iter: 701 loss: 4.72107587e-07
Iter: 702 loss: 4.72056342e-07
Iter: 703 loss: 4.71997197e-07
Iter: 704 loss: 4.71943707e-07
Iter: 705 loss: 4.71923528e-07
Iter: 706 loss: 4.71921339e-07
Iter: 707 loss: 4.71728072e-07
Iter: 708 loss: 4.71645251e-07
Iter: 709 loss: 4.71582e-07
Iter: 710 loss: 4.71496747e-07
Iter: 711 loss: 4.71932537e-07
Iter: 712 loss: 4.71463551e-07
Iter: 713 loss: 4.71404178e-07
Iter: 714 loss: 4.71348898e-07
Iter: 715 loss: 4.71328548e-07
Iter: 716 loss: 4.71311211e-07
Iter: 717 loss: 4.71281055e-07
Iter: 718 loss: 4.71264684e-07
Iter: 719 loss: 4.71814872e-07
Iter: 720 loss: 4.71223188e-07
Iter: 721 loss: 4.71209859e-07
Iter: 722 loss: 4.71130193e-07
Iter: 723 loss: 4.71124196e-07
Iter: 724 loss: 4.71002522e-07
Iter: 725 loss: 4.71565102e-07
Iter: 726 loss: 4.70981689e-07
Iter: 727 loss: 4.70919645e-07
Iter: 728 loss: 4.71652754e-07
Iter: 729 loss: 4.70849e-07
Iter: 730 loss: 4.70830855e-07
Iter: 731 loss: 4.70791377e-07
Iter: 732 loss: 4.70745647e-07
Iter: 733 loss: 4.70634404e-07
Iter: 734 loss: 4.70842167e-07
Iter: 735 loss: 4.70624059e-07
Iter: 736 loss: 4.70560849e-07
Iter: 737 loss: 4.70524014e-07
Iter: 738 loss: 4.70484707e-07
Iter: 739 loss: 4.70357435e-07
Iter: 740 loss: 4.70260147e-07
Iter: 741 loss: 4.70224734e-07
Iter: 742 loss: 4.70395747e-07
Iter: 743 loss: 4.70189264e-07
Iter: 744 loss: 4.69978716e-07
Iter: 745 loss: 4.70100048e-07
Iter: 746 loss: 4.69895554e-07
Iter: 747 loss: 4.69989402e-07
Iter: 748 loss: 4.6987833e-07
Iter: 749 loss: 4.69800028e-07
Iter: 750 loss: 4.6974904e-07
Iter: 751 loss: 4.69805485e-07
Iter: 752 loss: 4.69648626e-07
Iter: 753 loss: 4.6981026e-07
Iter: 754 loss: 4.69616566e-07
Iter: 755 loss: 4.69497166e-07
Iter: 756 loss: 4.6939752e-07
Iter: 757 loss: 4.69371315e-07
Iter: 758 loss: 4.69205617e-07
Iter: 759 loss: 4.6987725e-07
Iter: 760 loss: 4.69186745e-07
Iter: 761 loss: 4.68992653e-07
Iter: 762 loss: 4.69185238e-07
Iter: 763 loss: 4.68943199e-07
Iter: 764 loss: 4.68821781e-07
Iter: 765 loss: 4.6953329e-07
Iter: 766 loss: 4.68814875e-07
Iter: 767 loss: 4.68705423e-07
Iter: 768 loss: 4.69173216e-07
Iter: 769 loss: 4.68613678e-07
Iter: 770 loss: 4.68630134e-07
Iter: 771 loss: 4.68598728e-07
Iter: 772 loss: 4.68566668e-07
Iter: 773 loss: 4.6858986e-07
Iter: 774 loss: 4.68638518e-07
Iter: 775 loss: 4.68607624e-07
Iter: 776 loss: 4.68584545e-07
Iter: 777 loss: 4.68607311e-07
Iter: 778 loss: 4.68580595e-07
Iter: 779 loss: 4.68624023e-07
Iter: 780 loss: 4.68599211e-07
Iter: 781 loss: 4.68605492e-07
Iter: 782 loss: 4.68602053e-07
Iter: 783 loss: 4.68609898e-07
Iter: 784 loss: 4.68602792e-07
Iter: 785 loss: 4.68604242e-07
Iter: 786 loss: 4.68609045e-07
Iter: 787 loss: 4.68617344e-07
Iter: 788 loss: 4.68608278e-07
Iter: 789 loss: 4.68610807e-07
Iter: 790 loss: 4.68617316e-07
Iter: 791 loss: 4.68616946e-07
Iter: 792 loss: 4.68616861e-07
Iter: 793 loss: 4.68617799e-07
Iter: 794 loss: 4.68610835e-07
Iter: 795 loss: 4.68617799e-07
Iter: 796 loss: 4.68441471e-07
Iter: 797 loss: 4.69057682e-07
Iter: 798 loss: 4.68433228e-07
Iter: 799 loss: 4.68248828e-07
Iter: 800 loss: 4.68532392e-07
Iter: 801 loss: 4.6819008e-07
Iter: 802 loss: 4.68166775e-07
Iter: 803 loss: 4.69130555e-07
Iter: 804 loss: 4.68159328e-07
Iter: 805 loss: 4.68095323e-07
Iter: 806 loss: 4.68084579e-07
Iter: 807 loss: 4.67994084e-07
Iter: 808 loss: 4.6793744e-07
Iter: 809 loss: 4.69255752e-07
Iter: 810 loss: 4.67962707e-07
Iter: 811 loss: 4.67878152e-07
Iter: 812 loss: 4.67908222e-07
Iter: 813 loss: 4.67860758e-07
Iter: 814 loss: 4.67828272e-07
Iter: 815 loss: 4.67903334e-07
Iter: 816 loss: 4.67760742e-07
Iter: 817 loss: 4.67600103e-07
Iter: 818 loss: 4.6781355e-07
Iter: 819 loss: 4.67580605e-07
Iter: 820 loss: 4.67520806e-07
Iter: 821 loss: 4.67437559e-07
Iter: 822 loss: 4.67432443e-07
Iter: 823 loss: 4.67281183e-07
Iter: 824 loss: 4.6863866e-07
Iter: 825 loss: 4.67336321e-07
Iter: 826 loss: 4.67214477e-07
Iter: 827 loss: 4.67070862e-07
Iter: 828 loss: 4.67062932e-07
Iter: 829 loss: 4.66916759e-07
Iter: 830 loss: 4.67289595e-07
Iter: 831 loss: 4.66872848e-07
Iter: 832 loss: 4.66729915e-07
Iter: 833 loss: 4.67589274e-07
Iter: 834 loss: 4.66665057e-07
Iter: 835 loss: 4.66613898e-07
Iter: 836 loss: 4.66991168e-07
Iter: 837 loss: 4.66532867e-07
Iter: 838 loss: 4.66488814e-07
Iter: 839 loss: 4.6676405e-07
Iter: 840 loss: 4.6647375e-07
Iter: 841 loss: 4.66372313e-07
Iter: 842 loss: 4.66399854e-07
Iter: 843 loss: 4.66306091e-07
Iter: 844 loss: 4.66247542e-07
Iter: 845 loss: 4.67197509e-07
Iter: 846 loss: 4.66261611e-07
Iter: 847 loss: 4.66177568e-07
Iter: 848 loss: 4.66015592e-07
Iter: 849 loss: 4.66063113e-07
Iter: 850 loss: 4.65913445e-07
Iter: 851 loss: 4.67226187e-07
Iter: 852 loss: 4.65937916e-07
Iter: 853 loss: 4.65843669e-07
Iter: 854 loss: 4.65983192e-07
Iter: 855 loss: 4.65778669e-07
Iter: 856 loss: 4.65637612e-07
Iter: 857 loss: 4.66137578e-07
Iter: 858 loss: 4.65653272e-07
Iter: 859 loss: 4.65600635e-07
Iter: 860 loss: 4.65558912e-07
Iter: 861 loss: 4.65492946e-07
Iter: 862 loss: 4.65367322e-07
Iter: 863 loss: 4.65939934e-07
Iter: 864 loss: 4.65352798e-07
Iter: 865 loss: 4.65257585e-07
Iter: 866 loss: 4.6578262e-07
Iter: 867 loss: 4.6530414e-07
Iter: 868 loss: 4.65218136e-07
Iter: 869 loss: 4.65363087e-07
Iter: 870 loss: 4.65207052e-07
Iter: 871 loss: 4.65049624e-07
Iter: 872 loss: 4.65080234e-07
Iter: 873 loss: 4.64993718e-07
Iter: 874 loss: 4.64900523e-07
Iter: 875 loss: 4.65418424e-07
Iter: 876 loss: 4.64885687e-07
Iter: 877 loss: 4.64779248e-07
Iter: 878 loss: 4.64826712e-07
Iter: 879 loss: 4.6474355e-07
Iter: 880 loss: 4.64630546e-07
Iter: 881 loss: 4.65164362e-07
Iter: 882 loss: 4.64715356e-07
Iter: 883 loss: 4.64612896e-07
Iter: 884 loss: 4.64743266e-07
Iter: 885 loss: 4.64602948e-07
Iter: 886 loss: 4.64438443e-07
Iter: 887 loss: 4.64735336e-07
Iter: 888 loss: 4.64478404e-07
Iter: 889 loss: 4.64336296e-07
Iter: 890 loss: 4.64941365e-07
Iter: 891 loss: 4.64351729e-07
Iter: 892 loss: 4.64241282e-07
Iter: 893 loss: 4.64478319e-07
Iter: 894 loss: 4.64264303e-07
Iter: 895 loss: 4.64132597e-07
Iter: 896 loss: 4.64433924e-07
Iter: 897 loss: 4.64166732e-07
Iter: 898 loss: 4.64168465e-07
Iter: 899 loss: 4.64142829e-07
Iter: 900 loss: 4.64111423e-07
Iter: 901 loss: 4.64103834e-07
Iter: 902 loss: 4.64128e-07
Iter: 903 loss: 4.6418063e-07
Iter: 904 loss: 4.64191572e-07
Iter: 905 loss: 4.64136889e-07
Iter: 906 loss: 4.64130551e-07
Iter: 907 loss: 4.64120603e-07
Iter: 908 loss: 4.64160621e-07
Iter: 909 loss: 4.64185746e-07
Iter: 910 loss: 4.64165197e-07
Iter: 911 loss: 4.6417415e-07
Iter: 912 loss: 4.64166135e-07
Iter: 913 loss: 4.6417378e-07
Iter: 914 loss: 4.64178328e-07
Iter: 915 loss: 4.64169034e-07
Iter: 916 loss: 4.64166845e-07
Iter: 917 loss: 4.64167897e-07
Iter: 918 loss: 4.64167897e-07
Iter: 919 loss: 4.64166419e-07
Iter: 920 loss: 4.64166646e-07
Iter: 921 loss: 4.64167215e-07
Iter: 922 loss: 4.64167044e-07
Iter: 923 loss: 4.64167215e-07
Iter: 924 loss: 4.63951466e-07
Iter: 925 loss: 4.64855475e-07
Iter: 926 loss: 4.63940779e-07
Iter: 927 loss: 4.63947657e-07
Iter: 928 loss: 4.63959452e-07
Iter: 929 loss: 4.63971617e-07
Iter: 930 loss: 4.63989778e-07
Iter: 931 loss: 4.638988e-07
Iter: 932 loss: 4.63917871e-07
Iter: 933 loss: 4.63907838e-07
Iter: 934 loss: 4.63966103e-07
Iter: 935 loss: 4.63958116e-07
Iter: 936 loss: 4.63955e-07
Iter: 937 loss: 4.63925176e-07
Iter: 938 loss: 4.63940125e-07
Iter: 939 loss: 4.63957861e-07
Iter: 940 loss: 4.63949959e-07
Iter: 941 loss: 4.6395877e-07
Iter: 942 loss: 4.63978324e-07
Iter: 943 loss: 4.63933e-07
Iter: 944 loss: 4.63955928e-07
Iter: 945 loss: 4.63954819e-07
Iter: 946 loss: 4.63933873e-07
Iter: 947 loss: 4.63948822e-07
Iter: 948 loss: 4.63930178e-07
Iter: 949 loss: 4.63930718e-07
Iter: 950 loss: 4.63931826e-07
Iter: 951 loss: 4.6394851e-07
Iter: 952 loss: 4.63931855e-07
Iter: 953 loss: 4.63948396e-07
Iter: 954 loss: 4.63948396e-07
Iter: 955 loss: 4.63931855e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.4 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.4
+ date
Sat Nov  7 21:34:59 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2/300_100_100_100_1 --function f1 --psi 0 --phi 2.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.4/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909a7f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909abea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909b127b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909a5e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909a5e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909b12f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909bfb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99099e9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99099e97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99099e9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f990994f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909945bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909913a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99016cf268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909913950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9909955730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99016bac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99016f28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f990163ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f990161b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9901664048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99015dc2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99015d16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99015f2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f990153b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99015aef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99015b9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99015ae378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99014d51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99014e40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99014e3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99014821e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99014bd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99014519d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99013b5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f99013bcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.19120349
test_loss: 0.25796536
train_loss: 0.101216435
test_loss: 0.09353203
train_loss: 0.043432698
test_loss: 0.05243531
train_loss: 0.43763041
test_loss: 0.44070894
train_loss: 0.14945735
test_loss: 0.14830118
train_loss: 0.72572404
test_loss: 0.7060617
train_loss: 0.64831233
test_loss: 0.7020694
train_loss: 0.6228864
test_loss: 0.6971441
train_loss: 0.6011795
test_loss: 0.68919957
train_loss: 0.62396395
test_loss: 0.6786588
train_loss: 0.70506185
test_loss: 0.6651177
train_loss: 0.60368145
test_loss: 0.65007013
train_loss: 0.6339357
test_loss: 0.63305044
train_loss: 0.60470796
test_loss: 0.6199148
train_loss: 0.5628178
test_loss: 0.6103781
train_loss: 0.5630678
test_loss: 0.6032699
train_loss: 0.5621696
test_loss: 0.5973414
train_loss: 0.5421396
test_loss: 0.58921313
train_loss: 0.5484753
test_loss: 0.5769965
train_loss: 0.49579805
test_loss: 0.54112107
train_loss: 0.35546634
test_loss: 0.37307674
train_loss: 0.20674437
test_loss: 0.20034038
train_loss: 0.15496613
test_loss: 0.16272308
train_loss: 0.16912849
test_loss: 0.14956494
train_loss: 0.14468828
test_loss: 0.13106954
train_loss: 0.11940151
test_loss: 0.12956096
train_loss: 0.12109329
test_loss: 0.12584525
train_loss: 0.1225177
test_loss: 0.112150006
train_loss: 0.10971837
test_loss: 0.11026711
train_loss: 0.09812627
test_loss: 0.105890766
train_loss: 0.09868874
test_loss: 0.096678734
train_loss: 0.09981036
test_loss: 0.09276626
train_loss: 0.07771316
test_loss: 0.09016493
train_loss: 0.43733174
test_loss: 0.4921814
train_loss: 0.51396173
test_loss: 0.5296336
train_loss: 0.4341588
test_loss: 0.49028906
train_loss: 0.3613329
test_loss: 0.4548745
train_loss: 0.3735229
test_loss: 0.4265994
train_loss: 0.37965637
test_loss: 0.39938036
train_loss: 0.34057668
test_loss: 0.36694977
train_loss: 0.3480452
test_loss: 0.32307553
train_loss: 0.2006792
test_loss: 0.22249909
train_loss: 0.2692167
test_loss: 0.27844456
train_loss: 0.21057057
test_loss: 0.18152826
train_loss: 0.1424585
test_loss: 0.1674085
train_loss: 0.15111573
test_loss: 0.1580441
train_loss: 0.13387313
test_loss: 0.14802493
train_loss: 0.12895179
test_loss: 0.14011565
train_loss: 0.10889324
test_loss: 0.13230385
train_loss: 0.10301167
test_loss: 0.12396836
train_loss: 0.12997486
test_loss: 0.11743277
train_loss: 0.10746266
test_loss: 0.1108792
train_loss: 0.09948297
test_loss: 0.1276479
train_loss: 0.15253225
test_loss: 0.1409333
train_loss: 0.11230998
test_loss: 0.117789485
train_loss: 0.0883234
test_loss: 0.110822655
train_loss: 0.12034567
test_loss: 0.10612902
train_loss: 0.11005388
test_loss: 0.10064512
train_loss: 0.10220763
test_loss: 0.09656615
train_loss: 0.08667806
test_loss: 0.092793226
train_loss: 0.09034366
test_loss: 0.0884073
train_loss: 0.07214151
test_loss: 0.085402094
train_loss: 0.08246606
test_loss: 0.081564315
train_loss: 0.07452452
test_loss: 0.0791981
train_loss: 0.08528335
test_loss: 0.07701701
train_loss: 0.06471595
test_loss: 0.075183086
train_loss: 0.06632257
test_loss: 0.072819784
train_loss: 0.06132327
test_loss: 0.07163088
train_loss: 0.06708814
test_loss: 0.074146114
train_loss: 0.07406962
test_loss: 0.070529446
train_loss: 0.061737094
test_loss: 0.070082486
train_loss: 0.11508033
test_loss: 0.11884572
train_loss: 0.10666236
test_loss: 0.08896397
train_loss: 0.06872702
test_loss: 0.07574229
train_loss: 0.059510823
test_loss: 0.07082575
train_loss: 0.08218874
test_loss: 0.06627017
train_loss: 0.07043836
test_loss: 0.06404347
train_loss: 0.07958701
test_loss: 0.06215942
train_loss: 0.08497296
test_loss: 0.059473574
train_loss: 0.053829685
test_loss: 0.05825547
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.4/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.4/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28707727b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28707099d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28706c5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28707e2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28707e2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28707e2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870665730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28706bc048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870665510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28705c01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28705c0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28705c0ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28705d4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28705620d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870517158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870517c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28704d0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28704d0ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f287048b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870441a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870462048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28704012f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28704106a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28703ebe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28703ebd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28703eb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870345f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28703b30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28703051e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28703280d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870317510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702d81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702d06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f28702969d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2870254268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f287026ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00862749293
Iter: 2 loss: 0.187691391
Iter: 3 loss: 0.0185063556
Iter: 4 loss: 0.00845702458
Iter: 5 loss: 0.00794572197
Iter: 6 loss: 0.010940779
Iter: 7 loss: 0.00784397684
Iter: 8 loss: 0.00771799823
Iter: 9 loss: 0.00823429786
Iter: 10 loss: 0.00768808741
Iter: 11 loss: 0.00747918617
Iter: 12 loss: 0.00735512
Iter: 13 loss: 0.0072536543
Iter: 14 loss: 0.00710205082
Iter: 15 loss: 0.00868456252
Iter: 16 loss: 0.00709516741
Iter: 17 loss: 0.00698614214
Iter: 18 loss: 0.00720572099
Iter: 19 loss: 0.00693741115
Iter: 20 loss: 0.00680507906
Iter: 21 loss: 0.00697509386
Iter: 22 loss: 0.00673907669
Iter: 23 loss: 0.00660100859
Iter: 24 loss: 0.00638990197
Iter: 25 loss: 0.00638601603
Iter: 26 loss: 0.00619459525
Iter: 27 loss: 0.00689570606
Iter: 28 loss: 0.0061500459
Iter: 29 loss: 0.00598205626
Iter: 30 loss: 0.00694419257
Iter: 31 loss: 0.00596367382
Iter: 32 loss: 0.00581795536
Iter: 33 loss: 0.00612512371
Iter: 34 loss: 0.00576297473
Iter: 35 loss: 0.00561964652
Iter: 36 loss: 0.00607396
Iter: 37 loss: 0.00556998048
Iter: 38 loss: 0.00549319154
Iter: 39 loss: 0.0054904297
Iter: 40 loss: 0.0054241484
Iter: 41 loss: 0.00559031405
Iter: 42 loss: 0.00540285418
Iter: 43 loss: 0.00533381943
Iter: 44 loss: 0.00526674837
Iter: 45 loss: 0.00524998177
Iter: 46 loss: 0.0051482264
Iter: 47 loss: 0.00512670912
Iter: 48 loss: 0.00501668407
Iter: 49 loss: 0.00623775786
Iter: 50 loss: 0.00501489127
Iter: 51 loss: 0.00496587111
Iter: 52 loss: 0.00513302721
Iter: 53 loss: 0.00495309569
Iter: 54 loss: 0.00492077507
Iter: 55 loss: 0.00494144484
Iter: 56 loss: 0.00490007224
Iter: 57 loss: 0.00486723613
Iter: 58 loss: 0.00482394919
Iter: 59 loss: 0.00482143834
Iter: 60 loss: 0.00474060653
Iter: 61 loss: 0.0048849266
Iter: 62 loss: 0.00470572617
Iter: 63 loss: 0.0046477518
Iter: 64 loss: 0.00482842606
Iter: 65 loss: 0.00463074166
Iter: 66 loss: 0.00458650663
Iter: 67 loss: 0.00493242126
Iter: 68 loss: 0.00458332244
Iter: 69 loss: 0.00460206
Iter: 70 loss: 0.00457379222
Iter: 71 loss: 0.00455121137
Iter: 72 loss: 0.00463886186
Iter: 73 loss: 0.004546165
Iter: 74 loss: 0.00453445967
Iter: 75 loss: 0.00450353138
Iter: 76 loss: 0.00473537529
Iter: 77 loss: 0.0044971155
Iter: 78 loss: 0.00447368342
Iter: 79 loss: 0.0045030266
Iter: 80 loss: 0.00446143514
Iter: 81 loss: 0.00445034681
Iter: 82 loss: 0.00444436
Iter: 83 loss: 0.00443913881
Iter: 84 loss: 0.00442509074
Iter: 85 loss: 0.0044605406
Iter: 86 loss: 0.00442015845
Iter: 87 loss: 0.00440470828
Iter: 88 loss: 0.00451949798
Iter: 89 loss: 0.00440364704
Iter: 90 loss: 0.0043828534
Iter: 91 loss: 0.00436097616
Iter: 92 loss: 0.00435712794
Iter: 93 loss: 0.00433277432
Iter: 94 loss: 0.00433205254
Iter: 95 loss: 0.00430636341
Iter: 96 loss: 0.00440225843
Iter: 97 loss: 0.00430020131
Iter: 98 loss: 0.00428560795
Iter: 99 loss: 0.00426750351
Iter: 100 loss: 0.00426585972
Iter: 101 loss: 0.00425811484
Iter: 102 loss: 0.00425667223
Iter: 103 loss: 0.00424846262
Iter: 104 loss: 0.00430171425
Iter: 105 loss: 0.00424754806
Iter: 106 loss: 0.00423801178
Iter: 107 loss: 0.00422108825
Iter: 108 loss: 0.00422109
Iter: 109 loss: 0.00420456426
Iter: 110 loss: 0.0043548774
Iter: 111 loss: 0.00420338567
Iter: 112 loss: 0.00418413058
Iter: 113 loss: 0.00416637585
Iter: 114 loss: 0.00416172203
Iter: 115 loss: 0.00411965186
Iter: 116 loss: 0.00434098952
Iter: 117 loss: 0.00411231443
Iter: 118 loss: 0.00410160795
Iter: 119 loss: 0.00409180205
Iter: 120 loss: 0.00407132506
Iter: 121 loss: 0.00408127531
Iter: 122 loss: 0.00405784603
Iter: 123 loss: 0.00403940724
Iter: 124 loss: 0.00403848151
Iter: 125 loss: 0.00402666209
Iter: 126 loss: 0.00404264126
Iter: 127 loss: 0.00402084133
Iter: 128 loss: 0.00401183031
Iter: 129 loss: 0.00400444027
Iter: 130 loss: 0.00400178228
Iter: 131 loss: 0.00399361
Iter: 132 loss: 0.00398337655
Iter: 133 loss: 0.00398249645
Iter: 134 loss: 0.00397382304
Iter: 135 loss: 0.00396934943
Iter: 136 loss: 0.00394641142
Iter: 137 loss: 0.00400230754
Iter: 138 loss: 0.00393807376
Iter: 139 loss: 0.00392089039
Iter: 140 loss: 0.00399554335
Iter: 141 loss: 0.00391582772
Iter: 142 loss: 0.00389316492
Iter: 143 loss: 0.00392822083
Iter: 144 loss: 0.00388274342
Iter: 145 loss: 0.003850871
Iter: 146 loss: 0.00412229402
Iter: 147 loss: 0.00384738599
Iter: 148 loss: 0.00382433785
Iter: 149 loss: 0.00402608048
Iter: 150 loss: 0.0038229432
Iter: 151 loss: 0.00380322291
Iter: 152 loss: 0.00392906787
Iter: 153 loss: 0.00379920681
Iter: 154 loss: 0.00377834868
Iter: 155 loss: 0.00377168157
Iter: 156 loss: 0.00376007613
Iter: 157 loss: 0.00373815466
Iter: 158 loss: 0.00374812307
Iter: 159 loss: 0.00372279715
Iter: 160 loss: 0.00371278496
Iter: 161 loss: 0.00370802404
Iter: 162 loss: 0.00369307725
Iter: 163 loss: 0.00388197275
Iter: 164 loss: 0.00369288749
Iter: 165 loss: 0.0036729537
Iter: 166 loss: 0.00388575508
Iter: 167 loss: 0.00367238093
Iter: 168 loss: 0.00365693378
Iter: 169 loss: 0.00369085139
Iter: 170 loss: 0.00365101919
Iter: 171 loss: 0.00364326872
Iter: 172 loss: 0.00362852751
Iter: 173 loss: 0.00413297489
Iter: 174 loss: 0.00362850167
Iter: 175 loss: 0.00362888724
Iter: 176 loss: 0.0036156287
Iter: 177 loss: 0.00359918061
Iter: 178 loss: 0.00370402634
Iter: 179 loss: 0.00359654753
Iter: 180 loss: 0.00358007848
Iter: 181 loss: 0.00358945155
Iter: 182 loss: 0.0035697578
Iter: 183 loss: 0.0035519572
Iter: 184 loss: 0.00355194742
Iter: 185 loss: 0.0035438356
Iter: 186 loss: 0.00357207563
Iter: 187 loss: 0.00354177691
Iter: 188 loss: 0.00352315023
Iter: 189 loss: 0.00355452788
Iter: 190 loss: 0.00351437251
Iter: 191 loss: 0.00349809765
Iter: 192 loss: 0.00361591
Iter: 193 loss: 0.00349678565
Iter: 194 loss: 0.00348286843
Iter: 195 loss: 0.00351482769
Iter: 196 loss: 0.00347768096
Iter: 197 loss: 0.0034775
Iter: 198 loss: 0.00347304414
Iter: 199 loss: 0.00346691557
Iter: 200 loss: 0.00351799489
Iter: 201 loss: 0.00346645294
Iter: 202 loss: 0.00346237142
Iter: 203 loss: 0.00347268209
Iter: 204 loss: 0.00346095324
Iter: 205 loss: 0.00345637556
Iter: 206 loss: 0.00345981983
Iter: 207 loss: 0.00345346774
Iter: 208 loss: 0.00344584719
Iter: 209 loss: 0.00346442685
Iter: 210 loss: 0.00344310631
Iter: 211 loss: 0.00343277724
Iter: 212 loss: 0.00345485937
Iter: 213 loss: 0.00342886825
Iter: 214 loss: 0.00342070172
Iter: 215 loss: 0.00342334947
Iter: 216 loss: 0.0034147054
Iter: 217 loss: 0.00340521173
Iter: 218 loss: 0.003421325
Iter: 219 loss: 0.00340095116
Iter: 220 loss: 0.00338812894
Iter: 221 loss: 0.00337558892
Iter: 222 loss: 0.00337253418
Iter: 223 loss: 0.0033607271
Iter: 224 loss: 0.00341314357
Iter: 225 loss: 0.00335870357
Iter: 226 loss: 0.0033460455
Iter: 227 loss: 0.00345138507
Iter: 228 loss: 0.00334472791
Iter: 229 loss: 0.00333681819
Iter: 230 loss: 0.00334177213
Iter: 231 loss: 0.00333172921
Iter: 232 loss: 0.00332620135
Iter: 233 loss: 0.00332614314
Iter: 234 loss: 0.00331786484
Iter: 235 loss: 0.00331562385
Iter: 236 loss: 0.00331058889
Iter: 237 loss: 0.00330213737
Iter: 238 loss: 0.00330708362
Iter: 239 loss: 0.00329664466
Iter: 240 loss: 0.00328840199
Iter: 241 loss: 0.003282452
Iter: 242 loss: 0.00327972556
Iter: 243 loss: 0.00326127489
Iter: 244 loss: 0.00328403316
Iter: 245 loss: 0.00325050484
Iter: 246 loss: 0.00323471148
Iter: 247 loss: 0.0034478493
Iter: 248 loss: 0.00323413801
Iter: 249 loss: 0.00322261173
Iter: 250 loss: 0.0032220413
Iter: 251 loss: 0.00321627059
Iter: 252 loss: 0.0032193854
Iter: 253 loss: 0.00321194343
Iter: 254 loss: 0.00319933868
Iter: 255 loss: 0.00323106395
Iter: 256 loss: 0.00319495774
Iter: 257 loss: 0.00318711624
Iter: 258 loss: 0.00320059294
Iter: 259 loss: 0.00318362052
Iter: 260 loss: 0.00317911687
Iter: 261 loss: 0.00317299
Iter: 262 loss: 0.00317268725
Iter: 263 loss: 0.00315929553
Iter: 264 loss: 0.00318705896
Iter: 265 loss: 0.00315368199
Iter: 266 loss: 0.00317484746
Iter: 267 loss: 0.00314977299
Iter: 268 loss: 0.00314639765
Iter: 269 loss: 0.00314866379
Iter: 270 loss: 0.00314425025
Iter: 271 loss: 0.00313787488
Iter: 272 loss: 0.00313109183
Iter: 273 loss: 0.00312976469
Iter: 274 loss: 0.00312278
Iter: 275 loss: 0.0031242813
Iter: 276 loss: 0.00311805354
Iter: 277 loss: 0.00310525717
Iter: 278 loss: 0.00309922267
Iter: 279 loss: 0.00309374323
Iter: 280 loss: 0.00308262324
Iter: 281 loss: 0.00312025659
Iter: 282 loss: 0.00307971938
Iter: 283 loss: 0.00307447603
Iter: 284 loss: 0.00308562908
Iter: 285 loss: 0.00307278708
Iter: 286 loss: 0.00306376512
Iter: 287 loss: 0.00307673868
Iter: 288 loss: 0.00305906381
Iter: 289 loss: 0.00305252522
Iter: 290 loss: 0.00309707085
Iter: 291 loss: 0.00305192475
Iter: 292 loss: 0.00304477243
Iter: 293 loss: 0.00308664516
Iter: 294 loss: 0.00304376287
Iter: 295 loss: 0.00303964876
Iter: 296 loss: 0.0030336366
Iter: 297 loss: 0.00303345569
Iter: 298 loss: 0.00302449195
Iter: 299 loss: 0.00303092133
Iter: 300 loss: 0.00301874802
Iter: 301 loss: 0.00301149674
Iter: 302 loss: 0.00309266988
Iter: 303 loss: 0.00301138964
Iter: 304 loss: 0.0030040415
Iter: 305 loss: 0.00301965699
Iter: 306 loss: 0.00300119398
Iter: 307 loss: 0.00299420767
Iter: 308 loss: 0.00308492966
Iter: 309 loss: 0.00299390778
Iter: 310 loss: 0.00298686232
Iter: 311 loss: 0.00298654987
Iter: 312 loss: 0.00298113795
Iter: 313 loss: 0.00296679768
Iter: 314 loss: 0.00295918621
Iter: 315 loss: 0.00295244367
Iter: 316 loss: 0.0029395388
Iter: 317 loss: 0.00300461706
Iter: 318 loss: 0.00293746125
Iter: 319 loss: 0.00292911171
Iter: 320 loss: 0.00291470415
Iter: 321 loss: 0.00291469414
Iter: 322 loss: 0.00290713343
Iter: 323 loss: 0.00302556716
Iter: 324 loss: 0.00290711899
Iter: 325 loss: 0.00290222955
Iter: 326 loss: 0.00295318337
Iter: 327 loss: 0.00290208962
Iter: 328 loss: 0.0028985939
Iter: 329 loss: 0.00292012142
Iter: 330 loss: 0.00289820647
Iter: 331 loss: 0.00289390236
Iter: 332 loss: 0.00288979849
Iter: 333 loss: 0.00288880384
Iter: 334 loss: 0.00288137281
Iter: 335 loss: 0.00287495134
Iter: 336 loss: 0.0028729164
Iter: 337 loss: 0.00286346674
Iter: 338 loss: 0.00290979352
Iter: 339 loss: 0.00286177336
Iter: 340 loss: 0.0028613708
Iter: 341 loss: 0.0028554257
Iter: 342 loss: 0.00285297376
Iter: 343 loss: 0.00284915324
Iter: 344 loss: 0.00284910342
Iter: 345 loss: 0.0028443723
Iter: 346 loss: 0.00284254784
Iter: 347 loss: 0.00283993222
Iter: 348 loss: 0.0028315112
Iter: 349 loss: 0.00284249941
Iter: 350 loss: 0.00282699591
Iter: 351 loss: 0.00280890497
Iter: 352 loss: 0.00293028913
Iter: 353 loss: 0.00280720787
Iter: 354 loss: 0.00280430983
Iter: 355 loss: 0.00280004088
Iter: 356 loss: 0.0027946285
Iter: 357 loss: 0.00280618249
Iter: 358 loss: 0.00279234303
Iter: 359 loss: 0.00278615067
Iter: 360 loss: 0.00278296927
Iter: 361 loss: 0.00278020673
Iter: 362 loss: 0.00277880323
Iter: 363 loss: 0.00277585443
Iter: 364 loss: 0.00277121551
Iter: 365 loss: 0.00277754082
Iter: 366 loss: 0.0027688432
Iter: 367 loss: 0.00276446
Iter: 368 loss: 0.00276434328
Iter: 369 loss: 0.00276091695
Iter: 370 loss: 0.00275469664
Iter: 371 loss: 0.00282949791
Iter: 372 loss: 0.00275451364
Iter: 373 loss: 0.00274700345
Iter: 374 loss: 0.0027676
Iter: 375 loss: 0.00274498644
Iter: 376 loss: 0.00273634749
Iter: 377 loss: 0.00275596138
Iter: 378 loss: 0.0027325605
Iter: 379 loss: 0.00272536371
Iter: 380 loss: 0.00274949335
Iter: 381 loss: 0.0027236829
Iter: 382 loss: 0.00271555292
Iter: 383 loss: 0.0027235446
Iter: 384 loss: 0.00271079084
Iter: 385 loss: 0.00270556193
Iter: 386 loss: 0.00270621851
Iter: 387 loss: 0.00270157261
Iter: 388 loss: 0.00269428128
Iter: 389 loss: 0.00279783923
Iter: 390 loss: 0.00269425195
Iter: 391 loss: 0.00268753618
Iter: 392 loss: 0.00269008288
Iter: 393 loss: 0.00268276385
Iter: 394 loss: 0.00267381687
Iter: 395 loss: 0.00266442937
Iter: 396 loss: 0.00266283425
Iter: 397 loss: 0.00265329261
Iter: 398 loss: 0.00274623907
Iter: 399 loss: 0.00265286164
Iter: 400 loss: 0.00265352754
Iter: 401 loss: 0.00264866138
Iter: 402 loss: 0.00264670327
Iter: 403 loss: 0.00265402161
Iter: 404 loss: 0.00264629349
Iter: 405 loss: 0.00264176307
Iter: 406 loss: 0.00263372646
Iter: 407 loss: 0.00263371225
Iter: 408 loss: 0.00262838649
Iter: 409 loss: 0.00262347981
Iter: 410 loss: 0.00262221275
Iter: 411 loss: 0.00261031
Iter: 412 loss: 0.00271328236
Iter: 413 loss: 0.00260954909
Iter: 414 loss: 0.00259901816
Iter: 415 loss: 0.00266392669
Iter: 416 loss: 0.00259744166
Iter: 417 loss: 0.00259395526
Iter: 418 loss: 0.00259466376
Iter: 419 loss: 0.00259135454
Iter: 420 loss: 0.00258426135
Iter: 421 loss: 0.0026230684
Iter: 422 loss: 0.00258260872
Iter: 423 loss: 0.00257265661
Iter: 424 loss: 0.00260374579
Iter: 425 loss: 0.00256950478
Iter: 426 loss: 0.00255748956
Iter: 427 loss: 0.00264903158
Iter: 428 loss: 0.00255643413
Iter: 429 loss: 0.0025502136
Iter: 430 loss: 0.00262605515
Iter: 431 loss: 0.00255014119
Iter: 432 loss: 0.00254702894
Iter: 433 loss: 0.00254673022
Iter: 434 loss: 0.00254283403
Iter: 435 loss: 0.00254625315
Iter: 436 loss: 0.00254040025
Iter: 437 loss: 0.00253443141
Iter: 438 loss: 0.00262006558
Iter: 439 loss: 0.00253443047
Iter: 440 loss: 0.00252995314
Iter: 441 loss: 0.00253252592
Iter: 442 loss: 0.00252701226
Iter: 443 loss: 0.00252016704
Iter: 444 loss: 0.00255210605
Iter: 445 loss: 0.00251883501
Iter: 446 loss: 0.00251176069
Iter: 447 loss: 0.00253757462
Iter: 448 loss: 0.00250997255
Iter: 449 loss: 0.00250120088
Iter: 450 loss: 0.00251254532
Iter: 451 loss: 0.00249670958
Iter: 452 loss: 0.00248628948
Iter: 453 loss: 0.00250419625
Iter: 454 loss: 0.0024814338
Iter: 455 loss: 0.00247145304
Iter: 456 loss: 0.00257813488
Iter: 457 loss: 0.00247104117
Iter: 458 loss: 0.00246256148
Iter: 459 loss: 0.00246173237
Iter: 460 loss: 0.00245568249
Iter: 461 loss: 0.00249578524
Iter: 462 loss: 0.00245453347
Iter: 463 loss: 0.00245122
Iter: 464 loss: 0.00247005979
Iter: 465 loss: 0.0024507232
Iter: 466 loss: 0.00244717533
Iter: 467 loss: 0.00244713388
Iter: 468 loss: 0.00244415272
Iter: 469 loss: 0.00246559642
Iter: 470 loss: 0.0024439015
Iter: 471 loss: 0.00244266726
Iter: 472 loss: 0.00244253222
Iter: 473 loss: 0.00243999157
Iter: 474 loss: 0.00243549352
Iter: 475 loss: 0.0024354863
Iter: 476 loss: 0.00243089069
Iter: 477 loss: 0.00244254433
Iter: 478 loss: 0.00242993445
Iter: 479 loss: 0.00242613419
Iter: 480 loss: 0.00243538781
Iter: 481 loss: 0.00242473744
Iter: 482 loss: 0.00242348248
Iter: 483 loss: 0.00242337631
Iter: 484 loss: 0.00242243614
Iter: 485 loss: 0.00241878768
Iter: 486 loss: 0.002411847
Iter: 487 loss: 0.00256722141
Iter: 488 loss: 0.00241181906
Iter: 489 loss: 0.0025167889
Iter: 490 loss: 0.00240497524
Iter: 491 loss: 0.00239688763
Iter: 492 loss: 0.00242585735
Iter: 493 loss: 0.00239421963
Iter: 494 loss: 0.00238271337
Iter: 495 loss: 0.00254518073
Iter: 496 loss: 0.00238266774
Iter: 497 loss: 0.00237441156
Iter: 498 loss: 0.00241632131
Iter: 499 loss: 0.00237316359
Iter: 500 loss: 0.00237501599
Iter: 501 loss: 0.00237057265
Iter: 502 loss: 0.00236716447
Iter: 503 loss: 0.00237007812
Iter: 504 loss: 0.0023651
Iter: 505 loss: 0.00235833
Iter: 506 loss: 0.00240841834
Iter: 507 loss: 0.00235768547
Iter: 508 loss: 0.00235840119
Iter: 509 loss: 0.00235343026
Iter: 510 loss: 0.00234974315
Iter: 511 loss: 0.00234223227
Iter: 512 loss: 0.00249869423
Iter: 513 loss: 0.00234211585
Iter: 514 loss: 0.00233687251
Iter: 515 loss: 0.00236834539
Iter: 516 loss: 0.00233629206
Iter: 517 loss: 0.00233233673
Iter: 518 loss: 0.00234190887
Iter: 519 loss: 0.00233069132
Iter: 520 loss: 0.00232164841
Iter: 521 loss: 0.00244300161
Iter: 522 loss: 0.00232146028
Iter: 523 loss: 0.00231694151
Iter: 524 loss: 0.00234563951
Iter: 525 loss: 0.00231635012
Iter: 526 loss: 0.00231395569
Iter: 527 loss: 0.00231456687
Iter: 528 loss: 0.00231216475
Iter: 529 loss: 0.00230854889
Iter: 530 loss: 0.00230265502
Iter: 531 loss: 0.00230260962
Iter: 532 loss: 0.00234798156
Iter: 533 loss: 0.00229948759
Iter: 534 loss: 0.00229464658
Iter: 535 loss: 0.0023297444
Iter: 536 loss: 0.00229427498
Iter: 537 loss: 0.00228864886
Iter: 538 loss: 0.0022825459
Iter: 539 loss: 0.00228167628
Iter: 540 loss: 0.00227237819
Iter: 541 loss: 0.00235168799
Iter: 542 loss: 0.00227176538
Iter: 543 loss: 0.0022631688
Iter: 544 loss: 0.00229609455
Iter: 545 loss: 0.00226103771
Iter: 546 loss: 0.00225175335
Iter: 547 loss: 0.00227497448
Iter: 548 loss: 0.00224759872
Iter: 549 loss: 0.00225522276
Iter: 550 loss: 0.00224183
Iter: 551 loss: 0.00223420118
Iter: 552 loss: 0.00229702517
Iter: 553 loss: 0.00223329104
Iter: 554 loss: 0.00223444356
Iter: 555 loss: 0.00223072898
Iter: 556 loss: 0.00222599483
Iter: 557 loss: 0.0022408329
Iter: 558 loss: 0.00222427421
Iter: 559 loss: 0.00222019805
Iter: 560 loss: 0.00223119394
Iter: 561 loss: 0.00221888861
Iter: 562 loss: 0.00221050018
Iter: 563 loss: 0.00232985523
Iter: 564 loss: 0.00221035723
Iter: 565 loss: 0.00220373808
Iter: 566 loss: 0.00220253505
Iter: 567 loss: 0.00220065704
Iter: 568 loss: 0.00222493149
Iter: 569 loss: 0.00220065028
Iter: 570 loss: 0.00219771871
Iter: 571 loss: 0.00219089235
Iter: 572 loss: 0.00235035573
Iter: 573 loss: 0.00219058292
Iter: 574 loss: 0.00218420825
Iter: 575 loss: 0.00218382617
Iter: 576 loss: 0.00217992184
Iter: 577 loss: 0.00219173916
Iter: 578 loss: 0.00217881426
Iter: 579 loss: 0.00217455532
Iter: 580 loss: 0.002171495
Iter: 581 loss: 0.00216988358
Iter: 582 loss: 0.00216475222
Iter: 583 loss: 0.00218408881
Iter: 584 loss: 0.00216366746
Iter: 585 loss: 0.00215950329
Iter: 586 loss: 0.00215909025
Iter: 587 loss: 0.00215384
Iter: 588 loss: 0.00221783319
Iter: 589 loss: 0.00215374189
Iter: 590 loss: 0.00215080101
Iter: 591 loss: 0.00215199613
Iter: 592 loss: 0.00214883359
Iter: 593 loss: 0.00214421493
Iter: 594 loss: 0.00214963709
Iter: 595 loss: 0.00214147614
Iter: 596 loss: 0.00213786028
Iter: 597 loss: 0.00213802559
Iter: 598 loss: 0.00213504024
Iter: 599 loss: 0.00212711492
Iter: 600 loss: 0.00227849884
Iter: 601 loss: 0.00212710304
Iter: 602 loss: 0.00212250743
Iter: 603 loss: 0.00212238
Iter: 604 loss: 0.00211943127
Iter: 605 loss: 0.00213860092
Iter: 606 loss: 0.00211910298
Iter: 607 loss: 0.00211652741
Iter: 608 loss: 0.00212562154
Iter: 609 loss: 0.00211560167
Iter: 610 loss: 0.00211101654
Iter: 611 loss: 0.00211361493
Iter: 612 loss: 0.00210804702
Iter: 613 loss: 0.00210189121
Iter: 614 loss: 0.00210187864
Iter: 615 loss: 0.00209501339
Iter: 616 loss: 0.00211148825
Iter: 617 loss: 0.00209253817
Iter: 618 loss: 0.00208587619
Iter: 619 loss: 0.00223208684
Iter: 620 loss: 0.00208573556
Iter: 621 loss: 0.00208036485
Iter: 622 loss: 0.0021356463
Iter: 623 loss: 0.00208024704
Iter: 624 loss: 0.0020751392
Iter: 625 loss: 0.00208442984
Iter: 626 loss: 0.00207270728
Iter: 627 loss: 0.00206719176
Iter: 628 loss: 0.00208854256
Iter: 629 loss: 0.00206616521
Iter: 630 loss: 0.00206129509
Iter: 631 loss: 0.00207882491
Iter: 632 loss: 0.00205976237
Iter: 633 loss: 0.00205582986
Iter: 634 loss: 0.00205611251
Iter: 635 loss: 0.00205271109
Iter: 636 loss: 0.00205050875
Iter: 637 loss: 0.00204954157
Iter: 638 loss: 0.00204697112
Iter: 639 loss: 0.00205748505
Iter: 640 loss: 0.00204642816
Iter: 641 loss: 0.00204386143
Iter: 642 loss: 0.00204486959
Iter: 643 loss: 0.0020417762
Iter: 644 loss: 0.00203615241
Iter: 645 loss: 0.00204230612
Iter: 646 loss: 0.0020330851
Iter: 647 loss: 0.00202740589
Iter: 648 loss: 0.00206181756
Iter: 649 loss: 0.00202672346
Iter: 650 loss: 0.00202233577
Iter: 651 loss: 0.00204624794
Iter: 652 loss: 0.00202167174
Iter: 653 loss: 0.00201959885
Iter: 654 loss: 0.00201694923
Iter: 655 loss: 0.00201672595
Iter: 656 loss: 0.00201702514
Iter: 657 loss: 0.00201146561
Iter: 658 loss: 0.00200673891
Iter: 659 loss: 0.00203745649
Iter: 660 loss: 0.00200619758
Iter: 661 loss: 0.00200467324
Iter: 662 loss: 0.0020108223
Iter: 663 loss: 0.00200423482
Iter: 664 loss: 0.0019991342
Iter: 665 loss: 0.00200784858
Iter: 666 loss: 0.00199687877
Iter: 667 loss: 0.00201365189
Iter: 668 loss: 0.00199208548
Iter: 669 loss: 0.00198834785
Iter: 670 loss: 0.00199153251
Iter: 671 loss: 0.0019862398
Iter: 672 loss: 0.00198160019
Iter: 673 loss: 0.00198799279
Iter: 674 loss: 0.00197915267
Iter: 675 loss: 0.00197521271
Iter: 676 loss: 0.00197639037
Iter: 677 loss: 0.00197241548
Iter: 678 loss: 0.00196710508
Iter: 679 loss: 0.00206677616
Iter: 680 loss: 0.00196706667
Iter: 681 loss: 0.00196293672
Iter: 682 loss: 0.00200097635
Iter: 683 loss: 0.00196279795
Iter: 684 loss: 0.00196069
Iter: 685 loss: 0.00195728173
Iter: 686 loss: 0.00195725588
Iter: 687 loss: 0.00195440976
Iter: 688 loss: 0.00195436366
Iter: 689 loss: 0.00195187214
Iter: 690 loss: 0.00196514302
Iter: 691 loss: 0.00195151649
Iter: 692 loss: 0.0019509613
Iter: 693 loss: 0.00194848992
Iter: 694 loss: 0.00194555498
Iter: 695 loss: 0.00194914732
Iter: 696 loss: 0.0019440013
Iter: 697 loss: 0.00194158987
Iter: 698 loss: 0.00193536305
Iter: 699 loss: 0.00198660884
Iter: 700 loss: 0.00193424779
Iter: 701 loss: 0.00192899397
Iter: 702 loss: 0.00195145211
Iter: 703 loss: 0.00192781596
Iter: 704 loss: 0.00192188611
Iter: 705 loss: 0.00200443435
Iter: 706 loss: 0.00192186411
Iter: 707 loss: 0.00191840075
Iter: 708 loss: 0.00191446533
Iter: 709 loss: 0.00191400526
Iter: 710 loss: 0.00190872164
Iter: 711 loss: 0.00189794588
Iter: 712 loss: 0.00248062983
Iter: 713 loss: 0.00189792225
Iter: 714 loss: 0.0018868685
Iter: 715 loss: 0.00199050899
Iter: 716 loss: 0.00188615709
Iter: 717 loss: 0.00188147
Iter: 718 loss: 0.00188132667
Iter: 719 loss: 0.00188042596
Iter: 720 loss: 0.0018791568
Iter: 721 loss: 0.00187685317
Iter: 722 loss: 0.0018760619
Iter: 723 loss: 0.00187474419
Iter: 724 loss: 0.00187081576
Iter: 725 loss: 0.00189424818
Iter: 726 loss: 0.00187033881
Iter: 727 loss: 0.00186697836
Iter: 728 loss: 0.00186697638
Iter: 729 loss: 0.00186383515
Iter: 730 loss: 0.00187469041
Iter: 731 loss: 0.00186303246
Iter: 732 loss: 0.00186013966
Iter: 733 loss: 0.00186667952
Iter: 734 loss: 0.00185887702
Iter: 735 loss: 0.00185589283
Iter: 736 loss: 0.00185985176
Iter: 737 loss: 0.00185438967
Iter: 738 loss: 0.00185072178
Iter: 739 loss: 0.00186196098
Iter: 740 loss: 0.00184962759
Iter: 741 loss: 0.00184519181
Iter: 742 loss: 0.00184180541
Iter: 743 loss: 0.00184037595
Iter: 744 loss: 0.00183566974
Iter: 745 loss: 0.0018422564
Iter: 746 loss: 0.00183315366
Iter: 747 loss: 0.00183104246
Iter: 748 loss: 0.0018333348
Iter: 749 loss: 0.00183007552
Iter: 750 loss: 0.00182496884
Iter: 751 loss: 0.00181786087
Iter: 752 loss: 0.00181743898
Iter: 753 loss: 0.00181016827
Iter: 754 loss: 0.00183869433
Iter: 755 loss: 0.00180868432
Iter: 756 loss: 0.0018031525
Iter: 757 loss: 0.00187511405
Iter: 758 loss: 0.00180308463
Iter: 759 loss: 0.00180035
Iter: 760 loss: 0.00180264201
Iter: 761 loss: 0.00179871824
Iter: 762 loss: 0.0017946919
Iter: 763 loss: 0.00181475957
Iter: 764 loss: 0.00179403
Iter: 765 loss: 0.00179081946
Iter: 766 loss: 0.00179078721
Iter: 767 loss: 0.00178983528
Iter: 768 loss: 0.00178851141
Iter: 769 loss: 0.001788461
Iter: 770 loss: 0.0017859498
Iter: 771 loss: 0.00179081573
Iter: 772 loss: 0.00178473513
Iter: 773 loss: 0.00178188877
Iter: 774 loss: 0.00179192901
Iter: 775 loss: 0.00178112066
Iter: 776 loss: 0.00178323593
Iter: 777 loss: 0.00177896372
Iter: 778 loss: 0.00177625776
Iter: 779 loss: 0.00180171081
Iter: 780 loss: 0.00177615206
Iter: 781 loss: 0.00177516951
Iter: 782 loss: 0.00177342934
Iter: 783 loss: 0.00177342258
Iter: 784 loss: 0.00177039
Iter: 785 loss: 0.00176493719
Iter: 786 loss: 0.00189991738
Iter: 787 loss: 0.00176493067
Iter: 788 loss: 0.00175899954
Iter: 789 loss: 0.00175899453
Iter: 790 loss: 0.0017550959
Iter: 791 loss: 0.00178040669
Iter: 792 loss: 0.00175465946
Iter: 793 loss: 0.00175148528
Iter: 794 loss: 0.00175415992
Iter: 795 loss: 0.00174962438
Iter: 796 loss: 0.00174671481
Iter: 797 loss: 0.00174331584
Iter: 798 loss: 0.00174293388
Iter: 799 loss: 0.0017452616
Iter: 800 loss: 0.00174176833
Iter: 801 loss: 0.00174026424
Iter: 802 loss: 0.00174194237
Iter: 803 loss: 0.00173943979
Iter: 804 loss: 0.00173630205
Iter: 805 loss: 0.00174696173
Iter: 806 loss: 0.00173545978
Iter: 807 loss: 0.00173018407
Iter: 808 loss: 0.00174424867
Iter: 809 loss: 0.00172845169
Iter: 810 loss: 0.00172515505
Iter: 811 loss: 0.00173380016
Iter: 812 loss: 0.00172404945
Iter: 813 loss: 0.00171986502
Iter: 814 loss: 0.0017132645
Iter: 815 loss: 0.0017131858
Iter: 816 loss: 0.00170884386
Iter: 817 loss: 0.00171362027
Iter: 818 loss: 0.00170648587
Iter: 819 loss: 0.00170290819
Iter: 820 loss: 0.00173440413
Iter: 821 loss: 0.00170269306
Iter: 822 loss: 0.00169987162
Iter: 823 loss: 0.00169604132
Iter: 824 loss: 0.00169586239
Iter: 825 loss: 0.00169240078
Iter: 826 loss: 0.00169925962
Iter: 827 loss: 0.00169093884
Iter: 828 loss: 0.00168905815
Iter: 829 loss: 0.00168927456
Iter: 830 loss: 0.0016876437
Iter: 831 loss: 0.00168412714
Iter: 832 loss: 0.00168411736
Iter: 833 loss: 0.00168063969
Iter: 834 loss: 0.00170110201
Iter: 835 loss: 0.00168007391
Iter: 836 loss: 0.00167697819
Iter: 837 loss: 0.00169368612
Iter: 838 loss: 0.00167650613
Iter: 839 loss: 0.00167299807
Iter: 840 loss: 0.00168576045
Iter: 841 loss: 0.00167212659
Iter: 842 loss: 0.00167089759
Iter: 843 loss: 0.00167082867
Iter: 844 loss: 0.00166990503
Iter: 845 loss: 0.00166646158
Iter: 846 loss: 0.00167832512
Iter: 847 loss: 0.00166551606
Iter: 848 loss: 0.00165929855
Iter: 849 loss: 0.00167887495
Iter: 850 loss: 0.00165748654
Iter: 851 loss: 0.00165332423
Iter: 852 loss: 0.00165687548
Iter: 853 loss: 0.00165086077
Iter: 854 loss: 0.00164450053
Iter: 855 loss: 0.00168044586
Iter: 856 loss: 0.00164358062
Iter: 857 loss: 0.00164144579
Iter: 858 loss: 0.00164594816
Iter: 859 loss: 0.00164060434
Iter: 860 loss: 0.00163813028
Iter: 861 loss: 0.0016356156
Iter: 862 loss: 0.00163511652
Iter: 863 loss: 0.00163252454
Iter: 864 loss: 0.00164664967
Iter: 865 loss: 0.00163206097
Iter: 866 loss: 0.00163042184
Iter: 867 loss: 0.00163728592
Iter: 868 loss: 0.00163007481
Iter: 869 loss: 0.00162523007
Iter: 870 loss: 0.0016565409
Iter: 871 loss: 0.00162464194
Iter: 872 loss: 0.00162896095
Iter: 873 loss: 0.00162171759
Iter: 874 loss: 0.00161998603
Iter: 875 loss: 0.00162854069
Iter: 876 loss: 0.00161969475
Iter: 877 loss: 0.00161702943
Iter: 878 loss: 0.00161494024
Iter: 879 loss: 0.00161411136
Iter: 880 loss: 0.00161106023
Iter: 881 loss: 0.00162928202
Iter: 882 loss: 0.00161046279
Iter: 883 loss: 0.00160881528
Iter: 884 loss: 0.00161146501
Iter: 885 loss: 0.00160808279
Iter: 886 loss: 0.00160690118
Iter: 887 loss: 0.00160747929
Iter: 888 loss: 0.00160610338
Iter: 889 loss: 0.00160479092
Iter: 890 loss: 0.00160138961
Iter: 891 loss: 0.00162610214
Iter: 892 loss: 0.00160075049
Iter: 893 loss: 0.00159852696
Iter: 894 loss: 0.00161664968
Iter: 895 loss: 0.00159828621
Iter: 896 loss: 0.00159717281
Iter: 897 loss: 0.00159537466
Iter: 898 loss: 0.0015953586
Iter: 899 loss: 0.00161000551
Iter: 900 loss: 0.00159361714
Iter: 901 loss: 0.00159091479
Iter: 902 loss: 0.0015972734
Iter: 903 loss: 0.00158989336
Iter: 904 loss: 0.00158811128
Iter: 905 loss: 0.00158595177
Iter: 906 loss: 0.0015857151
Iter: 907 loss: 0.00158266234
Iter: 908 loss: 0.00158944912
Iter: 909 loss: 0.00158152916
Iter: 910 loss: 0.00157823693
Iter: 911 loss: 0.00160358381
Iter: 912 loss: 0.0015778885
Iter: 913 loss: 0.00157633866
Iter: 914 loss: 0.00158326817
Iter: 915 loss: 0.00157607021
Iter: 916 loss: 0.00157458615
Iter: 917 loss: 0.001571181
Iter: 918 loss: 0.00161306211
Iter: 919 loss: 0.0015709186
Iter: 920 loss: 0.00156714651
Iter: 921 loss: 0.00156714837
Iter: 922 loss: 0.0015640182
Iter: 923 loss: 0.00157599733
Iter: 924 loss: 0.00156321668
Iter: 925 loss: 0.00156040234
Iter: 926 loss: 0.00156509457
Iter: 927 loss: 0.00155910093
Iter: 928 loss: 0.00155541557
Iter: 929 loss: 0.00155712117
Iter: 930 loss: 0.0015529861
Iter: 931 loss: 0.00155113591
Iter: 932 loss: 0.00155033311
Iter: 933 loss: 0.00154932821
Iter: 934 loss: 0.00154689653
Iter: 935 loss: 0.00157816615
Iter: 936 loss: 0.0015468921
Iter: 937 loss: 0.00154523214
Iter: 938 loss: 0.00156069547
Iter: 939 loss: 0.00154513679
Iter: 940 loss: 0.00154438661
Iter: 941 loss: 0.00154344807
Iter: 942 loss: 0.00154337694
Iter: 943 loss: 0.00154154806
Iter: 944 loss: 0.001540325
Iter: 945 loss: 0.00153961359
Iter: 946 loss: 0.00153674162
Iter: 947 loss: 0.00156520563
Iter: 948 loss: 0.0015366422
Iter: 949 loss: 0.00153457047
Iter: 950 loss: 0.00154105248
Iter: 951 loss: 0.00153399608
Iter: 952 loss: 0.00153295835
Iter: 953 loss: 0.00154443551
Iter: 954 loss: 0.00153291225
Iter: 955 loss: 0.00153228827
Iter: 956 loss: 0.00153324683
Iter: 957 loss: 0.00153198931
Iter: 958 loss: 0.00153060129
Iter: 959 loss: 0.00152728066
Iter: 960 loss: 0.00156549306
Iter: 961 loss: 0.00152695877
Iter: 962 loss: 0.00152178737
Iter: 963 loss: 0.00158368528
Iter: 964 loss: 0.00152165268
Iter: 965 loss: 0.00152300973
Iter: 966 loss: 0.00151822215
Iter: 967 loss: 0.00151486695
Iter: 968 loss: 0.00151452923
Iter: 969 loss: 0.00150873861
Iter: 970 loss: 0.0015952281
Iter: 971 loss: 0.00150842057
Iter: 972 loss: 0.00150673499
Iter: 973 loss: 0.00150281098
Iter: 974 loss: 0.00150063518
Iter: 975 loss: 0.00150850206
Iter: 976 loss: 0.00149995019
Iter: 977 loss: 0.00149737578
Iter: 978 loss: 0.00150129502
Iter: 979 loss: 0.00149617507
Iter: 980 loss: 0.00149299041
Iter: 981 loss: 0.0014981227
Iter: 982 loss: 0.00149151869
Iter: 983 loss: 0.00153194927
Iter: 984 loss: 0.00149008946
Iter: 985 loss: 0.00148823147
Iter: 986 loss: 0.00148265925
Iter: 987 loss: 0.00150128128
Iter: 988 loss: 0.00147990976
Iter: 989 loss: 0.00147348177
Iter: 990 loss: 0.00150453218
Iter: 991 loss: 0.00147224031
Iter: 992 loss: 0.00147030037
Iter: 993 loss: 0.00146971492
Iter: 994 loss: 0.00146846008
Iter: 995 loss: 0.00146761583
Iter: 996 loss: 0.001467144
Iter: 997 loss: 0.00146515516
Iter: 998 loss: 0.0014690191
Iter: 999 loss: 0.00146436493
Iter: 1000 loss: 0.00146328169
Iter: 1001 loss: 0.00147049199
Iter: 1002 loss: 0.00146308239
Iter: 1003 loss: 0.00146158994
Iter: 1004 loss: 0.00146418228
Iter: 1005 loss: 0.00146095757
Iter: 1006 loss: 0.00145893916
Iter: 1007 loss: 0.00146405993
Iter: 1008 loss: 0.00145825231
Iter: 1009 loss: 0.00145638431
Iter: 1010 loss: 0.0014549077
Iter: 1011 loss: 0.00145433
Iter: 1012 loss: 0.00145141827
Iter: 1013 loss: 0.00144995155
Iter: 1014 loss: 0.00144857494
Iter: 1015 loss: 0.00144379283
Iter: 1016 loss: 0.00144530344
Iter: 1017 loss: 0.00144041074
Iter: 1018 loss: 0.00146299321
Iter: 1019 loss: 0.00143877661
Iter: 1020 loss: 0.00143785356
Iter: 1021 loss: 0.00145055389
Iter: 1022 loss: 0.00143781235
Iter: 1023 loss: 0.00143711478
Iter: 1024 loss: 0.00143490359
Iter: 1025 loss: 0.00143812504
Iter: 1026 loss: 0.00143330346
Iter: 1027 loss: 0.0014283763
Iter: 1028 loss: 0.00144372345
Iter: 1029 loss: 0.00142683
Iter: 1030 loss: 0.00150772545
Iter: 1031 loss: 0.00142616848
Iter: 1032 loss: 0.00142574334
Iter: 1033 loss: 0.00142631645
Iter: 1034 loss: 0.00142553262
Iter: 1035 loss: 0.00142445508
Iter: 1036 loss: 0.00142189907
Iter: 1037 loss: 0.00144992094
Iter: 1038 loss: 0.00142165041
Iter: 1039 loss: 0.00141870836
Iter: 1040 loss: 0.00141747459
Iter: 1041 loss: 0.0014159017
Iter: 1042 loss: 0.00141436839
Iter: 1043 loss: 0.0014143663
Iter: 1044 loss: 0.00141323416
Iter: 1045 loss: 0.00141214347
Iter: 1046 loss: 0.00141191692
Iter: 1047 loss: 0.00140875718
Iter: 1048 loss: 0.00142878527
Iter: 1049 loss: 0.00140820991
Iter: 1050 loss: 0.00141138863
Iter: 1051 loss: 0.0014062929
Iter: 1052 loss: 0.00140438008
Iter: 1053 loss: 0.00140795566
Iter: 1054 loss: 0.00140357332
Iter: 1055 loss: 0.00140158948
Iter: 1056 loss: 0.00140104361
Iter: 1057 loss: 0.00139978691
Iter: 1058 loss: 0.00139403809
Iter: 1059 loss: 0.00140825682
Iter: 1060 loss: 0.00139197335
Iter: 1061 loss: 0.00139219291
Iter: 1062 loss: 0.00138835306
Iter: 1063 loss: 0.0013869293
Iter: 1064 loss: 0.00139738037
Iter: 1065 loss: 0.00138680614
Iter: 1066 loss: 0.00138338702
Iter: 1067 loss: 0.00138341449
Iter: 1068 loss: 0.00138053193
Iter: 1069 loss: 0.00137754914
Iter: 1070 loss: 0.00137676054
Iter: 1071 loss: 0.00137577974
Iter: 1072 loss: 0.00137551443
Iter: 1073 loss: 0.001374949
Iter: 1074 loss: 0.00137357321
Iter: 1075 loss: 0.00138622755
Iter: 1076 loss: 0.0013733845
Iter: 1077 loss: 0.00137126469
Iter: 1078 loss: 0.0013735611
Iter: 1079 loss: 0.00137006934
Iter: 1080 loss: 0.00136810809
Iter: 1081 loss: 0.00136989669
Iter: 1082 loss: 0.00136698992
Iter: 1083 loss: 0.00136381947
Iter: 1084 loss: 0.00136712263
Iter: 1085 loss: 0.0013618716
Iter: 1086 loss: 0.00135858613
Iter: 1087 loss: 0.00135862082
Iter: 1088 loss: 0.0013559846
Iter: 1089 loss: 0.00135265884
Iter: 1090 loss: 0.00136655488
Iter: 1091 loss: 0.0013521217
Iter: 1092 loss: 0.00135004707
Iter: 1093 loss: 0.00134997279
Iter: 1094 loss: 0.00134880852
Iter: 1095 loss: 0.0013539819
Iter: 1096 loss: 0.00134856452
Iter: 1097 loss: 0.00134580419
Iter: 1098 loss: 0.001346551
Iter: 1099 loss: 0.00134362921
Iter: 1100 loss: 0.00133932196
Iter: 1101 loss: 0.00133921974
Iter: 1102 loss: 0.00133718434
Iter: 1103 loss: 0.00134301977
Iter: 1104 loss: 0.0013365557
Iter: 1105 loss: 0.00133463112
Iter: 1106 loss: 0.00133100653
Iter: 1107 loss: 0.00141414709
Iter: 1108 loss: 0.00133099291
Iter: 1109 loss: 0.00132981013
Iter: 1110 loss: 0.00132931955
Iter: 1111 loss: 0.0013259137
Iter: 1112 loss: 0.00135178934
Iter: 1113 loss: 0.00132561894
Iter: 1114 loss: 0.00132295908
Iter: 1115 loss: 0.00132320274
Iter: 1116 loss: 0.00132087583
Iter: 1117 loss: 0.0013190693
Iter: 1118 loss: 0.00131932308
Iter: 1119 loss: 0.00131769758
Iter: 1120 loss: 0.00131508661
Iter: 1121 loss: 0.00131026236
Iter: 1122 loss: 0.00146720884
Iter: 1123 loss: 0.00131025421
Iter: 1124 loss: 0.00130843569
Iter: 1125 loss: 0.00130804849
Iter: 1126 loss: 0.00130746549
Iter: 1127 loss: 0.00131115247
Iter: 1128 loss: 0.00130740087
Iter: 1129 loss: 0.00130411785
Iter: 1130 loss: 0.00131200009
Iter: 1131 loss: 0.00130289653
Iter: 1132 loss: 0.00130009651
Iter: 1133 loss: 0.00131074851
Iter: 1134 loss: 0.00129939895
Iter: 1135 loss: 0.00129831443
Iter: 1136 loss: 0.00130061689
Iter: 1137 loss: 0.00129787694
Iter: 1138 loss: 0.00129650813
Iter: 1139 loss: 0.00131175644
Iter: 1140 loss: 0.00129647925
Iter: 1141 loss: 0.00129515468
Iter: 1142 loss: 0.00129843806
Iter: 1143 loss: 0.00129467715
Iter: 1144 loss: 0.00129286642
Iter: 1145 loss: 0.0013028119
Iter: 1146 loss: 0.00129257247
Iter: 1147 loss: 0.0012911174
Iter: 1148 loss: 0.00131384144
Iter: 1149 loss: 0.00129111414
Iter: 1150 loss: 0.00129041087
Iter: 1151 loss: 0.00128955941
Iter: 1152 loss: 0.00128948141
Iter: 1153 loss: 0.00128995231
Iter: 1154 loss: 0.00128880749
Iter: 1155 loss: 0.00128719129
Iter: 1156 loss: 0.00130514789
Iter: 1157 loss: 0.00128711131
Iter: 1158 loss: 0.001286702
Iter: 1159 loss: 0.00128893903
Iter: 1160 loss: 0.00128664554
Iter: 1161 loss: 0.00128576544
Iter: 1162 loss: 0.00128378824
Iter: 1163 loss: 0.00131687487
Iter: 1164 loss: 0.00128369068
Iter: 1165 loss: 0.00129040424
Iter: 1166 loss: 0.00128297647
Iter: 1167 loss: 0.00128207006
Iter: 1168 loss: 0.00128370058
Iter: 1169 loss: 0.00128168077
Iter: 1170 loss: 0.00128066365
Iter: 1171 loss: 0.00128088298
Iter: 1172 loss: 0.00127981184
Iter: 1173 loss: 0.00127882371
Iter: 1174 loss: 0.00128679373
Iter: 1175 loss: 0.00127876922
Iter: 1176 loss: 0.00127781474
Iter: 1177 loss: 0.00127737178
Iter: 1178 loss: 0.00127684651
Iter: 1179 loss: 0.00127568538
Iter: 1180 loss: 0.00128391781
Iter: 1181 loss: 0.00127559784
Iter: 1182 loss: 0.0012752153
Iter: 1183 loss: 0.00127551518
Iter: 1184 loss: 0.00127495895
Iter: 1185 loss: 0.00127432041
Iter: 1186 loss: 0.00127331819
Iter: 1187 loss: 0.00127330888
Iter: 1188 loss: 0.0012778563
Iter: 1189 loss: 0.00127273402
Iter: 1190 loss: 0.00127166952
Iter: 1191 loss: 0.0012728835
Iter: 1192 loss: 0.00127112
Iter: 1193 loss: 0.0012702581
Iter: 1194 loss: 0.00127060292
Iter: 1195 loss: 0.0012696163
Iter: 1196 loss: 0.00126902177
Iter: 1197 loss: 0.00126901828
Iter: 1198 loss: 0.0012685965
Iter: 1199 loss: 0.00126834633
Iter: 1200 loss: 0.00126816717
Iter: 1201 loss: 0.00126710266
Iter: 1202 loss: 0.00126768695
Iter: 1203 loss: 0.00126639986
Iter: 1204 loss: 0.00126536889
Iter: 1205 loss: 0.00126380112
Iter: 1206 loss: 0.00126376562
Iter: 1207 loss: 0.0012609011
Iter: 1208 loss: 0.00125780306
Iter: 1209 loss: 0.00125726871
Iter: 1210 loss: 0.00125577266
Iter: 1211 loss: 0.00127080688
Iter: 1212 loss: 0.00125573925
Iter: 1213 loss: 0.00125509035
Iter: 1214 loss: 0.00125578931
Iter: 1215 loss: 0.00125470199
Iter: 1216 loss: 0.00125369802
Iter: 1217 loss: 0.00125396461
Iter: 1218 loss: 0.00125295774
Iter: 1219 loss: 0.00124862324
Iter: 1220 loss: 0.00131672481
Iter: 1221 loss: 0.00124858203
Iter: 1222 loss: 0.00124641822
Iter: 1223 loss: 0.00127125904
Iter: 1224 loss: 0.00124634989
Iter: 1225 loss: 0.00124781416
Iter: 1226 loss: 0.00124516967
Iter: 1227 loss: 0.00124446943
Iter: 1228 loss: 0.00124376721
Iter: 1229 loss: 0.00124362414
Iter: 1230 loss: 0.00124225905
Iter: 1231 loss: 0.00124181388
Iter: 1232 loss: 0.00124098349
Iter: 1233 loss: 0.00123916171
Iter: 1234 loss: 0.00124851125
Iter: 1235 loss: 0.0012388532
Iter: 1236 loss: 0.00123803038
Iter: 1237 loss: 0.00124215521
Iter: 1238 loss: 0.00123793387
Iter: 1239 loss: 0.00123734644
Iter: 1240 loss: 0.00123813655
Iter: 1241 loss: 0.00123700267
Iter: 1242 loss: 0.00123649929
Iter: 1243 loss: 0.00123723852
Iter: 1244 loss: 0.00123621849
Iter: 1245 loss: 0.00123459497
Iter: 1246 loss: 0.00123422267
Iter: 1247 loss: 0.001233196
Iter: 1248 loss: 0.00123217062
Iter: 1249 loss: 0.00124655035
Iter: 1250 loss: 0.00123213697
Iter: 1251 loss: 0.00123172626
Iter: 1252 loss: 0.00123375724
Iter: 1253 loss: 0.00123167457
Iter: 1254 loss: 0.00123039063
Iter: 1255 loss: 0.00124752708
Iter: 1256 loss: 0.00123036304
Iter: 1257 loss: 0.00122890179
Iter: 1258 loss: 0.0012302103
Iter: 1259 loss: 0.00122801831
Iter: 1260 loss: 0.0012248836
Iter: 1261 loss: 0.00123102986
Iter: 1262 loss: 0.00122360233
Iter: 1263 loss: 0.00121957704
Iter: 1264 loss: 0.00123469415
Iter: 1265 loss: 0.0012186463
Iter: 1266 loss: 0.0012174712
Iter: 1267 loss: 0.00121743989
Iter: 1268 loss: 0.00121689448
Iter: 1269 loss: 0.00121811882
Iter: 1270 loss: 0.00121667073
Iter: 1271 loss: 0.00121573161
Iter: 1272 loss: 0.00121410168
Iter: 1273 loss: 0.00121409923
Iter: 1274 loss: 0.0012124842
Iter: 1275 loss: 0.0012193385
Iter: 1276 loss: 0.00121222297
Iter: 1277 loss: 0.00121154753
Iter: 1278 loss: 0.0012165365
Iter: 1279 loss: 0.0012114899
Iter: 1280 loss: 0.00121118617
Iter: 1281 loss: 0.0012110211
Iter: 1282 loss: 0.00121019082
Iter: 1283 loss: 0.00121012749
Iter: 1284 loss: 0.00120950141
Iter: 1285 loss: 0.00120865158
Iter: 1286 loss: 0.00120657403
Iter: 1287 loss: 0.00122631085
Iter: 1288 loss: 0.0012063157
Iter: 1289 loss: 0.00120405504
Iter: 1290 loss: 0.00120738009
Iter: 1291 loss: 0.00120285875
Iter: 1292 loss: 0.00120094512
Iter: 1293 loss: 0.00120126433
Iter: 1294 loss: 0.00119949249
Iter: 1295 loss: 0.00119696278
Iter: 1296 loss: 0.00120486098
Iter: 1297 loss: 0.00119582901
Iter: 1298 loss: 0.00119157822
Iter: 1299 loss: 0.00120890082
Iter: 1300 loss: 0.00119092572
Iter: 1301 loss: 0.00118914433
Iter: 1302 loss: 0.00118902593
Iter: 1303 loss: 0.00118723628
Iter: 1304 loss: 0.00118706096
Iter: 1305 loss: 0.00118658738
Iter: 1306 loss: 0.00118903571
Iter: 1307 loss: 0.00118649192
Iter: 1308 loss: 0.00118599925
Iter: 1309 loss: 0.00118563185
Iter: 1310 loss: 0.00118549529
Iter: 1311 loss: 0.00118405302
Iter: 1312 loss: 0.00118380296
Iter: 1313 loss: 0.00118281052
Iter: 1314 loss: 0.00118117535
Iter: 1315 loss: 0.00119201175
Iter: 1316 loss: 0.00118099689
Iter: 1317 loss: 0.00117989525
Iter: 1318 loss: 0.00119708048
Iter: 1319 loss: 0.00117985706
Iter: 1320 loss: 0.0011783957
Iter: 1321 loss: 0.00118337816
Iter: 1322 loss: 0.00117798266
Iter: 1323 loss: 0.00117705343
Iter: 1324 loss: 0.00117771165
Iter: 1325 loss: 0.00117661245
Iter: 1326 loss: 0.00117562618
Iter: 1327 loss: 0.00117605412
Iter: 1328 loss: 0.00117486529
Iter: 1329 loss: 0.00117422361
Iter: 1330 loss: 0.00117620477
Iter: 1331 loss: 0.00117403746
Iter: 1332 loss: 0.00117268274
Iter: 1333 loss: 0.00117579068
Iter: 1334 loss: 0.00117218611
Iter: 1335 loss: 0.00117140892
Iter: 1336 loss: 0.00117140636
Iter: 1337 loss: 0.00117067713
Iter: 1338 loss: 0.00117280614
Iter: 1339 loss: 0.00117037422
Iter: 1340 loss: 0.00116842252
Iter: 1341 loss: 0.00117460056
Iter: 1342 loss: 0.00116790261
Iter: 1343 loss: 0.00116700376
Iter: 1344 loss: 0.00117020775
Iter: 1345 loss: 0.0011667764
Iter: 1346 loss: 0.00116621517
Iter: 1347 loss: 0.00116582937
Iter: 1348 loss: 0.00116561656
Iter: 1349 loss: 0.00116230128
Iter: 1350 loss: 0.00116967456
Iter: 1351 loss: 0.00116100116
Iter: 1352 loss: 0.00115656538
Iter: 1353 loss: 0.00117542478
Iter: 1354 loss: 0.00115567329
Iter: 1355 loss: 0.00115388108
Iter: 1356 loss: 0.00115567469
Iter: 1357 loss: 0.00115286338
Iter: 1358 loss: 0.00115133426
Iter: 1359 loss: 0.00115679635
Iter: 1360 loss: 0.00115095195
Iter: 1361 loss: 0.00115031097
Iter: 1362 loss: 0.00115112425
Iter: 1363 loss: 0.00114994915
Iter: 1364 loss: 0.00114917627
Iter: 1365 loss: 0.00116774708
Iter: 1366 loss: 0.0011491325
Iter: 1367 loss: 0.00114925439
Iter: 1368 loss: 0.00114872213
Iter: 1369 loss: 0.00114814762
Iter: 1370 loss: 0.00115056778
Iter: 1371 loss: 0.00114802353
Iter: 1372 loss: 0.00114713924
Iter: 1373 loss: 0.00116932765
Iter: 1374 loss: 0.00114714121
Iter: 1375 loss: 0.00115079898
Iter: 1376 loss: 0.00114659918
Iter: 1377 loss: 0.00114592479
Iter: 1378 loss: 0.00115888147
Iter: 1379 loss: 0.00114588614
Iter: 1380 loss: 0.00114616519
Iter: 1381 loss: 0.00114524411
Iter: 1382 loss: 0.00114429556
Iter: 1383 loss: 0.00115410541
Iter: 1384 loss: 0.00114411255
Iter: 1385 loss: 0.00114241801
Iter: 1386 loss: 0.00116644148
Iter: 1387 loss: 0.00114233536
Iter: 1388 loss: 0.00114147016
Iter: 1389 loss: 0.00114103302
Iter: 1390 loss: 0.00114011008
Iter: 1391 loss: 0.00114088878
Iter: 1392 loss: 0.00113950158
Iter: 1393 loss: 0.0011389436
Iter: 1394 loss: 0.00113893859
Iter: 1395 loss: 0.00113881216
Iter: 1396 loss: 0.00113908062
Iter: 1397 loss: 0.0011387571
Iter: 1398 loss: 0.00113860099
Iter: 1399 loss: 0.00113817723
Iter: 1400 loss: 0.00114208693
Iter: 1401 loss: 0.00113807863
Iter: 1402 loss: 0.00113677967
Iter: 1403 loss: 0.0011425371
Iter: 1404 loss: 0.00113652623
Iter: 1405 loss: 0.00113471772
Iter: 1406 loss: 0.00113467709
Iter: 1407 loss: 0.00113497139
Iter: 1408 loss: 0.00113421492
Iter: 1409 loss: 0.00113417
Iter: 1410 loss: 0.00113391387
Iter: 1411 loss: 0.00113366614
Iter: 1412 loss: 0.0011338715
Iter: 1413 loss: 0.00113350945
Iter: 1414 loss: 0.00113325915
Iter: 1415 loss: 0.0011333396
Iter: 1416 loss: 0.00113308337
Iter: 1417 loss: 0.00113283494
Iter: 1418 loss: 0.00113205449
Iter: 1419 loss: 0.00113563181
Iter: 1420 loss: 0.00113168219
Iter: 1421 loss: 0.00113216811
Iter: 1422 loss: 0.00113115087
Iter: 1423 loss: 0.00113058556
Iter: 1424 loss: 0.00113059
Iter: 1425 loss: 0.00113107287
Iter: 1426 loss: 0.00113004365
Iter: 1427 loss: 0.00112986076
Iter: 1428 loss: 0.00113049638
Iter: 1429 loss: 0.00112981116
Iter: 1430 loss: 0.00112963817
Iter: 1431 loss: 0.00112926879
Iter: 1432 loss: 0.00113324984
Iter: 1433 loss: 0.00112925423
Iter: 1434 loss: 0.0011283803
Iter: 1435 loss: 0.00112654036
Iter: 1436 loss: 0.00112654536
Iter: 1437 loss: 0.00112602406
Iter: 1438 loss: 0.0011260031
Iter: 1439 loss: 0.00112585281
Iter: 1440 loss: 0.00112584443
Iter: 1441 loss: 0.00112574187
Iter: 1442 loss: 0.00112545164
Iter: 1443 loss: 0.00112715736
Iter: 1444 loss: 0.00112531916
Iter: 1445 loss: 0.00112476258
Iter: 1446 loss: 0.00112476037
Iter: 1447 loss: 0.00112463965
Iter: 1448 loss: 0.00112410728
Iter: 1449 loss: 0.00112380949
Iter: 1450 loss: 0.00112956157
Iter: 1451 loss: 0.00112381065
Iter: 1452 loss: 0.00112328888
Iter: 1453 loss: 0.00112790149
Iter: 1454 loss: 0.0011232628
Iter: 1455 loss: 0.00112271472
Iter: 1456 loss: 0.001122216
Iter: 1457 loss: 0.00112207502
Iter: 1458 loss: 0.00112154242
Iter: 1459 loss: 0.0011221515
Iter: 1460 loss: 0.0011212409
Iter: 1461 loss: 0.00112103461
Iter: 1462 loss: 0.0011215352
Iter: 1463 loss: 0.00112095918
Iter: 1464 loss: 0.00112079526
Iter: 1465 loss: 0.00112056953
Iter: 1466 loss: 0.0011205622
Iter: 1467 loss: 0.00112037605
Iter: 1468 loss: 0.00112096732
Iter: 1469 loss: 0.00112033496
Iter: 1470 loss: 0.00111963623
Iter: 1471 loss: 0.00111957686
Iter: 1472 loss: 0.00111878267
Iter: 1473 loss: 0.0011171425
Iter: 1474 loss: 0.0012976781
Iter: 1475 loss: 0.00111715507
Iter: 1476 loss: 0.00111685973
Iter: 1477 loss: 0.00111638242
Iter: 1478 loss: 0.00111586647
Iter: 1479 loss: 0.00112097617
Iter: 1480 loss: 0.0011158085
Iter: 1481 loss: 0.0011155461
Iter: 1482 loss: 0.00111726415
Iter: 1483 loss: 0.00111551536
Iter: 1484 loss: 0.00111695216
Iter: 1485 loss: 0.00111526554
Iter: 1486 loss: 0.00111489696
Iter: 1487 loss: 0.0011193864
Iter: 1488 loss: 0.00111490232
Iter: 1489 loss: 0.00111452735
Iter: 1490 loss: 0.0011147341
Iter: 1491 loss: 0.00111427414
Iter: 1492 loss: 0.00111398147
Iter: 1493 loss: 0.00111392024
Iter: 1494 loss: 0.00111371814
Iter: 1495 loss: 0.00111345539
Iter: 1496 loss: 0.0011133654
Iter: 1497 loss: 0.00111320475
Iter: 1498 loss: 0.00111281208
Iter: 1499 loss: 0.00111254316
Iter: 1500 loss: 0.001112425
Iter: 1501 loss: 0.00111211697
Iter: 1502 loss: 0.00111368881
Iter: 1503 loss: 0.00111205294
Iter: 1504 loss: 0.00111191405
Iter: 1505 loss: 0.00111264247
Iter: 1506 loss: 0.00111188879
Iter: 1507 loss: 0.00111173792
Iter: 1508 loss: 0.00111203548
Iter: 1509 loss: 0.00111166434
Iter: 1510 loss: 0.00111151207
Iter: 1511 loss: 0.00111154106
Iter: 1512 loss: 0.0011113981
Iter: 1513 loss: 0.00111130951
Iter: 1514 loss: 0.00111124781
Iter: 1515 loss: 0.0011112194
Iter: 1516 loss: 0.00111115421
Iter: 1517 loss: 0.00111102965
Iter: 1518 loss: 0.00111370045
Iter: 1519 loss: 0.00111103128
Iter: 1520 loss: 0.00112245954
Iter: 1521 loss: 0.0011108208
Iter: 1522 loss: 0.00111577578
Iter: 1523 loss: 0.00111060531
Iter: 1524 loss: 0.00111615658
Iter: 1525 loss: 0.00110925455
Iter: 1526 loss: 0.00110836688
Iter: 1527 loss: 0.00111248
Iter: 1528 loss: 0.00110817479
Iter: 1529 loss: 0.00110764499
Iter: 1530 loss: 0.00110707642
Iter: 1531 loss: 0.00110697
Iter: 1532 loss: 0.00110633858
Iter: 1533 loss: 0.0011062806
Iter: 1534 loss: 0.0011059324
Iter: 1535 loss: 0.00110954535
Iter: 1536 loss: 0.00110591645
Iter: 1537 loss: 0.00110574707
Iter: 1538 loss: 0.00110629364
Iter: 1539 loss: 0.00110569014
Iter: 1540 loss: 0.0011056246
Iter: 1541 loss: 0.0011058175
Iter: 1542 loss: 0.00110560213
Iter: 1543 loss: 0.0011055111
Iter: 1544 loss: 0.00110542914
Iter: 1545 loss: 0.0011054019
Iter: 1546 loss: 0.00110516162
Iter: 1547 loss: 0.00110497954
Iter: 1548 loss: 0.00110490504
Iter: 1549 loss: 0.00110481877
Iter: 1550 loss: 0.00110487267
Iter: 1551 loss: 0.00110476138
Iter: 1552 loss: 0.00110443006
Iter: 1553 loss: 0.00110394845
Iter: 1554 loss: 0.00110393879
Iter: 1555 loss: 0.00110552763
Iter: 1556 loss: 0.00110330223
Iter: 1557 loss: 0.00110291503
Iter: 1558 loss: 0.00110422284
Iter: 1559 loss: 0.00110278605
Iter: 1560 loss: 0.00110250642
Iter: 1561 loss: 0.0011046388
Iter: 1562 loss: 0.00110248302
Iter: 1563 loss: 0.00110244297
Iter: 1564 loss: 0.0011024035
Iter: 1565 loss: 0.00110226218
Iter: 1566 loss: 0.00110199559
Iter: 1567 loss: 0.00110813254
Iter: 1568 loss: 0.00110199256
Iter: 1569 loss: 0.00110168615
Iter: 1570 loss: 0.00110235659
Iter: 1571 loss: 0.00110154902
Iter: 1572 loss: 0.00110125216
Iter: 1573 loss: 0.00110538956
Iter: 1574 loss: 0.00110124773
Iter: 1575 loss: 0.00110111234
Iter: 1576 loss: 0.00110095041
Iter: 1577 loss: 0.0011009227
Iter: 1578 loss: 0.00110054039
Iter: 1579 loss: 0.00110034179
Iter: 1580 loss: 0.00110017299
Iter: 1581 loss: 0.00110092654
Iter: 1582 loss: 0.00110012665
Iter: 1583 loss: 0.00109993096
Iter: 1584 loss: 0.00110052747
Iter: 1585 loss: 0.00109987066
Iter: 1586 loss: 0.00109979883
Iter: 1587 loss: 0.00110130361
Iter: 1588 loss: 0.00109979848
Iter: 1589 loss: 0.00109976775
Iter: 1590 loss: 0.00109980965
Iter: 1591 loss: 0.00109975156
Iter: 1592 loss: 0.00110120594
Iter: 1593 loss: 0.00109952583
Iter: 1594 loss: 0.00109898695
Iter: 1595 loss: 0.00109997159
Iter: 1596 loss: 0.00109875668
Iter: 1597 loss: 0.00109851954
Iter: 1598 loss: 0.00109964225
Iter: 1599 loss: 0.00109849009
Iter: 1600 loss: 0.00109828811
Iter: 1601 loss: 0.00110080105
Iter: 1602 loss: 0.00109829195
Iter: 1603 loss: 0.00109825633
Iter: 1604 loss: 0.0010984299
Iter: 1605 loss: 0.00109824666
Iter: 1606 loss: 0.00109821314
Iter: 1607 loss: 0.00109820673
Iter: 1608 loss: 0.00109813153
Iter: 1609 loss: 0.00109793805
Iter: 1610 loss: 0.00109900418
Iter: 1611 loss: 0.00109788531
Iter: 1612 loss: 0.00109726191
Iter: 1613 loss: 0.0011046
Iter: 1614 loss: 0.00109724386
Iter: 1615 loss: 0.0010974101
Iter: 1616 loss: 0.00109700742
Iter: 1617 loss: 0.00109673059
Iter: 1618 loss: 0.00109696994
Iter: 1619 loss: 0.00109657086
Iter: 1620 loss: 0.00109624839
Iter: 1621 loss: 0.00110105705
Iter: 1622 loss: 0.00109622721
Iter: 1623 loss: 0.00109587738
Iter: 1624 loss: 0.00109542604
Iter: 1625 loss: 0.00109537668
Iter: 1626 loss: 0.00109493756
Iter: 1627 loss: 0.00109644607
Iter: 1628 loss: 0.00109484373
Iter: 1629 loss: 0.00109458866
Iter: 1630 loss: 0.00110012689
Iter: 1631 loss: 0.00109458668
Iter: 1632 loss: 0.00109450868
Iter: 1633 loss: 0.00109495292
Iter: 1634 loss: 0.00109449972
Iter: 1635 loss: 0.00109448237
Iter: 1636 loss: 0.0010944684
Iter: 1637 loss: 0.001094445
Iter: 1638 loss: 0.00109438342
Iter: 1639 loss: 0.00109450729
Iter: 1640 loss: 0.00109434512
Iter: 1641 loss: 0.00109420577
Iter: 1642 loss: 0.00109399413
Iter: 1643 loss: 0.00109398516
Iter: 1644 loss: 0.00109383056
Iter: 1645 loss: 0.00109458598
Iter: 1646 loss: 0.00109381403
Iter: 1647 loss: 0.00109373778
Iter: 1648 loss: 0.0010938592
Iter: 1649 loss: 0.00109371275
Iter: 1650 loss: 0.00109367841
Iter: 1651 loss: 0.00109385967
Iter: 1652 loss: 0.00109367433
Iter: 1653 loss: 0.00109356723
Iter: 1654 loss: 0.00109356712
Iter: 1655 loss: 0.00109347561
Iter: 1656 loss: 0.00109327526
Iter: 1657 loss: 0.0010930805
Iter: 1658 loss: 0.00109303743
Iter: 1659 loss: 0.00175424223
Iter: 1660 loss: 0.00109303137
Iter: 1661 loss: 0.00109290658
Iter: 1662 loss: 0.00109329075
Iter: 1663 loss: 0.00109287351
Iter: 1664 loss: 0.00109300669
Iter: 1665 loss: 0.00109282532
Iter: 1666 loss: 0.00109277712
Iter: 1667 loss: 0.00109304034
Iter: 1668 loss: 0.00109276292
Iter: 1669 loss: 0.00109290204
Iter: 1670 loss: 0.00109275
Iter: 1671 loss: 0.00109274301
Iter: 1672 loss: 0.00109277957
Iter: 1673 loss: 0.00109273661
Iter: 1674 loss: 0.00109273358
Iter: 1675 loss: 0.0010927479
Iter: 1676 loss: 0.00109272823
Iter: 1677 loss: 0.00109271775
Iter: 1678 loss: 0.00109272148
Iter: 1679 loss: 0.00109270448
Iter: 1680 loss: 0.001092677
Iter: 1681 loss: 0.00109310739
Iter: 1682 loss: 0.00109267607
Iter: 1683 loss: 0.00109261274
Iter: 1684 loss: 0.00109243614
Iter: 1685 loss: 0.00109269912
Iter: 1686 loss: 0.00109233963
Iter: 1687 loss: 0.00109200249
Iter: 1688 loss: 0.00109193835
Iter: 1689 loss: 0.00109171588
Iter: 1690 loss: 0.00109142903
Iter: 1691 loss: 0.0010938287
Iter: 1692 loss: 0.00109141762
Iter: 1693 loss: 0.00109137106
Iter: 1694 loss: 0.00109165837
Iter: 1695 loss: 0.00109136058
Iter: 1696 loss: 0.00109133776
Iter: 1697 loss: 0.00109159306
Iter: 1698 loss: 0.00109133462
Iter: 1699 loss: 0.00109126279
Iter: 1700 loss: 0.00109134009
Iter: 1701 loss: 0.0010912302
Iter: 1702 loss: 0.00109118549
Iter: 1703 loss: 0.00109127653
Iter: 1704 loss: 0.00109116628
Iter: 1705 loss: 0.0010911047
Iter: 1706 loss: 0.00109116768
Iter: 1707 loss: 0.00109107
Iter: 1708 loss: 0.00109100295
Iter: 1709 loss: 0.00109128165
Iter: 1710 loss: 0.00109098852
Iter: 1711 loss: 0.0010909657
Iter: 1712 loss: 0.00109096174
Iter: 1713 loss: 0.00109094719
Iter: 1714 loss: 0.00109092041
Iter: 1715 loss: 0.00109088537
Iter: 1716 loss: 0.00109088211
Iter: 1717 loss: 0.00109080691
Iter: 1718 loss: 0.00109105546
Iter: 1719 loss: 0.001090782
Iter: 1720 loss: 0.00109073904
Iter: 1721 loss: 0.0010909657
Iter: 1722 loss: 0.00109073252
Iter: 1723 loss: 0.00109069678
Iter: 1724 loss: 0.00109063101
Iter: 1725 loss: 0.00109154289
Iter: 1726 loss: 0.00109062821
Iter: 1727 loss: 0.00109011447
Iter: 1728 loss: 0.00109256012
Iter: 1729 loss: 0.00109001808
Iter: 1730 loss: 0.00108955894
Iter: 1731 loss: 0.00108959037
Iter: 1732 loss: 0.00108920014
Iter: 1733 loss: 0.00108866789
Iter: 1734 loss: 0.00109646586
Iter: 1735 loss: 0.00108864845
Iter: 1736 loss: 0.00108836044
Iter: 1737 loss: 0.00108835741
Iter: 1738 loss: 0.00108825846
Iter: 1739 loss: 0.00109073205
Iter: 1740 loss: 0.00108825532
Iter: 1741 loss: 0.00108824507
Iter: 1742 loss: 0.00108832179
Iter: 1743 loss: 0.00108823867
Iter: 1744 loss: 0.00108807965
Iter: 1745 loss: 0.00108759198
Iter: 1746 loss: 0.00109064823
Iter: 1747 loss: 0.00108741014
Iter: 1748 loss: 0.00108668313
Iter: 1749 loss: 0.0010876843
Iter: 1750 loss: 0.00108634273
Iter: 1751 loss: 0.00108586671
Iter: 1752 loss: 0.00108956813
Iter: 1753 loss: 0.00108586089
Iter: 1754 loss: 0.00108566612
Iter: 1755 loss: 0.00108556217
Iter: 1756 loss: 0.00108549441
Iter: 1757 loss: 0.00108594913
Iter: 1758 loss: 0.00108548487
Iter: 1759 loss: 0.0010999965
Iter: 1760 loss: 0.00108541548
Iter: 1761 loss: 0.00108487532
Iter: 1762 loss: 0.0010842859
Iter: 1763 loss: 0.00108421186
Iter: 1764 loss: 0.00108387147
Iter: 1765 loss: 0.0010854844
Iter: 1766 loss: 0.00108379882
Iter: 1767 loss: 0.00108371081
Iter: 1768 loss: 0.00108439988
Iter: 1769 loss: 0.00108370173
Iter: 1770 loss: 0.00116187579
Iter: 1771 loss: 0.00108370022
Iter: 1772 loss: 0.00108366436
Iter: 1773 loss: 0.00108409522
Iter: 1774 loss: 0.00108366483
Iter: 1775 loss: 0.00108359451
Iter: 1776 loss: 0.00108345901
Iter: 1777 loss: 0.00108591118
Iter: 1778 loss: 0.00108345
Iter: 1779 loss: 0.00108338147
Iter: 1780 loss: 0.001083432
Iter: 1781 loss: 0.00108333724
Iter: 1782 loss: 0.00108327321
Iter: 1783 loss: 0.00108311512
Iter: 1784 loss: 0.00108620082
Iter: 1785 loss: 0.00108311558
Iter: 1786 loss: 0.00108468812
Iter: 1787 loss: 0.00108303665
Iter: 1788 loss: 0.00108284887
Iter: 1789 loss: 0.00108268019
Iter: 1790 loss: 0.00108256796
Iter: 1791 loss: 0.00108192523
Iter: 1792 loss: 0.00108870619
Iter: 1793 loss: 0.0010818257
Iter: 1794 loss: 0.00108171022
Iter: 1795 loss: 0.00108169578
Iter: 1796 loss: 0.00108166877
Iter: 1797 loss: 0.00108166505
Iter: 1798 loss: 0.00108165352
Iter: 1799 loss: 0.00108161662
Iter: 1800 loss: 0.00108189741
Iter: 1801 loss: 0.00108160253
Iter: 1802 loss: 0.00109385245
Iter: 1803 loss: 0.00108154921
Iter: 1804 loss: 0.00108103035
Iter: 1805 loss: 0.00108496496
Iter: 1806 loss: 0.00108096818
Iter: 1807 loss: 0.00108061254
Iter: 1808 loss: 0.00108468393
Iter: 1809 loss: 0.00108060474
Iter: 1810 loss: 0.00108012115
Iter: 1811 loss: 0.0010801187
Iter: 1812 loss: 0.0010799797
Iter: 1813 loss: 0.00107996562
Iter: 1814 loss: 0.00107990066
Iter: 1815 loss: 0.00107988308
Iter: 1816 loss: 0.00107987691
Iter: 1817 loss: 0.00107986666
Iter: 1818 loss: 0.00107986224
Iter: 1819 loss: 0.00107983896
Iter: 1820 loss: 0.00107975956
Iter: 1821 loss: 0.0010805421
Iter: 1822 loss: 0.00107974559
Iter: 1823 loss: 0.00107971148
Iter: 1824 loss: 0.00107970322
Iter: 1825 loss: 0.00107966783
Iter: 1826 loss: 0.00107964769
Iter: 1827 loss: 0.00107964012
Iter: 1828 loss: 0.00107957784
Iter: 1829 loss: 0.00107948249
Iter: 1830 loss: 0.00108122511
Iter: 1831 loss: 0.00107948144
Iter: 1832 loss: 0.00107940426
Iter: 1833 loss: 0.00107930205
Iter: 1834 loss: 0.00107928738
Iter: 1835 loss: 0.00113904197
Iter: 1836 loss: 0.00107926177
Iter: 1837 loss: 0.00107912929
Iter: 1838 loss: 0.00107904198
Iter: 1839 loss: 0.00107952
Iter: 1840 loss: 0.00107903127
Iter: 1841 loss: 0.00107897935
Iter: 1842 loss: 0.00107910729
Iter: 1843 loss: 0.00107897189
Iter: 1844 loss: 0.00107887015
Iter: 1845 loss: 0.00107858435
Iter: 1846 loss: 0.00108030264
Iter: 1847 loss: 0.0010784748
Iter: 1848 loss: 0.0010792691
Iter: 1849 loss: 0.00107833685
Iter: 1850 loss: 0.00107802381
Iter: 1851 loss: 0.00107803277
Iter: 1852 loss: 0.00107728783
Iter: 1853 loss: 0.00108093815
Iter: 1854 loss: 0.00107708131
Iter: 1855 loss: 0.00107634487
Iter: 1856 loss: 0.00108106865
Iter: 1857 loss: 0.00107624312
Iter: 1858 loss: 0.00107572577
Iter: 1859 loss: 0.001078289
Iter: 1860 loss: 0.0010755955
Iter: 1861 loss: 0.00107551133
Iter: 1862 loss: 0.00107551378
Iter: 1863 loss: 0.00107549538
Iter: 1864 loss: 0.00107549841
Iter: 1865 loss: 0.00107547862
Iter: 1866 loss: 0.00107544125
Iter: 1867 loss: 0.0010758756
Iter: 1868 loss: 0.00107542612
Iter: 1869 loss: 0.00107533298
Iter: 1870 loss: 0.00107516046
Iter: 1871 loss: 0.00107679027
Iter: 1872 loss: 0.00107503729
Iter: 1873 loss: 0.0010748324
Iter: 1874 loss: 0.00107734604
Iter: 1875 loss: 0.00107480423
Iter: 1876 loss: 0.00107467477
Iter: 1877 loss: 0.00107482797
Iter: 1878 loss: 0.00107459759
Iter: 1879 loss: 0.001074353
Iter: 1880 loss: 0.00107644883
Iter: 1881 loss: 0.00107431854
Iter: 1882 loss: 0.0010742445
Iter: 1883 loss: 0.00107287406
Iter: 1884 loss: 0.0010724403
Iter: 1885 loss: 0.00107236218
Iter: 1886 loss: 0.00107228151
Iter: 1887 loss: 0.00107255054
Iter: 1888 loss: 0.00107225135
Iter: 1889 loss: 0.00107216276
Iter: 1890 loss: 0.00107191992
Iter: 1891 loss: 0.00107294286
Iter: 1892 loss: 0.00107184111
Iter: 1893 loss: 0.00107167102
Iter: 1894 loss: 0.00107197254
Iter: 1895 loss: 0.00107160548
Iter: 1896 loss: 0.00107145193
Iter: 1897 loss: 0.00107185589
Iter: 1898 loss: 0.00107140141
Iter: 1899 loss: 0.00107461773
Iter: 1900 loss: 0.00107134692
Iter: 1901 loss: 0.0196203515
Iter: 1902 loss: 0.00107133586
Iter: 1903 loss: 0.00107128103
Iter: 1904 loss: 0.00107208
Iter: 1905 loss: 0.00107127451
Iter: 1906 loss: 0.00107124366
Iter: 1907 loss: 0.00107123912
Iter: 1908 loss: 0.00107123074
Iter: 1909 loss: 0.0010712418
Iter: 1910 loss: 0.00107121281
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.4/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.8 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.8
+ date
Sat Nov  7 22:12:03 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.4/300_100_100_100_1 --function f1 --psi 0 --phi 2.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.8/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846bce400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846b6d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846b2dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846ac2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846a61ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846a61048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846a167b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78469c5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78469c5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846a22f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846a222f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846964f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78469768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f784693d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f784694c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846a44d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846892d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f784690fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7846a57950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f784690f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78467fd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78468ca268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78467fdd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7825346c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7825346f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78252ecea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f782527bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78252ec2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7825217158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78252330d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f782521b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78252b5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78252b5510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7825290ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f780022b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f78001c7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.047592256
test_loss: 0.047936596
train_loss: 0.022825208
test_loss: 0.023085333
train_loss: 0.013578207
test_loss: 0.012280903
train_loss: 0.010181904
test_loss: 0.010781767
train_loss: 0.011166247
test_loss: 0.010113215
train_loss: 0.007519086
test_loss: 0.008307191
train_loss: 0.0071975123
test_loss: 0.007742084
train_loss: 0.0066228504
test_loss: 0.0062765796
train_loss: 0.007121714
test_loss: 0.007642834
train_loss: 0.006173672
test_loss: 0.006341405
train_loss: 0.005211071
test_loss: 0.005766009
train_loss: 0.006001175
test_loss: 0.005986358
train_loss: 0.005269501
test_loss: 0.005875978
train_loss: 0.006975005
test_loss: 0.0060274913
train_loss: 0.006041993
test_loss: 0.0050655566
train_loss: 0.004615495
test_loss: 0.0044075893
train_loss: 0.004173333
test_loss: 0.0046612523
train_loss: 0.0045304825
test_loss: 0.0055053825
train_loss: 0.0046237702
test_loss: 0.0047242483
train_loss: 0.0048998613
test_loss: 0.004579559
train_loss: 0.0045956494
test_loss: 0.0051959264
train_loss: 0.0061768154
test_loss: 0.0054641026
train_loss: 0.0050842664
test_loss: 0.004566211
train_loss: 0.0041071987
test_loss: 0.004449923
train_loss: 0.00436535
test_loss: 0.004435648
train_loss: 0.0046844343
test_loss: 0.004381243
train_loss: 0.004032065
test_loss: 0.0049347035
train_loss: 0.0042423774
test_loss: 0.005124712
train_loss: 0.0046427827
test_loss: 0.0048856856
train_loss: 0.0036380887
test_loss: 0.0043593883
train_loss: 0.0038284527
test_loss: 0.004287854
train_loss: 0.00403192
test_loss: 0.004243472
train_loss: 0.005837184
test_loss: 0.004893019
train_loss: 0.0033448804
test_loss: 0.0039090617
train_loss: 0.0038939225
test_loss: 0.0044735754
train_loss: 0.0038408106
test_loss: 0.0044325483
train_loss: 0.003642755
test_loss: 0.0035016742
train_loss: 0.0039564245
test_loss: 0.004102821
train_loss: 0.0038093012
test_loss: 0.004344311
train_loss: 0.0036053252
test_loss: 0.0036056407
train_loss: 0.005056571
test_loss: 0.0048396783
train_loss: 0.004136706
test_loss: 0.0035713785
train_loss: 0.0040629944
test_loss: 0.0042506135
train_loss: 0.0042206943
test_loss: 0.004227097
train_loss: 0.003610968
test_loss: 0.0044907797
train_loss: 0.003609755
test_loss: 0.0037022326
train_loss: 0.0034076616
test_loss: 0.0039405865
train_loss: 0.0038637493
test_loss: 0.0039482373
train_loss: 0.0039400924
test_loss: 0.0036954316
train_loss: 0.0031721918
test_loss: 0.0031136086
train_loss: 0.0036397185
test_loss: 0.003770638
train_loss: 0.0033250558
test_loss: 0.003362983
train_loss: 0.0033800236
test_loss: 0.0035183823
train_loss: 0.002853339
test_loss: 0.0029061367
train_loss: 0.0028620972
test_loss: 0.0036388305
train_loss: 0.003322922
test_loss: 0.0039776857
train_loss: 0.003647922
test_loss: 0.0030715577
train_loss: 0.003929703
test_loss: 0.0034404031
train_loss: 0.0033831466
test_loss: 0.0035439346
train_loss: 0.0031117583
test_loss: 0.004048595
train_loss: 0.0031683738
test_loss: 0.0036126298
train_loss: 0.0027788463
test_loss: 0.0028302225
train_loss: 0.0031808142
test_loss: 0.003076509
train_loss: 0.0047977604
test_loss: 0.0035089802
train_loss: 0.0037148232
test_loss: 0.0033369137
train_loss: 0.0042107147
test_loss: 0.003516406
train_loss: 0.0036527803
test_loss: 0.003194969
train_loss: 0.003941558
test_loss: 0.0045493827
train_loss: 0.0031563607
test_loss: 0.0031107522
train_loss: 0.0037876961
test_loss: 0.0044445014
train_loss: 0.0038598112
test_loss: 0.004088121
train_loss: 0.0036887913
test_loss: 0.0029855762
train_loss: 0.0033305949
test_loss: 0.0032054414
train_loss: 0.0030163117
test_loss: 0.0034235865
train_loss: 0.003009859
test_loss: 0.0033417987
train_loss: 0.0032518394
test_loss: 0.0033321897
train_loss: 0.0035926437
test_loss: 0.004045157
train_loss: 0.0032723066
test_loss: 0.0031282632
train_loss: 0.003922815
test_loss: 0.003480685
train_loss: 0.00300437
test_loss: 0.0032702612
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.8/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi2.8/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e690400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e64f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e5dbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e6c67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e6c6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e6c6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e5b5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e500ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e51bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e4ce158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e4ce9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e49bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e4add90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e45d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e4190d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e420c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e471f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e471ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e389bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e3669d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e3660d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e2fa268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e366a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e2c3c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e2c3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e2b0ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37445c4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f379e2b02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f374457c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37445b60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37445ae400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3744567158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3744567510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f374454fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37444d31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37444f5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.75097248e-05
Iter: 2 loss: 0.000214171741
Iter: 3 loss: 1.29080408e-05
Iter: 4 loss: 1.00044635e-05
Iter: 5 loss: 1.25158567e-05
Iter: 6 loss: 8.30020872e-06
Iter: 7 loss: 7.25239715e-06
Iter: 8 loss: 7.82705047e-06
Iter: 9 loss: 6.56483644e-06
Iter: 10 loss: 5.46903266e-06
Iter: 11 loss: 7.92843639e-06
Iter: 12 loss: 5.05403705e-06
Iter: 13 loss: 4.54434394e-06
Iter: 14 loss: 6.36088407e-06
Iter: 15 loss: 4.41402972e-06
Iter: 16 loss: 4.06337e-06
Iter: 17 loss: 4.95850463e-06
Iter: 18 loss: 3.94249946e-06
Iter: 19 loss: 3.69862528e-06
Iter: 20 loss: 5.71654618e-06
Iter: 21 loss: 3.68371548e-06
Iter: 22 loss: 3.52608345e-06
Iter: 23 loss: 3.657658e-06
Iter: 24 loss: 3.43235638e-06
Iter: 25 loss: 3.24896428e-06
Iter: 26 loss: 3.47426931e-06
Iter: 27 loss: 3.15327111e-06
Iter: 28 loss: 3.01208115e-06
Iter: 29 loss: 4.33104833e-06
Iter: 30 loss: 3.0063552e-06
Iter: 31 loss: 2.9212797e-06
Iter: 32 loss: 3.2034925e-06
Iter: 33 loss: 2.89791024e-06
Iter: 34 loss: 2.85549208e-06
Iter: 35 loss: 2.8553568e-06
Iter: 36 loss: 2.8303316e-06
Iter: 37 loss: 2.82927726e-06
Iter: 38 loss: 2.81634175e-06
Iter: 39 loss: 2.77697882e-06
Iter: 40 loss: 2.88173101e-06
Iter: 41 loss: 2.75540333e-06
Iter: 42 loss: 2.70672626e-06
Iter: 43 loss: 3.18546222e-06
Iter: 44 loss: 2.70510895e-06
Iter: 45 loss: 2.67624227e-06
Iter: 46 loss: 2.78133e-06
Iter: 47 loss: 2.66877055e-06
Iter: 48 loss: 2.64051914e-06
Iter: 49 loss: 2.59801936e-06
Iter: 50 loss: 2.59734e-06
Iter: 51 loss: 2.55379155e-06
Iter: 52 loss: 2.92792652e-06
Iter: 53 loss: 2.5513641e-06
Iter: 54 loss: 2.51297502e-06
Iter: 55 loss: 2.58346608e-06
Iter: 56 loss: 2.49689e-06
Iter: 57 loss: 2.4658334e-06
Iter: 58 loss: 2.63191441e-06
Iter: 59 loss: 2.46128e-06
Iter: 60 loss: 2.4292267e-06
Iter: 61 loss: 2.42474061e-06
Iter: 62 loss: 2.40205e-06
Iter: 63 loss: 2.36939923e-06
Iter: 64 loss: 2.6383716e-06
Iter: 65 loss: 2.36747633e-06
Iter: 66 loss: 2.34330901e-06
Iter: 67 loss: 2.35948028e-06
Iter: 68 loss: 2.32812135e-06
Iter: 69 loss: 2.33011201e-06
Iter: 70 loss: 2.31901322e-06
Iter: 71 loss: 2.30847513e-06
Iter: 72 loss: 2.32653838e-06
Iter: 73 loss: 2.30387036e-06
Iter: 74 loss: 2.2978e-06
Iter: 75 loss: 2.28066574e-06
Iter: 76 loss: 2.34984236e-06
Iter: 77 loss: 2.27363216e-06
Iter: 78 loss: 2.25977101e-06
Iter: 79 loss: 2.25966346e-06
Iter: 80 loss: 2.24668406e-06
Iter: 81 loss: 2.24515225e-06
Iter: 82 loss: 2.23582924e-06
Iter: 83 loss: 2.21882556e-06
Iter: 84 loss: 2.27898454e-06
Iter: 85 loss: 2.21451887e-06
Iter: 86 loss: 2.20252582e-06
Iter: 87 loss: 2.22100562e-06
Iter: 88 loss: 2.19682693e-06
Iter: 89 loss: 2.18263449e-06
Iter: 90 loss: 2.20609354e-06
Iter: 91 loss: 2.17623938e-06
Iter: 92 loss: 2.16236913e-06
Iter: 93 loss: 2.24696805e-06
Iter: 94 loss: 2.16054832e-06
Iter: 95 loss: 2.14962301e-06
Iter: 96 loss: 2.18423656e-06
Iter: 97 loss: 2.14656779e-06
Iter: 98 loss: 2.13524709e-06
Iter: 99 loss: 2.13952967e-06
Iter: 100 loss: 2.12738905e-06
Iter: 101 loss: 2.11650945e-06
Iter: 102 loss: 2.19050708e-06
Iter: 103 loss: 2.11555061e-06
Iter: 104 loss: 2.1128044e-06
Iter: 105 loss: 2.10988719e-06
Iter: 106 loss: 2.10607232e-06
Iter: 107 loss: 2.09490281e-06
Iter: 108 loss: 2.1332994e-06
Iter: 109 loss: 2.09017e-06
Iter: 110 loss: 2.08136294e-06
Iter: 111 loss: 2.09773543e-06
Iter: 112 loss: 2.07761741e-06
Iter: 113 loss: 2.06754612e-06
Iter: 114 loss: 2.13711564e-06
Iter: 115 loss: 2.06648792e-06
Iter: 116 loss: 2.05920605e-06
Iter: 117 loss: 2.10268786e-06
Iter: 118 loss: 2.05865445e-06
Iter: 119 loss: 2.05405217e-06
Iter: 120 loss: 2.04516232e-06
Iter: 121 loss: 2.21606138e-06
Iter: 122 loss: 2.04503954e-06
Iter: 123 loss: 2.03322907e-06
Iter: 124 loss: 2.11124598e-06
Iter: 125 loss: 2.03218769e-06
Iter: 126 loss: 2.02422916e-06
Iter: 127 loss: 2.0307898e-06
Iter: 128 loss: 2.01963621e-06
Iter: 129 loss: 2.00935165e-06
Iter: 130 loss: 2.06049e-06
Iter: 131 loss: 2.00760087e-06
Iter: 132 loss: 1.99955662e-06
Iter: 133 loss: 2.02778e-06
Iter: 134 loss: 1.99757369e-06
Iter: 135 loss: 1.98872067e-06
Iter: 136 loss: 1.9872241e-06
Iter: 137 loss: 1.98111366e-06
Iter: 138 loss: 1.98685098e-06
Iter: 139 loss: 1.97767099e-06
Iter: 140 loss: 1.97352529e-06
Iter: 141 loss: 1.96938845e-06
Iter: 142 loss: 1.96855603e-06
Iter: 143 loss: 1.9649226e-06
Iter: 144 loss: 1.95746725e-06
Iter: 145 loss: 2.09483028e-06
Iter: 146 loss: 1.95737e-06
Iter: 147 loss: 1.9492295e-06
Iter: 148 loss: 1.98801399e-06
Iter: 149 loss: 1.94759741e-06
Iter: 150 loss: 1.94208178e-06
Iter: 151 loss: 2.00118939e-06
Iter: 152 loss: 1.94178142e-06
Iter: 153 loss: 1.93773781e-06
Iter: 154 loss: 1.94543304e-06
Iter: 155 loss: 1.93587857e-06
Iter: 156 loss: 1.93195388e-06
Iter: 157 loss: 1.93459e-06
Iter: 158 loss: 1.92945549e-06
Iter: 159 loss: 1.9248323e-06
Iter: 160 loss: 1.92703669e-06
Iter: 161 loss: 1.92170864e-06
Iter: 162 loss: 1.91550362e-06
Iter: 163 loss: 1.94711834e-06
Iter: 164 loss: 1.91440085e-06
Iter: 165 loss: 1.91007371e-06
Iter: 166 loss: 1.93183746e-06
Iter: 167 loss: 1.9094939e-06
Iter: 168 loss: 1.90527089e-06
Iter: 169 loss: 1.90876335e-06
Iter: 170 loss: 1.90263893e-06
Iter: 171 loss: 1.89913112e-06
Iter: 172 loss: 1.93901906e-06
Iter: 173 loss: 1.89893717e-06
Iter: 174 loss: 1.89656987e-06
Iter: 175 loss: 1.89646323e-06
Iter: 176 loss: 1.89505727e-06
Iter: 177 loss: 1.89133539e-06
Iter: 178 loss: 1.90827905e-06
Iter: 179 loss: 1.88986928e-06
Iter: 180 loss: 1.8865984e-06
Iter: 181 loss: 1.88808008e-06
Iter: 182 loss: 1.8841647e-06
Iter: 183 loss: 1.8791327e-06
Iter: 184 loss: 1.90394962e-06
Iter: 185 loss: 1.87817102e-06
Iter: 186 loss: 1.87499154e-06
Iter: 187 loss: 1.9085187e-06
Iter: 188 loss: 1.87497812e-06
Iter: 189 loss: 1.8715898e-06
Iter: 190 loss: 1.8670828e-06
Iter: 191 loss: 1.8668552e-06
Iter: 192 loss: 1.86293391e-06
Iter: 193 loss: 1.89054572e-06
Iter: 194 loss: 1.86245177e-06
Iter: 195 loss: 1.85920715e-06
Iter: 196 loss: 1.8642362e-06
Iter: 197 loss: 1.85754357e-06
Iter: 198 loss: 1.85408442e-06
Iter: 199 loss: 1.86757404e-06
Iter: 200 loss: 1.85311399e-06
Iter: 201 loss: 1.84945679e-06
Iter: 202 loss: 1.85397778e-06
Iter: 203 loss: 1.84767646e-06
Iter: 204 loss: 1.84411022e-06
Iter: 205 loss: 1.87533419e-06
Iter: 206 loss: 1.84370492e-06
Iter: 207 loss: 1.84406667e-06
Iter: 208 loss: 1.84280645e-06
Iter: 209 loss: 1.84189139e-06
Iter: 210 loss: 1.83940574e-06
Iter: 211 loss: 1.86346074e-06
Iter: 212 loss: 1.83909458e-06
Iter: 213 loss: 1.83697443e-06
Iter: 214 loss: 1.83426869e-06
Iter: 215 loss: 1.83410498e-06
Iter: 216 loss: 1.83025668e-06
Iter: 217 loss: 1.85805709e-06
Iter: 218 loss: 1.82983308e-06
Iter: 219 loss: 1.82773624e-06
Iter: 220 loss: 1.83514e-06
Iter: 221 loss: 1.82701228e-06
Iter: 222 loss: 1.82409804e-06
Iter: 223 loss: 1.83420934e-06
Iter: 224 loss: 1.82338238e-06
Iter: 225 loss: 1.82116753e-06
Iter: 226 loss: 1.82318399e-06
Iter: 227 loss: 1.81980045e-06
Iter: 228 loss: 1.81717814e-06
Iter: 229 loss: 1.81707446e-06
Iter: 230 loss: 1.81495898e-06
Iter: 231 loss: 1.81168571e-06
Iter: 232 loss: 1.83709062e-06
Iter: 233 loss: 1.81133305e-06
Iter: 234 loss: 1.80892971e-06
Iter: 235 loss: 1.8085633e-06
Iter: 236 loss: 1.80680559e-06
Iter: 237 loss: 1.80364782e-06
Iter: 238 loss: 1.83974976e-06
Iter: 239 loss: 1.80369204e-06
Iter: 240 loss: 1.80286463e-06
Iter: 241 loss: 1.80274253e-06
Iter: 242 loss: 1.80151233e-06
Iter: 243 loss: 1.79969948e-06
Iter: 244 loss: 1.79969231e-06
Iter: 245 loss: 1.79773417e-06
Iter: 246 loss: 1.79661663e-06
Iter: 247 loss: 1.79593371e-06
Iter: 248 loss: 1.79364542e-06
Iter: 249 loss: 1.79570839e-06
Iter: 250 loss: 1.7925131e-06
Iter: 251 loss: 1.78939308e-06
Iter: 252 loss: 1.79591621e-06
Iter: 253 loss: 1.7882461e-06
Iter: 254 loss: 1.78606206e-06
Iter: 255 loss: 1.78607536e-06
Iter: 256 loss: 1.78452444e-06
Iter: 257 loss: 1.78477489e-06
Iter: 258 loss: 1.78316043e-06
Iter: 259 loss: 1.78102619e-06
Iter: 260 loss: 1.78298114e-06
Iter: 261 loss: 1.77965353e-06
Iter: 262 loss: 1.77688878e-06
Iter: 263 loss: 1.78059349e-06
Iter: 264 loss: 1.77540585e-06
Iter: 265 loss: 1.7726768e-06
Iter: 266 loss: 1.78143409e-06
Iter: 267 loss: 1.77189895e-06
Iter: 268 loss: 1.76913784e-06
Iter: 269 loss: 1.78128744e-06
Iter: 270 loss: 1.76844765e-06
Iter: 271 loss: 1.76650224e-06
Iter: 272 loss: 1.78029757e-06
Iter: 273 loss: 1.766266e-06
Iter: 274 loss: 1.76470428e-06
Iter: 275 loss: 1.76445451e-06
Iter: 276 loss: 1.76420292e-06
Iter: 277 loss: 1.7630241e-06
Iter: 278 loss: 1.77685024e-06
Iter: 279 loss: 1.76281947e-06
Iter: 280 loss: 1.76181629e-06
Iter: 281 loss: 1.76101253e-06
Iter: 282 loss: 1.7606535e-06
Iter: 283 loss: 1.75857747e-06
Iter: 284 loss: 1.76647609e-06
Iter: 285 loss: 1.75806531e-06
Iter: 286 loss: 1.75631271e-06
Iter: 287 loss: 1.75877369e-06
Iter: 288 loss: 1.75564287e-06
Iter: 289 loss: 1.75375601e-06
Iter: 290 loss: 1.77608047e-06
Iter: 291 loss: 1.75379023e-06
Iter: 292 loss: 1.75267223e-06
Iter: 293 loss: 1.75278058e-06
Iter: 294 loss: 1.75169771e-06
Iter: 295 loss: 1.74991578e-06
Iter: 296 loss: 1.74920524e-06
Iter: 297 loss: 1.74842557e-06
Iter: 298 loss: 1.74600041e-06
Iter: 299 loss: 1.76035564e-06
Iter: 300 loss: 1.74557294e-06
Iter: 301 loss: 1.74326863e-06
Iter: 302 loss: 1.74278193e-06
Iter: 303 loss: 1.74127e-06
Iter: 304 loss: 1.73884769e-06
Iter: 305 loss: 1.77296477e-06
Iter: 306 loss: 1.73888384e-06
Iter: 307 loss: 1.73932403e-06
Iter: 308 loss: 1.73829278e-06
Iter: 309 loss: 1.73760145e-06
Iter: 310 loss: 1.73579065e-06
Iter: 311 loss: 1.73836e-06
Iter: 312 loss: 1.73450746e-06
Iter: 313 loss: 1.73256785e-06
Iter: 314 loss: 1.74147965e-06
Iter: 315 loss: 1.73215744e-06
Iter: 316 loss: 1.73054536e-06
Iter: 317 loss: 1.73622288e-06
Iter: 318 loss: 1.73014973e-06
Iter: 319 loss: 1.72852253e-06
Iter: 320 loss: 1.72876094e-06
Iter: 321 loss: 1.72741966e-06
Iter: 322 loss: 1.7256292e-06
Iter: 323 loss: 1.7422617e-06
Iter: 324 loss: 1.72577688e-06
Iter: 325 loss: 1.72436796e-06
Iter: 326 loss: 1.73174351e-06
Iter: 327 loss: 1.7242445e-06
Iter: 328 loss: 1.72290515e-06
Iter: 329 loss: 1.72166199e-06
Iter: 330 loss: 1.7215001e-06
Iter: 331 loss: 1.7198015e-06
Iter: 332 loss: 1.73280591e-06
Iter: 333 loss: 1.71965723e-06
Iter: 334 loss: 1.71838599e-06
Iter: 335 loss: 1.71657985e-06
Iter: 336 loss: 1.71646457e-06
Iter: 337 loss: 1.71420231e-06
Iter: 338 loss: 1.73859382e-06
Iter: 339 loss: 1.71401302e-06
Iter: 340 loss: 1.71267641e-06
Iter: 341 loss: 1.72265493e-06
Iter: 342 loss: 1.71263196e-06
Iter: 343 loss: 1.71084412e-06
Iter: 344 loss: 1.72267073e-06
Iter: 345 loss: 1.7108373e-06
Iter: 346 loss: 1.7103855e-06
Iter: 347 loss: 1.7090664e-06
Iter: 348 loss: 1.71537658e-06
Iter: 349 loss: 1.70882e-06
Iter: 350 loss: 1.70665055e-06
Iter: 351 loss: 1.70671501e-06
Iter: 352 loss: 1.70502051e-06
Iter: 353 loss: 1.70346095e-06
Iter: 354 loss: 1.70323108e-06
Iter: 355 loss: 1.70212695e-06
Iter: 356 loss: 1.7008158e-06
Iter: 357 loss: 1.70067688e-06
Iter: 358 loss: 1.69840496e-06
Iter: 359 loss: 1.71630552e-06
Iter: 360 loss: 1.69859743e-06
Iter: 361 loss: 1.69719226e-06
Iter: 362 loss: 1.70589453e-06
Iter: 363 loss: 1.69690657e-06
Iter: 364 loss: 1.69582677e-06
Iter: 365 loss: 1.69557961e-06
Iter: 366 loss: 1.69465159e-06
Iter: 367 loss: 1.69325097e-06
Iter: 368 loss: 1.69438147e-06
Iter: 369 loss: 1.69246221e-06
Iter: 370 loss: 1.69080272e-06
Iter: 371 loss: 1.69505927e-06
Iter: 372 loss: 1.68998395e-06
Iter: 373 loss: 1.68842553e-06
Iter: 374 loss: 1.69844748e-06
Iter: 375 loss: 1.68816734e-06
Iter: 376 loss: 1.68878182e-06
Iter: 377 loss: 1.68778035e-06
Iter: 378 loss: 1.68736847e-06
Iter: 379 loss: 1.68619442e-06
Iter: 380 loss: 1.69243697e-06
Iter: 381 loss: 1.68582778e-06
Iter: 382 loss: 1.68495103e-06
Iter: 383 loss: 1.68548024e-06
Iter: 384 loss: 1.68439067e-06
Iter: 385 loss: 1.6832455e-06
Iter: 386 loss: 1.68611746e-06
Iter: 387 loss: 1.68298493e-06
Iter: 388 loss: 1.68160977e-06
Iter: 389 loss: 1.68467943e-06
Iter: 390 loss: 1.68122176e-06
Iter: 391 loss: 1.68017618e-06
Iter: 392 loss: 1.68561144e-06
Iter: 393 loss: 1.6797419e-06
Iter: 394 loss: 1.67881058e-06
Iter: 395 loss: 1.68022939e-06
Iter: 396 loss: 1.67809378e-06
Iter: 397 loss: 1.67686119e-06
Iter: 398 loss: 1.68611825e-06
Iter: 399 loss: 1.67665053e-06
Iter: 400 loss: 1.67576286e-06
Iter: 401 loss: 1.67686449e-06
Iter: 402 loss: 1.67503799e-06
Iter: 403 loss: 1.67400617e-06
Iter: 404 loss: 1.67393318e-06
Iter: 405 loss: 1.67287317e-06
Iter: 406 loss: 1.67180087e-06
Iter: 407 loss: 1.67384246e-06
Iter: 408 loss: 1.67112046e-06
Iter: 409 loss: 1.67007488e-06
Iter: 410 loss: 1.68442534e-06
Iter: 411 loss: 1.66987888e-06
Iter: 412 loss: 1.67039707e-06
Iter: 413 loss: 1.66975587e-06
Iter: 414 loss: 1.66960558e-06
Iter: 415 loss: 1.66896041e-06
Iter: 416 loss: 1.66818484e-06
Iter: 417 loss: 1.66787504e-06
Iter: 418 loss: 1.66650921e-06
Iter: 419 loss: 1.67344592e-06
Iter: 420 loss: 1.66625489e-06
Iter: 421 loss: 1.66522398e-06
Iter: 422 loss: 1.6652516e-06
Iter: 423 loss: 1.66438429e-06
Iter: 424 loss: 1.66285713e-06
Iter: 425 loss: 1.67250766e-06
Iter: 426 loss: 1.66273458e-06
Iter: 427 loss: 1.66188499e-06
Iter: 428 loss: 1.66232076e-06
Iter: 429 loss: 1.66119185e-06
Iter: 430 loss: 1.65999836e-06
Iter: 431 loss: 1.66684572e-06
Iter: 432 loss: 1.65995175e-06
Iter: 433 loss: 1.65915742e-06
Iter: 434 loss: 1.66569839e-06
Iter: 435 loss: 1.6591523e-06
Iter: 436 loss: 1.65851054e-06
Iter: 437 loss: 1.65766539e-06
Iter: 438 loss: 1.65745769e-06
Iter: 439 loss: 1.65645133e-06
Iter: 440 loss: 1.66024597e-06
Iter: 441 loss: 1.65616905e-06
Iter: 442 loss: 1.65524966e-06
Iter: 443 loss: 1.65918721e-06
Iter: 444 loss: 1.6550589e-06
Iter: 445 loss: 1.65424308e-06
Iter: 446 loss: 1.65485562e-06
Iter: 447 loss: 1.65382721e-06
Iter: 448 loss: 1.65285189e-06
Iter: 449 loss: 1.65288088e-06
Iter: 450 loss: 1.65253346e-06
Iter: 451 loss: 1.65183314e-06
Iter: 452 loss: 1.652695e-06
Iter: 453 loss: 1.6512746e-06
Iter: 454 loss: 1.65022834e-06
Iter: 455 loss: 1.65692006e-06
Iter: 456 loss: 1.65000904e-06
Iter: 457 loss: 1.64928713e-06
Iter: 458 loss: 1.64826793e-06
Iter: 459 loss: 1.64820381e-06
Iter: 460 loss: 1.64676362e-06
Iter: 461 loss: 1.66168968e-06
Iter: 462 loss: 1.64685548e-06
Iter: 463 loss: 1.64590699e-06
Iter: 464 loss: 1.64725282e-06
Iter: 465 loss: 1.64558435e-06
Iter: 466 loss: 1.64476069e-06
Iter: 467 loss: 1.64732205e-06
Iter: 468 loss: 1.64457356e-06
Iter: 469 loss: 1.6437059e-06
Iter: 470 loss: 1.64534595e-06
Iter: 471 loss: 1.64322216e-06
Iter: 472 loss: 1.64231892e-06
Iter: 473 loss: 1.64805226e-06
Iter: 474 loss: 1.64230642e-06
Iter: 475 loss: 1.64152584e-06
Iter: 476 loss: 1.64068717e-06
Iter: 477 loss: 1.64051733e-06
Iter: 478 loss: 1.63933441e-06
Iter: 479 loss: 1.63927e-06
Iter: 480 loss: 1.63975369e-06
Iter: 481 loss: 1.63900108e-06
Iter: 482 loss: 1.63879918e-06
Iter: 483 loss: 1.63828304e-06
Iter: 484 loss: 1.64075766e-06
Iter: 485 loss: 1.63818254e-06
Iter: 486 loss: 1.63740151e-06
Iter: 487 loss: 1.63773268e-06
Iter: 488 loss: 1.63697837e-06
Iter: 489 loss: 1.63607342e-06
Iter: 490 loss: 1.63907328e-06
Iter: 491 loss: 1.63580239e-06
Iter: 492 loss: 1.63469076e-06
Iter: 493 loss: 1.63508764e-06
Iter: 494 loss: 1.63401103e-06
Iter: 495 loss: 1.63302866e-06
Iter: 496 loss: 1.64430935e-06
Iter: 497 loss: 1.63296806e-06
Iter: 498 loss: 1.63217601e-06
Iter: 499 loss: 1.63125583e-06
Iter: 500 loss: 1.631229e-06
Iter: 501 loss: 1.62984475e-06
Iter: 502 loss: 1.64148173e-06
Iter: 503 loss: 1.62976664e-06
Iter: 504 loss: 1.62883134e-06
Iter: 505 loss: 1.6346039e-06
Iter: 506 loss: 1.62866377e-06
Iter: 507 loss: 1.62762558e-06
Iter: 508 loss: 1.63125355e-06
Iter: 509 loss: 1.62762262e-06
Iter: 510 loss: 1.62686422e-06
Iter: 511 loss: 1.62723302e-06
Iter: 512 loss: 1.62660228e-06
Iter: 513 loss: 1.62610809e-06
Iter: 514 loss: 1.62607284e-06
Iter: 515 loss: 1.62549577e-06
Iter: 516 loss: 1.62544211e-06
Iter: 517 loss: 1.62504261e-06
Iter: 518 loss: 1.62476499e-06
Iter: 519 loss: 1.624118e-06
Iter: 520 loss: 1.6388326e-06
Iter: 521 loss: 1.62385561e-06
Iter: 522 loss: 1.62309129e-06
Iter: 523 loss: 1.62549418e-06
Iter: 524 loss: 1.62269066e-06
Iter: 525 loss: 1.6218861e-06
Iter: 526 loss: 1.62673473e-06
Iter: 527 loss: 1.62195249e-06
Iter: 528 loss: 1.62121535e-06
Iter: 529 loss: 1.62033245e-06
Iter: 530 loss: 1.62023821e-06
Iter: 531 loss: 1.61926823e-06
Iter: 532 loss: 1.63164532e-06
Iter: 533 loss: 1.61910793e-06
Iter: 534 loss: 1.61836715e-06
Iter: 535 loss: 1.61688922e-06
Iter: 536 loss: 1.61684648e-06
Iter: 537 loss: 1.61546609e-06
Iter: 538 loss: 1.63005006e-06
Iter: 539 loss: 1.61546166e-06
Iter: 540 loss: 1.61445018e-06
Iter: 541 loss: 1.6189457e-06
Iter: 542 loss: 1.61409298e-06
Iter: 543 loss: 1.61294099e-06
Iter: 544 loss: 1.61807964e-06
Iter: 545 loss: 1.61269122e-06
Iter: 546 loss: 1.61181424e-06
Iter: 547 loss: 1.61204503e-06
Iter: 548 loss: 1.61132721e-06
Iter: 549 loss: 1.61087371e-06
Iter: 550 loss: 1.61059404e-06
Iter: 551 loss: 1.61034e-06
Iter: 552 loss: 1.60940749e-06
Iter: 553 loss: 1.6176997e-06
Iter: 554 loss: 1.60913828e-06
Iter: 555 loss: 1.60840136e-06
Iter: 556 loss: 1.6095828e-06
Iter: 557 loss: 1.60780007e-06
Iter: 558 loss: 1.6069082e-06
Iter: 559 loss: 1.60658851e-06
Iter: 560 loss: 1.60563172e-06
Iter: 561 loss: 1.60436969e-06
Iter: 562 loss: 1.61067226e-06
Iter: 563 loss: 1.60413742e-06
Iter: 564 loss: 1.60288e-06
Iter: 565 loss: 1.60551235e-06
Iter: 566 loss: 1.60244758e-06
Iter: 567 loss: 1.60134618e-06
Iter: 568 loss: 1.6086949e-06
Iter: 569 loss: 1.60121158e-06
Iter: 570 loss: 1.60043078e-06
Iter: 571 loss: 1.60237801e-06
Iter: 572 loss: 1.60015759e-06
Iter: 573 loss: 1.59933666e-06
Iter: 574 loss: 1.6007823e-06
Iter: 575 loss: 1.59891238e-06
Iter: 576 loss: 1.598106e-06
Iter: 577 loss: 1.60160425e-06
Iter: 578 loss: 1.59789533e-06
Iter: 579 loss: 1.59718547e-06
Iter: 580 loss: 1.59889214e-06
Iter: 581 loss: 1.59676847e-06
Iter: 582 loss: 1.5968651e-06
Iter: 583 loss: 1.59648107e-06
Iter: 584 loss: 1.59613501e-06
Iter: 585 loss: 1.59625779e-06
Iter: 586 loss: 1.59596584e-06
Iter: 587 loss: 1.59550927e-06
Iter: 588 loss: 1.59461081e-06
Iter: 589 loss: 1.60961258e-06
Iter: 590 loss: 1.59473575e-06
Iter: 591 loss: 1.59369802e-06
Iter: 592 loss: 1.59700289e-06
Iter: 593 loss: 1.59359286e-06
Iter: 594 loss: 1.59275896e-06
Iter: 595 loss: 1.59261435e-06
Iter: 596 loss: 1.59201431e-06
Iter: 597 loss: 1.59128217e-06
Iter: 598 loss: 1.60362299e-06
Iter: 599 loss: 1.5912367e-06
Iter: 600 loss: 1.59062677e-06
Iter: 601 loss: 1.58983244e-06
Iter: 602 loss: 1.58977377e-06
Iter: 603 loss: 1.5887897e-06
Iter: 604 loss: 1.59638466e-06
Iter: 605 loss: 1.58881312e-06
Iter: 606 loss: 1.58808643e-06
Iter: 607 loss: 1.58763089e-06
Iter: 608 loss: 1.58714829e-06
Iter: 609 loss: 1.58611363e-06
Iter: 610 loss: 1.59182855e-06
Iter: 611 loss: 1.58587704e-06
Iter: 612 loss: 1.58521311e-06
Iter: 613 loss: 1.58424382e-06
Iter: 614 loss: 1.58422699e-06
Iter: 615 loss: 1.58361695e-06
Iter: 616 loss: 1.58357182e-06
Iter: 617 loss: 1.58319654e-06
Iter: 618 loss: 1.5844214e-06
Iter: 619 loss: 1.58301873e-06
Iter: 620 loss: 1.58266221e-06
Iter: 621 loss: 1.58336923e-06
Iter: 622 loss: 1.58240186e-06
Iter: 623 loss: 1.58197201e-06
Iter: 624 loss: 1.58128182e-06
Iter: 625 loss: 1.58137743e-06
Iter: 626 loss: 1.5805839e-06
Iter: 627 loss: 1.58294017e-06
Iter: 628 loss: 1.58021135e-06
Iter: 629 loss: 1.57956663e-06
Iter: 630 loss: 1.58011403e-06
Iter: 631 loss: 1.57923523e-06
Iter: 632 loss: 1.57827685e-06
Iter: 633 loss: 1.58230841e-06
Iter: 634 loss: 1.57821671e-06
Iter: 635 loss: 1.57756642e-06
Iter: 636 loss: 1.57939189e-06
Iter: 637 loss: 1.57734394e-06
Iter: 638 loss: 1.57669592e-06
Iter: 639 loss: 1.57750719e-06
Iter: 640 loss: 1.57625755e-06
Iter: 641 loss: 1.57535578e-06
Iter: 642 loss: 1.57793522e-06
Iter: 643 loss: 1.57535953e-06
Iter: 644 loss: 1.57471982e-06
Iter: 645 loss: 1.57554132e-06
Iter: 646 loss: 1.57433431e-06
Iter: 647 loss: 1.57361035e-06
Iter: 648 loss: 1.57644035e-06
Iter: 649 loss: 1.57322484e-06
Iter: 650 loss: 1.57388854e-06
Iter: 651 loss: 1.57314344e-06
Iter: 652 loss: 1.57293414e-06
Iter: 653 loss: 1.57248076e-06
Iter: 654 loss: 1.57537477e-06
Iter: 655 loss: 1.57244529e-06
Iter: 656 loss: 1.57177283e-06
Iter: 657 loss: 1.57326338e-06
Iter: 658 loss: 1.57147315e-06
Iter: 659 loss: 1.57087413e-06
Iter: 660 loss: 1.57211093e-06
Iter: 661 loss: 1.57070303e-06
Iter: 662 loss: 1.57021282e-06
Iter: 663 loss: 1.57000909e-06
Iter: 664 loss: 1.56968656e-06
Iter: 665 loss: 1.56896931e-06
Iter: 666 loss: 1.57471413e-06
Iter: 667 loss: 1.56894225e-06
Iter: 668 loss: 1.56849683e-06
Iter: 669 loss: 1.5679276e-06
Iter: 670 loss: 1.56792885e-06
Iter: 671 loss: 1.56718454e-06
Iter: 672 loss: 1.57606178e-06
Iter: 673 loss: 1.56720102e-06
Iter: 674 loss: 1.56657643e-06
Iter: 675 loss: 1.56630813e-06
Iter: 676 loss: 1.56599458e-06
Iter: 677 loss: 1.56530086e-06
Iter: 678 loss: 1.56964802e-06
Iter: 679 loss: 1.56504007e-06
Iter: 680 loss: 1.56471674e-06
Iter: 681 loss: 1.56668079e-06
Iter: 682 loss: 1.564488e-06
Iter: 683 loss: 1.56398812e-06
Iter: 684 loss: 1.56620797e-06
Iter: 685 loss: 1.56396482e-06
Iter: 686 loss: 1.56373153e-06
Iter: 687 loss: 1.56363149e-06
Iter: 688 loss: 1.56351143e-06
Iter: 689 loss: 1.56317992e-06
Iter: 690 loss: 1.5636042e-06
Iter: 691 loss: 1.5627204e-06
Iter: 692 loss: 1.5621049e-06
Iter: 693 loss: 1.5675439e-06
Iter: 694 loss: 1.56208512e-06
Iter: 695 loss: 1.56155545e-06
Iter: 696 loss: 1.56163549e-06
Iter: 697 loss: 1.56105489e-06
Iter: 698 loss: 1.56067449e-06
Iter: 699 loss: 1.56101714e-06
Iter: 700 loss: 1.56017836e-06
Iter: 701 loss: 1.55939642e-06
Iter: 702 loss: 1.56195233e-06
Iter: 703 loss: 1.55906594e-06
Iter: 704 loss: 1.55841417e-06
Iter: 705 loss: 1.561933e-06
Iter: 706 loss: 1.55840746e-06
Iter: 707 loss: 1.55774819e-06
Iter: 708 loss: 1.56011799e-06
Iter: 709 loss: 1.55758232e-06
Iter: 710 loss: 1.55721932e-06
Iter: 711 loss: 1.5581079e-06
Iter: 712 loss: 1.55695886e-06
Iter: 713 loss: 1.55642488e-06
Iter: 714 loss: 1.55738667e-06
Iter: 715 loss: 1.55633268e-06
Iter: 716 loss: 1.55577459e-06
Iter: 717 loss: 1.55868975e-06
Iter: 718 loss: 1.55571115e-06
Iter: 719 loss: 1.55617886e-06
Iter: 720 loss: 1.5555845e-06
Iter: 721 loss: 1.55537418e-06
Iter: 722 loss: 1.55511111e-06
Iter: 723 loss: 1.55578232e-06
Iter: 724 loss: 1.55477449e-06
Iter: 725 loss: 1.55442603e-06
Iter: 726 loss: 1.55614589e-06
Iter: 727 loss: 1.55417956e-06
Iter: 728 loss: 1.55353132e-06
Iter: 729 loss: 1.55513135e-06
Iter: 730 loss: 1.55360203e-06
Iter: 731 loss: 1.55289763e-06
Iter: 732 loss: 1.55245823e-06
Iter: 733 loss: 1.55254349e-06
Iter: 734 loss: 1.55131431e-06
Iter: 735 loss: 1.55782732e-06
Iter: 736 loss: 1.55151361e-06
Iter: 737 loss: 1.55106204e-06
Iter: 738 loss: 1.55138412e-06
Iter: 739 loss: 1.55094096e-06
Iter: 740 loss: 1.55010889e-06
Iter: 741 loss: 1.55378018e-06
Iter: 742 loss: 1.54997656e-06
Iter: 743 loss: 1.54964152e-06
Iter: 744 loss: 1.55175644e-06
Iter: 745 loss: 1.54949225e-06
Iter: 746 loss: 1.54902705e-06
Iter: 747 loss: 1.54870656e-06
Iter: 748 loss: 1.54851773e-06
Iter: 749 loss: 1.5479211e-06
Iter: 750 loss: 1.54952147e-06
Iter: 751 loss: 1.54767963e-06
Iter: 752 loss: 1.54748057e-06
Iter: 753 loss: 1.54722852e-06
Iter: 754 loss: 1.54712359e-06
Iter: 755 loss: 1.54721693e-06
Iter: 756 loss: 1.54677878e-06
Iter: 757 loss: 1.54661166e-06
Iter: 758 loss: 1.54612644e-06
Iter: 759 loss: 1.54613383e-06
Iter: 760 loss: 1.54581596e-06
Iter: 761 loss: 1.54681788e-06
Iter: 762 loss: 1.54557483e-06
Iter: 763 loss: 1.54510508e-06
Iter: 764 loss: 1.5452913e-06
Iter: 765 loss: 1.54459917e-06
Iter: 766 loss: 1.54391182e-06
Iter: 767 loss: 1.54511827e-06
Iter: 768 loss: 1.54355098e-06
Iter: 769 loss: 1.54315831e-06
Iter: 770 loss: 1.54550617e-06
Iter: 771 loss: 1.54296993e-06
Iter: 772 loss: 1.54239638e-06
Iter: 773 loss: 1.54362908e-06
Iter: 774 loss: 1.54221334e-06
Iter: 775 loss: 1.54172403e-06
Iter: 776 loss: 1.54322356e-06
Iter: 777 loss: 1.54172426e-06
Iter: 778 loss: 1.54102486e-06
Iter: 779 loss: 1.54353859e-06
Iter: 780 loss: 1.54073894e-06
Iter: 781 loss: 1.54029351e-06
Iter: 782 loss: 1.54049417e-06
Iter: 783 loss: 1.53995711e-06
Iter: 784 loss: 1.53923065e-06
Iter: 785 loss: 1.54235192e-06
Iter: 786 loss: 1.53918154e-06
Iter: 787 loss: 1.53975463e-06
Iter: 788 loss: 1.53888368e-06
Iter: 789 loss: 1.53880978e-06
Iter: 790 loss: 1.53840585e-06
Iter: 791 loss: 1.5392485e-06
Iter: 792 loss: 1.53815654e-06
Iter: 793 loss: 1.53764267e-06
Iter: 794 loss: 1.54060046e-06
Iter: 795 loss: 1.5375698e-06
Iter: 796 loss: 1.5370598e-06
Iter: 797 loss: 1.53980204e-06
Iter: 798 loss: 1.53711039e-06
Iter: 799 loss: 1.53683072e-06
Iter: 800 loss: 1.53614849e-06
Iter: 801 loss: 1.53621386e-06
Iter: 802 loss: 1.53546466e-06
Iter: 803 loss: 1.53740461e-06
Iter: 804 loss: 1.53536109e-06
Iter: 805 loss: 1.53469341e-06
Iter: 806 loss: 1.5360489e-06
Iter: 807 loss: 1.53445296e-06
Iter: 808 loss: 1.5339e-06
Iter: 809 loss: 1.53607061e-06
Iter: 810 loss: 1.53381552e-06
Iter: 811 loss: 1.53325277e-06
Iter: 812 loss: 1.53529243e-06
Iter: 813 loss: 1.53317546e-06
Iter: 814 loss: 1.53273686e-06
Iter: 815 loss: 1.53405335e-06
Iter: 816 loss: 1.53255337e-06
Iter: 817 loss: 1.53224141e-06
Iter: 818 loss: 1.53302062e-06
Iter: 819 loss: 1.53184487e-06
Iter: 820 loss: 1.53162046e-06
Iter: 821 loss: 1.5315311e-06
Iter: 822 loss: 1.53114081e-06
Iter: 823 loss: 1.53208111e-06
Iter: 824 loss: 1.53099541e-06
Iter: 825 loss: 1.53076735e-06
Iter: 826 loss: 1.53008023e-06
Iter: 827 loss: 1.53336805e-06
Iter: 828 loss: 1.52999394e-06
Iter: 829 loss: 1.52926816e-06
Iter: 830 loss: 1.52930068e-06
Iter: 831 loss: 1.52868392e-06
Iter: 832 loss: 1.52869336e-06
Iter: 833 loss: 1.52835628e-06
Iter: 834 loss: 1.52762266e-06
Iter: 835 loss: 1.5314356e-06
Iter: 836 loss: 1.52758605e-06
Iter: 837 loss: 1.52726716e-06
Iter: 838 loss: 1.52629354e-06
Iter: 839 loss: 1.54187228e-06
Iter: 840 loss: 1.52631264e-06
Iter: 841 loss: 1.52563121e-06
Iter: 842 loss: 1.52562654e-06
Iter: 843 loss: 1.52511791e-06
Iter: 844 loss: 1.5256212e-06
Iter: 845 loss: 1.52493499e-06
Iter: 846 loss: 1.52427924e-06
Iter: 847 loss: 1.52592372e-06
Iter: 848 loss: 1.5240646e-06
Iter: 849 loss: 1.52342955e-06
Iter: 850 loss: 1.52472956e-06
Iter: 851 loss: 1.52307734e-06
Iter: 852 loss: 1.5230014e-06
Iter: 853 loss: 1.52280882e-06
Iter: 854 loss: 1.52260532e-06
Iter: 855 loss: 1.52316761e-06
Iter: 856 loss: 1.52250266e-06
Iter: 857 loss: 1.52226971e-06
Iter: 858 loss: 1.52177381e-06
Iter: 859 loss: 1.52747543e-06
Iter: 860 loss: 1.52169184e-06
Iter: 861 loss: 1.5208866e-06
Iter: 862 loss: 1.52270854e-06
Iter: 863 loss: 1.52075825e-06
Iter: 864 loss: 1.52009852e-06
Iter: 865 loss: 1.52195014e-06
Iter: 866 loss: 1.51999939e-06
Iter: 867 loss: 1.51940117e-06
Iter: 868 loss: 1.52226789e-06
Iter: 869 loss: 1.51939923e-06
Iter: 870 loss: 1.51876691e-06
Iter: 871 loss: 1.51937161e-06
Iter: 872 loss: 1.51853123e-06
Iter: 873 loss: 1.51806353e-06
Iter: 874 loss: 1.51808206e-06
Iter: 875 loss: 1.51768609e-06
Iter: 876 loss: 1.51691756e-06
Iter: 877 loss: 1.51905238e-06
Iter: 878 loss: 1.51665563e-06
Iter: 879 loss: 1.51604468e-06
Iter: 880 loss: 1.5181663e-06
Iter: 881 loss: 1.51571942e-06
Iter: 882 loss: 1.515024e-06
Iter: 883 loss: 1.51545134e-06
Iter: 884 loss: 1.51468271e-06
Iter: 885 loss: 1.5139367e-06
Iter: 886 loss: 1.52053144e-06
Iter: 887 loss: 1.513965e-06
Iter: 888 loss: 1.51333347e-06
Iter: 889 loss: 1.51476979e-06
Iter: 890 loss: 1.51315351e-06
Iter: 891 loss: 1.51339964e-06
Iter: 892 loss: 1.51290487e-06
Iter: 893 loss: 1.51272525e-06
Iter: 894 loss: 1.51225049e-06
Iter: 895 loss: 1.51615632e-06
Iter: 896 loss: 1.51216273e-06
Iter: 897 loss: 1.51188942e-06
Iter: 898 loss: 1.51110703e-06
Iter: 899 loss: 1.5111782e-06
Iter: 900 loss: 1.51056156e-06
Iter: 901 loss: 1.51315817e-06
Iter: 902 loss: 1.51035351e-06
Iter: 903 loss: 1.5096241e-06
Iter: 904 loss: 1.51256245e-06
Iter: 905 loss: 1.50945709e-06
Iter: 906 loss: 1.50887331e-06
Iter: 907 loss: 1.50950473e-06
Iter: 908 loss: 1.50879396e-06
Iter: 909 loss: 1.5082876e-06
Iter: 910 loss: 1.51471954e-06
Iter: 911 loss: 1.50821506e-06
Iter: 912 loss: 1.50779977e-06
Iter: 913 loss: 1.50829521e-06
Iter: 914 loss: 1.50743404e-06
Iter: 915 loss: 1.50693597e-06
Iter: 916 loss: 1.5066139e-06
Iter: 917 loss: 1.50630137e-06
Iter: 918 loss: 1.50567462e-06
Iter: 919 loss: 1.51290305e-06
Iter: 920 loss: 1.50570247e-06
Iter: 921 loss: 1.50517963e-06
Iter: 922 loss: 1.50459573e-06
Iter: 923 loss: 1.50447181e-06
Iter: 924 loss: 1.50464166e-06
Iter: 925 loss: 1.50424285e-06
Iter: 926 loss: 1.50392532e-06
Iter: 927 loss: 1.50541507e-06
Iter: 928 loss: 1.50387768e-06
Iter: 929 loss: 1.50372261e-06
Iter: 930 loss: 1.5034841e-06
Iter: 931 loss: 1.50671883e-06
Iter: 932 loss: 1.50320898e-06
Iter: 933 loss: 1.50269057e-06
Iter: 934 loss: 1.50471021e-06
Iter: 935 loss: 1.50259541e-06
Iter: 936 loss: 1.50206949e-06
Iter: 937 loss: 1.5021626e-06
Iter: 938 loss: 1.50172355e-06
Iter: 939 loss: 1.50109042e-06
Iter: 940 loss: 1.50335791e-06
Iter: 941 loss: 1.50107439e-06
Iter: 942 loss: 1.50054723e-06
Iter: 943 loss: 1.50068684e-06
Iter: 944 loss: 1.50010965e-06
Iter: 945 loss: 1.49948789e-06
Iter: 946 loss: 1.50571907e-06
Iter: 947 loss: 1.49956225e-06
Iter: 948 loss: 1.49914945e-06
Iter: 949 loss: 1.50312519e-06
Iter: 950 loss: 1.49905532e-06
Iter: 951 loss: 1.49872812e-06
Iter: 952 loss: 1.49854623e-06
Iter: 953 loss: 1.49835807e-06
Iter: 954 loss: 1.49797688e-06
Iter: 955 loss: 1.49883317e-06
Iter: 956 loss: 1.49763173e-06
Iter: 957 loss: 1.49713856e-06
Iter: 958 loss: 1.49815787e-06
Iter: 959 loss: 1.49694347e-06
Iter: 960 loss: 1.49699031e-06
Iter: 961 loss: 1.49670575e-06
Iter: 962 loss: 1.49645166e-06
Iter: 963 loss: 1.49594007e-06
Iter: 964 loss: 1.50192159e-06
Iter: 965 loss: 1.4957642e-06
Iter: 966 loss: 1.49540062e-06
Iter: 967 loss: 1.49520656e-06
Iter: 968 loss: 1.49493235e-06
Iter: 969 loss: 1.49429718e-06
Iter: 970 loss: 1.49518871e-06
Iter: 971 loss: 1.49396226e-06
Iter: 972 loss: 1.49328696e-06
Iter: 973 loss: 1.49730272e-06
Iter: 974 loss: 1.49333141e-06
Iter: 975 loss: 1.49269658e-06
Iter: 976 loss: 1.49281743e-06
Iter: 977 loss: 1.49212542e-06
Iter: 978 loss: 1.49129016e-06
Iter: 979 loss: 1.49450875e-06
Iter: 980 loss: 1.49125435e-06
Iter: 981 loss: 1.49050686e-06
Iter: 982 loss: 1.49138691e-06
Iter: 983 loss: 1.49008e-06
Iter: 984 loss: 1.48953109e-06
Iter: 985 loss: 1.48960976e-06
Iter: 986 loss: 1.48927086e-06
Iter: 987 loss: 1.4888542e-06
Iter: 988 loss: 1.48887955e-06
Iter: 989 loss: 1.48823733e-06
Iter: 990 loss: 1.48924528e-06
Iter: 991 loss: 1.48790446e-06
Iter: 992 loss: 1.48766333e-06
Iter: 993 loss: 1.48763377e-06
Iter: 994 loss: 1.48716435e-06
Iter: 995 loss: 1.48812876e-06
Iter: 996 loss: 1.48695779e-06
Iter: 997 loss: 1.4867594e-06
Iter: 998 loss: 1.48616266e-06
Iter: 999 loss: 1.49484731e-06
Iter: 1000 loss: 1.48611343e-06
Iter: 1001 loss: 1.48552397e-06
Iter: 1002 loss: 1.48654431e-06
Iter: 1003 loss: 1.48536742e-06
Iter: 1004 loss: 1.48462641e-06
Iter: 1005 loss: 1.48676327e-06
Iter: 1006 loss: 1.4844627e-06
Iter: 1007 loss: 1.48387562e-06
Iter: 1008 loss: 1.48554977e-06
Iter: 1009 loss: 1.48358095e-06
Iter: 1010 loss: 1.48290508e-06
Iter: 1011 loss: 1.48417303e-06
Iter: 1012 loss: 1.48268737e-06
Iter: 1013 loss: 1.48182653e-06
Iter: 1014 loss: 1.48442177e-06
Iter: 1015 loss: 1.48176491e-06
Iter: 1016 loss: 1.48111917e-06
Iter: 1017 loss: 1.48463209e-06
Iter: 1018 loss: 1.48106585e-06
Iter: 1019 loss: 1.48065612e-06
Iter: 1020 loss: 1.48148376e-06
Iter: 1021 loss: 1.48018512e-06
Iter: 1022 loss: 1.47972719e-06
Iter: 1023 loss: 1.48187917e-06
Iter: 1024 loss: 1.47965648e-06
Iter: 1025 loss: 1.47924698e-06
Iter: 1026 loss: 1.47874243e-06
Iter: 1027 loss: 1.47866194e-06
Iter: 1028 loss: 1.47933451e-06
Iter: 1029 loss: 1.47837409e-06
Iter: 1030 loss: 1.47824153e-06
Iter: 1031 loss: 1.47773255e-06
Iter: 1032 loss: 1.48207164e-06
Iter: 1033 loss: 1.47756191e-06
Iter: 1034 loss: 1.47714741e-06
Iter: 1035 loss: 1.47680089e-06
Iter: 1036 loss: 1.47661058e-06
Iter: 1037 loss: 1.47593232e-06
Iter: 1038 loss: 1.48100844e-06
Iter: 1039 loss: 1.47583376e-06
Iter: 1040 loss: 1.47538572e-06
Iter: 1041 loss: 1.47474952e-06
Iter: 1042 loss: 1.47457524e-06
Iter: 1043 loss: 1.47392768e-06
Iter: 1044 loss: 1.48515358e-06
Iter: 1045 loss: 1.47393382e-06
Iter: 1046 loss: 1.47345372e-06
Iter: 1047 loss: 1.47390028e-06
Iter: 1048 loss: 1.47314131e-06
Iter: 1049 loss: 1.47256367e-06
Iter: 1050 loss: 1.4763134e-06
Iter: 1051 loss: 1.4725872e-06
Iter: 1052 loss: 1.47222e-06
Iter: 1053 loss: 1.47184755e-06
Iter: 1054 loss: 1.47167111e-06
Iter: 1055 loss: 1.47108403e-06
Iter: 1056 loss: 1.47389903e-06
Iter: 1057 loss: 1.47100013e-06
Iter: 1058 loss: 1.47060587e-06
Iter: 1059 loss: 1.47487106e-06
Iter: 1060 loss: 1.47066271e-06
Iter: 1061 loss: 1.47045239e-06
Iter: 1062 loss: 1.4698237e-06
Iter: 1063 loss: 1.47694698e-06
Iter: 1064 loss: 1.46989532e-06
Iter: 1065 loss: 1.4706809e-06
Iter: 1066 loss: 1.46959e-06
Iter: 1067 loss: 1.46948082e-06
Iter: 1068 loss: 1.4691467e-06
Iter: 1069 loss: 1.47349249e-06
Iter: 1070 loss: 1.46902448e-06
Iter: 1071 loss: 1.46872719e-06
Iter: 1072 loss: 1.46832724e-06
Iter: 1073 loss: 1.46831201e-06
Iter: 1074 loss: 1.46777643e-06
Iter: 1075 loss: 1.47008927e-06
Iter: 1076 loss: 1.46759601e-06
Iter: 1077 loss: 1.46736227e-06
Iter: 1078 loss: 1.46852653e-06
Iter: 1079 loss: 1.46729872e-06
Iter: 1080 loss: 1.46672892e-06
Iter: 1081 loss: 1.46673e-06
Iter: 1082 loss: 1.4664206e-06
Iter: 1083 loss: 1.46591617e-06
Iter: 1084 loss: 1.46909156e-06
Iter: 1085 loss: 1.46592345e-06
Iter: 1086 loss: 1.46546017e-06
Iter: 1087 loss: 1.46561342e-06
Iter: 1088 loss: 1.46520313e-06
Iter: 1089 loss: 1.46468528e-06
Iter: 1090 loss: 1.46778211e-06
Iter: 1091 loss: 1.46467187e-06
Iter: 1092 loss: 1.46420689e-06
Iter: 1093 loss: 1.46370746e-06
Iter: 1094 loss: 1.46356319e-06
Iter: 1095 loss: 1.46307229e-06
Iter: 1096 loss: 1.46309276e-06
Iter: 1097 loss: 1.46292848e-06
Iter: 1098 loss: 1.46279069e-06
Iter: 1099 loss: 1.46257457e-06
Iter: 1100 loss: 1.46263631e-06
Iter: 1101 loss: 1.4623547e-06
Iter: 1102 loss: 1.46213483e-06
Iter: 1103 loss: 1.46183697e-06
Iter: 1104 loss: 1.46187506e-06
Iter: 1105 loss: 1.46138814e-06
Iter: 1106 loss: 1.46277239e-06
Iter: 1107 loss: 1.46127968e-06
Iter: 1108 loss: 1.46099649e-06
Iter: 1109 loss: 1.46100501e-06
Iter: 1110 loss: 1.46067066e-06
Iter: 1111 loss: 1.46032744e-06
Iter: 1112 loss: 1.46153548e-06
Iter: 1113 loss: 1.46007972e-06
Iter: 1114 loss: 1.45973354e-06
Iter: 1115 loss: 1.45984211e-06
Iter: 1116 loss: 1.45923639e-06
Iter: 1117 loss: 1.45879858e-06
Iter: 1118 loss: 1.46217349e-06
Iter: 1119 loss: 1.4586933e-06
Iter: 1120 loss: 1.45825618e-06
Iter: 1121 loss: 1.45844638e-06
Iter: 1122 loss: 1.45788783e-06
Iter: 1123 loss: 1.4574174e-06
Iter: 1124 loss: 1.46140735e-06
Iter: 1125 loss: 1.45746776e-06
Iter: 1126 loss: 1.45701745e-06
Iter: 1127 loss: 1.45725335e-06
Iter: 1128 loss: 1.45675881e-06
Iter: 1129 loss: 1.45635931e-06
Iter: 1130 loss: 1.45965373e-06
Iter: 1131 loss: 1.45624642e-06
Iter: 1132 loss: 1.45650313e-06
Iter: 1133 loss: 1.45619856e-06
Iter: 1134 loss: 1.45603383e-06
Iter: 1135 loss: 1.45582703e-06
Iter: 1136 loss: 1.45748413e-06
Iter: 1137 loss: 1.45571835e-06
Iter: 1138 loss: 1.45547062e-06
Iter: 1139 loss: 1.45521403e-06
Iter: 1140 loss: 1.45521176e-06
Iter: 1141 loss: 1.45471e-06
Iter: 1142 loss: 1.4598113e-06
Iter: 1143 loss: 1.4547885e-06
Iter: 1144 loss: 1.45438798e-06
Iter: 1145 loss: 1.45434706e-06
Iter: 1146 loss: 1.45402021e-06
Iter: 1147 loss: 1.45368699e-06
Iter: 1148 loss: 1.45439969e-06
Iter: 1149 loss: 1.45350919e-06
Iter: 1150 loss: 1.45299487e-06
Iter: 1151 loss: 1.4534894e-06
Iter: 1152 loss: 1.45281592e-06
Iter: 1153 loss: 1.45239039e-06
Iter: 1154 loss: 1.45415061e-06
Iter: 1155 loss: 1.45220838e-06
Iter: 1156 loss: 1.4517243e-06
Iter: 1157 loss: 1.452476e-06
Iter: 1158 loss: 1.45163494e-06
Iter: 1159 loss: 1.45101239e-06
Iter: 1160 loss: 1.45097749e-06
Iter: 1161 loss: 1.45069055e-06
Iter: 1162 loss: 1.45007402e-06
Iter: 1163 loss: 1.45418323e-06
Iter: 1164 loss: 1.45001241e-06
Iter: 1165 loss: 1.4495912e-06
Iter: 1166 loss: 1.45507352e-06
Iter: 1167 loss: 1.44955038e-06
Iter: 1168 loss: 1.44923638e-06
Iter: 1169 loss: 1.45032e-06
Iter: 1170 loss: 1.44910359e-06
Iter: 1171 loss: 1.4488578e-06
Iter: 1172 loss: 1.44844762e-06
Iter: 1173 loss: 1.45397075e-06
Iter: 1174 loss: 1.44842534e-06
Iter: 1175 loss: 1.44811099e-06
Iter: 1176 loss: 1.44899241e-06
Iter: 1177 loss: 1.44791852e-06
Iter: 1178 loss: 1.44735395e-06
Iter: 1179 loss: 1.44980959e-06
Iter: 1180 loss: 1.44733417e-06
Iter: 1181 loss: 1.44683031e-06
Iter: 1182 loss: 1.44835246e-06
Iter: 1183 loss: 1.44674482e-06
Iter: 1184 loss: 1.44653222e-06
Iter: 1185 loss: 1.44663227e-06
Iter: 1186 loss: 1.44623357e-06
Iter: 1187 loss: 1.4457778e-06
Iter: 1188 loss: 1.44670605e-06
Iter: 1189 loss: 1.44575074e-06
Iter: 1190 loss: 1.44540331e-06
Iter: 1191 loss: 1.44558817e-06
Iter: 1192 loss: 1.44497392e-06
Iter: 1193 loss: 1.44439673e-06
Iter: 1194 loss: 1.44760327e-06
Iter: 1195 loss: 1.44444596e-06
Iter: 1196 loss: 1.44395494e-06
Iter: 1197 loss: 1.44489275e-06
Iter: 1198 loss: 1.44389526e-06
Iter: 1199 loss: 1.44356125e-06
Iter: 1200 loss: 1.44385649e-06
Iter: 1201 loss: 1.44331557e-06
Iter: 1202 loss: 1.44330568e-06
Iter: 1203 loss: 1.44298895e-06
Iter: 1204 loss: 1.44297223e-06
Iter: 1205 loss: 1.44286798e-06
Iter: 1206 loss: 1.44278101e-06
Iter: 1207 loss: 1.44242267e-06
Iter: 1208 loss: 1.44212686e-06
Iter: 1209 loss: 1.4489608e-06
Iter: 1210 loss: 1.44229261e-06
Iter: 1211 loss: 1.44199475e-06
Iter: 1212 loss: 1.44252454e-06
Iter: 1213 loss: 1.44179671e-06
Iter: 1214 loss: 1.44151443e-06
Iter: 1215 loss: 1.44274668e-06
Iter: 1216 loss: 1.44138266e-06
Iter: 1217 loss: 1.44095156e-06
Iter: 1218 loss: 1.44201272e-06
Iter: 1219 loss: 1.44085652e-06
Iter: 1220 loss: 1.44058959e-06
Iter: 1221 loss: 1.44049011e-06
Iter: 1222 loss: 1.440196e-06
Iter: 1223 loss: 1.43979355e-06
Iter: 1224 loss: 1.44159139e-06
Iter: 1225 loss: 1.43971897e-06
Iter: 1226 loss: 1.43929083e-06
Iter: 1227 loss: 1.43974341e-06
Iter: 1228 loss: 1.43900911e-06
Iter: 1229 loss: 1.438715e-06
Iter: 1230 loss: 1.43953287e-06
Iter: 1231 loss: 1.43854959e-06
Iter: 1232 loss: 1.43804482e-06
Iter: 1233 loss: 1.43885188e-06
Iter: 1234 loss: 1.43795626e-06
Iter: 1235 loss: 1.43743523e-06
Iter: 1236 loss: 1.43883744e-06
Iter: 1237 loss: 1.43721934e-06
Iter: 1238 loss: 1.43675845e-06
Iter: 1239 loss: 1.43885632e-06
Iter: 1240 loss: 1.43676834e-06
Iter: 1241 loss: 1.43700288e-06
Iter: 1242 loss: 1.43664943e-06
Iter: 1243 loss: 1.43654051e-06
Iter: 1244 loss: 1.43637817e-06
Iter: 1245 loss: 1.43650459e-06
Iter: 1246 loss: 1.4359066e-06
Iter: 1247 loss: 1.43560101e-06
Iter: 1248 loss: 1.43727289e-06
Iter: 1249 loss: 1.43556622e-06
Iter: 1250 loss: 1.43525983e-06
Iter: 1251 loss: 1.43555587e-06
Iter: 1252 loss: 1.43500574e-06
Iter: 1253 loss: 1.43457385e-06
Iter: 1254 loss: 1.43665966e-06
Iter: 1255 loss: 1.43450688e-06
Iter: 1256 loss: 1.43409181e-06
Iter: 1257 loss: 1.43717455e-06
Iter: 1258 loss: 1.43413718e-06
Iter: 1259 loss: 1.43399177e-06
Iter: 1260 loss: 1.43371233e-06
Iter: 1261 loss: 1.43360967e-06
Iter: 1262 loss: 1.43325326e-06
Iter: 1263 loss: 1.43452087e-06
Iter: 1264 loss: 1.43314014e-06
Iter: 1265 loss: 1.4327743e-06
Iter: 1266 loss: 1.43332318e-06
Iter: 1267 loss: 1.43277839e-06
Iter: 1268 loss: 1.4322286e-06
Iter: 1269 loss: 1.43307454e-06
Iter: 1270 loss: 1.43211878e-06
Iter: 1271 loss: 1.43176044e-06
Iter: 1272 loss: 1.43322586e-06
Iter: 1273 loss: 1.43152715e-06
Iter: 1274 loss: 1.43108878e-06
Iter: 1275 loss: 1.43267971e-06
Iter: 1276 loss: 1.43093587e-06
Iter: 1277 loss: 1.43087402e-06
Iter: 1278 loss: 1.43079592e-06
Iter: 1279 loss: 1.43064369e-06
Iter: 1280 loss: 1.43051557e-06
Iter: 1281 loss: 1.4303215e-06
Iter: 1282 loss: 1.4302866e-06
Iter: 1283 loss: 1.42989961e-06
Iter: 1284 loss: 1.42987403e-06
Iter: 1285 loss: 1.42972976e-06
Iter: 1286 loss: 1.42980548e-06
Iter: 1287 loss: 1.42945873e-06
Iter: 1288 loss: 1.42915871e-06
Iter: 1289 loss: 1.42979854e-06
Iter: 1290 loss: 1.42893009e-06
Iter: 1291 loss: 1.42865861e-06
Iter: 1292 loss: 1.43272416e-06
Iter: 1293 loss: 1.42852434e-06
Iter: 1294 loss: 1.42825706e-06
Iter: 1295 loss: 1.42917338e-06
Iter: 1296 loss: 1.42813485e-06
Iter: 1297 loss: 1.42777196e-06
Iter: 1298 loss: 1.4280688e-06
Iter: 1299 loss: 1.427592e-06
Iter: 1300 loss: 1.42722115e-06
Iter: 1301 loss: 1.42767544e-06
Iter: 1302 loss: 1.42702629e-06
Iter: 1303 loss: 1.42654426e-06
Iter: 1304 loss: 1.42800104e-06
Iter: 1305 loss: 1.42640795e-06
Iter: 1306 loss: 1.4259299e-06
Iter: 1307 loss: 1.42796534e-06
Iter: 1308 loss: 1.42596059e-06
Iter: 1309 loss: 1.42559259e-06
Iter: 1310 loss: 1.42544786e-06
Iter: 1311 loss: 1.42530678e-06
Iter: 1312 loss: 1.42490205e-06
Iter: 1313 loss: 1.42929525e-06
Iter: 1314 loss: 1.42486283e-06
Iter: 1315 loss: 1.42481008e-06
Iter: 1316 loss: 1.42481588e-06
Iter: 1317 loss: 1.4246001e-06
Iter: 1318 loss: 1.42441877e-06
Iter: 1319 loss: 1.42374734e-06
Iter: 1320 loss: 1.42392446e-06
Iter: 1321 loss: 1.42324075e-06
Iter: 1322 loss: 1.42786894e-06
Iter: 1323 loss: 1.42321016e-06
Iter: 1324 loss: 1.42289741e-06
Iter: 1325 loss: 1.42285853e-06
Iter: 1326 loss: 1.42240629e-06
Iter: 1327 loss: 1.42197359e-06
Iter: 1328 loss: 1.42597582e-06
Iter: 1329 loss: 1.42182103e-06
Iter: 1330 loss: 1.42148019e-06
Iter: 1331 loss: 1.42519036e-06
Iter: 1332 loss: 1.42162332e-06
Iter: 1333 loss: 1.42132694e-06
Iter: 1334 loss: 1.42102419e-06
Iter: 1335 loss: 1.42094177e-06
Iter: 1336 loss: 1.42072338e-06
Iter: 1337 loss: 1.4225817e-06
Iter: 1338 loss: 1.42068438e-06
Iter: 1339 loss: 1.42020554e-06
Iter: 1340 loss: 1.42130534e-06
Iter: 1341 loss: 1.42010742e-06
Iter: 1342 loss: 1.41975408e-06
Iter: 1343 loss: 1.42007525e-06
Iter: 1344 loss: 1.41957912e-06
Iter: 1345 loss: 1.41923078e-06
Iter: 1346 loss: 1.41981707e-06
Iter: 1347 loss: 1.41900387e-06
Iter: 1348 loss: 1.41873238e-06
Iter: 1349 loss: 1.42141971e-06
Iter: 1350 loss: 1.41856378e-06
Iter: 1351 loss: 1.41830594e-06
Iter: 1352 loss: 1.41827377e-06
Iter: 1353 loss: 1.41833993e-06
Iter: 1354 loss: 1.41836654e-06
Iter: 1355 loss: 1.41825296e-06
Iter: 1356 loss: 1.41834983e-06
Iter: 1357 loss: 1.41830583e-06
Iter: 1358 loss: 1.41834505e-06
Iter: 1359 loss: 1.41815985e-06
Iter: 1360 loss: 1.41826172e-06
Iter: 1361 loss: 1.41834812e-06
Iter: 1362 loss: 1.41836e-06
Iter: 1363 loss: 1.41827968e-06
Iter: 1364 loss: 1.41828127e-06
Iter: 1365 loss: 1.4183297e-06
Iter: 1366 loss: 1.41827218e-06
Iter: 1367 loss: 1.41831106e-06
Iter: 1368 loss: 1.41831629e-06
Iter: 1369 loss: 1.41828821e-06
Iter: 1370 loss: 1.41826933e-06
Iter: 1371 loss: 1.41827127e-06
Iter: 1372 loss: 1.41827809e-06
Iter: 1373 loss: 1.41827115e-06
Iter: 1374 loss: 1.4182765e-06
Iter: 1375 loss: 1.41826922e-06
Iter: 1376 loss: 1.4182765e-06
Iter: 1377 loss: 1.4182765e-06
Iter: 1378 loss: 1.4182765e-06
Iter: 1379 loss: 1.41826922e-06
Iter: 1380 loss: 1.41755822e-06
Iter: 1381 loss: 1.42627698e-06
Iter: 1382 loss: 1.41762473e-06
Iter: 1383 loss: 1.41717646e-06
Iter: 1384 loss: 1.41811029e-06
Iter: 1385 loss: 1.41699434e-06
Iter: 1386 loss: 1.4167349e-06
Iter: 1387 loss: 1.42084116e-06
Iter: 1388 loss: 1.41678026e-06
Iter: 1389 loss: 1.41646888e-06
Iter: 1390 loss: 1.41823966e-06
Iter: 1391 loss: 1.41635121e-06
Iter: 1392 loss: 1.41626117e-06
Iter: 1393 loss: 1.41591295e-06
Iter: 1394 loss: 1.41591431e-06
Iter: 1395 loss: 1.41550515e-06
Iter: 1396 loss: 1.41597116e-06
Iter: 1397 loss: 1.41545775e-06
Iter: 1398 loss: 1.41501459e-06
Iter: 1399 loss: 1.41639816e-06
Iter: 1400 loss: 1.41487976e-06
Iter: 1401 loss: 1.41474823e-06
Iter: 1402 loss: 1.41493638e-06
Iter: 1403 loss: 1.41442433e-06
Iter: 1404 loss: 1.41414728e-06
Iter: 1405 loss: 1.41543956e-06
Iter: 1406 loss: 1.41415489e-06
Iter: 1407 loss: 1.413988e-06
Iter: 1408 loss: 1.41383316e-06
Iter: 1409 loss: 1.4137953e-06
Iter: 1410 loss: 1.41350642e-06
Iter: 1411 loss: 1.41357714e-06
Iter: 1412 loss: 1.41340411e-06
Iter: 1413 loss: 1.41299574e-06
Iter: 1414 loss: 1.41294754e-06
Iter: 1415 loss: 1.41268424e-06
Iter: 1416 loss: 1.41472697e-06
Iter: 1417 loss: 1.41264695e-06
Iter: 1418 loss: 1.41233568e-06
Iter: 1419 loss: 1.41233613e-06
Iter: 1420 loss: 1.41207715e-06
Iter: 1421 loss: 1.4117611e-06
Iter: 1422 loss: 1.41496e-06
Iter: 1423 loss: 1.41172677e-06
Iter: 1424 loss: 1.41142846e-06
Iter: 1425 loss: 1.4120825e-06
Iter: 1426 loss: 1.41121984e-06
Iter: 1427 loss: 1.41096552e-06
Iter: 1428 loss: 1.41120358e-06
Iter: 1429 loss: 1.41055307e-06
Iter: 1430 loss: 1.41021724e-06
Iter: 1431 loss: 1.4112328e-06
Iter: 1432 loss: 1.41022088e-06
Iter: 1433 loss: 1.40968166e-06
Iter: 1434 loss: 1.4102967e-06
Iter: 1435 loss: 1.40952363e-06
Iter: 1436 loss: 1.40903546e-06
Iter: 1437 loss: 1.41087753e-06
Iter: 1438 loss: 1.40891473e-06
Iter: 1439 loss: 1.40923032e-06
Iter: 1440 loss: 1.40884583e-06
Iter: 1441 loss: 1.40862585e-06
Iter: 1442 loss: 1.40864552e-06
Iter: 1443 loss: 1.408662e-06
Iter: 1444 loss: 1.40842087e-06
Iter: 1445 loss: 1.40823784e-06
Iter: 1446 loss: 1.41252315e-06
Iter: 1447 loss: 1.40816746e-06
Iter: 1448 loss: 1.4076918e-06
Iter: 1449 loss: 1.40865563e-06
Iter: 1450 loss: 1.40763905e-06
Iter: 1451 loss: 1.40727332e-06
Iter: 1452 loss: 1.40750672e-06
Iter: 1453 loss: 1.40680481e-06
Iter: 1454 loss: 1.4064392e-06
Iter: 1455 loss: 1.4107469e-06
Iter: 1456 loss: 1.40650707e-06
Iter: 1457 loss: 1.40628038e-06
Iter: 1458 loss: 1.40680947e-06
Iter: 1459 loss: 1.40619215e-06
Iter: 1460 loss: 1.40584802e-06
Iter: 1461 loss: 1.40604402e-06
Iter: 1462 loss: 1.40551151e-06
Iter: 1463 loss: 1.40526686e-06
Iter: 1464 loss: 1.40677366e-06
Iter: 1465 loss: 1.40518046e-06
Iter: 1466 loss: 1.40470013e-06
Iter: 1467 loss: 1.40455e-06
Iter: 1468 loss: 1.40435839e-06
Iter: 1469 loss: 1.40384861e-06
Iter: 1470 loss: 1.40981933e-06
Iter: 1471 loss: 1.40396673e-06
Iter: 1472 loss: 1.40363909e-06
Iter: 1473 loss: 1.40648217e-06
Iter: 1474 loss: 1.40369752e-06
Iter: 1475 loss: 1.40348936e-06
Iter: 1476 loss: 1.40420195e-06
Iter: 1477 loss: 1.40327097e-06
Iter: 1478 loss: 1.40321288e-06
Iter: 1479 loss: 1.40291058e-06
Iter: 1480 loss: 1.40290376e-06
Iter: 1481 loss: 1.40253496e-06
Iter: 1482 loss: 1.40298698e-06
Iter: 1483 loss: 1.40238683e-06
Iter: 1484 loss: 1.40210705e-06
Iter: 1485 loss: 1.4022994e-06
Iter: 1486 loss: 1.40191833e-06
Iter: 1487 loss: 1.40150792e-06
Iter: 1488 loss: 1.40354e-06
Iter: 1489 loss: 1.40150291e-06
Iter: 1490 loss: 1.40110876e-06
Iter: 1491 loss: 1.40258726e-06
Iter: 1492 loss: 1.40112411e-06
Iter: 1493 loss: 1.40076213e-06
Iter: 1494 loss: 1.40159909e-06
Iter: 1495 loss: 1.40070551e-06
Iter: 1496 loss: 1.40031329e-06
Iter: 1497 loss: 1.40067937e-06
Iter: 1498 loss: 1.4002577e-06
Iter: 1499 loss: 1.39999406e-06
Iter: 1500 loss: 1.40147426e-06
Iter: 1501 loss: 1.39984365e-06
Iter: 1502 loss: 1.3996937e-06
Iter: 1503 loss: 1.39969563e-06
Iter: 1504 loss: 1.39944439e-06
Iter: 1505 loss: 1.39912413e-06
Iter: 1506 loss: 1.40221596e-06
Iter: 1507 loss: 1.39912549e-06
Iter: 1508 loss: 1.39913686e-06
Iter: 1509 loss: 1.39890597e-06
Iter: 1510 loss: 1.39898634e-06
Iter: 1511 loss: 1.39891711e-06
Iter: 1512 loss: 1.39901397e-06
Iter: 1513 loss: 1.3990275e-06
Iter: 1514 loss: 1.39897952e-06
Iter: 1515 loss: 1.39897452e-06
Iter: 1516 loss: 1.39903977e-06
Iter: 1517 loss: 1.39900476e-06
Iter: 1518 loss: 1.3989677e-06
Iter: 1519 loss: 1.39892495e-06
Iter: 1520 loss: 1.39890483e-06
Iter: 1521 loss: 1.39891881e-06
Iter: 1522 loss: 1.39886356e-06
Iter: 1523 loss: 1.39887072e-06
Iter: 1524 loss: 1.39883377e-06
Iter: 1525 loss: 1.39885128e-06
Iter: 1526 loss: 1.39887038e-06
Iter: 1527 loss: 1.3989054e-06
Iter: 1528 loss: 1.39891233e-06
Iter: 1529 loss: 1.39891108e-06
Iter: 1530 loss: 1.39890517e-06
Iter: 1531 loss: 1.39890517e-06
Iter: 1532 loss: 1.39890517e-06
Iter: 1533 loss: 1.39890506e-06
Iter: 1534 loss: 1.39890506e-06
Iter: 1535 loss: 1.39891108e-06
Iter: 1536 loss: 1.39890506e-06
Iter: 1537 loss: 1.39890506e-06
Iter: 1538 loss: 1.39891108e-06
Iter: 1539 loss: 1.39891108e-06
Iter: 1540 loss: 1.39890506e-06
Iter: 1541 loss: 1.39890506e-06
Iter: 1542 loss: 1.39891108e-06
Iter: 1543 loss: 1.39891108e-06
Iter: 1544 loss: 1.39890506e-06
Iter: 1545 loss: 1.40386351e-06
Iter: 1546 loss: 1.39898111e-06
Iter: 1547 loss: 1.39894541e-06
Iter: 1548 loss: 1.39900772e-06
Iter: 1549 loss: 1.3990624e-06
Iter: 1550 loss: 1.39894883e-06
Iter: 1551 loss: 1.39903523e-06
Iter: 1552 loss: 1.39896781e-06
Iter: 1553 loss: 1.39894337e-06
Iter: 1554 loss: 1.3989652e-06
Iter: 1555 loss: 1.39896474e-06
Iter: 1556 loss: 1.39900749e-06
Iter: 1557 loss: 1.3989561e-06
Iter: 1558 loss: 1.39902045e-06
Iter: 1559 loss: 1.3989395e-06
Iter: 1560 loss: 1.39895837e-06
Iter: 1561 loss: 1.39894746e-06
Iter: 1562 loss: 1.39893677e-06
Iter: 1563 loss: 1.39892131e-06
Iter: 1564 loss: 1.39890267e-06
Iter: 1565 loss: 1.39892e-06
Iter: 1566 loss: 1.39891745e-06
Iter: 1567 loss: 1.39891199e-06
Iter: 1568 loss: 1.39890335e-06
Iter: 1569 loss: 1.3989121e-06
Iter: 1570 loss: 1.3989121e-06
Iter: 1571 loss: 1.39890335e-06
Iter: 1572 loss: 1.3989121e-06
Iter: 1573 loss: 1.39890335e-06
Iter: 1574 loss: 1.39890335e-06
Iter: 1575 loss: 1.39890335e-06
Iter: 1576 loss: 1.3989121e-06
Iter: 1577 loss: 1.3989121e-06
Iter: 1578 loss: 1.3989121e-06
Iter: 1579 loss: 1.3989121e-06
Iter: 1580 loss: 1.3989121e-06
Iter: 1581 loss: 1.3989121e-06
Iter: 1582 loss: 1.39890335e-06
Iter: 1583 loss: 1.39890335e-06
Iter: 1584 loss: 1.39890335e-06
Iter: 1585 loss: 1.39890335e-06
Iter: 1586 loss: 1.39890335e-06
Iter: 1587 loss: 1.39890335e-06
Iter: 1588 loss: 1.39890335e-06
Iter: 1589 loss: 1.3989121e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.8/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi3
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi3
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi3 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi3
+ date
Sat Nov  7 22:47:16 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi3/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi2.8/300_100_100_100_1 --function f1 --psi 0 --phi 3 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi3/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67da7d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67da6b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67db44b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67da38f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67da43ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67da43048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d996a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d9b2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d9b22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d993f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d9932f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d981f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dc44ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dc9d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dc91620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d9219d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dc1ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dba7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc67d97f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dba7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dbc71e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dbcc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc65dbc7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc638469ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6383db6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6383a2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6383b8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6383a2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6382f00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6383510d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc63835e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc63826a0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc63826a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc63824cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6382111e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc638312598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0028247195
test_loss: 0.003092425
train_loss: 0.0032912567
test_loss: 0.0031344965
train_loss: 0.002711112
test_loss: 0.002765566
train_loss: 0.0019498285
test_loss: 0.0023669747
train_loss: 0.0018965047
test_loss: 0.0021737178
train_loss: 0.0025550225
test_loss: 0.0023969884
train_loss: 0.0023043982
test_loss: 0.0025722082
train_loss: 0.0025607427
test_loss: 0.0029085963
train_loss: 0.0020396607
test_loss: 0.0024353918
train_loss: 0.002146107
test_loss: 0.0025022845
train_loss: 0.0022708112
test_loss: 0.003032168
train_loss: 0.0020700663
test_loss: 0.0020151956
train_loss: 0.0022859399
test_loss: 0.0024155779
train_loss: 0.003340003
test_loss: 0.0026533613
train_loss: 0.0026301132
test_loss: 0.0021722224
train_loss: 0.0016901586
test_loss: 0.0023497557
train_loss: 0.0019735773
test_loss: 0.0024316374
train_loss: 0.0021969639
test_loss: 0.0018985145
train_loss: 0.0024665997
test_loss: 0.0024266648
train_loss: 0.0029323944
test_loss: 0.0032212867
train_loss: 0.0024114945
test_loss: 0.0022500274
train_loss: 0.0022889709
test_loss: 0.0025048438
train_loss: 0.0021197258
test_loss: 0.0023505834
train_loss: 0.002304849
test_loss: 0.002305744
train_loss: 0.0021405248
test_loss: 0.002064967
train_loss: 0.002170205
test_loss: 0.0024428556
train_loss: 0.0022576062
test_loss: 0.0025392736
train_loss: 0.0022346894
test_loss: 0.00222399
train_loss: 0.0020088889
test_loss: 0.0021553242
train_loss: 0.0018886093
test_loss: 0.0020429487
train_loss: 0.0023055573
test_loss: 0.003154692
train_loss: 0.002570608
test_loss: 0.0024650304
train_loss: 0.0021555617
test_loss: 0.0018256531
train_loss: 0.0025707858
test_loss: 0.0019885264
train_loss: 0.0026528083
test_loss: 0.0019347057
train_loss: 0.0022522963
test_loss: 0.0022159913
train_loss: 0.0023814547
test_loss: 0.0024174529
train_loss: 0.0031951796
test_loss: 0.0034802498
train_loss: 0.0023092222
test_loss: 0.0022033222
train_loss: 0.0019671684
test_loss: 0.0020104356
train_loss: 0.0021250914
test_loss: 0.0022758238
train_loss: 0.002102321
test_loss: 0.0019897448
train_loss: 0.0023174426
test_loss: 0.0021292067
train_loss: 0.0022652026
test_loss: 0.00230642
train_loss: 0.0019960823
test_loss: 0.0019888405
train_loss: 0.0019833306
test_loss: 0.0023508193
train_loss: 0.0024890509
test_loss: 0.0020660472
train_loss: 0.002078712
test_loss: 0.0021076275
train_loss: 0.0019361217
test_loss: 0.0019141438
train_loss: 0.00239876
test_loss: 0.0018861043
train_loss: 0.0027792724
test_loss: 0.0038089044
train_loss: 0.002020714
test_loss: 0.0021207095
train_loss: 0.0021988873
test_loss: 0.0021789356
train_loss: 0.0020219034
test_loss: 0.002040801
train_loss: 0.0019070196
test_loss: 0.0020077042
train_loss: 0.0020581405
test_loss: 0.002162517
train_loss: 0.0031672702
test_loss: 0.0020839009
train_loss: 0.001629459
test_loss: 0.0024160196
train_loss: 0.0022006931
test_loss: 0.0019924503
train_loss: 0.0023225716
test_loss: 0.0018835288
train_loss: 0.0020449343
test_loss: 0.0017140259
train_loss: 0.0024382926
test_loss: 0.0023399736
train_loss: 0.0019344582
test_loss: 0.0023224242
train_loss: 0.002392843
test_loss: 0.002089096
train_loss: 0.0023753755
test_loss: 0.0019281785
train_loss: 0.003009217
test_loss: 0.0030921996
train_loss: 0.0022121042
test_loss: 0.0027506799
train_loss: 0.002229911
test_loss: 0.0020712968
train_loss: 0.0022072692
test_loss: 0.0018715721
train_loss: 0.0018372235
test_loss: 0.0018220016
train_loss: 0.002515589
test_loss: 0.0017596202
train_loss: 0.001963887
test_loss: 0.0023390814
train_loss: 0.0020838794
test_loss: 0.0019514234
train_loss: 0.0028698775
test_loss: 0.002262738
train_loss: 0.0020440728
test_loss: 0.002302912
train_loss: 0.0018999032
test_loss: 0.001976473
train_loss: 0.0020825616
test_loss: 0.0024295833
train_loss: 0.0022856463
test_loss: 0.0023254415
train_loss: 0.0025835529
test_loss: 0.002517537
train_loss: 0.0022610982
test_loss: 0.0033264603
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi3/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi3/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 0 --phi 3 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi0_phi3/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee234488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee1a7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee1ff598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee2a77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee2a72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee281b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee281c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee0d9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee0d91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee0810d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee099268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee081e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee0817b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee02b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee081620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75ee081730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edff0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edff0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edf4aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edfbf158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edf268c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edf372f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edf3b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75edeeff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbcf8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbcbcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbcf3840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbcbc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbc841e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbc410d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbc3b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbc0a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbc06950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbbaf9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbb5d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f75cbb78d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.671071e-05
Iter: 2 loss: 0.000214090483
Iter: 3 loss: 6.32712909e-06
Iter: 4 loss: 5.30235957e-06
Iter: 5 loss: 3.65599681e-06
Iter: 6 loss: 3.64340167e-06
Iter: 7 loss: 2.9600692e-06
Iter: 8 loss: 4.62078697e-06
Iter: 9 loss: 2.71588601e-06
Iter: 10 loss: 2.33586479e-06
Iter: 11 loss: 3.27291446e-06
Iter: 12 loss: 2.20132642e-06
Iter: 13 loss: 2.03199488e-06
Iter: 14 loss: 2.39594056e-06
Iter: 15 loss: 1.96592e-06
Iter: 16 loss: 1.87080616e-06
Iter: 17 loss: 1.99954889e-06
Iter: 18 loss: 1.82333065e-06
Iter: 19 loss: 1.77916604e-06
Iter: 20 loss: 1.76730191e-06
Iter: 21 loss: 1.73997489e-06
Iter: 22 loss: 1.68149052e-06
Iter: 23 loss: 1.74174284e-06
Iter: 24 loss: 1.64896142e-06
Iter: 25 loss: 1.59273679e-06
Iter: 26 loss: 1.73484477e-06
Iter: 27 loss: 1.57320062e-06
Iter: 28 loss: 1.54976874e-06
Iter: 29 loss: 1.56523083e-06
Iter: 30 loss: 1.53483393e-06
Iter: 31 loss: 1.51009351e-06
Iter: 32 loss: 1.52744678e-06
Iter: 33 loss: 1.49459152e-06
Iter: 34 loss: 1.46864363e-06
Iter: 35 loss: 1.76493904e-06
Iter: 36 loss: 1.46829746e-06
Iter: 37 loss: 1.45104923e-06
Iter: 38 loss: 1.46948287e-06
Iter: 39 loss: 1.44149089e-06
Iter: 40 loss: 1.42315753e-06
Iter: 41 loss: 1.46039861e-06
Iter: 42 loss: 1.41575629e-06
Iter: 43 loss: 1.3954101e-06
Iter: 44 loss: 1.49249411e-06
Iter: 45 loss: 1.3917047e-06
Iter: 46 loss: 1.37415805e-06
Iter: 47 loss: 1.44993794e-06
Iter: 48 loss: 1.37057577e-06
Iter: 49 loss: 1.35581445e-06
Iter: 50 loss: 1.36232495e-06
Iter: 51 loss: 1.34558763e-06
Iter: 52 loss: 1.32879848e-06
Iter: 53 loss: 1.58912894e-06
Iter: 54 loss: 1.32872447e-06
Iter: 55 loss: 1.3204924e-06
Iter: 56 loss: 1.31622573e-06
Iter: 57 loss: 1.31231866e-06
Iter: 58 loss: 1.30030821e-06
Iter: 59 loss: 1.28535476e-06
Iter: 60 loss: 1.28418719e-06
Iter: 61 loss: 1.27524584e-06
Iter: 62 loss: 1.27383146e-06
Iter: 63 loss: 1.26256907e-06
Iter: 64 loss: 1.25263978e-06
Iter: 65 loss: 1.24973019e-06
Iter: 66 loss: 1.23506334e-06
Iter: 67 loss: 1.28585896e-06
Iter: 68 loss: 1.23119196e-06
Iter: 69 loss: 1.22134759e-06
Iter: 70 loss: 1.23704058e-06
Iter: 71 loss: 1.21673838e-06
Iter: 72 loss: 1.20707352e-06
Iter: 73 loss: 1.34257562e-06
Iter: 74 loss: 1.2070609e-06
Iter: 75 loss: 1.20107882e-06
Iter: 76 loss: 1.20444611e-06
Iter: 77 loss: 1.19720073e-06
Iter: 78 loss: 1.18907667e-06
Iter: 79 loss: 1.21482458e-06
Iter: 80 loss: 1.18665821e-06
Iter: 81 loss: 1.17915704e-06
Iter: 82 loss: 1.23215523e-06
Iter: 83 loss: 1.17853335e-06
Iter: 84 loss: 1.17424588e-06
Iter: 85 loss: 1.19076833e-06
Iter: 86 loss: 1.17340278e-06
Iter: 87 loss: 1.16784361e-06
Iter: 88 loss: 1.1618348e-06
Iter: 89 loss: 1.16102524e-06
Iter: 90 loss: 1.15218268e-06
Iter: 91 loss: 1.17936247e-06
Iter: 92 loss: 1.14964951e-06
Iter: 93 loss: 1.14314e-06
Iter: 94 loss: 1.14729255e-06
Iter: 95 loss: 1.13925694e-06
Iter: 96 loss: 1.13276803e-06
Iter: 97 loss: 1.21969185e-06
Iter: 98 loss: 1.13271869e-06
Iter: 99 loss: 1.12812393e-06
Iter: 100 loss: 1.14819989e-06
Iter: 101 loss: 1.12718294e-06
Iter: 102 loss: 1.12343332e-06
Iter: 103 loss: 1.1165364e-06
Iter: 104 loss: 1.28460124e-06
Iter: 105 loss: 1.11652207e-06
Iter: 106 loss: 1.1092468e-06
Iter: 107 loss: 1.14759018e-06
Iter: 108 loss: 1.1080258e-06
Iter: 109 loss: 1.10262044e-06
Iter: 110 loss: 1.12704242e-06
Iter: 111 loss: 1.1015195e-06
Iter: 112 loss: 1.09614234e-06
Iter: 113 loss: 1.13274348e-06
Iter: 114 loss: 1.09565497e-06
Iter: 115 loss: 1.09131952e-06
Iter: 116 loss: 1.1107461e-06
Iter: 117 loss: 1.09069276e-06
Iter: 118 loss: 1.08801783e-06
Iter: 119 loss: 1.10501287e-06
Iter: 120 loss: 1.08779454e-06
Iter: 121 loss: 1.08591496e-06
Iter: 122 loss: 1.09028042e-06
Iter: 123 loss: 1.08519851e-06
Iter: 124 loss: 1.08283029e-06
Iter: 125 loss: 1.08207428e-06
Iter: 126 loss: 1.08064057e-06
Iter: 127 loss: 1.07781261e-06
Iter: 128 loss: 1.0819499e-06
Iter: 129 loss: 1.07651249e-06
Iter: 130 loss: 1.07394237e-06
Iter: 131 loss: 1.07312906e-06
Iter: 132 loss: 1.0715471e-06
Iter: 133 loss: 1.06995572e-06
Iter: 134 loss: 1.06935147e-06
Iter: 135 loss: 1.06768039e-06
Iter: 136 loss: 1.06505672e-06
Iter: 137 loss: 1.06506286e-06
Iter: 138 loss: 1.06107075e-06
Iter: 139 loss: 1.06738e-06
Iter: 140 loss: 1.0592081e-06
Iter: 141 loss: 1.05625179e-06
Iter: 142 loss: 1.07429469e-06
Iter: 143 loss: 1.05597428e-06
Iter: 144 loss: 1.05321237e-06
Iter: 145 loss: 1.05474714e-06
Iter: 146 loss: 1.05138042e-06
Iter: 147 loss: 1.04992864e-06
Iter: 148 loss: 1.04957144e-06
Iter: 149 loss: 1.04841126e-06
Iter: 150 loss: 1.05021741e-06
Iter: 151 loss: 1.04774267e-06
Iter: 152 loss: 1.04639798e-06
Iter: 153 loss: 1.0478492e-06
Iter: 154 loss: 1.04563492e-06
Iter: 155 loss: 1.04368735e-06
Iter: 156 loss: 1.04825449e-06
Iter: 157 loss: 1.04302512e-06
Iter: 158 loss: 1.04137666e-06
Iter: 159 loss: 1.04512196e-06
Iter: 160 loss: 1.04089577e-06
Iter: 161 loss: 1.03934826e-06
Iter: 162 loss: 1.03722687e-06
Iter: 163 loss: 1.03706952e-06
Iter: 164 loss: 1.03502634e-06
Iter: 165 loss: 1.06410994e-06
Iter: 166 loss: 1.0350476e-06
Iter: 167 loss: 1.0337335e-06
Iter: 168 loss: 1.03742275e-06
Iter: 169 loss: 1.03333116e-06
Iter: 170 loss: 1.0313147e-06
Iter: 171 loss: 1.03464572e-06
Iter: 172 loss: 1.03036768e-06
Iter: 173 loss: 1.02869899e-06
Iter: 174 loss: 1.02674164e-06
Iter: 175 loss: 1.0266001e-06
Iter: 176 loss: 1.02342847e-06
Iter: 177 loss: 1.03887385e-06
Iter: 178 loss: 1.02291563e-06
Iter: 179 loss: 1.02057959e-06
Iter: 180 loss: 1.03051309e-06
Iter: 181 loss: 1.02019e-06
Iter: 182 loss: 1.01774253e-06
Iter: 183 loss: 1.03465914e-06
Iter: 184 loss: 1.01741114e-06
Iter: 185 loss: 1.01580292e-06
Iter: 186 loss: 1.02098375e-06
Iter: 187 loss: 1.01522153e-06
Iter: 188 loss: 1.01390947e-06
Iter: 189 loss: 1.01740602e-06
Iter: 190 loss: 1.01342891e-06
Iter: 191 loss: 1.01210185e-06
Iter: 192 loss: 1.01306023e-06
Iter: 193 loss: 1.01120747e-06
Iter: 194 loss: 1.00941338e-06
Iter: 195 loss: 1.00996488e-06
Iter: 196 loss: 1.00817431e-06
Iter: 197 loss: 1.0063435e-06
Iter: 198 loss: 1.01244359e-06
Iter: 199 loss: 1.00589671e-06
Iter: 200 loss: 1.00420357e-06
Iter: 201 loss: 1.00873353e-06
Iter: 202 loss: 1.00361e-06
Iter: 203 loss: 1.0020151e-06
Iter: 204 loss: 1.01804744e-06
Iter: 205 loss: 1.00199736e-06
Iter: 206 loss: 1.00077341e-06
Iter: 207 loss: 1.00325906e-06
Iter: 208 loss: 1.00028012e-06
Iter: 209 loss: 9.99132226e-07
Iter: 210 loss: 9.9854833e-07
Iter: 211 loss: 9.98051e-07
Iter: 212 loss: 9.96426593e-07
Iter: 213 loss: 1.00318255e-06
Iter: 214 loss: 9.9598094e-07
Iter: 215 loss: 9.94997094e-07
Iter: 216 loss: 1.00536045e-06
Iter: 217 loss: 9.94983793e-07
Iter: 218 loss: 9.93865683e-07
Iter: 219 loss: 9.97016741e-07
Iter: 220 loss: 9.93529625e-07
Iter: 221 loss: 9.92770651e-07
Iter: 222 loss: 9.9504075e-07
Iter: 223 loss: 9.92556807e-07
Iter: 224 loss: 9.91753268e-07
Iter: 225 loss: 9.91436082e-07
Iter: 226 loss: 9.90972467e-07
Iter: 227 loss: 9.89613e-07
Iter: 228 loss: 9.91556817e-07
Iter: 229 loss: 9.88971124e-07
Iter: 230 loss: 9.87731937e-07
Iter: 231 loss: 9.93780532e-07
Iter: 232 loss: 9.87524231e-07
Iter: 233 loss: 9.86489908e-07
Iter: 234 loss: 9.84916369e-07
Iter: 235 loss: 9.84902158e-07
Iter: 236 loss: 9.83919335e-07
Iter: 237 loss: 9.83760856e-07
Iter: 238 loss: 9.83068e-07
Iter: 239 loss: 9.87583689e-07
Iter: 240 loss: 9.82930487e-07
Iter: 241 loss: 9.82379788e-07
Iter: 242 loss: 9.81097401e-07
Iter: 243 loss: 1.00753346e-06
Iter: 244 loss: 9.81162202e-07
Iter: 245 loss: 9.79904712e-07
Iter: 246 loss: 9.89623118e-07
Iter: 247 loss: 9.79753395e-07
Iter: 248 loss: 9.78716571e-07
Iter: 249 loss: 9.78498861e-07
Iter: 250 loss: 9.77856871e-07
Iter: 251 loss: 9.77712716e-07
Iter: 252 loss: 9.7713064e-07
Iter: 253 loss: 9.767233e-07
Iter: 254 loss: 9.76275146e-07
Iter: 255 loss: 9.76150204e-07
Iter: 256 loss: 9.75303351e-07
Iter: 257 loss: 9.76061642e-07
Iter: 258 loss: 9.74850309e-07
Iter: 259 loss: 9.7391387e-07
Iter: 260 loss: 9.7703e-07
Iter: 261 loss: 9.73633405e-07
Iter: 262 loss: 9.73041551e-07
Iter: 263 loss: 9.75157491e-07
Iter: 264 loss: 9.72837597e-07
Iter: 265 loss: 9.72282692e-07
Iter: 266 loss: 9.72572934e-07
Iter: 267 loss: 9.71708232e-07
Iter: 268 loss: 9.70935844e-07
Iter: 269 loss: 9.71870691e-07
Iter: 270 loss: 9.70474275e-07
Iter: 271 loss: 9.69616e-07
Iter: 272 loss: 9.74468776e-07
Iter: 273 loss: 9.6935787e-07
Iter: 274 loss: 9.68473159e-07
Iter: 275 loss: 9.74067461e-07
Iter: 276 loss: 9.68313202e-07
Iter: 277 loss: 9.6757833e-07
Iter: 278 loss: 9.67384608e-07
Iter: 279 loss: 9.66894163e-07
Iter: 280 loss: 9.66051857e-07
Iter: 281 loss: 9.66004109e-07
Iter: 282 loss: 9.65399522e-07
Iter: 283 loss: 9.64331434e-07
Iter: 284 loss: 9.75745479e-07
Iter: 285 loss: 9.64272317e-07
Iter: 286 loss: 9.63519824e-07
Iter: 287 loss: 9.63553e-07
Iter: 288 loss: 9.63223101e-07
Iter: 289 loss: 9.6236522e-07
Iter: 290 loss: 9.77233412e-07
Iter: 291 loss: 9.62357603e-07
Iter: 292 loss: 9.61308388e-07
Iter: 293 loss: 9.64675337e-07
Iter: 294 loss: 9.61023829e-07
Iter: 295 loss: 9.60263606e-07
Iter: 296 loss: 9.62270406e-07
Iter: 297 loss: 9.59989393e-07
Iter: 298 loss: 9.59154704e-07
Iter: 299 loss: 9.59721092e-07
Iter: 300 loss: 9.58600367e-07
Iter: 301 loss: 9.57589e-07
Iter: 302 loss: 9.62472541e-07
Iter: 303 loss: 9.5745e-07
Iter: 304 loss: 9.5680025e-07
Iter: 305 loss: 9.56217e-07
Iter: 306 loss: 9.56078225e-07
Iter: 307 loss: 9.55491e-07
Iter: 308 loss: 9.5541111e-07
Iter: 309 loss: 9.54905886e-07
Iter: 310 loss: 9.55876885e-07
Iter: 311 loss: 9.5462633e-07
Iter: 312 loss: 9.54140774e-07
Iter: 313 loss: 9.53231279e-07
Iter: 314 loss: 9.53209508e-07
Iter: 315 loss: 9.5249203e-07
Iter: 316 loss: 9.59742692e-07
Iter: 317 loss: 9.5246105e-07
Iter: 318 loss: 9.51802235e-07
Iter: 319 loss: 9.54679876e-07
Iter: 320 loss: 9.51717766e-07
Iter: 321 loss: 9.50792867e-07
Iter: 322 loss: 9.54210918e-07
Iter: 323 loss: 9.50600338e-07
Iter: 324 loss: 9.50366712e-07
Iter: 325 loss: 9.50369554e-07
Iter: 326 loss: 9.50142294e-07
Iter: 327 loss: 9.49604328e-07
Iter: 328 loss: 9.49311e-07
Iter: 329 loss: 9.4912707e-07
Iter: 330 loss: 9.48425395e-07
Iter: 331 loss: 9.52784035e-07
Iter: 332 loss: 9.48335355e-07
Iter: 333 loss: 9.47864407e-07
Iter: 334 loss: 9.48227409e-07
Iter: 335 loss: 9.47448825e-07
Iter: 336 loss: 9.46748855e-07
Iter: 337 loss: 9.48520949e-07
Iter: 338 loss: 9.46452644e-07
Iter: 339 loss: 9.45795477e-07
Iter: 340 loss: 9.47749e-07
Iter: 341 loss: 9.45692193e-07
Iter: 342 loss: 9.44987733e-07
Iter: 343 loss: 9.48867864e-07
Iter: 344 loss: 9.44894794e-07
Iter: 345 loss: 9.44435897e-07
Iter: 346 loss: 9.4677722e-07
Iter: 347 loss: 9.4424081e-07
Iter: 348 loss: 9.43895657e-07
Iter: 349 loss: 9.44172029e-07
Iter: 350 loss: 9.4365663e-07
Iter: 351 loss: 9.43126224e-07
Iter: 352 loss: 9.43059547e-07
Iter: 353 loss: 9.4274094e-07
Iter: 354 loss: 9.42304609e-07
Iter: 355 loss: 9.42225881e-07
Iter: 356 loss: 9.41628741e-07
Iter: 357 loss: 9.43224791e-07
Iter: 358 loss: 9.41464805e-07
Iter: 359 loss: 9.41203496e-07
Iter: 360 loss: 9.40835662e-07
Iter: 361 loss: 9.40840209e-07
Iter: 362 loss: 9.40112329e-07
Iter: 363 loss: 9.4245172e-07
Iter: 364 loss: 9.39918209e-07
Iter: 365 loss: 9.39458801e-07
Iter: 366 loss: 9.40766881e-07
Iter: 367 loss: 9.39346364e-07
Iter: 368 loss: 9.38906794e-07
Iter: 369 loss: 9.392229e-07
Iter: 370 loss: 9.38566529e-07
Iter: 371 loss: 9.38017934e-07
Iter: 372 loss: 9.42854854e-07
Iter: 373 loss: 9.38005883e-07
Iter: 374 loss: 9.37657148e-07
Iter: 375 loss: 9.3710662e-07
Iter: 376 loss: 9.37177219e-07
Iter: 377 loss: 9.36473157e-07
Iter: 378 loss: 9.43985e-07
Iter: 379 loss: 9.36544211e-07
Iter: 380 loss: 9.36152389e-07
Iter: 381 loss: 9.39302595e-07
Iter: 382 loss: 9.36108165e-07
Iter: 383 loss: 9.3570219e-07
Iter: 384 loss: 9.35170817e-07
Iter: 385 loss: 9.35276375e-07
Iter: 386 loss: 9.34639445e-07
Iter: 387 loss: 9.38924472e-07
Iter: 388 loss: 9.34506886e-07
Iter: 389 loss: 9.34407751e-07
Iter: 390 loss: 9.34370291e-07
Iter: 391 loss: 9.34196521e-07
Iter: 392 loss: 9.33592844e-07
Iter: 393 loss: 9.38867174e-07
Iter: 394 loss: 9.33564479e-07
Iter: 395 loss: 9.33131332e-07
Iter: 396 loss: 9.36467131e-07
Iter: 397 loss: 9.33101944e-07
Iter: 398 loss: 9.3284649e-07
Iter: 399 loss: 9.33204774e-07
Iter: 400 loss: 9.32575347e-07
Iter: 401 loss: 9.32236844e-07
Iter: 402 loss: 9.33336651e-07
Iter: 403 loss: 9.3220217e-07
Iter: 404 loss: 9.317788e-07
Iter: 405 loss: 9.31855084e-07
Iter: 406 loss: 9.31632712e-07
Iter: 407 loss: 9.31122088e-07
Iter: 408 loss: 9.32748719e-07
Iter: 409 loss: 9.30949454e-07
Iter: 410 loss: 9.30526e-07
Iter: 411 loss: 9.31214515e-07
Iter: 412 loss: 9.30337194e-07
Iter: 413 loss: 9.29911209e-07
Iter: 414 loss: 9.30755846e-07
Iter: 415 loss: 9.2978928e-07
Iter: 416 loss: 9.2939348e-07
Iter: 417 loss: 9.35161665e-07
Iter: 418 loss: 9.29378416e-07
Iter: 419 loss: 9.29060434e-07
Iter: 420 loss: 9.29177418e-07
Iter: 421 loss: 9.2882658e-07
Iter: 422 loss: 9.28542e-07
Iter: 423 loss: 9.29529278e-07
Iter: 424 loss: 9.28429927e-07
Iter: 425 loss: 9.28053055e-07
Iter: 426 loss: 9.31132604e-07
Iter: 427 loss: 9.28033e-07
Iter: 428 loss: 9.27825965e-07
Iter: 429 loss: 9.27387077e-07
Iter: 430 loss: 9.27394296e-07
Iter: 431 loss: 9.27087967e-07
Iter: 432 loss: 9.27700569e-07
Iter: 433 loss: 9.27005544e-07
Iter: 434 loss: 9.26539656e-07
Iter: 435 loss: 9.27971598e-07
Iter: 436 loss: 9.26465873e-07
Iter: 437 loss: 9.26058249e-07
Iter: 438 loss: 9.27266683e-07
Iter: 439 loss: 9.26001348e-07
Iter: 440 loss: 9.2566836e-07
Iter: 441 loss: 9.25882148e-07
Iter: 442 loss: 9.25542508e-07
Iter: 443 loss: 9.25108111e-07
Iter: 444 loss: 9.2654318e-07
Iter: 445 loss: 9.25031031e-07
Iter: 446 loss: 9.24769097e-07
Iter: 447 loss: 9.25568315e-07
Iter: 448 loss: 9.24556e-07
Iter: 449 loss: 9.24156268e-07
Iter: 450 loss: 9.24334415e-07
Iter: 451 loss: 9.23930941e-07
Iter: 452 loss: 9.23586413e-07
Iter: 453 loss: 9.2816822e-07
Iter: 454 loss: 9.23637458e-07
Iter: 455 loss: 9.23261666e-07
Iter: 456 loss: 9.24135065e-07
Iter: 457 loss: 9.23170035e-07
Iter: 458 loss: 9.22948857e-07
Iter: 459 loss: 9.24712424e-07
Iter: 460 loss: 9.22866491e-07
Iter: 461 loss: 9.22585969e-07
Iter: 462 loss: 9.22680385e-07
Iter: 463 loss: 9.22444542e-07
Iter: 464 loss: 9.22204947e-07
Iter: 465 loss: 9.21964784e-07
Iter: 466 loss: 9.21954666e-07
Iter: 467 loss: 9.21561536e-07
Iter: 468 loss: 9.22163963e-07
Iter: 469 loss: 9.21253559e-07
Iter: 470 loss: 9.20906928e-07
Iter: 471 loss: 9.25102427e-07
Iter: 472 loss: 9.20881746e-07
Iter: 473 loss: 9.20555863e-07
Iter: 474 loss: 9.19980778e-07
Iter: 475 loss: 9.20046091e-07
Iter: 476 loss: 9.19533363e-07
Iter: 477 loss: 9.24522226e-07
Iter: 478 loss: 9.19459524e-07
Iter: 479 loss: 9.19117497e-07
Iter: 480 loss: 9.19314232e-07
Iter: 481 loss: 9.18757223e-07
Iter: 482 loss: 9.18175147e-07
Iter: 483 loss: 9.21132084e-07
Iter: 484 loss: 9.18204364e-07
Iter: 485 loss: 9.17884e-07
Iter: 486 loss: 9.17772809e-07
Iter: 487 loss: 9.17530258e-07
Iter: 488 loss: 9.172727e-07
Iter: 489 loss: 9.17228704e-07
Iter: 490 loss: 9.17016223e-07
Iter: 491 loss: 9.18124556e-07
Iter: 492 loss: 9.16910551e-07
Iter: 493 loss: 9.16675333e-07
Iter: 494 loss: 9.17050443e-07
Iter: 495 loss: 9.16574436e-07
Iter: 496 loss: 9.16382248e-07
Iter: 497 loss: 9.16000943e-07
Iter: 498 loss: 9.16040165e-07
Iter: 499 loss: 9.15668124e-07
Iter: 500 loss: 9.17635e-07
Iter: 501 loss: 9.15513283e-07
Iter: 502 loss: 9.15287956e-07
Iter: 503 loss: 9.15698536e-07
Iter: 504 loss: 9.15075475e-07
Iter: 505 loss: 9.14779434e-07
Iter: 506 loss: 9.15548185e-07
Iter: 507 loss: 9.14643124e-07
Iter: 508 loss: 9.14104248e-07
Iter: 509 loss: 9.15397436e-07
Iter: 510 loss: 9.1405991e-07
Iter: 511 loss: 9.13676672e-07
Iter: 512 loss: 9.14398925e-07
Iter: 513 loss: 9.1355173e-07
Iter: 514 loss: 9.13154622e-07
Iter: 515 loss: 9.13746192e-07
Iter: 516 loss: 9.12946859e-07
Iter: 517 loss: 9.12614382e-07
Iter: 518 loss: 9.15483e-07
Iter: 519 loss: 9.12480346e-07
Iter: 520 loss: 9.12181065e-07
Iter: 521 loss: 9.11780717e-07
Iter: 522 loss: 9.11835059e-07
Iter: 523 loss: 9.11683458e-07
Iter: 524 loss: 9.11538109e-07
Iter: 525 loss: 9.11305619e-07
Iter: 526 loss: 9.11754285e-07
Iter: 527 loss: 9.11243433e-07
Iter: 528 loss: 9.11064603e-07
Iter: 529 loss: 9.105853e-07
Iter: 530 loss: 9.19671379e-07
Iter: 531 loss: 9.10676363e-07
Iter: 532 loss: 9.10064784e-07
Iter: 533 loss: 9.12188057e-07
Iter: 534 loss: 9.09971163e-07
Iter: 535 loss: 9.09714913e-07
Iter: 536 loss: 9.0959378e-07
Iter: 537 loss: 9.09462074e-07
Iter: 538 loss: 9.08845209e-07
Iter: 539 loss: 9.09598953e-07
Iter: 540 loss: 9.08595268e-07
Iter: 541 loss: 9.08278594e-07
Iter: 542 loss: 9.13337658e-07
Iter: 543 loss: 9.08295192e-07
Iter: 544 loss: 9.07919741e-07
Iter: 545 loss: 9.08647166e-07
Iter: 546 loss: 9.07768e-07
Iter: 547 loss: 9.07444701e-07
Iter: 548 loss: 9.08146092e-07
Iter: 549 loss: 9.07385e-07
Iter: 550 loss: 9.07039748e-07
Iter: 551 loss: 9.07574076e-07
Iter: 552 loss: 9.06888602e-07
Iter: 553 loss: 9.06481944e-07
Iter: 554 loss: 9.06705623e-07
Iter: 555 loss: 9.06216769e-07
Iter: 556 loss: 9.05813124e-07
Iter: 557 loss: 9.09127436e-07
Iter: 558 loss: 9.05782088e-07
Iter: 559 loss: 9.05507306e-07
Iter: 560 loss: 9.05535842e-07
Iter: 561 loss: 9.05368609e-07
Iter: 562 loss: 9.04992476e-07
Iter: 563 loss: 9.04972126e-07
Iter: 564 loss: 9.04631634e-07
Iter: 565 loss: 9.05356842e-07
Iter: 566 loss: 9.04473e-07
Iter: 567 loss: 9.04134708e-07
Iter: 568 loss: 9.04171031e-07
Iter: 569 loss: 9.038489e-07
Iter: 570 loss: 9.03447358e-07
Iter: 571 loss: 9.0709068e-07
Iter: 572 loss: 9.03432e-07
Iter: 573 loss: 9.03110958e-07
Iter: 574 loss: 9.03665239e-07
Iter: 575 loss: 9.02990905e-07
Iter: 576 loss: 9.02598174e-07
Iter: 577 loss: 9.02524903e-07
Iter: 578 loss: 9.02285763e-07
Iter: 579 loss: 9.01917e-07
Iter: 580 loss: 9.01944418e-07
Iter: 581 loss: 9.01705732e-07
Iter: 582 loss: 9.01880298e-07
Iter: 583 loss: 9.015e-07
Iter: 584 loss: 9.01164242e-07
Iter: 585 loss: 9.01863871e-07
Iter: 586 loss: 9.01047542e-07
Iter: 587 loss: 9.00810676e-07
Iter: 588 loss: 9.00875e-07
Iter: 589 loss: 9.00710802e-07
Iter: 590 loss: 9.00380826e-07
Iter: 591 loss: 9.0038975e-07
Iter: 592 loss: 9.0014737e-07
Iter: 593 loss: 9.01584485e-07
Iter: 594 loss: 9.00141345e-07
Iter: 595 loss: 9.00003e-07
Iter: 596 loss: 8.99802e-07
Iter: 597 loss: 9.03773582e-07
Iter: 598 loss: 8.99835072e-07
Iter: 599 loss: 8.99495092e-07
Iter: 600 loss: 8.99783231e-07
Iter: 601 loss: 8.99220424e-07
Iter: 602 loss: 8.98974577e-07
Iter: 603 loss: 9.01080512e-07
Iter: 604 loss: 8.98829171e-07
Iter: 605 loss: 8.98597875e-07
Iter: 606 loss: 8.98934843e-07
Iter: 607 loss: 8.98401083e-07
Iter: 608 loss: 8.98032056e-07
Iter: 609 loss: 8.9900152e-07
Iter: 610 loss: 8.97871189e-07
Iter: 611 loss: 8.97538939e-07
Iter: 612 loss: 8.99449674e-07
Iter: 613 loss: 8.97490509e-07
Iter: 614 loss: 8.97236589e-07
Iter: 615 loss: 8.97116252e-07
Iter: 616 loss: 8.96939582e-07
Iter: 617 loss: 8.96582776e-07
Iter: 618 loss: 8.99695294e-07
Iter: 619 loss: 8.96542247e-07
Iter: 620 loss: 8.96271217e-07
Iter: 621 loss: 8.97234202e-07
Iter: 622 loss: 8.96236884e-07
Iter: 623 loss: 8.95966139e-07
Iter: 624 loss: 8.9548746e-07
Iter: 625 loss: 8.95544645e-07
Iter: 626 loss: 8.95593246e-07
Iter: 627 loss: 8.95342737e-07
Iter: 628 loss: 8.95229675e-07
Iter: 629 loss: 8.95384915e-07
Iter: 630 loss: 8.9502754e-07
Iter: 631 loss: 8.9490868e-07
Iter: 632 loss: 8.9449162e-07
Iter: 633 loss: 8.99444501e-07
Iter: 634 loss: 8.94432844e-07
Iter: 635 loss: 8.94120546e-07
Iter: 636 loss: 8.95996834e-07
Iter: 637 loss: 8.94152265e-07
Iter: 638 loss: 8.93881179e-07
Iter: 639 loss: 8.94868663e-07
Iter: 640 loss: 8.93782044e-07
Iter: 641 loss: 8.93548e-07
Iter: 642 loss: 8.9414749e-07
Iter: 643 loss: 8.93416427e-07
Iter: 644 loss: 8.93182346e-07
Iter: 645 loss: 8.93387323e-07
Iter: 646 loss: 8.93029664e-07
Iter: 647 loss: 8.92732885e-07
Iter: 648 loss: 8.94000323e-07
Iter: 649 loss: 8.92615333e-07
Iter: 650 loss: 8.92329695e-07
Iter: 651 loss: 8.9328023e-07
Iter: 652 loss: 8.92287289e-07
Iter: 653 loss: 8.91927243e-07
Iter: 654 loss: 8.92156379e-07
Iter: 655 loss: 8.91733237e-07
Iter: 656 loss: 8.91358809e-07
Iter: 657 loss: 8.92621586e-07
Iter: 658 loss: 8.91254615e-07
Iter: 659 loss: 8.9088951e-07
Iter: 660 loss: 8.92757612e-07
Iter: 661 loss: 8.90925776e-07
Iter: 662 loss: 8.90589831e-07
Iter: 663 loss: 8.90810384e-07
Iter: 664 loss: 8.90338e-07
Iter: 665 loss: 8.903246e-07
Iter: 666 loss: 8.90180104e-07
Iter: 667 loss: 8.90015656e-07
Iter: 668 loss: 8.89731439e-07
Iter: 669 loss: 8.94943696e-07
Iter: 670 loss: 8.89723e-07
Iter: 671 loss: 8.89360081e-07
Iter: 672 loss: 8.89114631e-07
Iter: 673 loss: 8.89012426e-07
Iter: 674 loss: 8.88788691e-07
Iter: 675 loss: 8.88799548e-07
Iter: 676 loss: 8.88487591e-07
Iter: 677 loss: 8.88676141e-07
Iter: 678 loss: 8.88375951e-07
Iter: 679 loss: 8.88029e-07
Iter: 680 loss: 8.89025785e-07
Iter: 681 loss: 8.879e-07
Iter: 682 loss: 8.87801889e-07
Iter: 683 loss: 8.88460647e-07
Iter: 684 loss: 8.87630506e-07
Iter: 685 loss: 8.87402734e-07
Iter: 686 loss: 8.87610554e-07
Iter: 687 loss: 8.87202077e-07
Iter: 688 loss: 8.87047634e-07
Iter: 689 loss: 8.88370209e-07
Iter: 690 loss: 8.87016938e-07
Iter: 691 loss: 8.86674457e-07
Iter: 692 loss: 8.86660587e-07
Iter: 693 loss: 8.8652871e-07
Iter: 694 loss: 8.86244834e-07
Iter: 695 loss: 8.88057286e-07
Iter: 696 loss: 8.86132568e-07
Iter: 697 loss: 8.85970678e-07
Iter: 698 loss: 8.8751716e-07
Iter: 699 loss: 8.85923441e-07
Iter: 700 loss: 8.85754901e-07
Iter: 701 loss: 8.88101e-07
Iter: 702 loss: 8.85783038e-07
Iter: 703 loss: 8.85691804e-07
Iter: 704 loss: 8.85315842e-07
Iter: 705 loss: 8.88719342e-07
Iter: 706 loss: 8.85285658e-07
Iter: 707 loss: 8.85130476e-07
Iter: 708 loss: 8.8556942e-07
Iter: 709 loss: 8.84884798e-07
Iter: 710 loss: 8.84608312e-07
Iter: 711 loss: 8.85083523e-07
Iter: 712 loss: 8.84416e-07
Iter: 713 loss: 8.84107465e-07
Iter: 714 loss: 8.86103237e-07
Iter: 715 loss: 8.84059489e-07
Iter: 716 loss: 8.83724e-07
Iter: 717 loss: 8.84563462e-07
Iter: 718 loss: 8.83687562e-07
Iter: 719 loss: 8.83286305e-07
Iter: 720 loss: 8.83342864e-07
Iter: 721 loss: 8.83169037e-07
Iter: 722 loss: 8.82733332e-07
Iter: 723 loss: 8.84781e-07
Iter: 724 loss: 8.82651932e-07
Iter: 725 loss: 8.82291829e-07
Iter: 726 loss: 8.83520556e-07
Iter: 727 loss: 8.82162738e-07
Iter: 728 loss: 8.81783649e-07
Iter: 729 loss: 8.82239192e-07
Iter: 730 loss: 8.81648873e-07
Iter: 731 loss: 8.81305141e-07
Iter: 732 loss: 8.82717302e-07
Iter: 733 loss: 8.81178892e-07
Iter: 734 loss: 8.80855623e-07
Iter: 735 loss: 8.84414249e-07
Iter: 736 loss: 8.80882e-07
Iter: 737 loss: 8.80676282e-07
Iter: 738 loss: 8.81621e-07
Iter: 739 loss: 8.80574589e-07
Iter: 740 loss: 8.80484777e-07
Iter: 741 loss: 8.80326866e-07
Iter: 742 loss: 8.80240236e-07
Iter: 743 loss: 8.8013087e-07
Iter: 744 loss: 8.79909521e-07
Iter: 745 loss: 8.79840684e-07
Iter: 746 loss: 8.79582728e-07
Iter: 747 loss: 8.83196265e-07
Iter: 748 loss: 8.79564425e-07
Iter: 749 loss: 8.79387642e-07
Iter: 750 loss: 8.79435106e-07
Iter: 751 loss: 8.79295726e-07
Iter: 752 loss: 8.78964443e-07
Iter: 753 loss: 8.80913149e-07
Iter: 754 loss: 8.78959099e-07
Iter: 755 loss: 8.78762535e-07
Iter: 756 loss: 8.7857245e-07
Iter: 757 loss: 8.78588196e-07
Iter: 758 loss: 8.78125945e-07
Iter: 759 loss: 8.79351e-07
Iter: 760 loss: 8.77920684e-07
Iter: 761 loss: 8.77717412e-07
Iter: 762 loss: 8.80662242e-07
Iter: 763 loss: 8.77699335e-07
Iter: 764 loss: 8.77458319e-07
Iter: 765 loss: 8.7732235e-07
Iter: 766 loss: 8.77217246e-07
Iter: 767 loss: 8.76921547e-07
Iter: 768 loss: 8.78422611e-07
Iter: 769 loss: 8.76836282e-07
Iter: 770 loss: 8.76880904e-07
Iter: 771 loss: 8.76771e-07
Iter: 772 loss: 8.76678826e-07
Iter: 773 loss: 8.76406546e-07
Iter: 774 loss: 8.78628725e-07
Iter: 775 loss: 8.76409e-07
Iter: 776 loss: 8.76169338e-07
Iter: 777 loss: 8.77245043e-07
Iter: 778 loss: 8.7606918e-07
Iter: 779 loss: 8.75971182e-07
Iter: 780 loss: 8.76186732e-07
Iter: 781 loss: 8.75840556e-07
Iter: 782 loss: 8.75583851e-07
Iter: 783 loss: 8.75846297e-07
Iter: 784 loss: 8.75444812e-07
Iter: 785 loss: 8.75181286e-07
Iter: 786 loss: 8.75673322e-07
Iter: 787 loss: 8.75184583e-07
Iter: 788 loss: 8.74857449e-07
Iter: 789 loss: 8.76716967e-07
Iter: 790 loss: 8.74901218e-07
Iter: 791 loss: 8.74620468e-07
Iter: 792 loss: 8.75312423e-07
Iter: 793 loss: 8.74602279e-07
Iter: 794 loss: 8.744193e-07
Iter: 795 loss: 8.74533214e-07
Iter: 796 loss: 8.7426514e-07
Iter: 797 loss: 8.74069656e-07
Iter: 798 loss: 8.74608588e-07
Iter: 799 loss: 8.73926808e-07
Iter: 800 loss: 8.73734905e-07
Iter: 801 loss: 8.7594259e-07
Iter: 802 loss: 8.73701083e-07
Iter: 803 loss: 8.73473255e-07
Iter: 804 loss: 8.73650151e-07
Iter: 805 loss: 8.73405895e-07
Iter: 806 loss: 8.73233375e-07
Iter: 807 loss: 8.73242698e-07
Iter: 808 loss: 8.73128045e-07
Iter: 809 loss: 8.72934436e-07
Iter: 810 loss: 8.77678076e-07
Iter: 811 loss: 8.72975079e-07
Iter: 812 loss: 8.7273e-07
Iter: 813 loss: 8.73135605e-07
Iter: 814 loss: 8.72669091e-07
Iter: 815 loss: 8.72491228e-07
Iter: 816 loss: 8.72435919e-07
Iter: 817 loss: 8.72311546e-07
Iter: 818 loss: 8.72035059e-07
Iter: 819 loss: 8.74144234e-07
Iter: 820 loss: 8.71962811e-07
Iter: 821 loss: 8.71761699e-07
Iter: 822 loss: 8.71456791e-07
Iter: 823 loss: 8.7149931e-07
Iter: 824 loss: 8.71084467e-07
Iter: 825 loss: 8.71084353e-07
Iter: 826 loss: 8.70862777e-07
Iter: 827 loss: 8.710727e-07
Iter: 828 loss: 8.70791837e-07
Iter: 829 loss: 8.70541896e-07
Iter: 830 loss: 8.71124371e-07
Iter: 831 loss: 8.70458166e-07
Iter: 832 loss: 8.70216468e-07
Iter: 833 loss: 8.70750853e-07
Iter: 834 loss: 8.70177189e-07
Iter: 835 loss: 8.69894961e-07
Iter: 836 loss: 8.7088705e-07
Iter: 837 loss: 8.69927305e-07
Iter: 838 loss: 8.69765131e-07
Iter: 839 loss: 8.71699399e-07
Iter: 840 loss: 8.69768769e-07
Iter: 841 loss: 8.696029e-07
Iter: 842 loss: 8.70284339e-07
Iter: 843 loss: 8.69563564e-07
Iter: 844 loss: 8.69491203e-07
Iter: 845 loss: 8.69332951e-07
Iter: 846 loss: 8.7167291e-07
Iter: 847 loss: 8.69288897e-07
Iter: 848 loss: 8.6916009e-07
Iter: 849 loss: 8.70071688e-07
Iter: 850 loss: 8.69069879e-07
Iter: 851 loss: 8.68959e-07
Iter: 852 loss: 8.69192377e-07
Iter: 853 loss: 8.68869222e-07
Iter: 854 loss: 8.68688289e-07
Iter: 855 loss: 8.69074313e-07
Iter: 856 loss: 8.68621441e-07
Iter: 857 loss: 8.68410268e-07
Iter: 858 loss: 8.68823747e-07
Iter: 859 loss: 8.68317102e-07
Iter: 860 loss: 8.6809149e-07
Iter: 861 loss: 8.68701e-07
Iter: 862 loss: 8.68081429e-07
Iter: 863 loss: 8.67815459e-07
Iter: 864 loss: 8.68192501e-07
Iter: 865 loss: 8.67707172e-07
Iter: 866 loss: 8.67391577e-07
Iter: 867 loss: 8.68466202e-07
Iter: 868 loss: 8.67371114e-07
Iter: 869 loss: 8.67148117e-07
Iter: 870 loss: 8.67120605e-07
Iter: 871 loss: 8.66964513e-07
Iter: 872 loss: 8.66810694e-07
Iter: 873 loss: 8.66761354e-07
Iter: 874 loss: 8.66716846e-07
Iter: 875 loss: 8.67898621e-07
Iter: 876 loss: 8.66730772e-07
Iter: 877 loss: 8.66639425e-07
Iter: 878 loss: 8.66445e-07
Iter: 879 loss: 8.69131725e-07
Iter: 880 loss: 8.66377036e-07
Iter: 881 loss: 8.66238e-07
Iter: 882 loss: 8.66286655e-07
Iter: 883 loss: 8.66147843e-07
Iter: 884 loss: 8.65930588e-07
Iter: 885 loss: 8.66659e-07
Iter: 886 loss: 8.65926e-07
Iter: 887 loss: 8.65750394e-07
Iter: 888 loss: 8.65740276e-07
Iter: 889 loss: 8.65546212e-07
Iter: 890 loss: 8.65355332e-07
Iter: 891 loss: 8.67338e-07
Iter: 892 loss: 8.65311847e-07
Iter: 893 loss: 8.65179572e-07
Iter: 894 loss: 8.65138588e-07
Iter: 895 loss: 8.65028539e-07
Iter: 896 loss: 8.6484431e-07
Iter: 897 loss: 8.66177857e-07
Iter: 898 loss: 8.6477371e-07
Iter: 899 loss: 8.64589254e-07
Iter: 900 loss: 8.64977039e-07
Iter: 901 loss: 8.64544063e-07
Iter: 902 loss: 8.64346646e-07
Iter: 903 loss: 8.6492571e-07
Iter: 904 loss: 8.64247284e-07
Iter: 905 loss: 8.64104209e-07
Iter: 906 loss: 8.64306685e-07
Iter: 907 loss: 8.6396625e-07
Iter: 908 loss: 8.63901903e-07
Iter: 909 loss: 8.66209e-07
Iter: 910 loss: 8.63820617e-07
Iter: 911 loss: 8.63610126e-07
Iter: 912 loss: 8.64624e-07
Iter: 913 loss: 8.63585285e-07
Iter: 914 loss: 8.63499963e-07
Iter: 915 loss: 8.63330513e-07
Iter: 916 loss: 8.63257469e-07
Iter: 917 loss: 8.63188689e-07
Iter: 918 loss: 8.63473872e-07
Iter: 919 loss: 8.63057608e-07
Iter: 920 loss: 8.62966203e-07
Iter: 921 loss: 8.62825686e-07
Iter: 922 loss: 8.62790046e-07
Iter: 923 loss: 8.62477407e-07
Iter: 924 loss: 8.65065715e-07
Iter: 925 loss: 8.62473314e-07
Iter: 926 loss: 8.62257821e-07
Iter: 927 loss: 8.62359741e-07
Iter: 928 loss: 8.62189381e-07
Iter: 929 loss: 8.61919148e-07
Iter: 930 loss: 8.62737693e-07
Iter: 931 loss: 8.61760668e-07
Iter: 932 loss: 8.61610488e-07
Iter: 933 loss: 8.62070294e-07
Iter: 934 loss: 8.61487365e-07
Iter: 935 loss: 8.61262606e-07
Iter: 936 loss: 8.62397883e-07
Iter: 937 loss: 8.61276078e-07
Iter: 938 loss: 8.61138119e-07
Iter: 939 loss: 8.62011632e-07
Iter: 940 loss: 8.6111578e-07
Iter: 941 loss: 8.61056776e-07
Iter: 942 loss: 8.60958e-07
Iter: 943 loss: 8.60864702e-07
Iter: 944 loss: 8.60877321e-07
Iter: 945 loss: 8.60795637e-07
Iter: 946 loss: 8.60791e-07
Iter: 947 loss: 8.60664272e-07
Iter: 948 loss: 8.60715772e-07
Iter: 949 loss: 8.60552e-07
Iter: 950 loss: 8.6048567e-07
Iter: 951 loss: 8.60503235e-07
Iter: 952 loss: 8.60277794e-07
Iter: 953 loss: 8.61027274e-07
Iter: 954 loss: 8.60282739e-07
Iter: 955 loss: 8.60093792e-07
Iter: 956 loss: 8.59996533e-07
Iter: 957 loss: 8.59919396e-07
Iter: 958 loss: 8.59625573e-07
Iter: 959 loss: 8.60567127e-07
Iter: 960 loss: 8.59651323e-07
Iter: 961 loss: 8.59467093e-07
Iter: 962 loss: 8.60685816e-07
Iter: 963 loss: 8.59484203e-07
Iter: 964 loss: 8.59347836e-07
Iter: 965 loss: 8.59162697e-07
Iter: 966 loss: 8.59100965e-07
Iter: 967 loss: 8.58916678e-07
Iter: 968 loss: 8.6005889e-07
Iter: 969 loss: 8.58824365e-07
Iter: 970 loss: 8.58722615e-07
Iter: 971 loss: 8.58739497e-07
Iter: 972 loss: 8.5859557e-07
Iter: 973 loss: 8.58256271e-07
Iter: 974 loss: 8.59124555e-07
Iter: 975 loss: 8.58195676e-07
Iter: 976 loss: 8.57991211e-07
Iter: 977 loss: 8.59804913e-07
Iter: 978 loss: 8.57970804e-07
Iter: 979 loss: 8.57900773e-07
Iter: 980 loss: 8.57847681e-07
Iter: 981 loss: 8.57795669e-07
Iter: 982 loss: 8.57714667e-07
Iter: 983 loss: 8.57661348e-07
Iter: 984 loss: 8.57580346e-07
Iter: 985 loss: 8.57546695e-07
Iter: 986 loss: 8.5746484e-07
Iter: 987 loss: 8.57243e-07
Iter: 988 loss: 8.57646739e-07
Iter: 989 loss: 8.57226e-07
Iter: 990 loss: 8.57062787e-07
Iter: 991 loss: 8.57584894e-07
Iter: 992 loss: 8.56993381e-07
Iter: 993 loss: 8.56897316e-07
Iter: 994 loss: 8.573885e-07
Iter: 995 loss: 8.56840757e-07
Iter: 996 loss: 8.56555289e-07
Iter: 997 loss: 8.56623217e-07
Iter: 998 loss: 8.56524082e-07
Iter: 999 loss: 8.56315182e-07
Iter: 1000 loss: 8.57598479e-07
Iter: 1001 loss: 8.56309725e-07
Iter: 1002 loss: 8.56197914e-07
Iter: 1003 loss: 8.55976509e-07
Iter: 1004 loss: 8.55953431e-07
Iter: 1005 loss: 8.55815e-07
Iter: 1006 loss: 8.557966e-07
Iter: 1007 loss: 8.55656936e-07
Iter: 1008 loss: 8.55322583e-07
Iter: 1009 loss: 8.61819217e-07
Iter: 1010 loss: 8.55323094e-07
Iter: 1011 loss: 8.5519855e-07
Iter: 1012 loss: 8.5522646e-07
Iter: 1013 loss: 8.55077076e-07
Iter: 1014 loss: 8.57128384e-07
Iter: 1015 loss: 8.55078838e-07
Iter: 1016 loss: 8.55027281e-07
Iter: 1017 loss: 8.54901373e-07
Iter: 1018 loss: 8.57101497e-07
Iter: 1019 loss: 8.54792745e-07
Iter: 1020 loss: 8.54615337e-07
Iter: 1021 loss: 8.56348436e-07
Iter: 1022 loss: 8.54638415e-07
Iter: 1023 loss: 8.54482892e-07
Iter: 1024 loss: 8.54492953e-07
Iter: 1025 loss: 8.54439918e-07
Iter: 1026 loss: 8.54259383e-07
Iter: 1027 loss: 8.5466047e-07
Iter: 1028 loss: 8.54055315e-07
Iter: 1029 loss: 8.53947654e-07
Iter: 1030 loss: 8.54912287e-07
Iter: 1031 loss: 8.53959818e-07
Iter: 1032 loss: 8.53797815e-07
Iter: 1033 loss: 8.53860058e-07
Iter: 1034 loss: 8.53713857e-07
Iter: 1035 loss: 8.53477104e-07
Iter: 1036 loss: 8.53992105e-07
Iter: 1037 loss: 8.53460051e-07
Iter: 1038 loss: 8.53280369e-07
Iter: 1039 loss: 8.53340339e-07
Iter: 1040 loss: 8.53110691e-07
Iter: 1041 loss: 8.52887922e-07
Iter: 1042 loss: 8.54448331e-07
Iter: 1043 loss: 8.52903895e-07
Iter: 1044 loss: 8.52688515e-07
Iter: 1045 loss: 8.53643542e-07
Iter: 1046 loss: 8.52773326e-07
Iter: 1047 loss: 8.52586425e-07
Iter: 1048 loss: 8.53160202e-07
Iter: 1049 loss: 8.52529183e-07
Iter: 1050 loss: 8.52426865e-07
Iter: 1051 loss: 8.52967787e-07
Iter: 1052 loss: 8.52395374e-07
Iter: 1053 loss: 8.523715e-07
Iter: 1054 loss: 8.52060055e-07
Iter: 1055 loss: 8.52153107e-07
Iter: 1056 loss: 8.51989228e-07
Iter: 1057 loss: 8.52094956e-07
Iter: 1058 loss: 8.5181307e-07
Iter: 1059 loss: 8.51606956e-07
Iter: 1060 loss: 8.5273723e-07
Iter: 1061 loss: 8.51565233e-07
Iter: 1062 loss: 8.51430059e-07
Iter: 1063 loss: 8.51765549e-07
Iter: 1064 loss: 8.513436e-07
Iter: 1065 loss: 8.51104e-07
Iter: 1066 loss: 8.51229743e-07
Iter: 1067 loss: 8.50998788e-07
Iter: 1068 loss: 8.50775677e-07
Iter: 1069 loss: 8.53287e-07
Iter: 1070 loss: 8.50682227e-07
Iter: 1071 loss: 8.50609e-07
Iter: 1072 loss: 8.50408185e-07
Iter: 1073 loss: 8.50335255e-07
Iter: 1074 loss: 8.5006161e-07
Iter: 1075 loss: 8.51822278e-07
Iter: 1076 loss: 8.50088611e-07
Iter: 1077 loss: 8.49876244e-07
Iter: 1078 loss: 8.50148467e-07
Iter: 1079 loss: 8.49800131e-07
Iter: 1080 loss: 8.49631476e-07
Iter: 1081 loss: 8.51312336e-07
Iter: 1082 loss: 8.49595267e-07
Iter: 1083 loss: 8.49511935e-07
Iter: 1084 loss: 8.49600326e-07
Iter: 1085 loss: 8.49535866e-07
Iter: 1086 loss: 8.4952444e-07
Iter: 1087 loss: 8.49505284e-07
Iter: 1088 loss: 8.49469643e-07
Iter: 1089 loss: 8.49500168e-07
Iter: 1090 loss: 8.49567698e-07
Iter: 1091 loss: 8.49565311e-07
Iter: 1092 loss: 8.49539674e-07
Iter: 1093 loss: 8.49536207e-07
Iter: 1094 loss: 8.49530693e-07
Iter: 1095 loss: 8.49585604e-07
Iter: 1096 loss: 8.49577532e-07
Iter: 1097 loss: 8.49568551e-07
Iter: 1098 loss: 8.49581966e-07
Iter: 1099 loss: 8.49611183e-07
Iter: 1100 loss: 8.49600838e-07
Iter: 1101 loss: 8.49605385e-07
Iter: 1102 loss: 8.49577532e-07
Iter: 1103 loss: 8.49594187e-07
Iter: 1104 loss: 8.49600383e-07
Iter: 1105 loss: 8.49593505e-07
Iter: 1106 loss: 8.49593107e-07
Iter: 1107 loss: 8.49597768e-07
Iter: 1108 loss: 8.49595e-07
Iter: 1109 loss: 8.49597768e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi0_phi3/300_100_100_100_1
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0
+ date
Sat Nov  7 23:23:44 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1 --function f1 --psi 1 --phi 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c536a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c21488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c53bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5d4de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c96048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c71d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5bd1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5bd1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c71d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5ae87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5ae8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5aaa378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c719d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5b5bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5aaac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5c71950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5a3b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5a1c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5a7b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecfd90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecfd9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecf88e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecf5f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecf69f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecf70488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecf707b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5b74b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87f5b74d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ece80488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ece80f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ece80620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ece4bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ece4b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ed01be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecd78400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f87ecd96e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0017627226
test_loss: 0.001731871
train_loss: 0.0018746128
test_loss: 0.0018748816
train_loss: 0.0017830019
test_loss: 0.0019405216
train_loss: 0.001687341
test_loss: 0.0020070064
train_loss: 0.0017368714
test_loss: 0.0019355101
train_loss: 0.0018643112
test_loss: 0.0018940091
train_loss: 0.001743909
test_loss: 0.0018685193
train_loss: 0.0018400254
test_loss: 0.0017502292
train_loss: 0.0018537773
test_loss: 0.0018276648
train_loss: 0.00185027
test_loss: 0.0018574293
train_loss: 0.001760981
test_loss: 0.0017535298
train_loss: 0.0018995698
test_loss: 0.0022883546
train_loss: 0.0017816327
test_loss: 0.0018716689
train_loss: 0.0017481815
test_loss: 0.0017537342
train_loss: 0.0017354791
test_loss: 0.0017103786
train_loss: 0.0017991357
test_loss: 0.0018004299
train_loss: 0.0016785702
test_loss: 0.0016527091
train_loss: 0.0017979883
test_loss: 0.0017856596
train_loss: 0.0017665984
test_loss: 0.0018909989
train_loss: 0.0017124652
test_loss: 0.0018397468
train_loss: 0.0018337319
test_loss: 0.0017458663
train_loss: 0.0018643178
test_loss: 0.0017027487
train_loss: 0.0017865617
test_loss: 0.001736674
train_loss: 0.0016743352
test_loss: 0.0018148423
train_loss: 0.0018741337
test_loss: 0.0018454781
train_loss: 0.0020375894
test_loss: 0.0017917516
train_loss: 0.0016052083
test_loss: 0.0018069312
train_loss: 0.0017865616
test_loss: 0.0016597279
train_loss: 0.0017008662
test_loss: 0.0017044549
train_loss: 0.0017553514
test_loss: 0.0018978743
train_loss: 0.001954615
test_loss: 0.0017594284
train_loss: 0.0017127322
test_loss: 0.0016829625
train_loss: 0.0016210718
test_loss: 0.0017610933
train_loss: 0.0018898377
test_loss: 0.001750259
train_loss: 0.0016903426
test_loss: 0.0018119352
train_loss: 0.0019366811
test_loss: 0.0018617299
train_loss: 0.0015563703
test_loss: 0.0016870926
train_loss: 0.001893253
test_loss: 0.0018338194
train_loss: 0.0017002183
test_loss: 0.001867999
train_loss: 0.0019501878
test_loss: 0.0017483633
train_loss: 0.0017444994
test_loss: 0.0017192678
train_loss: 0.0016955694
test_loss: 0.0018458694
train_loss: 0.0017398447
test_loss: 0.0017198684
train_loss: 0.0015878002
test_loss: 0.0016931642
train_loss: 0.0018225963
test_loss: 0.001881297
train_loss: 0.0017396945
test_loss: 0.0017394987
train_loss: 0.0016476141
test_loss: 0.0017653775
train_loss: 0.0017690904
test_loss: 0.0016838859
train_loss: 0.0019090748
test_loss: 0.0019569625
train_loss: 0.0015442003
test_loss: 0.001683316
train_loss: 0.0018065542
test_loss: 0.0016856877
train_loss: 0.0016261765
test_loss: 0.0017798448
train_loss: 0.0016642201
test_loss: 0.0021416247
train_loss: 0.0017417767
test_loss: 0.0020520973
train_loss: 0.0019047585
test_loss: 0.0018241492
train_loss: 0.001733222
test_loss: 0.0020265682
train_loss: 0.0015459959
test_loss: 0.0016215686
train_loss: 0.0016896965
test_loss: 0.0017098875
train_loss: 0.0016602001
test_loss: 0.0017894163
train_loss: 0.0016326979
test_loss: 0.0017512955
train_loss: 0.0016474396
test_loss: 0.001605966
train_loss: 0.0016738784
test_loss: 0.0016740746
train_loss: 0.0017704035
test_loss: 0.0017178212
train_loss: 0.0016705889
test_loss: 0.0016485315
train_loss: 0.0018109663
test_loss: 0.0019485175
train_loss: 0.0015970208
test_loss: 0.0017079028
train_loss: 0.001737094
test_loss: 0.0017210364
train_loss: 0.0016231822
test_loss: 0.0017385831
train_loss: 0.0016640364
test_loss: 0.0017146203
train_loss: 0.0018494541
test_loss: 0.0018863956
train_loss: 0.001843473
test_loss: 0.0018529722
train_loss: 0.0015194366
test_loss: 0.0016052467
train_loss: 0.0016495358
test_loss: 0.0016874435
train_loss: 0.001672132
test_loss: 0.0018020747
train_loss: 0.0016850648
test_loss: 0.0020160081
train_loss: 0.0016415594
test_loss: 0.00173556
train_loss: 0.0016581565
test_loss: 0.0016041094
train_loss: 0.0017235152
test_loss: 0.0016293324
train_loss: 0.0017239276
test_loss: 0.0018693287
train_loss: 0.0016990667
test_loss: 0.0017263594
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984313d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98422d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98422d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984276268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9842762f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984276a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98427ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98427e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98427e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984179a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984190268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98427e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9841f7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984155ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984065840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984066d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98408a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98408a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff984054a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9840546a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98400a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff983fcd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bdd3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bdec9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bdecae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bdec950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bd9de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bd007b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bd1f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bd1fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bd2d048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bc848c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bcb20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bc517b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bc51ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff97bc049d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.39836822e-06
Iter: 2 loss: 6.07707079e-06
Iter: 3 loss: 3.69075701e-06
Iter: 4 loss: 3.37211236e-06
Iter: 5 loss: 4.04894763e-06
Iter: 6 loss: 3.24689586e-06
Iter: 7 loss: 3.13048326e-06
Iter: 8 loss: 2.95766176e-06
Iter: 9 loss: 2.95367113e-06
Iter: 10 loss: 2.99283056e-06
Iter: 11 loss: 2.86875638e-06
Iter: 12 loss: 2.83147892e-06
Iter: 13 loss: 2.81797611e-06
Iter: 14 loss: 2.79712822e-06
Iter: 15 loss: 2.76536593e-06
Iter: 16 loss: 3.02014e-06
Iter: 17 loss: 2.76325227e-06
Iter: 18 loss: 2.72581974e-06
Iter: 19 loss: 2.71696626e-06
Iter: 20 loss: 2.69295333e-06
Iter: 21 loss: 2.65548078e-06
Iter: 22 loss: 2.60942829e-06
Iter: 23 loss: 2.60524189e-06
Iter: 24 loss: 2.55300074e-06
Iter: 25 loss: 2.55076702e-06
Iter: 26 loss: 2.51034635e-06
Iter: 27 loss: 2.43916702e-06
Iter: 28 loss: 2.43916452e-06
Iter: 29 loss: 2.3674329e-06
Iter: 30 loss: 2.25074609e-06
Iter: 31 loss: 2.25002123e-06
Iter: 32 loss: 2.17742058e-06
Iter: 33 loss: 2.17034312e-06
Iter: 34 loss: 2.13100657e-06
Iter: 35 loss: 2.1306505e-06
Iter: 36 loss: 2.10116286e-06
Iter: 37 loss: 2.04208482e-06
Iter: 38 loss: 3.15606098e-06
Iter: 39 loss: 2.04124376e-06
Iter: 40 loss: 2.00811087e-06
Iter: 41 loss: 2.40443615e-06
Iter: 42 loss: 2.00769682e-06
Iter: 43 loss: 1.98347743e-06
Iter: 44 loss: 2.28067529e-06
Iter: 45 loss: 1.98320549e-06
Iter: 46 loss: 1.96616156e-06
Iter: 47 loss: 1.92923289e-06
Iter: 48 loss: 2.50269204e-06
Iter: 49 loss: 1.92790867e-06
Iter: 50 loss: 1.92960874e-06
Iter: 51 loss: 1.91198978e-06
Iter: 52 loss: 1.90246692e-06
Iter: 53 loss: 1.87988189e-06
Iter: 54 loss: 2.14054853e-06
Iter: 55 loss: 1.8778112e-06
Iter: 56 loss: 1.84537703e-06
Iter: 57 loss: 1.85434169e-06
Iter: 58 loss: 1.82194219e-06
Iter: 59 loss: 1.80129678e-06
Iter: 60 loss: 1.7951503e-06
Iter: 61 loss: 1.7843555e-06
Iter: 62 loss: 1.75086075e-06
Iter: 63 loss: 1.81767621e-06
Iter: 64 loss: 1.72984903e-06
Iter: 65 loss: 1.66857126e-06
Iter: 66 loss: 1.96753717e-06
Iter: 67 loss: 1.65786571e-06
Iter: 68 loss: 1.6313071e-06
Iter: 69 loss: 1.63081359e-06
Iter: 70 loss: 1.59827744e-06
Iter: 71 loss: 1.56374517e-06
Iter: 72 loss: 1.55800785e-06
Iter: 73 loss: 1.51370023e-06
Iter: 74 loss: 1.59902584e-06
Iter: 75 loss: 1.49519474e-06
Iter: 76 loss: 1.48323033e-06
Iter: 77 loss: 1.47971309e-06
Iter: 78 loss: 1.46334673e-06
Iter: 79 loss: 1.4438906e-06
Iter: 80 loss: 1.44179512e-06
Iter: 81 loss: 1.4294842e-06
Iter: 82 loss: 1.42947442e-06
Iter: 83 loss: 1.41850228e-06
Iter: 84 loss: 1.44200521e-06
Iter: 85 loss: 1.41418332e-06
Iter: 86 loss: 1.40603515e-06
Iter: 87 loss: 1.39290773e-06
Iter: 88 loss: 1.39276062e-06
Iter: 89 loss: 1.38547455e-06
Iter: 90 loss: 1.38415066e-06
Iter: 91 loss: 1.37550569e-06
Iter: 92 loss: 1.36640244e-06
Iter: 93 loss: 1.36480026e-06
Iter: 94 loss: 1.34969173e-06
Iter: 95 loss: 1.32515527e-06
Iter: 96 loss: 1.32498712e-06
Iter: 97 loss: 1.29667308e-06
Iter: 98 loss: 1.41798932e-06
Iter: 99 loss: 1.29083469e-06
Iter: 100 loss: 1.26865677e-06
Iter: 101 loss: 1.2680191e-06
Iter: 102 loss: 1.25597194e-06
Iter: 103 loss: 1.24591179e-06
Iter: 104 loss: 1.24254007e-06
Iter: 105 loss: 1.23038467e-06
Iter: 106 loss: 1.23862355e-06
Iter: 107 loss: 1.22278198e-06
Iter: 108 loss: 1.2085959e-06
Iter: 109 loss: 1.20841764e-06
Iter: 110 loss: 1.20293885e-06
Iter: 111 loss: 1.19692436e-06
Iter: 112 loss: 1.19605681e-06
Iter: 113 loss: 1.18860794e-06
Iter: 114 loss: 1.18858338e-06
Iter: 115 loss: 1.18263904e-06
Iter: 116 loss: 1.16858564e-06
Iter: 117 loss: 1.32636615e-06
Iter: 118 loss: 1.16725801e-06
Iter: 119 loss: 1.15823468e-06
Iter: 120 loss: 1.28892339e-06
Iter: 121 loss: 1.15821035e-06
Iter: 122 loss: 1.14971817e-06
Iter: 123 loss: 1.19954632e-06
Iter: 124 loss: 1.14863917e-06
Iter: 125 loss: 1.1423615e-06
Iter: 126 loss: 1.13360716e-06
Iter: 127 loss: 1.13325962e-06
Iter: 128 loss: 1.12576743e-06
Iter: 129 loss: 1.12816451e-06
Iter: 130 loss: 1.12041744e-06
Iter: 131 loss: 1.11479994e-06
Iter: 132 loss: 1.11385066e-06
Iter: 133 loss: 1.10782821e-06
Iter: 134 loss: 1.10300425e-06
Iter: 135 loss: 1.10115695e-06
Iter: 136 loss: 1.09236953e-06
Iter: 137 loss: 1.07702817e-06
Iter: 138 loss: 1.0770076e-06
Iter: 139 loss: 1.08140978e-06
Iter: 140 loss: 1.06941297e-06
Iter: 141 loss: 1.06407765e-06
Iter: 142 loss: 1.05364757e-06
Iter: 143 loss: 1.27085912e-06
Iter: 144 loss: 1.05360027e-06
Iter: 145 loss: 1.04741582e-06
Iter: 146 loss: 1.04717299e-06
Iter: 147 loss: 1.04086655e-06
Iter: 148 loss: 1.04036985e-06
Iter: 149 loss: 1.03560023e-06
Iter: 150 loss: 1.03139928e-06
Iter: 151 loss: 1.02773913e-06
Iter: 152 loss: 1.02660636e-06
Iter: 153 loss: 1.02524496e-06
Iter: 154 loss: 1.02347337e-06
Iter: 155 loss: 1.02118315e-06
Iter: 156 loss: 1.01839601e-06
Iter: 157 loss: 1.01812475e-06
Iter: 158 loss: 1.01424894e-06
Iter: 159 loss: 1.00880345e-06
Iter: 160 loss: 1.00858711e-06
Iter: 161 loss: 1.00234638e-06
Iter: 162 loss: 1.06446237e-06
Iter: 163 loss: 1.00214254e-06
Iter: 164 loss: 9.98902237e-07
Iter: 165 loss: 9.98833912e-07
Iter: 166 loss: 9.95584287e-07
Iter: 167 loss: 9.86544364e-07
Iter: 168 loss: 1.03932655e-06
Iter: 169 loss: 9.84012217e-07
Iter: 170 loss: 9.76937827e-07
Iter: 171 loss: 1.01738146e-06
Iter: 172 loss: 9.75944772e-07
Iter: 173 loss: 9.6974054e-07
Iter: 174 loss: 1.02627382e-06
Iter: 175 loss: 9.69481221e-07
Iter: 176 loss: 9.6205e-07
Iter: 177 loss: 9.70975634e-07
Iter: 178 loss: 9.58148462e-07
Iter: 179 loss: 9.5480641e-07
Iter: 180 loss: 9.66557536e-07
Iter: 181 loss: 9.53883e-07
Iter: 182 loss: 9.47997876e-07
Iter: 183 loss: 9.37195864e-07
Iter: 184 loss: 1.19092158e-06
Iter: 185 loss: 9.37215589e-07
Iter: 186 loss: 9.31578256e-07
Iter: 187 loss: 9.53644e-07
Iter: 188 loss: 9.30321676e-07
Iter: 189 loss: 9.27419478e-07
Iter: 190 loss: 9.2722513e-07
Iter: 191 loss: 9.24223514e-07
Iter: 192 loss: 9.18763362e-07
Iter: 193 loss: 1.04409742e-06
Iter: 194 loss: 9.18730962e-07
Iter: 195 loss: 9.15756e-07
Iter: 196 loss: 9.21098831e-07
Iter: 197 loss: 9.14420866e-07
Iter: 198 loss: 9.11100301e-07
Iter: 199 loss: 9.28059421e-07
Iter: 200 loss: 9.10512767e-07
Iter: 201 loss: 9.08966854e-07
Iter: 202 loss: 9.08958214e-07
Iter: 203 loss: 9.07086928e-07
Iter: 204 loss: 9.03707075e-07
Iter: 205 loss: 9.85909082e-07
Iter: 206 loss: 9.03708553e-07
Iter: 207 loss: 9.00222517e-07
Iter: 208 loss: 9.05718707e-07
Iter: 209 loss: 8.98551605e-07
Iter: 210 loss: 8.96451638e-07
Iter: 211 loss: 8.96399968e-07
Iter: 212 loss: 8.93763513e-07
Iter: 213 loss: 8.878e-07
Iter: 214 loss: 9.70527253e-07
Iter: 215 loss: 8.87464921e-07
Iter: 216 loss: 8.84883093e-07
Iter: 217 loss: 8.84641054e-07
Iter: 218 loss: 8.81657343e-07
Iter: 219 loss: 8.8098e-07
Iter: 220 loss: 8.79110189e-07
Iter: 221 loss: 8.75441174e-07
Iter: 222 loss: 8.69457097e-07
Iter: 223 loss: 8.69420546e-07
Iter: 224 loss: 8.71057296e-07
Iter: 225 loss: 8.67027097e-07
Iter: 226 loss: 8.64952085e-07
Iter: 227 loss: 8.59511943e-07
Iter: 228 loss: 9.03332307e-07
Iter: 229 loss: 8.58477279e-07
Iter: 230 loss: 8.54201062e-07
Iter: 231 loss: 8.82305756e-07
Iter: 232 loss: 8.53749611e-07
Iter: 233 loss: 8.50879815e-07
Iter: 234 loss: 8.55093788e-07
Iter: 235 loss: 8.49489425e-07
Iter: 236 loss: 8.48664172e-07
Iter: 237 loss: 8.48223181e-07
Iter: 238 loss: 8.47059368e-07
Iter: 239 loss: 8.47593924e-07
Iter: 240 loss: 8.46221326e-07
Iter: 241 loss: 8.44772e-07
Iter: 242 loss: 8.44949398e-07
Iter: 243 loss: 8.43659905e-07
Iter: 244 loss: 8.42007125e-07
Iter: 245 loss: 8.42025031e-07
Iter: 246 loss: 8.41281405e-07
Iter: 247 loss: 8.3926335e-07
Iter: 248 loss: 8.51720358e-07
Iter: 249 loss: 8.38690653e-07
Iter: 250 loss: 8.35699836e-07
Iter: 251 loss: 8.75820717e-07
Iter: 252 loss: 8.35711717e-07
Iter: 253 loss: 8.33438776e-07
Iter: 254 loss: 8.297406e-07
Iter: 255 loss: 8.29744693e-07
Iter: 256 loss: 8.26882683e-07
Iter: 257 loss: 8.25861321e-07
Iter: 258 loss: 8.24260724e-07
Iter: 259 loss: 8.21600622e-07
Iter: 260 loss: 8.21052765e-07
Iter: 261 loss: 8.19978482e-07
Iter: 262 loss: 8.18014598e-07
Iter: 263 loss: 8.18029e-07
Iter: 264 loss: 8.15975852e-07
Iter: 265 loss: 8.15201361e-07
Iter: 266 loss: 8.14102918e-07
Iter: 267 loss: 8.12711448e-07
Iter: 268 loss: 8.12705366e-07
Iter: 269 loss: 8.11318216e-07
Iter: 270 loss: 8.14134751e-07
Iter: 271 loss: 8.10777465e-07
Iter: 272 loss: 8.09613539e-07
Iter: 273 loss: 8.13735483e-07
Iter: 274 loss: 8.09294647e-07
Iter: 275 loss: 8.0844211e-07
Iter: 276 loss: 8.21173785e-07
Iter: 277 loss: 8.08451091e-07
Iter: 278 loss: 8.07734068e-07
Iter: 279 loss: 8.05942477e-07
Iter: 280 loss: 8.21355854e-07
Iter: 281 loss: 8.05643253e-07
Iter: 282 loss: 8.0447461e-07
Iter: 283 loss: 8.04367176e-07
Iter: 284 loss: 8.03097919e-07
Iter: 285 loss: 8.03319836e-07
Iter: 286 loss: 8.02154204e-07
Iter: 287 loss: 8.00822249e-07
Iter: 288 loss: 7.97567566e-07
Iter: 289 loss: 8.3168112e-07
Iter: 290 loss: 7.9718734e-07
Iter: 291 loss: 7.96450706e-07
Iter: 292 loss: 7.95441906e-07
Iter: 293 loss: 7.93378376e-07
Iter: 294 loss: 7.9036613e-07
Iter: 295 loss: 7.90310878e-07
Iter: 296 loss: 7.86999863e-07
Iter: 297 loss: 7.911475e-07
Iter: 298 loss: 7.85286e-07
Iter: 299 loss: 7.83415658e-07
Iter: 300 loss: 7.97296195e-07
Iter: 301 loss: 7.83263772e-07
Iter: 302 loss: 7.81605422e-07
Iter: 303 loss: 7.94809296e-07
Iter: 304 loss: 7.81451206e-07
Iter: 305 loss: 7.80187179e-07
Iter: 306 loss: 7.80256e-07
Iter: 307 loss: 7.79228799e-07
Iter: 308 loss: 7.78389392e-07
Iter: 309 loss: 7.89207263e-07
Iter: 310 loss: 7.78419121e-07
Iter: 311 loss: 7.77513549e-07
Iter: 312 loss: 7.77523837e-07
Iter: 313 loss: 7.76800334e-07
Iter: 314 loss: 7.75859462e-07
Iter: 315 loss: 7.75943249e-07
Iter: 316 loss: 7.75103e-07
Iter: 317 loss: 7.7407924e-07
Iter: 318 loss: 7.74077648e-07
Iter: 319 loss: 7.73199872e-07
Iter: 320 loss: 7.70585586e-07
Iter: 321 loss: 7.77726655e-07
Iter: 322 loss: 7.69157509e-07
Iter: 323 loss: 7.66268897e-07
Iter: 324 loss: 7.89308672e-07
Iter: 325 loss: 7.66053631e-07
Iter: 326 loss: 7.64213837e-07
Iter: 327 loss: 7.64176832e-07
Iter: 328 loss: 7.62956e-07
Iter: 329 loss: 7.60775833e-07
Iter: 330 loss: 8.11900918e-07
Iter: 331 loss: 7.6074906e-07
Iter: 332 loss: 7.58906253e-07
Iter: 333 loss: 7.61927254e-07
Iter: 334 loss: 7.58052636e-07
Iter: 335 loss: 7.57356815e-07
Iter: 336 loss: 7.56987845e-07
Iter: 337 loss: 7.56271106e-07
Iter: 338 loss: 7.55631334e-07
Iter: 339 loss: 7.55401175e-07
Iter: 340 loss: 7.5417455e-07
Iter: 341 loss: 7.53589063e-07
Iter: 342 loss: 7.52971459e-07
Iter: 343 loss: 7.52167466e-07
Iter: 344 loss: 7.51842833e-07
Iter: 345 loss: 7.51282585e-07
Iter: 346 loss: 7.50447214e-07
Iter: 347 loss: 7.50429763e-07
Iter: 348 loss: 7.49604169e-07
Iter: 349 loss: 7.57313842e-07
Iter: 350 loss: 7.49582e-07
Iter: 351 loss: 7.48648745e-07
Iter: 352 loss: 7.49093488e-07
Iter: 353 loss: 7.48038588e-07
Iter: 354 loss: 7.47508466e-07
Iter: 355 loss: 7.46931846e-07
Iter: 356 loss: 7.4686568e-07
Iter: 357 loss: 7.45970169e-07
Iter: 358 loss: 7.50687377e-07
Iter: 359 loss: 7.45826924e-07
Iter: 360 loss: 7.44774241e-07
Iter: 361 loss: 7.508811e-07
Iter: 362 loss: 7.44667489e-07
Iter: 363 loss: 7.44189492e-07
Iter: 364 loss: 7.42774944e-07
Iter: 365 loss: 7.46052478e-07
Iter: 366 loss: 7.41906547e-07
Iter: 367 loss: 7.39549705e-07
Iter: 368 loss: 7.60412092e-07
Iter: 369 loss: 7.39444886e-07
Iter: 370 loss: 7.38291362e-07
Iter: 371 loss: 7.38153517e-07
Iter: 372 loss: 7.37258631e-07
Iter: 373 loss: 7.35139e-07
Iter: 374 loss: 7.59063141e-07
Iter: 375 loss: 7.34900482e-07
Iter: 376 loss: 7.34113712e-07
Iter: 377 loss: 7.33944944e-07
Iter: 378 loss: 7.32910735e-07
Iter: 379 loss: 7.34086655e-07
Iter: 380 loss: 7.32280228e-07
Iter: 381 loss: 7.31657678e-07
Iter: 382 loss: 7.34597336e-07
Iter: 383 loss: 7.31546208e-07
Iter: 384 loss: 7.30990223e-07
Iter: 385 loss: 7.34037428e-07
Iter: 386 loss: 7.30897398e-07
Iter: 387 loss: 7.30474824e-07
Iter: 388 loss: 7.29543217e-07
Iter: 389 loss: 7.43219516e-07
Iter: 390 loss: 7.2949706e-07
Iter: 391 loss: 7.28486782e-07
Iter: 392 loss: 7.34823516e-07
Iter: 393 loss: 7.28353484e-07
Iter: 394 loss: 7.28098485e-07
Iter: 395 loss: 7.27958e-07
Iter: 396 loss: 7.27597921e-07
Iter: 397 loss: 7.26531312e-07
Iter: 398 loss: 7.30078796e-07
Iter: 399 loss: 7.26021312e-07
Iter: 400 loss: 7.24927418e-07
Iter: 401 loss: 7.30570264e-07
Iter: 402 loss: 7.24741085e-07
Iter: 403 loss: 7.2398052e-07
Iter: 404 loss: 7.36364541e-07
Iter: 405 loss: 7.23958465e-07
Iter: 406 loss: 7.23004177e-07
Iter: 407 loss: 7.22692789e-07
Iter: 408 loss: 7.22126515e-07
Iter: 409 loss: 7.21260449e-07
Iter: 410 loss: 7.2009334e-07
Iter: 411 loss: 7.19981529e-07
Iter: 412 loss: 7.18571812e-07
Iter: 413 loss: 7.18536739e-07
Iter: 414 loss: 7.17634236e-07
Iter: 415 loss: 7.16885324e-07
Iter: 416 loss: 7.16666932e-07
Iter: 417 loss: 7.15748456e-07
Iter: 418 loss: 7.15713213e-07
Iter: 419 loss: 7.15153362e-07
Iter: 420 loss: 7.14285591e-07
Iter: 421 loss: 7.1422869e-07
Iter: 422 loss: 7.1341924e-07
Iter: 423 loss: 7.15810302e-07
Iter: 424 loss: 7.13174131e-07
Iter: 425 loss: 7.12628264e-07
Iter: 426 loss: 7.1945135e-07
Iter: 427 loss: 7.12620817e-07
Iter: 428 loss: 7.12033227e-07
Iter: 429 loss: 7.13205281e-07
Iter: 430 loss: 7.11768394e-07
Iter: 431 loss: 7.11434893e-07
Iter: 432 loss: 7.10771815e-07
Iter: 433 loss: 7.22858942e-07
Iter: 434 loss: 7.10762492e-07
Iter: 435 loss: 7.09723167e-07
Iter: 436 loss: 7.10630843e-07
Iter: 437 loss: 7.09152573e-07
Iter: 438 loss: 7.08942e-07
Iter: 439 loss: 7.08482446e-07
Iter: 440 loss: 7.08040147e-07
Iter: 441 loss: 7.06695062e-07
Iter: 442 loss: 7.13631437e-07
Iter: 443 loss: 7.06271692e-07
Iter: 444 loss: 7.05592129e-07
Iter: 445 loss: 7.05431489e-07
Iter: 446 loss: 7.04624e-07
Iter: 447 loss: 7.05609182e-07
Iter: 448 loss: 7.04152e-07
Iter: 449 loss: 7.03476758e-07
Iter: 450 loss: 7.04448894e-07
Iter: 451 loss: 7.03094088e-07
Iter: 452 loss: 7.01932265e-07
Iter: 453 loss: 7.05107936e-07
Iter: 454 loss: 7.01581257e-07
Iter: 455 loss: 7.00979058e-07
Iter: 456 loss: 7.00483952e-07
Iter: 457 loss: 7.003365e-07
Iter: 458 loss: 6.99305474e-07
Iter: 459 loss: 6.99176212e-07
Iter: 460 loss: 6.98473855e-07
Iter: 461 loss: 6.98656891e-07
Iter: 462 loss: 6.97969597e-07
Iter: 463 loss: 6.97548671e-07
Iter: 464 loss: 6.97172425e-07
Iter: 465 loss: 6.97078178e-07
Iter: 466 loss: 6.9661354e-07
Iter: 467 loss: 6.96172378e-07
Iter: 468 loss: 6.96036466e-07
Iter: 469 loss: 6.95334052e-07
Iter: 470 loss: 6.97404403e-07
Iter: 471 loss: 6.95081269e-07
Iter: 472 loss: 6.94415576e-07
Iter: 473 loss: 6.94404775e-07
Iter: 474 loss: 6.94052e-07
Iter: 475 loss: 6.93219363e-07
Iter: 476 loss: 7.04398929e-07
Iter: 477 loss: 6.93186394e-07
Iter: 478 loss: 6.9246164e-07
Iter: 479 loss: 6.92441631e-07
Iter: 480 loss: 6.91589094e-07
Iter: 481 loss: 6.90550621e-07
Iter: 482 loss: 6.90472916e-07
Iter: 483 loss: 6.89827914e-07
Iter: 484 loss: 6.89829506e-07
Iter: 485 loss: 6.89106116e-07
Iter: 486 loss: 6.87926217e-07
Iter: 487 loss: 6.87926104e-07
Iter: 488 loss: 6.87152692e-07
Iter: 489 loss: 6.90252136e-07
Iter: 490 loss: 6.86967951e-07
Iter: 491 loss: 6.86475119e-07
Iter: 492 loss: 6.87071633e-07
Iter: 493 loss: 6.86187377e-07
Iter: 494 loss: 6.85868372e-07
Iter: 495 loss: 6.85813063e-07
Iter: 496 loss: 6.85556074e-07
Iter: 497 loss: 6.86530257e-07
Iter: 498 loss: 6.85517762e-07
Iter: 499 loss: 6.85276518e-07
Iter: 500 loss: 6.84715815e-07
Iter: 501 loss: 6.85871214e-07
Iter: 502 loss: 6.84316319e-07
Iter: 503 loss: 6.83344524e-07
Iter: 504 loss: 6.89323599e-07
Iter: 505 loss: 6.83201677e-07
Iter: 506 loss: 6.82735447e-07
Iter: 507 loss: 6.8267326e-07
Iter: 508 loss: 6.82158657e-07
Iter: 509 loss: 6.81124391e-07
Iter: 510 loss: 7.01716829e-07
Iter: 511 loss: 6.81096253e-07
Iter: 512 loss: 6.80277935e-07
Iter: 513 loss: 6.81052143e-07
Iter: 514 loss: 6.7978e-07
Iter: 515 loss: 6.79535276e-07
Iter: 516 loss: 6.79229402e-07
Iter: 517 loss: 6.78867423e-07
Iter: 518 loss: 6.78157107e-07
Iter: 519 loss: 6.92646154e-07
Iter: 520 loss: 6.78161882e-07
Iter: 521 loss: 6.77732544e-07
Iter: 522 loss: 6.77756134e-07
Iter: 523 loss: 6.77331627e-07
Iter: 524 loss: 6.77177354e-07
Iter: 525 loss: 6.76930767e-07
Iter: 526 loss: 6.76605168e-07
Iter: 527 loss: 6.76163268e-07
Iter: 528 loss: 6.76101763e-07
Iter: 529 loss: 6.76017748e-07
Iter: 530 loss: 6.75844e-07
Iter: 531 loss: 6.75610409e-07
Iter: 532 loss: 6.75710623e-07
Iter: 533 loss: 6.75423166e-07
Iter: 534 loss: 6.75213073e-07
Iter: 535 loss: 6.74764181e-07
Iter: 536 loss: 6.84896236e-07
Iter: 537 loss: 6.74761395e-07
Iter: 538 loss: 6.74215926e-07
Iter: 539 loss: 6.77624826e-07
Iter: 540 loss: 6.74126682e-07
Iter: 541 loss: 6.73713828e-07
Iter: 542 loss: 6.76691798e-07
Iter: 543 loss: 6.73702061e-07
Iter: 544 loss: 6.73116688e-07
Iter: 545 loss: 6.72768692e-07
Iter: 546 loss: 6.72555416e-07
Iter: 547 loss: 6.71916837e-07
Iter: 548 loss: 6.72122667e-07
Iter: 549 loss: 6.71421219e-07
Iter: 550 loss: 6.70745294e-07
Iter: 551 loss: 6.76884838e-07
Iter: 552 loss: 6.70705219e-07
Iter: 553 loss: 6.69867632e-07
Iter: 554 loss: 6.70408212e-07
Iter: 555 loss: 6.69334611e-07
Iter: 556 loss: 6.690139e-07
Iter: 557 loss: 6.69600922e-07
Iter: 558 loss: 6.68890607e-07
Iter: 559 loss: 6.68418863e-07
Iter: 560 loss: 6.71082944e-07
Iter: 561 loss: 6.68336952e-07
Iter: 562 loss: 6.6807479e-07
Iter: 563 loss: 6.67783183e-07
Iter: 564 loss: 6.67707923e-07
Iter: 565 loss: 6.67681e-07
Iter: 566 loss: 6.67568088e-07
Iter: 567 loss: 6.67415748e-07
Iter: 568 loss: 6.66969527e-07
Iter: 569 loss: 6.67497488e-07
Iter: 570 loss: 6.66657115e-07
Iter: 571 loss: 6.65954133e-07
Iter: 572 loss: 6.71563498e-07
Iter: 573 loss: 6.65933726e-07
Iter: 574 loss: 6.65322034e-07
Iter: 575 loss: 6.65963796e-07
Iter: 576 loss: 6.64986374e-07
Iter: 577 loss: 6.64592903e-07
Iter: 578 loss: 6.64590061e-07
Iter: 579 loss: 6.6413611e-07
Iter: 580 loss: 6.65137e-07
Iter: 581 loss: 6.63936873e-07
Iter: 582 loss: 6.63608603e-07
Iter: 583 loss: 6.63526521e-07
Iter: 584 loss: 6.63321828e-07
Iter: 585 loss: 6.63224796e-07
Iter: 586 loss: 6.63106789e-07
Iter: 587 loss: 6.62853552e-07
Iter: 588 loss: 6.62207867e-07
Iter: 589 loss: 6.66082144e-07
Iter: 590 loss: 6.62029265e-07
Iter: 591 loss: 6.61769491e-07
Iter: 592 loss: 6.61643639e-07
Iter: 593 loss: 6.61329295e-07
Iter: 594 loss: 6.61260572e-07
Iter: 595 loss: 6.61011654e-07
Iter: 596 loss: 6.60647515e-07
Iter: 597 loss: 6.596905e-07
Iter: 598 loss: 6.69208418e-07
Iter: 599 loss: 6.59584543e-07
Iter: 600 loss: 6.60136948e-07
Iter: 601 loss: 6.59109162e-07
Iter: 602 loss: 6.58937267e-07
Iter: 603 loss: 6.58700174e-07
Iter: 604 loss: 6.58710576e-07
Iter: 605 loss: 6.58330464e-07
Iter: 606 loss: 6.5824014e-07
Iter: 607 loss: 6.5799918e-07
Iter: 608 loss: 6.5762481e-07
Iter: 609 loss: 6.61310764e-07
Iter: 610 loss: 6.57622422e-07
Iter: 611 loss: 6.57339399e-07
Iter: 612 loss: 6.58925273e-07
Iter: 613 loss: 6.57282158e-07
Iter: 614 loss: 6.56909492e-07
Iter: 615 loss: 6.562e-07
Iter: 616 loss: 6.56225325e-07
Iter: 617 loss: 6.55564577e-07
Iter: 618 loss: 6.56094926e-07
Iter: 619 loss: 6.55142969e-07
Iter: 620 loss: 6.54417249e-07
Iter: 621 loss: 6.54402356e-07
Iter: 622 loss: 6.54097335e-07
Iter: 623 loss: 6.53483426e-07
Iter: 624 loss: 6.63224796e-07
Iter: 625 loss: 6.53471375e-07
Iter: 626 loss: 6.52917151e-07
Iter: 627 loss: 6.58043632e-07
Iter: 628 loss: 6.52876111e-07
Iter: 629 loss: 6.5235588e-07
Iter: 630 loss: 6.55077088e-07
Iter: 631 loss: 6.52242306e-07
Iter: 632 loss: 6.52038125e-07
Iter: 633 loss: 6.51832181e-07
Iter: 634 loss: 6.51757489e-07
Iter: 635 loss: 6.51397045e-07
Iter: 636 loss: 6.51477876e-07
Iter: 637 loss: 6.51100095e-07
Iter: 638 loss: 6.50827246e-07
Iter: 639 loss: 6.50817e-07
Iter: 640 loss: 6.50531547e-07
Iter: 641 loss: 6.5199481e-07
Iter: 642 loss: 6.50484481e-07
Iter: 643 loss: 6.50285756e-07
Iter: 644 loss: 6.49906951e-07
Iter: 645 loss: 6.55867439e-07
Iter: 646 loss: 6.49890069e-07
Iter: 647 loss: 6.497512e-07
Iter: 648 loss: 6.49656158e-07
Iter: 649 loss: 6.49464937e-07
Iter: 650 loss: 6.49237052e-07
Iter: 651 loss: 6.49181231e-07
Iter: 652 loss: 6.48958689e-07
Iter: 653 loss: 6.4907664e-07
Iter: 654 loss: 6.48779519e-07
Iter: 655 loss: 6.48476771e-07
Iter: 656 loss: 6.4847012e-07
Iter: 657 loss: 6.48245418e-07
Iter: 658 loss: 6.47803631e-07
Iter: 659 loss: 6.55202541e-07
Iter: 660 loss: 6.47794081e-07
Iter: 661 loss: 6.47580691e-07
Iter: 662 loss: 6.47517879e-07
Iter: 663 loss: 6.47350362e-07
Iter: 664 loss: 6.46821718e-07
Iter: 665 loss: 6.50113634e-07
Iter: 666 loss: 6.46710077e-07
Iter: 667 loss: 6.46118735e-07
Iter: 668 loss: 6.46863327e-07
Iter: 669 loss: 6.45856e-07
Iter: 670 loss: 6.45481862e-07
Iter: 671 loss: 6.45284786e-07
Iter: 672 loss: 6.4509436e-07
Iter: 673 loss: 6.44911381e-07
Iter: 674 loss: 6.44856186e-07
Iter: 675 loss: 6.44592376e-07
Iter: 676 loss: 6.4481236e-07
Iter: 677 loss: 6.44443048e-07
Iter: 678 loss: 6.44183217e-07
Iter: 679 loss: 6.44064926e-07
Iter: 680 loss: 6.43931855e-07
Iter: 681 loss: 6.43786393e-07
Iter: 682 loss: 6.4371568e-07
Iter: 683 loss: 6.43550493e-07
Iter: 684 loss: 6.43190219e-07
Iter: 685 loss: 6.47051479e-07
Iter: 686 loss: 6.43119847e-07
Iter: 687 loss: 6.4261161e-07
Iter: 688 loss: 6.44830948e-07
Iter: 689 loss: 6.4251617e-07
Iter: 690 loss: 6.42130885e-07
Iter: 691 loss: 6.42135e-07
Iter: 692 loss: 6.41989971e-07
Iter: 693 loss: 6.4168e-07
Iter: 694 loss: 6.45377213e-07
Iter: 695 loss: 6.4164476e-07
Iter: 696 loss: 6.41239524e-07
Iter: 697 loss: 6.45295302e-07
Iter: 698 loss: 6.41221732e-07
Iter: 699 loss: 6.40987309e-07
Iter: 700 loss: 6.40709459e-07
Iter: 701 loss: 6.40674784e-07
Iter: 702 loss: 6.40306666e-07
Iter: 703 loss: 6.40240387e-07
Iter: 704 loss: 6.40016083e-07
Iter: 705 loss: 6.39604309e-07
Iter: 706 loss: 6.44799059e-07
Iter: 707 loss: 6.39606128e-07
Iter: 708 loss: 6.39335838e-07
Iter: 709 loss: 6.40313374e-07
Iter: 710 loss: 6.39269786e-07
Iter: 711 loss: 6.39040877e-07
Iter: 712 loss: 6.38978349e-07
Iter: 713 loss: 6.38827601e-07
Iter: 714 loss: 6.38562824e-07
Iter: 715 loss: 6.41085933e-07
Iter: 716 loss: 6.38530707e-07
Iter: 717 loss: 6.38300776e-07
Iter: 718 loss: 6.39296729e-07
Iter: 719 loss: 6.38270194e-07
Iter: 720 loss: 6.3810586e-07
Iter: 721 loss: 6.37908272e-07
Iter: 722 loss: 6.37911228e-07
Iter: 723 loss: 6.37743369e-07
Iter: 724 loss: 6.37723645e-07
Iter: 725 loss: 6.3759e-07
Iter: 726 loss: 6.37345352e-07
Iter: 727 loss: 6.37342339e-07
Iter: 728 loss: 6.3708535e-07
Iter: 729 loss: 6.38374672e-07
Iter: 730 loss: 6.37023447e-07
Iter: 731 loss: 6.3668864e-07
Iter: 732 loss: 6.36452853e-07
Iter: 733 loss: 6.36309608e-07
Iter: 734 loss: 6.35954734e-07
Iter: 735 loss: 6.36160792e-07
Iter: 736 loss: 6.3577113e-07
Iter: 737 loss: 6.35243623e-07
Iter: 738 loss: 6.39181053e-07
Iter: 739 loss: 6.35228844e-07
Iter: 740 loss: 6.34771197e-07
Iter: 741 loss: 6.37307721e-07
Iter: 742 loss: 6.3473351e-07
Iter: 743 loss: 6.34519552e-07
Iter: 744 loss: 6.34779269e-07
Iter: 745 loss: 6.3438074e-07
Iter: 746 loss: 6.34185596e-07
Iter: 747 loss: 6.34746755e-07
Iter: 748 loss: 6.34087826e-07
Iter: 749 loss: 6.33845161e-07
Iter: 750 loss: 6.35732704e-07
Iter: 751 loss: 6.33829814e-07
Iter: 752 loss: 6.33690433e-07
Iter: 753 loss: 6.33541674e-07
Iter: 754 loss: 6.33501372e-07
Iter: 755 loss: 6.3328622e-07
Iter: 756 loss: 6.3480951e-07
Iter: 757 loss: 6.33272293e-07
Iter: 758 loss: 6.33004674e-07
Iter: 759 loss: 6.32999559e-07
Iter: 760 loss: 6.32806461e-07
Iter: 761 loss: 6.3252503e-07
Iter: 762 loss: 6.3305788e-07
Iter: 763 loss: 6.32435672e-07
Iter: 764 loss: 6.32140654e-07
Iter: 765 loss: 6.34078333e-07
Iter: 766 loss: 6.32123601e-07
Iter: 767 loss: 6.31906744e-07
Iter: 768 loss: 6.31329499e-07
Iter: 769 loss: 6.36932668e-07
Iter: 770 loss: 6.31240937e-07
Iter: 771 loss: 6.31047442e-07
Iter: 772 loss: 6.30983266e-07
Iter: 773 loss: 6.30798922e-07
Iter: 774 loss: 6.31763385e-07
Iter: 775 loss: 6.30768511e-07
Iter: 776 loss: 6.30591444e-07
Iter: 777 loss: 6.304723e-07
Iter: 778 loss: 6.30431259e-07
Iter: 779 loss: 6.30200589e-07
Iter: 780 loss: 6.30791874e-07
Iter: 781 loss: 6.30134423e-07
Iter: 782 loss: 6.29877377e-07
Iter: 783 loss: 6.32160095e-07
Iter: 784 loss: 6.29887325e-07
Iter: 785 loss: 6.29653186e-07
Iter: 786 loss: 6.29384317e-07
Iter: 787 loss: 6.29387387e-07
Iter: 788 loss: 6.29121303e-07
Iter: 789 loss: 6.30493332e-07
Iter: 790 loss: 6.29097144e-07
Iter: 791 loss: 6.28906491e-07
Iter: 792 loss: 6.28883697e-07
Iter: 793 loss: 6.28751593e-07
Iter: 794 loss: 6.28546275e-07
Iter: 795 loss: 6.32960109e-07
Iter: 796 loss: 6.28521548e-07
Iter: 797 loss: 6.28484713e-07
Iter: 798 loss: 6.28424232e-07
Iter: 799 loss: 6.28327371e-07
Iter: 800 loss: 6.28176167e-07
Iter: 801 loss: 6.30537613e-07
Iter: 802 loss: 6.28185148e-07
Iter: 803 loss: 6.27949134e-07
Iter: 804 loss: 6.2808806e-07
Iter: 805 loss: 6.27818054e-07
Iter: 806 loss: 6.27687768e-07
Iter: 807 loss: 6.27679867e-07
Iter: 808 loss: 6.27552367e-07
Iter: 809 loss: 6.27265877e-07
Iter: 810 loss: 6.32038677e-07
Iter: 811 loss: 6.27280144e-07
Iter: 812 loss: 6.26949145e-07
Iter: 813 loss: 6.2749524e-07
Iter: 814 loss: 6.26805559e-07
Iter: 815 loss: 6.26600468e-07
Iter: 816 loss: 6.29878286e-07
Iter: 817 loss: 6.26600524e-07
Iter: 818 loss: 6.26422661e-07
Iter: 819 loss: 6.26389351e-07
Iter: 820 loss: 6.26215183e-07
Iter: 821 loss: 6.25984285e-07
Iter: 822 loss: 6.25766518e-07
Iter: 823 loss: 6.25671419e-07
Iter: 824 loss: 6.2570723e-07
Iter: 825 loss: 6.2553238e-07
Iter: 826 loss: 6.2541244e-07
Iter: 827 loss: 6.25140046e-07
Iter: 828 loss: 6.29313888e-07
Iter: 829 loss: 6.25131406e-07
Iter: 830 loss: 6.24925747e-07
Iter: 831 loss: 6.27350687e-07
Iter: 832 loss: 6.24917448e-07
Iter: 833 loss: 6.24716222e-07
Iter: 834 loss: 6.25125949e-07
Iter: 835 loss: 6.24609356e-07
Iter: 836 loss: 6.24472932e-07
Iter: 837 loss: 6.24145684e-07
Iter: 838 loss: 6.28424687e-07
Iter: 839 loss: 6.24121867e-07
Iter: 840 loss: 6.23901e-07
Iter: 841 loss: 6.23885171e-07
Iter: 842 loss: 6.23732944e-07
Iter: 843 loss: 6.26049939e-07
Iter: 844 loss: 6.23709298e-07
Iter: 845 loss: 6.23647452e-07
Iter: 846 loss: 6.23386541e-07
Iter: 847 loss: 6.24470204e-07
Iter: 848 loss: 6.23275639e-07
Iter: 849 loss: 6.22946345e-07
Iter: 850 loss: 6.24831614e-07
Iter: 851 loss: 6.2289e-07
Iter: 852 loss: 6.22652806e-07
Iter: 853 loss: 6.26377869e-07
Iter: 854 loss: 6.22657751e-07
Iter: 855 loss: 6.22448283e-07
Iter: 856 loss: 6.22003824e-07
Iter: 857 loss: 6.29384658e-07
Iter: 858 loss: 6.22040545e-07
Iter: 859 loss: 6.21695449e-07
Iter: 860 loss: 6.26563462e-07
Iter: 861 loss: 6.21710285e-07
Iter: 862 loss: 6.21434594e-07
Iter: 863 loss: 6.23658821e-07
Iter: 864 loss: 6.21435447e-07
Iter: 865 loss: 6.21263666e-07
Iter: 866 loss: 6.20921355e-07
Iter: 867 loss: 6.25789085e-07
Iter: 868 loss: 6.2091874e-07
Iter: 869 loss: 6.20874744e-07
Iter: 870 loss: 6.20750598e-07
Iter: 871 loss: 6.2065169e-07
Iter: 872 loss: 6.2048656e-07
Iter: 873 loss: 6.23949347e-07
Iter: 874 loss: 6.20488436e-07
Iter: 875 loss: 6.20305173e-07
Iter: 876 loss: 6.20490312e-07
Iter: 877 loss: 6.20182163e-07
Iter: 878 loss: 6.20085132e-07
Iter: 879 loss: 6.2008337e-07
Iter: 880 loss: 6.19941147e-07
Iter: 881 loss: 6.19937964e-07
Iter: 882 loss: 6.19833656e-07
Iter: 883 loss: 6.19632544e-07
Iter: 884 loss: 6.19804041e-07
Iter: 885 loss: 6.19489583e-07
Iter: 886 loss: 6.19320076e-07
Iter: 887 loss: 6.20738433e-07
Iter: 888 loss: 6.1929876e-07
Iter: 889 loss: 6.19086165e-07
Iter: 890 loss: 6.18837134e-07
Iter: 891 loss: 6.18819058e-07
Iter: 892 loss: 6.18381137e-07
Iter: 893 loss: 6.18398303e-07
Iter: 894 loss: 6.18012166e-07
Iter: 895 loss: 6.18085494e-07
Iter: 896 loss: 6.17804687e-07
Iter: 897 loss: 6.17698902e-07
Iter: 898 loss: 6.17462206e-07
Iter: 899 loss: 6.17479145e-07
Iter: 900 loss: 6.17330613e-07
Iter: 901 loss: 6.19246123e-07
Iter: 902 loss: 6.1730168e-07
Iter: 903 loss: 6.17120293e-07
Iter: 904 loss: 6.17214255e-07
Iter: 905 loss: 6.17017122e-07
Iter: 906 loss: 6.16902071e-07
Iter: 907 loss: 6.16823684e-07
Iter: 908 loss: 6.16741886e-07
Iter: 909 loss: 6.16593638e-07
Iter: 910 loss: 6.17090564e-07
Iter: 911 loss: 6.16505417e-07
Iter: 912 loss: 6.16381953e-07
Iter: 913 loss: 6.16343925e-07
Iter: 914 loss: 6.16291231e-07
Iter: 915 loss: 6.1615458e-07
Iter: 916 loss: 6.18486411e-07
Iter: 917 loss: 6.1614611e-07
Iter: 918 loss: 6.15968361e-07
Iter: 919 loss: 6.17074875e-07
Iter: 920 loss: 6.15888666e-07
Iter: 921 loss: 6.1567988e-07
Iter: 922 loss: 6.16344437e-07
Iter: 923 loss: 6.15649583e-07
Iter: 924 loss: 6.15478427e-07
Iter: 925 loss: 6.15401575e-07
Iter: 926 loss: 6.15285387e-07
Iter: 927 loss: 6.15131114e-07
Iter: 928 loss: 6.1817417e-07
Iter: 929 loss: 6.15125771e-07
Iter: 930 loss: 6.14934379e-07
Iter: 931 loss: 6.1483928e-07
Iter: 932 loss: 6.14731903e-07
Iter: 933 loss: 6.14565749e-07
Iter: 934 loss: 6.15202111e-07
Iter: 935 loss: 6.1448e-07
Iter: 936 loss: 6.14241117e-07
Iter: 937 loss: 6.14888165e-07
Iter: 938 loss: 6.14163525e-07
Iter: 939 loss: 6.13952921e-07
Iter: 940 loss: 6.13826e-07
Iter: 941 loss: 6.13774205e-07
Iter: 942 loss: 6.13539555e-07
Iter: 943 loss: 6.14254304e-07
Iter: 944 loss: 6.13476629e-07
Iter: 945 loss: 6.13336908e-07
Iter: 946 loss: 6.13351403e-07
Iter: 947 loss: 6.13238e-07
Iter: 948 loss: 6.13238342e-07
Iter: 949 loss: 6.13137615e-07
Iter: 950 loss: 6.13055533e-07
Iter: 951 loss: 6.13138923e-07
Iter: 952 loss: 6.13011082e-07
Iter: 953 loss: 6.12863687e-07
Iter: 954 loss: 6.13390171e-07
Iter: 955 loss: 6.12817473e-07
Iter: 956 loss: 6.12687472e-07
Iter: 957 loss: 6.12762051e-07
Iter: 958 loss: 6.12601752e-07
Iter: 959 loss: 6.12454301e-07
Iter: 960 loss: 6.13285636e-07
Iter: 961 loss: 6.12438953e-07
Iter: 962 loss: 6.12237e-07
Iter: 963 loss: 6.12266376e-07
Iter: 964 loss: 6.1210784e-07
Iter: 965 loss: 6.11876317e-07
Iter: 966 loss: 6.11906728e-07
Iter: 967 loss: 6.11731707e-07
Iter: 968 loss: 6.11519397e-07
Iter: 969 loss: 6.11502401e-07
Iter: 970 loss: 6.11418272e-07
Iter: 971 loss: 6.11161227e-07
Iter: 972 loss: 6.14471219e-07
Iter: 973 loss: 6.11155826e-07
Iter: 974 loss: 6.10911172e-07
Iter: 975 loss: 6.11877681e-07
Iter: 976 loss: 6.10862458e-07
Iter: 977 loss: 6.10730353e-07
Iter: 978 loss: 6.123758e-07
Iter: 979 loss: 6.10741893e-07
Iter: 980 loss: 6.10603365e-07
Iter: 981 loss: 6.10688517e-07
Iter: 982 loss: 6.105181e-07
Iter: 983 loss: 6.10363088e-07
Iter: 984 loss: 6.10598704e-07
Iter: 985 loss: 6.10291067e-07
Iter: 986 loss: 6.10169081e-07
Iter: 987 loss: 6.11335906e-07
Iter: 988 loss: 6.10152256e-07
Iter: 989 loss: 6.10002644e-07
Iter: 990 loss: 6.09860535e-07
Iter: 991 loss: 6.09830295e-07
Iter: 992 loss: 6.09627477e-07
Iter: 993 loss: 6.10936468e-07
Iter: 994 loss: 6.09598146e-07
Iter: 995 loss: 6.09420226e-07
Iter: 996 loss: 6.11028838e-07
Iter: 997 loss: 6.09409199e-07
Iter: 998 loss: 6.09317453e-07
Iter: 999 loss: 6.09170343e-07
Iter: 1000 loss: 6.09146127e-07
Iter: 1001 loss: 6.09007e-07
Iter: 1002 loss: 6.09019537e-07
Iter: 1003 loss: 6.08865207e-07
Iter: 1004 loss: 6.08736741e-07
Iter: 1005 loss: 6.08703317e-07
Iter: 1006 loss: 6.08540574e-07
Iter: 1007 loss: 6.08625669e-07
Iter: 1008 loss: 6.08397727e-07
Iter: 1009 loss: 6.08184791e-07
Iter: 1010 loss: 6.10375764e-07
Iter: 1011 loss: 6.08188202e-07
Iter: 1012 loss: 6.07990273e-07
Iter: 1013 loss: 6.09508447e-07
Iter: 1014 loss: 6.08003859e-07
Iter: 1015 loss: 6.07900688e-07
Iter: 1016 loss: 6.07818379e-07
Iter: 1017 loss: 6.07791833e-07
Iter: 1018 loss: 6.07657853e-07
Iter: 1019 loss: 6.08576954e-07
Iter: 1020 loss: 6.07650804e-07
Iter: 1021 loss: 6.075187e-07
Iter: 1022 loss: 6.07458333e-07
Iter: 1023 loss: 6.07380912e-07
Iter: 1024 loss: 6.07282402e-07
Iter: 1025 loss: 6.08155517e-07
Iter: 1026 loss: 6.07257e-07
Iter: 1027 loss: 6.07125116e-07
Iter: 1028 loss: 6.08193432e-07
Iter: 1029 loss: 6.07124434e-07
Iter: 1030 loss: 6.07063953e-07
Iter: 1031 loss: 6.06908e-07
Iter: 1032 loss: 6.09503275e-07
Iter: 1033 loss: 6.06911499e-07
Iter: 1034 loss: 6.06783317e-07
Iter: 1035 loss: 6.06774e-07
Iter: 1036 loss: 6.06620858e-07
Iter: 1037 loss: 6.065e-07
Iter: 1038 loss: 6.06479318e-07
Iter: 1039 loss: 6.06248e-07
Iter: 1040 loss: 6.0609807e-07
Iter: 1041 loss: 6.06024742e-07
Iter: 1042 loss: 6.05758544e-07
Iter: 1043 loss: 6.08418e-07
Iter: 1044 loss: 6.05729667e-07
Iter: 1045 loss: 6.05508149e-07
Iter: 1046 loss: 6.06687536e-07
Iter: 1047 loss: 6.05505932e-07
Iter: 1048 loss: 6.05311357e-07
Iter: 1049 loss: 6.05216201e-07
Iter: 1050 loss: 6.0510763e-07
Iter: 1051 loss: 6.04985303e-07
Iter: 1052 loss: 6.04975185e-07
Iter: 1053 loss: 6.0487605e-07
Iter: 1054 loss: 6.04734453e-07
Iter: 1055 loss: 6.04728029e-07
Iter: 1056 loss: 6.04519812e-07
Iter: 1057 loss: 6.04758668e-07
Iter: 1058 loss: 6.0443142e-07
Iter: 1059 loss: 6.04324839e-07
Iter: 1060 loss: 6.043133e-07
Iter: 1061 loss: 6.04205184e-07
Iter: 1062 loss: 6.04037382e-07
Iter: 1063 loss: 6.07163656e-07
Iter: 1064 loss: 6.04056595e-07
Iter: 1065 loss: 6.03847525e-07
Iter: 1066 loss: 6.04983711e-07
Iter: 1067 loss: 6.03806654e-07
Iter: 1068 loss: 6.03620776e-07
Iter: 1069 loss: 6.04078195e-07
Iter: 1070 loss: 6.0352977e-07
Iter: 1071 loss: 6.03397098e-07
Iter: 1072 loss: 6.03320359e-07
Iter: 1073 loss: 6.03274543e-07
Iter: 1074 loss: 6.03096964e-07
Iter: 1075 loss: 6.03847923e-07
Iter: 1076 loss: 6.03072181e-07
Iter: 1077 loss: 6.02922114e-07
Iter: 1078 loss: 6.04719389e-07
Iter: 1079 loss: 6.02921148e-07
Iter: 1080 loss: 6.02809e-07
Iter: 1081 loss: 6.02843897e-07
Iter: 1082 loss: 6.02762725e-07
Iter: 1083 loss: 6.02693262e-07
Iter: 1084 loss: 6.03336389e-07
Iter: 1085 loss: 6.02622322e-07
Iter: 1086 loss: 6.02544901e-07
Iter: 1087 loss: 6.02408875e-07
Iter: 1088 loss: 6.02412229e-07
Iter: 1089 loss: 6.02248235e-07
Iter: 1090 loss: 6.02500904e-07
Iter: 1091 loss: 6.02187811e-07
Iter: 1092 loss: 6.02075374e-07
Iter: 1093 loss: 6.02069235e-07
Iter: 1094 loss: 6.01941792e-07
Iter: 1095 loss: 6.01780698e-07
Iter: 1096 loss: 6.0177706e-07
Iter: 1097 loss: 6.01598856e-07
Iter: 1098 loss: 6.03120043e-07
Iter: 1099 loss: 6.01615284e-07
Iter: 1100 loss: 6.01482213e-07
Iter: 1101 loss: 6.01987381e-07
Iter: 1102 loss: 6.0146948e-07
Iter: 1103 loss: 6.01388308e-07
Iter: 1104 loss: 6.01215675e-07
Iter: 1105 loss: 6.01199133e-07
Iter: 1106 loss: 6.01074873e-07
Iter: 1107 loss: 6.02800469e-07
Iter: 1108 loss: 6.01069075e-07
Iter: 1109 loss: 6.00963403e-07
Iter: 1110 loss: 6.01826969e-07
Iter: 1111 loss: 6.00964768e-07
Iter: 1112 loss: 6.00854605e-07
Iter: 1113 loss: 6.00739e-07
Iter: 1114 loss: 6.00747626e-07
Iter: 1115 loss: 6.00592841e-07
Iter: 1116 loss: 6.02079297e-07
Iter: 1117 loss: 6.00556689e-07
Iter: 1118 loss: 6.00449482e-07
Iter: 1119 loss: 6.00398153e-07
Iter: 1120 loss: 6.00301178e-07
Iter: 1121 loss: 6.00124451e-07
Iter: 1122 loss: 5.99918508e-07
Iter: 1123 loss: 5.99880366e-07
Iter: 1124 loss: 5.99736268e-07
Iter: 1125 loss: 5.99708926e-07
Iter: 1126 loss: 5.9955471e-07
Iter: 1127 loss: 5.99594841e-07
Iter: 1128 loss: 5.99462453e-07
Iter: 1129 loss: 5.99316536e-07
Iter: 1130 loss: 5.99351e-07
Iter: 1131 loss: 5.99214786e-07
Iter: 1132 loss: 5.99018392e-07
Iter: 1133 loss: 6.01231875e-07
Iter: 1134 loss: 5.9900924e-07
Iter: 1135 loss: 5.98888391e-07
Iter: 1136 loss: 5.98762824e-07
Iter: 1137 loss: 5.98743895e-07
Iter: 1138 loss: 5.98564952e-07
Iter: 1139 loss: 5.99105647e-07
Iter: 1140 loss: 5.98533518e-07
Iter: 1141 loss: 5.98388681e-07
Iter: 1142 loss: 6.00067551e-07
Iter: 1143 loss: 5.9840022e-07
Iter: 1144 loss: 5.98280394e-07
Iter: 1145 loss: 5.98239581e-07
Iter: 1146 loss: 5.98190923e-07
Iter: 1147 loss: 5.98046086e-07
Iter: 1148 loss: 5.98860765e-07
Iter: 1149 loss: 5.98066265e-07
Iter: 1150 loss: 5.97899543e-07
Iter: 1151 loss: 5.97958092e-07
Iter: 1152 loss: 5.97825533e-07
Iter: 1153 loss: 5.97677058e-07
Iter: 1154 loss: 5.97686437e-07
Iter: 1155 loss: 5.9753e-07
Iter: 1156 loss: 5.97405631e-07
Iter: 1157 loss: 5.97417852e-07
Iter: 1158 loss: 5.97324572e-07
Iter: 1159 loss: 5.97365556e-07
Iter: 1160 loss: 5.97242888e-07
Iter: 1161 loss: 5.97131475e-07
Iter: 1162 loss: 5.96996301e-07
Iter: 1163 loss: 5.96992e-07
Iter: 1164 loss: 5.96832592e-07
Iter: 1165 loss: 5.96827e-07
Iter: 1166 loss: 5.9673954e-07
Iter: 1167 loss: 5.96557584e-07
Iter: 1168 loss: 6.00265082e-07
Iter: 1169 loss: 5.96535074e-07
Iter: 1170 loss: 5.96317761e-07
Iter: 1171 loss: 5.97150915e-07
Iter: 1172 loss: 5.96246537e-07
Iter: 1173 loss: 5.96139557e-07
Iter: 1174 loss: 5.96129041e-07
Iter: 1175 loss: 5.96007624e-07
Iter: 1176 loss: 5.95931056e-07
Iter: 1177 loss: 5.95866709e-07
Iter: 1178 loss: 5.95709139e-07
Iter: 1179 loss: 5.96129439e-07
Iter: 1180 loss: 5.95653319e-07
Iter: 1181 loss: 5.95447489e-07
Iter: 1182 loss: 5.96700033e-07
Iter: 1183 loss: 5.95440099e-07
Iter: 1184 loss: 5.95326242e-07
Iter: 1185 loss: 5.95230631e-07
Iter: 1186 loss: 5.95229892e-07
Iter: 1187 loss: 5.95026847e-07
Iter: 1188 loss: 5.95598181e-07
Iter: 1189 loss: 5.95006554e-07
Iter: 1190 loss: 5.9482079e-07
Iter: 1191 loss: 5.96523876e-07
Iter: 1192 loss: 5.94797939e-07
Iter: 1193 loss: 5.94722337e-07
Iter: 1194 loss: 5.94530206e-07
Iter: 1195 loss: 5.9789329e-07
Iter: 1196 loss: 5.9453987e-07
Iter: 1197 loss: 5.94355583e-07
Iter: 1198 loss: 5.96866698e-07
Iter: 1199 loss: 5.9433961e-07
Iter: 1200 loss: 5.94189146e-07
Iter: 1201 loss: 5.94078301e-07
Iter: 1202 loss: 5.9403e-07
Iter: 1203 loss: 5.93855702e-07
Iter: 1204 loss: 5.94012306e-07
Iter: 1205 loss: 5.93755146e-07
Iter: 1206 loss: 5.93534082e-07
Iter: 1207 loss: 5.95386723e-07
Iter: 1208 loss: 5.93554e-07
Iter: 1209 loss: 5.93367872e-07
Iter: 1210 loss: 5.9360093e-07
Iter: 1211 loss: 5.93275217e-07
Iter: 1212 loss: 5.93131858e-07
Iter: 1213 loss: 5.93685627e-07
Iter: 1214 loss: 5.93086e-07
Iter: 1215 loss: 5.92955189e-07
Iter: 1216 loss: 5.93973e-07
Iter: 1217 loss: 5.92962351e-07
Iter: 1218 loss: 5.92849517e-07
Iter: 1219 loss: 5.92688423e-07
Iter: 1220 loss: 5.96897678e-07
Iter: 1221 loss: 5.92677679e-07
Iter: 1222 loss: 5.92474294e-07
Iter: 1223 loss: 5.93666186e-07
Iter: 1224 loss: 5.92465767e-07
Iter: 1225 loss: 5.92366405e-07
Iter: 1226 loss: 5.92358674e-07
Iter: 1227 loss: 5.92288131e-07
Iter: 1228 loss: 5.92090657e-07
Iter: 1229 loss: 5.95161509e-07
Iter: 1230 loss: 5.9210987e-07
Iter: 1231 loss: 5.92022104e-07
Iter: 1232 loss: 5.92019887e-07
Iter: 1233 loss: 5.9197157e-07
Iter: 1234 loss: 5.91875732e-07
Iter: 1235 loss: 5.91883861e-07
Iter: 1236 loss: 5.91756418e-07
Iter: 1237 loss: 5.91620847e-07
Iter: 1238 loss: 5.91603794e-07
Iter: 1239 loss: 5.91460037e-07
Iter: 1240 loss: 5.91474304e-07
Iter: 1241 loss: 5.91335947e-07
Iter: 1242 loss: 5.91563548e-07
Iter: 1243 loss: 5.91271373e-07
Iter: 1244 loss: 5.91122e-07
Iter: 1245 loss: 5.90959075e-07
Iter: 1246 loss: 5.90947593e-07
Iter: 1247 loss: 5.90775e-07
Iter: 1248 loss: 5.9075694e-07
Iter: 1249 loss: 5.90660648e-07
Iter: 1250 loss: 5.90483637e-07
Iter: 1251 loss: 5.90467891e-07
Iter: 1252 loss: 5.90275874e-07
Iter: 1253 loss: 5.90544687e-07
Iter: 1254 loss: 5.90153604e-07
Iter: 1255 loss: 5.90244156e-07
Iter: 1256 loss: 5.90098e-07
Iter: 1257 loss: 5.90053787e-07
Iter: 1258 loss: 5.89904971e-07
Iter: 1259 loss: 5.91479477e-07
Iter: 1260 loss: 5.89911e-07
Iter: 1261 loss: 5.89778892e-07
Iter: 1262 loss: 5.90634045e-07
Iter: 1263 loss: 5.89776846e-07
Iter: 1264 loss: 5.89645367e-07
Iter: 1265 loss: 5.89804131e-07
Iter: 1266 loss: 5.89574142e-07
Iter: 1267 loss: 5.89464378e-07
Iter: 1268 loss: 5.8943e-07
Iter: 1269 loss: 5.89369108e-07
Iter: 1270 loss: 5.89183742e-07
Iter: 1271 loss: 5.89486206e-07
Iter: 1272 loss: 5.89097169e-07
Iter: 1273 loss: 5.88811304e-07
Iter: 1274 loss: 5.91435878e-07
Iter: 1275 loss: 5.88798571e-07
Iter: 1276 loss: 5.88717057e-07
Iter: 1277 loss: 5.88552552e-07
Iter: 1278 loss: 5.88551131e-07
Iter: 1279 loss: 5.88423404e-07
Iter: 1280 loss: 5.88406124e-07
Iter: 1281 loss: 5.88268051e-07
Iter: 1282 loss: 5.88272e-07
Iter: 1283 loss: 5.88172497e-07
Iter: 1284 loss: 5.88060061e-07
Iter: 1285 loss: 5.88103376e-07
Iter: 1286 loss: 5.87978093e-07
Iter: 1287 loss: 5.87909483e-07
Iter: 1288 loss: 5.8791e-07
Iter: 1289 loss: 5.87804891e-07
Iter: 1290 loss: 5.87752311e-07
Iter: 1291 loss: 5.87733098e-07
Iter: 1292 loss: 5.87654199e-07
Iter: 1293 loss: 5.88027206e-07
Iter: 1294 loss: 5.8761708e-07
Iter: 1295 loss: 5.87542047e-07
Iter: 1296 loss: 5.87714794e-07
Iter: 1297 loss: 5.87500438e-07
Iter: 1298 loss: 5.87399882e-07
Iter: 1299 loss: 5.87331044e-07
Iter: 1300 loss: 5.87327122e-07
Iter: 1301 loss: 5.87193881e-07
Iter: 1302 loss: 5.87763964e-07
Iter: 1303 loss: 5.87139198e-07
Iter: 1304 loss: 5.87034606e-07
Iter: 1305 loss: 5.87057116e-07
Iter: 1306 loss: 5.86969e-07
Iter: 1307 loss: 5.86824115e-07
Iter: 1308 loss: 5.89158788e-07
Iter: 1309 loss: 5.86798649e-07
Iter: 1310 loss: 5.86733222e-07
Iter: 1311 loss: 5.86714918e-07
Iter: 1312 loss: 5.86646934e-07
Iter: 1313 loss: 5.86560702e-07
Iter: 1314 loss: 5.86535123e-07
Iter: 1315 loss: 5.86396823e-07
Iter: 1316 loss: 5.86315537e-07
Iter: 1317 loss: 5.8626415e-07
Iter: 1318 loss: 5.86166493e-07
Iter: 1319 loss: 5.86159217e-07
Iter: 1320 loss: 5.86059e-07
Iter: 1321 loss: 5.8623084e-07
Iter: 1322 loss: 5.85977944e-07
Iter: 1323 loss: 5.85940597e-07
Iter: 1324 loss: 5.85870112e-07
Iter: 1325 loss: 5.85866758e-07
Iter: 1326 loss: 5.85774387e-07
Iter: 1327 loss: 5.85767395e-07
Iter: 1328 loss: 5.85716236e-07
Iter: 1329 loss: 5.85624e-07
Iter: 1330 loss: 5.87740544e-07
Iter: 1331 loss: 5.85611133e-07
Iter: 1332 loss: 5.85503358e-07
Iter: 1333 loss: 5.85696398e-07
Iter: 1334 loss: 5.8546533e-07
Iter: 1335 loss: 5.85401949e-07
Iter: 1336 loss: 5.85395298e-07
Iter: 1337 loss: 5.85335727e-07
Iter: 1338 loss: 5.85172472e-07
Iter: 1339 loss: 5.88495141e-07
Iter: 1340 loss: 5.85193447e-07
Iter: 1341 loss: 5.85026896e-07
Iter: 1342 loss: 5.86101294e-07
Iter: 1343 loss: 5.8503997e-07
Iter: 1344 loss: 5.84911959e-07
Iter: 1345 loss: 5.85377961e-07
Iter: 1346 loss: 5.84902864e-07
Iter: 1347 loss: 5.84829081e-07
Iter: 1348 loss: 5.84662303e-07
Iter: 1349 loss: 5.84665713e-07
Iter: 1350 loss: 5.84508143e-07
Iter: 1351 loss: 5.85496139e-07
Iter: 1352 loss: 5.84490181e-07
Iter: 1353 loss: 5.84425493e-07
Iter: 1354 loss: 5.84393774e-07
Iter: 1355 loss: 5.84374391e-07
Iter: 1356 loss: 5.84274517e-07
Iter: 1357 loss: 5.85202883e-07
Iter: 1358 loss: 5.84279633e-07
Iter: 1359 loss: 5.8416714e-07
Iter: 1360 loss: 5.84166742e-07
Iter: 1361 loss: 5.84102679e-07
Iter: 1362 loss: 5.84066e-07
Iter: 1363 loss: 5.84055329e-07
Iter: 1364 loss: 5.83971655e-07
Iter: 1365 loss: 5.83976657e-07
Iter: 1366 loss: 5.83915153e-07
Iter: 1367 loss: 5.83805274e-07
Iter: 1368 loss: 5.8448893e-07
Iter: 1369 loss: 5.83797316e-07
Iter: 1370 loss: 5.83689712e-07
Iter: 1371 loss: 5.84162422e-07
Iter: 1372 loss: 5.83646681e-07
Iter: 1373 loss: 5.83583187e-07
Iter: 1374 loss: 5.83530323e-07
Iter: 1375 loss: 5.83496785e-07
Iter: 1376 loss: 5.83396172e-07
Iter: 1377 loss: 5.84408895e-07
Iter: 1378 loss: 5.83364226e-07
Iter: 1379 loss: 5.83281178e-07
Iter: 1380 loss: 5.83207e-07
Iter: 1381 loss: 5.83190968e-07
Iter: 1382 loss: 5.83055566e-07
Iter: 1383 loss: 5.83096494e-07
Iter: 1384 loss: 5.82967289e-07
Iter: 1385 loss: 5.82904477e-07
Iter: 1386 loss: 5.82879e-07
Iter: 1387 loss: 5.82794428e-07
Iter: 1388 loss: 5.82630094e-07
Iter: 1389 loss: 5.82613893e-07
Iter: 1390 loss: 5.82550911e-07
Iter: 1391 loss: 5.83794304e-07
Iter: 1392 loss: 5.82530902e-07
Iter: 1393 loss: 5.82447683e-07
Iter: 1394 loss: 5.82408802e-07
Iter: 1395 loss: 5.82312509e-07
Iter: 1396 loss: 5.82207122e-07
Iter: 1397 loss: 5.82325811e-07
Iter: 1398 loss: 5.82170742e-07
Iter: 1399 loss: 5.82043413e-07
Iter: 1400 loss: 5.82406642e-07
Iter: 1401 loss: 5.8199646e-07
Iter: 1402 loss: 5.81889822e-07
Iter: 1403 loss: 5.81883e-07
Iter: 1404 loss: 5.81814277e-07
Iter: 1405 loss: 5.81754193e-07
Iter: 1406 loss: 5.81717e-07
Iter: 1407 loss: 5.81713721e-07
Iter: 1408 loss: 5.82740029e-07
Iter: 1409 loss: 5.81692916e-07
Iter: 1410 loss: 5.81603729e-07
Iter: 1411 loss: 5.81503514e-07
Iter: 1412 loss: 5.81476286e-07
Iter: 1413 loss: 5.81366635e-07
Iter: 1414 loss: 5.81331619e-07
Iter: 1415 loss: 5.81263066e-07
Iter: 1416 loss: 5.81124425e-07
Iter: 1417 loss: 5.82915732e-07
Iter: 1418 loss: 5.81128347e-07
Iter: 1419 loss: 5.81011e-07
Iter: 1420 loss: 5.81230893e-07
Iter: 1421 loss: 5.80958613e-07
Iter: 1422 loss: 5.80885853e-07
Iter: 1423 loss: 5.8114324e-07
Iter: 1424 loss: 5.80871585e-07
Iter: 1425 loss: 5.80810593e-07
Iter: 1426 loss: 5.80954406e-07
Iter: 1427 loss: 5.80790697e-07
Iter: 1428 loss: 5.80720211e-07
Iter: 1429 loss: 5.80604876e-07
Iter: 1430 loss: 5.80606184e-07
Iter: 1431 loss: 5.8052882e-07
Iter: 1432 loss: 5.81277845e-07
Iter: 1433 loss: 5.8052558e-07
Iter: 1434 loss: 5.80486471e-07
Iter: 1435 loss: 5.81127949e-07
Iter: 1436 loss: 5.80473397e-07
Iter: 1437 loss: 5.80417691e-07
Iter: 1438 loss: 5.80291726e-07
Iter: 1439 loss: 5.82198766e-07
Iter: 1440 loss: 5.80289452e-07
Iter: 1441 loss: 5.80178209e-07
Iter: 1442 loss: 5.80971118e-07
Iter: 1443 loss: 5.80172582e-07
Iter: 1444 loss: 5.80075039e-07
Iter: 1445 loss: 5.80598e-07
Iter: 1446 loss: 5.80045594e-07
Iter: 1447 loss: 5.79961124e-07
Iter: 1448 loss: 5.79877053e-07
Iter: 1449 loss: 5.82764642e-07
Iter: 1450 loss: 5.79863354e-07
Iter: 1451 loss: 5.79755579e-07
Iter: 1452 loss: 5.81237e-07
Iter: 1453 loss: 5.79750633e-07
Iter: 1454 loss: 5.79657865e-07
Iter: 1455 loss: 5.80298718e-07
Iter: 1456 loss: 5.79641323e-07
Iter: 1457 loss: 5.79571065e-07
Iter: 1458 loss: 5.79546963e-07
Iter: 1459 loss: 5.79502512e-07
Iter: 1460 loss: 5.79424466e-07
Iter: 1461 loss: 5.80171104e-07
Iter: 1462 loss: 5.79396215e-07
Iter: 1463 loss: 5.79343691e-07
Iter: 1464 loss: 5.79206755e-07
Iter: 1465 loss: 5.79192488e-07
Iter: 1466 loss: 5.79028722e-07
Iter: 1467 loss: 5.79024288e-07
Iter: 1468 loss: 5.78921117e-07
Iter: 1469 loss: 5.78780714e-07
Iter: 1470 loss: 5.78754793e-07
Iter: 1471 loss: 5.78597508e-07
Iter: 1472 loss: 5.78797199e-07
Iter: 1473 loss: 5.78543677e-07
Iter: 1474 loss: 5.7843522e-07
Iter: 1475 loss: 5.78411459e-07
Iter: 1476 loss: 5.78322897e-07
Iter: 1477 loss: 5.78289303e-07
Iter: 1478 loss: 5.78270942e-07
Iter: 1479 loss: 5.7820921e-07
Iter: 1480 loss: 5.78064601e-07
Iter: 1481 loss: 5.81090603e-07
Iter: 1482 loss: 5.78069432e-07
Iter: 1483 loss: 5.78011964e-07
Iter: 1484 loss: 5.78871777e-07
Iter: 1485 loss: 5.77993546e-07
Iter: 1486 loss: 5.7796143e-07
Iter: 1487 loss: 5.78573122e-07
Iter: 1488 loss: 5.77939147e-07
Iter: 1489 loss: 5.77903961e-07
Iter: 1490 loss: 5.77818867e-07
Iter: 1491 loss: 5.77834385e-07
Iter: 1492 loss: 5.77747358e-07
Iter: 1493 loss: 5.78727054e-07
Iter: 1494 loss: 5.77739513e-07
Iter: 1495 loss: 5.77699723e-07
Iter: 1496 loss: 5.776227e-07
Iter: 1497 loss: 5.77602577e-07
Iter: 1498 loss: 5.77520495e-07
Iter: 1499 loss: 5.7740624e-07
Iter: 1500 loss: 5.77402147e-07
Iter: 1501 loss: 5.77252763e-07
Iter: 1502 loss: 5.77948867e-07
Iter: 1503 loss: 5.77220817e-07
Iter: 1504 loss: 5.77095307e-07
Iter: 1505 loss: 5.77071944e-07
Iter: 1506 loss: 5.77014475e-07
Iter: 1507 loss: 5.76803757e-07
Iter: 1508 loss: 5.78914126e-07
Iter: 1509 loss: 5.76775e-07
Iter: 1510 loss: 5.76613616e-07
Iter: 1511 loss: 5.77248102e-07
Iter: 1512 loss: 5.76555522e-07
Iter: 1513 loss: 5.76455363e-07
Iter: 1514 loss: 5.76453e-07
Iter: 1515 loss: 5.76396133e-07
Iter: 1516 loss: 5.76341563e-07
Iter: 1517 loss: 5.76335538e-07
Iter: 1518 loss: 5.76292166e-07
Iter: 1519 loss: 5.76283924e-07
Iter: 1520 loss: 5.7625806e-07
Iter: 1521 loss: 5.76255445e-07
Iter: 1522 loss: 5.76213e-07
Iter: 1523 loss: 5.76194509e-07
Iter: 1524 loss: 5.76138291e-07
Iter: 1525 loss: 5.77066373e-07
Iter: 1526 loss: 5.76162506e-07
Iter: 1527 loss: 5.76086677e-07
Iter: 1528 loss: 5.76339801e-07
Iter: 1529 loss: 5.76074285e-07
Iter: 1530 loss: 5.75993909e-07
Iter: 1531 loss: 5.7595804e-07
Iter: 1532 loss: 5.75929789e-07
Iter: 1533 loss: 5.75816898e-07
Iter: 1534 loss: 5.75765796e-07
Iter: 1535 loss: 5.75720378e-07
Iter: 1536 loss: 5.75521597e-07
Iter: 1537 loss: 5.75825709e-07
Iter: 1538 loss: 5.75491299e-07
Iter: 1539 loss: 5.75408762e-07
Iter: 1540 loss: 5.75393074e-07
Iter: 1541 loss: 5.75318268e-07
Iter: 1542 loss: 5.75535125e-07
Iter: 1543 loss: 5.75301215e-07
Iter: 1544 loss: 5.75218223e-07
Iter: 1545 loss: 5.7509726e-07
Iter: 1546 loss: 5.78029244e-07
Iter: 1547 loss: 5.75100728e-07
Iter: 1548 loss: 5.75141371e-07
Iter: 1549 loss: 5.75076115e-07
Iter: 1550 loss: 5.75039621e-07
Iter: 1551 loss: 5.74968738e-07
Iter: 1552 loss: 5.75501872e-07
Iter: 1553 loss: 5.74931732e-07
Iter: 1554 loss: 5.74862099e-07
Iter: 1555 loss: 5.74874775e-07
Iter: 1556 loss: 5.74819069e-07
Iter: 1557 loss: 5.74828732e-07
Iter: 1558 loss: 5.74772457e-07
Iter: 1559 loss: 5.7470379e-07
Iter: 1560 loss: 5.74837827e-07
Iter: 1561 loss: 5.74681451e-07
Iter: 1562 loss: 5.74616251e-07
Iter: 1563 loss: 5.74786782e-07
Iter: 1564 loss: 5.74590786e-07
Iter: 1565 loss: 5.74538262e-07
Iter: 1566 loss: 5.74529508e-07
Iter: 1567 loss: 5.745095e-07
Iter: 1568 loss: 5.74442879e-07
Iter: 1569 loss: 5.74356136e-07
Iter: 1570 loss: 5.76544437e-07
Iter: 1571 loss: 5.74335729e-07
Iter: 1572 loss: 5.74253818e-07
Iter: 1573 loss: 5.74322655e-07
Iter: 1574 loss: 5.74206467e-07
Iter: 1575 loss: 5.74151557e-07
Iter: 1576 loss: 5.74663261e-07
Iter: 1577 loss: 5.74122907e-07
Iter: 1578 loss: 5.74026728e-07
Iter: 1579 loss: 5.74001319e-07
Iter: 1580 loss: 5.73938621e-07
Iter: 1581 loss: 5.73852503e-07
Iter: 1582 loss: 5.7485687e-07
Iter: 1583 loss: 5.73885814e-07
Iter: 1584 loss: 5.73805664e-07
Iter: 1585 loss: 5.74341e-07
Iter: 1586 loss: 5.73795774e-07
Iter: 1587 loss: 5.73751095e-07
Iter: 1588 loss: 5.73740749e-07
Iter: 1589 loss: 5.73713578e-07
Iter: 1590 loss: 5.73652187e-07
Iter: 1591 loss: 5.73672196e-07
Iter: 1592 loss: 5.73645252e-07
Iter: 1593 loss: 5.73592e-07
Iter: 1594 loss: 5.73866373e-07
Iter: 1595 loss: 5.73562488e-07
Iter: 1596 loss: 5.73476655e-07
Iter: 1597 loss: 5.73484556e-07
Iter: 1598 loss: 5.73413899e-07
Iter: 1599 loss: 5.7349348e-07
Iter: 1600 loss: 5.73422426e-07
Iter: 1601 loss: 5.73364389e-07
Iter: 1602 loss: 5.73412649e-07
Iter: 1603 loss: 5.73320563e-07
Iter: 1604 loss: 5.73225407e-07
Iter: 1605 loss: 5.73457e-07
Iter: 1606 loss: 5.73213924e-07
Iter: 1607 loss: 5.73142643e-07
Iter: 1608 loss: 5.73447096e-07
Iter: 1609 loss: 5.73133207e-07
Iter: 1610 loss: 5.73069485e-07
Iter: 1611 loss: 5.73059481e-07
Iter: 1612 loss: 5.73001159e-07
Iter: 1613 loss: 5.72929935e-07
Iter: 1614 loss: 5.73490752e-07
Iter: 1615 loss: 5.7294551e-07
Iter: 1616 loss: 5.7291021e-07
Iter: 1617 loss: 5.72929196e-07
Iter: 1618 loss: 5.7287707e-07
Iter: 1619 loss: 5.72849217e-07
Iter: 1620 loss: 5.72850865e-07
Iter: 1621 loss: 5.72782426e-07
Iter: 1622 loss: 5.73393208e-07
Iter: 1623 loss: 5.72792146e-07
Iter: 1624 loss: 5.72770773e-07
Iter: 1625 loss: 5.72671183e-07
Iter: 1626 loss: 5.73831926e-07
Iter: 1627 loss: 5.72669876e-07
Iter: 1628 loss: 5.72570855e-07
Iter: 1629 loss: 5.72969213e-07
Iter: 1630 loss: 5.72593081e-07
Iter: 1631 loss: 5.72461374e-07
Iter: 1632 loss: 5.72890258e-07
Iter: 1633 loss: 5.72459385e-07
Iter: 1634 loss: 5.72379463e-07
Iter: 1635 loss: 5.7242903e-07
Iter: 1636 loss: 5.72330578e-07
Iter: 1637 loss: 5.72277031e-07
Iter: 1638 loss: 5.72903161e-07
Iter: 1639 loss: 5.72269755e-07
Iter: 1640 loss: 5.72186877e-07
Iter: 1641 loss: 5.72206886e-07
Iter: 1642 loss: 5.72163231e-07
Iter: 1643 loss: 5.72103e-07
Iter: 1644 loss: 5.72284137e-07
Iter: 1645 loss: 5.72062277e-07
Iter: 1646 loss: 5.7201089e-07
Iter: 1647 loss: 5.72213366e-07
Iter: 1648 loss: 5.71982071e-07
Iter: 1649 loss: 5.71931082e-07
Iter: 1650 loss: 5.72241277e-07
Iter: 1651 loss: 5.71946202e-07
Iter: 1652 loss: 5.71883106e-07
Iter: 1653 loss: 5.71825694e-07
Iter: 1654 loss: 5.71796534e-07
Iter: 1655 loss: 5.71783687e-07
Iter: 1656 loss: 5.71745943e-07
Iter: 1657 loss: 5.71703595e-07
Iter: 1658 loss: 5.71616397e-07
Iter: 1659 loss: 5.73449597e-07
Iter: 1660 loss: 5.71628561e-07
Iter: 1661 loss: 5.71552505e-07
Iter: 1662 loss: 5.71811711e-07
Iter: 1663 loss: 5.71519479e-07
Iter: 1664 loss: 5.71445071e-07
Iter: 1665 loss: 5.71456781e-07
Iter: 1666 loss: 5.71376859e-07
Iter: 1667 loss: 5.71309101e-07
Iter: 1668 loss: 5.73058685e-07
Iter: 1669 loss: 5.71276132e-07
Iter: 1670 loss: 5.71220426e-07
Iter: 1671 loss: 5.72327622e-07
Iter: 1672 loss: 5.71204e-07
Iter: 1673 loss: 5.71130386e-07
Iter: 1674 loss: 5.7122918e-07
Iter: 1675 loss: 5.71082808e-07
Iter: 1676 loss: 5.70994871e-07
Iter: 1677 loss: 5.71075361e-07
Iter: 1678 loss: 5.70979296e-07
Iter: 1679 loss: 5.70889142e-07
Iter: 1680 loss: 5.70911197e-07
Iter: 1681 loss: 5.7083e-07
Iter: 1682 loss: 5.70749478e-07
Iter: 1683 loss: 5.71926421e-07
Iter: 1684 loss: 5.70748739e-07
Iter: 1685 loss: 5.70658472e-07
Iter: 1686 loss: 5.70918701e-07
Iter: 1687 loss: 5.7061186e-07
Iter: 1688 loss: 5.70547456e-07
Iter: 1689 loss: 5.70869133e-07
Iter: 1690 loss: 5.70549673e-07
Iter: 1691 loss: 5.70465261e-07
Iter: 1692 loss: 5.70438146e-07
Iter: 1693 loss: 5.70381872e-07
Iter: 1694 loss: 5.70295242e-07
Iter: 1695 loss: 5.70501129e-07
Iter: 1696 loss: 5.70255736e-07
Iter: 1697 loss: 5.70228622e-07
Iter: 1698 loss: 5.71010105e-07
Iter: 1699 loss: 5.70218617e-07
Iter: 1700 loss: 5.70137445e-07
Iter: 1701 loss: 5.69983513e-07
Iter: 1702 loss: 5.72481042e-07
Iter: 1703 loss: 5.70005341e-07
Iter: 1704 loss: 5.69882332e-07
Iter: 1705 loss: 5.6987227e-07
Iter: 1706 loss: 5.6981213e-07
Iter: 1707 loss: 5.69879603e-07
Iter: 1708 loss: 5.69760459e-07
Iter: 1709 loss: 5.69669623e-07
Iter: 1710 loss: 5.69616191e-07
Iter: 1711 loss: 5.6959027e-07
Iter: 1712 loss: 5.69452595e-07
Iter: 1713 loss: 5.69960378e-07
Iter: 1714 loss: 5.6944458e-07
Iter: 1715 loss: 5.69358292e-07
Iter: 1716 loss: 5.69993063e-07
Iter: 1717 loss: 5.6939183e-07
Iter: 1718 loss: 5.69320491e-07
Iter: 1719 loss: 5.69557528e-07
Iter: 1720 loss: 5.69284339e-07
Iter: 1721 loss: 5.69244492e-07
Iter: 1722 loss: 5.69392e-07
Iter: 1723 loss: 5.6922147e-07
Iter: 1724 loss: 5.69160761e-07
Iter: 1725 loss: 5.69374834e-07
Iter: 1726 loss: 5.69145413e-07
Iter: 1727 loss: 5.69115855e-07
Iter: 1728 loss: 5.69031954e-07
Iter: 1729 loss: 5.69025076e-07
Iter: 1730 loss: 5.68900873e-07
Iter: 1731 loss: 5.69592e-07
Iter: 1732 loss: 5.68909854e-07
Iter: 1733 loss: 5.68760129e-07
Iter: 1734 loss: 5.68943733e-07
Iter: 1735 loss: 5.68678956e-07
Iter: 1736 loss: 5.68591474e-07
Iter: 1737 loss: 5.68761948e-07
Iter: 1738 loss: 5.68585619e-07
Iter: 1739 loss: 5.68495693e-07
Iter: 1740 loss: 5.68717269e-07
Iter: 1741 loss: 5.68441919e-07
Iter: 1742 loss: 5.68331927e-07
Iter: 1743 loss: 5.68395706e-07
Iter: 1744 loss: 5.68245184e-07
Iter: 1745 loss: 5.68140194e-07
Iter: 1746 loss: 5.68531391e-07
Iter: 1747 loss: 5.68125188e-07
Iter: 1748 loss: 5.68068e-07
Iter: 1749 loss: 5.68096766e-07
Iter: 1750 loss: 5.6801e-07
Iter: 1751 loss: 5.67921575e-07
Iter: 1752 loss: 5.69194071e-07
Iter: 1753 loss: 5.67906625e-07
Iter: 1754 loss: 5.67861093e-07
Iter: 1755 loss: 5.6791157e-07
Iter: 1756 loss: 5.67827101e-07
Iter: 1757 loss: 5.67776851e-07
Iter: 1758 loss: 5.68153382e-07
Iter: 1759 loss: 5.67750646e-07
Iter: 1760 loss: 5.67708753e-07
Iter: 1761 loss: 5.67584891e-07
Iter: 1762 loss: 5.69581744e-07
Iter: 1763 loss: 5.67584891e-07
Iter: 1764 loss: 5.67478e-07
Iter: 1765 loss: 5.68487565e-07
Iter: 1766 loss: 5.6745921e-07
Iter: 1767 loss: 5.67364452e-07
Iter: 1768 loss: 5.68221708e-07
Iter: 1769 loss: 5.67340749e-07
Iter: 1770 loss: 5.67318921e-07
Iter: 1771 loss: 5.67200459e-07
Iter: 1772 loss: 5.688687e-07
Iter: 1773 loss: 5.67189602e-07
Iter: 1774 loss: 5.67059033e-07
Iter: 1775 loss: 5.67053235e-07
Iter: 1776 loss: 5.66984909e-07
Iter: 1777 loss: 5.66965127e-07
Iter: 1778 loss: 5.66928634e-07
Iter: 1779 loss: 5.66848087e-07
Iter: 1780 loss: 5.66909762e-07
Iter: 1781 loss: 5.66823132e-07
Iter: 1782 loss: 5.6670865e-07
Iter: 1783 loss: 5.66882477e-07
Iter: 1784 loss: 5.66652375e-07
Iter: 1785 loss: 5.66569383e-07
Iter: 1786 loss: 5.66559493e-07
Iter: 1787 loss: 5.66505776e-07
Iter: 1788 loss: 5.66486563e-07
Iter: 1789 loss: 5.66448648e-07
Iter: 1790 loss: 5.66387882e-07
Iter: 1791 loss: 5.66385552e-07
Iter: 1792 loss: 5.66331153e-07
Iter: 1793 loss: 5.66298525e-07
Iter: 1794 loss: 5.66287326e-07
Iter: 1795 loss: 5.66211952e-07
Iter: 1796 loss: 5.66138169e-07
Iter: 1797 loss: 5.66108838e-07
Iter: 1798 loss: 5.65976052e-07
Iter: 1799 loss: 5.66148628e-07
Iter: 1800 loss: 5.65926143e-07
Iter: 1801 loss: 5.65762548e-07
Iter: 1802 loss: 5.67622351e-07
Iter: 1803 loss: 5.65757091e-07
Iter: 1804 loss: 5.65754931e-07
Iter: 1805 loss: 5.65725486e-07
Iter: 1806 loss: 5.65690812e-07
Iter: 1807 loss: 5.65649088e-07
Iter: 1808 loss: 5.66563187e-07
Iter: 1809 loss: 5.65632547e-07
Iter: 1810 loss: 5.6556587e-07
Iter: 1811 loss: 5.6620695e-07
Iter: 1812 loss: 5.65577352e-07
Iter: 1813 loss: 5.65508401e-07
Iter: 1814 loss: 5.66001745e-07
Iter: 1815 loss: 5.65522498e-07
Iter: 1816 loss: 5.65527102e-07
Iter: 1817 loss: 5.65528126e-07
Iter: 1818 loss: 5.65520622e-07
Iter: 1819 loss: 5.6551761e-07
Iter: 1820 loss: 5.65517269e-07
Iter: 1821 loss: 5.65521873e-07
Iter: 1822 loss: 5.65525568e-07
Iter: 1823 loss: 5.65525909e-07
Iter: 1824 loss: 5.65517325e-07
Iter: 1825 loss: 5.65523578e-07
Iter: 1826 loss: 5.65520622e-07
Iter: 1827 loss: 5.65516928e-07
Iter: 1828 loss: 5.65527102e-07
Iter: 1829 loss: 5.65522612e-07
Iter: 1830 loss: 5.65523123e-07
Iter: 1831 loss: 5.6551994e-07
Iter: 1832 loss: 5.65520679e-07
Iter: 1833 loss: 5.65521191e-07
Iter: 1834 loss: 5.65521532e-07
Iter: 1835 loss: 5.65521873e-07
Iter: 1836 loss: 5.65523067e-07
Iter: 1837 loss: 5.65523123e-07
Iter: 1838 loss: 5.65523067e-07
Iter: 1839 loss: 5.65523123e-07
Iter: 1840 loss: 5.65523123e-07
Iter: 1841 loss: 5.65523067e-07
Iter: 1842 loss: 5.65523123e-07
Iter: 1843 loss: 5.65467246e-07
Iter: 1844 loss: 5.66246626e-07
Iter: 1845 loss: 5.65461619e-07
Iter: 1846 loss: 5.65449113e-07
Iter: 1847 loss: 5.6543422e-07
Iter: 1848 loss: 5.6539875e-07
Iter: 1849 loss: 5.65373e-07
Iter: 1850 loss: 5.65374307e-07
Iter: 1851 loss: 5.65322466e-07
Iter: 1852 loss: 5.65849632e-07
Iter: 1853 loss: 5.65339633e-07
Iter: 1854 loss: 5.6528495e-07
Iter: 1855 loss: 5.65181438e-07
Iter: 1856 loss: 5.65510959e-07
Iter: 1857 loss: 5.65121468e-07
Iter: 1858 loss: 5.6497322e-07
Iter: 1859 loss: 5.65331959e-07
Iter: 1860 loss: 5.64938659e-07
Iter: 1861 loss: 5.64814513e-07
Iter: 1862 loss: 5.64769039e-07
Iter: 1863 loss: 5.64713559e-07
Iter: 1864 loss: 5.6446197e-07
Iter: 1865 loss: 5.66126459e-07
Iter: 1866 loss: 5.64485674e-07
Iter: 1867 loss: 5.64368349e-07
Iter: 1868 loss: 5.64352e-07
Iter: 1869 loss: 5.64294169e-07
Iter: 1870 loss: 5.64205948e-07
Iter: 1871 loss: 5.642259e-07
Iter: 1872 loss: 5.6413154e-07
Iter: 1873 loss: 5.64107154e-07
Iter: 1874 loss: 5.64053607e-07
Iter: 1875 loss: 5.63949072e-07
Iter: 1876 loss: 5.63773142e-07
Iter: 1877 loss: 5.63757226e-07
Iter: 1878 loss: 5.63645358e-07
Iter: 1879 loss: 5.65601908e-07
Iter: 1880 loss: 5.63633819e-07
Iter: 1881 loss: 5.63613128e-07
Iter: 1882 loss: 5.63601816e-07
Iter: 1883 loss: 5.63567e-07
Iter: 1884 loss: 5.63521e-07
Iter: 1885 loss: 5.63506831e-07
Iter: 1886 loss: 5.63483468e-07
Iter: 1887 loss: 5.6405753e-07
Iter: 1888 loss: 5.63483e-07
Iter: 1889 loss: 5.63415711e-07
Iter: 1890 loss: 5.63368417e-07
Iter: 1891 loss: 5.63364836e-07
Iter: 1892 loss: 5.63334879e-07
Iter: 1893 loss: 5.63341132e-07
Iter: 1894 loss: 5.6328804e-07
Iter: 1895 loss: 5.63210449e-07
Iter: 1896 loss: 5.6322483e-07
Iter: 1897 loss: 5.63186404e-07
Iter: 1898 loss: 5.6312706e-07
Iter: 1899 loss: 5.64156664e-07
Iter: 1900 loss: 5.63124615e-07
Iter: 1901 loss: 5.63054698e-07
Iter: 1902 loss: 5.63811e-07
Iter: 1903 loss: 5.63064418e-07
Iter: 1904 loss: 5.62981768e-07
Iter: 1905 loss: 5.63007745e-07
Iter: 1906 loss: 5.62937316e-07
Iter: 1907 loss: 5.62865068e-07
Iter: 1908 loss: 5.62786738e-07
Iter: 1909 loss: 5.62763944e-07
Iter: 1910 loss: 5.62691298e-07
Iter: 1911 loss: 5.62944251e-07
Iter: 1912 loss: 5.62669527e-07
Iter: 1913 loss: 5.62606203e-07
Iter: 1914 loss: 5.63412186e-07
Iter: 1915 loss: 5.62592732e-07
Iter: 1916 loss: 5.62524122e-07
Iter: 1917 loss: 5.62558682e-07
Iter: 1918 loss: 5.62436298e-07
Iter: 1919 loss: 5.62425498e-07
Iter: 1920 loss: 5.63186461e-07
Iter: 1921 loss: 5.62427772e-07
Iter: 1922 loss: 5.62380478e-07
Iter: 1923 loss: 5.62401851e-07
Iter: 1924 loss: 5.62332e-07
Iter: 1925 loss: 5.62284e-07
Iter: 1926 loss: 5.62278046e-07
Iter: 1927 loss: 5.62239848e-07
Iter: 1928 loss: 5.62190962e-07
Iter: 1929 loss: 5.6296858e-07
Iter: 1930 loss: 5.621838e-07
Iter: 1931 loss: 5.62112348e-07
Iter: 1932 loss: 5.62124342e-07
Iter: 1933 loss: 5.62059256e-07
Iter: 1934 loss: 5.62015089e-07
Iter: 1935 loss: 5.62168566e-07
Iter: 1936 loss: 5.6197365e-07
Iter: 1937 loss: 5.61893785e-07
Iter: 1938 loss: 5.61910724e-07
Iter: 1939 loss: 5.61877755e-07
Iter: 1940 loss: 5.61782656e-07
Iter: 1941 loss: 5.62004971e-07
Iter: 1942 loss: 5.61735249e-07
Iter: 1943 loss: 5.61585921e-07
Iter: 1944 loss: 5.62284754e-07
Iter: 1945 loss: 5.61599506e-07
Iter: 1946 loss: 5.61490424e-07
Iter: 1947 loss: 5.61483489e-07
Iter: 1948 loss: 5.61414367e-07
Iter: 1949 loss: 5.61857121e-07
Iter: 1950 loss: 5.61395495e-07
Iter: 1951 loss: 5.61363777e-07
Iter: 1952 loss: 5.61302954e-07
Iter: 1953 loss: 5.6129727e-07
Iter: 1954 loss: 5.61249522e-07
Iter: 1955 loss: 5.61501793e-07
Iter: 1956 loss: 5.61215188e-07
Iter: 1957 loss: 5.61181139e-07
Iter: 1958 loss: 5.61164143e-07
Iter: 1959 loss: 5.61137313e-07
Iter: 1960 loss: 5.6113231e-07
Iter: 1961 loss: 5.61091e-07
Iter: 1962 loss: 5.610882e-07
Iter: 1963 loss: 5.61355364e-07
Iter: 1964 loss: 5.61109175e-07
Iter: 1965 loss: 5.61094339e-07
Iter: 1966 loss: 5.61096499e-07
Iter: 1967 loss: 5.61104684e-07
Iter: 1968 loss: 5.6110116e-07
Iter: 1969 loss: 5.61111563e-07
Iter: 1970 loss: 5.61108209e-07
Iter: 1971 loss: 5.61088768e-07
Iter: 1972 loss: 5.61083311e-07
Iter: 1973 loss: 5.61095362e-07
Iter: 1974 loss: 5.61091781e-07
Iter: 1975 loss: 5.61098659e-07
Iter: 1976 loss: 5.61083539e-07
Iter: 1977 loss: 5.61092349e-07
Iter: 1978 loss: 5.61085869e-07
Iter: 1979 loss: 5.61083652e-07
Iter: 1980 loss: 5.61091269e-07
Iter: 1981 loss: 5.61093145e-07
Iter: 1982 loss: 5.61093543e-07
Iter: 1983 loss: 5.6109e-07
Iter: 1984 loss: 5.61091554e-07
Iter: 1985 loss: 5.61091611e-07
Iter: 1986 loss: 5.61091724e-07
Iter: 1987 loss: 5.61091724e-07
Iter: 1988 loss: 5.61091554e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.4 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.4
+ date
Sun Nov  8 00:16:22 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0/300_100_100_100_1 --function f1 --psi 1 --phi 0.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.4/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d2f75620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d2f68ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d2f816a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d2fcfe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1f74ca048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac79e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d2f3ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac79eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d2f08378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1d2f08158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac769730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac6a3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac694ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac701730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac65fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac672bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac683400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac62bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac7346a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac734ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac5a4158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac593d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac734e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac4e0048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac4ef598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac4ef840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac52b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac521510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac413598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac4137b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac4b9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac3978c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac397378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac397048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac35a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc1ac351d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0063903453
test_loss: 0.0065473863
train_loss: 0.00334719
test_loss: 0.0034240088
train_loss: 0.0028403816
test_loss: 0.0027932154
train_loss: 0.0024859407
test_loss: 0.0024874443
train_loss: 0.002429146
test_loss: 0.0023756186
train_loss: 0.0023963482
test_loss: 0.0024155353
train_loss: 0.002486961
test_loss: 0.0026801447
train_loss: 0.0022096194
test_loss: 0.00227623
train_loss: 0.002330175
test_loss: 0.0021825917
train_loss: 0.0020863228
test_loss: 0.0023085007
train_loss: 0.002160095
test_loss: 0.0022138893
train_loss: 0.0021175477
test_loss: 0.0022708925
train_loss: 0.0020182494
test_loss: 0.0020857593
train_loss: 0.0023043866
test_loss: 0.0025004707
train_loss: 0.0020520696
test_loss: 0.0021049967
train_loss: 0.0020521176
test_loss: 0.0021461847
train_loss: 0.0022201596
test_loss: 0.0021358002
train_loss: 0.001978876
test_loss: 0.0022423454
train_loss: 0.0020182626
test_loss: 0.002066855
train_loss: 0.0020001282
test_loss: 0.0020969803
train_loss: 0.0021152298
test_loss: 0.0021149816
train_loss: 0.0019950215
test_loss: 0.0021395527
train_loss: 0.0019878447
test_loss: 0.0020089103
train_loss: 0.0019720604
test_loss: 0.0019661703
train_loss: 0.00205506
test_loss: 0.0022897606
train_loss: 0.0019165068
test_loss: 0.0022064205
train_loss: 0.001985085
test_loss: 0.002180307
train_loss: 0.0020295684
test_loss: 0.0020733539
train_loss: 0.001990213
test_loss: 0.0020679124
train_loss: 0.0021472322
test_loss: 0.002351103
train_loss: 0.002010124
test_loss: 0.0020062954
train_loss: 0.0019649984
test_loss: 0.002072154
train_loss: 0.001946494
test_loss: 0.0019580324
train_loss: 0.0019671977
test_loss: 0.0021517067
train_loss: 0.0018930582
test_loss: 0.0022193782
train_loss: 0.0019273312
test_loss: 0.0021859792
train_loss: 0.0018799967
test_loss: 0.00202474
train_loss: 0.0018254635
test_loss: 0.0019564396
train_loss: 0.0022105942
test_loss: 0.0020872818
train_loss: 0.0019427156
test_loss: 0.0020610178
train_loss: 0.0018392188
test_loss: 0.0019216916
train_loss: 0.0019664222
test_loss: 0.001983006
train_loss: 0.0019809955
test_loss: 0.0021172152
train_loss: 0.0017525267
test_loss: 0.0018674483
train_loss: 0.0018304917
test_loss: 0.0018503009
train_loss: 0.0017166693
test_loss: 0.0019941044
train_loss: 0.0021120089
test_loss: 0.0019926534
train_loss: 0.0017647848
test_loss: 0.00182919
train_loss: 0.0019569753
test_loss: 0.0019524369
train_loss: 0.0019642604
test_loss: 0.002146631
train_loss: 0.0020822883
test_loss: 0.0022379828
train_loss: 0.0019436673
test_loss: 0.002048964
train_loss: 0.0018874769
test_loss: 0.0020712158
train_loss: 0.0017533004
test_loss: 0.0018944454
train_loss: 0.001894586
test_loss: 0.002056265
train_loss: 0.0019125158
test_loss: 0.0019997202
train_loss: 0.0017991937
test_loss: 0.0018268697
train_loss: 0.0019436437
test_loss: 0.0021026828
train_loss: 0.0019744784
test_loss: 0.0018906741
train_loss: 0.0018870863
test_loss: 0.0018942716
train_loss: 0.0019092647
test_loss: 0.0019026271
train_loss: 0.0017606517
test_loss: 0.0019339116
train_loss: 0.0019198313
test_loss: 0.0019980841
train_loss: 0.0019643367
test_loss: 0.0019818263
train_loss: 0.001937784
test_loss: 0.001992454
train_loss: 0.0019047497
test_loss: 0.0023863823
train_loss: 0.0017206537
test_loss: 0.0018533274
train_loss: 0.0017599766
test_loss: 0.0018383741
train_loss: 0.0018092478
test_loss: 0.0020406465
train_loss: 0.0018037789
test_loss: 0.0020083596
train_loss: 0.0020655002
test_loss: 0.0020240888
train_loss: 0.0016828239
test_loss: 0.0019135604
train_loss: 0.0017551624
test_loss: 0.0018490789
train_loss: 0.0020208117
test_loss: 0.0019593402
train_loss: 0.0019049884
test_loss: 0.0018525139
train_loss: 0.0017822768
test_loss: 0.0019055995
train_loss: 0.0017021871
test_loss: 0.0019493434
train_loss: 0.0018743234
test_loss: 0.0019298495
train_loss: 0.001776583
test_loss: 0.0018383411
train_loss: 0.0020898497
test_loss: 0.0021378014
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.4/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 0.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.4/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e231b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e2415ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e2415378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e24159d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e237c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e237c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e22b5e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e226c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e226c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e22689d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e22688c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e21fff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e21e4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e21b9c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e21619d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e2182c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e2181620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e2181e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e20f7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e20f7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e209e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e209ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e2007a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e202bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e202b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e1fcd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e1f95598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e1fbc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6e1fbc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6d1847378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6d17f1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6d17a2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6d17b6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6d17c1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6d178b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc6a52b1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.74231524e-06
Iter: 2 loss: 1.05329018e-05
Iter: 3 loss: 5.08610265e-06
Iter: 4 loss: 4.45693331e-06
Iter: 5 loss: 7.82053212e-06
Iter: 6 loss: 4.36095615e-06
Iter: 7 loss: 4.20389233e-06
Iter: 8 loss: 4.32586148e-06
Iter: 9 loss: 4.1084877e-06
Iter: 10 loss: 3.86092415e-06
Iter: 11 loss: 4.70712303e-06
Iter: 12 loss: 3.79495259e-06
Iter: 13 loss: 3.6304923e-06
Iter: 14 loss: 3.67006396e-06
Iter: 15 loss: 3.51000972e-06
Iter: 16 loss: 3.43845841e-06
Iter: 17 loss: 3.98246448e-06
Iter: 18 loss: 3.43296506e-06
Iter: 19 loss: 3.36218181e-06
Iter: 20 loss: 3.7638813e-06
Iter: 21 loss: 3.35236155e-06
Iter: 22 loss: 3.29401087e-06
Iter: 23 loss: 3.18431671e-06
Iter: 24 loss: 5.61039906e-06
Iter: 25 loss: 3.18401158e-06
Iter: 26 loss: 3.16632463e-06
Iter: 27 loss: 3.13584405e-06
Iter: 28 loss: 3.08991093e-06
Iter: 29 loss: 2.97102383e-06
Iter: 30 loss: 3.93098844e-06
Iter: 31 loss: 2.9492096e-06
Iter: 32 loss: 2.83314671e-06
Iter: 33 loss: 3.18124876e-06
Iter: 34 loss: 2.79805363e-06
Iter: 35 loss: 2.72125908e-06
Iter: 36 loss: 2.73187925e-06
Iter: 37 loss: 2.6628104e-06
Iter: 38 loss: 2.61237687e-06
Iter: 39 loss: 2.60558227e-06
Iter: 40 loss: 2.56075759e-06
Iter: 41 loss: 2.89477157e-06
Iter: 42 loss: 2.55726263e-06
Iter: 43 loss: 2.53425151e-06
Iter: 44 loss: 2.48183824e-06
Iter: 45 loss: 3.1644488e-06
Iter: 46 loss: 2.47835487e-06
Iter: 47 loss: 2.47296225e-06
Iter: 48 loss: 2.44883472e-06
Iter: 49 loss: 2.43399154e-06
Iter: 50 loss: 2.39720885e-06
Iter: 51 loss: 2.76684e-06
Iter: 52 loss: 2.39276847e-06
Iter: 53 loss: 2.34062918e-06
Iter: 54 loss: 2.32768411e-06
Iter: 55 loss: 2.29478042e-06
Iter: 56 loss: 2.29814032e-06
Iter: 57 loss: 2.26695238e-06
Iter: 58 loss: 2.24502833e-06
Iter: 59 loss: 2.22311269e-06
Iter: 60 loss: 2.2185227e-06
Iter: 61 loss: 2.17979664e-06
Iter: 62 loss: 2.2006775e-06
Iter: 63 loss: 2.15432055e-06
Iter: 64 loss: 2.11787824e-06
Iter: 65 loss: 2.11708129e-06
Iter: 66 loss: 2.09976929e-06
Iter: 67 loss: 2.0673092e-06
Iter: 68 loss: 2.78371272e-06
Iter: 69 loss: 2.0672328e-06
Iter: 70 loss: 2.02217052e-06
Iter: 71 loss: 1.95791722e-06
Iter: 72 loss: 1.95572466e-06
Iter: 73 loss: 1.93892765e-06
Iter: 74 loss: 1.92305106e-06
Iter: 75 loss: 1.89124603e-06
Iter: 76 loss: 2.02961041e-06
Iter: 77 loss: 1.88485e-06
Iter: 78 loss: 1.86511215e-06
Iter: 79 loss: 1.8320884e-06
Iter: 80 loss: 1.83202587e-06
Iter: 81 loss: 1.83205668e-06
Iter: 82 loss: 1.81500172e-06
Iter: 83 loss: 1.80734469e-06
Iter: 84 loss: 1.78565028e-06
Iter: 85 loss: 1.89371815e-06
Iter: 86 loss: 1.77827167e-06
Iter: 87 loss: 1.75841376e-06
Iter: 88 loss: 1.92914467e-06
Iter: 89 loss: 1.75730634e-06
Iter: 90 loss: 1.74434194e-06
Iter: 91 loss: 1.82270298e-06
Iter: 92 loss: 1.74277216e-06
Iter: 93 loss: 1.72393538e-06
Iter: 94 loss: 1.72272189e-06
Iter: 95 loss: 1.70856015e-06
Iter: 96 loss: 1.68833901e-06
Iter: 97 loss: 1.69649013e-06
Iter: 98 loss: 1.67433882e-06
Iter: 99 loss: 1.6490153e-06
Iter: 100 loss: 2.0069906e-06
Iter: 101 loss: 1.64895653e-06
Iter: 102 loss: 1.63221785e-06
Iter: 103 loss: 1.60012871e-06
Iter: 104 loss: 2.27381088e-06
Iter: 105 loss: 1.59990952e-06
Iter: 106 loss: 1.57129978e-06
Iter: 107 loss: 1.66581253e-06
Iter: 108 loss: 1.56342742e-06
Iter: 109 loss: 1.5386853e-06
Iter: 110 loss: 1.73242893e-06
Iter: 111 loss: 1.53692758e-06
Iter: 112 loss: 1.52708526e-06
Iter: 113 loss: 1.52553821e-06
Iter: 114 loss: 1.5214523e-06
Iter: 115 loss: 1.5135829e-06
Iter: 116 loss: 1.67763847e-06
Iter: 117 loss: 1.51348718e-06
Iter: 118 loss: 1.50642495e-06
Iter: 119 loss: 1.50640221e-06
Iter: 120 loss: 1.50011329e-06
Iter: 121 loss: 1.49021525e-06
Iter: 122 loss: 1.49008292e-06
Iter: 123 loss: 1.48027311e-06
Iter: 124 loss: 1.46983905e-06
Iter: 125 loss: 1.46811487e-06
Iter: 126 loss: 1.4456e-06
Iter: 127 loss: 1.50217841e-06
Iter: 128 loss: 1.43766351e-06
Iter: 129 loss: 1.42338195e-06
Iter: 130 loss: 1.42126214e-06
Iter: 131 loss: 1.4149532e-06
Iter: 132 loss: 1.39850124e-06
Iter: 133 loss: 1.53087808e-06
Iter: 134 loss: 1.39548649e-06
Iter: 135 loss: 1.38970313e-06
Iter: 136 loss: 1.38444477e-06
Iter: 137 loss: 1.37890106e-06
Iter: 138 loss: 1.37107122e-06
Iter: 139 loss: 1.37082839e-06
Iter: 140 loss: 1.36363019e-06
Iter: 141 loss: 1.36470544e-06
Iter: 142 loss: 1.35820324e-06
Iter: 143 loss: 1.35372886e-06
Iter: 144 loss: 1.35300445e-06
Iter: 145 loss: 1.34814536e-06
Iter: 146 loss: 1.36243398e-06
Iter: 147 loss: 1.34666527e-06
Iter: 148 loss: 1.34237075e-06
Iter: 149 loss: 1.33388608e-06
Iter: 150 loss: 1.49855066e-06
Iter: 151 loss: 1.33378319e-06
Iter: 152 loss: 1.32554055e-06
Iter: 153 loss: 1.32538059e-06
Iter: 154 loss: 1.32112143e-06
Iter: 155 loss: 1.31734578e-06
Iter: 156 loss: 1.31622767e-06
Iter: 157 loss: 1.30971193e-06
Iter: 158 loss: 1.30010494e-06
Iter: 159 loss: 1.29988848e-06
Iter: 160 loss: 1.29565638e-06
Iter: 161 loss: 1.29435352e-06
Iter: 162 loss: 1.28882766e-06
Iter: 163 loss: 1.30441e-06
Iter: 164 loss: 1.28708609e-06
Iter: 165 loss: 1.28246779e-06
Iter: 166 loss: 1.27519718e-06
Iter: 167 loss: 1.27515386e-06
Iter: 168 loss: 1.27225098e-06
Iter: 169 loss: 1.27035617e-06
Iter: 170 loss: 1.26736029e-06
Iter: 171 loss: 1.26093892e-06
Iter: 172 loss: 1.36105734e-06
Iter: 173 loss: 1.26068551e-06
Iter: 174 loss: 1.25240524e-06
Iter: 175 loss: 1.2490467e-06
Iter: 176 loss: 1.24460689e-06
Iter: 177 loss: 1.24367727e-06
Iter: 178 loss: 1.24134954e-06
Iter: 179 loss: 1.23759366e-06
Iter: 180 loss: 1.23801522e-06
Iter: 181 loss: 1.23468635e-06
Iter: 182 loss: 1.23068685e-06
Iter: 183 loss: 1.23351515e-06
Iter: 184 loss: 1.22814549e-06
Iter: 185 loss: 1.22456322e-06
Iter: 186 loss: 1.22450388e-06
Iter: 187 loss: 1.22277947e-06
Iter: 188 loss: 1.21776134e-06
Iter: 189 loss: 1.2364535e-06
Iter: 190 loss: 1.21556286e-06
Iter: 191 loss: 1.20636844e-06
Iter: 192 loss: 1.22868073e-06
Iter: 193 loss: 1.20307982e-06
Iter: 194 loss: 1.19540618e-06
Iter: 195 loss: 1.28734848e-06
Iter: 196 loss: 1.19534445e-06
Iter: 197 loss: 1.18758896e-06
Iter: 198 loss: 1.2079804e-06
Iter: 199 loss: 1.185055e-06
Iter: 200 loss: 1.18040452e-06
Iter: 201 loss: 1.18251216e-06
Iter: 202 loss: 1.177223e-06
Iter: 203 loss: 1.17332127e-06
Iter: 204 loss: 1.17330455e-06
Iter: 205 loss: 1.16985677e-06
Iter: 206 loss: 1.16398587e-06
Iter: 207 loss: 1.16397928e-06
Iter: 208 loss: 1.16051785e-06
Iter: 209 loss: 1.17619766e-06
Iter: 210 loss: 1.15986313e-06
Iter: 211 loss: 1.15755199e-06
Iter: 212 loss: 1.17496597e-06
Iter: 213 loss: 1.1573768e-06
Iter: 214 loss: 1.15429611e-06
Iter: 215 loss: 1.15893204e-06
Iter: 216 loss: 1.15282307e-06
Iter: 217 loss: 1.15096327e-06
Iter: 218 loss: 1.15136766e-06
Iter: 219 loss: 1.14958107e-06
Iter: 220 loss: 1.14635895e-06
Iter: 221 loss: 1.16512888e-06
Iter: 222 loss: 1.14595412e-06
Iter: 223 loss: 1.14351383e-06
Iter: 224 loss: 1.13770977e-06
Iter: 225 loss: 1.20530694e-06
Iter: 226 loss: 1.13724445e-06
Iter: 227 loss: 1.13156739e-06
Iter: 228 loss: 1.14106638e-06
Iter: 229 loss: 1.12900307e-06
Iter: 230 loss: 1.12628777e-06
Iter: 231 loss: 1.12511702e-06
Iter: 232 loss: 1.12231805e-06
Iter: 233 loss: 1.12292378e-06
Iter: 234 loss: 1.12027988e-06
Iter: 235 loss: 1.11789177e-06
Iter: 236 loss: 1.12153032e-06
Iter: 237 loss: 1.11677537e-06
Iter: 238 loss: 1.11361408e-06
Iter: 239 loss: 1.13406145e-06
Iter: 240 loss: 1.11330439e-06
Iter: 241 loss: 1.11083511e-06
Iter: 242 loss: 1.10872099e-06
Iter: 243 loss: 1.10805649e-06
Iter: 244 loss: 1.1053985e-06
Iter: 245 loss: 1.1040479e-06
Iter: 246 loss: 1.10280462e-06
Iter: 247 loss: 1.10279211e-06
Iter: 248 loss: 1.10095141e-06
Iter: 249 loss: 1.09945813e-06
Iter: 250 loss: 1.09813334e-06
Iter: 251 loss: 1.0977983e-06
Iter: 252 loss: 1.09579878e-06
Iter: 253 loss: 1.09797782e-06
Iter: 254 loss: 1.09473604e-06
Iter: 255 loss: 1.09109249e-06
Iter: 256 loss: 1.09931057e-06
Iter: 257 loss: 1.08975064e-06
Iter: 258 loss: 1.08822064e-06
Iter: 259 loss: 1.08518566e-06
Iter: 260 loss: 1.14288559e-06
Iter: 261 loss: 1.08512006e-06
Iter: 262 loss: 1.08107633e-06
Iter: 263 loss: 1.10075553e-06
Iter: 264 loss: 1.08039171e-06
Iter: 265 loss: 1.07799951e-06
Iter: 266 loss: 1.07778624e-06
Iter: 267 loss: 1.07633673e-06
Iter: 268 loss: 1.07278242e-06
Iter: 269 loss: 1.11017926e-06
Iter: 270 loss: 1.07234939e-06
Iter: 271 loss: 1.06976813e-06
Iter: 272 loss: 1.06955599e-06
Iter: 273 loss: 1.0673524e-06
Iter: 274 loss: 1.06934704e-06
Iter: 275 loss: 1.06603284e-06
Iter: 276 loss: 1.06442144e-06
Iter: 277 loss: 1.06403274e-06
Iter: 278 loss: 1.06295795e-06
Iter: 279 loss: 1.06092261e-06
Iter: 280 loss: 1.07279982e-06
Iter: 281 loss: 1.0606542e-06
Iter: 282 loss: 1.05973027e-06
Iter: 283 loss: 1.05963261e-06
Iter: 284 loss: 1.05893116e-06
Iter: 285 loss: 1.05750121e-06
Iter: 286 loss: 1.07883943e-06
Iter: 287 loss: 1.05743413e-06
Iter: 288 loss: 1.05653726e-06
Iter: 289 loss: 1.056472e-06
Iter: 290 loss: 1.05551112e-06
Iter: 291 loss: 1.05350671e-06
Iter: 292 loss: 1.08108804e-06
Iter: 293 loss: 1.05336517e-06
Iter: 294 loss: 1.05067238e-06
Iter: 295 loss: 1.04653918e-06
Iter: 296 loss: 1.04646779e-06
Iter: 297 loss: 1.04772801e-06
Iter: 298 loss: 1.04484729e-06
Iter: 299 loss: 1.04310857e-06
Iter: 300 loss: 1.04250023e-06
Iter: 301 loss: 1.04156049e-06
Iter: 302 loss: 1.03892489e-06
Iter: 303 loss: 1.03615412e-06
Iter: 304 loss: 1.03565571e-06
Iter: 305 loss: 1.0359845e-06
Iter: 306 loss: 1.03393188e-06
Iter: 307 loss: 1.03320542e-06
Iter: 308 loss: 1.03160858e-06
Iter: 309 loss: 1.05519212e-06
Iter: 310 loss: 1.03156015e-06
Iter: 311 loss: 1.02951981e-06
Iter: 312 loss: 1.03096374e-06
Iter: 313 loss: 1.02827346e-06
Iter: 314 loss: 1.0272588e-06
Iter: 315 loss: 1.02702734e-06
Iter: 316 loss: 1.02588444e-06
Iter: 317 loss: 1.0261025e-06
Iter: 318 loss: 1.02507624e-06
Iter: 319 loss: 1.0238083e-06
Iter: 320 loss: 1.02338868e-06
Iter: 321 loss: 1.0226189e-06
Iter: 322 loss: 1.02095782e-06
Iter: 323 loss: 1.02094987e-06
Iter: 324 loss: 1.02026593e-06
Iter: 325 loss: 1.01849196e-06
Iter: 326 loss: 1.03662933e-06
Iter: 327 loss: 1.01826379e-06
Iter: 328 loss: 1.01580633e-06
Iter: 329 loss: 1.01704018e-06
Iter: 330 loss: 1.01411081e-06
Iter: 331 loss: 1.01420733e-06
Iter: 332 loss: 1.01288094e-06
Iter: 333 loss: 1.01176443e-06
Iter: 334 loss: 1.00959028e-06
Iter: 335 loss: 1.05319782e-06
Iter: 336 loss: 1.0095705e-06
Iter: 337 loss: 1.00721149e-06
Iter: 338 loss: 1.01500723e-06
Iter: 339 loss: 1.00657928e-06
Iter: 340 loss: 1.00466241e-06
Iter: 341 loss: 1.00468674e-06
Iter: 342 loss: 1.00386671e-06
Iter: 343 loss: 1.00186276e-06
Iter: 344 loss: 1.01920409e-06
Iter: 345 loss: 1.00151397e-06
Iter: 346 loss: 1.00025102e-06
Iter: 347 loss: 1.00017746e-06
Iter: 348 loss: 9.99434405e-07
Iter: 349 loss: 9.99446684e-07
Iter: 350 loss: 9.98935775e-07
Iter: 351 loss: 9.97744337e-07
Iter: 352 loss: 1.00841032e-06
Iter: 353 loss: 9.97539928e-07
Iter: 354 loss: 9.96597464e-07
Iter: 355 loss: 9.96536301e-07
Iter: 356 loss: 9.95649543e-07
Iter: 357 loss: 9.95107484e-07
Iter: 358 loss: 9.94788252e-07
Iter: 359 loss: 9.93564868e-07
Iter: 360 loss: 9.91468369e-07
Iter: 361 loss: 9.91489287e-07
Iter: 362 loss: 9.88989314e-07
Iter: 363 loss: 1.00713783e-06
Iter: 364 loss: 9.88771262e-07
Iter: 365 loss: 9.8772307e-07
Iter: 366 loss: 9.87574481e-07
Iter: 367 loss: 9.86626105e-07
Iter: 368 loss: 9.84442636e-07
Iter: 369 loss: 1.00944681e-06
Iter: 370 loss: 9.84214e-07
Iter: 371 loss: 9.83101131e-07
Iter: 372 loss: 9.83071e-07
Iter: 373 loss: 9.81748826e-07
Iter: 374 loss: 9.83343625e-07
Iter: 375 loss: 9.810758e-07
Iter: 376 loss: 9.80081609e-07
Iter: 377 loss: 9.7974339e-07
Iter: 378 loss: 9.79141e-07
Iter: 379 loss: 9.7788336e-07
Iter: 380 loss: 9.77958e-07
Iter: 381 loss: 9.76916795e-07
Iter: 382 loss: 9.76209549e-07
Iter: 383 loss: 9.75833927e-07
Iter: 384 loss: 9.75107469e-07
Iter: 385 loss: 9.73748e-07
Iter: 386 loss: 1.00091347e-06
Iter: 387 loss: 9.73738224e-07
Iter: 388 loss: 9.72894e-07
Iter: 389 loss: 9.8569285e-07
Iter: 390 loss: 9.7289842e-07
Iter: 391 loss: 9.71894451e-07
Iter: 392 loss: 9.70998371e-07
Iter: 393 loss: 9.70735073e-07
Iter: 394 loss: 9.69535e-07
Iter: 395 loss: 9.72224939e-07
Iter: 396 loss: 9.69001462e-07
Iter: 397 loss: 9.67920414e-07
Iter: 398 loss: 9.66657353e-07
Iter: 399 loss: 9.66473181e-07
Iter: 400 loss: 9.65882691e-07
Iter: 401 loss: 9.65380877e-07
Iter: 402 loss: 9.645006e-07
Iter: 403 loss: 9.63755383e-07
Iter: 404 loss: 9.63496e-07
Iter: 405 loss: 9.62215722e-07
Iter: 406 loss: 9.62515173e-07
Iter: 407 loss: 9.61307933e-07
Iter: 408 loss: 9.59930503e-07
Iter: 409 loss: 9.59921067e-07
Iter: 410 loss: 9.5931e-07
Iter: 411 loss: 9.58458372e-07
Iter: 412 loss: 9.58448709e-07
Iter: 413 loss: 9.57609586e-07
Iter: 414 loss: 9.6329336e-07
Iter: 415 loss: 9.57573548e-07
Iter: 416 loss: 9.56690201e-07
Iter: 417 loss: 9.59703584e-07
Iter: 418 loss: 9.56453277e-07
Iter: 419 loss: 9.559609e-07
Iter: 420 loss: 9.55945211e-07
Iter: 421 loss: 9.55555379e-07
Iter: 422 loss: 9.54764118e-07
Iter: 423 loss: 9.60196758e-07
Iter: 424 loss: 9.54710458e-07
Iter: 425 loss: 9.54088478e-07
Iter: 426 loss: 9.53074846e-07
Iter: 427 loss: 9.53059782e-07
Iter: 428 loss: 9.51859306e-07
Iter: 429 loss: 9.52442747e-07
Iter: 430 loss: 9.51015295e-07
Iter: 431 loss: 9.49312835e-07
Iter: 432 loss: 9.57009661e-07
Iter: 433 loss: 9.49036803e-07
Iter: 434 loss: 9.48143054e-07
Iter: 435 loss: 9.48048637e-07
Iter: 436 loss: 9.47586841e-07
Iter: 437 loss: 9.46647219e-07
Iter: 438 loss: 9.64411242e-07
Iter: 439 loss: 9.46645514e-07
Iter: 440 loss: 9.45823956e-07
Iter: 441 loss: 9.45820091e-07
Iter: 442 loss: 9.45115289e-07
Iter: 443 loss: 9.44942087e-07
Iter: 444 loss: 9.44529347e-07
Iter: 445 loss: 9.43905206e-07
Iter: 446 loss: 9.44844714e-07
Iter: 447 loss: 9.43639805e-07
Iter: 448 loss: 9.42975817e-07
Iter: 449 loss: 9.52029e-07
Iter: 450 loss: 9.42983888e-07
Iter: 451 loss: 9.42468546e-07
Iter: 452 loss: 9.41677797e-07
Iter: 453 loss: 9.41682572e-07
Iter: 454 loss: 9.41191047e-07
Iter: 455 loss: 9.41159215e-07
Iter: 456 loss: 9.40612438e-07
Iter: 457 loss: 9.39597896e-07
Iter: 458 loss: 9.60039074e-07
Iter: 459 loss: 9.3960972e-07
Iter: 460 loss: 9.38405037e-07
Iter: 461 loss: 9.40658083e-07
Iter: 462 loss: 9.37901e-07
Iter: 463 loss: 9.37135042e-07
Iter: 464 loss: 9.3942856e-07
Iter: 465 loss: 9.36872311e-07
Iter: 466 loss: 9.36179219e-07
Iter: 467 loss: 9.45924285e-07
Iter: 468 loss: 9.36164611e-07
Iter: 469 loss: 9.3546e-07
Iter: 470 loss: 9.35682237e-07
Iter: 471 loss: 9.34931563e-07
Iter: 472 loss: 9.34393086e-07
Iter: 473 loss: 9.35119431e-07
Iter: 474 loss: 9.34081356e-07
Iter: 475 loss: 9.33143951e-07
Iter: 476 loss: 9.36782214e-07
Iter: 477 loss: 9.32900093e-07
Iter: 478 loss: 9.32314606e-07
Iter: 479 loss: 9.32179773e-07
Iter: 480 loss: 9.31807506e-07
Iter: 481 loss: 9.31296142e-07
Iter: 482 loss: 9.31307682e-07
Iter: 483 loss: 9.30764429e-07
Iter: 484 loss: 9.2974085e-07
Iter: 485 loss: 9.5372161e-07
Iter: 486 loss: 9.29760347e-07
Iter: 487 loss: 9.29066e-07
Iter: 488 loss: 9.39296115e-07
Iter: 489 loss: 9.29042642e-07
Iter: 490 loss: 9.28522866e-07
Iter: 491 loss: 9.30972305e-07
Iter: 492 loss: 9.28415091e-07
Iter: 493 loss: 9.2810177e-07
Iter: 494 loss: 9.2727646e-07
Iter: 495 loss: 9.36330821e-07
Iter: 496 loss: 9.27189035e-07
Iter: 497 loss: 9.26061944e-07
Iter: 498 loss: 9.30143528e-07
Iter: 499 loss: 9.2574885e-07
Iter: 500 loss: 9.25145798e-07
Iter: 501 loss: 9.25164272e-07
Iter: 502 loss: 9.24462483e-07
Iter: 503 loss: 9.25426434e-07
Iter: 504 loss: 9.24206233e-07
Iter: 505 loss: 9.23430889e-07
Iter: 506 loss: 9.22645597e-07
Iter: 507 loss: 9.22505194e-07
Iter: 508 loss: 9.21991386e-07
Iter: 509 loss: 9.21836261e-07
Iter: 510 loss: 9.21481046e-07
Iter: 511 loss: 9.20668526e-07
Iter: 512 loss: 9.32509295e-07
Iter: 513 loss: 9.20621517e-07
Iter: 514 loss: 9.19871e-07
Iter: 515 loss: 9.28496775e-07
Iter: 516 loss: 9.19845377e-07
Iter: 517 loss: 9.19179115e-07
Iter: 518 loss: 9.21531921e-07
Iter: 519 loss: 9.18968908e-07
Iter: 520 loss: 9.1861466e-07
Iter: 521 loss: 9.18333967e-07
Iter: 522 loss: 9.18211754e-07
Iter: 523 loss: 9.17507123e-07
Iter: 524 loss: 9.21560172e-07
Iter: 525 loss: 9.1740003e-07
Iter: 526 loss: 9.1685348e-07
Iter: 527 loss: 9.16217687e-07
Iter: 528 loss: 9.16195177e-07
Iter: 529 loss: 9.15381804e-07
Iter: 530 loss: 9.15864405e-07
Iter: 531 loss: 9.14863676e-07
Iter: 532 loss: 9.13752956e-07
Iter: 533 loss: 9.20505215e-07
Iter: 534 loss: 9.13654731e-07
Iter: 535 loss: 9.12962491e-07
Iter: 536 loss: 9.12990458e-07
Iter: 537 loss: 9.12469545e-07
Iter: 538 loss: 9.11669417e-07
Iter: 539 loss: 9.31991167e-07
Iter: 540 loss: 9.11680104e-07
Iter: 541 loss: 9.11092854e-07
Iter: 542 loss: 9.11063694e-07
Iter: 543 loss: 9.10627648e-07
Iter: 544 loss: 9.10275332e-07
Iter: 545 loss: 9.10137373e-07
Iter: 546 loss: 9.09639652e-07
Iter: 547 loss: 9.11431073e-07
Iter: 548 loss: 9.09507548e-07
Iter: 549 loss: 9.08908476e-07
Iter: 550 loss: 9.13063218e-07
Iter: 551 loss: 9.08908532e-07
Iter: 552 loss: 9.0854985e-07
Iter: 553 loss: 9.08129095e-07
Iter: 554 loss: 9.08067875e-07
Iter: 555 loss: 9.07679e-07
Iter: 556 loss: 9.07659626e-07
Iter: 557 loss: 9.07300659e-07
Iter: 558 loss: 9.06412765e-07
Iter: 559 loss: 9.1925574e-07
Iter: 560 loss: 9.06385708e-07
Iter: 561 loss: 9.05587967e-07
Iter: 562 loss: 9.08201287e-07
Iter: 563 loss: 9.05362469e-07
Iter: 564 loss: 9.04588319e-07
Iter: 565 loss: 9.0398828e-07
Iter: 566 loss: 9.03724867e-07
Iter: 567 loss: 9.03198043e-07
Iter: 568 loss: 9.02978115e-07
Iter: 569 loss: 9.02378815e-07
Iter: 570 loss: 9.03190312e-07
Iter: 571 loss: 9.02117904e-07
Iter: 572 loss: 9.01650878e-07
Iter: 573 loss: 9.01857334e-07
Iter: 574 loss: 9.01320448e-07
Iter: 575 loss: 9.00432e-07
Iter: 576 loss: 9.03007333e-07
Iter: 577 loss: 9.00200234e-07
Iter: 578 loss: 8.99722579e-07
Iter: 579 loss: 9.00648729e-07
Iter: 580 loss: 8.99523684e-07
Iter: 581 loss: 8.99146471e-07
Iter: 582 loss: 9.0392524e-07
Iter: 583 loss: 8.99155339e-07
Iter: 584 loss: 8.98860606e-07
Iter: 585 loss: 8.98332e-07
Iter: 586 loss: 8.9832929e-07
Iter: 587 loss: 8.98019664e-07
Iter: 588 loss: 8.98013639e-07
Iter: 589 loss: 8.97718792e-07
Iter: 590 loss: 8.97522114e-07
Iter: 591 loss: 8.9733345e-07
Iter: 592 loss: 8.96820779e-07
Iter: 593 loss: 8.96207439e-07
Iter: 594 loss: 8.96140932e-07
Iter: 595 loss: 8.95330231e-07
Iter: 596 loss: 8.99652093e-07
Iter: 597 loss: 8.95217e-07
Iter: 598 loss: 8.94542268e-07
Iter: 599 loss: 8.98277904e-07
Iter: 600 loss: 8.94403513e-07
Iter: 601 loss: 8.93522952e-07
Iter: 602 loss: 8.96537756e-07
Iter: 603 loss: 8.93277274e-07
Iter: 604 loss: 8.92763524e-07
Iter: 605 loss: 8.93528352e-07
Iter: 606 loss: 8.92476066e-07
Iter: 607 loss: 8.91963e-07
Iter: 608 loss: 8.98323833e-07
Iter: 609 loss: 8.91969364e-07
Iter: 610 loss: 8.91597949e-07
Iter: 611 loss: 8.91017521e-07
Iter: 612 loss: 8.91010757e-07
Iter: 613 loss: 8.90732451e-07
Iter: 614 loss: 8.90693229e-07
Iter: 615 loss: 8.90400202e-07
Iter: 616 loss: 8.90208469e-07
Iter: 617 loss: 8.9015532e-07
Iter: 618 loss: 8.89822729e-07
Iter: 619 loss: 8.90047374e-07
Iter: 620 loss: 8.89586e-07
Iter: 621 loss: 8.89193075e-07
Iter: 622 loss: 8.95583298e-07
Iter: 623 loss: 8.89205353e-07
Iter: 624 loss: 8.88937961e-07
Iter: 625 loss: 8.88392776e-07
Iter: 626 loss: 8.94017319e-07
Iter: 627 loss: 8.88339628e-07
Iter: 628 loss: 8.8763e-07
Iter: 629 loss: 8.90445e-07
Iter: 630 loss: 8.8743883e-07
Iter: 631 loss: 8.86931502e-07
Iter: 632 loss: 8.89509693e-07
Iter: 633 loss: 8.86902285e-07
Iter: 634 loss: 8.86327939e-07
Iter: 635 loss: 8.89588648e-07
Iter: 636 loss: 8.86260807e-07
Iter: 637 loss: 8.85830104e-07
Iter: 638 loss: 8.85855854e-07
Iter: 639 loss: 8.85488362e-07
Iter: 640 loss: 8.85189479e-07
Iter: 641 loss: 8.85161796e-07
Iter: 642 loss: 8.84878318e-07
Iter: 643 loss: 8.8428618e-07
Iter: 644 loss: 8.95691926e-07
Iter: 645 loss: 8.84237238e-07
Iter: 646 loss: 8.83726159e-07
Iter: 647 loss: 8.83721668e-07
Iter: 648 loss: 8.83242649e-07
Iter: 649 loss: 8.83438531e-07
Iter: 650 loss: 8.82937172e-07
Iter: 651 loss: 8.82495613e-07
Iter: 652 loss: 8.81844187e-07
Iter: 653 loss: 8.81797348e-07
Iter: 654 loss: 8.8120629e-07
Iter: 655 loss: 8.81192705e-07
Iter: 656 loss: 8.80650589e-07
Iter: 657 loss: 8.80067603e-07
Iter: 658 loss: 8.80014e-07
Iter: 659 loss: 8.79543279e-07
Iter: 660 loss: 8.80333403e-07
Iter: 661 loss: 8.79362062e-07
Iter: 662 loss: 8.78820742e-07
Iter: 663 loss: 8.80997561e-07
Iter: 664 loss: 8.7871706e-07
Iter: 665 loss: 8.78535161e-07
Iter: 666 loss: 8.78486048e-07
Iter: 667 loss: 8.78352353e-07
Iter: 668 loss: 8.78105595e-07
Iter: 669 loss: 8.8432671e-07
Iter: 670 loss: 8.780695e-07
Iter: 671 loss: 8.77627485e-07
Iter: 672 loss: 8.76752608e-07
Iter: 673 loss: 8.933456e-07
Iter: 674 loss: 8.76709919e-07
Iter: 675 loss: 8.76030072e-07
Iter: 676 loss: 8.8520909e-07
Iter: 677 loss: 8.76058095e-07
Iter: 678 loss: 8.7522892e-07
Iter: 679 loss: 8.77368052e-07
Iter: 680 loss: 8.74938394e-07
Iter: 681 loss: 8.74392754e-07
Iter: 682 loss: 8.74121099e-07
Iter: 683 loss: 8.73877809e-07
Iter: 684 loss: 8.73305282e-07
Iter: 685 loss: 8.77344746e-07
Iter: 686 loss: 8.7326157e-07
Iter: 687 loss: 8.7280182e-07
Iter: 688 loss: 8.77455136e-07
Iter: 689 loss: 8.72772489e-07
Iter: 690 loss: 8.72559212e-07
Iter: 691 loss: 8.72410737e-07
Iter: 692 loss: 8.72380269e-07
Iter: 693 loss: 8.72141413e-07
Iter: 694 loss: 8.72134365e-07
Iter: 695 loss: 8.71916711e-07
Iter: 696 loss: 8.71487e-07
Iter: 697 loss: 8.77436719e-07
Iter: 698 loss: 8.71481e-07
Iter: 699 loss: 8.71091459e-07
Iter: 700 loss: 8.72697228e-07
Iter: 701 loss: 8.71018301e-07
Iter: 702 loss: 8.70643078e-07
Iter: 703 loss: 8.73849274e-07
Iter: 704 loss: 8.70628242e-07
Iter: 705 loss: 8.70297868e-07
Iter: 706 loss: 8.69942369e-07
Iter: 707 loss: 8.69872451e-07
Iter: 708 loss: 8.69364669e-07
Iter: 709 loss: 8.69671794e-07
Iter: 710 loss: 8.69013e-07
Iter: 711 loss: 8.68481095e-07
Iter: 712 loss: 8.68455572e-07
Iter: 713 loss: 8.68010829e-07
Iter: 714 loss: 8.68825794e-07
Iter: 715 loss: 8.67826031e-07
Iter: 716 loss: 8.6753397e-07
Iter: 717 loss: 8.66919834e-07
Iter: 718 loss: 8.80598691e-07
Iter: 719 loss: 8.66902e-07
Iter: 720 loss: 8.66403e-07
Iter: 721 loss: 8.74528837e-07
Iter: 722 loss: 8.66400455e-07
Iter: 723 loss: 8.66017388e-07
Iter: 724 loss: 8.70244946e-07
Iter: 725 loss: 8.65986635e-07
Iter: 726 loss: 8.6578018e-07
Iter: 727 loss: 8.65370282e-07
Iter: 728 loss: 8.70616077e-07
Iter: 729 loss: 8.65307641e-07
Iter: 730 loss: 8.65153e-07
Iter: 731 loss: 8.65027459e-07
Iter: 732 loss: 8.64817139e-07
Iter: 733 loss: 8.64442086e-07
Iter: 734 loss: 8.71151428e-07
Iter: 735 loss: 8.64415881e-07
Iter: 736 loss: 8.64088747e-07
Iter: 737 loss: 8.65438381e-07
Iter: 738 loss: 8.64004448e-07
Iter: 739 loss: 8.63556409e-07
Iter: 740 loss: 8.65628181e-07
Iter: 741 loss: 8.63467449e-07
Iter: 742 loss: 8.63261903e-07
Iter: 743 loss: 8.63090804e-07
Iter: 744 loss: 8.6303794e-07
Iter: 745 loss: 8.62698357e-07
Iter: 746 loss: 8.63073637e-07
Iter: 747 loss: 8.62489856e-07
Iter: 748 loss: 8.62246338e-07
Iter: 749 loss: 8.6221246e-07
Iter: 750 loss: 8.61997e-07
Iter: 751 loss: 8.61726164e-07
Iter: 752 loss: 8.61707235e-07
Iter: 753 loss: 8.61287447e-07
Iter: 754 loss: 8.61100489e-07
Iter: 755 loss: 8.60871069e-07
Iter: 756 loss: 8.61174044e-07
Iter: 757 loss: 8.60703494e-07
Iter: 758 loss: 8.60541832e-07
Iter: 759 loss: 8.60249258e-07
Iter: 760 loss: 8.64542869e-07
Iter: 761 loss: 8.60201339e-07
Iter: 762 loss: 8.59820375e-07
Iter: 763 loss: 8.60029331e-07
Iter: 764 loss: 8.59586748e-07
Iter: 765 loss: 8.59469878e-07
Iter: 766 loss: 8.5934e-07
Iter: 767 loss: 8.59193335e-07
Iter: 768 loss: 8.58840735e-07
Iter: 769 loss: 8.62135323e-07
Iter: 770 loss: 8.58805947e-07
Iter: 771 loss: 8.58436e-07
Iter: 772 loss: 8.61772833e-07
Iter: 773 loss: 8.58424073e-07
Iter: 774 loss: 8.58117119e-07
Iter: 775 loss: 8.59651038e-07
Iter: 776 loss: 8.58044302e-07
Iter: 777 loss: 8.57775603e-07
Iter: 778 loss: 8.57222119e-07
Iter: 779 loss: 8.62735078e-07
Iter: 780 loss: 8.57134523e-07
Iter: 781 loss: 8.56619067e-07
Iter: 782 loss: 8.59684121e-07
Iter: 783 loss: 8.56562508e-07
Iter: 784 loss: 8.56226507e-07
Iter: 785 loss: 8.56227359e-07
Iter: 786 loss: 8.55861117e-07
Iter: 787 loss: 8.55396479e-07
Iter: 788 loss: 8.55363737e-07
Iter: 789 loss: 8.54972711e-07
Iter: 790 loss: 8.56152383e-07
Iter: 791 loss: 8.54842483e-07
Iter: 792 loss: 8.54729137e-07
Iter: 793 loss: 8.54624545e-07
Iter: 794 loss: 8.54510745e-07
Iter: 795 loss: 8.5405776e-07
Iter: 796 loss: 8.58018723e-07
Iter: 797 loss: 8.53997335e-07
Iter: 798 loss: 8.53664176e-07
Iter: 799 loss: 8.55706276e-07
Iter: 800 loss: 8.53600795e-07
Iter: 801 loss: 8.53259166e-07
Iter: 802 loss: 8.55684618e-07
Iter: 803 loss: 8.53209883e-07
Iter: 804 loss: 8.52937433e-07
Iter: 805 loss: 8.52771564e-07
Iter: 806 loss: 8.52634e-07
Iter: 807 loss: 8.52358767e-07
Iter: 808 loss: 8.52542769e-07
Iter: 809 loss: 8.52155267e-07
Iter: 810 loss: 8.51812047e-07
Iter: 811 loss: 8.56572058e-07
Iter: 812 loss: 8.51772e-07
Iter: 813 loss: 8.51458196e-07
Iter: 814 loss: 8.51053869e-07
Iter: 815 loss: 8.51002824e-07
Iter: 816 loss: 8.50718322e-07
Iter: 817 loss: 8.51194443e-07
Iter: 818 loss: 8.50564447e-07
Iter: 819 loss: 8.50339802e-07
Iter: 820 loss: 8.50349295e-07
Iter: 821 loss: 8.50085542e-07
Iter: 822 loss: 8.49705771e-07
Iter: 823 loss: 8.49733226e-07
Iter: 824 loss: 8.49420132e-07
Iter: 825 loss: 8.49429341e-07
Iter: 826 loss: 8.49122614e-07
Iter: 827 loss: 8.49216349e-07
Iter: 828 loss: 8.4896169e-07
Iter: 829 loss: 8.48831e-07
Iter: 830 loss: 8.48547757e-07
Iter: 831 loss: 8.5384022e-07
Iter: 832 loss: 8.48530703e-07
Iter: 833 loss: 8.48259106e-07
Iter: 834 loss: 8.48518084e-07
Iter: 835 loss: 8.48072091e-07
Iter: 836 loss: 8.47748e-07
Iter: 837 loss: 8.47745582e-07
Iter: 838 loss: 8.47584602e-07
Iter: 839 loss: 8.47329e-07
Iter: 840 loss: 8.53384e-07
Iter: 841 loss: 8.47347e-07
Iter: 842 loss: 8.47062779e-07
Iter: 843 loss: 8.46833359e-07
Iter: 844 loss: 8.46703529e-07
Iter: 845 loss: 8.46404816e-07
Iter: 846 loss: 8.46402941e-07
Iter: 847 loss: 8.46081605e-07
Iter: 848 loss: 8.46259638e-07
Iter: 849 loss: 8.45838656e-07
Iter: 850 loss: 8.45489353e-07
Iter: 851 loss: 8.4526971e-07
Iter: 852 loss: 8.45092e-07
Iter: 853 loss: 8.4482997e-07
Iter: 854 loss: 8.44828833e-07
Iter: 855 loss: 8.4456093e-07
Iter: 856 loss: 8.44525573e-07
Iter: 857 loss: 8.4426506e-07
Iter: 858 loss: 8.43935368e-07
Iter: 859 loss: 8.44020292e-07
Iter: 860 loss: 8.43647115e-07
Iter: 861 loss: 8.43590101e-07
Iter: 862 loss: 8.43476585e-07
Iter: 863 loss: 8.43338626e-07
Iter: 864 loss: 8.43372732e-07
Iter: 865 loss: 8.43237331e-07
Iter: 866 loss: 8.43072087e-07
Iter: 867 loss: 8.42769907e-07
Iter: 868 loss: 8.49613e-07
Iter: 869 loss: 8.42773602e-07
Iter: 870 loss: 8.42684699e-07
Iter: 871 loss: 8.42580789e-07
Iter: 872 loss: 8.42445502e-07
Iter: 873 loss: 8.42095e-07
Iter: 874 loss: 8.4586452e-07
Iter: 875 loss: 8.42038503e-07
Iter: 876 loss: 8.41642418e-07
Iter: 877 loss: 8.41878432e-07
Iter: 878 loss: 8.41314545e-07
Iter: 879 loss: 8.41017652e-07
Iter: 880 loss: 8.41010433e-07
Iter: 881 loss: 8.40662096e-07
Iter: 882 loss: 8.40166422e-07
Iter: 883 loss: 8.40152666e-07
Iter: 884 loss: 8.39681263e-07
Iter: 885 loss: 8.40397774e-07
Iter: 886 loss: 8.39480208e-07
Iter: 887 loss: 8.39102768e-07
Iter: 888 loss: 8.42357679e-07
Iter: 889 loss: 8.39117e-07
Iter: 890 loss: 8.38693e-07
Iter: 891 loss: 8.39494191e-07
Iter: 892 loss: 8.38546896e-07
Iter: 893 loss: 8.38367555e-07
Iter: 894 loss: 8.38509834e-07
Iter: 895 loss: 8.38314747e-07
Iter: 896 loss: 8.3813643e-07
Iter: 897 loss: 8.40544317e-07
Iter: 898 loss: 8.38129949e-07
Iter: 899 loss: 8.37978064e-07
Iter: 900 loss: 8.37742448e-07
Iter: 901 loss: 8.37718517e-07
Iter: 902 loss: 8.37516382e-07
Iter: 903 loss: 8.37979e-07
Iter: 904 loss: 8.37427592e-07
Iter: 905 loss: 8.37222274e-07
Iter: 906 loss: 8.39646759e-07
Iter: 907 loss: 8.37224661e-07
Iter: 908 loss: 8.370057e-07
Iter: 909 loss: 8.36505819e-07
Iter: 910 loss: 8.42915085e-07
Iter: 911 loss: 8.36519746e-07
Iter: 912 loss: 8.36119057e-07
Iter: 913 loss: 8.38662345e-07
Iter: 914 loss: 8.36082108e-07
Iter: 915 loss: 8.35776177e-07
Iter: 916 loss: 8.40138341e-07
Iter: 917 loss: 8.35748438e-07
Iter: 918 loss: 8.35528795e-07
Iter: 919 loss: 8.3505563e-07
Iter: 920 loss: 8.43902285e-07
Iter: 921 loss: 8.35045796e-07
Iter: 922 loss: 8.34612763e-07
Iter: 923 loss: 8.35671131e-07
Iter: 924 loss: 8.34475713e-07
Iter: 925 loss: 8.34203206e-07
Iter: 926 loss: 8.34181265e-07
Iter: 927 loss: 8.33932631e-07
Iter: 928 loss: 8.33710146e-07
Iter: 929 loss: 8.33610443e-07
Iter: 930 loss: 8.33386196e-07
Iter: 931 loss: 8.33258355e-07
Iter: 932 loss: 8.33161778e-07
Iter: 933 loss: 8.32988462e-07
Iter: 934 loss: 8.32968112e-07
Iter: 935 loss: 8.32751141e-07
Iter: 936 loss: 8.32540479e-07
Iter: 937 loss: 8.32540081e-07
Iter: 938 loss: 8.32318506e-07
Iter: 939 loss: 8.32012176e-07
Iter: 940 loss: 8.32022863e-07
Iter: 941 loss: 8.31645139e-07
Iter: 942 loss: 8.33920751e-07
Iter: 943 loss: 8.31589603e-07
Iter: 944 loss: 8.31171747e-07
Iter: 945 loss: 8.31045327e-07
Iter: 946 loss: 8.30799422e-07
Iter: 947 loss: 8.30726208e-07
Iter: 948 loss: 8.30527426e-07
Iter: 949 loss: 8.30340127e-07
Iter: 950 loss: 8.30457054e-07
Iter: 951 loss: 8.30195461e-07
Iter: 952 loss: 8.29905503e-07
Iter: 953 loss: 8.29403632e-07
Iter: 954 loss: 8.41489793e-07
Iter: 955 loss: 8.29419946e-07
Iter: 956 loss: 8.29297051e-07
Iter: 957 loss: 8.29246574e-07
Iter: 958 loss: 8.29084229e-07
Iter: 959 loss: 8.29822511e-07
Iter: 960 loss: 8.29063538e-07
Iter: 961 loss: 8.28917223e-07
Iter: 962 loss: 8.2864284e-07
Iter: 963 loss: 8.32386888e-07
Iter: 964 loss: 8.28578095e-07
Iter: 965 loss: 8.28567522e-07
Iter: 966 loss: 8.28443945e-07
Iter: 967 loss: 8.28333555e-07
Iter: 968 loss: 8.28068e-07
Iter: 969 loss: 8.32957369e-07
Iter: 970 loss: 8.28061729e-07
Iter: 971 loss: 8.2775648e-07
Iter: 972 loss: 8.2797e-07
Iter: 973 loss: 8.2755497e-07
Iter: 974 loss: 8.2733311e-07
Iter: 975 loss: 8.27309918e-07
Iter: 976 loss: 8.27137512e-07
Iter: 977 loss: 8.2668e-07
Iter: 978 loss: 8.28559791e-07
Iter: 979 loss: 8.26512e-07
Iter: 980 loss: 8.2602196e-07
Iter: 981 loss: 8.30165504e-07
Iter: 982 loss: 8.25999564e-07
Iter: 983 loss: 8.25881273e-07
Iter: 984 loss: 8.2588474e-07
Iter: 985 loss: 8.25666234e-07
Iter: 986 loss: 8.25501445e-07
Iter: 987 loss: 8.25486552e-07
Iter: 988 loss: 8.2524366e-07
Iter: 989 loss: 8.25747293e-07
Iter: 990 loss: 8.25074835e-07
Iter: 991 loss: 8.24975e-07
Iter: 992 loss: 8.27028089e-07
Iter: 993 loss: 8.24967174e-07
Iter: 994 loss: 8.24813355e-07
Iter: 995 loss: 8.24792892e-07
Iter: 996 loss: 8.24706831e-07
Iter: 997 loss: 8.24499409e-07
Iter: 998 loss: 8.24297217e-07
Iter: 999 loss: 8.24225538e-07
Iter: 1000 loss: 8.24194842e-07
Iter: 1001 loss: 8.24089796e-07
Iter: 1002 loss: 8.23930463e-07
Iter: 1003 loss: 8.2363556e-07
Iter: 1004 loss: 8.25551183e-07
Iter: 1005 loss: 8.23549215e-07
Iter: 1006 loss: 8.23204516e-07
Iter: 1007 loss: 8.27839813e-07
Iter: 1008 loss: 8.23218e-07
Iter: 1009 loss: 8.22902393e-07
Iter: 1010 loss: 8.24218887e-07
Iter: 1011 loss: 8.22791151e-07
Iter: 1012 loss: 8.22664617e-07
Iter: 1013 loss: 8.22264155e-07
Iter: 1014 loss: 8.2504647e-07
Iter: 1015 loss: 8.22168545e-07
Iter: 1016 loss: 8.21664173e-07
Iter: 1017 loss: 8.23982248e-07
Iter: 1018 loss: 8.21531387e-07
Iter: 1019 loss: 8.21244612e-07
Iter: 1020 loss: 8.22978734e-07
Iter: 1021 loss: 8.2120431e-07
Iter: 1022 loss: 8.20829314e-07
Iter: 1023 loss: 8.23079802e-07
Iter: 1024 loss: 8.20742457e-07
Iter: 1025 loss: 8.20610865e-07
Iter: 1026 loss: 8.20583921e-07
Iter: 1027 loss: 8.20449145e-07
Iter: 1028 loss: 8.20341484e-07
Iter: 1029 loss: 8.2221004e-07
Iter: 1030 loss: 8.20313289e-07
Iter: 1031 loss: 8.20174137e-07
Iter: 1032 loss: 8.19905324e-07
Iter: 1033 loss: 8.25446762e-07
Iter: 1034 loss: 8.19881507e-07
Iter: 1035 loss: 8.19603315e-07
Iter: 1036 loss: 8.2077139e-07
Iter: 1037 loss: 8.19547267e-07
Iter: 1038 loss: 8.19353e-07
Iter: 1039 loss: 8.20967614e-07
Iter: 1040 loss: 8.19353261e-07
Iter: 1041 loss: 8.19157776e-07
Iter: 1042 loss: 8.1932626e-07
Iter: 1043 loss: 8.19048523e-07
Iter: 1044 loss: 8.18784031e-07
Iter: 1045 loss: 8.18735543e-07
Iter: 1046 loss: 8.18553872e-07
Iter: 1047 loss: 8.18399258e-07
Iter: 1048 loss: 8.18364e-07
Iter: 1049 loss: 8.18230035e-07
Iter: 1050 loss: 8.178e-07
Iter: 1051 loss: 8.21369326e-07
Iter: 1052 loss: 8.17722e-07
Iter: 1053 loss: 8.17453611e-07
Iter: 1054 loss: 8.1874839e-07
Iter: 1055 loss: 8.17380794e-07
Iter: 1056 loss: 8.17114199e-07
Iter: 1057 loss: 8.17828663e-07
Iter: 1058 loss: 8.17001137e-07
Iter: 1059 loss: 8.16883926e-07
Iter: 1060 loss: 8.16797296e-07
Iter: 1061 loss: 8.16755232e-07
Iter: 1062 loss: 8.16520298e-07
Iter: 1063 loss: 8.18526473e-07
Iter: 1064 loss: 8.16496595e-07
Iter: 1065 loss: 8.16285137e-07
Iter: 1066 loss: 8.18856506e-07
Iter: 1067 loss: 8.16265413e-07
Iter: 1068 loss: 8.16030933e-07
Iter: 1069 loss: 8.16410591e-07
Iter: 1070 loss: 8.15926796e-07
Iter: 1071 loss: 8.15794237e-07
Iter: 1072 loss: 8.15483816e-07
Iter: 1073 loss: 8.15474266e-07
Iter: 1074 loss: 8.15221824e-07
Iter: 1075 loss: 8.15238593e-07
Iter: 1076 loss: 8.15024634e-07
Iter: 1077 loss: 8.14886448e-07
Iter: 1078 loss: 8.14817326e-07
Iter: 1079 loss: 8.14624741e-07
Iter: 1080 loss: 8.15703061e-07
Iter: 1081 loss: 8.14608484e-07
Iter: 1082 loss: 8.14386e-07
Iter: 1083 loss: 8.14858936e-07
Iter: 1084 loss: 8.14303689e-07
Iter: 1085 loss: 8.14168288e-07
Iter: 1086 loss: 8.1396405e-07
Iter: 1087 loss: 8.13938527e-07
Iter: 1088 loss: 8.13702513e-07
Iter: 1089 loss: 8.13732584e-07
Iter: 1090 loss: 8.13497479e-07
Iter: 1091 loss: 8.13209112e-07
Iter: 1092 loss: 8.17014723e-07
Iter: 1093 loss: 8.13195925e-07
Iter: 1094 loss: 8.13079282e-07
Iter: 1095 loss: 8.13084569e-07
Iter: 1096 loss: 8.12968835e-07
Iter: 1097 loss: 8.12670635e-07
Iter: 1098 loss: 8.14862346e-07
Iter: 1099 loss: 8.12615099e-07
Iter: 1100 loss: 8.12306894e-07
Iter: 1101 loss: 8.14361556e-07
Iter: 1102 loss: 8.1226915e-07
Iter: 1103 loss: 8.12122721e-07
Iter: 1104 loss: 8.12100325e-07
Iter: 1105 loss: 8.11990958e-07
Iter: 1106 loss: 8.11654559e-07
Iter: 1107 loss: 8.14860243e-07
Iter: 1108 loss: 8.11627388e-07
Iter: 1109 loss: 8.11324639e-07
Iter: 1110 loss: 8.11878067e-07
Iter: 1111 loss: 8.11178836e-07
Iter: 1112 loss: 8.10778829e-07
Iter: 1113 loss: 8.1197112e-07
Iter: 1114 loss: 8.10676852e-07
Iter: 1115 loss: 8.10470453e-07
Iter: 1116 loss: 8.10433676e-07
Iter: 1117 loss: 8.10291795e-07
Iter: 1118 loss: 8.10067036e-07
Iter: 1119 loss: 8.15023327e-07
Iter: 1120 loss: 8.10041513e-07
Iter: 1121 loss: 8.09846256e-07
Iter: 1122 loss: 8.09845176e-07
Iter: 1123 loss: 8.09732967e-07
Iter: 1124 loss: 8.09549761e-07
Iter: 1125 loss: 8.14386112e-07
Iter: 1126 loss: 8.09568519e-07
Iter: 1127 loss: 8.09392589e-07
Iter: 1128 loss: 8.10015536e-07
Iter: 1129 loss: 8.09328412e-07
Iter: 1130 loss: 8.09032599e-07
Iter: 1131 loss: 8.0990668e-07
Iter: 1132 loss: 8.08926359e-07
Iter: 1133 loss: 8.08757648e-07
Iter: 1134 loss: 8.08820971e-07
Iter: 1135 loss: 8.08626282e-07
Iter: 1136 loss: 8.08412e-07
Iter: 1137 loss: 8.08757e-07
Iter: 1138 loss: 8.08303867e-07
Iter: 1139 loss: 8.0797804e-07
Iter: 1140 loss: 8.08993263e-07
Iter: 1141 loss: 8.07886522e-07
Iter: 1142 loss: 8.07608899e-07
Iter: 1143 loss: 8.07582467e-07
Iter: 1144 loss: 8.07427796e-07
Iter: 1145 loss: 8.07151309e-07
Iter: 1146 loss: 8.07022616e-07
Iter: 1147 loss: 8.06932348e-07
Iter: 1148 loss: 8.06547575e-07
Iter: 1149 loss: 8.0981988e-07
Iter: 1150 loss: 8.06525861e-07
Iter: 1151 loss: 8.06490846e-07
Iter: 1152 loss: 8.06434741e-07
Iter: 1153 loss: 8.06355843e-07
Iter: 1154 loss: 8.06130799e-07
Iter: 1155 loss: 8.0786424e-07
Iter: 1156 loss: 8.06117e-07
Iter: 1157 loss: 8.06005119e-07
Iter: 1158 loss: 8.05966181e-07
Iter: 1159 loss: 8.05839704e-07
Iter: 1160 loss: 8.05781724e-07
Iter: 1161 loss: 8.05701234e-07
Iter: 1162 loss: 8.05569698e-07
Iter: 1163 loss: 8.05738296e-07
Iter: 1164 loss: 8.05455727e-07
Iter: 1165 loss: 8.05244042e-07
Iter: 1166 loss: 8.06382786e-07
Iter: 1167 loss: 8.05212608e-07
Iter: 1168 loss: 8.05074592e-07
Iter: 1169 loss: 8.04836304e-07
Iter: 1170 loss: 8.04831473e-07
Iter: 1171 loss: 8.04566e-07
Iter: 1172 loss: 8.07759704e-07
Iter: 1173 loss: 8.04583465e-07
Iter: 1174 loss: 8.04366721e-07
Iter: 1175 loss: 8.04824595e-07
Iter: 1176 loss: 8.04254739e-07
Iter: 1177 loss: 8.04120646e-07
Iter: 1178 loss: 8.03887247e-07
Iter: 1179 loss: 8.03837906e-07
Iter: 1180 loss: 8.03517878e-07
Iter: 1181 loss: 8.04951185e-07
Iter: 1182 loss: 8.03461262e-07
Iter: 1183 loss: 8.03267426e-07
Iter: 1184 loss: 8.03307046e-07
Iter: 1185 loss: 8.03098942e-07
Iter: 1186 loss: 8.03573357e-07
Iter: 1187 loss: 8.03041e-07
Iter: 1188 loss: 8.02874354e-07
Iter: 1189 loss: 8.02647e-07
Iter: 1190 loss: 8.0263726e-07
Iter: 1191 loss: 8.02584282e-07
Iter: 1192 loss: 8.02520503e-07
Iter: 1193 loss: 8.02385671e-07
Iter: 1194 loss: 8.02215652e-07
Iter: 1195 loss: 8.06346748e-07
Iter: 1196 loss: 8.02175e-07
Iter: 1197 loss: 8.02058537e-07
Iter: 1198 loss: 8.03810735e-07
Iter: 1199 loss: 8.02056e-07
Iter: 1200 loss: 8.01911824e-07
Iter: 1201 loss: 8.02211446e-07
Iter: 1202 loss: 8.01812746e-07
Iter: 1203 loss: 8.01702868e-07
Iter: 1204 loss: 8.01626e-07
Iter: 1205 loss: 8.01604529e-07
Iter: 1206 loss: 8.0140228e-07
Iter: 1207 loss: 8.03100193e-07
Iter: 1208 loss: 8.01372437e-07
Iter: 1209 loss: 8.01203498e-07
Iter: 1210 loss: 8.01012277e-07
Iter: 1211 loss: 8.00996645e-07
Iter: 1212 loss: 8.00738576e-07
Iter: 1213 loss: 8.00669739e-07
Iter: 1214 loss: 8.00525811e-07
Iter: 1215 loss: 8.00210898e-07
Iter: 1216 loss: 8.02816885e-07
Iter: 1217 loss: 8.00155533e-07
Iter: 1218 loss: 8.0002809e-07
Iter: 1219 loss: 8.00010071e-07
Iter: 1220 loss: 7.9990491e-07
Iter: 1221 loss: 7.99709085e-07
Iter: 1222 loss: 7.99732561e-07
Iter: 1223 loss: 7.99593181e-07
Iter: 1224 loss: 8.01480496e-07
Iter: 1225 loss: 7.99561803e-07
Iter: 1226 loss: 7.99466534e-07
Iter: 1227 loss: 7.99836243e-07
Iter: 1228 loss: 7.99411623e-07
Iter: 1229 loss: 7.99293957e-07
Iter: 1230 loss: 7.99171687e-07
Iter: 1231 loss: 7.99199938e-07
Iter: 1232 loss: 7.9904936e-07
Iter: 1233 loss: 7.99016107e-07
Iter: 1234 loss: 7.9895e-07
Iter: 1235 loss: 7.98817723e-07
Iter: 1236 loss: 8.02257603e-07
Iter: 1237 loss: 7.98802432e-07
Iter: 1238 loss: 7.98611154e-07
Iter: 1239 loss: 8.00685712e-07
Iter: 1240 loss: 7.98579322e-07
Iter: 1241 loss: 7.98417e-07
Iter: 1242 loss: 7.9824872e-07
Iter: 1243 loss: 7.98216831e-07
Iter: 1244 loss: 7.97951259e-07
Iter: 1245 loss: 7.98135602e-07
Iter: 1246 loss: 7.97785e-07
Iter: 1247 loss: 7.97494295e-07
Iter: 1248 loss: 7.99538839e-07
Iter: 1249 loss: 7.9749509e-07
Iter: 1250 loss: 7.97397888e-07
Iter: 1251 loss: 7.97376288e-07
Iter: 1252 loss: 7.97289431e-07
Iter: 1253 loss: 7.9716358e-07
Iter: 1254 loss: 7.97174607e-07
Iter: 1255 loss: 7.96994414e-07
Iter: 1256 loss: 7.96708207e-07
Iter: 1257 loss: 7.96684162e-07
Iter: 1258 loss: 7.96628e-07
Iter: 1259 loss: 7.96568372e-07
Iter: 1260 loss: 7.96384484e-07
Iter: 1261 loss: 7.96552627e-07
Iter: 1262 loss: 7.9631e-07
Iter: 1263 loss: 7.962214e-07
Iter: 1264 loss: 7.95964297e-07
Iter: 1265 loss: 8.00430598e-07
Iter: 1266 loss: 7.95943663e-07
Iter: 1267 loss: 7.9583333e-07
Iter: 1268 loss: 7.95801498e-07
Iter: 1269 loss: 7.95648134e-07
Iter: 1270 loss: 7.95416781e-07
Iter: 1271 loss: 7.95352e-07
Iter: 1272 loss: 7.95171957e-07
Iter: 1273 loss: 7.96149834e-07
Iter: 1274 loss: 7.95120059e-07
Iter: 1275 loss: 7.94931793e-07
Iter: 1276 loss: 7.96219865e-07
Iter: 1277 loss: 7.94900416e-07
Iter: 1278 loss: 7.94767402e-07
Iter: 1279 loss: 7.94461812e-07
Iter: 1280 loss: 8.00085047e-07
Iter: 1281 loss: 7.94455843e-07
Iter: 1282 loss: 7.941631e-07
Iter: 1283 loss: 7.97056089e-07
Iter: 1284 loss: 7.94186349e-07
Iter: 1285 loss: 7.93891502e-07
Iter: 1286 loss: 7.96013182e-07
Iter: 1287 loss: 7.93861091e-07
Iter: 1288 loss: 7.93723359e-07
Iter: 1289 loss: 7.93494e-07
Iter: 1290 loss: 7.93482229e-07
Iter: 1291 loss: 7.93307152e-07
Iter: 1292 loss: 7.94070388e-07
Iter: 1293 loss: 7.93258891e-07
Iter: 1294 loss: 7.93172433e-07
Iter: 1295 loss: 7.93145261e-07
Iter: 1296 loss: 7.93056074e-07
Iter: 1297 loss: 7.92954097e-07
Iter: 1298 loss: 7.92920105e-07
Iter: 1299 loss: 7.92802837e-07
Iter: 1300 loss: 7.92927437e-07
Iter: 1301 loss: 7.92744686e-07
Iter: 1302 loss: 7.92605192e-07
Iter: 1303 loss: 7.9262395e-07
Iter: 1304 loss: 7.9253283e-07
Iter: 1305 loss: 7.92231845e-07
Iter: 1306 loss: 7.94846301e-07
Iter: 1307 loss: 7.92228889e-07
Iter: 1308 loss: 7.92037554e-07
Iter: 1309 loss: 7.92029482e-07
Iter: 1310 loss: 7.91849061e-07
Iter: 1311 loss: 7.91743901e-07
Iter: 1312 loss: 7.91645959e-07
Iter: 1313 loss: 7.91436946e-07
Iter: 1314 loss: 7.91439277e-07
Iter: 1315 loss: 7.91254251e-07
Iter: 1316 loss: 7.91171942e-07
Iter: 1317 loss: 7.9113056e-07
Iter: 1318 loss: 7.90981346e-07
Iter: 1319 loss: 7.90797912e-07
Iter: 1320 loss: 7.90796548e-07
Iter: 1321 loss: 7.90555e-07
Iter: 1322 loss: 7.91664604e-07
Iter: 1323 loss: 7.90531e-07
Iter: 1324 loss: 7.90461456e-07
Iter: 1325 loss: 7.9044537e-07
Iter: 1326 loss: 7.90362378e-07
Iter: 1327 loss: 7.90217655e-07
Iter: 1328 loss: 7.90208446e-07
Iter: 1329 loss: 7.90055537e-07
Iter: 1330 loss: 7.89893249e-07
Iter: 1331 loss: 7.89856813e-07
Iter: 1332 loss: 7.8980645e-07
Iter: 1333 loss: 7.89767569e-07
Iter: 1334 loss: 7.89632963e-07
Iter: 1335 loss: 7.89727665e-07
Iter: 1336 loss: 7.8953974e-07
Iter: 1337 loss: 7.89438332e-07
Iter: 1338 loss: 7.89319301e-07
Iter: 1339 loss: 7.8928224e-07
Iter: 1340 loss: 7.89096589e-07
Iter: 1341 loss: 7.89120236e-07
Iter: 1342 loss: 7.8901428e-07
Iter: 1343 loss: 7.88866487e-07
Iter: 1344 loss: 7.92751621e-07
Iter: 1345 loss: 7.8887183e-07
Iter: 1346 loss: 7.88772354e-07
Iter: 1347 loss: 7.9045293e-07
Iter: 1348 loss: 7.88749389e-07
Iter: 1349 loss: 7.88570787e-07
Iter: 1350 loss: 7.88602165e-07
Iter: 1351 loss: 7.88461705e-07
Iter: 1352 loss: 7.88377065e-07
Iter: 1353 loss: 7.88327156e-07
Iter: 1354 loss: 7.88231205e-07
Iter: 1355 loss: 7.88063e-07
Iter: 1356 loss: 7.88753198e-07
Iter: 1357 loss: 7.88043053e-07
Iter: 1358 loss: 7.87851604e-07
Iter: 1359 loss: 7.89892738e-07
Iter: 1360 loss: 7.87877298e-07
Iter: 1361 loss: 7.87803515e-07
Iter: 1362 loss: 7.87614567e-07
Iter: 1363 loss: 7.90819286e-07
Iter: 1364 loss: 7.8758427e-07
Iter: 1365 loss: 7.87396971e-07
Iter: 1366 loss: 7.87943179e-07
Iter: 1367 loss: 7.87366048e-07
Iter: 1368 loss: 7.87163e-07
Iter: 1369 loss: 7.8941207e-07
Iter: 1370 loss: 7.87171416e-07
Iter: 1371 loss: 7.87035788e-07
Iter: 1372 loss: 7.87502472e-07
Iter: 1373 loss: 7.87009071e-07
Iter: 1374 loss: 7.86916246e-07
Iter: 1375 loss: 7.86768794e-07
Iter: 1376 loss: 7.86763962e-07
Iter: 1377 loss: 7.86687565e-07
Iter: 1378 loss: 7.86674377e-07
Iter: 1379 loss: 7.86559895e-07
Iter: 1380 loss: 7.86464625e-07
Iter: 1381 loss: 7.86429e-07
Iter: 1382 loss: 7.86341957e-07
Iter: 1383 loss: 7.86335363e-07
Iter: 1384 loss: 7.8624447e-07
Iter: 1385 loss: 7.86140504e-07
Iter: 1386 loss: 7.86133455e-07
Iter: 1387 loss: 7.85963039e-07
Iter: 1388 loss: 7.86063e-07
Iter: 1389 loss: 7.85888119e-07
Iter: 1390 loss: 7.85743168e-07
Iter: 1391 loss: 7.87218596e-07
Iter: 1392 loss: 7.85725206e-07
Iter: 1393 loss: 7.85646648e-07
Iter: 1394 loss: 7.86802957e-07
Iter: 1395 loss: 7.85641134e-07
Iter: 1396 loss: 7.85561838e-07
Iter: 1397 loss: 7.85425527e-07
Iter: 1398 loss: 7.8543161e-07
Iter: 1399 loss: 7.8526e-07
Iter: 1400 loss: 7.85596512e-07
Iter: 1401 loss: 7.85203e-07
Iter: 1402 loss: 7.85083e-07
Iter: 1403 loss: 7.86633734e-07
Iter: 1404 loss: 7.85088332e-07
Iter: 1405 loss: 7.8499329e-07
Iter: 1406 loss: 7.84846e-07
Iter: 1407 loss: 7.87470526e-07
Iter: 1408 loss: 7.84832423e-07
Iter: 1409 loss: 7.84648137e-07
Iter: 1410 loss: 7.86889871e-07
Iter: 1411 loss: 7.8462233e-07
Iter: 1412 loss: 7.84530243e-07
Iter: 1413 loss: 7.85127895e-07
Iter: 1414 loss: 7.84489316e-07
Iter: 1415 loss: 7.84378699e-07
Iter: 1416 loss: 7.84377562e-07
Iter: 1417 loss: 7.84307417e-07
Iter: 1418 loss: 7.84185715e-07
Iter: 1419 loss: 7.8576204e-07
Iter: 1420 loss: 7.84171107e-07
Iter: 1421 loss: 7.84098518e-07
Iter: 1422 loss: 7.8387427e-07
Iter: 1423 loss: 7.86313876e-07
Iter: 1424 loss: 7.83843518e-07
Iter: 1425 loss: 7.83646897e-07
Iter: 1426 loss: 7.84215e-07
Iter: 1427 loss: 7.8360722e-07
Iter: 1428 loss: 7.83476196e-07
Iter: 1429 loss: 7.84320548e-07
Iter: 1430 loss: 7.83455107e-07
Iter: 1431 loss: 7.83324595e-07
Iter: 1432 loss: 7.83827545e-07
Iter: 1433 loss: 7.83299356e-07
Iter: 1434 loss: 7.83212215e-07
Iter: 1435 loss: 7.83127916e-07
Iter: 1436 loss: 7.83086193e-07
Iter: 1437 loss: 7.82942e-07
Iter: 1438 loss: 7.84289455e-07
Iter: 1439 loss: 7.82947609e-07
Iter: 1440 loss: 7.82841653e-07
Iter: 1441 loss: 7.82756842e-07
Iter: 1442 loss: 7.82741154e-07
Iter: 1443 loss: 7.82596487e-07
Iter: 1444 loss: 7.83059704e-07
Iter: 1445 loss: 7.82560278e-07
Iter: 1446 loss: 7.82435905e-07
Iter: 1447 loss: 7.83867e-07
Iter: 1448 loss: 7.82437269e-07
Iter: 1449 loss: 7.823582e-07
Iter: 1450 loss: 7.82151915e-07
Iter: 1451 loss: 7.85991119e-07
Iter: 1452 loss: 7.82151119e-07
Iter: 1453 loss: 7.82038171e-07
Iter: 1454 loss: 7.82033908e-07
Iter: 1455 loss: 7.81907602e-07
Iter: 1456 loss: 7.81772e-07
Iter: 1457 loss: 7.81752078e-07
Iter: 1458 loss: 7.81581718e-07
Iter: 1459 loss: 7.81723372e-07
Iter: 1460 loss: 7.81478e-07
Iter: 1461 loss: 7.81312679e-07
Iter: 1462 loss: 7.83229439e-07
Iter: 1463 loss: 7.8131211e-07
Iter: 1464 loss: 7.81188533e-07
Iter: 1465 loss: 7.81891117e-07
Iter: 1466 loss: 7.81220649e-07
Iter: 1467 loss: 7.81101733e-07
Iter: 1468 loss: 7.81049607e-07
Iter: 1469 loss: 7.81023914e-07
Iter: 1470 loss: 7.80906589e-07
Iter: 1471 loss: 7.81711037e-07
Iter: 1472 loss: 7.80902496e-07
Iter: 1473 loss: 7.80804271e-07
Iter: 1474 loss: 7.81240033e-07
Iter: 1475 loss: 7.80747882e-07
Iter: 1476 loss: 7.80689447e-07
Iter: 1477 loss: 7.80583377e-07
Iter: 1478 loss: 7.80544383e-07
Iter: 1479 loss: 7.80478047e-07
Iter: 1480 loss: 7.80463097e-07
Iter: 1481 loss: 7.80364644e-07
Iter: 1482 loss: 7.80116579e-07
Iter: 1483 loss: 7.80142841e-07
Iter: 1484 loss: 7.79948778e-07
Iter: 1485 loss: 7.81392316e-07
Iter: 1486 loss: 7.7995179e-07
Iter: 1487 loss: 7.7976506e-07
Iter: 1488 loss: 7.80154892e-07
Iter: 1489 loss: 7.79709126e-07
Iter: 1490 loss: 7.79570314e-07
Iter: 1491 loss: 7.79341349e-07
Iter: 1492 loss: 7.79327252e-07
Iter: 1493 loss: 7.7906077e-07
Iter: 1494 loss: 7.8094e-07
Iter: 1495 loss: 7.79063498e-07
Iter: 1496 loss: 7.7892e-07
Iter: 1497 loss: 7.78942365e-07
Iter: 1498 loss: 7.7880992e-07
Iter: 1499 loss: 7.78616709e-07
Iter: 1500 loss: 7.78681965e-07
Iter: 1501 loss: 7.78526442e-07
Iter: 1502 loss: 7.79806101e-07
Iter: 1503 loss: 7.7851746e-07
Iter: 1504 loss: 7.78384788e-07
Iter: 1505 loss: 7.78817196e-07
Iter: 1506 loss: 7.78380127e-07
Iter: 1507 loss: 7.78278832e-07
Iter: 1508 loss: 7.78231652e-07
Iter: 1509 loss: 7.78171511e-07
Iter: 1510 loss: 7.78054925e-07
Iter: 1511 loss: 7.78495519e-07
Iter: 1512 loss: 7.7798677e-07
Iter: 1513 loss: 7.77823e-07
Iter: 1514 loss: 7.78394792e-07
Iter: 1515 loss: 7.77756e-07
Iter: 1516 loss: 7.77642299e-07
Iter: 1517 loss: 7.77725745e-07
Iter: 1518 loss: 7.77551577e-07
Iter: 1519 loss: 7.77396792e-07
Iter: 1520 loss: 7.79089646e-07
Iter: 1521 loss: 7.77398839e-07
Iter: 1522 loss: 7.77315222e-07
Iter: 1523 loss: 7.77053231e-07
Iter: 1524 loss: 7.7922374e-07
Iter: 1525 loss: 7.77046125e-07
Iter: 1526 loss: 7.76704951e-07
Iter: 1527 loss: 7.7785046e-07
Iter: 1528 loss: 7.76680963e-07
Iter: 1529 loss: 7.76508614e-07
Iter: 1530 loss: 7.78828166e-07
Iter: 1531 loss: 7.76495654e-07
Iter: 1532 loss: 7.76340869e-07
Iter: 1533 loss: 7.7664788e-07
Iter: 1534 loss: 7.76265665e-07
Iter: 1535 loss: 7.76123045e-07
Iter: 1536 loss: 7.76044089e-07
Iter: 1537 loss: 7.75984518e-07
Iter: 1538 loss: 7.75878675e-07
Iter: 1539 loss: 7.75843546e-07
Iter: 1540 loss: 7.75776812e-07
Iter: 1541 loss: 7.75618673e-07
Iter: 1542 loss: 7.75597812e-07
Iter: 1543 loss: 7.75536193e-07
Iter: 1544 loss: 7.76109459e-07
Iter: 1545 loss: 7.75441663e-07
Iter: 1546 loss: 7.75308877e-07
Iter: 1547 loss: 7.7612691e-07
Iter: 1548 loss: 7.75294836e-07
Iter: 1549 loss: 7.75217245e-07
Iter: 1550 loss: 7.75050125e-07
Iter: 1551 loss: 7.75070248e-07
Iter: 1552 loss: 7.74920238e-07
Iter: 1553 loss: 7.76885088e-07
Iter: 1554 loss: 7.74920636e-07
Iter: 1555 loss: 7.74816385e-07
Iter: 1556 loss: 7.74576847e-07
Iter: 1557 loss: 7.74579917e-07
Iter: 1558 loss: 7.74375735e-07
Iter: 1559 loss: 7.74471459e-07
Iter: 1560 loss: 7.74209525e-07
Iter: 1561 loss: 7.73946454e-07
Iter: 1562 loss: 7.76303864e-07
Iter: 1563 loss: 7.73955946e-07
Iter: 1564 loss: 7.73655472e-07
Iter: 1565 loss: 7.75048534e-07
Iter: 1566 loss: 7.7361392e-07
Iter: 1567 loss: 7.73432248e-07
Iter: 1568 loss: 7.73335728e-07
Iter: 1569 loss: 7.73248701e-07
Iter: 1570 loss: 7.730996e-07
Iter: 1571 loss: 7.75516696e-07
Iter: 1572 loss: 7.73104603e-07
Iter: 1573 loss: 7.72962323e-07
Iter: 1574 loss: 7.7311239e-07
Iter: 1575 loss: 7.72875637e-07
Iter: 1576 loss: 7.72711132e-07
Iter: 1577 loss: 7.72804697e-07
Iter: 1578 loss: 7.72682e-07
Iter: 1579 loss: 7.72502176e-07
Iter: 1580 loss: 7.74231e-07
Iter: 1581 loss: 7.72492285e-07
Iter: 1582 loss: 7.72381782e-07
Iter: 1583 loss: 7.72521162e-07
Iter: 1584 loss: 7.72349665e-07
Iter: 1585 loss: 7.72250132e-07
Iter: 1586 loss: 7.72766668e-07
Iter: 1587 loss: 7.72223757e-07
Iter: 1588 loss: 7.72129283e-07
Iter: 1589 loss: 7.72022076e-07
Iter: 1590 loss: 7.71985356e-07
Iter: 1591 loss: 7.71839439e-07
Iter: 1592 loss: 7.71689e-07
Iter: 1593 loss: 7.71637247e-07
Iter: 1594 loss: 7.71373664e-07
Iter: 1595 loss: 7.72514e-07
Iter: 1596 loss: 7.71288683e-07
Iter: 1597 loss: 7.71142197e-07
Iter: 1598 loss: 7.71155328e-07
Iter: 1599 loss: 7.70995428e-07
Iter: 1600 loss: 7.70840813e-07
Iter: 1601 loss: 7.70815802e-07
Iter: 1602 loss: 7.7067989e-07
Iter: 1603 loss: 7.7185075e-07
Iter: 1604 loss: 7.70644476e-07
Iter: 1605 loss: 7.7047423e-07
Iter: 1606 loss: 7.70932672e-07
Iter: 1607 loss: 7.70440579e-07
Iter: 1608 loss: 7.70303245e-07
Iter: 1609 loss: 7.70164718e-07
Iter: 1610 loss: 7.70123734e-07
Iter: 1611 loss: 7.69998337e-07
Iter: 1612 loss: 7.69969859e-07
Iter: 1613 loss: 7.69872031e-07
Iter: 1614 loss: 7.69787164e-07
Iter: 1615 loss: 7.6976346e-07
Iter: 1616 loss: 7.69621806e-07
Iter: 1617 loss: 7.7079045e-07
Iter: 1618 loss: 7.6963795e-07
Iter: 1619 loss: 7.69511871e-07
Iter: 1620 loss: 7.695e-07
Iter: 1621 loss: 7.69392614e-07
Iter: 1622 loss: 7.69236181e-07
Iter: 1623 loss: 7.69377721e-07
Iter: 1624 loss: 7.69187523e-07
Iter: 1625 loss: 7.69019039e-07
Iter: 1626 loss: 7.692596e-07
Iter: 1627 loss: 7.68909e-07
Iter: 1628 loss: 7.68811731e-07
Iter: 1629 loss: 7.68816108e-07
Iter: 1630 loss: 7.68701113e-07
Iter: 1631 loss: 7.68765801e-07
Iter: 1632 loss: 7.68611699e-07
Iter: 1633 loss: 7.68490395e-07
Iter: 1634 loss: 7.68323218e-07
Iter: 1635 loss: 7.68331745e-07
Iter: 1636 loss: 7.68226528e-07
Iter: 1637 loss: 7.68220843e-07
Iter: 1638 loss: 7.68073619e-07
Iter: 1639 loss: 7.67845961e-07
Iter: 1640 loss: 7.67878589e-07
Iter: 1641 loss: 7.67697088e-07
Iter: 1642 loss: 7.68679058e-07
Iter: 1643 loss: 7.67694928e-07
Iter: 1644 loss: 7.67495123e-07
Iter: 1645 loss: 7.68264044e-07
Iter: 1646 loss: 7.67469828e-07
Iter: 1647 loss: 7.67376946e-07
Iter: 1648 loss: 7.67722554e-07
Iter: 1649 loss: 7.6730197e-07
Iter: 1650 loss: 7.67155484e-07
Iter: 1651 loss: 7.67490519e-07
Iter: 1652 loss: 7.67107e-07
Iter: 1653 loss: 7.67016786e-07
Iter: 1654 loss: 7.6698359e-07
Iter: 1655 loss: 7.6694505e-07
Iter: 1656 loss: 7.66786457e-07
Iter: 1657 loss: 7.6685842e-07
Iter: 1658 loss: 7.66666687e-07
Iter: 1659 loss: 7.66585742e-07
Iter: 1660 loss: 7.66550215e-07
Iter: 1661 loss: 7.66431526e-07
Iter: 1662 loss: 7.6704049e-07
Iter: 1663 loss: 7.66426865e-07
Iter: 1664 loss: 7.66301127e-07
Iter: 1665 loss: 7.66043399e-07
Iter: 1666 loss: 7.69893063e-07
Iter: 1667 loss: 7.66006849e-07
Iter: 1668 loss: 7.65841378e-07
Iter: 1669 loss: 7.65854793e-07
Iter: 1670 loss: 7.65685911e-07
Iter: 1671 loss: 7.65931247e-07
Iter: 1672 loss: 7.65618097e-07
Iter: 1673 loss: 7.65474738e-07
Iter: 1674 loss: 7.65369407e-07
Iter: 1675 loss: 7.6535207e-07
Iter: 1676 loss: 7.65255379e-07
Iter: 1677 loss: 7.6524e-07
Iter: 1678 loss: 7.65144932e-07
Iter: 1679 loss: 7.65135951e-07
Iter: 1680 loss: 7.65078084e-07
Iter: 1681 loss: 7.64991569e-07
Iter: 1682 loss: 7.65827963e-07
Iter: 1683 loss: 7.6495769e-07
Iter: 1684 loss: 7.64912102e-07
Iter: 1685 loss: 7.64793867e-07
Iter: 1686 loss: 7.66532366e-07
Iter: 1687 loss: 7.64793242e-07
Iter: 1688 loss: 7.64625952e-07
Iter: 1689 loss: 7.64793072e-07
Iter: 1690 loss: 7.64585479e-07
Iter: 1691 loss: 7.64360379e-07
Iter: 1692 loss: 7.65167101e-07
Iter: 1693 loss: 7.64322067e-07
Iter: 1694 loss: 7.64173819e-07
Iter: 1695 loss: 7.64177116e-07
Iter: 1696 loss: 7.64083e-07
Iter: 1697 loss: 7.64043762e-07
Iter: 1698 loss: 7.63966852e-07
Iter: 1699 loss: 7.63857884e-07
Iter: 1700 loss: 7.64115896e-07
Iter: 1701 loss: 7.63807748e-07
Iter: 1702 loss: 7.63675928e-07
Iter: 1703 loss: 7.64661e-07
Iter: 1704 loss: 7.63633352e-07
Iter: 1705 loss: 7.63540356e-07
Iter: 1706 loss: 7.63387959e-07
Iter: 1707 loss: 7.63426499e-07
Iter: 1708 loss: 7.63277058e-07
Iter: 1709 loss: 7.64735773e-07
Iter: 1710 loss: 7.63281719e-07
Iter: 1711 loss: 7.63152229e-07
Iter: 1712 loss: 7.63538083e-07
Iter: 1713 loss: 7.63113576e-07
Iter: 1714 loss: 7.63064236e-07
Iter: 1715 loss: 7.63109313e-07
Iter: 1716 loss: 7.62998297e-07
Iter: 1717 loss: 7.62846526e-07
Iter: 1718 loss: 7.63489595e-07
Iter: 1719 loss: 7.62832542e-07
Iter: 1720 loss: 7.627782e-07
Iter: 1721 loss: 7.62592322e-07
Iter: 1722 loss: 7.65179607e-07
Iter: 1723 loss: 7.62598e-07
Iter: 1724 loss: 7.62475281e-07
Iter: 1725 loss: 7.62600735e-07
Iter: 1726 loss: 7.62358582e-07
Iter: 1727 loss: 7.62236425e-07
Iter: 1728 loss: 7.62242962e-07
Iter: 1729 loss: 7.62078e-07
Iter: 1730 loss: 7.62335048e-07
Iter: 1731 loss: 7.62022751e-07
Iter: 1732 loss: 7.61901504e-07
Iter: 1733 loss: 7.61864953e-07
Iter: 1734 loss: 7.61792535e-07
Iter: 1735 loss: 7.61656452e-07
Iter: 1736 loss: 7.63531204e-07
Iter: 1737 loss: 7.61645879e-07
Iter: 1738 loss: 7.6156482e-07
Iter: 1739 loss: 7.61509682e-07
Iter: 1740 loss: 7.61428e-07
Iter: 1741 loss: 7.61287708e-07
Iter: 1742 loss: 7.61256e-07
Iter: 1743 loss: 7.61164415e-07
Iter: 1744 loss: 7.61052434e-07
Iter: 1745 loss: 7.61014e-07
Iter: 1746 loss: 7.60917942e-07
Iter: 1747 loss: 7.60801527e-07
Iter: 1748 loss: 7.60806756e-07
Iter: 1749 loss: 7.60739283e-07
Iter: 1750 loss: 7.60712396e-07
Iter: 1751 loss: 7.60669593e-07
Iter: 1752 loss: 7.60555508e-07
Iter: 1753 loss: 7.62678781e-07
Iter: 1754 loss: 7.60559544e-07
Iter: 1755 loss: 7.60440912e-07
Iter: 1756 loss: 7.60425735e-07
Iter: 1757 loss: 7.6035144e-07
Iter: 1758 loss: 7.60209844e-07
Iter: 1759 loss: 7.6128191e-07
Iter: 1760 loss: 7.60206262e-07
Iter: 1761 loss: 7.6008638e-07
Iter: 1762 loss: 7.61099614e-07
Iter: 1763 loss: 7.60069156e-07
Iter: 1764 loss: 7.60010153e-07
Iter: 1765 loss: 7.59878162e-07
Iter: 1766 loss: 7.59882369e-07
Iter: 1767 loss: 7.59719569e-07
Iter: 1768 loss: 7.60277089e-07
Iter: 1769 loss: 7.59686657e-07
Iter: 1770 loss: 7.59503223e-07
Iter: 1771 loss: 7.61551462e-07
Iter: 1772 loss: 7.59492e-07
Iter: 1773 loss: 7.59411705e-07
Iter: 1774 loss: 7.59272325e-07
Iter: 1775 loss: 7.5928449e-07
Iter: 1776 loss: 7.59165232e-07
Iter: 1777 loss: 7.60186e-07
Iter: 1778 loss: 7.59171598e-07
Iter: 1779 loss: 7.59061095e-07
Iter: 1780 loss: 7.59425745e-07
Iter: 1781 loss: 7.59026307e-07
Iter: 1782 loss: 7.5895e-07
Iter: 1783 loss: 7.58963665e-07
Iter: 1784 loss: 7.5888147e-07
Iter: 1785 loss: 7.5877449e-07
Iter: 1786 loss: 7.60240198e-07
Iter: 1787 loss: 7.58794044e-07
Iter: 1788 loss: 7.58734e-07
Iter: 1789 loss: 7.58633632e-07
Iter: 1790 loss: 7.6054522e-07
Iter: 1791 loss: 7.58620558e-07
Iter: 1792 loss: 7.58512385e-07
Iter: 1793 loss: 7.58820192e-07
Iter: 1794 loss: 7.58479e-07
Iter: 1795 loss: 7.58392048e-07
Iter: 1796 loss: 7.58369197e-07
Iter: 1797 loss: 7.58282624e-07
Iter: 1798 loss: 7.58240105e-07
Iter: 1799 loss: 7.58208216e-07
Iter: 1800 loss: 7.58117949e-07
Iter: 1801 loss: 7.58483338e-07
Iter: 1802 loss: 7.58102374e-07
Iter: 1803 loss: 7.58008525e-07
Iter: 1804 loss: 7.5906496e-07
Iter: 1805 loss: 7.58039505e-07
Iter: 1806 loss: 7.57924909e-07
Iter: 1807 loss: 7.57756766e-07
Iter: 1808 loss: 7.60653847e-07
Iter: 1809 loss: 7.57757448e-07
Iter: 1810 loss: 7.57585e-07
Iter: 1811 loss: 7.57940029e-07
Iter: 1812 loss: 7.57518478e-07
Iter: 1813 loss: 7.57373755e-07
Iter: 1814 loss: 7.5736807e-07
Iter: 1815 loss: 7.57275814e-07
Iter: 1816 loss: 7.57011e-07
Iter: 1817 loss: 7.60499802e-07
Iter: 1818 loss: 7.5703457e-07
Iter: 1819 loss: 7.56991938e-07
Iter: 1820 loss: 7.56904569e-07
Iter: 1821 loss: 7.56835107e-07
Iter: 1822 loss: 7.56719032e-07
Iter: 1823 loss: 7.59718773e-07
Iter: 1824 loss: 7.56702548e-07
Iter: 1825 loss: 7.56529857e-07
Iter: 1826 loss: 7.56725285e-07
Iter: 1827 loss: 7.56451072e-07
Iter: 1828 loss: 7.56435384e-07
Iter: 1829 loss: 7.56405825e-07
Iter: 1830 loss: 7.56316183e-07
Iter: 1831 loss: 7.56275313e-07
Iter: 1832 loss: 7.5625951e-07
Iter: 1833 loss: 7.56162535e-07
Iter: 1834 loss: 7.56150712e-07
Iter: 1835 loss: 7.5609853e-07
Iter: 1836 loss: 7.56014288e-07
Iter: 1837 loss: 7.56032591e-07
Iter: 1838 loss: 7.55932e-07
Iter: 1839 loss: 7.55880876e-07
Iter: 1840 loss: 7.55854387e-07
Iter: 1841 loss: 7.55746e-07
Iter: 1842 loss: 7.55798396e-07
Iter: 1843 loss: 7.55667656e-07
Iter: 1844 loss: 7.55550332e-07
Iter: 1845 loss: 7.57030705e-07
Iter: 1846 loss: 7.55549536e-07
Iter: 1847 loss: 7.55419705e-07
Iter: 1848 loss: 7.55369911e-07
Iter: 1849 loss: 7.55307326e-07
Iter: 1850 loss: 7.55209385e-07
Iter: 1851 loss: 7.562669e-07
Iter: 1852 loss: 7.55202052e-07
Iter: 1853 loss: 7.5511565e-07
Iter: 1854 loss: 7.5507262e-07
Iter: 1855 loss: 7.55007136e-07
Iter: 1856 loss: 7.54898906e-07
Iter: 1857 loss: 7.54954897e-07
Iter: 1858 loss: 7.54822622e-07
Iter: 1859 loss: 7.54705695e-07
Iter: 1860 loss: 7.55212682e-07
Iter: 1861 loss: 7.54701546e-07
Iter: 1862 loss: 7.54606162e-07
Iter: 1863 loss: 7.55628434e-07
Iter: 1864 loss: 7.54604685e-07
Iter: 1865 loss: 7.54504413e-07
Iter: 1866 loss: 7.54372593e-07
Iter: 1867 loss: 7.57580551e-07
Iter: 1868 loss: 7.54372422e-07
Iter: 1869 loss: 7.54274424e-07
Iter: 1870 loss: 7.55300391e-07
Iter: 1871 loss: 7.5428045e-07
Iter: 1872 loss: 7.54130326e-07
Iter: 1873 loss: 7.54680514e-07
Iter: 1874 loss: 7.54103326e-07
Iter: 1875 loss: 7.54011126e-07
Iter: 1876 loss: 7.53909887e-07
Iter: 1877 loss: 7.53914605e-07
Iter: 1878 loss: 7.53725203e-07
Iter: 1879 loss: 7.546289e-07
Iter: 1880 loss: 7.53693655e-07
Iter: 1881 loss: 7.53578888e-07
Iter: 1882 loss: 7.55036e-07
Iter: 1883 loss: 7.53566951e-07
Iter: 1884 loss: 7.53474637e-07
Iter: 1885 loss: 7.53510562e-07
Iter: 1886 loss: 7.53437291e-07
Iter: 1887 loss: 7.53321387e-07
Iter: 1888 loss: 7.54264533e-07
Iter: 1889 loss: 7.53315362e-07
Iter: 1890 loss: 7.53229301e-07
Iter: 1891 loss: 7.53119139e-07
Iter: 1892 loss: 7.55719213e-07
Iter: 1893 loss: 7.53100721e-07
Iter: 1894 loss: 7.52979474e-07
Iter: 1895 loss: 7.53477821e-07
Iter: 1896 loss: 7.52903645e-07
Iter: 1897 loss: 7.52826168e-07
Iter: 1898 loss: 7.52827e-07
Iter: 1899 loss: 7.52711685e-07
Iter: 1900 loss: 7.52652909e-07
Iter: 1901 loss: 7.52619201e-07
Iter: 1902 loss: 7.52529786e-07
Iter: 1903 loss: 7.5254718e-07
Iter: 1904 loss: 7.52448386e-07
Iter: 1905 loss: 7.52404958e-07
Iter: 1906 loss: 7.52389383e-07
Iter: 1907 loss: 7.52327082e-07
Iter: 1908 loss: 7.52369886e-07
Iter: 1909 loss: 7.52260405e-07
Iter: 1910 loss: 7.52225958e-07
Iter: 1911 loss: 7.52066342e-07
Iter: 1912 loss: 7.54613893e-07
Iter: 1913 loss: 7.52083338e-07
Iter: 1914 loss: 7.5196192e-07
Iter: 1915 loss: 7.51954417e-07
Iter: 1916 loss: 7.51832204e-07
Iter: 1917 loss: 7.51936739e-07
Iter: 1918 loss: 7.51734206e-07
Iter: 1919 loss: 7.51626885e-07
Iter: 1920 loss: 7.52330379e-07
Iter: 1921 loss: 7.51648145e-07
Iter: 1922 loss: 7.51529342e-07
Iter: 1923 loss: 7.51389734e-07
Iter: 1924 loss: 7.51367224e-07
Iter: 1925 loss: 7.51209598e-07
Iter: 1926 loss: 7.51239668e-07
Iter: 1927 loss: 7.51075504e-07
Iter: 1928 loss: 7.50918616e-07
Iter: 1929 loss: 7.52027347e-07
Iter: 1930 loss: 7.50923277e-07
Iter: 1931 loss: 7.50831873e-07
Iter: 1932 loss: 7.50804304e-07
Iter: 1933 loss: 7.50749e-07
Iter: 1934 loss: 7.50630932e-07
Iter: 1935 loss: 7.52413484e-07
Iter: 1936 loss: 7.50631955e-07
Iter: 1937 loss: 7.50508377e-07
Iter: 1938 loss: 7.50777076e-07
Iter: 1939 loss: 7.50449829e-07
Iter: 1940 loss: 7.50432719e-07
Iter: 1941 loss: 7.50401796e-07
Iter: 1942 loss: 7.50361551e-07
Iter: 1943 loss: 7.50220124e-07
Iter: 1944 loss: 7.51484322e-07
Iter: 1945 loss: 7.5023047e-07
Iter: 1946 loss: 7.50077561e-07
Iter: 1947 loss: 7.5010837e-07
Iter: 1948 loss: 7.49951141e-07
Iter: 1949 loss: 7.49911123e-07
Iter: 1950 loss: 7.49864228e-07
Iter: 1951 loss: 7.49759522e-07
Iter: 1952 loss: 7.49670392e-07
Iter: 1953 loss: 7.49659193e-07
Iter: 1954 loss: 7.49568358e-07
Iter: 1955 loss: 7.51015705e-07
Iter: 1956 loss: 7.49585183e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.4/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.8 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.8
+ date
Sun Nov  8 01:05:22 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.4/300_100_100_100_1 --function f1 --psi 1 --phi 0.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.8/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cf35fe620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cf35fe378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cbd0fcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cf363dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cf3633840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cf3633d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c980a86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cf3633f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cbd050488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8cbd04b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c98054ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80251b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80251730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c980138c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c980e89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c980c6d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c980f1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c801c9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80155840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80155b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80195488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c801ab9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80212730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c800fed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c800f9d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c800a5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c800a5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80119840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c8004f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80119730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c80034ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c34777048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c347780d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c3477ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c3470f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8c346c4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0028833388
test_loss: 0.0028263137
train_loss: 0.002342519
test_loss: 0.0024956723
train_loss: 0.00240044
test_loss: 0.0025435241
train_loss: 0.0021792615
test_loss: 0.0022272777
train_loss: 0.0022851324
test_loss: 0.0022498926
train_loss: 0.0020939296
test_loss: 0.0022952796
train_loss: 0.0020748957
test_loss: 0.0022611592
train_loss: 0.0021690342
test_loss: 0.0024706675
train_loss: 0.002108114
test_loss: 0.0021904171
train_loss: 0.0021126904
test_loss: 0.002358781
train_loss: 0.0019412024
test_loss: 0.0021597364
train_loss: 0.0021263226
test_loss: 0.0022150865
train_loss: 0.0020988563
test_loss: 0.0023629777
train_loss: 0.0020469597
test_loss: 0.0021750252
train_loss: 0.0021965145
test_loss: 0.0021282556
train_loss: 0.0022261245
test_loss: 0.0022829783
train_loss: 0.002111224
test_loss: 0.0021410603
train_loss: 0.0019003795
test_loss: 0.0020253852
train_loss: 0.0020642611
test_loss: 0.002283271
train_loss: 0.0021091993
test_loss: 0.0022772788
train_loss: 0.0020719743
test_loss: 0.0022675083
train_loss: 0.0020463956
test_loss: 0.002042662
train_loss: 0.0019984858
test_loss: 0.0020634537
train_loss: 0.0020164256
test_loss: 0.0022462963
train_loss: 0.0021138065
test_loss: 0.0021544353
train_loss: 0.0022841953
test_loss: 0.0021659206
train_loss: 0.0020279526
test_loss: 0.0022606095
train_loss: 0.0018756355
test_loss: 0.0020292413
train_loss: 0.002019621
test_loss: 0.0020214047
train_loss: 0.002032341
test_loss: 0.002215878
train_loss: 0.0020348346
test_loss: 0.0022172623
train_loss: 0.0020140635
test_loss: 0.0022332422
train_loss: 0.001962952
test_loss: 0.0020438498
train_loss: 0.0020145078
test_loss: 0.0021137688
train_loss: 0.0019192023
test_loss: 0.002281616
train_loss: 0.001942481
test_loss: 0.0021189759
train_loss: 0.0023837693
test_loss: 0.0023324217
train_loss: 0.0020852697
test_loss: 0.0021083201
train_loss: 0.0019721305
test_loss: 0.002245586
train_loss: 0.0018904789
test_loss: 0.002059249
train_loss: 0.0020565002
test_loss: 0.0022123985
train_loss: 0.0019432092
test_loss: 0.0021886653
train_loss: 0.0019950992
test_loss: 0.0020991284
train_loss: 0.0019608699
test_loss: 0.002126184
train_loss: 0.0021191915
test_loss: 0.002160864
train_loss: 0.0018690012
test_loss: 0.002148816
train_loss: 0.0019139517
test_loss: 0.0020824736
train_loss: 0.001915852
test_loss: 0.0021174278
train_loss: 0.0019309068
test_loss: 0.0020847504
train_loss: 0.0019045856
test_loss: 0.0020198345
train_loss: 0.0020387997
test_loss: 0.0022102378
train_loss: 0.002023381
test_loss: 0.0019631821
train_loss: 0.0020402647
test_loss: 0.0021653213
train_loss: 0.002027989
test_loss: 0.0022048915
train_loss: 0.0019351018
test_loss: 0.0020438426
train_loss: 0.0018631327
test_loss: 0.0022108816
train_loss: 0.0020569174
test_loss: 0.0022265941
train_loss: 0.0020785264
test_loss: 0.0020967678
train_loss: 0.0019209981
test_loss: 0.0019689722
train_loss: 0.0019184405
test_loss: 0.0021471742
train_loss: 0.0018451799
test_loss: 0.0020235444
train_loss: 0.002020638
test_loss: 0.002113179
train_loss: 0.002018317
test_loss: 0.0022078017
train_loss: 0.0021961909
test_loss: 0.0020365557
train_loss: 0.001776004
test_loss: 0.0021299883
train_loss: 0.0020249514
test_loss: 0.0021516406
train_loss: 0.0019078376
test_loss: 0.0020178996
train_loss: 0.0019877094
test_loss: 0.0020528813
train_loss: 0.0020629528
test_loss: 0.0021690791
train_loss: 0.0018393103
test_loss: 0.0020208173
train_loss: 0.0019782507
test_loss: 0.0021288563
train_loss: 0.0020784144
test_loss: 0.0020968993
train_loss: 0.0017989713
test_loss: 0.0021128356
train_loss: 0.0018582693
test_loss: 0.0020231649
train_loss: 0.0018826531
test_loss: 0.0021198718
train_loss: 0.0019087491
test_loss: 0.002071898
train_loss: 0.0020621135
test_loss: 0.0021366007
train_loss: 0.0018771355
test_loss: 0.0021541272
train_loss: 0.001972023
test_loss: 0.001991801
train_loss: 0.0019304738
test_loss: 0.002028622
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.8/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 0.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi0.8/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe851741378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe851775d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe851775ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8516a1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8516c27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8516c2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe851607730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8515b2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8515a9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe85156e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8515b2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe851518f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe85154a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8514ffc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8514a18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8514bed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8514c7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8514c7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe85143f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe85143ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8513dcea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8489f7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8489a2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8489b17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8489a2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe84896c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe848936510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe848960840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8488e97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe84890a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8488b06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8488de1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe848877378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe848877c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8488459d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe8488452f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.49877586e-06
Iter: 2 loss: 6.71671614e-06
Iter: 3 loss: 4.74172111e-06
Iter: 4 loss: 4.34612275e-06
Iter: 5 loss: 5.20223512e-06
Iter: 6 loss: 4.19256094e-06
Iter: 7 loss: 4.00344197e-06
Iter: 8 loss: 4.54194833e-06
Iter: 9 loss: 3.94381914e-06
Iter: 10 loss: 3.73320336e-06
Iter: 11 loss: 4.58860904e-06
Iter: 12 loss: 3.68661495e-06
Iter: 13 loss: 3.58422903e-06
Iter: 14 loss: 3.6078477e-06
Iter: 15 loss: 3.50900086e-06
Iter: 16 loss: 3.46052025e-06
Iter: 17 loss: 3.45494118e-06
Iter: 18 loss: 3.41051305e-06
Iter: 19 loss: 3.3759743e-06
Iter: 20 loss: 3.36217681e-06
Iter: 21 loss: 3.29538625e-06
Iter: 22 loss: 3.48860158e-06
Iter: 23 loss: 3.27454063e-06
Iter: 24 loss: 3.20058734e-06
Iter: 25 loss: 3.74718957e-06
Iter: 26 loss: 3.19457376e-06
Iter: 27 loss: 3.14104363e-06
Iter: 28 loss: 3.02001763e-06
Iter: 29 loss: 4.63642755e-06
Iter: 30 loss: 3.01253726e-06
Iter: 31 loss: 2.87478747e-06
Iter: 32 loss: 3.06819243e-06
Iter: 33 loss: 2.80683616e-06
Iter: 34 loss: 2.70258897e-06
Iter: 35 loss: 3.65970368e-06
Iter: 36 loss: 2.69796396e-06
Iter: 37 loss: 2.60667571e-06
Iter: 38 loss: 2.76702576e-06
Iter: 39 loss: 2.56657904e-06
Iter: 40 loss: 2.57287275e-06
Iter: 41 loss: 2.54008319e-06
Iter: 42 loss: 2.51472625e-06
Iter: 43 loss: 2.46788522e-06
Iter: 44 loss: 3.55222119e-06
Iter: 45 loss: 2.46794252e-06
Iter: 46 loss: 2.43972977e-06
Iter: 47 loss: 2.43973545e-06
Iter: 48 loss: 2.40994586e-06
Iter: 49 loss: 2.37989184e-06
Iter: 50 loss: 2.37396216e-06
Iter: 51 loss: 2.32766979e-06
Iter: 52 loss: 2.36486312e-06
Iter: 53 loss: 2.29984698e-06
Iter: 54 loss: 2.26897282e-06
Iter: 55 loss: 2.26676502e-06
Iter: 56 loss: 2.23874986e-06
Iter: 57 loss: 2.18802529e-06
Iter: 58 loss: 3.41481154e-06
Iter: 59 loss: 2.18792957e-06
Iter: 60 loss: 2.152967e-06
Iter: 61 loss: 2.15174805e-06
Iter: 62 loss: 2.11782344e-06
Iter: 63 loss: 2.09210771e-06
Iter: 64 loss: 2.08115898e-06
Iter: 65 loss: 2.05759898e-06
Iter: 66 loss: 2.05536344e-06
Iter: 67 loss: 2.03809282e-06
Iter: 68 loss: 2.00242175e-06
Iter: 69 loss: 2.18380819e-06
Iter: 70 loss: 1.99663828e-06
Iter: 71 loss: 1.97347094e-06
Iter: 72 loss: 2.03477953e-06
Iter: 73 loss: 1.96572432e-06
Iter: 74 loss: 1.95032248e-06
Iter: 75 loss: 1.95035227e-06
Iter: 76 loss: 1.93163964e-06
Iter: 77 loss: 1.92000766e-06
Iter: 78 loss: 1.91261074e-06
Iter: 79 loss: 1.89021307e-06
Iter: 80 loss: 1.96846895e-06
Iter: 81 loss: 1.88442891e-06
Iter: 82 loss: 1.86985824e-06
Iter: 83 loss: 1.8698928e-06
Iter: 84 loss: 1.8613e-06
Iter: 85 loss: 1.83962652e-06
Iter: 86 loss: 2.04028106e-06
Iter: 87 loss: 1.83649331e-06
Iter: 88 loss: 1.81697158e-06
Iter: 89 loss: 2.1227911e-06
Iter: 90 loss: 1.81699579e-06
Iter: 91 loss: 1.79639346e-06
Iter: 92 loss: 1.82105487e-06
Iter: 93 loss: 1.78551954e-06
Iter: 94 loss: 1.77125423e-06
Iter: 95 loss: 1.83196573e-06
Iter: 96 loss: 1.76828769e-06
Iter: 97 loss: 1.7468916e-06
Iter: 98 loss: 1.72569071e-06
Iter: 99 loss: 1.7212933e-06
Iter: 100 loss: 1.697176e-06
Iter: 101 loss: 1.7671174e-06
Iter: 102 loss: 1.68963038e-06
Iter: 103 loss: 1.67192957e-06
Iter: 104 loss: 1.66289408e-06
Iter: 105 loss: 1.6546735e-06
Iter: 106 loss: 1.6343788e-06
Iter: 107 loss: 1.87319017e-06
Iter: 108 loss: 1.63411028e-06
Iter: 109 loss: 1.62158221e-06
Iter: 110 loss: 1.69508337e-06
Iter: 111 loss: 1.61998241e-06
Iter: 112 loss: 1.608209e-06
Iter: 113 loss: 1.72036994e-06
Iter: 114 loss: 1.60769878e-06
Iter: 115 loss: 1.60018408e-06
Iter: 116 loss: 1.59203182e-06
Iter: 117 loss: 1.59076103e-06
Iter: 118 loss: 1.5814561e-06
Iter: 119 loss: 1.68328415e-06
Iter: 120 loss: 1.58124919e-06
Iter: 121 loss: 1.57057843e-06
Iter: 122 loss: 1.55150974e-06
Iter: 123 loss: 2.02323577e-06
Iter: 124 loss: 1.55154191e-06
Iter: 125 loss: 1.53358837e-06
Iter: 126 loss: 1.63095456e-06
Iter: 127 loss: 1.53087194e-06
Iter: 128 loss: 1.52206508e-06
Iter: 129 loss: 1.52185771e-06
Iter: 130 loss: 1.51423581e-06
Iter: 131 loss: 1.49993025e-06
Iter: 132 loss: 1.82133863e-06
Iter: 133 loss: 1.49987068e-06
Iter: 134 loss: 1.49063226e-06
Iter: 135 loss: 1.48970776e-06
Iter: 136 loss: 1.48277582e-06
Iter: 137 loss: 1.4696825e-06
Iter: 138 loss: 1.76191418e-06
Iter: 139 loss: 1.46968773e-06
Iter: 140 loss: 1.45985678e-06
Iter: 141 loss: 1.49556513e-06
Iter: 142 loss: 1.45742104e-06
Iter: 143 loss: 1.44795843e-06
Iter: 144 loss: 1.45946387e-06
Iter: 145 loss: 1.44298838e-06
Iter: 146 loss: 1.43426678e-06
Iter: 147 loss: 1.46291222e-06
Iter: 148 loss: 1.43188061e-06
Iter: 149 loss: 1.4272249e-06
Iter: 150 loss: 1.42625845e-06
Iter: 151 loss: 1.42152294e-06
Iter: 152 loss: 1.41113594e-06
Iter: 153 loss: 1.56805106e-06
Iter: 154 loss: 1.41067824e-06
Iter: 155 loss: 1.40447537e-06
Iter: 156 loss: 1.40444013e-06
Iter: 157 loss: 1.39803717e-06
Iter: 158 loss: 1.39875897e-06
Iter: 159 loss: 1.39315114e-06
Iter: 160 loss: 1.3844151e-06
Iter: 161 loss: 1.38160476e-06
Iter: 162 loss: 1.37646066e-06
Iter: 163 loss: 1.37169513e-06
Iter: 164 loss: 1.37081361e-06
Iter: 165 loss: 1.36567542e-06
Iter: 166 loss: 1.36173719e-06
Iter: 167 loss: 1.36011317e-06
Iter: 168 loss: 1.35274877e-06
Iter: 169 loss: 1.400663e-06
Iter: 170 loss: 1.3519533e-06
Iter: 171 loss: 1.34594814e-06
Iter: 172 loss: 1.37009511e-06
Iter: 173 loss: 1.34460583e-06
Iter: 174 loss: 1.34138293e-06
Iter: 175 loss: 1.33547746e-06
Iter: 176 loss: 1.47300773e-06
Iter: 177 loss: 1.33547474e-06
Iter: 178 loss: 1.32962055e-06
Iter: 179 loss: 1.33593744e-06
Iter: 180 loss: 1.3264264e-06
Iter: 181 loss: 1.31852e-06
Iter: 182 loss: 1.3584056e-06
Iter: 183 loss: 1.31711499e-06
Iter: 184 loss: 1.31317006e-06
Iter: 185 loss: 1.31280819e-06
Iter: 186 loss: 1.30839794e-06
Iter: 187 loss: 1.30547687e-06
Iter: 188 loss: 1.30385251e-06
Iter: 189 loss: 1.29779414e-06
Iter: 190 loss: 1.2957646e-06
Iter: 191 loss: 1.29222974e-06
Iter: 192 loss: 1.28650697e-06
Iter: 193 loss: 1.28603403e-06
Iter: 194 loss: 1.28282511e-06
Iter: 195 loss: 1.27507406e-06
Iter: 196 loss: 1.35926325e-06
Iter: 197 loss: 1.27424664e-06
Iter: 198 loss: 1.27208591e-06
Iter: 199 loss: 1.27054625e-06
Iter: 200 loss: 1.2671228e-06
Iter: 201 loss: 1.2655255e-06
Iter: 202 loss: 1.26374425e-06
Iter: 203 loss: 1.26080022e-06
Iter: 204 loss: 1.2896237e-06
Iter: 205 loss: 1.2607029e-06
Iter: 206 loss: 1.25829115e-06
Iter: 207 loss: 1.26568511e-06
Iter: 208 loss: 1.25767383e-06
Iter: 209 loss: 1.25514316e-06
Iter: 210 loss: 1.24976066e-06
Iter: 211 loss: 1.33169499e-06
Iter: 212 loss: 1.24953885e-06
Iter: 213 loss: 1.24588882e-06
Iter: 214 loss: 1.27859789e-06
Iter: 215 loss: 1.24569829e-06
Iter: 216 loss: 1.24158726e-06
Iter: 217 loss: 1.2344583e-06
Iter: 218 loss: 1.2344417e-06
Iter: 219 loss: 1.23768712e-06
Iter: 220 loss: 1.23129985e-06
Iter: 221 loss: 1.22852316e-06
Iter: 222 loss: 1.22439872e-06
Iter: 223 loss: 1.22435e-06
Iter: 224 loss: 1.22032156e-06
Iter: 225 loss: 1.22938491e-06
Iter: 226 loss: 1.21887138e-06
Iter: 227 loss: 1.21299729e-06
Iter: 228 loss: 1.23355312e-06
Iter: 229 loss: 1.21146877e-06
Iter: 230 loss: 1.2088077e-06
Iter: 231 loss: 1.21103096e-06
Iter: 232 loss: 1.20715345e-06
Iter: 233 loss: 1.20475033e-06
Iter: 234 loss: 1.22612505e-06
Iter: 235 loss: 1.20459345e-06
Iter: 236 loss: 1.20181267e-06
Iter: 237 loss: 1.20327991e-06
Iter: 238 loss: 1.19997298e-06
Iter: 239 loss: 1.1980303e-06
Iter: 240 loss: 1.20503e-06
Iter: 241 loss: 1.19742367e-06
Iter: 242 loss: 1.19521121e-06
Iter: 243 loss: 1.20927234e-06
Iter: 244 loss: 1.19495382e-06
Iter: 245 loss: 1.1935964e-06
Iter: 246 loss: 1.19032234e-06
Iter: 247 loss: 1.22367896e-06
Iter: 248 loss: 1.18989249e-06
Iter: 249 loss: 1.18476942e-06
Iter: 250 loss: 1.19968649e-06
Iter: 251 loss: 1.18314813e-06
Iter: 252 loss: 1.17934508e-06
Iter: 253 loss: 1.18814137e-06
Iter: 254 loss: 1.17795094e-06
Iter: 255 loss: 1.17520381e-06
Iter: 256 loss: 1.17507955e-06
Iter: 257 loss: 1.17239915e-06
Iter: 258 loss: 1.17165098e-06
Iter: 259 loss: 1.16999877e-06
Iter: 260 loss: 1.16779097e-06
Iter: 261 loss: 1.17165075e-06
Iter: 262 loss: 1.166846e-06
Iter: 263 loss: 1.16512274e-06
Iter: 264 loss: 1.1650925e-06
Iter: 265 loss: 1.16366186e-06
Iter: 266 loss: 1.16011643e-06
Iter: 267 loss: 1.20041159e-06
Iter: 268 loss: 1.1598238e-06
Iter: 269 loss: 1.1581825e-06
Iter: 270 loss: 1.1582099e-06
Iter: 271 loss: 1.15626699e-06
Iter: 272 loss: 1.15969181e-06
Iter: 273 loss: 1.15548551e-06
Iter: 274 loss: 1.15369198e-06
Iter: 275 loss: 1.15287958e-06
Iter: 276 loss: 1.15198645e-06
Iter: 277 loss: 1.1493255e-06
Iter: 278 loss: 1.1775976e-06
Iter: 279 loss: 1.14922227e-06
Iter: 280 loss: 1.14722661e-06
Iter: 281 loss: 1.14392196e-06
Iter: 282 loss: 1.14393242e-06
Iter: 283 loss: 1.1400366e-06
Iter: 284 loss: 1.14402019e-06
Iter: 285 loss: 1.137906e-06
Iter: 286 loss: 1.13454269e-06
Iter: 287 loss: 1.15645594e-06
Iter: 288 loss: 1.13417605e-06
Iter: 289 loss: 1.13247006e-06
Iter: 290 loss: 1.13238809e-06
Iter: 291 loss: 1.13096326e-06
Iter: 292 loss: 1.13566023e-06
Iter: 293 loss: 1.13052681e-06
Iter: 294 loss: 1.12958173e-06
Iter: 295 loss: 1.12850671e-06
Iter: 296 loss: 1.12834425e-06
Iter: 297 loss: 1.12712485e-06
Iter: 298 loss: 1.14470231e-06
Iter: 299 loss: 1.12713644e-06
Iter: 300 loss: 1.12576924e-06
Iter: 301 loss: 1.1235453e-06
Iter: 302 loss: 1.12350585e-06
Iter: 303 loss: 1.12048497e-06
Iter: 304 loss: 1.12289774e-06
Iter: 305 loss: 1.11871861e-06
Iter: 306 loss: 1.11720851e-06
Iter: 307 loss: 1.11705833e-06
Iter: 308 loss: 1.11522968e-06
Iter: 309 loss: 1.1136168e-06
Iter: 310 loss: 1.11312897e-06
Iter: 311 loss: 1.11143197e-06
Iter: 312 loss: 1.12378711e-06
Iter: 313 loss: 1.11118425e-06
Iter: 314 loss: 1.10919063e-06
Iter: 315 loss: 1.10907274e-06
Iter: 316 loss: 1.10751944e-06
Iter: 317 loss: 1.10558074e-06
Iter: 318 loss: 1.10809287e-06
Iter: 319 loss: 1.10460201e-06
Iter: 320 loss: 1.10304131e-06
Iter: 321 loss: 1.10631902e-06
Iter: 322 loss: 1.10245719e-06
Iter: 323 loss: 1.10093265e-06
Iter: 324 loss: 1.1150637e-06
Iter: 325 loss: 1.10091048e-06
Iter: 326 loss: 1.09929385e-06
Iter: 327 loss: 1.10542294e-06
Iter: 328 loss: 1.09893563e-06
Iter: 329 loss: 1.09802613e-06
Iter: 330 loss: 1.0963613e-06
Iter: 331 loss: 1.13172314e-06
Iter: 332 loss: 1.09631583e-06
Iter: 333 loss: 1.09471546e-06
Iter: 334 loss: 1.0947349e-06
Iter: 335 loss: 1.09351697e-06
Iter: 336 loss: 1.09733764e-06
Iter: 337 loss: 1.09317773e-06
Iter: 338 loss: 1.09215875e-06
Iter: 339 loss: 1.09009477e-06
Iter: 340 loss: 1.12226394e-06
Iter: 341 loss: 1.09004486e-06
Iter: 342 loss: 1.08875702e-06
Iter: 343 loss: 1.08856443e-06
Iter: 344 loss: 1.08728182e-06
Iter: 345 loss: 1.09030657e-06
Iter: 346 loss: 1.08671441e-06
Iter: 347 loss: 1.08550796e-06
Iter: 348 loss: 1.08371898e-06
Iter: 349 loss: 1.08366476e-06
Iter: 350 loss: 1.08164272e-06
Iter: 351 loss: 1.08163022e-06
Iter: 352 loss: 1.08026563e-06
Iter: 353 loss: 1.07771143e-06
Iter: 354 loss: 1.12858913e-06
Iter: 355 loss: 1.07769665e-06
Iter: 356 loss: 1.07528399e-06
Iter: 357 loss: 1.07772189e-06
Iter: 358 loss: 1.07398171e-06
Iter: 359 loss: 1.07245421e-06
Iter: 360 loss: 1.0722581e-06
Iter: 361 loss: 1.07076539e-06
Iter: 362 loss: 1.0787378e-06
Iter: 363 loss: 1.07055052e-06
Iter: 364 loss: 1.06986295e-06
Iter: 365 loss: 1.06880771e-06
Iter: 366 loss: 1.06872358e-06
Iter: 367 loss: 1.06755681e-06
Iter: 368 loss: 1.07622213e-06
Iter: 369 loss: 1.06741913e-06
Iter: 370 loss: 1.06614584e-06
Iter: 371 loss: 1.07272263e-06
Iter: 372 loss: 1.06593586e-06
Iter: 373 loss: 1.06537618e-06
Iter: 374 loss: 1.06412244e-06
Iter: 375 loss: 1.08161362e-06
Iter: 376 loss: 1.0640199e-06
Iter: 377 loss: 1.06248444e-06
Iter: 378 loss: 1.08280369e-06
Iter: 379 loss: 1.06245739e-06
Iter: 380 loss: 1.06119296e-06
Iter: 381 loss: 1.0659478e-06
Iter: 382 loss: 1.060915e-06
Iter: 383 loss: 1.06012067e-06
Iter: 384 loss: 1.05892138e-06
Iter: 385 loss: 1.05891888e-06
Iter: 386 loss: 1.05664549e-06
Iter: 387 loss: 1.0659129e-06
Iter: 388 loss: 1.05611764e-06
Iter: 389 loss: 1.05483355e-06
Iter: 390 loss: 1.05505785e-06
Iter: 391 loss: 1.05387892e-06
Iter: 392 loss: 1.05252593e-06
Iter: 393 loss: 1.05666095e-06
Iter: 394 loss: 1.05211802e-06
Iter: 395 loss: 1.05125889e-06
Iter: 396 loss: 1.06152402e-06
Iter: 397 loss: 1.05120102e-06
Iter: 398 loss: 1.05017455e-06
Iter: 399 loss: 1.05148877e-06
Iter: 400 loss: 1.04963522e-06
Iter: 401 loss: 1.04908906e-06
Iter: 402 loss: 1.04842456e-06
Iter: 403 loss: 1.04838068e-06
Iter: 404 loss: 1.04734033e-06
Iter: 405 loss: 1.05382742e-06
Iter: 406 loss: 1.04724927e-06
Iter: 407 loss: 1.04591186e-06
Iter: 408 loss: 1.04774335e-06
Iter: 409 loss: 1.0452593e-06
Iter: 410 loss: 1.04430148e-06
Iter: 411 loss: 1.04386106e-06
Iter: 412 loss: 1.04334356e-06
Iter: 413 loss: 1.04213564e-06
Iter: 414 loss: 1.0421486e-06
Iter: 415 loss: 1.04077321e-06
Iter: 416 loss: 1.03852449e-06
Iter: 417 loss: 1.03853301e-06
Iter: 418 loss: 1.03728462e-06
Iter: 419 loss: 1.03726097e-06
Iter: 420 loss: 1.03618822e-06
Iter: 421 loss: 1.03780417e-06
Iter: 422 loss: 1.03563104e-06
Iter: 423 loss: 1.03458115e-06
Iter: 424 loss: 1.03480488e-06
Iter: 425 loss: 1.03378909e-06
Iter: 426 loss: 1.03277307e-06
Iter: 427 loss: 1.03398952e-06
Iter: 428 loss: 1.03219406e-06
Iter: 429 loss: 1.03157674e-06
Iter: 430 loss: 1.03151478e-06
Iter: 431 loss: 1.03082937e-06
Iter: 432 loss: 1.03117031e-06
Iter: 433 loss: 1.03039292e-06
Iter: 434 loss: 1.02972399e-06
Iter: 435 loss: 1.02864715e-06
Iter: 436 loss: 1.02862055e-06
Iter: 437 loss: 1.02783804e-06
Iter: 438 loss: 1.0278336e-06
Iter: 439 loss: 1.02691297e-06
Iter: 440 loss: 1.02775732e-06
Iter: 441 loss: 1.02639274e-06
Iter: 442 loss: 1.02558704e-06
Iter: 443 loss: 1.02498939e-06
Iter: 444 loss: 1.02473075e-06
Iter: 445 loss: 1.02438867e-06
Iter: 446 loss: 1.02411832e-06
Iter: 447 loss: 1.02360559e-06
Iter: 448 loss: 1.02274726e-06
Iter: 449 loss: 1.02272566e-06
Iter: 450 loss: 1.02169372e-06
Iter: 451 loss: 1.0245567e-06
Iter: 452 loss: 1.02141166e-06
Iter: 453 loss: 1.0201577e-06
Iter: 454 loss: 1.02682338e-06
Iter: 455 loss: 1.01999331e-06
Iter: 456 loss: 1.01925252e-06
Iter: 457 loss: 1.0185239e-06
Iter: 458 loss: 1.01834075e-06
Iter: 459 loss: 1.01733849e-06
Iter: 460 loss: 1.0196577e-06
Iter: 461 loss: 1.01700789e-06
Iter: 462 loss: 1.0156607e-06
Iter: 463 loss: 1.02671675e-06
Iter: 464 loss: 1.01557168e-06
Iter: 465 loss: 1.01455248e-06
Iter: 466 loss: 1.01465639e-06
Iter: 467 loss: 1.01375485e-06
Iter: 468 loss: 1.0130135e-06
Iter: 469 loss: 1.01304272e-06
Iter: 470 loss: 1.01239175e-06
Iter: 471 loss: 1.01180444e-06
Iter: 472 loss: 1.0118066e-06
Iter: 473 loss: 1.01121805e-06
Iter: 474 loss: 1.01057117e-06
Iter: 475 loss: 1.01048033e-06
Iter: 476 loss: 1.00963837e-06
Iter: 477 loss: 1.01129285e-06
Iter: 478 loss: 1.00931675e-06
Iter: 479 loss: 1.00854641e-06
Iter: 480 loss: 1.00856687e-06
Iter: 481 loss: 1.00806358e-06
Iter: 482 loss: 1.00721252e-06
Iter: 483 loss: 1.02844422e-06
Iter: 484 loss: 1.00720104e-06
Iter: 485 loss: 1.00653017e-06
Iter: 486 loss: 1.01394949e-06
Iter: 487 loss: 1.00647378e-06
Iter: 488 loss: 1.00557065e-06
Iter: 489 loss: 1.0040917e-06
Iter: 490 loss: 1.00410807e-06
Iter: 491 loss: 1.00303373e-06
Iter: 492 loss: 1.00869897e-06
Iter: 493 loss: 1.00285638e-06
Iter: 494 loss: 1.00215107e-06
Iter: 495 loss: 1.00803277e-06
Iter: 496 loss: 1.00213185e-06
Iter: 497 loss: 1.00130023e-06
Iter: 498 loss: 1.00239868e-06
Iter: 499 loss: 1.00092427e-06
Iter: 500 loss: 1.00040972e-06
Iter: 501 loss: 1.00047646e-06
Iter: 502 loss: 9.99959866e-07
Iter: 503 loss: 9.99380063e-07
Iter: 504 loss: 1.00313719e-06
Iter: 505 loss: 9.99337885e-07
Iter: 506 loss: 9.9874444e-07
Iter: 507 loss: 1.00075079e-06
Iter: 508 loss: 9.98615e-07
Iter: 509 loss: 9.98011728e-07
Iter: 510 loss: 9.97219558e-07
Iter: 511 loss: 9.97186703e-07
Iter: 512 loss: 9.96480935e-07
Iter: 513 loss: 1.00698458e-06
Iter: 514 loss: 9.96481e-07
Iter: 515 loss: 9.95635219e-07
Iter: 516 loss: 9.95821551e-07
Iter: 517 loss: 9.95037e-07
Iter: 518 loss: 9.94329412e-07
Iter: 519 loss: 9.93663889e-07
Iter: 520 loss: 9.93539516e-07
Iter: 521 loss: 9.92171e-07
Iter: 522 loss: 1.00654654e-06
Iter: 523 loss: 9.92163223e-07
Iter: 524 loss: 9.91421075e-07
Iter: 525 loss: 9.91692104e-07
Iter: 526 loss: 9.90885383e-07
Iter: 527 loss: 9.90276249e-07
Iter: 528 loss: 9.90897092e-07
Iter: 529 loss: 9.8993462e-07
Iter: 530 loss: 9.89488171e-07
Iter: 531 loss: 9.89424279e-07
Iter: 532 loss: 9.89117325e-07
Iter: 533 loss: 9.88565603e-07
Iter: 534 loss: 9.98261726e-07
Iter: 535 loss: 9.88569241e-07
Iter: 536 loss: 9.8804253e-07
Iter: 537 loss: 9.90601848e-07
Iter: 538 loss: 9.87919179e-07
Iter: 539 loss: 9.87350404e-07
Iter: 540 loss: 9.90713943e-07
Iter: 541 loss: 9.87258318e-07
Iter: 542 loss: 9.86654e-07
Iter: 543 loss: 9.86229e-07
Iter: 544 loss: 9.86036184e-07
Iter: 545 loss: 9.85281304e-07
Iter: 546 loss: 9.87211e-07
Iter: 547 loss: 9.85085e-07
Iter: 548 loss: 9.84328608e-07
Iter: 549 loss: 9.93209142e-07
Iter: 550 loss: 9.84333383e-07
Iter: 551 loss: 9.83743e-07
Iter: 552 loss: 9.82358e-07
Iter: 553 loss: 9.99513759e-07
Iter: 554 loss: 9.82246661e-07
Iter: 555 loss: 9.81318863e-07
Iter: 556 loss: 9.81342282e-07
Iter: 557 loss: 9.80677555e-07
Iter: 558 loss: 9.83691848e-07
Iter: 559 loss: 9.80554091e-07
Iter: 560 loss: 9.8011742e-07
Iter: 561 loss: 9.79118226e-07
Iter: 562 loss: 9.89870159e-07
Iter: 563 loss: 9.79003175e-07
Iter: 564 loss: 9.78815478e-07
Iter: 565 loss: 9.78519665e-07
Iter: 566 loss: 9.78016146e-07
Iter: 567 loss: 9.78808771e-07
Iter: 568 loss: 9.77774107e-07
Iter: 569 loss: 9.77378363e-07
Iter: 570 loss: 9.76600859e-07
Iter: 571 loss: 9.94383299e-07
Iter: 572 loss: 9.76618708e-07
Iter: 573 loss: 9.76084834e-07
Iter: 574 loss: 9.76091314e-07
Iter: 575 loss: 9.75477633e-07
Iter: 576 loss: 9.76061301e-07
Iter: 577 loss: 9.7514328e-07
Iter: 578 loss: 9.74688874e-07
Iter: 579 loss: 9.74752766e-07
Iter: 580 loss: 9.74252657e-07
Iter: 581 loss: 9.73755277e-07
Iter: 582 loss: 9.7984082e-07
Iter: 583 loss: 9.73742203e-07
Iter: 584 loss: 9.73114311e-07
Iter: 585 loss: 9.73049e-07
Iter: 586 loss: 9.72609882e-07
Iter: 587 loss: 9.71971531e-07
Iter: 588 loss: 9.71965e-07
Iter: 589 loss: 9.71446866e-07
Iter: 590 loss: 9.70894689e-07
Iter: 591 loss: 9.7087127e-07
Iter: 592 loss: 9.70449378e-07
Iter: 593 loss: 9.69301595e-07
Iter: 594 loss: 9.79818878e-07
Iter: 595 loss: 9.6915e-07
Iter: 596 loss: 9.68102086e-07
Iter: 597 loss: 9.8089879e-07
Iter: 598 loss: 9.68148925e-07
Iter: 599 loss: 9.67726578e-07
Iter: 600 loss: 9.676628e-07
Iter: 601 loss: 9.67431788e-07
Iter: 602 loss: 9.66685207e-07
Iter: 603 loss: 9.71368308e-07
Iter: 604 loss: 9.66495691e-07
Iter: 605 loss: 9.6579015e-07
Iter: 606 loss: 9.74554e-07
Iter: 607 loss: 9.65792879e-07
Iter: 608 loss: 9.65340632e-07
Iter: 609 loss: 9.70627752e-07
Iter: 610 loss: 9.65323238e-07
Iter: 611 loss: 9.65058916e-07
Iter: 612 loss: 9.64691708e-07
Iter: 613 loss: 9.64671e-07
Iter: 614 loss: 9.64166e-07
Iter: 615 loss: 9.66860853e-07
Iter: 616 loss: 9.64076889e-07
Iter: 617 loss: 9.63544e-07
Iter: 618 loss: 9.66784455e-07
Iter: 619 loss: 9.63475259e-07
Iter: 620 loss: 9.63193429e-07
Iter: 621 loss: 9.62787567e-07
Iter: 622 loss: 9.62744366e-07
Iter: 623 loss: 9.62191e-07
Iter: 624 loss: 9.65657e-07
Iter: 625 loss: 9.6215831e-07
Iter: 626 loss: 9.61559408e-07
Iter: 627 loss: 9.62701733e-07
Iter: 628 loss: 9.61343403e-07
Iter: 629 loss: 9.6086319e-07
Iter: 630 loss: 9.60716193e-07
Iter: 631 loss: 9.60454145e-07
Iter: 632 loss: 9.60149805e-07
Iter: 633 loss: 9.60115244e-07
Iter: 634 loss: 9.59716203e-07
Iter: 635 loss: 9.58940291e-07
Iter: 636 loss: 9.73462647e-07
Iter: 637 loss: 9.58931878e-07
Iter: 638 loss: 9.5832047e-07
Iter: 639 loss: 9.61174237e-07
Iter: 640 loss: 9.58194278e-07
Iter: 641 loss: 9.57892098e-07
Iter: 642 loss: 9.6289682e-07
Iter: 643 loss: 9.57895281e-07
Iter: 644 loss: 9.57519e-07
Iter: 645 loss: 9.57166321e-07
Iter: 646 loss: 9.5711664e-07
Iter: 647 loss: 9.56687245e-07
Iter: 648 loss: 9.58105943e-07
Iter: 649 loss: 9.5658811e-07
Iter: 650 loss: 9.56295366e-07
Iter: 651 loss: 9.56272288e-07
Iter: 652 loss: 9.56018e-07
Iter: 653 loss: 9.55484438e-07
Iter: 654 loss: 9.63700131e-07
Iter: 655 loss: 9.55438622e-07
Iter: 656 loss: 9.54728e-07
Iter: 657 loss: 9.5674784e-07
Iter: 658 loss: 9.54559823e-07
Iter: 659 loss: 9.53899871e-07
Iter: 660 loss: 9.61004275e-07
Iter: 661 loss: 9.53917e-07
Iter: 662 loss: 9.53444e-07
Iter: 663 loss: 9.52620439e-07
Iter: 664 loss: 9.52619416e-07
Iter: 665 loss: 9.51869652e-07
Iter: 666 loss: 9.60398324e-07
Iter: 667 loss: 9.51814343e-07
Iter: 668 loss: 9.51109485e-07
Iter: 669 loss: 9.55368e-07
Iter: 670 loss: 9.50997e-07
Iter: 671 loss: 9.50606136e-07
Iter: 672 loss: 9.49836362e-07
Iter: 673 loss: 9.66538892e-07
Iter: 674 loss: 9.49874789e-07
Iter: 675 loss: 9.49511332e-07
Iter: 676 loss: 9.4945409e-07
Iter: 677 loss: 9.49079379e-07
Iter: 678 loss: 9.50112394e-07
Iter: 679 loss: 9.49002356e-07
Iter: 680 loss: 9.48679144e-07
Iter: 681 loss: 9.48376112e-07
Iter: 682 loss: 9.48346496e-07
Iter: 683 loss: 9.47986564e-07
Iter: 684 loss: 9.4800663e-07
Iter: 685 loss: 9.47639592e-07
Iter: 686 loss: 9.47277556e-07
Iter: 687 loss: 9.47219746e-07
Iter: 688 loss: 9.46719e-07
Iter: 689 loss: 9.47359695e-07
Iter: 690 loss: 9.46419902e-07
Iter: 691 loss: 9.45865054e-07
Iter: 692 loss: 9.51316e-07
Iter: 693 loss: 9.45866532e-07
Iter: 694 loss: 9.45403e-07
Iter: 695 loss: 9.45378247e-07
Iter: 696 loss: 9.45048669e-07
Iter: 697 loss: 9.44538897e-07
Iter: 698 loss: 9.45671104e-07
Iter: 699 loss: 9.44342901e-07
Iter: 700 loss: 9.43867235e-07
Iter: 701 loss: 9.43875648e-07
Iter: 702 loss: 9.43604732e-07
Iter: 703 loss: 9.43044768e-07
Iter: 704 loss: 9.53402832e-07
Iter: 705 loss: 9.43070802e-07
Iter: 706 loss: 9.42527151e-07
Iter: 707 loss: 9.44177771e-07
Iter: 708 loss: 9.42384645e-07
Iter: 709 loss: 9.42028919e-07
Iter: 710 loss: 9.42041709e-07
Iter: 711 loss: 9.41717872e-07
Iter: 712 loss: 9.41154e-07
Iter: 713 loss: 9.53929884e-07
Iter: 714 loss: 9.41128633e-07
Iter: 715 loss: 9.40638358e-07
Iter: 716 loss: 9.4484335e-07
Iter: 717 loss: 9.40621e-07
Iter: 718 loss: 9.40063273e-07
Iter: 719 loss: 9.41104531e-07
Iter: 720 loss: 9.39805091e-07
Iter: 721 loss: 9.39378481e-07
Iter: 722 loss: 9.39985114e-07
Iter: 723 loss: 9.39166398e-07
Iter: 724 loss: 9.38883773e-07
Iter: 725 loss: 9.40856e-07
Iter: 726 loss: 9.38853361e-07
Iter: 727 loss: 9.384745e-07
Iter: 728 loss: 9.38312496e-07
Iter: 729 loss: 9.38115761e-07
Iter: 730 loss: 9.37715754e-07
Iter: 731 loss: 9.39886377e-07
Iter: 732 loss: 9.37629466e-07
Iter: 733 loss: 9.37395157e-07
Iter: 734 loss: 9.4093059e-07
Iter: 735 loss: 9.37392599e-07
Iter: 736 loss: 9.37163918e-07
Iter: 737 loss: 9.3677852e-07
Iter: 738 loss: 9.46464411e-07
Iter: 739 loss: 9.3677761e-07
Iter: 740 loss: 9.36318258e-07
Iter: 741 loss: 9.3638306e-07
Iter: 742 loss: 9.35955654e-07
Iter: 743 loss: 9.35658591e-07
Iter: 744 loss: 9.35615446e-07
Iter: 745 loss: 9.35250227e-07
Iter: 746 loss: 9.34713967e-07
Iter: 747 loss: 9.34691514e-07
Iter: 748 loss: 9.34058903e-07
Iter: 749 loss: 9.35927687e-07
Iter: 750 loss: 9.33895876e-07
Iter: 751 loss: 9.33450167e-07
Iter: 752 loss: 9.33450906e-07
Iter: 753 loss: 9.3323365e-07
Iter: 754 loss: 9.32893045e-07
Iter: 755 loss: 9.32897706e-07
Iter: 756 loss: 9.32499574e-07
Iter: 757 loss: 9.34887453e-07
Iter: 758 loss: 9.32474563e-07
Iter: 759 loss: 9.32143053e-07
Iter: 760 loss: 9.33249e-07
Iter: 761 loss: 9.32022544e-07
Iter: 762 loss: 9.31681598e-07
Iter: 763 loss: 9.31894476e-07
Iter: 764 loss: 9.31491741e-07
Iter: 765 loss: 9.31196098e-07
Iter: 766 loss: 9.3465178e-07
Iter: 767 loss: 9.31225827e-07
Iter: 768 loss: 9.30929332e-07
Iter: 769 loss: 9.30679789e-07
Iter: 770 loss: 9.30588158e-07
Iter: 771 loss: 9.30209239e-07
Iter: 772 loss: 9.30351405e-07
Iter: 773 loss: 9.2988455e-07
Iter: 774 loss: 9.29405303e-07
Iter: 775 loss: 9.3137163e-07
Iter: 776 loss: 9.29282351e-07
Iter: 777 loss: 9.28695385e-07
Iter: 778 loss: 9.32123271e-07
Iter: 779 loss: 9.28608301e-07
Iter: 780 loss: 9.28287307e-07
Iter: 781 loss: 9.27811527e-07
Iter: 782 loss: 9.27795782e-07
Iter: 783 loss: 9.27502185e-07
Iter: 784 loss: 9.27467568e-07
Iter: 785 loss: 9.2718625e-07
Iter: 786 loss: 9.26789141e-07
Iter: 787 loss: 9.26773339e-07
Iter: 788 loss: 9.26396638e-07
Iter: 789 loss: 9.27350243e-07
Iter: 790 loss: 9.26195298e-07
Iter: 791 loss: 9.25789e-07
Iter: 792 loss: 9.29423e-07
Iter: 793 loss: 9.25775e-07
Iter: 794 loss: 9.25521931e-07
Iter: 795 loss: 9.25487882e-07
Iter: 796 loss: 9.25199856e-07
Iter: 797 loss: 9.24955486e-07
Iter: 798 loss: 9.27573637e-07
Iter: 799 loss: 9.24968731e-07
Iter: 800 loss: 9.24689743e-07
Iter: 801 loss: 9.2511732e-07
Iter: 802 loss: 9.24531037e-07
Iter: 803 loss: 9.24220217e-07
Iter: 804 loss: 9.23791276e-07
Iter: 805 loss: 9.23792584e-07
Iter: 806 loss: 9.23308733e-07
Iter: 807 loss: 9.25683139e-07
Iter: 808 loss: 9.23208802e-07
Iter: 809 loss: 9.22723814e-07
Iter: 810 loss: 9.27211318e-07
Iter: 811 loss: 9.22704373e-07
Iter: 812 loss: 9.22329377e-07
Iter: 813 loss: 9.21881281e-07
Iter: 814 loss: 9.21830519e-07
Iter: 815 loss: 9.21548235e-07
Iter: 816 loss: 9.21545961e-07
Iter: 817 loss: 9.21241792e-07
Iter: 818 loss: 9.21324954e-07
Iter: 819 loss: 9.21048354e-07
Iter: 820 loss: 9.20748505e-07
Iter: 821 loss: 9.20550576e-07
Iter: 822 loss: 9.20452578e-07
Iter: 823 loss: 9.20044727e-07
Iter: 824 loss: 9.25737311e-07
Iter: 825 loss: 9.20068715e-07
Iter: 826 loss: 9.197704e-07
Iter: 827 loss: 9.20051946e-07
Iter: 828 loss: 9.19657509e-07
Iter: 829 loss: 9.1938e-07
Iter: 830 loss: 9.2000073e-07
Iter: 831 loss: 9.19283934e-07
Iter: 832 loss: 9.18990281e-07
Iter: 833 loss: 9.19877209e-07
Iter: 834 loss: 9.18856813e-07
Iter: 835 loss: 9.18587e-07
Iter: 836 loss: 9.18387627e-07
Iter: 837 loss: 9.1832635e-07
Iter: 838 loss: 9.17868647e-07
Iter: 839 loss: 9.18326066e-07
Iter: 840 loss: 9.17668672e-07
Iter: 841 loss: 9.17360353e-07
Iter: 842 loss: 9.17325963e-07
Iter: 843 loss: 9.16983254e-07
Iter: 844 loss: 9.16647764e-07
Iter: 845 loss: 9.16612521e-07
Iter: 846 loss: 9.1632478e-07
Iter: 847 loss: 9.19262391e-07
Iter: 848 loss: 9.16293516e-07
Iter: 849 loss: 9.15967121e-07
Iter: 850 loss: 9.1650179e-07
Iter: 851 loss: 9.15813416e-07
Iter: 852 loss: 9.1553494e-07
Iter: 853 loss: 9.15252656e-07
Iter: 854 loss: 9.15170233e-07
Iter: 855 loss: 9.14855036e-07
Iter: 856 loss: 9.14865609e-07
Iter: 857 loss: 9.14627435e-07
Iter: 858 loss: 9.14531881e-07
Iter: 859 loss: 9.14381303e-07
Iter: 860 loss: 9.14087195e-07
Iter: 861 loss: 9.1601737e-07
Iter: 862 loss: 9.14052e-07
Iter: 863 loss: 9.13789734e-07
Iter: 864 loss: 9.14652e-07
Iter: 865 loss: 9.1375523e-07
Iter: 866 loss: 9.13491817e-07
Iter: 867 loss: 9.13210783e-07
Iter: 868 loss: 9.13183328e-07
Iter: 869 loss: 9.12662813e-07
Iter: 870 loss: 9.12707208e-07
Iter: 871 loss: 9.12299129e-07
Iter: 872 loss: 9.11932716e-07
Iter: 873 loss: 9.11894574e-07
Iter: 874 loss: 9.11543907e-07
Iter: 875 loss: 9.12037422e-07
Iter: 876 loss: 9.11384291e-07
Iter: 877 loss: 9.11033112e-07
Iter: 878 loss: 9.10977406e-07
Iter: 879 loss: 9.10751623e-07
Iter: 880 loss: 9.10312849e-07
Iter: 881 loss: 9.16712224e-07
Iter: 882 loss: 9.10281756e-07
Iter: 883 loss: 9.10056656e-07
Iter: 884 loss: 9.09580081e-07
Iter: 885 loss: 9.09552227e-07
Iter: 886 loss: 9.09160292e-07
Iter: 887 loss: 9.14292059e-07
Iter: 888 loss: 9.09153755e-07
Iter: 889 loss: 9.08834522e-07
Iter: 890 loss: 9.09784944e-07
Iter: 891 loss: 9.0870509e-07
Iter: 892 loss: 9.08421498e-07
Iter: 893 loss: 9.08634206e-07
Iter: 894 loss: 9.08260063e-07
Iter: 895 loss: 9.07879439e-07
Iter: 896 loss: 9.10921699e-07
Iter: 897 loss: 9.07858464e-07
Iter: 898 loss: 9.07625349e-07
Iter: 899 loss: 9.07433446e-07
Iter: 900 loss: 9.07362505e-07
Iter: 901 loss: 9.06932939e-07
Iter: 902 loss: 9.07093863e-07
Iter: 903 loss: 9.06724722e-07
Iter: 904 loss: 9.06296464e-07
Iter: 905 loss: 9.08869822e-07
Iter: 906 loss: 9.06225068e-07
Iter: 907 loss: 9.05815909e-07
Iter: 908 loss: 9.08894776e-07
Iter: 909 loss: 9.05776062e-07
Iter: 910 loss: 9.05591264e-07
Iter: 911 loss: 9.05437446e-07
Iter: 912 loss: 9.05366e-07
Iter: 913 loss: 9.05052786e-07
Iter: 914 loss: 9.08966399e-07
Iter: 915 loss: 9.05055e-07
Iter: 916 loss: 9.04772435e-07
Iter: 917 loss: 9.04197577e-07
Iter: 918 loss: 9.13207259e-07
Iter: 919 loss: 9.04218268e-07
Iter: 920 loss: 9.03824684e-07
Iter: 921 loss: 9.09033702e-07
Iter: 922 loss: 9.03822922e-07
Iter: 923 loss: 9.03515797e-07
Iter: 924 loss: 9.04746116e-07
Iter: 925 loss: 9.03476234e-07
Iter: 926 loss: 9.03145065e-07
Iter: 927 loss: 9.03054399e-07
Iter: 928 loss: 9.02879833e-07
Iter: 929 loss: 9.02510578e-07
Iter: 930 loss: 9.07155197e-07
Iter: 931 loss: 9.02498755e-07
Iter: 932 loss: 9.02225167e-07
Iter: 933 loss: 9.02230227e-07
Iter: 934 loss: 9.0204469e-07
Iter: 935 loss: 9.01759677e-07
Iter: 936 loss: 9.01737849e-07
Iter: 937 loss: 9.01460339e-07
Iter: 938 loss: 9.01070166e-07
Iter: 939 loss: 9.02509498e-07
Iter: 940 loss: 9.00952841e-07
Iter: 941 loss: 9.00686473e-07
Iter: 942 loss: 9.00631562e-07
Iter: 943 loss: 9.00473594e-07
Iter: 944 loss: 9.00085e-07
Iter: 945 loss: 9.05989509e-07
Iter: 946 loss: 9.00071143e-07
Iter: 947 loss: 8.99840813e-07
Iter: 948 loss: 8.99837119e-07
Iter: 949 loss: 8.9954824e-07
Iter: 950 loss: 8.9942e-07
Iter: 951 loss: 8.99280735e-07
Iter: 952 loss: 8.9898225e-07
Iter: 953 loss: 8.98920689e-07
Iter: 954 loss: 8.98708095e-07
Iter: 955 loss: 8.98283645e-07
Iter: 956 loss: 9.03774094e-07
Iter: 957 loss: 8.98318262e-07
Iter: 958 loss: 8.97947359e-07
Iter: 959 loss: 8.97701966e-07
Iter: 960 loss: 8.97544908e-07
Iter: 961 loss: 8.97094822e-07
Iter: 962 loss: 9.02243e-07
Iter: 963 loss: 8.97063671e-07
Iter: 964 loss: 8.96791676e-07
Iter: 965 loss: 8.9686e-07
Iter: 966 loss: 8.96583629e-07
Iter: 967 loss: 8.96131155e-07
Iter: 968 loss: 8.95972903e-07
Iter: 969 loss: 8.95799644e-07
Iter: 970 loss: 8.95278447e-07
Iter: 971 loss: 8.97785924e-07
Iter: 972 loss: 8.95247354e-07
Iter: 973 loss: 8.94965865e-07
Iter: 974 loss: 8.94953814e-07
Iter: 975 loss: 8.94705124e-07
Iter: 976 loss: 8.94384129e-07
Iter: 977 loss: 8.9432956e-07
Iter: 978 loss: 8.93980882e-07
Iter: 979 loss: 8.95218477e-07
Iter: 980 loss: 8.9390835e-07
Iter: 981 loss: 8.93538072e-07
Iter: 982 loss: 8.97436735e-07
Iter: 983 loss: 8.93588549e-07
Iter: 984 loss: 8.9337459e-07
Iter: 985 loss: 8.92949856e-07
Iter: 986 loss: 8.98652502e-07
Iter: 987 loss: 8.92893809e-07
Iter: 988 loss: 8.92511594e-07
Iter: 989 loss: 8.92542118e-07
Iter: 990 loss: 8.92198727e-07
Iter: 991 loss: 8.92924618e-07
Iter: 992 loss: 8.92081971e-07
Iter: 993 loss: 8.9182231e-07
Iter: 994 loss: 8.93299671e-07
Iter: 995 loss: 8.91803893e-07
Iter: 996 loss: 8.91587945e-07
Iter: 997 loss: 8.91991306e-07
Iter: 998 loss: 8.91493755e-07
Iter: 999 loss: 8.91291904e-07
Iter: 1000 loss: 8.91209424e-07
Iter: 1001 loss: 8.91110403e-07
Iter: 1002 loss: 8.9080055e-07
Iter: 1003 loss: 8.90860179e-07
Iter: 1004 loss: 8.90588524e-07
Iter: 1005 loss: 8.90295667e-07
Iter: 1006 loss: 8.93461959e-07
Iter: 1007 loss: 8.90281115e-07
Iter: 1008 loss: 8.9000639e-07
Iter: 1009 loss: 8.90849776e-07
Iter: 1010 loss: 8.89937e-07
Iter: 1011 loss: 8.89651176e-07
Iter: 1012 loss: 8.89369574e-07
Iter: 1013 loss: 8.89347064e-07
Iter: 1014 loss: 8.89155e-07
Iter: 1015 loss: 8.89127421e-07
Iter: 1016 loss: 8.88932e-07
Iter: 1017 loss: 8.88585873e-07
Iter: 1018 loss: 8.9602753e-07
Iter: 1019 loss: 8.8853858e-07
Iter: 1020 loss: 8.88152385e-07
Iter: 1021 loss: 8.89399473e-07
Iter: 1022 loss: 8.88062857e-07
Iter: 1023 loss: 8.87788474e-07
Iter: 1024 loss: 8.87766305e-07
Iter: 1025 loss: 8.87598446e-07
Iter: 1026 loss: 8.87754766e-07
Iter: 1027 loss: 8.87503688e-07
Iter: 1028 loss: 8.87304452e-07
Iter: 1029 loss: 8.89070634e-07
Iter: 1030 loss: 8.87320539e-07
Iter: 1031 loss: 8.8716763e-07
Iter: 1032 loss: 8.86794851e-07
Iter: 1033 loss: 8.90662818e-07
Iter: 1034 loss: 8.86741418e-07
Iter: 1035 loss: 8.86374551e-07
Iter: 1036 loss: 8.88612362e-07
Iter: 1037 loss: 8.86243299e-07
Iter: 1038 loss: 8.85908491e-07
Iter: 1039 loss: 8.86065e-07
Iter: 1040 loss: 8.85651673e-07
Iter: 1041 loss: 8.85330792e-07
Iter: 1042 loss: 8.85291911e-07
Iter: 1043 loss: 8.85079885e-07
Iter: 1044 loss: 8.8495284e-07
Iter: 1045 loss: 8.84883207e-07
Iter: 1046 loss: 8.84589156e-07
Iter: 1047 loss: 8.85441295e-07
Iter: 1048 loss: 8.84572501e-07
Iter: 1049 loss: 8.84242752e-07
Iter: 1050 loss: 8.85483587e-07
Iter: 1051 loss: 8.84187045e-07
Iter: 1052 loss: 8.8390459e-07
Iter: 1053 loss: 8.83654934e-07
Iter: 1054 loss: 8.8362367e-07
Iter: 1055 loss: 8.8347889e-07
Iter: 1056 loss: 8.83470136e-07
Iter: 1057 loss: 8.833415e-07
Iter: 1058 loss: 8.8305103e-07
Iter: 1059 loss: 8.87302065e-07
Iter: 1060 loss: 8.83056089e-07
Iter: 1061 loss: 8.8275e-07
Iter: 1062 loss: 8.87283306e-07
Iter: 1063 loss: 8.82778522e-07
Iter: 1064 loss: 8.82499137e-07
Iter: 1065 loss: 8.82620725e-07
Iter: 1066 loss: 8.82328152e-07
Iter: 1067 loss: 8.82101176e-07
Iter: 1068 loss: 8.81981293e-07
Iter: 1069 loss: 8.81922517e-07
Iter: 1070 loss: 8.81543428e-07
Iter: 1071 loss: 8.82219069e-07
Iter: 1072 loss: 8.81398876e-07
Iter: 1073 loss: 8.81027063e-07
Iter: 1074 loss: 8.81765061e-07
Iter: 1075 loss: 8.80836467e-07
Iter: 1076 loss: 8.80610855e-07
Iter: 1077 loss: 8.80633706e-07
Iter: 1078 loss: 8.80343862e-07
Iter: 1079 loss: 8.80686628e-07
Iter: 1080 loss: 8.80312371e-07
Iter: 1081 loss: 8.80167306e-07
Iter: 1082 loss: 8.80623531e-07
Iter: 1083 loss: 8.80129505e-07
Iter: 1084 loss: 8.79892127e-07
Iter: 1085 loss: 8.80653658e-07
Iter: 1086 loss: 8.79881895e-07
Iter: 1087 loss: 8.79722506e-07
Iter: 1088 loss: 8.79479217e-07
Iter: 1089 loss: 8.79473646e-07
Iter: 1090 loss: 8.79259233e-07
Iter: 1091 loss: 8.79250194e-07
Iter: 1092 loss: 8.79038794e-07
Iter: 1093 loss: 8.78769413e-07
Iter: 1094 loss: 8.78740821e-07
Iter: 1095 loss: 8.78557501e-07
Iter: 1096 loss: 8.78549372e-07
Iter: 1097 loss: 8.78330127e-07
Iter: 1098 loss: 8.78000947e-07
Iter: 1099 loss: 8.78006631e-07
Iter: 1100 loss: 8.77732e-07
Iter: 1101 loss: 8.78414255e-07
Iter: 1102 loss: 8.77585137e-07
Iter: 1103 loss: 8.77308764e-07
Iter: 1104 loss: 8.77907041e-07
Iter: 1105 loss: 8.7710805e-07
Iter: 1106 loss: 8.76830427e-07
Iter: 1107 loss: 8.78704611e-07
Iter: 1108 loss: 8.76791773e-07
Iter: 1109 loss: 8.76584409e-07
Iter: 1110 loss: 8.78153571e-07
Iter: 1111 loss: 8.76575029e-07
Iter: 1112 loss: 8.76321451e-07
Iter: 1113 loss: 8.76160243e-07
Iter: 1114 loss: 8.76078957e-07
Iter: 1115 loss: 8.75869432e-07
Iter: 1116 loss: 8.75850276e-07
Iter: 1117 loss: 8.75737555e-07
Iter: 1118 loss: 8.75521323e-07
Iter: 1119 loss: 8.75503247e-07
Iter: 1120 loss: 8.75247963e-07
Iter: 1121 loss: 8.7590837e-07
Iter: 1122 loss: 8.7513115e-07
Iter: 1123 loss: 8.74901673e-07
Iter: 1124 loss: 8.7738249e-07
Iter: 1125 loss: 8.74857278e-07
Iter: 1126 loss: 8.74732e-07
Iter: 1127 loss: 8.74893772e-07
Iter: 1128 loss: 8.74627347e-07
Iter: 1129 loss: 8.74460795e-07
Iter: 1130 loss: 8.75480964e-07
Iter: 1131 loss: 8.74421971e-07
Iter: 1132 loss: 8.74291572e-07
Iter: 1133 loss: 8.7394352e-07
Iter: 1134 loss: 8.78442336e-07
Iter: 1135 loss: 8.738578e-07
Iter: 1136 loss: 8.73646798e-07
Iter: 1137 loss: 8.77089633e-07
Iter: 1138 loss: 8.73588e-07
Iter: 1139 loss: 8.73434033e-07
Iter: 1140 loss: 8.73410556e-07
Iter: 1141 loss: 8.73260262e-07
Iter: 1142 loss: 8.72952853e-07
Iter: 1143 loss: 8.7522892e-07
Iter: 1144 loss: 8.7293688e-07
Iter: 1145 loss: 8.72765554e-07
Iter: 1146 loss: 8.75365117e-07
Iter: 1147 loss: 8.7279318e-07
Iter: 1148 loss: 8.72628107e-07
Iter: 1149 loss: 8.72658575e-07
Iter: 1150 loss: 8.7254e-07
Iter: 1151 loss: 8.72332691e-07
Iter: 1152 loss: 8.72836381e-07
Iter: 1153 loss: 8.72274427e-07
Iter: 1154 loss: 8.72050521e-07
Iter: 1155 loss: 8.71794271e-07
Iter: 1156 loss: 8.71811039e-07
Iter: 1157 loss: 8.71619079e-07
Iter: 1158 loss: 8.71595716e-07
Iter: 1159 loss: 8.71462589e-07
Iter: 1160 loss: 8.71229417e-07
Iter: 1161 loss: 8.71284215e-07
Iter: 1162 loss: 8.71050474e-07
Iter: 1163 loss: 8.73692159e-07
Iter: 1164 loss: 8.71031943e-07
Iter: 1165 loss: 8.70766826e-07
Iter: 1166 loss: 8.70680822e-07
Iter: 1167 loss: 8.7057731e-07
Iter: 1168 loss: 8.70371e-07
Iter: 1169 loss: 8.70569e-07
Iter: 1170 loss: 8.70237614e-07
Iter: 1171 loss: 8.69946859e-07
Iter: 1172 loss: 8.70279905e-07
Iter: 1173 loss: 8.69799123e-07
Iter: 1174 loss: 8.69442e-07
Iter: 1175 loss: 8.73081262e-07
Iter: 1176 loss: 8.6941867e-07
Iter: 1177 loss: 8.69229e-07
Iter: 1178 loss: 8.70458734e-07
Iter: 1179 loss: 8.69220401e-07
Iter: 1180 loss: 8.68984444e-07
Iter: 1181 loss: 8.6894886e-07
Iter: 1182 loss: 8.68814823e-07
Iter: 1183 loss: 8.68489337e-07
Iter: 1184 loss: 8.71223733e-07
Iter: 1185 loss: 8.68497068e-07
Iter: 1186 loss: 8.68294478e-07
Iter: 1187 loss: 8.6824e-07
Iter: 1188 loss: 8.68113318e-07
Iter: 1189 loss: 8.67941e-07
Iter: 1190 loss: 8.68729444e-07
Iter: 1191 loss: 8.67887e-07
Iter: 1192 loss: 8.67626738e-07
Iter: 1193 loss: 8.6806142e-07
Iter: 1194 loss: 8.67544884e-07
Iter: 1195 loss: 8.67391236e-07
Iter: 1196 loss: 8.67943584e-07
Iter: 1197 loss: 8.67337e-07
Iter: 1198 loss: 8.67182223e-07
Iter: 1199 loss: 8.68135089e-07
Iter: 1200 loss: 8.67152949e-07
Iter: 1201 loss: 8.67050574e-07
Iter: 1202 loss: 8.66838832e-07
Iter: 1203 loss: 8.70686506e-07
Iter: 1204 loss: 8.66818823e-07
Iter: 1205 loss: 8.66552853e-07
Iter: 1206 loss: 8.66974688e-07
Iter: 1207 loss: 8.6641603e-07
Iter: 1208 loss: 8.66096229e-07
Iter: 1209 loss: 8.67655e-07
Iter: 1210 loss: 8.66067865e-07
Iter: 1211 loss: 8.65735046e-07
Iter: 1212 loss: 8.68097914e-07
Iter: 1213 loss: 8.65726065e-07
Iter: 1214 loss: 8.65486413e-07
Iter: 1215 loss: 8.66121525e-07
Iter: 1216 loss: 8.65380287e-07
Iter: 1217 loss: 8.65217544e-07
Iter: 1218 loss: 8.66614812e-07
Iter: 1219 loss: 8.65178095e-07
Iter: 1220 loss: 8.65063157e-07
Iter: 1221 loss: 8.65067136e-07
Iter: 1222 loss: 8.64940944e-07
Iter: 1223 loss: 8.64717833e-07
Iter: 1224 loss: 8.6456555e-07
Iter: 1225 loss: 8.64472611e-07
Iter: 1226 loss: 8.64305775e-07
Iter: 1227 loss: 8.6426013e-07
Iter: 1228 loss: 8.64116487e-07
Iter: 1229 loss: 8.64029971e-07
Iter: 1230 loss: 8.63932314e-07
Iter: 1231 loss: 8.63875471e-07
Iter: 1232 loss: 8.6384847e-07
Iter: 1233 loss: 8.63711421e-07
Iter: 1234 loss: 8.63448e-07
Iter: 1235 loss: 8.69115127e-07
Iter: 1236 loss: 8.63459206e-07
Iter: 1237 loss: 8.63184937e-07
Iter: 1238 loss: 8.63759283e-07
Iter: 1239 loss: 8.63104901e-07
Iter: 1240 loss: 8.62894467e-07
Iter: 1241 loss: 8.63063235e-07
Iter: 1242 loss: 8.6271325e-07
Iter: 1243 loss: 8.62459899e-07
Iter: 1244 loss: 8.64999834e-07
Iter: 1245 loss: 8.62482068e-07
Iter: 1246 loss: 8.62272032e-07
Iter: 1247 loss: 8.63956e-07
Iter: 1248 loss: 8.62285219e-07
Iter: 1249 loss: 8.62107186e-07
Iter: 1250 loss: 8.62157833e-07
Iter: 1251 loss: 8.6204841e-07
Iter: 1252 loss: 8.61842e-07
Iter: 1253 loss: 8.62837112e-07
Iter: 1254 loss: 8.61808871e-07
Iter: 1255 loss: 8.61629701e-07
Iter: 1256 loss: 8.61440355e-07
Iter: 1257 loss: 8.61448711e-07
Iter: 1258 loss: 8.61221963e-07
Iter: 1259 loss: 8.63409809e-07
Iter: 1260 loss: 8.61152444e-07
Iter: 1261 loss: 8.6092723e-07
Iter: 1262 loss: 8.61304e-07
Iter: 1263 loss: 8.60848047e-07
Iter: 1264 loss: 8.60676494e-07
Iter: 1265 loss: 8.60999592e-07
Iter: 1266 loss: 8.60639261e-07
Iter: 1267 loss: 8.6038051e-07
Iter: 1268 loss: 8.61790568e-07
Iter: 1269 loss: 8.60332875e-07
Iter: 1270 loss: 8.60222315e-07
Iter: 1271 loss: 8.60058265e-07
Iter: 1272 loss: 8.60044679e-07
Iter: 1273 loss: 8.59847148e-07
Iter: 1274 loss: 8.60198611e-07
Iter: 1275 loss: 8.59762224e-07
Iter: 1276 loss: 8.59476927e-07
Iter: 1277 loss: 8.60371074e-07
Iter: 1278 loss: 8.59437307e-07
Iter: 1279 loss: 8.59270301e-07
Iter: 1280 loss: 8.62148227e-07
Iter: 1281 loss: 8.5928815e-07
Iter: 1282 loss: 8.59115062e-07
Iter: 1283 loss: 8.59320039e-07
Iter: 1284 loss: 8.5906936e-07
Iter: 1285 loss: 8.58884334e-07
Iter: 1286 loss: 8.59582258e-07
Iter: 1287 loss: 8.58849262e-07
Iter: 1288 loss: 8.58707494e-07
Iter: 1289 loss: 8.58629903e-07
Iter: 1290 loss: 8.58586418e-07
Iter: 1291 loss: 8.58390138e-07
Iter: 1292 loss: 8.5887541e-07
Iter: 1293 loss: 8.58337614e-07
Iter: 1294 loss: 8.58197382e-07
Iter: 1295 loss: 8.60445311e-07
Iter: 1296 loss: 8.58182318e-07
Iter: 1297 loss: 8.58082558e-07
Iter: 1298 loss: 8.57813802e-07
Iter: 1299 loss: 8.62412548e-07
Iter: 1300 loss: 8.5783563e-07
Iter: 1301 loss: 8.57671751e-07
Iter: 1302 loss: 8.57653731e-07
Iter: 1303 loss: 8.5752356e-07
Iter: 1304 loss: 8.57445798e-07
Iter: 1305 loss: 8.57364739e-07
Iter: 1306 loss: 8.57191594e-07
Iter: 1307 loss: 8.57031409e-07
Iter: 1308 loss: 8.56995257e-07
Iter: 1309 loss: 8.56682789e-07
Iter: 1310 loss: 8.58073236e-07
Iter: 1311 loss: 8.56618669e-07
Iter: 1312 loss: 8.56459167e-07
Iter: 1313 loss: 8.56468318e-07
Iter: 1314 loss: 8.56332633e-07
Iter: 1315 loss: 8.56319105e-07
Iter: 1316 loss: 8.56243048e-07
Iter: 1317 loss: 8.56036309e-07
Iter: 1318 loss: 8.56696943e-07
Iter: 1319 loss: 8.55985036e-07
Iter: 1320 loss: 8.55806945e-07
Iter: 1321 loss: 8.56202348e-07
Iter: 1322 loss: 8.55721055e-07
Iter: 1323 loss: 8.55604583e-07
Iter: 1324 loss: 8.55637666e-07
Iter: 1325 loss: 8.55507494e-07
Iter: 1326 loss: 8.55326334e-07
Iter: 1327 loss: 8.5612794e-07
Iter: 1328 loss: 8.55312919e-07
Iter: 1329 loss: 8.55082192e-07
Iter: 1330 loss: 8.55061501e-07
Iter: 1331 loss: 8.5491348e-07
Iter: 1332 loss: 8.54696964e-07
Iter: 1333 loss: 8.56053816e-07
Iter: 1334 loss: 8.5466678e-07
Iter: 1335 loss: 8.54555367e-07
Iter: 1336 loss: 8.55393921e-07
Iter: 1337 loss: 8.54492782e-07
Iter: 1338 loss: 8.5436011e-07
Iter: 1339 loss: 8.53997733e-07
Iter: 1340 loss: 8.57287489e-07
Iter: 1341 loss: 8.54007908e-07
Iter: 1342 loss: 8.53675431e-07
Iter: 1343 loss: 8.56250438e-07
Iter: 1344 loss: 8.53662243e-07
Iter: 1345 loss: 8.53530651e-07
Iter: 1346 loss: 8.55396422e-07
Iter: 1347 loss: 8.53541565e-07
Iter: 1348 loss: 8.53448284e-07
Iter: 1349 loss: 8.54049063e-07
Iter: 1350 loss: 8.5343197e-07
Iter: 1351 loss: 8.53344091e-07
Iter: 1352 loss: 8.5329043e-07
Iter: 1353 loss: 8.53251436e-07
Iter: 1354 loss: 8.53099209e-07
Iter: 1355 loss: 8.54101131e-07
Iter: 1356 loss: 8.53062147e-07
Iter: 1357 loss: 8.52980236e-07
Iter: 1358 loss: 8.52864e-07
Iter: 1359 loss: 8.52881612e-07
Iter: 1360 loss: 8.52643666e-07
Iter: 1361 loss: 8.5289571e-07
Iter: 1362 loss: 8.52540097e-07
Iter: 1363 loss: 8.52358369e-07
Iter: 1364 loss: 8.54521886e-07
Iter: 1365 loss: 8.52322728e-07
Iter: 1366 loss: 8.52210292e-07
Iter: 1367 loss: 8.52266453e-07
Iter: 1368 loss: 8.52110929e-07
Iter: 1369 loss: 8.51965808e-07
Iter: 1370 loss: 8.53330221e-07
Iter: 1371 loss: 8.51947561e-07
Iter: 1372 loss: 8.51765151e-07
Iter: 1373 loss: 8.51533116e-07
Iter: 1374 loss: 8.57998202e-07
Iter: 1375 loss: 8.51519872e-07
Iter: 1376 loss: 8.51297671e-07
Iter: 1377 loss: 8.52592052e-07
Iter: 1378 loss: 8.51246909e-07
Iter: 1379 loss: 8.511293e-07
Iter: 1380 loss: 8.51275445e-07
Iter: 1381 loss: 8.51001118e-07
Iter: 1382 loss: 8.5084514e-07
Iter: 1383 loss: 8.53118422e-07
Iter: 1384 loss: 8.50837694e-07
Iter: 1385 loss: 8.50721733e-07
Iter: 1386 loss: 8.50782214e-07
Iter: 1387 loss: 8.50597303e-07
Iter: 1388 loss: 8.50464801e-07
Iter: 1389 loss: 8.51796e-07
Iter: 1390 loss: 8.50449055e-07
Iter: 1391 loss: 8.50347e-07
Iter: 1392 loss: 8.50117317e-07
Iter: 1393 loss: 8.50130164e-07
Iter: 1394 loss: 8.49834e-07
Iter: 1395 loss: 8.50142385e-07
Iter: 1396 loss: 8.49707476e-07
Iter: 1397 loss: 8.4946754e-07
Iter: 1398 loss: 8.53388258e-07
Iter: 1399 loss: 8.49465323e-07
Iter: 1400 loss: 8.49297749e-07
Iter: 1401 loss: 8.4948806e-07
Iter: 1402 loss: 8.49171101e-07
Iter: 1403 loss: 8.48989487e-07
Iter: 1404 loss: 8.50202127e-07
Iter: 1405 loss: 8.48980562e-07
Iter: 1406 loss: 8.4886068e-07
Iter: 1407 loss: 8.4900006e-07
Iter: 1408 loss: 8.48785e-07
Iter: 1409 loss: 8.48647858e-07
Iter: 1410 loss: 8.48470336e-07
Iter: 1411 loss: 8.48409229e-07
Iter: 1412 loss: 8.4819078e-07
Iter: 1413 loss: 8.48861134e-07
Iter: 1414 loss: 8.48131151e-07
Iter: 1415 loss: 8.47936235e-07
Iter: 1416 loss: 8.50226456e-07
Iter: 1417 loss: 8.47938338e-07
Iter: 1418 loss: 8.47759509e-07
Iter: 1419 loss: 8.48178161e-07
Iter: 1420 loss: 8.47659578e-07
Iter: 1421 loss: 8.47519857e-07
Iter: 1422 loss: 8.48085961e-07
Iter: 1423 loss: 8.47508488e-07
Iter: 1424 loss: 8.47317551e-07
Iter: 1425 loss: 8.47773322e-07
Iter: 1426 loss: 8.47253659e-07
Iter: 1427 loss: 8.47116439e-07
Iter: 1428 loss: 8.46943408e-07
Iter: 1429 loss: 8.46909302e-07
Iter: 1430 loss: 8.46710122e-07
Iter: 1431 loss: 8.48476532e-07
Iter: 1432 loss: 8.46670957e-07
Iter: 1433 loss: 8.46513e-07
Iter: 1434 loss: 8.47453919e-07
Iter: 1435 loss: 8.46444436e-07
Iter: 1436 loss: 8.46332e-07
Iter: 1437 loss: 8.46526746e-07
Iter: 1438 loss: 8.46231387e-07
Iter: 1439 loss: 8.46060686e-07
Iter: 1440 loss: 8.47041065e-07
Iter: 1441 loss: 8.46047442e-07
Iter: 1442 loss: 8.45928923e-07
Iter: 1443 loss: 8.45654199e-07
Iter: 1444 loss: 8.51656864e-07
Iter: 1445 loss: 8.45647662e-07
Iter: 1446 loss: 8.45383852e-07
Iter: 1447 loss: 8.46397199e-07
Iter: 1448 loss: 8.45336046e-07
Iter: 1449 loss: 8.45031195e-07
Iter: 1450 loss: 8.45725594e-07
Iter: 1451 loss: 8.44931776e-07
Iter: 1452 loss: 8.44665e-07
Iter: 1453 loss: 8.4787041e-07
Iter: 1454 loss: 8.44682461e-07
Iter: 1455 loss: 8.44508861e-07
Iter: 1456 loss: 8.44844294e-07
Iter: 1457 loss: 8.44429564e-07
Iter: 1458 loss: 8.44331e-07
Iter: 1459 loss: 8.45305e-07
Iter: 1460 loss: 8.44328952e-07
Iter: 1461 loss: 8.44216231e-07
Iter: 1462 loss: 8.43929286e-07
Iter: 1463 loss: 8.48303e-07
Iter: 1464 loss: 8.43908367e-07
Iter: 1465 loss: 8.43712144e-07
Iter: 1466 loss: 8.45807676e-07
Iter: 1467 loss: 8.43674684e-07
Iter: 1468 loss: 8.43522457e-07
Iter: 1469 loss: 8.45124077e-07
Iter: 1470 loss: 8.43495798e-07
Iter: 1471 loss: 8.43384896e-07
Iter: 1472 loss: 8.4327354e-07
Iter: 1473 loss: 8.43239718e-07
Iter: 1474 loss: 8.43038606e-07
Iter: 1475 loss: 8.45150453e-07
Iter: 1476 loss: 8.43059e-07
Iter: 1477 loss: 8.42896043e-07
Iter: 1478 loss: 8.42840848e-07
Iter: 1479 loss: 8.42747568e-07
Iter: 1480 loss: 8.42556119e-07
Iter: 1481 loss: 8.4234307e-07
Iter: 1482 loss: 8.4235586e-07
Iter: 1483 loss: 8.41942949e-07
Iter: 1484 loss: 8.43882503e-07
Iter: 1485 loss: 8.41925498e-07
Iter: 1486 loss: 8.4171262e-07
Iter: 1487 loss: 8.41732685e-07
Iter: 1488 loss: 8.4160547e-07
Iter: 1489 loss: 8.41486099e-07
Iter: 1490 loss: 8.41419705e-07
Iter: 1491 loss: 8.41217911e-07
Iter: 1492 loss: 8.43329303e-07
Iter: 1493 loss: 8.41244741e-07
Iter: 1494 loss: 8.41050792e-07
Iter: 1495 loss: 8.40970188e-07
Iter: 1496 loss: 8.4090118e-07
Iter: 1497 loss: 8.40694213e-07
Iter: 1498 loss: 8.40952339e-07
Iter: 1499 loss: 8.40595817e-07
Iter: 1500 loss: 8.40441032e-07
Iter: 1501 loss: 8.42885697e-07
Iter: 1502 loss: 8.40496796e-07
Iter: 1503 loss: 8.40311884e-07
Iter: 1504 loss: 8.40232246e-07
Iter: 1505 loss: 8.40149482e-07
Iter: 1506 loss: 8.39963263e-07
Iter: 1507 loss: 8.4141459e-07
Iter: 1508 loss: 8.39950303e-07
Iter: 1509 loss: 8.39780569e-07
Iter: 1510 loss: 8.40099e-07
Iter: 1511 loss: 8.39672168e-07
Iter: 1512 loss: 8.39532731e-07
Iter: 1513 loss: 8.39206e-07
Iter: 1514 loss: 8.3921293e-07
Iter: 1515 loss: 8.38829635e-07
Iter: 1516 loss: 8.40713312e-07
Iter: 1517 loss: 8.38778078e-07
Iter: 1518 loss: 8.38557582e-07
Iter: 1519 loss: 8.41285669e-07
Iter: 1520 loss: 8.38575943e-07
Iter: 1521 loss: 8.38343681e-07
Iter: 1522 loss: 8.38467713e-07
Iter: 1523 loss: 8.38196456e-07
Iter: 1524 loss: 8.37966e-07
Iter: 1525 loss: 8.38972596e-07
Iter: 1526 loss: 8.37934749e-07
Iter: 1527 loss: 8.37660536e-07
Iter: 1528 loss: 8.38699691e-07
Iter: 1529 loss: 8.37632285e-07
Iter: 1530 loss: 8.37509901e-07
Iter: 1531 loss: 8.37410539e-07
Iter: 1532 loss: 8.37336927e-07
Iter: 1533 loss: 8.37132461e-07
Iter: 1534 loss: 8.38004894e-07
Iter: 1535 loss: 8.37088805e-07
Iter: 1536 loss: 8.36852507e-07
Iter: 1537 loss: 8.38479309e-07
Iter: 1538 loss: 8.36845061e-07
Iter: 1539 loss: 8.36704771e-07
Iter: 1540 loss: 8.3701957e-07
Iter: 1541 loss: 8.36679249e-07
Iter: 1542 loss: 8.36523498e-07
Iter: 1543 loss: 8.36834431e-07
Iter: 1544 loss: 8.3649843e-07
Iter: 1545 loss: 8.36321703e-07
Iter: 1546 loss: 8.36028676e-07
Iter: 1547 loss: 8.3606426e-07
Iter: 1548 loss: 8.35762762e-07
Iter: 1549 loss: 8.37378536e-07
Iter: 1550 loss: 8.35728656e-07
Iter: 1551 loss: 8.35574156e-07
Iter: 1552 loss: 8.3630249e-07
Iter: 1553 loss: 8.35513e-07
Iter: 1554 loss: 8.35289939e-07
Iter: 1555 loss: 8.36401057e-07
Iter: 1556 loss: 8.35283856e-07
Iter: 1557 loss: 8.35106334e-07
Iter: 1558 loss: 8.35304718e-07
Iter: 1559 loss: 8.35029766e-07
Iter: 1560 loss: 8.3486043e-07
Iter: 1561 loss: 8.36375534e-07
Iter: 1562 loss: 8.34871855e-07
Iter: 1563 loss: 8.34790399e-07
Iter: 1564 loss: 8.34559557e-07
Iter: 1565 loss: 8.37608752e-07
Iter: 1566 loss: 8.34560581e-07
Iter: 1567 loss: 8.34303364e-07
Iter: 1568 loss: 8.34930802e-07
Iter: 1569 loss: 8.3421827e-07
Iter: 1570 loss: 8.34022899e-07
Iter: 1571 loss: 8.3403711e-07
Iter: 1572 loss: 8.33895342e-07
Iter: 1573 loss: 8.33840033e-07
Iter: 1574 loss: 8.33801721e-07
Iter: 1575 loss: 8.33590946e-07
Iter: 1576 loss: 8.35109233e-07
Iter: 1577 loss: 8.33587706e-07
Iter: 1578 loss: 8.3346049e-07
Iter: 1579 loss: 8.33242609e-07
Iter: 1580 loss: 8.33245394e-07
Iter: 1581 loss: 8.33021659e-07
Iter: 1582 loss: 8.33811441e-07
Iter: 1583 loss: 8.32938326e-07
Iter: 1584 loss: 8.32771093e-07
Iter: 1585 loss: 8.33030072e-07
Iter: 1586 loss: 8.32659964e-07
Iter: 1587 loss: 8.32486e-07
Iter: 1588 loss: 8.32486194e-07
Iter: 1589 loss: 8.32374e-07
Iter: 1590 loss: 8.32384e-07
Iter: 1591 loss: 8.32301566e-07
Iter: 1592 loss: 8.3213547e-07
Iter: 1593 loss: 8.33187244e-07
Iter: 1594 loss: 8.32144224e-07
Iter: 1595 loss: 8.32002911e-07
Iter: 1596 loss: 8.31744956e-07
Iter: 1597 loss: 8.36099389e-07
Iter: 1598 loss: 8.31733303e-07
Iter: 1599 loss: 8.31409352e-07
Iter: 1600 loss: 8.3215275e-07
Iter: 1601 loss: 8.31313514e-07
Iter: 1602 loss: 8.31110299e-07
Iter: 1603 loss: 8.3108705e-07
Iter: 1604 loss: 8.30914701e-07
Iter: 1605 loss: 8.31074544e-07
Iter: 1606 loss: 8.30776287e-07
Iter: 1607 loss: 8.30671524e-07
Iter: 1608 loss: 8.31700106e-07
Iter: 1609 loss: 8.30635145e-07
Iter: 1610 loss: 8.30497299e-07
Iter: 1611 loss: 8.30567558e-07
Iter: 1612 loss: 8.3038924e-07
Iter: 1613 loss: 8.30242413e-07
Iter: 1614 loss: 8.30213423e-07
Iter: 1615 loss: 8.30133899e-07
Iter: 1616 loss: 8.29912778e-07
Iter: 1617 loss: 8.30321255e-07
Iter: 1618 loss: 8.29859289e-07
Iter: 1619 loss: 8.29663634e-07
Iter: 1620 loss: 8.3188587e-07
Iter: 1621 loss: 8.29691828e-07
Iter: 1622 loss: 8.29521468e-07
Iter: 1623 loss: 8.29727071e-07
Iter: 1624 loss: 8.29469798e-07
Iter: 1625 loss: 8.29363444e-07
Iter: 1626 loss: 8.29619239e-07
Iter: 1627 loss: 8.29277383e-07
Iter: 1628 loss: 8.29059786e-07
Iter: 1629 loss: 8.29707574e-07
Iter: 1630 loss: 8.29046826e-07
Iter: 1631 loss: 8.28877e-07
Iter: 1632 loss: 8.28709574e-07
Iter: 1633 loss: 8.28680356e-07
Iter: 1634 loss: 8.28485327e-07
Iter: 1635 loss: 8.29516239e-07
Iter: 1636 loss: 8.28445081e-07
Iter: 1637 loss: 8.28285863e-07
Iter: 1638 loss: 8.30341378e-07
Iter: 1639 loss: 8.2828933e-07
Iter: 1640 loss: 8.28135342e-07
Iter: 1641 loss: 8.27980557e-07
Iter: 1642 loss: 8.27965209e-07
Iter: 1643 loss: 8.27814802e-07
Iter: 1644 loss: 8.27826057e-07
Iter: 1645 loss: 8.276931e-07
Iter: 1646 loss: 8.2754957e-07
Iter: 1647 loss: 8.27524048e-07
Iter: 1648 loss: 8.27383587e-07
Iter: 1649 loss: 8.27443841e-07
Iter: 1650 loss: 8.27268138e-07
Iter: 1651 loss: 8.27033318e-07
Iter: 1652 loss: 8.27675876e-07
Iter: 1653 loss: 8.26988298e-07
Iter: 1654 loss: 8.26918608e-07
Iter: 1655 loss: 8.26870746e-07
Iter: 1656 loss: 8.26830842e-07
Iter: 1657 loss: 8.26703172e-07
Iter: 1658 loss: 8.2672284e-07
Iter: 1659 loss: 8.26573796e-07
Iter: 1660 loss: 8.27244207e-07
Iter: 1661 loss: 8.26551116e-07
Iter: 1662 loss: 8.26350458e-07
Iter: 1663 loss: 8.26341591e-07
Iter: 1664 loss: 8.26205849e-07
Iter: 1665 loss: 8.26048449e-07
Iter: 1666 loss: 8.26048677e-07
Iter: 1667 loss: 8.25891902e-07
Iter: 1668 loss: 8.25664586e-07
Iter: 1669 loss: 8.25702955e-07
Iter: 1670 loss: 8.25477116e-07
Iter: 1671 loss: 8.25424763e-07
Iter: 1672 loss: 8.25350583e-07
Iter: 1673 loss: 8.25234906e-07
Iter: 1674 loss: 8.25044083e-07
Iter: 1675 loss: 8.25038e-07
Iter: 1676 loss: 8.24830408e-07
Iter: 1677 loss: 8.26462895e-07
Iter: 1678 loss: 8.24779192e-07
Iter: 1679 loss: 8.24603831e-07
Iter: 1680 loss: 8.25312441e-07
Iter: 1681 loss: 8.24574045e-07
Iter: 1682 loss: 8.24472579e-07
Iter: 1683 loss: 8.24258109e-07
Iter: 1684 loss: 8.28591965e-07
Iter: 1685 loss: 8.24273798e-07
Iter: 1686 loss: 8.2402255e-07
Iter: 1687 loss: 8.25208474e-07
Iter: 1688 loss: 8.23952e-07
Iter: 1689 loss: 8.23756068e-07
Iter: 1690 loss: 8.25177551e-07
Iter: 1691 loss: 8.2373748e-07
Iter: 1692 loss: 8.23579e-07
Iter: 1693 loss: 8.25430902e-07
Iter: 1694 loss: 8.23587129e-07
Iter: 1695 loss: 8.23502774e-07
Iter: 1696 loss: 8.23344067e-07
Iter: 1697 loss: 8.23366065e-07
Iter: 1698 loss: 8.23186838e-07
Iter: 1699 loss: 8.23208552e-07
Iter: 1700 loss: 8.23147957e-07
Iter: 1701 loss: 8.22928428e-07
Iter: 1702 loss: 8.26683106e-07
Iter: 1703 loss: 8.229282e-07
Iter: 1704 loss: 8.22782113e-07
Iter: 1705 loss: 8.22909499e-07
Iter: 1706 loss: 8.22605386e-07
Iter: 1707 loss: 8.22393417e-07
Iter: 1708 loss: 8.24005042e-07
Iter: 1709 loss: 8.22377388e-07
Iter: 1710 loss: 8.22247e-07
Iter: 1711 loss: 8.22233403e-07
Iter: 1712 loss: 8.22138588e-07
Iter: 1713 loss: 8.2192048e-07
Iter: 1714 loss: 8.26335281e-07
Iter: 1715 loss: 8.21926449e-07
Iter: 1716 loss: 8.21799119e-07
Iter: 1717 loss: 8.21759841e-07
Iter: 1718 loss: 8.21640867e-07
Iter: 1719 loss: 8.21426283e-07
Iter: 1720 loss: 8.21419633e-07
Iter: 1721 loss: 8.21212211e-07
Iter: 1722 loss: 8.21611138e-07
Iter: 1723 loss: 8.21150934e-07
Iter: 1724 loss: 8.20890421e-07
Iter: 1725 loss: 8.21819299e-07
Iter: 1726 loss: 8.20864329e-07
Iter: 1727 loss: 8.2063525e-07
Iter: 1728 loss: 8.20608e-07
Iter: 1729 loss: 8.20533273e-07
Iter: 1730 loss: 8.20445962e-07
Iter: 1731 loss: 8.20475179e-07
Iter: 1732 loss: 8.20304308e-07
Iter: 1733 loss: 8.20304649e-07
Iter: 1734 loss: 8.20174591e-07
Iter: 1735 loss: 8.2008745e-07
Iter: 1736 loss: 8.20087735e-07
Iter: 1737 loss: 8.1990072e-07
Iter: 1738 loss: 8.19803631e-07
Iter: 1739 loss: 8.1973019e-07
Iter: 1740 loss: 8.19581942e-07
Iter: 1741 loss: 8.21762114e-07
Iter: 1742 loss: 8.1960809e-07
Iter: 1743 loss: 8.19429715e-07
Iter: 1744 loss: 8.19650779e-07
Iter: 1745 loss: 8.19385434e-07
Iter: 1746 loss: 8.19215188e-07
Iter: 1747 loss: 8.19030561e-07
Iter: 1748 loss: 8.19021693e-07
Iter: 1749 loss: 8.18824105e-07
Iter: 1750 loss: 8.18772151e-07
Iter: 1751 loss: 8.18677677e-07
Iter: 1752 loss: 8.18471847e-07
Iter: 1753 loss: 8.21844367e-07
Iter: 1754 loss: 8.1846008e-07
Iter: 1755 loss: 8.18227e-07
Iter: 1756 loss: 8.18527667e-07
Iter: 1757 loss: 8.18113563e-07
Iter: 1758 loss: 8.1786493e-07
Iter: 1759 loss: 8.19103093e-07
Iter: 1760 loss: 8.17832813e-07
Iter: 1761 loss: 8.17618968e-07
Iter: 1762 loss: 8.17966622e-07
Iter: 1763 loss: 8.17521141e-07
Iter: 1764 loss: 8.17411149e-07
Iter: 1765 loss: 8.1737312e-07
Iter: 1766 loss: 8.17295529e-07
Iter: 1767 loss: 8.17126363e-07
Iter: 1768 loss: 8.17087084e-07
Iter: 1769 loss: 8.16943327e-07
Iter: 1770 loss: 8.17255568e-07
Iter: 1771 loss: 8.16935938e-07
Iter: 1772 loss: 8.16705608e-07
Iter: 1773 loss: 8.17566615e-07
Iter: 1774 loss: 8.16636089e-07
Iter: 1775 loss: 8.16453849e-07
Iter: 1776 loss: 8.16575607e-07
Iter: 1777 loss: 8.16303668e-07
Iter: 1778 loss: 8.1614769e-07
Iter: 1779 loss: 8.16894499e-07
Iter: 1780 loss: 8.16072202e-07
Iter: 1781 loss: 8.15907129e-07
Iter: 1782 loss: 8.17546891e-07
Iter: 1783 loss: 8.15915712e-07
Iter: 1784 loss: 8.15796454e-07
Iter: 1785 loss: 8.15541796e-07
Iter: 1786 loss: 8.2129543e-07
Iter: 1787 loss: 8.15555893e-07
Iter: 1788 loss: 8.15414126e-07
Iter: 1789 loss: 8.15376779e-07
Iter: 1790 loss: 8.15281965e-07
Iter: 1791 loss: 8.15142187e-07
Iter: 1792 loss: 8.15096882e-07
Iter: 1793 loss: 8.14966427e-07
Iter: 1794 loss: 8.14923851e-07
Iter: 1795 loss: 8.14816758e-07
Iter: 1796 loss: 8.14601151e-07
Iter: 1797 loss: 8.15173962e-07
Iter: 1798 loss: 8.14497582e-07
Iter: 1799 loss: 8.14374175e-07
Iter: 1800 loss: 8.14376165e-07
Iter: 1801 loss: 8.14195459e-07
Iter: 1802 loss: 8.13982751e-07
Iter: 1803 loss: 8.1398781e-07
Iter: 1804 loss: 8.13746738e-07
Iter: 1805 loss: 8.14232521e-07
Iter: 1806 loss: 8.13688814e-07
Iter: 1807 loss: 8.13462e-07
Iter: 1808 loss: 8.15928161e-07
Iter: 1809 loss: 8.13466499e-07
Iter: 1810 loss: 8.13306542e-07
Iter: 1811 loss: 8.13249642e-07
Iter: 1812 loss: 8.13157612e-07
Iter: 1813 loss: 8.12989185e-07
Iter: 1814 loss: 8.14090072e-07
Iter: 1815 loss: 8.129756e-07
Iter: 1816 loss: 8.12822464e-07
Iter: 1817 loss: 8.13631914e-07
Iter: 1818 loss: 8.12813255e-07
Iter: 1819 loss: 8.12702694e-07
Iter: 1820 loss: 8.12437634e-07
Iter: 1821 loss: 8.17570481e-07
Iter: 1822 loss: 8.12455369e-07
Iter: 1823 loss: 8.1234441e-07
Iter: 1824 loss: 8.12311441e-07
Iter: 1825 loss: 8.12175642e-07
Iter: 1826 loss: 8.12206963e-07
Iter: 1827 loss: 8.12100723e-07
Iter: 1828 loss: 8.11955772e-07
Iter: 1829 loss: 8.11645407e-07
Iter: 1830 loss: 8.17913474e-07
Iter: 1831 loss: 8.11669395e-07
Iter: 1832 loss: 8.11442533e-07
Iter: 1833 loss: 8.1141792e-07
Iter: 1834 loss: 8.11296047e-07
Iter: 1835 loss: 8.11282746e-07
Iter: 1836 loss: 8.11226073e-07
Iter: 1837 loss: 8.11011716e-07
Iter: 1838 loss: 8.13635211e-07
Iter: 1839 loss: 8.10982044e-07
Iter: 1840 loss: 8.10870631e-07
Iter: 1841 loss: 8.12517442e-07
Iter: 1842 loss: 8.10856136e-07
Iter: 1843 loss: 8.10698282e-07
Iter: 1844 loss: 8.11696339e-07
Iter: 1845 loss: 8.10694758e-07
Iter: 1846 loss: 8.10574306e-07
Iter: 1847 loss: 8.1054128e-07
Iter: 1848 loss: 8.10498591e-07
Iter: 1849 loss: 8.10357051e-07
Iter: 1850 loss: 8.11473114e-07
Iter: 1851 loss: 8.10340509e-07
Iter: 1852 loss: 8.1021733e-07
Iter: 1853 loss: 8.10419465e-07
Iter: 1854 loss: 8.10140591e-07
Iter: 1855 loss: 8.10010192e-07
Iter: 1856 loss: 8.09879793e-07
Iter: 1857 loss: 8.09839e-07
Iter: 1858 loss: 8.09696871e-07
Iter: 1859 loss: 8.09691699e-07
Iter: 1860 loss: 8.09535436e-07
Iter: 1861 loss: 8.09363542e-07
Iter: 1862 loss: 8.09349899e-07
Iter: 1863 loss: 8.09167716e-07
Iter: 1864 loss: 8.09167034e-07
Iter: 1865 loss: 8.0904e-07
Iter: 1866 loss: 8.08836603e-07
Iter: 1867 loss: 8.10726078e-07
Iter: 1868 loss: 8.08795619e-07
Iter: 1869 loss: 8.08672326e-07
Iter: 1870 loss: 8.0864038e-07
Iter: 1871 loss: 8.08591949e-07
Iter: 1872 loss: 8.08465302e-07
Iter: 1873 loss: 8.11292e-07
Iter: 1874 loss: 8.08510151e-07
Iter: 1875 loss: 8.08302502e-07
Iter: 1876 loss: 8.08366508e-07
Iter: 1877 loss: 8.0826328e-07
Iter: 1878 loss: 8.08131631e-07
Iter: 1879 loss: 8.08125662e-07
Iter: 1880 loss: 8.08058303e-07
Iter: 1881 loss: 8.07972924e-07
Iter: 1882 loss: 8.07944957e-07
Iter: 1883 loss: 8.07836273e-07
Iter: 1884 loss: 8.08357299e-07
Iter: 1885 loss: 8.07825472e-07
Iter: 1886 loss: 8.07693255e-07
Iter: 1887 loss: 8.07926085e-07
Iter: 1888 loss: 8.07629931e-07
Iter: 1889 loss: 8.07465597e-07
Iter: 1890 loss: 8.07351512e-07
Iter: 1891 loss: 8.07323488e-07
Iter: 1892 loss: 8.07204174e-07
Iter: 1893 loss: 8.07450419e-07
Iter: 1894 loss: 8.07095716e-07
Iter: 1895 loss: 8.07017045e-07
Iter: 1896 loss: 8.07018466e-07
Iter: 1897 loss: 8.06893468e-07
Iter: 1898 loss: 8.07272443e-07
Iter: 1899 loss: 8.06878234e-07
Iter: 1900 loss: 8.06790183e-07
Iter: 1901 loss: 8.06686e-07
Iter: 1902 loss: 8.06670585e-07
Iter: 1903 loss: 8.06573667e-07
Iter: 1904 loss: 8.08316713e-07
Iter: 1905 loss: 8.06572189e-07
Iter: 1906 loss: 8.06458502e-07
Iter: 1907 loss: 8.06374146e-07
Iter: 1908 loss: 8.06310879e-07
Iter: 1909 loss: 8.06132107e-07
Iter: 1910 loss: 8.06090327e-07
Iter: 1911 loss: 8.06005573e-07
Iter: 1912 loss: 8.05861589e-07
Iter: 1913 loss: 8.07851563e-07
Iter: 1914 loss: 8.05863067e-07
Iter: 1915 loss: 8.057321e-07
Iter: 1916 loss: 8.06719243e-07
Iter: 1917 loss: 8.05746652e-07
Iter: 1918 loss: 8.0560983e-07
Iter: 1919 loss: 8.05493528e-07
Iter: 1920 loss: 8.05479033e-07
Iter: 1921 loss: 8.05341642e-07
Iter: 1922 loss: 8.06148307e-07
Iter: 1923 loss: 8.05352443e-07
Iter: 1924 loss: 8.05267746e-07
Iter: 1925 loss: 8.05440493e-07
Iter: 1926 loss: 8.05165e-07
Iter: 1927 loss: 8.05092611e-07
Iter: 1928 loss: 8.05079821e-07
Iter: 1929 loss: 8.05030822e-07
Iter: 1930 loss: 8.04923104e-07
Iter: 1931 loss: 8.04896843e-07
Iter: 1932 loss: 8.04808678e-07
Iter: 1933 loss: 8.04932597e-07
Iter: 1934 loss: 8.04763715e-07
Iter: 1935 loss: 8.04631384e-07
Iter: 1936 loss: 8.06097205e-07
Iter: 1937 loss: 8.04615752e-07
Iter: 1938 loss: 8.04514912e-07
Iter: 1939 loss: 8.04483875e-07
Iter: 1940 loss: 8.04413958e-07
Iter: 1941 loss: 8.042839e-07
Iter: 1942 loss: 8.05085165e-07
Iter: 1943 loss: 8.04298111e-07
Iter: 1944 loss: 8.04187323e-07
Iter: 1945 loss: 8.04267131e-07
Iter: 1946 loss: 8.04155e-07
Iter: 1947 loss: 8.04025774e-07
Iter: 1948 loss: 8.0389907e-07
Iter: 1949 loss: 8.0390447e-07
Iter: 1950 loss: 8.03708531e-07
Iter: 1951 loss: 8.04845627e-07
Iter: 1952 loss: 8.03691535e-07
Iter: 1953 loss: 8.03568128e-07
Iter: 1954 loss: 8.04685101e-07
Iter: 1955 loss: 8.03569606e-07
Iter: 1956 loss: 8.03441935e-07
Iter: 1957 loss: 8.0333308e-07
Iter: 1958 loss: 8.03297837e-07
Iter: 1959 loss: 8.03177784e-07
Iter: 1960 loss: 8.03469e-07
Iter: 1961 loss: 8.03069e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.8/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.2 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.2
+ date
Sun Nov  8 01:54:22 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi0.8/300_100_100_100_1 --function f1 --psi 1 --phi 1.2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.2/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a7030c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a7030c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a7018ebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a7018ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a7022b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a7022b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a700b38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33b5a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33b5a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33b95378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33bab158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33ac58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33ac56a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a700659d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33b2f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33b35d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33b1f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c37d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c2cd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c3176a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c317510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c3171e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a33aed950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c2ac730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c2ac400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c253378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c253d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c1c26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c1548c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c17e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c1429d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c093048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c0a40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c0a3c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c1de8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9a0c1d2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0028670589
test_loss: 0.0031569193
train_loss: 0.0024266825
test_loss: 0.0025054454
train_loss: 0.0023687098
test_loss: 0.002357296
train_loss: 0.002375652
test_loss: 0.002523458
train_loss: 0.0023247323
test_loss: 0.0024211023
train_loss: 0.0022607832
test_loss: 0.002461317
train_loss: 0.0024406642
test_loss: 0.0023216875
train_loss: 0.0023388206
test_loss: 0.0023346627
train_loss: 0.0022321534
test_loss: 0.002541131
train_loss: 0.0023143305
test_loss: 0.0023495243
train_loss: 0.002243902
test_loss: 0.0024915976
train_loss: 0.0021343618
test_loss: 0.0025042838
train_loss: 0.002239348
test_loss: 0.002370174
train_loss: 0.002192122
test_loss: 0.0026245574
train_loss: 0.0019740607
test_loss: 0.0022744916
train_loss: 0.0023598701
test_loss: 0.0022352326
train_loss: 0.002286648
test_loss: 0.0023609595
train_loss: 0.0024811884
test_loss: 0.0024106333
train_loss: 0.0021915976
test_loss: 0.002340283
train_loss: 0.0020471315
test_loss: 0.0023205406
train_loss: 0.002259843
test_loss: 0.0023067922
train_loss: 0.002155561
test_loss: 0.00258548
train_loss: 0.002106078
test_loss: 0.0024377636
train_loss: 0.002104653
test_loss: 0.0023551853
train_loss: 0.0023470009
test_loss: 0.0023273635
train_loss: 0.002227571
test_loss: 0.0023994101
train_loss: 0.002151194
test_loss: 0.0023266803
train_loss: 0.0020476026
test_loss: 0.002288281
train_loss: 0.0021182983
test_loss: 0.0024173567
train_loss: 0.002383474
test_loss: 0.0024564324
train_loss: 0.0021335094
test_loss: 0.002302384
train_loss: 0.0020710097
test_loss: 0.0021685525
train_loss: 0.0022084217
test_loss: 0.0023186377
train_loss: 0.002002354
test_loss: 0.0022850374
train_loss: 0.002036741
test_loss: 0.0023295362
train_loss: 0.0019951113
test_loss: 0.0023286836
train_loss: 0.001988946
test_loss: 0.0023501343
train_loss: 0.002574577
test_loss: 0.0023493099
train_loss: 0.0021168555
test_loss: 0.0022987155
train_loss: 0.0021741842
test_loss: 0.0022677106
train_loss: 0.0021944945
test_loss: 0.0022829152
train_loss: 0.0022057367
test_loss: 0.0023612964
train_loss: 0.0019927262
test_loss: 0.0022504379
train_loss: 0.0021768056
test_loss: 0.0023686162
train_loss: 0.0020502491
test_loss: 0.002224152
train_loss: 0.0021011746
test_loss: 0.0024446386
train_loss: 0.0020759134
test_loss: 0.0023287872
train_loss: 0.002106415
test_loss: 0.0023158526
train_loss: 0.0020931405
test_loss: 0.0022160765
train_loss: 0.002088876
test_loss: 0.0022536172
train_loss: 0.0019912987
test_loss: 0.0021689706
train_loss: 0.0021304667
test_loss: 0.002395247
train_loss: 0.0019838035
test_loss: 0.0022888877
train_loss: 0.0021405092
test_loss: 0.0025928395
train_loss: 0.0019137608
test_loss: 0.0022468006
train_loss: 0.0022228707
test_loss: 0.0024601582
train_loss: 0.0019974955
test_loss: 0.0021877643
train_loss: 0.0019267733
test_loss: 0.0022942165
train_loss: 0.0021941753
test_loss: 0.002311879
train_loss: 0.0022535727
test_loss: 0.0023487292
train_loss: 0.0020228787
test_loss: 0.0023151764
train_loss: 0.0021258467
test_loss: 0.0023298054
train_loss: 0.0019143411
test_loss: 0.002140321
train_loss: 0.0024052237
test_loss: 0.0024634267
train_loss: 0.0020216908
test_loss: 0.0021763248
train_loss: 0.0020091052
test_loss: 0.0021698852
train_loss: 0.002122812
test_loss: 0.0023272794
train_loss: 0.0022372506
test_loss: 0.0023712283
train_loss: 0.0022011045
test_loss: 0.0023647551
train_loss: 0.0022514465
test_loss: 0.002462801
train_loss: 0.002073012
test_loss: 0.0023701503
train_loss: 0.0020389396
test_loss: 0.0022291988
train_loss: 0.0019136848
test_loss: 0.002234947
train_loss: 0.0021281887
test_loss: 0.002318575
train_loss: 0.0022346755
test_loss: 0.0022972515
train_loss: 0.0019752535
test_loss: 0.0022751596
train_loss: 0.001978975
test_loss: 0.0022284663
train_loss: 0.0020683492
test_loss: 0.0020402402
train_loss: 0.002242845
test_loss: 0.002153849
train_loss: 0.0022714646
test_loss: 0.002308998
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.2/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 1.2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.2/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ade3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ade36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8aee27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ae18f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ae4c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ae4c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ad8c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ad34730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ad2b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ad2bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ad2bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8acb8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8acb89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ac829d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ac1b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ac1b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ac497b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8abe8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8abc3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ab65620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ab79510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb8ab65378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a7cf9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a7f9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a7f9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a79a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a79ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a78a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a70f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a730400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a6ea730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a707510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a707488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a6cb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a6798c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdb6a67aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 7.34167952e-06
Iter: 2 loss: 1.05767795e-05
Iter: 3 loss: 5.97417647e-06
Iter: 4 loss: 5.32579634e-06
Iter: 5 loss: 7.62328455e-06
Iter: 6 loss: 5.15924785e-06
Iter: 7 loss: 4.89180638e-06
Iter: 8 loss: 5.5135406e-06
Iter: 9 loss: 4.79298342e-06
Iter: 10 loss: 4.55702866e-06
Iter: 11 loss: 6.34913977e-06
Iter: 12 loss: 4.53899429e-06
Iter: 13 loss: 4.4027488e-06
Iter: 14 loss: 4.29348347e-06
Iter: 15 loss: 4.25259077e-06
Iter: 16 loss: 4.1187659e-06
Iter: 17 loss: 4.11384099e-06
Iter: 18 loss: 4.07181597e-06
Iter: 19 loss: 3.98768043e-06
Iter: 20 loss: 5.56888153e-06
Iter: 21 loss: 3.98623433e-06
Iter: 22 loss: 3.89091383e-06
Iter: 23 loss: 4.48318815e-06
Iter: 24 loss: 3.8797325e-06
Iter: 25 loss: 3.77652987e-06
Iter: 26 loss: 4.08381356e-06
Iter: 27 loss: 3.7452478e-06
Iter: 28 loss: 3.66137738e-06
Iter: 29 loss: 3.58872808e-06
Iter: 30 loss: 3.56617716e-06
Iter: 31 loss: 3.4337661e-06
Iter: 32 loss: 3.27920338e-06
Iter: 33 loss: 3.26165514e-06
Iter: 34 loss: 3.10915448e-06
Iter: 35 loss: 3.10522364e-06
Iter: 36 loss: 3.02820899e-06
Iter: 37 loss: 3.02802755e-06
Iter: 38 loss: 2.95601149e-06
Iter: 39 loss: 3.00551847e-06
Iter: 40 loss: 2.91111201e-06
Iter: 41 loss: 2.85910914e-06
Iter: 42 loss: 3.09082839e-06
Iter: 43 loss: 2.84892917e-06
Iter: 44 loss: 2.78565312e-06
Iter: 45 loss: 2.85762053e-06
Iter: 46 loss: 2.7517367e-06
Iter: 47 loss: 2.70678038e-06
Iter: 48 loss: 2.91546075e-06
Iter: 49 loss: 2.69849988e-06
Iter: 50 loss: 2.66081042e-06
Iter: 51 loss: 2.81205666e-06
Iter: 52 loss: 2.65238396e-06
Iter: 53 loss: 2.61466198e-06
Iter: 54 loss: 2.54663973e-06
Iter: 55 loss: 4.19194339e-06
Iter: 56 loss: 2.54664019e-06
Iter: 57 loss: 2.48181072e-06
Iter: 58 loss: 2.99596468e-06
Iter: 59 loss: 2.47750131e-06
Iter: 60 loss: 2.43165459e-06
Iter: 61 loss: 2.95097311e-06
Iter: 62 loss: 2.43077375e-06
Iter: 63 loss: 2.39761926e-06
Iter: 64 loss: 2.33645414e-06
Iter: 65 loss: 3.75738796e-06
Iter: 66 loss: 2.33643391e-06
Iter: 67 loss: 2.25928807e-06
Iter: 68 loss: 2.53388157e-06
Iter: 69 loss: 2.23964798e-06
Iter: 70 loss: 2.1942792e-06
Iter: 71 loss: 2.21796381e-06
Iter: 72 loss: 2.16414355e-06
Iter: 73 loss: 2.14436545e-06
Iter: 74 loss: 2.13791373e-06
Iter: 75 loss: 2.11308679e-06
Iter: 76 loss: 2.23629786e-06
Iter: 77 loss: 2.10877715e-06
Iter: 78 loss: 2.09475388e-06
Iter: 79 loss: 2.09019981e-06
Iter: 80 loss: 2.08220399e-06
Iter: 81 loss: 2.06265895e-06
Iter: 82 loss: 2.24952578e-06
Iter: 83 loss: 2.06196319e-06
Iter: 84 loss: 2.04492926e-06
Iter: 85 loss: 2.01134822e-06
Iter: 86 loss: 2.67293126e-06
Iter: 87 loss: 2.01099306e-06
Iter: 88 loss: 1.99093802e-06
Iter: 89 loss: 1.98977568e-06
Iter: 90 loss: 1.9709255e-06
Iter: 91 loss: 1.9371e-06
Iter: 92 loss: 2.75681441e-06
Iter: 93 loss: 1.93706728e-06
Iter: 94 loss: 1.90418609e-06
Iter: 95 loss: 2.03569766e-06
Iter: 96 loss: 1.89680759e-06
Iter: 97 loss: 1.86604132e-06
Iter: 98 loss: 2.04435787e-06
Iter: 99 loss: 1.86199941e-06
Iter: 100 loss: 1.83698762e-06
Iter: 101 loss: 2.00184422e-06
Iter: 102 loss: 1.83439045e-06
Iter: 103 loss: 1.82122551e-06
Iter: 104 loss: 1.7954535e-06
Iter: 105 loss: 2.31152057e-06
Iter: 106 loss: 1.79533538e-06
Iter: 107 loss: 1.76565015e-06
Iter: 108 loss: 1.99817305e-06
Iter: 109 loss: 1.76355479e-06
Iter: 110 loss: 1.75032289e-06
Iter: 111 loss: 1.90783749e-06
Iter: 112 loss: 1.75016703e-06
Iter: 113 loss: 1.73696367e-06
Iter: 114 loss: 1.79960034e-06
Iter: 115 loss: 1.73461467e-06
Iter: 116 loss: 1.72824639e-06
Iter: 117 loss: 1.72171065e-06
Iter: 118 loss: 1.72043974e-06
Iter: 119 loss: 1.70752685e-06
Iter: 120 loss: 1.8025288e-06
Iter: 121 loss: 1.70638202e-06
Iter: 122 loss: 1.69663952e-06
Iter: 123 loss: 1.68687143e-06
Iter: 124 loss: 1.68487929e-06
Iter: 125 loss: 1.67271992e-06
Iter: 126 loss: 1.78351547e-06
Iter: 127 loss: 1.6721857e-06
Iter: 128 loss: 1.659296e-06
Iter: 129 loss: 1.65690301e-06
Iter: 130 loss: 1.648232e-06
Iter: 131 loss: 1.63465359e-06
Iter: 132 loss: 1.61896878e-06
Iter: 133 loss: 1.61702064e-06
Iter: 134 loss: 1.59944534e-06
Iter: 135 loss: 1.59910724e-06
Iter: 136 loss: 1.58517014e-06
Iter: 137 loss: 1.62183198e-06
Iter: 138 loss: 1.58054513e-06
Iter: 139 loss: 1.56829356e-06
Iter: 140 loss: 1.56416172e-06
Iter: 141 loss: 1.55715804e-06
Iter: 142 loss: 1.54199097e-06
Iter: 143 loss: 1.57346847e-06
Iter: 144 loss: 1.53591145e-06
Iter: 145 loss: 1.52891494e-06
Iter: 146 loss: 1.52748453e-06
Iter: 147 loss: 1.51979748e-06
Iter: 148 loss: 1.53081442e-06
Iter: 149 loss: 1.51600193e-06
Iter: 150 loss: 1.50907147e-06
Iter: 151 loss: 1.5018893e-06
Iter: 152 loss: 1.50045594e-06
Iter: 153 loss: 1.49472e-06
Iter: 154 loss: 1.49346351e-06
Iter: 155 loss: 1.48997378e-06
Iter: 156 loss: 1.48056279e-06
Iter: 157 loss: 1.54624524e-06
Iter: 158 loss: 1.47848709e-06
Iter: 159 loss: 1.47165133e-06
Iter: 160 loss: 1.47104072e-06
Iter: 161 loss: 1.46476009e-06
Iter: 162 loss: 1.45711635e-06
Iter: 163 loss: 1.45640718e-06
Iter: 164 loss: 1.44514956e-06
Iter: 165 loss: 1.46102275e-06
Iter: 166 loss: 1.43963439e-06
Iter: 167 loss: 1.43142165e-06
Iter: 168 loss: 1.5006475e-06
Iter: 169 loss: 1.43096247e-06
Iter: 170 loss: 1.42349961e-06
Iter: 171 loss: 1.46909758e-06
Iter: 172 loss: 1.42259785e-06
Iter: 173 loss: 1.4173969e-06
Iter: 174 loss: 1.40728139e-06
Iter: 175 loss: 1.61806713e-06
Iter: 176 loss: 1.40725217e-06
Iter: 177 loss: 1.39766416e-06
Iter: 178 loss: 1.48700371e-06
Iter: 179 loss: 1.39729241e-06
Iter: 180 loss: 1.39101905e-06
Iter: 181 loss: 1.43804459e-06
Iter: 182 loss: 1.39048734e-06
Iter: 183 loss: 1.38257974e-06
Iter: 184 loss: 1.39204178e-06
Iter: 185 loss: 1.37833081e-06
Iter: 186 loss: 1.37442385e-06
Iter: 187 loss: 1.37866232e-06
Iter: 188 loss: 1.37227221e-06
Iter: 189 loss: 1.36624055e-06
Iter: 190 loss: 1.39097358e-06
Iter: 191 loss: 1.36491553e-06
Iter: 192 loss: 1.35872608e-06
Iter: 193 loss: 1.35388109e-06
Iter: 194 loss: 1.35194477e-06
Iter: 195 loss: 1.34802735e-06
Iter: 196 loss: 1.40546717e-06
Iter: 197 loss: 1.34803008e-06
Iter: 198 loss: 1.34412983e-06
Iter: 199 loss: 1.34527431e-06
Iter: 200 loss: 1.34146342e-06
Iter: 201 loss: 1.33660637e-06
Iter: 202 loss: 1.32847345e-06
Iter: 203 loss: 1.32851289e-06
Iter: 204 loss: 1.31837157e-06
Iter: 205 loss: 1.39618669e-06
Iter: 206 loss: 1.31759793e-06
Iter: 207 loss: 1.31253069e-06
Iter: 208 loss: 1.38686255e-06
Iter: 209 loss: 1.31250545e-06
Iter: 210 loss: 1.30745229e-06
Iter: 211 loss: 1.3049289e-06
Iter: 212 loss: 1.30257979e-06
Iter: 213 loss: 1.29691875e-06
Iter: 214 loss: 1.29489104e-06
Iter: 215 loss: 1.29168905e-06
Iter: 216 loss: 1.28890474e-06
Iter: 217 loss: 1.28785223e-06
Iter: 218 loss: 1.28505451e-06
Iter: 219 loss: 1.3072455e-06
Iter: 220 loss: 1.28487454e-06
Iter: 221 loss: 1.28306692e-06
Iter: 222 loss: 1.27814951e-06
Iter: 223 loss: 1.30542958e-06
Iter: 224 loss: 1.27663407e-06
Iter: 225 loss: 1.27690123e-06
Iter: 226 loss: 1.27396083e-06
Iter: 227 loss: 1.27209228e-06
Iter: 228 loss: 1.26777729e-06
Iter: 229 loss: 1.32296236e-06
Iter: 230 loss: 1.26746556e-06
Iter: 231 loss: 1.26294674e-06
Iter: 232 loss: 1.28769591e-06
Iter: 233 loss: 1.26224245e-06
Iter: 234 loss: 1.25750989e-06
Iter: 235 loss: 1.27467547e-06
Iter: 236 loss: 1.25629072e-06
Iter: 237 loss: 1.25146744e-06
Iter: 238 loss: 1.25070437e-06
Iter: 239 loss: 1.24734333e-06
Iter: 240 loss: 1.24275789e-06
Iter: 241 loss: 1.24411076e-06
Iter: 242 loss: 1.23948848e-06
Iter: 243 loss: 1.2341477e-06
Iter: 244 loss: 1.28939882e-06
Iter: 245 loss: 1.23400514e-06
Iter: 246 loss: 1.23039013e-06
Iter: 247 loss: 1.26990017e-06
Iter: 248 loss: 1.23028371e-06
Iter: 249 loss: 1.22800407e-06
Iter: 250 loss: 1.22658685e-06
Iter: 251 loss: 1.22565348e-06
Iter: 252 loss: 1.22258075e-06
Iter: 253 loss: 1.2280866e-06
Iter: 254 loss: 1.22117615e-06
Iter: 255 loss: 1.21899723e-06
Iter: 256 loss: 1.21873563e-06
Iter: 257 loss: 1.21775668e-06
Iter: 258 loss: 1.21500693e-06
Iter: 259 loss: 1.23012114e-06
Iter: 260 loss: 1.21416e-06
Iter: 261 loss: 1.21078403e-06
Iter: 262 loss: 1.26209989e-06
Iter: 263 loss: 1.21078733e-06
Iter: 264 loss: 1.20767936e-06
Iter: 265 loss: 1.20800871e-06
Iter: 266 loss: 1.20536924e-06
Iter: 267 loss: 1.20218215e-06
Iter: 268 loss: 1.19852984e-06
Iter: 269 loss: 1.19803576e-06
Iter: 270 loss: 1.19332719e-06
Iter: 271 loss: 1.19330639e-06
Iter: 272 loss: 1.19027277e-06
Iter: 273 loss: 1.1872994e-06
Iter: 274 loss: 1.18663411e-06
Iter: 275 loss: 1.18215246e-06
Iter: 276 loss: 1.19622518e-06
Iter: 277 loss: 1.1809027e-06
Iter: 278 loss: 1.1777488e-06
Iter: 279 loss: 1.18292382e-06
Iter: 280 loss: 1.17632055e-06
Iter: 281 loss: 1.1738058e-06
Iter: 282 loss: 1.17382388e-06
Iter: 283 loss: 1.17159198e-06
Iter: 284 loss: 1.17432887e-06
Iter: 285 loss: 1.17053082e-06
Iter: 286 loss: 1.16843489e-06
Iter: 287 loss: 1.17150512e-06
Iter: 288 loss: 1.16751528e-06
Iter: 289 loss: 1.16600029e-06
Iter: 290 loss: 1.18500259e-06
Iter: 291 loss: 1.16595027e-06
Iter: 292 loss: 1.16399281e-06
Iter: 293 loss: 1.15889691e-06
Iter: 294 loss: 1.20860727e-06
Iter: 295 loss: 1.1583063e-06
Iter: 296 loss: 1.15576904e-06
Iter: 297 loss: 1.19382219e-06
Iter: 298 loss: 1.15579246e-06
Iter: 299 loss: 1.15339321e-06
Iter: 300 loss: 1.16374963e-06
Iter: 301 loss: 1.15295859e-06
Iter: 302 loss: 1.151427e-06
Iter: 303 loss: 1.15035925e-06
Iter: 304 loss: 1.14976956e-06
Iter: 305 loss: 1.1475131e-06
Iter: 306 loss: 1.15035198e-06
Iter: 307 loss: 1.14633258e-06
Iter: 308 loss: 1.14320187e-06
Iter: 309 loss: 1.17149443e-06
Iter: 310 loss: 1.14298757e-06
Iter: 311 loss: 1.14157433e-06
Iter: 312 loss: 1.13888314e-06
Iter: 313 loss: 1.13890235e-06
Iter: 314 loss: 1.13578812e-06
Iter: 315 loss: 1.14761815e-06
Iter: 316 loss: 1.13503324e-06
Iter: 317 loss: 1.13182068e-06
Iter: 318 loss: 1.13760711e-06
Iter: 319 loss: 1.1304902e-06
Iter: 320 loss: 1.12847272e-06
Iter: 321 loss: 1.12847852e-06
Iter: 322 loss: 1.12633791e-06
Iter: 323 loss: 1.12673035e-06
Iter: 324 loss: 1.12473765e-06
Iter: 325 loss: 1.12276848e-06
Iter: 326 loss: 1.13600834e-06
Iter: 327 loss: 1.12249825e-06
Iter: 328 loss: 1.12099565e-06
Iter: 329 loss: 1.1370704e-06
Iter: 330 loss: 1.1209886e-06
Iter: 331 loss: 1.11998224e-06
Iter: 332 loss: 1.1174094e-06
Iter: 333 loss: 1.14433317e-06
Iter: 334 loss: 1.11718225e-06
Iter: 335 loss: 1.11531449e-06
Iter: 336 loss: 1.14171905e-06
Iter: 337 loss: 1.11530471e-06
Iter: 338 loss: 1.11324141e-06
Iter: 339 loss: 1.11495456e-06
Iter: 340 loss: 1.11198779e-06
Iter: 341 loss: 1.10999724e-06
Iter: 342 loss: 1.11203099e-06
Iter: 343 loss: 1.1088531e-06
Iter: 344 loss: 1.10745236e-06
Iter: 345 loss: 1.1115294e-06
Iter: 346 loss: 1.10708129e-06
Iter: 347 loss: 1.10528049e-06
Iter: 348 loss: 1.11582165e-06
Iter: 349 loss: 1.10505e-06
Iter: 350 loss: 1.10386702e-06
Iter: 351 loss: 1.10181759e-06
Iter: 352 loss: 1.10179406e-06
Iter: 353 loss: 1.09933774e-06
Iter: 354 loss: 1.10902829e-06
Iter: 355 loss: 1.09879375e-06
Iter: 356 loss: 1.09633493e-06
Iter: 357 loss: 1.09641599e-06
Iter: 358 loss: 1.09436724e-06
Iter: 359 loss: 1.09373673e-06
Iter: 360 loss: 1.09275584e-06
Iter: 361 loss: 1.09174562e-06
Iter: 362 loss: 1.09110374e-06
Iter: 363 loss: 1.09062557e-06
Iter: 364 loss: 1.08935023e-06
Iter: 365 loss: 1.08936854e-06
Iter: 366 loss: 1.08846507e-06
Iter: 367 loss: 1.08646509e-06
Iter: 368 loss: 1.11101849e-06
Iter: 369 loss: 1.08634185e-06
Iter: 370 loss: 1.08423535e-06
Iter: 371 loss: 1.0992178e-06
Iter: 372 loss: 1.08405436e-06
Iter: 373 loss: 1.08292033e-06
Iter: 374 loss: 1.08292079e-06
Iter: 375 loss: 1.0821459e-06
Iter: 376 loss: 1.07990616e-06
Iter: 377 loss: 1.08899985e-06
Iter: 378 loss: 1.0790161e-06
Iter: 379 loss: 1.07651374e-06
Iter: 380 loss: 1.10288784e-06
Iter: 381 loss: 1.07646338e-06
Iter: 382 loss: 1.07466371e-06
Iter: 383 loss: 1.08407244e-06
Iter: 384 loss: 1.07444794e-06
Iter: 385 loss: 1.07301366e-06
Iter: 386 loss: 1.08602865e-06
Iter: 387 loss: 1.07292453e-06
Iter: 388 loss: 1.0721152e-06
Iter: 389 loss: 1.07024084e-06
Iter: 390 loss: 1.09107191e-06
Iter: 391 loss: 1.07001233e-06
Iter: 392 loss: 1.06811194e-06
Iter: 393 loss: 1.08046709e-06
Iter: 394 loss: 1.06790355e-06
Iter: 395 loss: 1.06653249e-06
Iter: 396 loss: 1.07402639e-06
Iter: 397 loss: 1.06634525e-06
Iter: 398 loss: 1.06519337e-06
Iter: 399 loss: 1.07519531e-06
Iter: 400 loss: 1.0651413e-06
Iter: 401 loss: 1.06387938e-06
Iter: 402 loss: 1.06421089e-06
Iter: 403 loss: 1.06308448e-06
Iter: 404 loss: 1.06173525e-06
Iter: 405 loss: 1.07928724e-06
Iter: 406 loss: 1.06175014e-06
Iter: 407 loss: 1.06105051e-06
Iter: 408 loss: 1.05905565e-06
Iter: 409 loss: 1.06415655e-06
Iter: 410 loss: 1.05787717e-06
Iter: 411 loss: 1.05549964e-06
Iter: 412 loss: 1.0868564e-06
Iter: 413 loss: 1.05546519e-06
Iter: 414 loss: 1.05446475e-06
Iter: 415 loss: 1.05441438e-06
Iter: 416 loss: 1.0534402e-06
Iter: 417 loss: 1.05171034e-06
Iter: 418 loss: 1.09514178e-06
Iter: 419 loss: 1.05165816e-06
Iter: 420 loss: 1.0499873e-06
Iter: 421 loss: 1.05288871e-06
Iter: 422 loss: 1.0491384e-06
Iter: 423 loss: 1.04842729e-06
Iter: 424 loss: 1.04827291e-06
Iter: 425 loss: 1.04761443e-06
Iter: 426 loss: 1.04786795e-06
Iter: 427 loss: 1.04705612e-06
Iter: 428 loss: 1.04607489e-06
Iter: 429 loss: 1.04540277e-06
Iter: 430 loss: 1.04507012e-06
Iter: 431 loss: 1.04366291e-06
Iter: 432 loss: 1.04581693e-06
Iter: 433 loss: 1.04288938e-06
Iter: 434 loss: 1.04140406e-06
Iter: 435 loss: 1.0483808e-06
Iter: 436 loss: 1.04112507e-06
Iter: 437 loss: 1.04000264e-06
Iter: 438 loss: 1.03996115e-06
Iter: 439 loss: 1.0388469e-06
Iter: 440 loss: 1.03901948e-06
Iter: 441 loss: 1.03804018e-06
Iter: 442 loss: 1.03702087e-06
Iter: 443 loss: 1.04220771e-06
Iter: 444 loss: 1.03686079e-06
Iter: 445 loss: 1.03582306e-06
Iter: 446 loss: 1.03451816e-06
Iter: 447 loss: 1.03438026e-06
Iter: 448 loss: 1.03304251e-06
Iter: 449 loss: 1.03459752e-06
Iter: 450 loss: 1.03238608e-06
Iter: 451 loss: 1.03095431e-06
Iter: 452 loss: 1.04029164e-06
Iter: 453 loss: 1.03079071e-06
Iter: 454 loss: 1.02987042e-06
Iter: 455 loss: 1.03271498e-06
Iter: 456 loss: 1.02964168e-06
Iter: 457 loss: 1.02827198e-06
Iter: 458 loss: 1.03354603e-06
Iter: 459 loss: 1.02789716e-06
Iter: 460 loss: 1.02709896e-06
Iter: 461 loss: 1.02595322e-06
Iter: 462 loss: 1.02595084e-06
Iter: 463 loss: 1.02460331e-06
Iter: 464 loss: 1.02921263e-06
Iter: 465 loss: 1.02423826e-06
Iter: 466 loss: 1.02257457e-06
Iter: 467 loss: 1.02508568e-06
Iter: 468 loss: 1.02179081e-06
Iter: 469 loss: 1.02097715e-06
Iter: 470 loss: 1.02082367e-06
Iter: 471 loss: 1.02011199e-06
Iter: 472 loss: 1.01841624e-06
Iter: 473 loss: 1.03407126e-06
Iter: 474 loss: 1.01812725e-06
Iter: 475 loss: 1.01729529e-06
Iter: 476 loss: 1.01700925e-06
Iter: 477 loss: 1.01632327e-06
Iter: 478 loss: 1.02208776e-06
Iter: 479 loss: 1.01625733e-06
Iter: 480 loss: 1.0158675e-06
Iter: 481 loss: 1.01519572e-06
Iter: 482 loss: 1.03027219e-06
Iter: 483 loss: 1.01517503e-06
Iter: 484 loss: 1.01443391e-06
Iter: 485 loss: 1.02365891e-06
Iter: 486 loss: 1.01441663e-06
Iter: 487 loss: 1.01379487e-06
Iter: 488 loss: 1.01254591e-06
Iter: 489 loss: 1.03759135e-06
Iter: 490 loss: 1.0125184e-06
Iter: 491 loss: 1.01132116e-06
Iter: 492 loss: 1.02000422e-06
Iter: 493 loss: 1.0112401e-06
Iter: 494 loss: 1.01045816e-06
Iter: 495 loss: 1.01047522e-06
Iter: 496 loss: 1.00981811e-06
Iter: 497 loss: 1.00830835e-06
Iter: 498 loss: 1.02823697e-06
Iter: 499 loss: 1.00827037e-06
Iter: 500 loss: 1.00665886e-06
Iter: 501 loss: 1.00847592e-06
Iter: 502 loss: 1.00582349e-06
Iter: 503 loss: 1.00459579e-06
Iter: 504 loss: 1.01613705e-06
Iter: 505 loss: 1.00457191e-06
Iter: 506 loss: 1.00361376e-06
Iter: 507 loss: 1.01047124e-06
Iter: 508 loss: 1.00351974e-06
Iter: 509 loss: 1.00258831e-06
Iter: 510 loss: 1.00559464e-06
Iter: 511 loss: 1.00233262e-06
Iter: 512 loss: 1.00170291e-06
Iter: 513 loss: 1.00153852e-06
Iter: 514 loss: 1.00111424e-06
Iter: 515 loss: 1.00023487e-06
Iter: 516 loss: 1.00025488e-06
Iter: 517 loss: 9.99711119e-07
Iter: 518 loss: 9.98398832e-07
Iter: 519 loss: 1.01289174e-06
Iter: 520 loss: 9.98305e-07
Iter: 521 loss: 9.97141115e-07
Iter: 522 loss: 1.01462183e-06
Iter: 523 loss: 9.97095412e-07
Iter: 524 loss: 9.96281e-07
Iter: 525 loss: 9.98608925e-07
Iter: 526 loss: 9.95999812e-07
Iter: 527 loss: 9.95259938e-07
Iter: 528 loss: 9.93943104e-07
Iter: 529 loss: 9.93959702e-07
Iter: 530 loss: 9.92666742e-07
Iter: 531 loss: 1.00396187e-06
Iter: 532 loss: 9.92635e-07
Iter: 533 loss: 9.91700404e-07
Iter: 534 loss: 1.00507e-06
Iter: 535 loss: 9.91617071e-07
Iter: 536 loss: 9.911e-07
Iter: 537 loss: 9.90654598e-07
Iter: 538 loss: 9.90527269e-07
Iter: 539 loss: 9.89642331e-07
Iter: 540 loss: 9.89153818e-07
Iter: 541 loss: 9.88759211e-07
Iter: 542 loss: 9.87553904e-07
Iter: 543 loss: 9.88950774e-07
Iter: 544 loss: 9.86892587e-07
Iter: 545 loss: 9.8555256e-07
Iter: 546 loss: 9.98630753e-07
Iter: 547 loss: 9.85470479e-07
Iter: 548 loss: 9.84584e-07
Iter: 549 loss: 9.92783e-07
Iter: 550 loss: 9.84545522e-07
Iter: 551 loss: 9.83594e-07
Iter: 552 loss: 9.86977284e-07
Iter: 553 loss: 9.83364771e-07
Iter: 554 loss: 9.82898655e-07
Iter: 555 loss: 9.85587462e-07
Iter: 556 loss: 9.82822257e-07
Iter: 557 loss: 9.82341362e-07
Iter: 558 loss: 9.81072162e-07
Iter: 559 loss: 9.95949108e-07
Iter: 560 loss: 9.80973368e-07
Iter: 561 loss: 9.80133677e-07
Iter: 562 loss: 9.89587534e-07
Iter: 563 loss: 9.80122e-07
Iter: 564 loss: 9.79629704e-07
Iter: 565 loss: 9.8256919e-07
Iter: 566 loss: 9.79496122e-07
Iter: 567 loss: 9.78870503e-07
Iter: 568 loss: 9.7891234e-07
Iter: 569 loss: 9.78358912e-07
Iter: 570 loss: 9.77581294e-07
Iter: 571 loss: 9.76933e-07
Iter: 572 loss: 9.76747515e-07
Iter: 573 loss: 9.75704666e-07
Iter: 574 loss: 9.87841e-07
Iter: 575 loss: 9.75726e-07
Iter: 576 loss: 9.74625891e-07
Iter: 577 loss: 9.79366746e-07
Iter: 578 loss: 9.74391355e-07
Iter: 579 loss: 9.73666147e-07
Iter: 580 loss: 9.73679789e-07
Iter: 581 loss: 9.73060651e-07
Iter: 582 loss: 9.72288262e-07
Iter: 583 loss: 9.71826466e-07
Iter: 584 loss: 9.71478357e-07
Iter: 585 loss: 9.7060024e-07
Iter: 586 loss: 9.77879722e-07
Iter: 587 loss: 9.70529754e-07
Iter: 588 loss: 9.69947678e-07
Iter: 589 loss: 9.69919938e-07
Iter: 590 loss: 9.69317853e-07
Iter: 591 loss: 9.69047505e-07
Iter: 592 loss: 9.68713266e-07
Iter: 593 loss: 9.68155518e-07
Iter: 594 loss: 9.69858206e-07
Iter: 595 loss: 9.67981e-07
Iter: 596 loss: 9.67306278e-07
Iter: 597 loss: 9.69203256e-07
Iter: 598 loss: 9.67079359e-07
Iter: 599 loss: 9.66488528e-07
Iter: 600 loss: 9.65470463e-07
Iter: 601 loss: 9.90627655e-07
Iter: 602 loss: 9.65441473e-07
Iter: 603 loss: 9.64076548e-07
Iter: 604 loss: 9.7124132e-07
Iter: 605 loss: 9.63888e-07
Iter: 606 loss: 9.63258799e-07
Iter: 607 loss: 9.63244588e-07
Iter: 608 loss: 9.62614308e-07
Iter: 609 loss: 9.61411274e-07
Iter: 610 loss: 9.84416602e-07
Iter: 611 loss: 9.61411388e-07
Iter: 612 loss: 9.60599664e-07
Iter: 613 loss: 9.73288479e-07
Iter: 614 loss: 9.60595685e-07
Iter: 615 loss: 9.59826707e-07
Iter: 616 loss: 9.64304e-07
Iter: 617 loss: 9.59773274e-07
Iter: 618 loss: 9.59543513e-07
Iter: 619 loss: 9.59061481e-07
Iter: 620 loss: 9.6910594e-07
Iter: 621 loss: 9.59048e-07
Iter: 622 loss: 9.58446435e-07
Iter: 623 loss: 9.61017804e-07
Iter: 624 loss: 9.58344685e-07
Iter: 625 loss: 9.57931434e-07
Iter: 626 loss: 9.63825073e-07
Iter: 627 loss: 9.57931e-07
Iter: 628 loss: 9.57471684e-07
Iter: 629 loss: 9.57315365e-07
Iter: 630 loss: 9.57034e-07
Iter: 631 loss: 9.56621761e-07
Iter: 632 loss: 9.57035127e-07
Iter: 633 loss: 9.56497e-07
Iter: 634 loss: 9.55686346e-07
Iter: 635 loss: 9.54798679e-07
Iter: 636 loss: 9.54646907e-07
Iter: 637 loss: 9.53390668e-07
Iter: 638 loss: 9.58842065e-07
Iter: 639 loss: 9.53127824e-07
Iter: 640 loss: 9.52271648e-07
Iter: 641 loss: 9.5219491e-07
Iter: 642 loss: 9.51559912e-07
Iter: 643 loss: 9.50870628e-07
Iter: 644 loss: 9.50756487e-07
Iter: 645 loss: 9.50257288e-07
Iter: 646 loss: 9.49887578e-07
Iter: 647 loss: 9.49668902e-07
Iter: 648 loss: 9.49144578e-07
Iter: 649 loss: 9.53497306e-07
Iter: 650 loss: 9.49140258e-07
Iter: 651 loss: 9.48753097e-07
Iter: 652 loss: 9.52256926e-07
Iter: 653 loss: 9.48757929e-07
Iter: 654 loss: 9.48431193e-07
Iter: 655 loss: 9.47719343e-07
Iter: 656 loss: 9.55696237e-07
Iter: 657 loss: 9.47609806e-07
Iter: 658 loss: 9.46906539e-07
Iter: 659 loss: 9.49974265e-07
Iter: 660 loss: 9.46777561e-07
Iter: 661 loss: 9.46315822e-07
Iter: 662 loss: 9.46326793e-07
Iter: 663 loss: 9.45792522e-07
Iter: 664 loss: 9.46231353e-07
Iter: 665 loss: 9.45519e-07
Iter: 666 loss: 9.4504594e-07
Iter: 667 loss: 9.44122462e-07
Iter: 668 loss: 9.62133527e-07
Iter: 669 loss: 9.44119222e-07
Iter: 670 loss: 9.43854161e-07
Iter: 671 loss: 9.43610189e-07
Iter: 672 loss: 9.43231328e-07
Iter: 673 loss: 9.42423242e-07
Iter: 674 loss: 9.57521138e-07
Iter: 675 loss: 9.42471388e-07
Iter: 676 loss: 9.4160265e-07
Iter: 677 loss: 9.44611031e-07
Iter: 678 loss: 9.4137016e-07
Iter: 679 loss: 9.40775521e-07
Iter: 680 loss: 9.47014e-07
Iter: 681 loss: 9.40739483e-07
Iter: 682 loss: 9.40263362e-07
Iter: 683 loss: 9.42117367e-07
Iter: 684 loss: 9.40135465e-07
Iter: 685 loss: 9.39825554e-07
Iter: 686 loss: 9.3947267e-07
Iter: 687 loss: 9.39406618e-07
Iter: 688 loss: 9.38817266e-07
Iter: 689 loss: 9.46996124e-07
Iter: 690 loss: 9.38814821e-07
Iter: 691 loss: 9.38504741e-07
Iter: 692 loss: 9.38161349e-07
Iter: 693 loss: 9.38153903e-07
Iter: 694 loss: 9.37613322e-07
Iter: 695 loss: 9.37654249e-07
Iter: 696 loss: 9.37236e-07
Iter: 697 loss: 9.36621063e-07
Iter: 698 loss: 9.36568597e-07
Iter: 699 loss: 9.36172171e-07
Iter: 700 loss: 9.3535283e-07
Iter: 701 loss: 9.52315361e-07
Iter: 702 loss: 9.35384378e-07
Iter: 703 loss: 9.346453e-07
Iter: 704 loss: 9.37632649e-07
Iter: 705 loss: 9.34367051e-07
Iter: 706 loss: 9.33556066e-07
Iter: 707 loss: 9.38823e-07
Iter: 708 loss: 9.33446813e-07
Iter: 709 loss: 9.32663681e-07
Iter: 710 loss: 9.32636453e-07
Iter: 711 loss: 9.3195888e-07
Iter: 712 loss: 9.31305181e-07
Iter: 713 loss: 9.32233775e-07
Iter: 714 loss: 9.30954116e-07
Iter: 715 loss: 9.30634769e-07
Iter: 716 loss: 9.30580427e-07
Iter: 717 loss: 9.30276087e-07
Iter: 718 loss: 9.29901205e-07
Iter: 719 loss: 9.29893417e-07
Iter: 720 loss: 9.29362955e-07
Iter: 721 loss: 9.32241e-07
Iter: 722 loss: 9.29266434e-07
Iter: 723 loss: 9.28843633e-07
Iter: 724 loss: 9.32839384e-07
Iter: 725 loss: 9.28821464e-07
Iter: 726 loss: 9.28586473e-07
Iter: 727 loss: 9.28144175e-07
Iter: 728 loss: 9.34121942e-07
Iter: 729 loss: 9.28111717e-07
Iter: 730 loss: 9.27648387e-07
Iter: 731 loss: 9.27671067e-07
Iter: 732 loss: 9.27231099e-07
Iter: 733 loss: 9.27525491e-07
Iter: 734 loss: 9.26925622e-07
Iter: 735 loss: 9.2643063e-07
Iter: 736 loss: 9.25893346e-07
Iter: 737 loss: 9.25844688e-07
Iter: 738 loss: 9.2513153e-07
Iter: 739 loss: 9.29032581e-07
Iter: 740 loss: 9.25045072e-07
Iter: 741 loss: 9.24284791e-07
Iter: 742 loss: 9.28891438e-07
Iter: 743 loss: 9.24217602e-07
Iter: 744 loss: 9.23861364e-07
Iter: 745 loss: 9.23801053e-07
Iter: 746 loss: 9.23564528e-07
Iter: 747 loss: 9.23052767e-07
Iter: 748 loss: 9.24304e-07
Iter: 749 loss: 9.22854781e-07
Iter: 750 loss: 9.22550498e-07
Iter: 751 loss: 9.22556751e-07
Iter: 752 loss: 9.2227242e-07
Iter: 753 loss: 9.21729168e-07
Iter: 754 loss: 9.21703247e-07
Iter: 755 loss: 9.21431138e-07
Iter: 756 loss: 9.21425794e-07
Iter: 757 loss: 9.21086098e-07
Iter: 758 loss: 9.20647153e-07
Iter: 759 loss: 9.20622369e-07
Iter: 760 loss: 9.19995216e-07
Iter: 761 loss: 9.1995264e-07
Iter: 762 loss: 9.19523359e-07
Iter: 763 loss: 9.19130912e-07
Iter: 764 loss: 9.19038712e-07
Iter: 765 loss: 9.18543378e-07
Iter: 766 loss: 9.17522925e-07
Iter: 767 loss: 9.3407391e-07
Iter: 768 loss: 9.17486204e-07
Iter: 769 loss: 9.16803629e-07
Iter: 770 loss: 9.17967782e-07
Iter: 771 loss: 9.16490308e-07
Iter: 772 loss: 9.15748046e-07
Iter: 773 loss: 9.24339929e-07
Iter: 774 loss: 9.15783744e-07
Iter: 775 loss: 9.15209682e-07
Iter: 776 loss: 9.16517536e-07
Iter: 777 loss: 9.1502352e-07
Iter: 778 loss: 9.14660063e-07
Iter: 779 loss: 9.145852e-07
Iter: 780 loss: 9.1438e-07
Iter: 781 loss: 9.13936276e-07
Iter: 782 loss: 9.17514e-07
Iter: 783 loss: 9.13886424e-07
Iter: 784 loss: 9.13553379e-07
Iter: 785 loss: 9.15267378e-07
Iter: 786 loss: 9.13467886e-07
Iter: 787 loss: 9.13107044e-07
Iter: 788 loss: 9.13207941e-07
Iter: 789 loss: 9.12798214e-07
Iter: 790 loss: 9.12411394e-07
Iter: 791 loss: 9.17801742e-07
Iter: 792 loss: 9.12417136e-07
Iter: 793 loss: 9.12155713e-07
Iter: 794 loss: 9.11699203e-07
Iter: 795 loss: 9.1166703e-07
Iter: 796 loss: 9.11243376e-07
Iter: 797 loss: 9.13070039e-07
Iter: 798 loss: 9.11142479e-07
Iter: 799 loss: 9.10555286e-07
Iter: 800 loss: 9.13312761e-07
Iter: 801 loss: 9.10464905e-07
Iter: 802 loss: 9.10106678e-07
Iter: 803 loss: 9.09745722e-07
Iter: 804 loss: 9.09609071e-07
Iter: 805 loss: 9.09116693e-07
Iter: 806 loss: 9.09246523e-07
Iter: 807 loss: 9.08653703e-07
Iter: 808 loss: 9.0837807e-07
Iter: 809 loss: 9.08286665e-07
Iter: 810 loss: 9.08078562e-07
Iter: 811 loss: 9.07683898e-07
Iter: 812 loss: 9.15728322e-07
Iter: 813 loss: 9.07680032e-07
Iter: 814 loss: 9.07154231e-07
Iter: 815 loss: 9.08294396e-07
Iter: 816 loss: 9.06941636e-07
Iter: 817 loss: 9.06480068e-07
Iter: 818 loss: 9.10742415e-07
Iter: 819 loss: 9.06405376e-07
Iter: 820 loss: 9.0592323e-07
Iter: 821 loss: 9.07341587e-07
Iter: 822 loss: 9.05778961e-07
Iter: 823 loss: 9.05506e-07
Iter: 824 loss: 9.06871776e-07
Iter: 825 loss: 9.05387139e-07
Iter: 826 loss: 9.04951492e-07
Iter: 827 loss: 9.04601166e-07
Iter: 828 loss: 9.04489355e-07
Iter: 829 loss: 9.03856233e-07
Iter: 830 loss: 9.05534819e-07
Iter: 831 loss: 9.03709349e-07
Iter: 832 loss: 9.03387217e-07
Iter: 833 loss: 9.03381761e-07
Iter: 834 loss: 9.03032912e-07
Iter: 835 loss: 9.02432191e-07
Iter: 836 loss: 9.14310704e-07
Iter: 837 loss: 9.02424745e-07
Iter: 838 loss: 9.02010697e-07
Iter: 839 loss: 9.02887564e-07
Iter: 840 loss: 9.01836302e-07
Iter: 841 loss: 9.01382919e-07
Iter: 842 loss: 9.0532285e-07
Iter: 843 loss: 9.01343867e-07
Iter: 844 loss: 9.00956309e-07
Iter: 845 loss: 9.02502052e-07
Iter: 846 loss: 9.00868031e-07
Iter: 847 loss: 9.00635087e-07
Iter: 848 loss: 9.00045848e-07
Iter: 849 loss: 9.08555705e-07
Iter: 850 loss: 9.0001231e-07
Iter: 851 loss: 8.99430859e-07
Iter: 852 loss: 8.99403801e-07
Iter: 853 loss: 8.99034148e-07
Iter: 854 loss: 9.00645546e-07
Iter: 855 loss: 8.98956387e-07
Iter: 856 loss: 8.9863147e-07
Iter: 857 loss: 8.99330189e-07
Iter: 858 loss: 8.98500105e-07
Iter: 859 loss: 8.98160295e-07
Iter: 860 loss: 9.00260432e-07
Iter: 861 loss: 8.98113854e-07
Iter: 862 loss: 8.9782236e-07
Iter: 863 loss: 8.9723045e-07
Iter: 864 loss: 9.10824269e-07
Iter: 865 loss: 8.97218115e-07
Iter: 866 loss: 8.97041559e-07
Iter: 867 loss: 8.96925e-07
Iter: 868 loss: 8.96689414e-07
Iter: 869 loss: 8.96811343e-07
Iter: 870 loss: 8.9655947e-07
Iter: 871 loss: 8.962582e-07
Iter: 872 loss: 8.95975063e-07
Iter: 873 loss: 8.95970516e-07
Iter: 874 loss: 8.95473647e-07
Iter: 875 loss: 8.96916276e-07
Iter: 876 loss: 8.95384119e-07
Iter: 877 loss: 8.95019639e-07
Iter: 878 loss: 8.94997697e-07
Iter: 879 loss: 8.94734171e-07
Iter: 880 loss: 8.94331038e-07
Iter: 881 loss: 8.94298353e-07
Iter: 882 loss: 8.93832294e-07
Iter: 883 loss: 8.96561232e-07
Iter: 884 loss: 8.938066e-07
Iter: 885 loss: 8.93523861e-07
Iter: 886 loss: 8.96798383e-07
Iter: 887 loss: 8.93498395e-07
Iter: 888 loss: 8.93212473e-07
Iter: 889 loss: 8.93055585e-07
Iter: 890 loss: 8.92923538e-07
Iter: 891 loss: 8.92644152e-07
Iter: 892 loss: 8.97131713e-07
Iter: 893 loss: 8.92617322e-07
Iter: 894 loss: 8.92384946e-07
Iter: 895 loss: 8.92105163e-07
Iter: 896 loss: 8.92086177e-07
Iter: 897 loss: 8.91717548e-07
Iter: 898 loss: 8.93004881e-07
Iter: 899 loss: 8.91602554e-07
Iter: 900 loss: 8.91294917e-07
Iter: 901 loss: 8.96150709e-07
Iter: 902 loss: 8.91245179e-07
Iter: 903 loss: 8.91098e-07
Iter: 904 loss: 8.90606373e-07
Iter: 905 loss: 8.95752578e-07
Iter: 906 loss: 8.90558283e-07
Iter: 907 loss: 8.9006e-07
Iter: 908 loss: 8.91501e-07
Iter: 909 loss: 8.89938747e-07
Iter: 910 loss: 8.89437047e-07
Iter: 911 loss: 8.92998401e-07
Iter: 912 loss: 8.89457112e-07
Iter: 913 loss: 8.89046873e-07
Iter: 914 loss: 8.90460342e-07
Iter: 915 loss: 8.88926138e-07
Iter: 916 loss: 8.88625948e-07
Iter: 917 loss: 8.87931662e-07
Iter: 918 loss: 8.9907968e-07
Iter: 919 loss: 8.87907618e-07
Iter: 920 loss: 8.8771651e-07
Iter: 921 loss: 8.87578949e-07
Iter: 922 loss: 8.87278361e-07
Iter: 923 loss: 8.87460942e-07
Iter: 924 loss: 8.87053034e-07
Iter: 925 loss: 8.86846e-07
Iter: 926 loss: 8.88520049e-07
Iter: 927 loss: 8.86807754e-07
Iter: 928 loss: 8.86531211e-07
Iter: 929 loss: 8.87385e-07
Iter: 930 loss: 8.86430314e-07
Iter: 931 loss: 8.86236194e-07
Iter: 932 loss: 8.85781049e-07
Iter: 933 loss: 8.85772295e-07
Iter: 934 loss: 8.85718862e-07
Iter: 935 loss: 8.85557256e-07
Iter: 936 loss: 8.85362567e-07
Iter: 937 loss: 8.85138093e-07
Iter: 938 loss: 8.85112e-07
Iter: 939 loss: 8.84850351e-07
Iter: 940 loss: 8.84989504e-07
Iter: 941 loss: 8.84597682e-07
Iter: 942 loss: 8.84211317e-07
Iter: 943 loss: 8.84958411e-07
Iter: 944 loss: 8.84019414e-07
Iter: 945 loss: 8.83565463e-07
Iter: 946 loss: 8.88638283e-07
Iter: 947 loss: 8.83537837e-07
Iter: 948 loss: 8.83226335e-07
Iter: 949 loss: 8.82905795e-07
Iter: 950 loss: 8.82884592e-07
Iter: 951 loss: 8.82382778e-07
Iter: 952 loss: 8.83860707e-07
Iter: 953 loss: 8.82200084e-07
Iter: 954 loss: 8.81830374e-07
Iter: 955 loss: 8.8185476e-07
Iter: 956 loss: 8.81553e-07
Iter: 957 loss: 8.81371e-07
Iter: 958 loss: 8.81238464e-07
Iter: 959 loss: 8.80940888e-07
Iter: 960 loss: 8.80915877e-07
Iter: 961 loss: 8.80686741e-07
Iter: 962 loss: 8.80252742e-07
Iter: 963 loss: 8.8027673e-07
Iter: 964 loss: 8.80067716e-07
Iter: 965 loss: 8.80051402e-07
Iter: 966 loss: 8.79801462e-07
Iter: 967 loss: 8.8017805e-07
Iter: 968 loss: 8.79645086e-07
Iter: 969 loss: 8.79435902e-07
Iter: 970 loss: 8.7908245e-07
Iter: 971 loss: 8.88059901e-07
Iter: 972 loss: 8.79076197e-07
Iter: 973 loss: 8.78594506e-07
Iter: 974 loss: 8.80121831e-07
Iter: 975 loss: 8.78493836e-07
Iter: 976 loss: 8.78004073e-07
Iter: 977 loss: 8.81048777e-07
Iter: 978 loss: 8.77969e-07
Iter: 979 loss: 8.77605601e-07
Iter: 980 loss: 8.78851552e-07
Iter: 981 loss: 8.77449793e-07
Iter: 982 loss: 8.77201614e-07
Iter: 983 loss: 8.76719469e-07
Iter: 984 loss: 8.87301894e-07
Iter: 985 loss: 8.76745048e-07
Iter: 986 loss: 8.76394324e-07
Iter: 987 loss: 8.76373633e-07
Iter: 988 loss: 8.76015179e-07
Iter: 989 loss: 8.76251931e-07
Iter: 990 loss: 8.75855051e-07
Iter: 991 loss: 8.75595788e-07
Iter: 992 loss: 8.7800538e-07
Iter: 993 loss: 8.75595902e-07
Iter: 994 loss: 8.75408148e-07
Iter: 995 loss: 8.75136777e-07
Iter: 996 loss: 8.75122225e-07
Iter: 997 loss: 8.74815e-07
Iter: 998 loss: 8.76154843e-07
Iter: 999 loss: 8.74758655e-07
Iter: 1000 loss: 8.74475859e-07
Iter: 1001 loss: 8.78317906e-07
Iter: 1002 loss: 8.74468924e-07
Iter: 1003 loss: 8.74253487e-07
Iter: 1004 loss: 8.73745194e-07
Iter: 1005 loss: 8.78183755e-07
Iter: 1006 loss: 8.73685735e-07
Iter: 1007 loss: 8.73173065e-07
Iter: 1008 loss: 8.76380341e-07
Iter: 1009 loss: 8.73088197e-07
Iter: 1010 loss: 8.72691203e-07
Iter: 1011 loss: 8.7525666e-07
Iter: 1012 loss: 8.7264948e-07
Iter: 1013 loss: 8.72292446e-07
Iter: 1014 loss: 8.73587283e-07
Iter: 1015 loss: 8.72183136e-07
Iter: 1016 loss: 8.71874249e-07
Iter: 1017 loss: 8.7160754e-07
Iter: 1018 loss: 8.7152614e-07
Iter: 1019 loss: 8.71104419e-07
Iter: 1020 loss: 8.74193915e-07
Iter: 1021 loss: 8.71076509e-07
Iter: 1022 loss: 8.70723625e-07
Iter: 1023 loss: 8.73388046e-07
Iter: 1024 loss: 8.70715837e-07
Iter: 1025 loss: 8.70509666e-07
Iter: 1026 loss: 8.70918939e-07
Iter: 1027 loss: 8.70454357e-07
Iter: 1028 loss: 8.70182419e-07
Iter: 1029 loss: 8.71781936e-07
Iter: 1030 loss: 8.70205213e-07
Iter: 1031 loss: 8.7004878e-07
Iter: 1032 loss: 8.69649057e-07
Iter: 1033 loss: 8.74071475e-07
Iter: 1034 loss: 8.6965332e-07
Iter: 1035 loss: 8.69524058e-07
Iter: 1036 loss: 8.69410201e-07
Iter: 1037 loss: 8.69202e-07
Iter: 1038 loss: 8.68801e-07
Iter: 1039 loss: 8.75101875e-07
Iter: 1040 loss: 8.68787424e-07
Iter: 1041 loss: 8.68340067e-07
Iter: 1042 loss: 8.69565781e-07
Iter: 1043 loss: 8.68208645e-07
Iter: 1044 loss: 8.67852293e-07
Iter: 1045 loss: 8.71615043e-07
Iter: 1046 loss: 8.67817562e-07
Iter: 1047 loss: 8.67525614e-07
Iter: 1048 loss: 8.68190909e-07
Iter: 1049 loss: 8.67365202e-07
Iter: 1050 loss: 8.67119297e-07
Iter: 1051 loss: 8.66956782e-07
Iter: 1052 loss: 8.66830192e-07
Iter: 1053 loss: 8.66385221e-07
Iter: 1054 loss: 8.6774071e-07
Iter: 1055 loss: 8.66194569e-07
Iter: 1056 loss: 8.65899608e-07
Iter: 1057 loss: 8.65866639e-07
Iter: 1058 loss: 8.65619029e-07
Iter: 1059 loss: 8.65575089e-07
Iter: 1060 loss: 8.65376e-07
Iter: 1061 loss: 8.65150867e-07
Iter: 1062 loss: 8.6858438e-07
Iter: 1063 loss: 8.6517548e-07
Iter: 1064 loss: 8.64946401e-07
Iter: 1065 loss: 8.64582091e-07
Iter: 1066 loss: 8.72844339e-07
Iter: 1067 loss: 8.64603692e-07
Iter: 1068 loss: 8.64185949e-07
Iter: 1069 loss: 8.68017651e-07
Iter: 1070 loss: 8.64183505e-07
Iter: 1071 loss: 8.63750643e-07
Iter: 1072 loss: 8.64679407e-07
Iter: 1073 loss: 8.63633261e-07
Iter: 1074 loss: 8.63379341e-07
Iter: 1075 loss: 8.63174648e-07
Iter: 1076 loss: 8.63148557e-07
Iter: 1077 loss: 8.62786408e-07
Iter: 1078 loss: 8.64132176e-07
Iter: 1079 loss: 8.62708191e-07
Iter: 1080 loss: 8.62441937e-07
Iter: 1081 loss: 8.64547189e-07
Iter: 1082 loss: 8.62416528e-07
Iter: 1083 loss: 8.62259526e-07
Iter: 1084 loss: 8.62277147e-07
Iter: 1085 loss: 8.62072056e-07
Iter: 1086 loss: 8.61818876e-07
Iter: 1087 loss: 8.61563763e-07
Iter: 1088 loss: 8.61501633e-07
Iter: 1089 loss: 8.61118394e-07
Iter: 1090 loss: 8.66284722e-07
Iter: 1091 loss: 8.61109527e-07
Iter: 1092 loss: 8.60725095e-07
Iter: 1093 loss: 8.61615263e-07
Iter: 1094 loss: 8.60661316e-07
Iter: 1095 loss: 8.60403816e-07
Iter: 1096 loss: 8.61628905e-07
Iter: 1097 loss: 8.60433829e-07
Iter: 1098 loss: 8.60149385e-07
Iter: 1099 loss: 8.60085208e-07
Iter: 1100 loss: 8.59911722e-07
Iter: 1101 loss: 8.59563102e-07
Iter: 1102 loss: 8.60045475e-07
Iter: 1103 loss: 8.59423039e-07
Iter: 1104 loss: 8.5914985e-07
Iter: 1105 loss: 8.59158376e-07
Iter: 1106 loss: 8.58950784e-07
Iter: 1107 loss: 8.58607905e-07
Iter: 1108 loss: 8.65239599e-07
Iter: 1109 loss: 8.58551175e-07
Iter: 1110 loss: 8.58270312e-07
Iter: 1111 loss: 8.58895646e-07
Iter: 1112 loss: 8.58160888e-07
Iter: 1113 loss: 8.57894406e-07
Iter: 1114 loss: 8.57880821e-07
Iter: 1115 loss: 8.57724331e-07
Iter: 1116 loss: 8.57595637e-07
Iter: 1117 loss: 8.57502528e-07
Iter: 1118 loss: 8.57220073e-07
Iter: 1119 loss: 8.575322e-07
Iter: 1120 loss: 8.57027317e-07
Iter: 1121 loss: 8.56709448e-07
Iter: 1122 loss: 8.57190287e-07
Iter: 1123 loss: 8.56567908e-07
Iter: 1124 loss: 8.56189672e-07
Iter: 1125 loss: 8.61357591e-07
Iter: 1126 loss: 8.56209454e-07
Iter: 1127 loss: 8.55939334e-07
Iter: 1128 loss: 8.56095141e-07
Iter: 1129 loss: 8.55796372e-07
Iter: 1130 loss: 8.55494704e-07
Iter: 1131 loss: 8.5704653e-07
Iter: 1132 loss: 8.5548686e-07
Iter: 1133 loss: 8.55189285e-07
Iter: 1134 loss: 8.54870336e-07
Iter: 1135 loss: 8.54844075e-07
Iter: 1136 loss: 8.54704467e-07
Iter: 1137 loss: 8.54635687e-07
Iter: 1138 loss: 8.54468396e-07
Iter: 1139 loss: 8.54121e-07
Iter: 1140 loss: 8.54121254e-07
Iter: 1141 loss: 8.53823394e-07
Iter: 1142 loss: 8.53544464e-07
Iter: 1143 loss: 8.53486711e-07
Iter: 1144 loss: 8.53223696e-07
Iter: 1145 loss: 8.53195843e-07
Iter: 1146 loss: 8.52992798e-07
Iter: 1147 loss: 8.53210224e-07
Iter: 1148 loss: 8.52806465e-07
Iter: 1149 loss: 8.52550443e-07
Iter: 1150 loss: 8.5325803e-07
Iter: 1151 loss: 8.52475409e-07
Iter: 1152 loss: 8.52197104e-07
Iter: 1153 loss: 8.52409073e-07
Iter: 1154 loss: 8.52005826e-07
Iter: 1155 loss: 8.51768505e-07
Iter: 1156 loss: 8.55388919e-07
Iter: 1157 loss: 8.5174338e-07
Iter: 1158 loss: 8.5151612e-07
Iter: 1159 loss: 8.51457173e-07
Iter: 1160 loss: 8.51320578e-07
Iter: 1161 loss: 8.51061714e-07
Iter: 1162 loss: 8.53386041e-07
Iter: 1163 loss: 8.51070467e-07
Iter: 1164 loss: 8.50831384e-07
Iter: 1165 loss: 8.50920685e-07
Iter: 1166 loss: 8.50677736e-07
Iter: 1167 loss: 8.50426943e-07
Iter: 1168 loss: 8.50603556e-07
Iter: 1169 loss: 8.50256697e-07
Iter: 1170 loss: 8.49985383e-07
Iter: 1171 loss: 8.49992148e-07
Iter: 1172 loss: 8.4992746e-07
Iter: 1173 loss: 8.49658818e-07
Iter: 1174 loss: 8.50927279e-07
Iter: 1175 loss: 8.49584694e-07
Iter: 1176 loss: 8.49221294e-07
Iter: 1177 loss: 8.51742641e-07
Iter: 1178 loss: 8.49189291e-07
Iter: 1179 loss: 8.48981131e-07
Iter: 1180 loss: 8.51743e-07
Iter: 1181 loss: 8.49012906e-07
Iter: 1182 loss: 8.48861191e-07
Iter: 1183 loss: 8.48656953e-07
Iter: 1184 loss: 8.48670766e-07
Iter: 1185 loss: 8.48348577e-07
Iter: 1186 loss: 8.48841808e-07
Iter: 1187 loss: 8.48220111e-07
Iter: 1188 loss: 8.47971933e-07
Iter: 1189 loss: 8.50299898e-07
Iter: 1190 loss: 8.47967044e-07
Iter: 1191 loss: 8.47727449e-07
Iter: 1192 loss: 8.48432705e-07
Iter: 1193 loss: 8.47652132e-07
Iter: 1194 loss: 8.47479498e-07
Iter: 1195 loss: 8.47711533e-07
Iter: 1196 loss: 8.47348929e-07
Iter: 1197 loss: 8.47122578e-07
Iter: 1198 loss: 8.48289574e-07
Iter: 1199 loss: 8.47095123e-07
Iter: 1200 loss: 8.46865191e-07
Iter: 1201 loss: 8.46653791e-07
Iter: 1202 loss: 8.46574324e-07
Iter: 1203 loss: 8.46569947e-07
Iter: 1204 loss: 8.46448415e-07
Iter: 1205 loss: 8.46352634e-07
Iter: 1206 loss: 8.46145326e-07
Iter: 1207 loss: 8.50864353e-07
Iter: 1208 loss: 8.46126113e-07
Iter: 1209 loss: 8.45908744e-07
Iter: 1210 loss: 8.45796535e-07
Iter: 1211 loss: 8.45704164e-07
Iter: 1212 loss: 8.45426712e-07
Iter: 1213 loss: 8.47359047e-07
Iter: 1214 loss: 8.45355373e-07
Iter: 1215 loss: 8.45212753e-07
Iter: 1216 loss: 8.45196723e-07
Iter: 1217 loss: 8.45079626e-07
Iter: 1218 loss: 8.44807914e-07
Iter: 1219 loss: 8.49319065e-07
Iter: 1220 loss: 8.44767271e-07
Iter: 1221 loss: 8.44498118e-07
Iter: 1222 loss: 8.45734e-07
Iter: 1223 loss: 8.44476403e-07
Iter: 1224 loss: 8.44230158e-07
Iter: 1225 loss: 8.46032378e-07
Iter: 1226 loss: 8.44236411e-07
Iter: 1227 loss: 8.44054853e-07
Iter: 1228 loss: 8.44377496e-07
Iter: 1229 loss: 8.43970724e-07
Iter: 1230 loss: 8.43756538e-07
Iter: 1231 loss: 8.44510623e-07
Iter: 1232 loss: 8.43752048e-07
Iter: 1233 loss: 8.43562702e-07
Iter: 1234 loss: 8.43590726e-07
Iter: 1235 loss: 8.43482553e-07
Iter: 1236 loss: 8.43252224e-07
Iter: 1237 loss: 8.44185593e-07
Iter: 1238 loss: 8.43244607e-07
Iter: 1239 loss: 8.43103635e-07
Iter: 1240 loss: 8.4416854e-07
Iter: 1241 loss: 8.43075554e-07
Iter: 1242 loss: 8.42989778e-07
Iter: 1243 loss: 8.42779514e-07
Iter: 1244 loss: 8.46406351e-07
Iter: 1245 loss: 8.42763029e-07
Iter: 1246 loss: 8.425244e-07
Iter: 1247 loss: 8.42766383e-07
Iter: 1248 loss: 8.42367399e-07
Iter: 1249 loss: 8.42208237e-07
Iter: 1250 loss: 8.42191753e-07
Iter: 1251 loss: 8.41964265e-07
Iter: 1252 loss: 8.42014288e-07
Iter: 1253 loss: 8.41841882e-07
Iter: 1254 loss: 8.41611268e-07
Iter: 1255 loss: 8.41898384e-07
Iter: 1256 loss: 8.41472627e-07
Iter: 1257 loss: 8.41290216e-07
Iter: 1258 loss: 8.41977283e-07
Iter: 1259 loss: 8.41211261e-07
Iter: 1260 loss: 8.40908854e-07
Iter: 1261 loss: 8.43189355e-07
Iter: 1262 loss: 8.40960183e-07
Iter: 1263 loss: 8.40750772e-07
Iter: 1264 loss: 8.4092926e-07
Iter: 1265 loss: 8.40714e-07
Iter: 1266 loss: 8.40524e-07
Iter: 1267 loss: 8.41191365e-07
Iter: 1268 loss: 8.40448138e-07
Iter: 1269 loss: 8.40284883e-07
Iter: 1270 loss: 8.40252e-07
Iter: 1271 loss: 8.40146e-07
Iter: 1272 loss: 8.39973268e-07
Iter: 1273 loss: 8.39987479e-07
Iter: 1274 loss: 8.39806148e-07
Iter: 1275 loss: 8.3956877e-07
Iter: 1276 loss: 8.39523466e-07
Iter: 1277 loss: 8.39272218e-07
Iter: 1278 loss: 8.39147447e-07
Iter: 1279 loss: 8.39048596e-07
Iter: 1280 loss: 8.38692301e-07
Iter: 1281 loss: 8.41022086e-07
Iter: 1282 loss: 8.38743802e-07
Iter: 1283 loss: 8.38498863e-07
Iter: 1284 loss: 8.4138054e-07
Iter: 1285 loss: 8.38521601e-07
Iter: 1286 loss: 8.3835414e-07
Iter: 1287 loss: 8.379875e-07
Iter: 1288 loss: 8.4382873e-07
Iter: 1289 loss: 8.38010351e-07
Iter: 1290 loss: 8.37694927e-07
Iter: 1291 loss: 8.38661094e-07
Iter: 1292 loss: 8.3762194e-07
Iter: 1293 loss: 8.37546509e-07
Iter: 1294 loss: 8.37515302e-07
Iter: 1295 loss: 8.37347955e-07
Iter: 1296 loss: 8.37294181e-07
Iter: 1297 loss: 8.37218522e-07
Iter: 1298 loss: 8.37018e-07
Iter: 1299 loss: 8.376457e-07
Iter: 1300 loss: 8.36962897e-07
Iter: 1301 loss: 8.36746e-07
Iter: 1302 loss: 8.37346875e-07
Iter: 1303 loss: 8.36677714e-07
Iter: 1304 loss: 8.36558058e-07
Iter: 1305 loss: 8.36683967e-07
Iter: 1306 loss: 8.3639145e-07
Iter: 1307 loss: 8.36274523e-07
Iter: 1308 loss: 8.36278275e-07
Iter: 1309 loss: 8.36196421e-07
Iter: 1310 loss: 8.35892649e-07
Iter: 1311 loss: 8.37246944e-07
Iter: 1312 loss: 8.35826029e-07
Iter: 1313 loss: 8.35467e-07
Iter: 1314 loss: 8.37770756e-07
Iter: 1315 loss: 8.35381741e-07
Iter: 1316 loss: 8.35226956e-07
Iter: 1317 loss: 8.36404581e-07
Iter: 1318 loss: 8.35224682e-07
Iter: 1319 loss: 8.35065862e-07
Iter: 1320 loss: 8.35634e-07
Iter: 1321 loss: 8.34995319e-07
Iter: 1322 loss: 8.34810464e-07
Iter: 1323 loss: 8.34602702e-07
Iter: 1324 loss: 8.34583204e-07
Iter: 1325 loss: 8.34356797e-07
Iter: 1326 loss: 8.36892525e-07
Iter: 1327 loss: 8.34367427e-07
Iter: 1328 loss: 8.34206162e-07
Iter: 1329 loss: 8.34444165e-07
Iter: 1330 loss: 8.34101456e-07
Iter: 1331 loss: 8.33856234e-07
Iter: 1332 loss: 8.34102e-07
Iter: 1333 loss: 8.33667059e-07
Iter: 1334 loss: 8.33482147e-07
Iter: 1335 loss: 8.35434321e-07
Iter: 1336 loss: 8.33467084e-07
Iter: 1337 loss: 8.33254944e-07
Iter: 1338 loss: 8.33212823e-07
Iter: 1339 loss: 8.33064746e-07
Iter: 1340 loss: 8.3284192e-07
Iter: 1341 loss: 8.3437169e-07
Iter: 1342 loss: 8.32835326e-07
Iter: 1343 loss: 8.32677472e-07
Iter: 1344 loss: 8.34144146e-07
Iter: 1345 loss: 8.32642513e-07
Iter: 1346 loss: 8.32561511e-07
Iter: 1347 loss: 8.32323678e-07
Iter: 1348 loss: 8.34764876e-07
Iter: 1349 loss: 8.32321803e-07
Iter: 1350 loss: 8.32111255e-07
Iter: 1351 loss: 8.33506e-07
Iter: 1352 loss: 8.32082378e-07
Iter: 1353 loss: 8.31934585e-07
Iter: 1354 loss: 8.32940145e-07
Iter: 1355 loss: 8.31925718e-07
Iter: 1356 loss: 8.31716306e-07
Iter: 1357 loss: 8.31919237e-07
Iter: 1358 loss: 8.31661509e-07
Iter: 1359 loss: 8.31465968e-07
Iter: 1360 loss: 8.31354e-07
Iter: 1361 loss: 8.31244e-07
Iter: 1362 loss: 8.31071929e-07
Iter: 1363 loss: 8.33556555e-07
Iter: 1364 loss: 8.31059083e-07
Iter: 1365 loss: 8.30885938e-07
Iter: 1366 loss: 8.31008379e-07
Iter: 1367 loss: 8.30744852e-07
Iter: 1368 loss: 8.30455917e-07
Iter: 1369 loss: 8.31499676e-07
Iter: 1370 loss: 8.30466888e-07
Iter: 1371 loss: 8.30246677e-07
Iter: 1372 loss: 8.30904241e-07
Iter: 1373 loss: 8.3014254e-07
Iter: 1374 loss: 8.29986334e-07
Iter: 1375 loss: 8.29994519e-07
Iter: 1376 loss: 8.29826718e-07
Iter: 1377 loss: 8.29691089e-07
Iter: 1378 loss: 8.29718147e-07
Iter: 1379 loss: 8.29544433e-07
Iter: 1380 loss: 8.29356168e-07
Iter: 1381 loss: 8.29357191e-07
Iter: 1382 loss: 8.29137093e-07
Iter: 1383 loss: 8.29349688e-07
Iter: 1384 loss: 8.29022554e-07
Iter: 1385 loss: 8.28811437e-07
Iter: 1386 loss: 8.2905558e-07
Iter: 1387 loss: 8.28712302e-07
Iter: 1388 loss: 8.28560246e-07
Iter: 1389 loss: 8.28540067e-07
Iter: 1390 loss: 8.28354e-07
Iter: 1391 loss: 8.28097541e-07
Iter: 1392 loss: 8.2811431e-07
Iter: 1393 loss: 8.27768304e-07
Iter: 1394 loss: 8.29172222e-07
Iter: 1395 loss: 8.27657118e-07
Iter: 1396 loss: 8.2746817e-07
Iter: 1397 loss: 8.30289082e-07
Iter: 1398 loss: 8.27477209e-07
Iter: 1399 loss: 8.27232725e-07
Iter: 1400 loss: 8.26932194e-07
Iter: 1401 loss: 8.26971132e-07
Iter: 1402 loss: 8.26675546e-07
Iter: 1403 loss: 8.26672704e-07
Iter: 1404 loss: 8.26515816e-07
Iter: 1405 loss: 8.26505527e-07
Iter: 1406 loss: 8.26377e-07
Iter: 1407 loss: 8.2621159e-07
Iter: 1408 loss: 8.27267229e-07
Iter: 1409 loss: 8.26183452e-07
Iter: 1410 loss: 8.2602935e-07
Iter: 1411 loss: 8.27045483e-07
Iter: 1412 loss: 8.25953634e-07
Iter: 1413 loss: 8.2584603e-07
Iter: 1414 loss: 8.25657935e-07
Iter: 1415 loss: 8.30742181e-07
Iter: 1416 loss: 8.25673283e-07
Iter: 1417 loss: 8.25428174e-07
Iter: 1418 loss: 8.2643669e-07
Iter: 1419 loss: 8.2537349e-07
Iter: 1420 loss: 8.25200232e-07
Iter: 1421 loss: 8.25665722e-07
Iter: 1422 loss: 8.25149868e-07
Iter: 1423 loss: 8.24905101e-07
Iter: 1424 loss: 8.26201074e-07
Iter: 1425 loss: 8.24876111e-07
Iter: 1426 loss: 8.24685458e-07
Iter: 1427 loss: 8.24437052e-07
Iter: 1428 loss: 8.24431538e-07
Iter: 1429 loss: 8.24163862e-07
Iter: 1430 loss: 8.27703843e-07
Iter: 1431 loss: 8.2413419e-07
Iter: 1432 loss: 8.23923642e-07
Iter: 1433 loss: 8.25433403e-07
Iter: 1434 loss: 8.23888e-07
Iter: 1435 loss: 8.23701612e-07
Iter: 1436 loss: 8.23608616e-07
Iter: 1437 loss: 8.23564562e-07
Iter: 1438 loss: 8.23319283e-07
Iter: 1439 loss: 8.26033101e-07
Iter: 1440 loss: 8.23324626e-07
Iter: 1441 loss: 8.23176094e-07
Iter: 1442 loss: 8.23145058e-07
Iter: 1443 loss: 8.23016421e-07
Iter: 1444 loss: 8.22907509e-07
Iter: 1445 loss: 8.22905577e-07
Iter: 1446 loss: 8.22810762e-07
Iter: 1447 loss: 8.22610559e-07
Iter: 1448 loss: 8.264538e-07
Iter: 1449 loss: 8.22589811e-07
Iter: 1450 loss: 8.22342486e-07
Iter: 1451 loss: 8.22737604e-07
Iter: 1452 loss: 8.22203162e-07
Iter: 1453 loss: 8.22036384e-07
Iter: 1454 loss: 8.2251745e-07
Iter: 1455 loss: 8.21944923e-07
Iter: 1456 loss: 8.21762683e-07
Iter: 1457 loss: 8.21795481e-07
Iter: 1458 loss: 8.21615686e-07
Iter: 1459 loss: 8.21736251e-07
Iter: 1460 loss: 8.21568506e-07
Iter: 1461 loss: 8.21381718e-07
Iter: 1462 loss: 8.21262347e-07
Iter: 1463 loss: 8.21181857e-07
Iter: 1464 loss: 8.21052595e-07
Iter: 1465 loss: 8.2105754e-07
Iter: 1466 loss: 8.20910714e-07
Iter: 1467 loss: 8.20827722e-07
Iter: 1468 loss: 8.20836362e-07
Iter: 1469 loss: 8.2063e-07
Iter: 1470 loss: 8.21491426e-07
Iter: 1471 loss: 8.20555499e-07
Iter: 1472 loss: 8.20364e-07
Iter: 1473 loss: 8.20766104e-07
Iter: 1474 loss: 8.202515e-07
Iter: 1475 loss: 8.20118203e-07
Iter: 1476 loss: 8.21407752e-07
Iter: 1477 loss: 8.20123148e-07
Iter: 1478 loss: 8.19980073e-07
Iter: 1479 loss: 8.19894524e-07
Iter: 1480 loss: 8.19786408e-07
Iter: 1481 loss: 8.19603201e-07
Iter: 1482 loss: 8.19470472e-07
Iter: 1483 loss: 8.19382478e-07
Iter: 1484 loss: 8.19116963e-07
Iter: 1485 loss: 8.20503828e-07
Iter: 1486 loss: 8.18993897e-07
Iter: 1487 loss: 8.18809497e-07
Iter: 1488 loss: 8.20636615e-07
Iter: 1489 loss: 8.18810747e-07
Iter: 1490 loss: 8.18539945e-07
Iter: 1491 loss: 8.18945296e-07
Iter: 1492 loss: 8.18472131e-07
Iter: 1493 loss: 8.18213095e-07
Iter: 1494 loss: 8.18708713e-07
Iter: 1495 loss: 8.18163926e-07
Iter: 1496 loss: 8.17972875e-07
Iter: 1497 loss: 8.19323816e-07
Iter: 1498 loss: 8.17982936e-07
Iter: 1499 loss: 8.17823832e-07
Iter: 1500 loss: 8.17961507e-07
Iter: 1501 loss: 8.17727596e-07
Iter: 1502 loss: 8.17569969e-07
Iter: 1503 loss: 8.1806968e-07
Iter: 1504 loss: 8.17503292e-07
Iter: 1505 loss: 8.17341913e-07
Iter: 1506 loss: 8.17801208e-07
Iter: 1507 loss: 8.17306784e-07
Iter: 1508 loss: 8.1717468e-07
Iter: 1509 loss: 8.17783871e-07
Iter: 1510 loss: 8.17127045e-07
Iter: 1511 loss: 8.17014438e-07
Iter: 1512 loss: 8.17260457e-07
Iter: 1513 loss: 8.16883528e-07
Iter: 1514 loss: 8.16743693e-07
Iter: 1515 loss: 8.16515353e-07
Iter: 1516 loss: 8.16519844e-07
Iter: 1517 loss: 8.16269164e-07
Iter: 1518 loss: 8.16614374e-07
Iter: 1519 loss: 8.16121144e-07
Iter: 1520 loss: 8.15896669e-07
Iter: 1521 loss: 8.18845592e-07
Iter: 1522 loss: 8.15853127e-07
Iter: 1523 loss: 8.15662e-07
Iter: 1524 loss: 8.16878355e-07
Iter: 1525 loss: 8.15662077e-07
Iter: 1526 loss: 8.15473641e-07
Iter: 1527 loss: 8.15297881e-07
Iter: 1528 loss: 8.15252918e-07
Iter: 1529 loss: 8.15026169e-07
Iter: 1530 loss: 8.17211458e-07
Iter: 1531 loss: 8.15072212e-07
Iter: 1532 loss: 8.14828e-07
Iter: 1533 loss: 8.15464e-07
Iter: 1534 loss: 8.14834266e-07
Iter: 1535 loss: 8.14666464e-07
Iter: 1536 loss: 8.14811e-07
Iter: 1537 loss: 8.14594159e-07
Iter: 1538 loss: 8.1443676e-07
Iter: 1539 loss: 8.15114049e-07
Iter: 1540 loss: 8.14403791e-07
Iter: 1541 loss: 8.14246e-07
Iter: 1542 loss: 8.14216151e-07
Iter: 1543 loss: 8.14108e-07
Iter: 1544 loss: 8.1387941e-07
Iter: 1545 loss: 8.13918291e-07
Iter: 1546 loss: 8.13818076e-07
Iter: 1547 loss: 8.13626571e-07
Iter: 1548 loss: 8.17437751e-07
Iter: 1549 loss: 8.13640895e-07
Iter: 1550 loss: 8.13326835e-07
Iter: 1551 loss: 8.13412043e-07
Iter: 1552 loss: 8.13170914e-07
Iter: 1553 loss: 8.12949509e-07
Iter: 1554 loss: 8.14206601e-07
Iter: 1555 loss: 8.12858445e-07
Iter: 1556 loss: 8.12737312e-07
Iter: 1557 loss: 8.12716053e-07
Iter: 1558 loss: 8.12575536e-07
Iter: 1559 loss: 8.12427061e-07
Iter: 1560 loss: 8.12472e-07
Iter: 1561 loss: 8.12210715e-07
Iter: 1562 loss: 8.1291148e-07
Iter: 1563 loss: 8.12167e-07
Iter: 1564 loss: 8.12048597e-07
Iter: 1565 loss: 8.12054395e-07
Iter: 1566 loss: 8.11950372e-07
Iter: 1567 loss: 8.11874429e-07
Iter: 1568 loss: 8.11825828e-07
Iter: 1569 loss: 8.11656946e-07
Iter: 1570 loss: 8.13154884e-07
Iter: 1571 loss: 8.1170225e-07
Iter: 1572 loss: 8.11572249e-07
Iter: 1573 loss: 8.1155406e-07
Iter: 1574 loss: 8.11487098e-07
Iter: 1575 loss: 8.11305199e-07
Iter: 1576 loss: 8.12824965e-07
Iter: 1577 loss: 8.11295877e-07
Iter: 1578 loss: 8.11192535e-07
Iter: 1579 loss: 8.11038603e-07
Iter: 1580 loss: 8.10997278e-07
Iter: 1581 loss: 8.10765414e-07
Iter: 1582 loss: 8.10706354e-07
Iter: 1583 loss: 8.10595793e-07
Iter: 1584 loss: 8.10268261e-07
Iter: 1585 loss: 8.11024847e-07
Iter: 1586 loss: 8.10163726e-07
Iter: 1587 loss: 8.09880362e-07
Iter: 1588 loss: 8.11531095e-07
Iter: 1589 loss: 8.09828407e-07
Iter: 1590 loss: 8.09591086e-07
Iter: 1591 loss: 8.11903305e-07
Iter: 1592 loss: 8.0958614e-07
Iter: 1593 loss: 8.09379344e-07
Iter: 1594 loss: 8.09166067e-07
Iter: 1595 loss: 8.09166352e-07
Iter: 1596 loss: 8.09016967e-07
Iter: 1597 loss: 8.08956031e-07
Iter: 1598 loss: 8.08883669e-07
Iter: 1599 loss: 8.08910954e-07
Iter: 1600 loss: 8.08793345e-07
Iter: 1601 loss: 8.0864794e-07
Iter: 1602 loss: 8.0903294e-07
Iter: 1603 loss: 8.08616051e-07
Iter: 1604 loss: 8.08453308e-07
Iter: 1605 loss: 8.08774644e-07
Iter: 1606 loss: 8.08398e-07
Iter: 1607 loss: 8.0832433e-07
Iter: 1608 loss: 8.09184314e-07
Iter: 1609 loss: 8.08293521e-07
Iter: 1610 loss: 8.0812174e-07
Iter: 1611 loss: 8.0805421e-07
Iter: 1612 loss: 8.07996571e-07
Iter: 1613 loss: 8.07870549e-07
Iter: 1614 loss: 8.07945469e-07
Iter: 1615 loss: 8.0779165e-07
Iter: 1616 loss: 8.07606e-07
Iter: 1617 loss: 8.07857816e-07
Iter: 1618 loss: 8.07500783e-07
Iter: 1619 loss: 8.0729626e-07
Iter: 1620 loss: 8.07877939e-07
Iter: 1621 loss: 8.07245783e-07
Iter: 1622 loss: 8.07080482e-07
Iter: 1623 loss: 8.09368316e-07
Iter: 1624 loss: 8.07098e-07
Iter: 1625 loss: 8.068954e-07
Iter: 1626 loss: 8.06813887e-07
Iter: 1627 loss: 8.0678592e-07
Iter: 1628 loss: 8.06609194e-07
Iter: 1629 loss: 8.08050061e-07
Iter: 1630 loss: 8.06598678e-07
Iter: 1631 loss: 8.06418825e-07
Iter: 1632 loss: 8.06698949e-07
Iter: 1633 loss: 8.06363e-07
Iter: 1634 loss: 8.06203673e-07
Iter: 1635 loss: 8.06387106e-07
Iter: 1636 loss: 8.06160358e-07
Iter: 1637 loss: 8.05896946e-07
Iter: 1638 loss: 8.0669497e-07
Iter: 1639 loss: 8.05897571e-07
Iter: 1640 loss: 8.05698278e-07
Iter: 1641 loss: 8.06228e-07
Iter: 1642 loss: 8.0564962e-07
Iter: 1643 loss: 8.05452146e-07
Iter: 1644 loss: 8.05842e-07
Iter: 1645 loss: 8.05332718e-07
Iter: 1646 loss: 8.0514809e-07
Iter: 1647 loss: 8.05117111e-07
Iter: 1648 loss: 8.04964e-07
Iter: 1649 loss: 8.04719605e-07
Iter: 1650 loss: 8.05095397e-07
Iter: 1651 loss: 8.04653496e-07
Iter: 1652 loss: 8.04493766e-07
Iter: 1653 loss: 8.05974537e-07
Iter: 1654 loss: 8.04443403e-07
Iter: 1655 loss: 8.04333354e-07
Iter: 1656 loss: 8.05660079e-07
Iter: 1657 loss: 8.04329432e-07
Iter: 1658 loss: 8.04216427e-07
Iter: 1659 loss: 8.04250476e-07
Iter: 1660 loss: 8.04102115e-07
Iter: 1661 loss: 8.03957e-07
Iter: 1662 loss: 8.04207389e-07
Iter: 1663 loss: 8.03897592e-07
Iter: 1664 loss: 8.03766625e-07
Iter: 1665 loss: 8.0469863e-07
Iter: 1666 loss: 8.0372547e-07
Iter: 1667 loss: 8.03595242e-07
Iter: 1668 loss: 8.03576768e-07
Iter: 1669 loss: 8.03526291e-07
Iter: 1670 loss: 8.03286468e-07
Iter: 1671 loss: 8.04329829e-07
Iter: 1672 loss: 8.03288856e-07
Iter: 1673 loss: 8.03113e-07
Iter: 1674 loss: 8.03500541e-07
Iter: 1675 loss: 8.03045054e-07
Iter: 1676 loss: 8.02854288e-07
Iter: 1677 loss: 8.03927151e-07
Iter: 1678 loss: 8.0282382e-07
Iter: 1679 loss: 8.02649822e-07
Iter: 1680 loss: 8.02479462e-07
Iter: 1681 loss: 8.02444617e-07
Iter: 1682 loss: 8.02259e-07
Iter: 1683 loss: 8.02630154e-07
Iter: 1684 loss: 8.02154204e-07
Iter: 1685 loss: 8.0189443e-07
Iter: 1686 loss: 8.0280364e-07
Iter: 1687 loss: 8.01848842e-07
Iter: 1688 loss: 8.01633064e-07
Iter: 1689 loss: 8.03568128e-07
Iter: 1690 loss: 8.01661429e-07
Iter: 1691 loss: 8.01527e-07
Iter: 1692 loss: 8.018269e-07
Iter: 1693 loss: 8.01421777e-07
Iter: 1694 loss: 8.01273245e-07
Iter: 1695 loss: 8.01306669e-07
Iter: 1696 loss: 8.0118059e-07
Iter: 1697 loss: 8.01012561e-07
Iter: 1698 loss: 8.01004603e-07
Iter: 1699 loss: 8.00911664e-07
Iter: 1700 loss: 8.00747671e-07
Iter: 1701 loss: 8.00741e-07
Iter: 1702 loss: 8.00525754e-07
Iter: 1703 loss: 8.0182889e-07
Iter: 1704 loss: 8.00506939e-07
Iter: 1705 loss: 8.00337261e-07
Iter: 1706 loss: 8.00370231e-07
Iter: 1707 loss: 8.00204703e-07
Iter: 1708 loss: 8.00044e-07
Iter: 1709 loss: 8.00054579e-07
Iter: 1710 loss: 7.99930433e-07
Iter: 1711 loss: 7.99715e-07
Iter: 1712 loss: 7.99711529e-07
Iter: 1713 loss: 7.99541453e-07
Iter: 1714 loss: 8.00006887e-07
Iter: 1715 loss: 7.99495126e-07
Iter: 1716 loss: 7.99222278e-07
Iter: 1717 loss: 7.99765303e-07
Iter: 1718 loss: 7.99125473e-07
Iter: 1719 loss: 7.98944086e-07
Iter: 1720 loss: 8.00669227e-07
Iter: 1721 loss: 7.98969836e-07
Iter: 1722 loss: 7.98810447e-07
Iter: 1723 loss: 7.99486202e-07
Iter: 1724 loss: 7.98797373e-07
Iter: 1725 loss: 7.98660608e-07
Iter: 1726 loss: 7.98589326e-07
Iter: 1727 loss: 7.98551355e-07
Iter: 1728 loss: 7.98375481e-07
Iter: 1729 loss: 8.00180715e-07
Iter: 1730 loss: 7.98411747e-07
Iter: 1731 loss: 7.98260544e-07
Iter: 1732 loss: 7.98266569e-07
Iter: 1733 loss: 7.98142139e-07
Iter: 1734 loss: 7.97972234e-07
Iter: 1735 loss: 7.98378323e-07
Iter: 1736 loss: 7.97960467e-07
Iter: 1737 loss: 7.9772758e-07
Iter: 1738 loss: 7.98384747e-07
Iter: 1739 loss: 7.9767392e-07
Iter: 1740 loss: 7.97550683e-07
Iter: 1741 loss: 7.98363487e-07
Iter: 1742 loss: 7.97585699e-07
Iter: 1743 loss: 7.97421308e-07
Iter: 1744 loss: 7.9727738e-07
Iter: 1745 loss: 7.9720337e-07
Iter: 1746 loss: 7.96986058e-07
Iter: 1747 loss: 7.9720661e-07
Iter: 1748 loss: 7.96888628e-07
Iter: 1749 loss: 7.96697691e-07
Iter: 1750 loss: 7.97260952e-07
Iter: 1751 loss: 7.96628797e-07
Iter: 1752 loss: 7.96423819e-07
Iter: 1753 loss: 7.97220764e-07
Iter: 1754 loss: 7.96393522e-07
Iter: 1755 loss: 7.96213612e-07
Iter: 1756 loss: 7.98015776e-07
Iter: 1757 loss: 7.96203608e-07
Iter: 1758 loss: 7.96096742e-07
Iter: 1759 loss: 7.96175073e-07
Iter: 1760 loss: 7.95993742e-07
Iter: 1761 loss: 7.95843562e-07
Iter: 1762 loss: 7.96058202e-07
Iter: 1763 loss: 7.95816163e-07
Iter: 1764 loss: 7.95606184e-07
Iter: 1765 loss: 7.96495669e-07
Iter: 1766 loss: 7.95590154e-07
Iter: 1767 loss: 7.95483913e-07
Iter: 1768 loss: 7.95428093e-07
Iter: 1769 loss: 7.9532623e-07
Iter: 1770 loss: 7.95178607e-07
Iter: 1771 loss: 7.96522727e-07
Iter: 1772 loss: 7.95180654e-07
Iter: 1773 loss: 7.9503053e-07
Iter: 1774 loss: 7.95221695e-07
Iter: 1775 loss: 7.94982498e-07
Iter: 1776 loss: 7.94803213e-07
Iter: 1777 loss: 7.95534447e-07
Iter: 1778 loss: 7.9478707e-07
Iter: 1779 loss: 7.94655762e-07
Iter: 1780 loss: 7.94409971e-07
Iter: 1781 loss: 7.94424466e-07
Iter: 1782 loss: 7.94138089e-07
Iter: 1783 loss: 7.94938785e-07
Iter: 1784 loss: 7.94115635e-07
Iter: 1785 loss: 7.93881895e-07
Iter: 1786 loss: 7.95280471e-07
Iter: 1787 loss: 7.938811e-07
Iter: 1788 loss: 7.93741151e-07
Iter: 1789 loss: 7.94868924e-07
Iter: 1790 loss: 7.93744334e-07
Iter: 1791 loss: 7.93618597e-07
Iter: 1792 loss: 7.93672939e-07
Iter: 1793 loss: 7.93493939e-07
Iter: 1794 loss: 7.93426807e-07
Iter: 1795 loss: 7.93607171e-07
Iter: 1796 loss: 7.93352342e-07
Iter: 1797 loss: 7.93199433e-07
Iter: 1798 loss: 7.93215065e-07
Iter: 1799 loss: 7.93133e-07
Iter: 1800 loss: 7.9293693e-07
Iter: 1801 loss: 7.92972287e-07
Iter: 1802 loss: 7.9282222e-07
Iter: 1803 loss: 7.94049924e-07
Iter: 1804 loss: 7.92800734e-07
Iter: 1805 loss: 7.926335e-07
Iter: 1806 loss: 7.92817048e-07
Iter: 1807 loss: 7.92520382e-07
Iter: 1808 loss: 7.92391688e-07
Iter: 1809 loss: 7.93948061e-07
Iter: 1810 loss: 7.92416699e-07
Iter: 1811 loss: 7.92326091e-07
Iter: 1812 loss: 7.92048127e-07
Iter: 1813 loss: 7.9632548e-07
Iter: 1814 loss: 7.92052106e-07
Iter: 1815 loss: 7.91881234e-07
Iter: 1816 loss: 7.92526066e-07
Iter: 1817 loss: 7.91777e-07
Iter: 1818 loss: 7.91577691e-07
Iter: 1819 loss: 7.91746459e-07
Iter: 1820 loss: 7.91512548e-07
Iter: 1821 loss: 7.91255502e-07
Iter: 1822 loss: 7.92954552e-07
Iter: 1823 loss: 7.91265393e-07
Iter: 1824 loss: 7.91029606e-07
Iter: 1825 loss: 7.92091726e-07
Iter: 1826 loss: 7.91000957e-07
Iter: 1827 loss: 7.90861634e-07
Iter: 1828 loss: 7.90797458e-07
Iter: 1829 loss: 7.90715035e-07
Iter: 1830 loss: 7.90494369e-07
Iter: 1831 loss: 7.92213e-07
Iter: 1832 loss: 7.90484364e-07
Iter: 1833 loss: 7.90318779e-07
Iter: 1834 loss: 7.90654099e-07
Iter: 1835 loss: 7.90263073e-07
Iter: 1836 loss: 7.90119316e-07
Iter: 1837 loss: 7.90276e-07
Iter: 1838 loss: 7.90028082e-07
Iter: 1839 loss: 7.89866135e-07
Iter: 1840 loss: 7.91308935e-07
Iter: 1841 loss: 7.89880289e-07
Iter: 1842 loss: 7.89772287e-07
Iter: 1843 loss: 7.90137165e-07
Iter: 1844 loss: 7.89752107e-07
Iter: 1845 loss: 7.8969822e-07
Iter: 1846 loss: 7.89551052e-07
Iter: 1847 loss: 7.89520413e-07
Iter: 1848 loss: 7.89348064e-07
Iter: 1849 loss: 7.89431283e-07
Iter: 1850 loss: 7.89218404e-07
Iter: 1851 loss: 7.89058276e-07
Iter: 1852 loss: 7.89624e-07
Iter: 1853 loss: 7.88957664e-07
Iter: 1854 loss: 7.88813452e-07
Iter: 1855 loss: 7.89363412e-07
Iter: 1856 loss: 7.88766044e-07
Iter: 1857 loss: 7.88585226e-07
Iter: 1858 loss: 7.89841465e-07
Iter: 1859 loss: 7.88563966e-07
Iter: 1860 loss: 7.88383716e-07
Iter: 1861 loss: 7.88336251e-07
Iter: 1862 loss: 7.88231091e-07
Iter: 1863 loss: 7.88088187e-07
Iter: 1864 loss: 7.90452191e-07
Iter: 1865 loss: 7.88088641e-07
Iter: 1866 loss: 7.87935846e-07
Iter: 1867 loss: 7.8832818e-07
Iter: 1868 loss: 7.87940735e-07
Iter: 1869 loss: 7.87797376e-07
Iter: 1870 loss: 7.87665726e-07
Iter: 1871 loss: 7.87612464e-07
Iter: 1872 loss: 7.87469673e-07
Iter: 1873 loss: 7.90002161e-07
Iter: 1874 loss: 7.87469503e-07
Iter: 1875 loss: 7.87382476e-07
Iter: 1876 loss: 7.8745245e-07
Iter: 1877 loss: 7.87333192e-07
Iter: 1878 loss: 7.87174713e-07
Iter: 1879 loss: 7.87363831e-07
Iter: 1880 loss: 7.87093825e-07
Iter: 1881 loss: 7.86904e-07
Iter: 1882 loss: 7.86838143e-07
Iter: 1883 loss: 7.86754754e-07
Iter: 1884 loss: 7.86566943e-07
Iter: 1885 loss: 7.86991052e-07
Iter: 1886 loss: 7.86460248e-07
Iter: 1887 loss: 7.86211103e-07
Iter: 1888 loss: 7.86964165e-07
Iter: 1889 loss: 7.8612868e-07
Iter: 1890 loss: 7.85915233e-07
Iter: 1891 loss: 7.87851263e-07
Iter: 1892 loss: 7.85936209e-07
Iter: 1893 loss: 7.85748398e-07
Iter: 1894 loss: 7.85931547e-07
Iter: 1895 loss: 7.85595091e-07
Iter: 1896 loss: 7.8541342e-07
Iter: 1897 loss: 7.85856969e-07
Iter: 1898 loss: 7.85343389e-07
Iter: 1899 loss: 7.85164275e-07
Iter: 1900 loss: 7.87197735e-07
Iter: 1901 loss: 7.85197244e-07
Iter: 1902 loss: 7.85084239e-07
Iter: 1903 loss: 7.84986469e-07
Iter: 1904 loss: 7.84942927e-07
Iter: 1905 loss: 7.84828273e-07
Iter: 1906 loss: 7.86253736e-07
Iter: 1907 loss: 7.8481969e-07
Iter: 1908 loss: 7.84677e-07
Iter: 1909 loss: 7.84720385e-07
Iter: 1910 loss: 7.84622159e-07
Iter: 1911 loss: 7.84490339e-07
Iter: 1912 loss: 7.85565248e-07
Iter: 1913 loss: 7.84497445e-07
Iter: 1914 loss: 7.84410702e-07
Iter: 1915 loss: 7.8429639e-07
Iter: 1916 loss: 7.84262056e-07
Iter: 1917 loss: 7.84104941e-07
Iter: 1918 loss: 7.83926339e-07
Iter: 1919 loss: 7.83906842e-07
Iter: 1920 loss: 7.83619612e-07
Iter: 1921 loss: 7.85944735e-07
Iter: 1922 loss: 7.83601934e-07
Iter: 1923 loss: 7.83342159e-07
Iter: 1924 loss: 7.85430643e-07
Iter: 1925 loss: 7.83342898e-07
Iter: 1926 loss: 7.83141786e-07
Iter: 1927 loss: 7.83290204e-07
Iter: 1928 loss: 7.83011785e-07
Iter: 1929 loss: 7.82805159e-07
Iter: 1930 loss: 7.83214603e-07
Iter: 1931 loss: 7.82721486e-07
Iter: 1932 loss: 7.82547659e-07
Iter: 1933 loss: 7.82565621e-07
Iter: 1934 loss: 7.82459153e-07
Iter: 1935 loss: 7.8233353e-07
Iter: 1936 loss: 7.82346547e-07
Iter: 1937 loss: 7.82229222e-07
Iter: 1938 loss: 7.83387577e-07
Iter: 1939 loss: 7.82217853e-07
Iter: 1940 loss: 7.82056759e-07
Iter: 1941 loss: 7.82330403e-07
Iter: 1942 loss: 7.82049e-07
Iter: 1943 loss: 7.81929771e-07
Iter: 1944 loss: 7.8266e-07
Iter: 1945 loss: 7.8194023e-07
Iter: 1946 loss: 7.81861e-07
Iter: 1947 loss: 7.81712686e-07
Iter: 1948 loss: 7.81725248e-07
Iter: 1949 loss: 7.81569554e-07
Iter: 1950 loss: 7.8139135e-07
Iter: 1951 loss: 7.81364577e-07
Iter: 1952 loss: 7.81086214e-07
Iter: 1953 loss: 7.82484165e-07
Iter: 1954 loss: 7.81039716e-07
Iter: 1955 loss: 7.80822177e-07
Iter: 1956 loss: 7.83481653e-07
Iter: 1957 loss: 7.80832238e-07
Iter: 1958 loss: 7.80643575e-07
Iter: 1959 loss: 7.81096048e-07
Iter: 1960 loss: 7.80550636e-07
Iter: 1961 loss: 7.80382948e-07
Iter: 1962 loss: 7.80474522e-07
Iter: 1963 loss: 7.80269374e-07
Iter: 1964 loss: 7.80138635e-07
Iter: 1965 loss: 7.80139317e-07
Iter: 1966 loss: 7.80024038e-07
Iter: 1967 loss: 7.79949971e-07
Iter: 1968 loss: 7.79921777e-07
Iter: 1969 loss: 7.79786888e-07
Iter: 1970 loss: 7.80547907e-07
Iter: 1971 loss: 7.79721063e-07
Iter: 1972 loss: 7.79586799e-07
Iter: 1973 loss: 7.80356118e-07
Iter: 1974 loss: 7.79584525e-07
Iter: 1975 loss: 7.79453558e-07
Iter: 1976 loss: 7.79817242e-07
Iter: 1977 loss: 7.79413767e-07
Iter: 1978 loss: 7.79318384e-07
Iter: 1979 loss: 7.79236757e-07
Iter: 1980 loss: 7.79175423e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.2/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.6
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.6
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.6 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.6
+ date
Sun Nov  8 02:43:17 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.6/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.2/300_100_100_100_1 --function f1 --psi 1 --phi 1.6 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.6/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffaf7388510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffaf7388840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffabed80bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffabee207b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffabee26400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffabee26510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa9854f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa985391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa985397b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98536378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa984a8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98465a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98465378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa985918c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa984009d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98437d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98403400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa983e8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa9833f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa9838a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa9838a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa984cb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa984c79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa9832c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa9832c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa982b76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa982b7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa982cc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa981be6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa982cc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98206b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa981a3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa9817e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98196d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98274b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa98245f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0036928323
test_loss: 0.0036367641
train_loss: 0.0032791167
test_loss: 0.0029172965
train_loss: 0.002840796
test_loss: 0.0030093659
train_loss: 0.0027459385
test_loss: 0.0029372368
train_loss: 0.003006992
test_loss: 0.0030079924
train_loss: 0.0027441476
test_loss: 0.002723021
train_loss: 0.0027281996
test_loss: 0.0028019412
train_loss: 0.0028573244
test_loss: 0.0030170707
train_loss: 0.0026667255
test_loss: 0.0027260138
train_loss: 0.0024759555
test_loss: 0.0027651223
train_loss: 0.002428617
test_loss: 0.0025585624
train_loss: 0.0025280467
test_loss: 0.002785907
train_loss: 0.0026832514
test_loss: 0.0029097842
train_loss: 0.0027599018
test_loss: 0.0030404131
train_loss: 0.0024680062
test_loss: 0.0026234877
train_loss: 0.002477989
test_loss: 0.0026533536
train_loss: 0.0023893556
test_loss: 0.0026676948
train_loss: 0.0024362768
test_loss: 0.0026367006
train_loss: 0.0026021106
test_loss: 0.0027652523
train_loss: 0.0024555943
test_loss: 0.0025461402
train_loss: 0.0025827314
test_loss: 0.002921574
train_loss: 0.0023982436
test_loss: 0.002574285
train_loss: 0.002853171
test_loss: 0.002655995
train_loss: 0.0024761003
test_loss: 0.0025398785
train_loss: 0.0024035042
test_loss: 0.0027097438
train_loss: 0.0026268682
test_loss: 0.0027121578
train_loss: 0.0024850904
test_loss: 0.0029861021
train_loss: 0.0027046658
test_loss: 0.0029806104
train_loss: 0.0026847823
test_loss: 0.0029025106
train_loss: 0.0023352916
test_loss: 0.0025776739
train_loss: 0.0025015248
test_loss: 0.0026027549
train_loss: 0.0024480945
test_loss: 0.0026582552
train_loss: 0.002434637
test_loss: 0.002663834
train_loss: 0.002417705
test_loss: 0.0027920085
train_loss: 0.0024225835
test_loss: 0.002730685
train_loss: 0.0024459548
test_loss: 0.0026564477
train_loss: 0.0024558674
test_loss: 0.002718589
train_loss: 0.0024319417
test_loss: 0.0025504918
train_loss: 0.0024829328
test_loss: 0.0026235713
train_loss: 0.0026036869
test_loss: 0.0026390748
train_loss: 0.002413435
test_loss: 0.002507191
train_loss: 0.002318916
test_loss: 0.0025584653
train_loss: 0.0024989592
test_loss: 0.0026599728
train_loss: 0.0022447326
test_loss: 0.002624548
train_loss: 0.0022734948
test_loss: 0.0024598194
train_loss: 0.0025674133
test_loss: 0.00279508
train_loss: 0.0023883078
test_loss: 0.0026831878
train_loss: 0.0025424508
test_loss: 0.002482963
train_loss: 0.0024247125
test_loss: 0.0026032946
train_loss: 0.002349474
test_loss: 0.0026524025
train_loss: 0.0023862277
test_loss: 0.0026885138
train_loss: 0.0022318708
test_loss: 0.002543148
train_loss: 0.002381837
test_loss: 0.002542191
train_loss: 0.002378312
test_loss: 0.0025382924
train_loss: 0.0025020791
test_loss: 0.0026066934
train_loss: 0.0025359713
test_loss: 0.002719142
train_loss: 0.002373613
test_loss: 0.0025528085
train_loss: 0.0023737473
test_loss: 0.0029026389
train_loss: 0.0023829292
test_loss: 0.0025304807
train_loss: 0.0021636244
test_loss: 0.0023944548
train_loss: 0.0023302566
test_loss: 0.0026488237
train_loss: 0.0023923488
test_loss: 0.0025947427
train_loss: 0.0023729594
test_loss: 0.002535111
train_loss: 0.0021846395
test_loss: 0.002574738
train_loss: 0.002377398
test_loss: 0.0025860153
train_loss: 0.0023696593
test_loss: 0.0027366278
train_loss: 0.0022572514
test_loss: 0.0025577233
train_loss: 0.0026257916
test_loss: 0.0026208572
train_loss: 0.0023494754
test_loss: 0.0026715952
train_loss: 0.0023164395
test_loss: 0.002576963
train_loss: 0.0022024303
test_loss: 0.0025752082
train_loss: 0.0024778713
test_loss: 0.0026477277
train_loss: 0.0021432133
test_loss: 0.00249121
train_loss: 0.0023228398
test_loss: 0.0025728254
train_loss: 0.0022850118
test_loss: 0.0024207197
train_loss: 0.002388121
test_loss: 0.002473834
train_loss: 0.0023792358
test_loss: 0.002642003
train_loss: 0.0023168474
test_loss: 0.0026564184
train_loss: 0.00249836
test_loss: 0.0026083214
train_loss: 0.0024444268
test_loss: 0.0027223895
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.6/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.6/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 1.6 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi1.6/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793e232f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793f3b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793f3bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793e422f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793e77730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793e77378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793db3f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793d4a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793d6b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793d68488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57941d4268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793ce1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793ce1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5793cba950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749fc4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749fc4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749ff1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749f8c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749f697b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749f69d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749f06268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5749ebd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57247729d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5724782ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57247829d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f572473d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5724704840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5724704950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57246b0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5724704268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57246889d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f572462f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57246882f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57246507b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57246109d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f57245b9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.05330873e-05
Iter: 2 loss: 2.96081471e-05
Iter: 3 loss: 8.68042207e-06
Iter: 4 loss: 7.97199664e-06
Iter: 5 loss: 8.81424421e-06
Iter: 6 loss: 7.59737623e-06
Iter: 7 loss: 7.25703e-06
Iter: 8 loss: 7.54751682e-06
Iter: 9 loss: 7.05586535e-06
Iter: 10 loss: 6.65989501e-06
Iter: 11 loss: 7.73441752e-06
Iter: 12 loss: 6.52989365e-06
Iter: 13 loss: 6.2617105e-06
Iter: 14 loss: 6.54804762e-06
Iter: 15 loss: 6.11460382e-06
Iter: 16 loss: 5.90376067e-06
Iter: 17 loss: 5.89832962e-06
Iter: 18 loss: 5.752584e-06
Iter: 19 loss: 5.65110349e-06
Iter: 20 loss: 5.59921318e-06
Iter: 21 loss: 5.38480163e-06
Iter: 22 loss: 5.12836777e-06
Iter: 23 loss: 5.1023e-06
Iter: 24 loss: 4.88918795e-06
Iter: 25 loss: 4.88833621e-06
Iter: 26 loss: 4.65576341e-06
Iter: 27 loss: 4.74144781e-06
Iter: 28 loss: 4.49320487e-06
Iter: 29 loss: 4.26770521e-06
Iter: 30 loss: 5.19574405e-06
Iter: 31 loss: 4.21871164e-06
Iter: 32 loss: 4.06972958e-06
Iter: 33 loss: 4.05527453e-06
Iter: 34 loss: 3.94630297e-06
Iter: 35 loss: 3.9266497e-06
Iter: 36 loss: 3.837039e-06
Iter: 37 loss: 3.79487233e-06
Iter: 38 loss: 3.73519288e-06
Iter: 39 loss: 3.73294893e-06
Iter: 40 loss: 3.65389292e-06
Iter: 41 loss: 3.80072561e-06
Iter: 42 loss: 3.62019227e-06
Iter: 43 loss: 3.53184578e-06
Iter: 44 loss: 3.78361119e-06
Iter: 45 loss: 3.50394953e-06
Iter: 46 loss: 3.42812791e-06
Iter: 47 loss: 3.41659825e-06
Iter: 48 loss: 3.36380117e-06
Iter: 49 loss: 3.24723624e-06
Iter: 50 loss: 4.64440882e-06
Iter: 51 loss: 3.24574557e-06
Iter: 52 loss: 3.18587649e-06
Iter: 53 loss: 3.15504417e-06
Iter: 54 loss: 3.12739462e-06
Iter: 55 loss: 3.04540072e-06
Iter: 56 loss: 3.11948e-06
Iter: 57 loss: 2.9978446e-06
Iter: 58 loss: 2.90787739e-06
Iter: 59 loss: 3.18774255e-06
Iter: 60 loss: 2.88162164e-06
Iter: 61 loss: 2.81343887e-06
Iter: 62 loss: 2.81273878e-06
Iter: 63 loss: 2.78364269e-06
Iter: 64 loss: 2.75495131e-06
Iter: 65 loss: 2.74883246e-06
Iter: 66 loss: 2.69313546e-06
Iter: 67 loss: 2.71345198e-06
Iter: 68 loss: 2.65419749e-06
Iter: 69 loss: 2.62110825e-06
Iter: 70 loss: 2.61854234e-06
Iter: 71 loss: 2.57713964e-06
Iter: 72 loss: 2.64116215e-06
Iter: 73 loss: 2.55765167e-06
Iter: 74 loss: 2.52968357e-06
Iter: 75 loss: 2.51410802e-06
Iter: 76 loss: 2.50211042e-06
Iter: 77 loss: 2.45486785e-06
Iter: 78 loss: 2.6323828e-06
Iter: 79 loss: 2.44352168e-06
Iter: 80 loss: 2.40285772e-06
Iter: 81 loss: 2.5335296e-06
Iter: 82 loss: 2.39126302e-06
Iter: 83 loss: 2.36552114e-06
Iter: 84 loss: 2.47176331e-06
Iter: 85 loss: 2.35983e-06
Iter: 86 loss: 2.32092452e-06
Iter: 87 loss: 2.29921807e-06
Iter: 88 loss: 2.2822785e-06
Iter: 89 loss: 2.25032136e-06
Iter: 90 loss: 2.37977474e-06
Iter: 91 loss: 2.24330597e-06
Iter: 92 loss: 2.21104074e-06
Iter: 93 loss: 2.18494893e-06
Iter: 94 loss: 2.17535171e-06
Iter: 95 loss: 2.14878946e-06
Iter: 96 loss: 2.14725469e-06
Iter: 97 loss: 2.12045643e-06
Iter: 98 loss: 2.1329e-06
Iter: 99 loss: 2.10249345e-06
Iter: 100 loss: 2.07161656e-06
Iter: 101 loss: 2.14998977e-06
Iter: 102 loss: 2.0610139e-06
Iter: 103 loss: 2.04137586e-06
Iter: 104 loss: 2.19155118e-06
Iter: 105 loss: 2.03988907e-06
Iter: 106 loss: 2.01652256e-06
Iter: 107 loss: 2.10193593e-06
Iter: 108 loss: 2.01064518e-06
Iter: 109 loss: 2.00197474e-06
Iter: 110 loss: 1.97955387e-06
Iter: 111 loss: 2.17599336e-06
Iter: 112 loss: 1.97611348e-06
Iter: 113 loss: 1.95610414e-06
Iter: 114 loss: 1.95553866e-06
Iter: 115 loss: 1.94172935e-06
Iter: 116 loss: 1.9462459e-06
Iter: 117 loss: 1.93181245e-06
Iter: 118 loss: 1.91163e-06
Iter: 119 loss: 1.96216615e-06
Iter: 120 loss: 1.90447622e-06
Iter: 121 loss: 1.88458205e-06
Iter: 122 loss: 2.06628033e-06
Iter: 123 loss: 1.88363333e-06
Iter: 124 loss: 1.87345904e-06
Iter: 125 loss: 1.84349665e-06
Iter: 126 loss: 1.94310451e-06
Iter: 127 loss: 1.82915755e-06
Iter: 128 loss: 1.8089753e-06
Iter: 129 loss: 1.80674795e-06
Iter: 130 loss: 1.7888932e-06
Iter: 131 loss: 1.83594739e-06
Iter: 132 loss: 1.78291339e-06
Iter: 133 loss: 1.76679134e-06
Iter: 134 loss: 1.93388632e-06
Iter: 135 loss: 1.76640765e-06
Iter: 136 loss: 1.75688183e-06
Iter: 137 loss: 1.75003174e-06
Iter: 138 loss: 1.74678087e-06
Iter: 139 loss: 1.73803983e-06
Iter: 140 loss: 1.73695082e-06
Iter: 141 loss: 1.72837815e-06
Iter: 142 loss: 1.71176646e-06
Iter: 143 loss: 2.05594938e-06
Iter: 144 loss: 1.7116123e-06
Iter: 145 loss: 1.69758164e-06
Iter: 146 loss: 1.71749832e-06
Iter: 147 loss: 1.69069392e-06
Iter: 148 loss: 1.68237295e-06
Iter: 149 loss: 1.79271558e-06
Iter: 150 loss: 1.68236204e-06
Iter: 151 loss: 1.67283827e-06
Iter: 152 loss: 1.66894893e-06
Iter: 153 loss: 1.6639849e-06
Iter: 154 loss: 1.65399e-06
Iter: 155 loss: 1.78517848e-06
Iter: 156 loss: 1.65392987e-06
Iter: 157 loss: 1.64630785e-06
Iter: 158 loss: 1.65706933e-06
Iter: 159 loss: 1.64259086e-06
Iter: 160 loss: 1.63459094e-06
Iter: 161 loss: 1.62721426e-06
Iter: 162 loss: 1.62532297e-06
Iter: 163 loss: 1.61208686e-06
Iter: 164 loss: 1.6144138e-06
Iter: 165 loss: 1.60210868e-06
Iter: 166 loss: 1.59373019e-06
Iter: 167 loss: 1.59299657e-06
Iter: 168 loss: 1.58419607e-06
Iter: 169 loss: 1.59160481e-06
Iter: 170 loss: 1.57899876e-06
Iter: 171 loss: 1.56702879e-06
Iter: 172 loss: 1.60003287e-06
Iter: 173 loss: 1.5631316e-06
Iter: 174 loss: 1.55875114e-06
Iter: 175 loss: 1.5571e-06
Iter: 176 loss: 1.55442876e-06
Iter: 177 loss: 1.54592738e-06
Iter: 178 loss: 1.56183637e-06
Iter: 179 loss: 1.54046666e-06
Iter: 180 loss: 1.53082647e-06
Iter: 181 loss: 1.6416443e-06
Iter: 182 loss: 1.53072563e-06
Iter: 183 loss: 1.52263249e-06
Iter: 184 loss: 1.53485075e-06
Iter: 185 loss: 1.51885069e-06
Iter: 186 loss: 1.51065956e-06
Iter: 187 loss: 1.61437026e-06
Iter: 188 loss: 1.51061568e-06
Iter: 189 loss: 1.50609685e-06
Iter: 190 loss: 1.50631581e-06
Iter: 191 loss: 1.50262952e-06
Iter: 192 loss: 1.49397715e-06
Iter: 193 loss: 1.50627352e-06
Iter: 194 loss: 1.48979132e-06
Iter: 195 loss: 1.48287631e-06
Iter: 196 loss: 1.48202525e-06
Iter: 197 loss: 1.47720539e-06
Iter: 198 loss: 1.46651837e-06
Iter: 199 loss: 1.48876006e-06
Iter: 200 loss: 1.46231037e-06
Iter: 201 loss: 1.45358831e-06
Iter: 202 loss: 1.47400965e-06
Iter: 203 loss: 1.45033755e-06
Iter: 204 loss: 1.44158253e-06
Iter: 205 loss: 1.57514432e-06
Iter: 206 loss: 1.44151863e-06
Iter: 207 loss: 1.43766829e-06
Iter: 208 loss: 1.463584e-06
Iter: 209 loss: 1.43721513e-06
Iter: 210 loss: 1.43300622e-06
Iter: 211 loss: 1.43820773e-06
Iter: 212 loss: 1.43081468e-06
Iter: 213 loss: 1.42586873e-06
Iter: 214 loss: 1.41488385e-06
Iter: 215 loss: 1.56556234e-06
Iter: 216 loss: 1.41422549e-06
Iter: 217 loss: 1.40707675e-06
Iter: 218 loss: 1.44417822e-06
Iter: 219 loss: 1.40599968e-06
Iter: 220 loss: 1.39910514e-06
Iter: 221 loss: 1.4456532e-06
Iter: 222 loss: 1.39843223e-06
Iter: 223 loss: 1.39275403e-06
Iter: 224 loss: 1.43250691e-06
Iter: 225 loss: 1.39218673e-06
Iter: 226 loss: 1.3882144e-06
Iter: 227 loss: 1.39236693e-06
Iter: 228 loss: 1.38595271e-06
Iter: 229 loss: 1.38071982e-06
Iter: 230 loss: 1.39951067e-06
Iter: 231 loss: 1.3794097e-06
Iter: 232 loss: 1.37543964e-06
Iter: 233 loss: 1.37120674e-06
Iter: 234 loss: 1.37059931e-06
Iter: 235 loss: 1.36409653e-06
Iter: 236 loss: 1.40075645e-06
Iter: 237 loss: 1.36307426e-06
Iter: 238 loss: 1.35799382e-06
Iter: 239 loss: 1.35541052e-06
Iter: 240 loss: 1.35303821e-06
Iter: 241 loss: 1.34856009e-06
Iter: 242 loss: 1.34763536e-06
Iter: 243 loss: 1.34475022e-06
Iter: 244 loss: 1.35776406e-06
Iter: 245 loss: 1.34423271e-06
Iter: 246 loss: 1.34047309e-06
Iter: 247 loss: 1.3361439e-06
Iter: 248 loss: 1.33570165e-06
Iter: 249 loss: 1.33127946e-06
Iter: 250 loss: 1.32603805e-06
Iter: 251 loss: 1.32552111e-06
Iter: 252 loss: 1.31742922e-06
Iter: 253 loss: 1.37489928e-06
Iter: 254 loss: 1.31668571e-06
Iter: 255 loss: 1.3123713e-06
Iter: 256 loss: 1.31827164e-06
Iter: 257 loss: 1.31027673e-06
Iter: 258 loss: 1.30347973e-06
Iter: 259 loss: 1.34268794e-06
Iter: 260 loss: 1.30251692e-06
Iter: 261 loss: 1.29931402e-06
Iter: 262 loss: 1.31894978e-06
Iter: 263 loss: 1.29887712e-06
Iter: 264 loss: 1.29611044e-06
Iter: 265 loss: 1.29604473e-06
Iter: 266 loss: 1.2938865e-06
Iter: 267 loss: 1.28952263e-06
Iter: 268 loss: 1.28953434e-06
Iter: 269 loss: 1.28616591e-06
Iter: 270 loss: 1.2805358e-06
Iter: 271 loss: 1.29042303e-06
Iter: 272 loss: 1.27818748e-06
Iter: 273 loss: 1.27441797e-06
Iter: 274 loss: 1.32026594e-06
Iter: 275 loss: 1.27435874e-06
Iter: 276 loss: 1.27161923e-06
Iter: 277 loss: 1.29316959e-06
Iter: 278 loss: 1.27146177e-06
Iter: 279 loss: 1.2685141e-06
Iter: 280 loss: 1.27161081e-06
Iter: 281 loss: 1.26689156e-06
Iter: 282 loss: 1.26339251e-06
Iter: 283 loss: 1.27560429e-06
Iter: 284 loss: 1.26246164e-06
Iter: 285 loss: 1.26061889e-06
Iter: 286 loss: 1.25636438e-06
Iter: 287 loss: 1.3139495e-06
Iter: 288 loss: 1.25610973e-06
Iter: 289 loss: 1.25190832e-06
Iter: 290 loss: 1.29677437e-06
Iter: 291 loss: 1.25188274e-06
Iter: 292 loss: 1.24906626e-06
Iter: 293 loss: 1.25152565e-06
Iter: 294 loss: 1.24747589e-06
Iter: 295 loss: 1.24359246e-06
Iter: 296 loss: 1.28299166e-06
Iter: 297 loss: 1.24329722e-06
Iter: 298 loss: 1.24100177e-06
Iter: 299 loss: 1.24182066e-06
Iter: 300 loss: 1.23947984e-06
Iter: 301 loss: 1.23620248e-06
Iter: 302 loss: 1.24819758e-06
Iter: 303 loss: 1.23540735e-06
Iter: 304 loss: 1.23288237e-06
Iter: 305 loss: 1.23359e-06
Iter: 306 loss: 1.23109339e-06
Iter: 307 loss: 1.22731274e-06
Iter: 308 loss: 1.22666211e-06
Iter: 309 loss: 1.22407528e-06
Iter: 310 loss: 1.21979974e-06
Iter: 311 loss: 1.2442772e-06
Iter: 312 loss: 1.21922938e-06
Iter: 313 loss: 1.21692233e-06
Iter: 314 loss: 1.21660514e-06
Iter: 315 loss: 1.21501955e-06
Iter: 316 loss: 1.21755716e-06
Iter: 317 loss: 1.21420976e-06
Iter: 318 loss: 1.21262747e-06
Iter: 319 loss: 1.21236894e-06
Iter: 320 loss: 1.2112173e-06
Iter: 321 loss: 1.20853269e-06
Iter: 322 loss: 1.20662378e-06
Iter: 323 loss: 1.20562663e-06
Iter: 324 loss: 1.20281038e-06
Iter: 325 loss: 1.20744812e-06
Iter: 326 loss: 1.2014641e-06
Iter: 327 loss: 1.19800893e-06
Iter: 328 loss: 1.22318465e-06
Iter: 329 loss: 1.19768129e-06
Iter: 330 loss: 1.19517006e-06
Iter: 331 loss: 1.22276288e-06
Iter: 332 loss: 1.19508127e-06
Iter: 333 loss: 1.19317e-06
Iter: 334 loss: 1.19124252e-06
Iter: 335 loss: 1.19093079e-06
Iter: 336 loss: 1.18889875e-06
Iter: 337 loss: 1.18882417e-06
Iter: 338 loss: 1.18726348e-06
Iter: 339 loss: 1.18269077e-06
Iter: 340 loss: 1.20476602e-06
Iter: 341 loss: 1.18109631e-06
Iter: 342 loss: 1.17859327e-06
Iter: 343 loss: 1.17799891e-06
Iter: 344 loss: 1.17621562e-06
Iter: 345 loss: 1.17447905e-06
Iter: 346 loss: 1.17416096e-06
Iter: 347 loss: 1.17194418e-06
Iter: 348 loss: 1.17165337e-06
Iter: 349 loss: 1.17041532e-06
Iter: 350 loss: 1.16979606e-06
Iter: 351 loss: 1.16918659e-06
Iter: 352 loss: 1.16713409e-06
Iter: 353 loss: 1.16985416e-06
Iter: 354 loss: 1.16603678e-06
Iter: 355 loss: 1.16420426e-06
Iter: 356 loss: 1.16413526e-06
Iter: 357 loss: 1.16268427e-06
Iter: 358 loss: 1.15949604e-06
Iter: 359 loss: 1.15970329e-06
Iter: 360 loss: 1.15691023e-06
Iter: 361 loss: 1.15564444e-06
Iter: 362 loss: 1.1547429e-06
Iter: 363 loss: 1.15311968e-06
Iter: 364 loss: 1.15421346e-06
Iter: 365 loss: 1.15206512e-06
Iter: 366 loss: 1.14983129e-06
Iter: 367 loss: 1.14876525e-06
Iter: 368 loss: 1.14766215e-06
Iter: 369 loss: 1.14525346e-06
Iter: 370 loss: 1.14523527e-06
Iter: 371 loss: 1.14372449e-06
Iter: 372 loss: 1.14071395e-06
Iter: 373 loss: 1.19867309e-06
Iter: 374 loss: 1.14066961e-06
Iter: 375 loss: 1.13781948e-06
Iter: 376 loss: 1.15958142e-06
Iter: 377 loss: 1.13759006e-06
Iter: 378 loss: 1.13598787e-06
Iter: 379 loss: 1.15913758e-06
Iter: 380 loss: 1.13598412e-06
Iter: 381 loss: 1.13439842e-06
Iter: 382 loss: 1.14113413e-06
Iter: 383 loss: 1.13405542e-06
Iter: 384 loss: 1.13300609e-06
Iter: 385 loss: 1.13175361e-06
Iter: 386 loss: 1.1317004e-06
Iter: 387 loss: 1.12919565e-06
Iter: 388 loss: 1.13469423e-06
Iter: 389 loss: 1.12838211e-06
Iter: 390 loss: 1.12659404e-06
Iter: 391 loss: 1.12634916e-06
Iter: 392 loss: 1.12512907e-06
Iter: 393 loss: 1.12210614e-06
Iter: 394 loss: 1.12827354e-06
Iter: 395 loss: 1.1209778e-06
Iter: 396 loss: 1.11955546e-06
Iter: 397 loss: 1.11937334e-06
Iter: 398 loss: 1.11788131e-06
Iter: 399 loss: 1.11541908e-06
Iter: 400 loss: 1.11539566e-06
Iter: 401 loss: 1.11321538e-06
Iter: 402 loss: 1.13846295e-06
Iter: 403 loss: 1.11319491e-06
Iter: 404 loss: 1.1117545e-06
Iter: 405 loss: 1.11474492e-06
Iter: 406 loss: 1.11127929e-06
Iter: 407 loss: 1.10950987e-06
Iter: 408 loss: 1.10807287e-06
Iter: 409 loss: 1.10757355e-06
Iter: 410 loss: 1.10583164e-06
Iter: 411 loss: 1.11298937e-06
Iter: 412 loss: 1.10537565e-06
Iter: 413 loss: 1.10487576e-06
Iter: 414 loss: 1.10447525e-06
Iter: 415 loss: 1.10373276e-06
Iter: 416 loss: 1.10233429e-06
Iter: 417 loss: 1.10234259e-06
Iter: 418 loss: 1.1008093e-06
Iter: 419 loss: 1.1050472e-06
Iter: 420 loss: 1.10040355e-06
Iter: 421 loss: 1.09864277e-06
Iter: 422 loss: 1.103e-06
Iter: 423 loss: 1.09808752e-06
Iter: 424 loss: 1.09676557e-06
Iter: 425 loss: 1.09439122e-06
Iter: 426 loss: 1.15351054e-06
Iter: 427 loss: 1.09435177e-06
Iter: 428 loss: 1.09116854e-06
Iter: 429 loss: 1.12430848e-06
Iter: 430 loss: 1.09110692e-06
Iter: 431 loss: 1.08930715e-06
Iter: 432 loss: 1.11311431e-06
Iter: 433 loss: 1.0892802e-06
Iter: 434 loss: 1.08814606e-06
Iter: 435 loss: 1.08581014e-06
Iter: 436 loss: 1.12703685e-06
Iter: 437 loss: 1.08573272e-06
Iter: 438 loss: 1.08366612e-06
Iter: 439 loss: 1.08368488e-06
Iter: 440 loss: 1.08256847e-06
Iter: 441 loss: 1.08313645e-06
Iter: 442 loss: 1.08178881e-06
Iter: 443 loss: 1.08042593e-06
Iter: 444 loss: 1.08192171e-06
Iter: 445 loss: 1.07963388e-06
Iter: 446 loss: 1.07810899e-06
Iter: 447 loss: 1.08182189e-06
Iter: 448 loss: 1.07765914e-06
Iter: 449 loss: 1.07587766e-06
Iter: 450 loss: 1.09892892e-06
Iter: 451 loss: 1.07587368e-06
Iter: 452 loss: 1.07526773e-06
Iter: 453 loss: 1.0743363e-06
Iter: 454 loss: 1.07436608e-06
Iter: 455 loss: 1.07272297e-06
Iter: 456 loss: 1.07540779e-06
Iter: 457 loss: 1.07200447e-06
Iter: 458 loss: 1.07023072e-06
Iter: 459 loss: 1.07410517e-06
Iter: 460 loss: 1.06957964e-06
Iter: 461 loss: 1.06833886e-06
Iter: 462 loss: 1.06909238e-06
Iter: 463 loss: 1.06752248e-06
Iter: 464 loss: 1.06644211e-06
Iter: 465 loss: 1.06641733e-06
Iter: 466 loss: 1.06535845e-06
Iter: 467 loss: 1.06457583e-06
Iter: 468 loss: 1.0642085e-06
Iter: 469 loss: 1.06277071e-06
Iter: 470 loss: 1.06721018e-06
Iter: 471 loss: 1.06229095e-06
Iter: 472 loss: 1.06113021e-06
Iter: 473 loss: 1.06783227e-06
Iter: 474 loss: 1.06093501e-06
Iter: 475 loss: 1.05970264e-06
Iter: 476 loss: 1.05835352e-06
Iter: 477 loss: 1.05814831e-06
Iter: 478 loss: 1.05685888e-06
Iter: 479 loss: 1.06782545e-06
Iter: 480 loss: 1.05677395e-06
Iter: 481 loss: 1.05600679e-06
Iter: 482 loss: 1.06856191e-06
Iter: 483 loss: 1.05599986e-06
Iter: 484 loss: 1.05510208e-06
Iter: 485 loss: 1.0532541e-06
Iter: 486 loss: 1.08700794e-06
Iter: 487 loss: 1.05315871e-06
Iter: 488 loss: 1.05209972e-06
Iter: 489 loss: 1.06144898e-06
Iter: 490 loss: 1.05206345e-06
Iter: 491 loss: 1.05095023e-06
Iter: 492 loss: 1.05085098e-06
Iter: 493 loss: 1.05004528e-06
Iter: 494 loss: 1.0486724e-06
Iter: 495 loss: 1.05126242e-06
Iter: 496 loss: 1.04815899e-06
Iter: 497 loss: 1.04685785e-06
Iter: 498 loss: 1.0502439e-06
Iter: 499 loss: 1.04634864e-06
Iter: 500 loss: 1.04534683e-06
Iter: 501 loss: 1.0453366e-06
Iter: 502 loss: 1.04475475e-06
Iter: 503 loss: 1.04314631e-06
Iter: 504 loss: 1.05462448e-06
Iter: 505 loss: 1.04282924e-06
Iter: 506 loss: 1.04102764e-06
Iter: 507 loss: 1.06677317e-06
Iter: 508 loss: 1.04104276e-06
Iter: 509 loss: 1.04004562e-06
Iter: 510 loss: 1.04565606e-06
Iter: 511 loss: 1.03985417e-06
Iter: 512 loss: 1.03893842e-06
Iter: 513 loss: 1.03738955e-06
Iter: 514 loss: 1.03737966e-06
Iter: 515 loss: 1.03611808e-06
Iter: 516 loss: 1.05270897e-06
Iter: 517 loss: 1.0361083e-06
Iter: 518 loss: 1.03460832e-06
Iter: 519 loss: 1.03803791e-06
Iter: 520 loss: 1.03407717e-06
Iter: 521 loss: 1.03315051e-06
Iter: 522 loss: 1.03326238e-06
Iter: 523 loss: 1.03248431e-06
Iter: 524 loss: 1.03148886e-06
Iter: 525 loss: 1.0367437e-06
Iter: 526 loss: 1.0313754e-06
Iter: 527 loss: 1.03031448e-06
Iter: 528 loss: 1.02940726e-06
Iter: 529 loss: 1.02911508e-06
Iter: 530 loss: 1.02787374e-06
Iter: 531 loss: 1.0306137e-06
Iter: 532 loss: 1.02743866e-06
Iter: 533 loss: 1.02642298e-06
Iter: 534 loss: 1.04070841e-06
Iter: 535 loss: 1.02635613e-06
Iter: 536 loss: 1.02539752e-06
Iter: 537 loss: 1.02751801e-06
Iter: 538 loss: 1.02498382e-06
Iter: 539 loss: 1.02406079e-06
Iter: 540 loss: 1.02274942e-06
Iter: 541 loss: 1.02269121e-06
Iter: 542 loss: 1.02194167e-06
Iter: 543 loss: 1.02188596e-06
Iter: 544 loss: 1.0211844e-06
Iter: 545 loss: 1.02062006e-06
Iter: 546 loss: 1.02043725e-06
Iter: 547 loss: 1.01912292e-06
Iter: 548 loss: 1.02019703e-06
Iter: 549 loss: 1.01835667e-06
Iter: 550 loss: 1.01827516e-06
Iter: 551 loss: 1.01771752e-06
Iter: 552 loss: 1.01715386e-06
Iter: 553 loss: 1.01593946e-06
Iter: 554 loss: 1.03403465e-06
Iter: 555 loss: 1.01593218e-06
Iter: 556 loss: 1.0148633e-06
Iter: 557 loss: 1.01691558e-06
Iter: 558 loss: 1.01446267e-06
Iter: 559 loss: 1.01313958e-06
Iter: 560 loss: 1.0195306e-06
Iter: 561 loss: 1.01286219e-06
Iter: 562 loss: 1.01204978e-06
Iter: 563 loss: 1.01379783e-06
Iter: 564 loss: 1.01173816e-06
Iter: 565 loss: 1.01085107e-06
Iter: 566 loss: 1.00936177e-06
Iter: 567 loss: 1.00941622e-06
Iter: 568 loss: 1.00925922e-06
Iter: 569 loss: 1.00850684e-06
Iter: 570 loss: 1.00798707e-06
Iter: 571 loss: 1.00695752e-06
Iter: 572 loss: 1.02887498e-06
Iter: 573 loss: 1.00706404e-06
Iter: 574 loss: 1.00576904e-06
Iter: 575 loss: 1.00849365e-06
Iter: 576 loss: 1.00525847e-06
Iter: 577 loss: 1.00439343e-06
Iter: 578 loss: 1.01663522e-06
Iter: 579 loss: 1.00437705e-06
Iter: 580 loss: 1.00363502e-06
Iter: 581 loss: 1.00283819e-06
Iter: 582 loss: 1.00272564e-06
Iter: 583 loss: 1.00178954e-06
Iter: 584 loss: 1.01163266e-06
Iter: 585 loss: 1.00175771e-06
Iter: 586 loss: 1.00069633e-06
Iter: 587 loss: 1.00461432e-06
Iter: 588 loss: 1.0004286e-06
Iter: 589 loss: 9.99700887e-07
Iter: 590 loss: 9.98510245e-07
Iter: 591 loss: 9.98525707e-07
Iter: 592 loss: 9.97532879e-07
Iter: 593 loss: 1.00403633e-06
Iter: 594 loss: 9.9740771e-07
Iter: 595 loss: 9.96246854e-07
Iter: 596 loss: 9.9673025e-07
Iter: 597 loss: 9.95367714e-07
Iter: 598 loss: 9.94545644e-07
Iter: 599 loss: 9.98183168e-07
Iter: 600 loss: 9.94342145e-07
Iter: 601 loss: 9.93492904e-07
Iter: 602 loss: 9.93715162e-07
Iter: 603 loss: 9.92865239e-07
Iter: 604 loss: 9.91965521e-07
Iter: 605 loss: 9.91987349e-07
Iter: 606 loss: 9.91527259e-07
Iter: 607 loss: 9.9048134e-07
Iter: 608 loss: 1.00300872e-06
Iter: 609 loss: 9.90416e-07
Iter: 610 loss: 9.89470777e-07
Iter: 611 loss: 9.99221356e-07
Iter: 612 loss: 9.89490445e-07
Iter: 613 loss: 9.88712827e-07
Iter: 614 loss: 9.89726e-07
Iter: 615 loss: 9.88285365e-07
Iter: 616 loss: 9.87220574e-07
Iter: 617 loss: 9.88917e-07
Iter: 618 loss: 9.86692157e-07
Iter: 619 loss: 9.86290615e-07
Iter: 620 loss: 9.86269811e-07
Iter: 621 loss: 9.85846782e-07
Iter: 622 loss: 9.84965254e-07
Iter: 623 loss: 1.00487591e-06
Iter: 624 loss: 9.85015504e-07
Iter: 625 loss: 9.84037797e-07
Iter: 626 loss: 9.8483747e-07
Iter: 627 loss: 9.83414452e-07
Iter: 628 loss: 9.82632173e-07
Iter: 629 loss: 9.92021114e-07
Iter: 630 loss: 9.82622623e-07
Iter: 631 loss: 9.81927201e-07
Iter: 632 loss: 9.82033725e-07
Iter: 633 loss: 9.81361381e-07
Iter: 634 loss: 9.80735877e-07
Iter: 635 loss: 9.81088419e-07
Iter: 636 loss: 9.80356504e-07
Iter: 637 loss: 9.79430524e-07
Iter: 638 loss: 9.8519638e-07
Iter: 639 loss: 9.79334686e-07
Iter: 640 loss: 9.78326e-07
Iter: 641 loss: 9.81423227e-07
Iter: 642 loss: 9.78045591e-07
Iter: 643 loss: 9.77479e-07
Iter: 644 loss: 9.76966362e-07
Iter: 645 loss: 9.7684358e-07
Iter: 646 loss: 9.75984449e-07
Iter: 647 loss: 9.80916184e-07
Iter: 648 loss: 9.75879516e-07
Iter: 649 loss: 9.74944896e-07
Iter: 650 loss: 9.77008e-07
Iter: 651 loss: 9.74619525e-07
Iter: 652 loss: 9.73996293e-07
Iter: 653 loss: 9.83541e-07
Iter: 654 loss: 9.74009481e-07
Iter: 655 loss: 9.73493115e-07
Iter: 656 loss: 9.74916e-07
Iter: 657 loss: 9.73305305e-07
Iter: 658 loss: 9.72874886e-07
Iter: 659 loss: 9.71725285e-07
Iter: 660 loss: 9.82181064e-07
Iter: 661 loss: 9.71536565e-07
Iter: 662 loss: 9.70609108e-07
Iter: 663 loss: 9.70610472e-07
Iter: 664 loss: 9.70091e-07
Iter: 665 loss: 9.73146484e-07
Iter: 666 loss: 9.70014526e-07
Iter: 667 loss: 9.69476787e-07
Iter: 668 loss: 9.68613676e-07
Iter: 669 loss: 9.68646e-07
Iter: 670 loss: 9.67763867e-07
Iter: 671 loss: 9.70763836e-07
Iter: 672 loss: 9.67477e-07
Iter: 673 loss: 9.66812536e-07
Iter: 674 loss: 9.6673557e-07
Iter: 675 loss: 9.66401444e-07
Iter: 676 loss: 9.65799e-07
Iter: 677 loss: 9.65816525e-07
Iter: 678 loss: 9.64913852e-07
Iter: 679 loss: 9.64976e-07
Iter: 680 loss: 9.64265155e-07
Iter: 681 loss: 9.63618277e-07
Iter: 682 loss: 9.63629e-07
Iter: 683 loss: 9.62925583e-07
Iter: 684 loss: 9.62206173e-07
Iter: 685 loss: 9.62036097e-07
Iter: 686 loss: 9.60954139e-07
Iter: 687 loss: 9.60958e-07
Iter: 688 loss: 9.60414354e-07
Iter: 689 loss: 9.60377633e-07
Iter: 690 loss: 9.59934596e-07
Iter: 691 loss: 9.59457338e-07
Iter: 692 loss: 9.58722694e-07
Iter: 693 loss: 9.58678356e-07
Iter: 694 loss: 9.5787982e-07
Iter: 695 loss: 9.57924158e-07
Iter: 696 loss: 9.57387e-07
Iter: 697 loss: 9.58806368e-07
Iter: 698 loss: 9.57145289e-07
Iter: 699 loss: 9.56640292e-07
Iter: 700 loss: 9.55875294e-07
Iter: 701 loss: 9.55791165e-07
Iter: 702 loss: 9.55301516e-07
Iter: 703 loss: 9.55241489e-07
Iter: 704 loss: 9.54632242e-07
Iter: 705 loss: 9.54385655e-07
Iter: 706 loss: 9.54081e-07
Iter: 707 loss: 9.53459335e-07
Iter: 708 loss: 9.54622e-07
Iter: 709 loss: 9.53198253e-07
Iter: 710 loss: 9.52485664e-07
Iter: 711 loss: 9.5309548e-07
Iter: 712 loss: 9.521263e-07
Iter: 713 loss: 9.51303036e-07
Iter: 714 loss: 9.62804506e-07
Iter: 715 loss: 9.5132e-07
Iter: 716 loss: 9.50887397e-07
Iter: 717 loss: 9.52683934e-07
Iter: 718 loss: 9.50785363e-07
Iter: 719 loss: 9.50124e-07
Iter: 720 loss: 9.49739729e-07
Iter: 721 loss: 9.49403102e-07
Iter: 722 loss: 9.48834895e-07
Iter: 723 loss: 9.49847959e-07
Iter: 724 loss: 9.48587285e-07
Iter: 725 loss: 9.47943533e-07
Iter: 726 loss: 9.47960302e-07
Iter: 727 loss: 9.47464628e-07
Iter: 728 loss: 9.46907903e-07
Iter: 729 loss: 9.46882096e-07
Iter: 730 loss: 9.46459068e-07
Iter: 731 loss: 9.45929401e-07
Iter: 732 loss: 9.45872e-07
Iter: 733 loss: 9.45056911e-07
Iter: 734 loss: 9.46392674e-07
Iter: 735 loss: 9.44713236e-07
Iter: 736 loss: 9.44024862e-07
Iter: 737 loss: 9.5218553e-07
Iter: 738 loss: 9.43993484e-07
Iter: 739 loss: 9.43377643e-07
Iter: 740 loss: 9.44993928e-07
Iter: 741 loss: 9.43139298e-07
Iter: 742 loss: 9.42706492e-07
Iter: 743 loss: 9.41415465e-07
Iter: 744 loss: 9.49551691e-07
Iter: 745 loss: 9.41118401e-07
Iter: 746 loss: 9.40464815e-07
Iter: 747 loss: 9.40186681e-07
Iter: 748 loss: 9.39671679e-07
Iter: 749 loss: 9.43255316e-07
Iter: 750 loss: 9.3965042e-07
Iter: 751 loss: 9.39174754e-07
Iter: 752 loss: 9.40491077e-07
Iter: 753 loss: 9.39015194e-07
Iter: 754 loss: 9.38384517e-07
Iter: 755 loss: 9.37894185e-07
Iter: 756 loss: 9.37748382e-07
Iter: 757 loss: 9.372053e-07
Iter: 758 loss: 9.37327968e-07
Iter: 759 loss: 9.36845e-07
Iter: 760 loss: 9.36054391e-07
Iter: 761 loss: 9.39454e-07
Iter: 762 loss: 9.3598004e-07
Iter: 763 loss: 9.35370736e-07
Iter: 764 loss: 9.39332892e-07
Iter: 765 loss: 9.3533032e-07
Iter: 766 loss: 9.3476956e-07
Iter: 767 loss: 9.34264449e-07
Iter: 768 loss: 9.34129503e-07
Iter: 769 loss: 9.33313288e-07
Iter: 770 loss: 9.33849719e-07
Iter: 771 loss: 9.32860075e-07
Iter: 772 loss: 9.31902036e-07
Iter: 773 loss: 9.4558942e-07
Iter: 774 loss: 9.31935e-07
Iter: 775 loss: 9.3129421e-07
Iter: 776 loss: 9.35479591e-07
Iter: 777 loss: 9.31185582e-07
Iter: 778 loss: 9.30849865e-07
Iter: 779 loss: 9.30100555e-07
Iter: 780 loss: 9.36886e-07
Iter: 781 loss: 9.30023248e-07
Iter: 782 loss: 9.29171335e-07
Iter: 783 loss: 9.38682888e-07
Iter: 784 loss: 9.29161786e-07
Iter: 785 loss: 9.28638428e-07
Iter: 786 loss: 9.28617908e-07
Iter: 787 loss: 9.28272357e-07
Iter: 788 loss: 9.28979262e-07
Iter: 789 loss: 9.28106829e-07
Iter: 790 loss: 9.27691076e-07
Iter: 791 loss: 9.27431415e-07
Iter: 792 loss: 9.27229394e-07
Iter: 793 loss: 9.26729911e-07
Iter: 794 loss: 9.2693972e-07
Iter: 795 loss: 9.26367306e-07
Iter: 796 loss: 9.25830363e-07
Iter: 797 loss: 9.28385873e-07
Iter: 798 loss: 9.25791369e-07
Iter: 799 loss: 9.25086056e-07
Iter: 800 loss: 9.2545946e-07
Iter: 801 loss: 9.24688266e-07
Iter: 802 loss: 9.23860341e-07
Iter: 803 loss: 9.27431927e-07
Iter: 804 loss: 9.23699133e-07
Iter: 805 loss: 9.23188395e-07
Iter: 806 loss: 9.22957838e-07
Iter: 807 loss: 9.2265816e-07
Iter: 808 loss: 9.22226661e-07
Iter: 809 loss: 9.22209324e-07
Iter: 810 loss: 9.21718936e-07
Iter: 811 loss: 9.22240815e-07
Iter: 812 loss: 9.21476556e-07
Iter: 813 loss: 9.20962748e-07
Iter: 814 loss: 9.21060177e-07
Iter: 815 loss: 9.2053574e-07
Iter: 816 loss: 9.19953777e-07
Iter: 817 loss: 9.19755166e-07
Iter: 818 loss: 9.19453669e-07
Iter: 819 loss: 9.19787283e-07
Iter: 820 loss: 9.19164449e-07
Iter: 821 loss: 9.18927526e-07
Iter: 822 loss: 9.1867588e-07
Iter: 823 loss: 9.18597721e-07
Iter: 824 loss: 9.18158378e-07
Iter: 825 loss: 9.18485512e-07
Iter: 826 loss: 9.17887178e-07
Iter: 827 loss: 9.17432089e-07
Iter: 828 loss: 9.18243416e-07
Iter: 829 loss: 9.17201078e-07
Iter: 830 loss: 9.16742749e-07
Iter: 831 loss: 9.16085696e-07
Iter: 832 loss: 9.16005092e-07
Iter: 833 loss: 9.15887824e-07
Iter: 834 loss: 9.15609917e-07
Iter: 835 loss: 9.15346561e-07
Iter: 836 loss: 9.1501272e-07
Iter: 837 loss: 9.14974692e-07
Iter: 838 loss: 9.1452614e-07
Iter: 839 loss: 9.15776468e-07
Iter: 840 loss: 9.14314228e-07
Iter: 841 loss: 9.13793485e-07
Iter: 842 loss: 9.16419594e-07
Iter: 843 loss: 9.1373181e-07
Iter: 844 loss: 9.13266263e-07
Iter: 845 loss: 9.15743215e-07
Iter: 846 loss: 9.13185374e-07
Iter: 847 loss: 9.12858127e-07
Iter: 848 loss: 9.12133487e-07
Iter: 849 loss: 9.20552452e-07
Iter: 850 loss: 9.12100518e-07
Iter: 851 loss: 9.1127e-07
Iter: 852 loss: 9.17304646e-07
Iter: 853 loss: 9.11162886e-07
Iter: 854 loss: 9.10913116e-07
Iter: 855 loss: 9.10940628e-07
Iter: 856 loss: 9.1051794e-07
Iter: 857 loss: 9.09985545e-07
Iter: 858 loss: 9.09925063e-07
Iter: 859 loss: 9.09431662e-07
Iter: 860 loss: 9.14159273e-07
Iter: 861 loss: 9.09401422e-07
Iter: 862 loss: 9.09190646e-07
Iter: 863 loss: 9.08721404e-07
Iter: 864 loss: 9.08679681e-07
Iter: 865 loss: 9.08054119e-07
Iter: 866 loss: 9.09796199e-07
Iter: 867 loss: 9.07818105e-07
Iter: 868 loss: 9.0716884e-07
Iter: 869 loss: 9.08765912e-07
Iter: 870 loss: 9.06986315e-07
Iter: 871 loss: 9.06447895e-07
Iter: 872 loss: 9.06478e-07
Iter: 873 loss: 9.06237801e-07
Iter: 874 loss: 9.05744344e-07
Iter: 875 loss: 9.16545503e-07
Iter: 876 loss: 9.05749e-07
Iter: 877 loss: 9.05130378e-07
Iter: 878 loss: 9.08554057e-07
Iter: 879 loss: 9.05046306e-07
Iter: 880 loss: 9.04713943e-07
Iter: 881 loss: 9.08956736e-07
Iter: 882 loss: 9.04723663e-07
Iter: 883 loss: 9.04311491e-07
Iter: 884 loss: 9.03626301e-07
Iter: 885 loss: 9.19740387e-07
Iter: 886 loss: 9.03661e-07
Iter: 887 loss: 9.02968e-07
Iter: 888 loss: 9.06608705e-07
Iter: 889 loss: 9.02833165e-07
Iter: 890 loss: 9.02449472e-07
Iter: 891 loss: 9.0247687e-07
Iter: 892 loss: 9.02191e-07
Iter: 893 loss: 9.01704652e-07
Iter: 894 loss: 9.01737735e-07
Iter: 895 loss: 9.01245642e-07
Iter: 896 loss: 9.03243802e-07
Iter: 897 loss: 9.01126157e-07
Iter: 898 loss: 9.00615532e-07
Iter: 899 loss: 9.0048195e-07
Iter: 900 loss: 9.00150155e-07
Iter: 901 loss: 8.99570409e-07
Iter: 902 loss: 9.00402597e-07
Iter: 903 loss: 8.99310805e-07
Iter: 904 loss: 8.98928079e-07
Iter: 905 loss: 9.05103718e-07
Iter: 906 loss: 8.98956046e-07
Iter: 907 loss: 8.98602423e-07
Iter: 908 loss: 8.99625093e-07
Iter: 909 loss: 8.98495045e-07
Iter: 910 loss: 8.98104133e-07
Iter: 911 loss: 8.97571397e-07
Iter: 912 loss: 8.97548489e-07
Iter: 913 loss: 8.97025132e-07
Iter: 914 loss: 9.02967372e-07
Iter: 915 loss: 8.97041616e-07
Iter: 916 loss: 8.96660481e-07
Iter: 917 loss: 8.98956728e-07
Iter: 918 loss: 8.9657118e-07
Iter: 919 loss: 8.96170661e-07
Iter: 920 loss: 8.95888263e-07
Iter: 921 loss: 8.95759626e-07
Iter: 922 loss: 8.95354844e-07
Iter: 923 loss: 8.99782151e-07
Iter: 924 loss: 8.95378491e-07
Iter: 925 loss: 8.94949039e-07
Iter: 926 loss: 8.95849269e-07
Iter: 927 loss: 8.94776065e-07
Iter: 928 loss: 8.94521804e-07
Iter: 929 loss: 8.94401069e-07
Iter: 930 loss: 8.94361449e-07
Iter: 931 loss: 8.9383866e-07
Iter: 932 loss: 8.94479342e-07
Iter: 933 loss: 8.93583206e-07
Iter: 934 loss: 8.93173649e-07
Iter: 935 loss: 8.95541746e-07
Iter: 936 loss: 8.9316427e-07
Iter: 937 loss: 8.92824744e-07
Iter: 938 loss: 8.92347e-07
Iter: 939 loss: 8.92309231e-07
Iter: 940 loss: 8.91903596e-07
Iter: 941 loss: 8.91866875e-07
Iter: 942 loss: 8.91442653e-07
Iter: 943 loss: 8.91804916e-07
Iter: 944 loss: 8.91216928e-07
Iter: 945 loss: 8.907e-07
Iter: 946 loss: 8.90497631e-07
Iter: 947 loss: 8.90275601e-07
Iter: 948 loss: 8.89620651e-07
Iter: 949 loss: 8.9732896e-07
Iter: 950 loss: 8.8965669e-07
Iter: 951 loss: 8.89134071e-07
Iter: 952 loss: 8.91084824e-07
Iter: 953 loss: 8.89026751e-07
Iter: 954 loss: 8.88738612e-07
Iter: 955 loss: 8.88345596e-07
Iter: 956 loss: 8.88309842e-07
Iter: 957 loss: 8.87971851e-07
Iter: 958 loss: 8.87932e-07
Iter: 959 loss: 8.87792794e-07
Iter: 960 loss: 8.87434283e-07
Iter: 961 loss: 8.9346122e-07
Iter: 962 loss: 8.87424221e-07
Iter: 963 loss: 8.87047349e-07
Iter: 964 loss: 8.87740612e-07
Iter: 965 loss: 8.86882674e-07
Iter: 966 loss: 8.86426051e-07
Iter: 967 loss: 8.90237231e-07
Iter: 968 loss: 8.86453734e-07
Iter: 969 loss: 8.86145244e-07
Iter: 970 loss: 8.85691406e-07
Iter: 971 loss: 8.85679e-07
Iter: 972 loss: 8.85254451e-07
Iter: 973 loss: 8.88307454e-07
Iter: 974 loss: 8.85189479e-07
Iter: 975 loss: 8.84798283e-07
Iter: 976 loss: 8.8635386e-07
Iter: 977 loss: 8.8470415e-07
Iter: 978 loss: 8.84215751e-07
Iter: 979 loss: 8.85803217e-07
Iter: 980 loss: 8.84112296e-07
Iter: 981 loss: 8.83807786e-07
Iter: 982 loss: 8.83310065e-07
Iter: 983 loss: 8.83290738e-07
Iter: 984 loss: 8.83100427e-07
Iter: 985 loss: 8.8300942e-07
Iter: 986 loss: 8.8275425e-07
Iter: 987 loss: 8.82797679e-07
Iter: 988 loss: 8.82509937e-07
Iter: 989 loss: 8.82231177e-07
Iter: 990 loss: 8.81646429e-07
Iter: 991 loss: 8.8163e-07
Iter: 992 loss: 8.81423261e-07
Iter: 993 loss: 8.81314065e-07
Iter: 994 loss: 8.8098011e-07
Iter: 995 loss: 8.81454525e-07
Iter: 996 loss: 8.80853577e-07
Iter: 997 loss: 8.80609718e-07
Iter: 998 loss: 8.80226e-07
Iter: 999 loss: 8.80208688e-07
Iter: 1000 loss: 8.79766276e-07
Iter: 1001 loss: 8.81126653e-07
Iter: 1002 loss: 8.79566812e-07
Iter: 1003 loss: 8.79268e-07
Iter: 1004 loss: 8.79276115e-07
Iter: 1005 loss: 8.79013328e-07
Iter: 1006 loss: 8.78514413e-07
Iter: 1007 loss: 8.854459e-07
Iter: 1008 loss: 8.78502817e-07
Iter: 1009 loss: 8.77942625e-07
Iter: 1010 loss: 8.82401935e-07
Iter: 1011 loss: 8.77862e-07
Iter: 1012 loss: 8.77472871e-07
Iter: 1013 loss: 8.77558364e-07
Iter: 1014 loss: 8.77094635e-07
Iter: 1015 loss: 8.7678734e-07
Iter: 1016 loss: 8.76696163e-07
Iter: 1017 loss: 8.76455147e-07
Iter: 1018 loss: 8.7604235e-07
Iter: 1019 loss: 8.76052297e-07
Iter: 1020 loss: 8.75626597e-07
Iter: 1021 loss: 8.79769345e-07
Iter: 1022 loss: 8.75605565e-07
Iter: 1023 loss: 8.75251828e-07
Iter: 1024 loss: 8.7697282e-07
Iter: 1025 loss: 8.75214766e-07
Iter: 1026 loss: 8.74874331e-07
Iter: 1027 loss: 8.74602847e-07
Iter: 1028 loss: 8.74508032e-07
Iter: 1029 loss: 8.74526108e-07
Iter: 1030 loss: 8.74367345e-07
Iter: 1031 loss: 8.74211764e-07
Iter: 1032 loss: 8.73825854e-07
Iter: 1033 loss: 8.76673e-07
Iter: 1034 loss: 8.73721774e-07
Iter: 1035 loss: 8.7331e-07
Iter: 1036 loss: 8.75036449e-07
Iter: 1037 loss: 8.73204556e-07
Iter: 1038 loss: 8.72952683e-07
Iter: 1039 loss: 8.76061335e-07
Iter: 1040 loss: 8.7291204e-07
Iter: 1041 loss: 8.72747933e-07
Iter: 1042 loss: 8.72398857e-07
Iter: 1043 loss: 8.72385328e-07
Iter: 1044 loss: 8.7200732e-07
Iter: 1045 loss: 8.72777377e-07
Iter: 1046 loss: 8.71844236e-07
Iter: 1047 loss: 8.71320537e-07
Iter: 1048 loss: 8.72126293e-07
Iter: 1049 loss: 8.71079123e-07
Iter: 1050 loss: 8.70554e-07
Iter: 1051 loss: 8.717318e-07
Iter: 1052 loss: 8.70307701e-07
Iter: 1053 loss: 8.7010244e-07
Iter: 1054 loss: 8.70075155e-07
Iter: 1055 loss: 8.69806286e-07
Iter: 1056 loss: 8.69514565e-07
Iter: 1057 loss: 8.69491e-07
Iter: 1058 loss: 8.69082157e-07
Iter: 1059 loss: 8.73109684e-07
Iter: 1060 loss: 8.69068458e-07
Iter: 1061 loss: 8.68819427e-07
Iter: 1062 loss: 8.70502902e-07
Iter: 1063 loss: 8.6880533e-07
Iter: 1064 loss: 8.6860274e-07
Iter: 1065 loss: 8.69364726e-07
Iter: 1066 loss: 8.68571306e-07
Iter: 1067 loss: 8.68361724e-07
Iter: 1068 loss: 8.67958249e-07
Iter: 1069 loss: 8.75579872e-07
Iter: 1070 loss: 8.6797445e-07
Iter: 1071 loss: 8.67708309e-07
Iter: 1072 loss: 8.67653398e-07
Iter: 1073 loss: 8.67378219e-07
Iter: 1074 loss: 8.66883056e-07
Iter: 1075 loss: 8.68779921e-07
Iter: 1076 loss: 8.66791822e-07
Iter: 1077 loss: 8.66308255e-07
Iter: 1078 loss: 8.67418862e-07
Iter: 1079 loss: 8.66122321e-07
Iter: 1080 loss: 8.65886534e-07
Iter: 1081 loss: 8.65854645e-07
Iter: 1082 loss: 8.65642562e-07
Iter: 1083 loss: 8.65570769e-07
Iter: 1084 loss: 8.65435538e-07
Iter: 1085 loss: 8.65103857e-07
Iter: 1086 loss: 8.65392963e-07
Iter: 1087 loss: 8.64940603e-07
Iter: 1088 loss: 8.64568563e-07
Iter: 1089 loss: 8.65692869e-07
Iter: 1090 loss: 8.64395702e-07
Iter: 1091 loss: 8.64153549e-07
Iter: 1092 loss: 8.6598493e-07
Iter: 1093 loss: 8.64148831e-07
Iter: 1094 loss: 8.63748426e-07
Iter: 1095 loss: 8.6438439e-07
Iter: 1096 loss: 8.63650541e-07
Iter: 1097 loss: 8.63315961e-07
Iter: 1098 loss: 8.64488584e-07
Iter: 1099 loss: 8.63202558e-07
Iter: 1100 loss: 8.62955915e-07
Iter: 1101 loss: 8.66811433e-07
Iter: 1102 loss: 8.62961826e-07
Iter: 1103 loss: 8.62840807e-07
Iter: 1104 loss: 8.62406125e-07
Iter: 1105 loss: 8.63751e-07
Iter: 1106 loss: 8.62158402e-07
Iter: 1107 loss: 8.61987189e-07
Iter: 1108 loss: 8.61887884e-07
Iter: 1109 loss: 8.61667615e-07
Iter: 1110 loss: 8.61595e-07
Iter: 1111 loss: 8.61422791e-07
Iter: 1112 loss: 8.61117e-07
Iter: 1113 loss: 8.61290687e-07
Iter: 1114 loss: 8.60904606e-07
Iter: 1115 loss: 8.60558487e-07
Iter: 1116 loss: 8.6245916e-07
Iter: 1117 loss: 8.60545128e-07
Iter: 1118 loss: 8.60250339e-07
Iter: 1119 loss: 8.60112948e-07
Iter: 1120 loss: 8.59960778e-07
Iter: 1121 loss: 8.59562533e-07
Iter: 1122 loss: 8.61640672e-07
Iter: 1123 loss: 8.5952e-07
Iter: 1124 loss: 8.59209877e-07
Iter: 1125 loss: 8.59553097e-07
Iter: 1126 loss: 8.59079364e-07
Iter: 1127 loss: 8.5868578e-07
Iter: 1128 loss: 8.58831413e-07
Iter: 1129 loss: 8.58426e-07
Iter: 1130 loss: 8.5800832e-07
Iter: 1131 loss: 8.58006558e-07
Iter: 1132 loss: 8.57755424e-07
Iter: 1133 loss: 8.58057774e-07
Iter: 1134 loss: 8.57616328e-07
Iter: 1135 loss: 8.57305508e-07
Iter: 1136 loss: 8.57167947e-07
Iter: 1137 loss: 8.5704005e-07
Iter: 1138 loss: 8.56773227e-07
Iter: 1139 loss: 8.56764132e-07
Iter: 1140 loss: 8.5646036e-07
Iter: 1141 loss: 8.5673463e-07
Iter: 1142 loss: 8.56336783e-07
Iter: 1143 loss: 8.56082295e-07
Iter: 1144 loss: 8.58035719e-07
Iter: 1145 loss: 8.56092811e-07
Iter: 1146 loss: 8.55936491e-07
Iter: 1147 loss: 8.5575715e-07
Iter: 1148 loss: 8.55733219e-07
Iter: 1149 loss: 8.55377891e-07
Iter: 1150 loss: 8.55690701e-07
Iter: 1151 loss: 8.55202416e-07
Iter: 1152 loss: 8.54890686e-07
Iter: 1153 loss: 8.57623149e-07
Iter: 1154 loss: 8.54844814e-07
Iter: 1155 loss: 8.54594305e-07
Iter: 1156 loss: 8.5437182e-07
Iter: 1157 loss: 8.54360792e-07
Iter: 1158 loss: 8.53924405e-07
Iter: 1159 loss: 8.55461053e-07
Iter: 1160 loss: 8.53830159e-07
Iter: 1161 loss: 8.53500637e-07
Iter: 1162 loss: 8.5381032e-07
Iter: 1163 loss: 8.5332033e-07
Iter: 1164 loss: 8.52942833e-07
Iter: 1165 loss: 8.54913878e-07
Iter: 1166 loss: 8.5293118e-07
Iter: 1167 loss: 8.52612516e-07
Iter: 1168 loss: 8.55415294e-07
Iter: 1169 loss: 8.52551182e-07
Iter: 1170 loss: 8.52400831e-07
Iter: 1171 loss: 8.52464382e-07
Iter: 1172 loss: 8.52147537e-07
Iter: 1173 loss: 8.51831601e-07
Iter: 1174 loss: 8.51354741e-07
Iter: 1175 loss: 8.51334619e-07
Iter: 1176 loss: 8.51355594e-07
Iter: 1177 loss: 8.51100708e-07
Iter: 1178 loss: 8.50911135e-07
Iter: 1179 loss: 8.51196887e-07
Iter: 1180 loss: 8.50839911e-07
Iter: 1181 loss: 8.50602135e-07
Iter: 1182 loss: 8.51243385e-07
Iter: 1183 loss: 8.50505103e-07
Iter: 1184 loss: 8.50233846e-07
Iter: 1185 loss: 8.50415404e-07
Iter: 1186 loss: 8.50114589e-07
Iter: 1187 loss: 8.49841797e-07
Iter: 1188 loss: 8.49855041e-07
Iter: 1189 loss: 8.49641424e-07
Iter: 1190 loss: 8.49216804e-07
Iter: 1191 loss: 8.50587867e-07
Iter: 1192 loss: 8.49124774e-07
Iter: 1193 loss: 8.48748073e-07
Iter: 1194 loss: 8.49184858e-07
Iter: 1195 loss: 8.48564241e-07
Iter: 1196 loss: 8.48227501e-07
Iter: 1197 loss: 8.49001e-07
Iter: 1198 loss: 8.48088746e-07
Iter: 1199 loss: 8.47750869e-07
Iter: 1200 loss: 8.48262061e-07
Iter: 1201 loss: 8.47559932e-07
Iter: 1202 loss: 8.47207389e-07
Iter: 1203 loss: 8.50660626e-07
Iter: 1204 loss: 8.47197043e-07
Iter: 1205 loss: 8.46983426e-07
Iter: 1206 loss: 8.48448963e-07
Iter: 1207 loss: 8.469558e-07
Iter: 1208 loss: 8.46642422e-07
Iter: 1209 loss: 8.46228147e-07
Iter: 1210 loss: 8.4621297e-07
Iter: 1211 loss: 8.45966269e-07
Iter: 1212 loss: 8.45954162e-07
Iter: 1213 loss: 8.45778857e-07
Iter: 1214 loss: 8.48655304e-07
Iter: 1215 loss: 8.45750606e-07
Iter: 1216 loss: 8.4564391e-07
Iter: 1217 loss: 8.45578484e-07
Iter: 1218 loss: 8.45543127e-07
Iter: 1219 loss: 8.45242482e-07
Iter: 1220 loss: 8.45879356e-07
Iter: 1221 loss: 8.45139709e-07
Iter: 1222 loss: 8.44853503e-07
Iter: 1223 loss: 8.44776139e-07
Iter: 1224 loss: 8.44634258e-07
Iter: 1225 loss: 8.44417286e-07
Iter: 1226 loss: 8.46614739e-07
Iter: 1227 loss: 8.44360954e-07
Iter: 1228 loss: 8.44117437e-07
Iter: 1229 loss: 8.43873067e-07
Iter: 1230 loss: 8.43794965e-07
Iter: 1231 loss: 8.43416274e-07
Iter: 1232 loss: 8.4548634e-07
Iter: 1233 loss: 8.43382111e-07
Iter: 1234 loss: 8.42996656e-07
Iter: 1235 loss: 8.42876602e-07
Iter: 1236 loss: 8.42702264e-07
Iter: 1237 loss: 8.42315e-07
Iter: 1238 loss: 8.42310499e-07
Iter: 1239 loss: 8.41997576e-07
Iter: 1240 loss: 8.42697318e-07
Iter: 1241 loss: 8.41927033e-07
Iter: 1242 loss: 8.41681242e-07
Iter: 1243 loss: 8.41841029e-07
Iter: 1244 loss: 8.41514179e-07
Iter: 1245 loss: 8.41205519e-07
Iter: 1246 loss: 8.42103304e-07
Iter: 1247 loss: 8.41166298e-07
Iter: 1248 loss: 8.40797099e-07
Iter: 1249 loss: 8.43147461e-07
Iter: 1250 loss: 8.40787834e-07
Iter: 1251 loss: 8.40587518e-07
Iter: 1252 loss: 8.41143105e-07
Iter: 1253 loss: 8.40539315e-07
Iter: 1254 loss: 8.40343e-07
Iter: 1255 loss: 8.40553241e-07
Iter: 1256 loss: 8.40292273e-07
Iter: 1257 loss: 8.40069561e-07
Iter: 1258 loss: 8.3977227e-07
Iter: 1259 loss: 8.39752829e-07
Iter: 1260 loss: 8.39509426e-07
Iter: 1261 loss: 8.44050874e-07
Iter: 1262 loss: 8.39502036e-07
Iter: 1263 loss: 8.39256927e-07
Iter: 1264 loss: 8.39110498e-07
Iter: 1265 loss: 8.3903825e-07
Iter: 1266 loss: 8.38723793e-07
Iter: 1267 loss: 8.39419329e-07
Iter: 1268 loss: 8.38575716e-07
Iter: 1269 loss: 8.38225901e-07
Iter: 1270 loss: 8.39090148e-07
Iter: 1271 loss: 8.38128813e-07
Iter: 1272 loss: 8.37818277e-07
Iter: 1273 loss: 8.41493e-07
Iter: 1274 loss: 8.37870289e-07
Iter: 1275 loss: 8.37560378e-07
Iter: 1276 loss: 8.37614721e-07
Iter: 1277 loss: 8.37410596e-07
Iter: 1278 loss: 8.37102334e-07
Iter: 1279 loss: 8.38169228e-07
Iter: 1280 loss: 8.37015591e-07
Iter: 1281 loss: 8.36828121e-07
Iter: 1282 loss: 8.38138419e-07
Iter: 1283 loss: 8.36813911e-07
Iter: 1284 loss: 8.36524919e-07
Iter: 1285 loss: 8.37013602e-07
Iter: 1286 loss: 8.36443633e-07
Iter: 1287 loss: 8.36297886e-07
Iter: 1288 loss: 8.37185212e-07
Iter: 1289 loss: 8.36313177e-07
Iter: 1290 loss: 8.36161348e-07
Iter: 1291 loss: 8.35915046e-07
Iter: 1292 loss: 8.35879689e-07
Iter: 1293 loss: 8.35577907e-07
Iter: 1294 loss: 8.36148956e-07
Iter: 1295 loss: 8.35438527e-07
Iter: 1296 loss: 8.35277e-07
Iter: 1297 loss: 8.35276808e-07
Iter: 1298 loss: 8.35063815e-07
Iter: 1299 loss: 8.34904938e-07
Iter: 1300 loss: 8.34867e-07
Iter: 1301 loss: 8.34632885e-07
Iter: 1302 loss: 8.35345759e-07
Iter: 1303 loss: 8.34516754e-07
Iter: 1304 loss: 8.34209118e-07
Iter: 1305 loss: 8.34826665e-07
Iter: 1306 loss: 8.34038929e-07
Iter: 1307 loss: 8.33785123e-07
Iter: 1308 loss: 8.35541812e-07
Iter: 1309 loss: 8.3373908e-07
Iter: 1310 loss: 8.33441959e-07
Iter: 1311 loss: 8.34126e-07
Iter: 1312 loss: 8.33359195e-07
Iter: 1313 loss: 8.33157969e-07
Iter: 1314 loss: 8.33700824e-07
Iter: 1315 loss: 8.3304883e-07
Iter: 1316 loss: 8.32889157e-07
Iter: 1317 loss: 8.34800346e-07
Iter: 1318 loss: 8.32893534e-07
Iter: 1319 loss: 8.32653541e-07
Iter: 1320 loss: 8.32605963e-07
Iter: 1321 loss: 8.32530873e-07
Iter: 1322 loss: 8.32330159e-07
Iter: 1323 loss: 8.3302109e-07
Iter: 1324 loss: 8.32265755e-07
Iter: 1325 loss: 8.32031503e-07
Iter: 1326 loss: 8.32499609e-07
Iter: 1327 loss: 8.31989951e-07
Iter: 1328 loss: 8.31833e-07
Iter: 1329 loss: 8.31657758e-07
Iter: 1330 loss: 8.31640421e-07
Iter: 1331 loss: 8.31342334e-07
Iter: 1332 loss: 8.32029e-07
Iter: 1333 loss: 8.31199088e-07
Iter: 1334 loss: 8.3095415e-07
Iter: 1335 loss: 8.34815e-07
Iter: 1336 loss: 8.30995077e-07
Iter: 1337 loss: 8.30801071e-07
Iter: 1338 loss: 8.30463705e-07
Iter: 1339 loss: 8.35344338e-07
Iter: 1340 loss: 8.30410102e-07
Iter: 1341 loss: 8.30080069e-07
Iter: 1342 loss: 8.34244474e-07
Iter: 1343 loss: 8.30079216e-07
Iter: 1344 loss: 8.29794658e-07
Iter: 1345 loss: 8.30066881e-07
Iter: 1346 loss: 8.29703424e-07
Iter: 1347 loss: 8.29397891e-07
Iter: 1348 loss: 8.32826345e-07
Iter: 1349 loss: 8.29433134e-07
Iter: 1350 loss: 8.29261467e-07
Iter: 1351 loss: 8.29083319e-07
Iter: 1352 loss: 8.29077067e-07
Iter: 1353 loss: 8.28933537e-07
Iter: 1354 loss: 8.28916086e-07
Iter: 1355 loss: 8.28754196e-07
Iter: 1356 loss: 8.28706845e-07
Iter: 1357 loss: 8.28627549e-07
Iter: 1358 loss: 8.28454404e-07
Iter: 1359 loss: 8.28092254e-07
Iter: 1360 loss: 8.28094244e-07
Iter: 1361 loss: 8.27939971e-07
Iter: 1362 loss: 8.27863687e-07
Iter: 1363 loss: 8.27628241e-07
Iter: 1364 loss: 8.27723511e-07
Iter: 1365 loss: 8.27494091e-07
Iter: 1366 loss: 8.27235738e-07
Iter: 1367 loss: 8.27395468e-07
Iter: 1368 loss: 8.27173096e-07
Iter: 1369 loss: 8.268957e-07
Iter: 1370 loss: 8.27170538e-07
Iter: 1371 loss: 8.26774567e-07
Iter: 1372 loss: 8.26544124e-07
Iter: 1373 loss: 8.27611643e-07
Iter: 1374 loss: 8.265e-07
Iter: 1375 loss: 8.26276164e-07
Iter: 1376 loss: 8.28589464e-07
Iter: 1377 loss: 8.2625877e-07
Iter: 1378 loss: 8.26131554e-07
Iter: 1379 loss: 8.26070277e-07
Iter: 1380 loss: 8.25986376e-07
Iter: 1381 loss: 8.25709e-07
Iter: 1382 loss: 8.25576535e-07
Iter: 1383 loss: 8.2548604e-07
Iter: 1384 loss: 8.25224163e-07
Iter: 1385 loss: 8.25247298e-07
Iter: 1386 loss: 8.25047e-07
Iter: 1387 loss: 8.25230813e-07
Iter: 1388 loss: 8.24953759e-07
Iter: 1389 loss: 8.24630149e-07
Iter: 1390 loss: 8.24702624e-07
Iter: 1391 loss: 8.24375e-07
Iter: 1392 loss: 8.2418353e-07
Iter: 1393 loss: 8.24929316e-07
Iter: 1394 loss: 8.24128335e-07
Iter: 1395 loss: 8.23947744e-07
Iter: 1396 loss: 8.25383381e-07
Iter: 1397 loss: 8.23960761e-07
Iter: 1398 loss: 8.2378989e-07
Iter: 1399 loss: 8.23552796e-07
Iter: 1400 loss: 8.23577125e-07
Iter: 1401 loss: 8.23268465e-07
Iter: 1402 loss: 8.23425466e-07
Iter: 1403 loss: 8.23148639e-07
Iter: 1404 loss: 8.22877496e-07
Iter: 1405 loss: 8.24676874e-07
Iter: 1406 loss: 8.228144e-07
Iter: 1407 loss: 8.22531604e-07
Iter: 1408 loss: 8.22491643e-07
Iter: 1409 loss: 8.22355105e-07
Iter: 1410 loss: 8.22192703e-07
Iter: 1411 loss: 8.22113748e-07
Iter: 1412 loss: 8.21956917e-07
Iter: 1413 loss: 8.21874835e-07
Iter: 1414 loss: 8.21854542e-07
Iter: 1415 loss: 8.21590731e-07
Iter: 1416 loss: 8.21771948e-07
Iter: 1417 loss: 8.21431172e-07
Iter: 1418 loss: 8.21211245e-07
Iter: 1419 loss: 8.21199478e-07
Iter: 1420 loss: 8.21067601e-07
Iter: 1421 loss: 8.21277922e-07
Iter: 1422 loss: 8.2102116e-07
Iter: 1423 loss: 8.20883e-07
Iter: 1424 loss: 8.21078856e-07
Iter: 1425 loss: 8.20803962e-07
Iter: 1426 loss: 8.20686068e-07
Iter: 1427 loss: 8.20406171e-07
Iter: 1428 loss: 8.24749918e-07
Iter: 1429 loss: 8.20441528e-07
Iter: 1430 loss: 8.20163564e-07
Iter: 1431 loss: 8.20207561e-07
Iter: 1432 loss: 8.20082846e-07
Iter: 1433 loss: 8.19796639e-07
Iter: 1434 loss: 8.23525738e-07
Iter: 1435 loss: 8.19763954e-07
Iter: 1436 loss: 8.19465924e-07
Iter: 1437 loss: 8.20618936e-07
Iter: 1438 loss: 8.19412321e-07
Iter: 1439 loss: 8.19119919e-07
Iter: 1440 loss: 8.19374861e-07
Iter: 1441 loss: 8.18916817e-07
Iter: 1442 loss: 8.18645844e-07
Iter: 1443 loss: 8.2085711e-07
Iter: 1444 loss: 8.18636522e-07
Iter: 1445 loss: 8.18353783e-07
Iter: 1446 loss: 8.20090804e-07
Iter: 1447 loss: 8.18354806e-07
Iter: 1448 loss: 8.18109754e-07
Iter: 1449 loss: 8.18449848e-07
Iter: 1450 loss: 8.18015167e-07
Iter: 1451 loss: 8.17843272e-07
Iter: 1452 loss: 8.19296815e-07
Iter: 1453 loss: 8.17860268e-07
Iter: 1454 loss: 8.17576733e-07
Iter: 1455 loss: 8.18359695e-07
Iter: 1456 loss: 8.17531202e-07
Iter: 1457 loss: 8.1741905e-07
Iter: 1458 loss: 8.181662e-07
Iter: 1459 loss: 8.17379487e-07
Iter: 1460 loss: 8.17240732e-07
Iter: 1461 loss: 8.16946681e-07
Iter: 1462 loss: 8.21989033e-07
Iter: 1463 loss: 8.16947249e-07
Iter: 1464 loss: 8.16771546e-07
Iter: 1465 loss: 8.16743295e-07
Iter: 1466 loss: 8.16614715e-07
Iter: 1467 loss: 8.17201339e-07
Iter: 1468 loss: 8.16566796e-07
Iter: 1469 loss: 8.16427701e-07
Iter: 1470 loss: 8.16051056e-07
Iter: 1471 loss: 8.19887759e-07
Iter: 1472 loss: 8.16020417e-07
Iter: 1473 loss: 8.15702606e-07
Iter: 1474 loss: 8.16777742e-07
Iter: 1475 loss: 8.15560441e-07
Iter: 1476 loss: 8.15219209e-07
Iter: 1477 loss: 8.17482487e-07
Iter: 1478 loss: 8.15181238e-07
Iter: 1479 loss: 8.14855696e-07
Iter: 1480 loss: 8.15453348e-07
Iter: 1481 loss: 8.147627e-07
Iter: 1482 loss: 8.14436191e-07
Iter: 1483 loss: 8.14580176e-07
Iter: 1484 loss: 8.1424264e-07
Iter: 1485 loss: 8.13967802e-07
Iter: 1486 loss: 8.17508862e-07
Iter: 1487 loss: 8.13938072e-07
Iter: 1488 loss: 8.13726047e-07
Iter: 1489 loss: 8.16379895e-07
Iter: 1490 loss: 8.13720476e-07
Iter: 1491 loss: 8.1351817e-07
Iter: 1492 loss: 8.13654822e-07
Iter: 1493 loss: 8.13392319e-07
Iter: 1494 loss: 8.13160682e-07
Iter: 1495 loss: 8.14394639e-07
Iter: 1496 loss: 8.13156873e-07
Iter: 1497 loss: 8.13048644e-07
Iter: 1498 loss: 8.12860833e-07
Iter: 1499 loss: 8.17608736e-07
Iter: 1500 loss: 8.12866517e-07
Iter: 1501 loss: 8.12565133e-07
Iter: 1502 loss: 8.15525e-07
Iter: 1503 loss: 8.12590372e-07
Iter: 1504 loss: 8.12389374e-07
Iter: 1505 loss: 8.12427174e-07
Iter: 1506 loss: 8.12272e-07
Iter: 1507 loss: 8.12097426e-07
Iter: 1508 loss: 8.12646249e-07
Iter: 1509 loss: 8.12014491e-07
Iter: 1510 loss: 8.11758923e-07
Iter: 1511 loss: 8.12003e-07
Iter: 1512 loss: 8.11598113e-07
Iter: 1513 loss: 8.11353459e-07
Iter: 1514 loss: 8.11402799e-07
Iter: 1515 loss: 8.11127393e-07
Iter: 1516 loss: 8.1088649e-07
Iter: 1517 loss: 8.11928e-07
Iter: 1518 loss: 8.10777919e-07
Iter: 1519 loss: 8.10507458e-07
Iter: 1520 loss: 8.10504275e-07
Iter: 1521 loss: 8.10187089e-07
Iter: 1522 loss: 8.09961875e-07
Iter: 1523 loss: 8.13284885e-07
Iter: 1524 loss: 8.09965513e-07
Iter: 1525 loss: 8.09857511e-07
Iter: 1526 loss: 8.09869e-07
Iter: 1527 loss: 8.09735411e-07
Iter: 1528 loss: 8.09578751e-07
Iter: 1529 loss: 8.09596202e-07
Iter: 1530 loss: 8.09330288e-07
Iter: 1531 loss: 8.09551693e-07
Iter: 1532 loss: 8.09157086e-07
Iter: 1533 loss: 8.08898e-07
Iter: 1534 loss: 8.09817266e-07
Iter: 1535 loss: 8.08780328e-07
Iter: 1536 loss: 8.08651066e-07
Iter: 1537 loss: 8.08676077e-07
Iter: 1538 loss: 8.0852476e-07
Iter: 1539 loss: 8.0817972e-07
Iter: 1540 loss: 8.10450842e-07
Iter: 1541 loss: 8.0815289e-07
Iter: 1542 loss: 8.07938363e-07
Iter: 1543 loss: 8.07912897e-07
Iter: 1544 loss: 8.07765673e-07
Iter: 1545 loss: 8.07662e-07
Iter: 1546 loss: 8.07612707e-07
Iter: 1547 loss: 8.0737982e-07
Iter: 1548 loss: 8.07321214e-07
Iter: 1549 loss: 8.07149718e-07
Iter: 1550 loss: 8.06860328e-07
Iter: 1551 loss: 8.06845151e-07
Iter: 1552 loss: 8.06659273e-07
Iter: 1553 loss: 8.06251592e-07
Iter: 1554 loss: 8.09912308e-07
Iter: 1555 loss: 8.06164849e-07
Iter: 1556 loss: 8.05925652e-07
Iter: 1557 loss: 8.06076287e-07
Iter: 1558 loss: 8.05727495e-07
Iter: 1559 loss: 8.05531613e-07
Iter: 1560 loss: 8.05509899e-07
Iter: 1561 loss: 8.05324646e-07
Iter: 1562 loss: 8.05895866e-07
Iter: 1563 loss: 8.05285e-07
Iter: 1564 loss: 8.05086643e-07
Iter: 1565 loss: 8.05222271e-07
Iter: 1566 loss: 8.04998479e-07
Iter: 1567 loss: 8.04778324e-07
Iter: 1568 loss: 8.05039122e-07
Iter: 1569 loss: 8.04626666e-07
Iter: 1570 loss: 8.04393267e-07
Iter: 1571 loss: 8.04498939e-07
Iter: 1572 loss: 8.04167712e-07
Iter: 1573 loss: 8.03985131e-07
Iter: 1574 loss: 8.03987064e-07
Iter: 1575 loss: 8.0384973e-07
Iter: 1576 loss: 8.03677e-07
Iter: 1577 loss: 8.07349579e-07
Iter: 1578 loss: 8.0365237e-07
Iter: 1579 loss: 8.03467799e-07
Iter: 1580 loss: 8.05860623e-07
Iter: 1581 loss: 8.03482862e-07
Iter: 1582 loss: 8.03277203e-07
Iter: 1583 loss: 8.03326429e-07
Iter: 1584 loss: 8.03145099e-07
Iter: 1585 loss: 8.02951e-07
Iter: 1586 loss: 8.03011744e-07
Iter: 1587 loss: 8.02758279e-07
Iter: 1588 loss: 8.02464967e-07
Iter: 1589 loss: 8.02629756e-07
Iter: 1590 loss: 8.022771e-07
Iter: 1591 loss: 8.02007207e-07
Iter: 1592 loss: 8.02006184e-07
Iter: 1593 loss: 8.01870897e-07
Iter: 1594 loss: 8.01881356e-07
Iter: 1595 loss: 8.0175505e-07
Iter: 1596 loss: 8.01604529e-07
Iter: 1597 loss: 8.01618512e-07
Iter: 1598 loss: 8.01336398e-07
Iter: 1599 loss: 8.02003058e-07
Iter: 1600 loss: 8.01227145e-07
Iter: 1601 loss: 8.0103905e-07
Iter: 1602 loss: 8.01509714e-07
Iter: 1603 loss: 8.00948101e-07
Iter: 1604 loss: 8.0072391e-07
Iter: 1605 loss: 8.02054103e-07
Iter: 1606 loss: 8.00754435e-07
Iter: 1607 loss: 8.0060147e-07
Iter: 1608 loss: 8.00452653e-07
Iter: 1609 loss: 8.00324869e-07
Iter: 1610 loss: 8.00114e-07
Iter: 1611 loss: 8.0042139e-07
Iter: 1612 loss: 8.00001e-07
Iter: 1613 loss: 7.9969476e-07
Iter: 1614 loss: 8.01986573e-07
Iter: 1615 loss: 7.99721931e-07
Iter: 1616 loss: 7.99489783e-07
Iter: 1617 loss: 7.99525537e-07
Iter: 1618 loss: 7.99330678e-07
Iter: 1619 loss: 7.9903225e-07
Iter: 1620 loss: 7.99094039e-07
Iter: 1621 loss: 7.9879e-07
Iter: 1622 loss: 7.98519e-07
Iter: 1623 loss: 7.99903091e-07
Iter: 1624 loss: 7.985293e-07
Iter: 1625 loss: 7.98410497e-07
Iter: 1626 loss: 7.9837514e-07
Iter: 1627 loss: 7.98196652e-07
Iter: 1628 loss: 7.98152769e-07
Iter: 1629 loss: 7.98072165e-07
Iter: 1630 loss: 7.97940345e-07
Iter: 1631 loss: 7.98691246e-07
Iter: 1632 loss: 7.9791306e-07
Iter: 1633 loss: 7.97772429e-07
Iter: 1634 loss: 7.97596726e-07
Iter: 1635 loss: 7.97547955e-07
Iter: 1636 loss: 7.97315124e-07
Iter: 1637 loss: 7.98601832e-07
Iter: 1638 loss: 7.97256803e-07
Iter: 1639 loss: 7.97025223e-07
Iter: 1640 loss: 7.98395661e-07
Iter: 1641 loss: 7.96955476e-07
Iter: 1642 loss: 7.96833433e-07
Iter: 1643 loss: 7.96765733e-07
Iter: 1644 loss: 7.96659663e-07
Iter: 1645 loss: 7.96403697e-07
Iter: 1646 loss: 7.96717075e-07
Iter: 1647 loss: 7.96361689e-07
Iter: 1648 loss: 7.96011477e-07
Iter: 1649 loss: 7.97252312e-07
Iter: 1650 loss: 7.95940423e-07
Iter: 1651 loss: 7.95744825e-07
Iter: 1652 loss: 7.95950541e-07
Iter: 1653 loss: 7.95650578e-07
Iter: 1654 loss: 7.95369e-07
Iter: 1655 loss: 7.9527041e-07
Iter: 1656 loss: 7.95162123e-07
Iter: 1657 loss: 7.94949074e-07
Iter: 1658 loss: 7.94952143e-07
Iter: 1659 loss: 7.94725395e-07
Iter: 1660 loss: 7.95398762e-07
Iter: 1661 loss: 7.94650077e-07
Iter: 1662 loss: 7.94483356e-07
Iter: 1663 loss: 7.94600226e-07
Iter: 1664 loss: 7.94404855e-07
Iter: 1665 loss: 7.94202435e-07
Iter: 1666 loss: 7.95098856e-07
Iter: 1667 loss: 7.94200218e-07
Iter: 1668 loss: 7.93989102e-07
Iter: 1669 loss: 7.93659865e-07
Iter: 1670 loss: 7.93682659e-07
Iter: 1671 loss: 7.93491154e-07
Iter: 1672 loss: 7.93473873e-07
Iter: 1673 loss: 7.93320737e-07
Iter: 1674 loss: 7.93177605e-07
Iter: 1675 loss: 7.93157255e-07
Iter: 1676 loss: 7.92983258e-07
Iter: 1677 loss: 7.93326421e-07
Iter: 1678 loss: 7.92865592e-07
Iter: 1679 loss: 7.92638446e-07
Iter: 1680 loss: 7.93470917e-07
Iter: 1681 loss: 7.92568471e-07
Iter: 1682 loss: 7.92316655e-07
Iter: 1683 loss: 7.92955348e-07
Iter: 1684 loss: 7.92266121e-07
Iter: 1685 loss: 7.91938874e-07
Iter: 1686 loss: 7.92071432e-07
Iter: 1687 loss: 7.91818479e-07
Iter: 1688 loss: 7.91481625e-07
Iter: 1689 loss: 7.92566823e-07
Iter: 1690 loss: 7.91417278e-07
Iter: 1691 loss: 7.91388402e-07
Iter: 1692 loss: 7.9127517e-07
Iter: 1693 loss: 7.91211619e-07
Iter: 1694 loss: 7.9096651e-07
Iter: 1695 loss: 7.92652031e-07
Iter: 1696 loss: 7.908817e-07
Iter: 1697 loss: 7.90593845e-07
Iter: 1698 loss: 7.92286073e-07
Iter: 1699 loss: 7.90583158e-07
Iter: 1700 loss: 7.90316733e-07
Iter: 1701 loss: 7.90901595e-07
Iter: 1702 loss: 7.90250112e-07
Iter: 1703 loss: 7.90009608e-07
Iter: 1704 loss: 7.90291494e-07
Iter: 1705 loss: 7.89935712e-07
Iter: 1706 loss: 7.89802186e-07
Iter: 1707 loss: 7.89768819e-07
Iter: 1708 loss: 7.89686737e-07
Iter: 1709 loss: 7.89361479e-07
Iter: 1710 loss: 7.91581328e-07
Iter: 1711 loss: 7.89306682e-07
Iter: 1712 loss: 7.89120065e-07
Iter: 1713 loss: 7.92290848e-07
Iter: 1714 loss: 7.89121941e-07
Iter: 1715 loss: 7.88901843e-07
Iter: 1716 loss: 7.89457545e-07
Iter: 1717 loss: 7.88859666e-07
Iter: 1718 loss: 7.88659122e-07
Iter: 1719 loss: 7.88510192e-07
Iter: 1720 loss: 7.88411739e-07
Iter: 1721 loss: 7.88197e-07
Iter: 1722 loss: 7.88035152e-07
Iter: 1723 loss: 7.87912654e-07
Iter: 1724 loss: 7.87742465e-07
Iter: 1725 loss: 7.87744682e-07
Iter: 1726 loss: 7.87480644e-07
Iter: 1727 loss: 7.88008265e-07
Iter: 1728 loss: 7.87367526e-07
Iter: 1729 loss: 7.87161071e-07
Iter: 1730 loss: 7.87170734e-07
Iter: 1731 loss: 7.86952342e-07
Iter: 1732 loss: 7.86824216e-07
Iter: 1733 loss: 7.87989677e-07
Iter: 1734 loss: 7.86799774e-07
Iter: 1735 loss: 7.86534883e-07
Iter: 1736 loss: 7.86171e-07
Iter: 1737 loss: 7.86165856e-07
Iter: 1738 loss: 7.8600317e-07
Iter: 1739 loss: 7.85981797e-07
Iter: 1740 loss: 7.85826e-07
Iter: 1741 loss: 7.85814507e-07
Iter: 1742 loss: 7.85660632e-07
Iter: 1743 loss: 7.85439e-07
Iter: 1744 loss: 7.85391535e-07
Iter: 1745 loss: 7.85206112e-07
Iter: 1746 loss: 7.84977431e-07
Iter: 1747 loss: 7.86184785e-07
Iter: 1748 loss: 7.84932467e-07
Iter: 1749 loss: 7.84656208e-07
Iter: 1750 loss: 7.86123962e-07
Iter: 1751 loss: 7.84605106e-07
Iter: 1752 loss: 7.84444751e-07
Iter: 1753 loss: 7.84152178e-07
Iter: 1754 loss: 7.91859577e-07
Iter: 1755 loss: 7.84155816e-07
Iter: 1756 loss: 7.83800601e-07
Iter: 1757 loss: 7.87168915e-07
Iter: 1758 loss: 7.8380117e-07
Iter: 1759 loss: 7.83599603e-07
Iter: 1760 loss: 7.84372787e-07
Iter: 1761 loss: 7.83554469e-07
Iter: 1762 loss: 7.83345e-07
Iter: 1763 loss: 7.85994075e-07
Iter: 1764 loss: 7.83377459e-07
Iter: 1765 loss: 7.83275e-07
Iter: 1766 loss: 7.83055839e-07
Iter: 1767 loss: 7.83725795e-07
Iter: 1768 loss: 7.82899178e-07
Iter: 1769 loss: 7.82687607e-07
Iter: 1770 loss: 7.82663108e-07
Iter: 1771 loss: 7.82465918e-07
Iter: 1772 loss: 7.83040093e-07
Iter: 1773 loss: 7.82381278e-07
Iter: 1774 loss: 7.82233315e-07
Iter: 1775 loss: 7.82361894e-07
Iter: 1776 loss: 7.82107406e-07
Iter: 1777 loss: 7.81894073e-07
Iter: 1778 loss: 7.84217491e-07
Iter: 1779 loss: 7.81918e-07
Iter: 1780 loss: 7.81735366e-07
Iter: 1781 loss: 7.81597919e-07
Iter: 1782 loss: 7.81577683e-07
Iter: 1783 loss: 7.81293124e-07
Iter: 1784 loss: 7.81759297e-07
Iter: 1785 loss: 7.81156245e-07
Iter: 1786 loss: 7.80940468e-07
Iter: 1787 loss: 7.80787e-07
Iter: 1788 loss: 7.80667733e-07
Iter: 1789 loss: 7.80272046e-07
Iter: 1790 loss: 7.82376787e-07
Iter: 1791 loss: 7.80276764e-07
Iter: 1792 loss: 7.800096e-07
Iter: 1793 loss: 7.81963649e-07
Iter: 1794 loss: 7.79965376e-07
Iter: 1795 loss: 7.79752213e-07
Iter: 1796 loss: 7.81396693e-07
Iter: 1797 loss: 7.79709126e-07
Iter: 1798 loss: 7.79614766e-07
Iter: 1799 loss: 7.80065477e-07
Iter: 1800 loss: 7.79548316e-07
Iter: 1801 loss: 7.79361e-07
Iter: 1802 loss: 7.79600555e-07
Iter: 1803 loss: 7.79266315e-07
Iter: 1804 loss: 7.79140123e-07
Iter: 1805 loss: 7.78869435e-07
Iter: 1806 loss: 7.788787e-07
Iter: 1807 loss: 7.78715957e-07
Iter: 1808 loss: 7.81348604e-07
Iter: 1809 loss: 7.78711296e-07
Iter: 1810 loss: 7.78548383e-07
Iter: 1811 loss: 7.79400864e-07
Iter: 1812 loss: 7.78514845e-07
Iter: 1813 loss: 7.7835e-07
Iter: 1814 loss: 7.78300603e-07
Iter: 1815 loss: 7.78207e-07
Iter: 1816 loss: 7.77999162e-07
Iter: 1817 loss: 7.80485379e-07
Iter: 1818 loss: 7.78019228e-07
Iter: 1819 loss: 7.77935952e-07
Iter: 1820 loss: 7.77727621e-07
Iter: 1821 loss: 7.77726314e-07
Iter: 1822 loss: 7.77500304e-07
Iter: 1823 loss: 7.77963578e-07
Iter: 1824 loss: 7.77394689e-07
Iter: 1825 loss: 7.77125649e-07
Iter: 1826 loss: 7.77358764e-07
Iter: 1827 loss: 7.76940851e-07
Iter: 1828 loss: 7.76632191e-07
Iter: 1829 loss: 7.77679816e-07
Iter: 1830 loss: 7.76623892e-07
Iter: 1831 loss: 7.76299373e-07
Iter: 1832 loss: 7.7780652e-07
Iter: 1833 loss: 7.76231843e-07
Iter: 1834 loss: 7.76070237e-07
Iter: 1835 loss: 7.7607649e-07
Iter: 1836 loss: 7.75976844e-07
Iter: 1837 loss: 7.76728939e-07
Iter: 1838 loss: 7.75966782e-07
Iter: 1839 loss: 7.75841727e-07
Iter: 1840 loss: 7.75631122e-07
Iter: 1841 loss: 7.78194135e-07
Iter: 1842 loss: 7.75607361e-07
Iter: 1843 loss: 7.75414946e-07
Iter: 1844 loss: 7.75985086e-07
Iter: 1845 loss: 7.75323201e-07
Iter: 1846 loss: 7.75099807e-07
Iter: 1847 loss: 7.76010097e-07
Iter: 1848 loss: 7.75083e-07
Iter: 1849 loss: 7.74954344e-07
Iter: 1850 loss: 7.7494758e-07
Iter: 1851 loss: 7.74889713e-07
Iter: 1852 loss: 7.74750674e-07
Iter: 1853 loss: 7.74747718e-07
Iter: 1854 loss: 7.74574573e-07
Iter: 1855 loss: 7.76334673e-07
Iter: 1856 loss: 7.74554167e-07
Iter: 1857 loss: 7.74437467e-07
Iter: 1858 loss: 7.74271143e-07
Iter: 1859 loss: 7.74235673e-07
Iter: 1860 loss: 7.7403422e-07
Iter: 1861 loss: 7.74396767e-07
Iter: 1862 loss: 7.73950887e-07
Iter: 1863 loss: 7.73686679e-07
Iter: 1864 loss: 7.73929571e-07
Iter: 1865 loss: 7.73544912e-07
Iter: 1866 loss: 7.73355623e-07
Iter: 1867 loss: 7.74746582e-07
Iter: 1868 loss: 7.73315833e-07
Iter: 1869 loss: 7.73101931e-07
Iter: 1870 loss: 7.74882665e-07
Iter: 1871 loss: 7.73098122e-07
Iter: 1872 loss: 7.7298364e-07
Iter: 1873 loss: 7.73798945e-07
Iter: 1874 loss: 7.72953058e-07
Iter: 1875 loss: 7.72831754e-07
Iter: 1876 loss: 7.73033889e-07
Iter: 1877 loss: 7.72794351e-07
Iter: 1878 loss: 7.72687486e-07
Iter: 1879 loss: 7.72493649e-07
Iter: 1880 loss: 7.76496336e-07
Iter: 1881 loss: 7.72485e-07
Iter: 1882 loss: 7.72262638e-07
Iter: 1883 loss: 7.72879332e-07
Iter: 1884 loss: 7.722183e-07
Iter: 1885 loss: 7.71981604e-07
Iter: 1886 loss: 7.72752401e-07
Iter: 1887 loss: 7.71909072e-07
Iter: 1888 loss: 7.71870191e-07
Iter: 1889 loss: 7.7178538e-07
Iter: 1890 loss: 7.71696818e-07
Iter: 1891 loss: 7.71428233e-07
Iter: 1892 loss: 7.73051454e-07
Iter: 1893 loss: 7.7136383e-07
Iter: 1894 loss: 7.71177838e-07
Iter: 1895 loss: 7.72937938e-07
Iter: 1896 loss: 7.71177781e-07
Iter: 1897 loss: 7.70939891e-07
Iter: 1898 loss: 7.71230646e-07
Iter: 1899 loss: 7.70851898e-07
Iter: 1900 loss: 7.70602412e-07
Iter: 1901 loss: 7.72021053e-07
Iter: 1902 loss: 7.70581551e-07
Iter: 1903 loss: 7.70414374e-07
Iter: 1904 loss: 7.70377255e-07
Iter: 1905 loss: 7.70265672e-07
Iter: 1906 loss: 7.70141469e-07
Iter: 1907 loss: 7.70120778e-07
Iter: 1908 loss: 7.70075928e-07
Iter: 1909 loss: 7.69834628e-07
Iter: 1910 loss: 7.6986089e-07
Iter: 1911 loss: 7.6966694e-07
Iter: 1912 loss: 7.70930342e-07
Iter: 1913 loss: 7.6966171e-07
Iter: 1914 loss: 7.69510905e-07
Iter: 1915 loss: 7.69530743e-07
Iter: 1916 loss: 7.6938727e-07
Iter: 1917 loss: 7.69203325e-07
Iter: 1918 loss: 7.69350379e-07
Iter: 1919 loss: 7.69073722e-07
Iter: 1920 loss: 7.68899213e-07
Iter: 1921 loss: 7.68977e-07
Iter: 1922 loss: 7.68732889e-07
Iter: 1923 loss: 7.68603172e-07
Iter: 1924 loss: 7.68573386e-07
Iter: 1925 loss: 7.68468453e-07
Iter: 1926 loss: 7.68499149e-07
Iter: 1927 loss: 7.68361929e-07
Iter: 1928 loss: 7.68198561e-07
Iter: 1929 loss: 7.67896381e-07
Iter: 1930 loss: 7.67920767e-07
Iter: 1931 loss: 7.67637175e-07
Iter: 1932 loss: 7.69477765e-07
Iter: 1933 loss: 7.67604888e-07
Iter: 1934 loss: 7.67344261e-07
Iter: 1935 loss: 7.68707e-07
Iter: 1936 loss: 7.67352e-07
Iter: 1937 loss: 7.67169354e-07
Iter: 1938 loss: 7.68520351e-07
Iter: 1939 loss: 7.67205393e-07
Iter: 1940 loss: 7.67033e-07
Iter: 1941 loss: 7.6700826e-07
Iter: 1942 loss: 7.66961193e-07
Iter: 1943 loss: 7.66813571e-07
Iter: 1944 loss: 7.66794869e-07
Iter: 1945 loss: 7.66690732e-07
Iter: 1946 loss: 7.66598134e-07
Iter: 1947 loss: 7.66561698e-07
Iter: 1948 loss: 7.66391736e-07
Iter: 1949 loss: 7.66222229e-07
Iter: 1950 loss: 7.66195569e-07
Iter: 1951 loss: 7.66007133e-07
Iter: 1952 loss: 7.68717598e-07
Iter: 1953 loss: 7.65980076e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.6/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2
+ date
Sun Nov  8 03:29:05 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi1.6/300_100_100_100_1 --function f1 --psi 1 --phi 2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9a6e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9b33e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9b2cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9b2ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9abf510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f99abd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f998bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9a21620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9a21598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f998bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f9a26158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0f187b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0f18488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0eb57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f99269d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f994ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f994d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f994d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0e7f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0e70ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0e708c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0e51840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0db2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0db3950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0de0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0d6b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0e0e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0e10620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0e10a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0cc3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0cc36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0bfd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0c16488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0c32ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0ca76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc0f0c7cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.11715647
test_loss: 0.121556185
train_loss: 0.102450915
test_loss: 0.113687776
train_loss: 0.10492891
test_loss: 0.10435451
train_loss: 0.09831216
test_loss: 0.094633214
train_loss: 0.08197976
test_loss: 0.08506979
train_loss: 0.06516143
test_loss: 0.069715455
train_loss: 0.056391094
test_loss: 0.05611179
train_loss: 0.042423945
test_loss: 0.045143977
train_loss: 0.031686433
test_loss: 0.032152995
train_loss: 0.02480628
test_loss: 0.026482599
train_loss: 0.022637527
test_loss: 0.023430688
train_loss: 0.020149728
test_loss: 0.021308346
train_loss: 0.018499732
test_loss: 0.019664489
train_loss: 0.016881857
test_loss: 0.01832084
train_loss: 0.015976887
test_loss: 0.017206002
train_loss: 0.01656154
test_loss: 0.016204836
train_loss: 0.014614128
test_loss: 0.015338895
train_loss: 0.013539892
test_loss: 0.014399243
train_loss: 0.012135837
test_loss: 0.013657256
train_loss: 0.012391628
test_loss: 0.012954878
train_loss: 0.011641626
test_loss: 0.012303483
train_loss: 0.01075809
test_loss: 0.0117678
train_loss: 0.010117491
test_loss: 0.011151844
train_loss: 0.009506738
test_loss: 0.010612342
train_loss: 0.00891358
test_loss: 0.010187204
train_loss: 0.008885332
test_loss: 0.009648213
train_loss: 0.008385152
test_loss: 0.009186692
train_loss: 0.007704503
test_loss: 0.008794283
train_loss: 0.007465779
test_loss: 0.008433289
train_loss: 0.0071246056
test_loss: 0.008053828
train_loss: 0.00660731
test_loss: 0.007680147
train_loss: 0.006379461
test_loss: 0.0073579294
train_loss: 0.0058107963
test_loss: 0.00705618
train_loss: 0.005611345
test_loss: 0.0067127272
train_loss: 0.005532147
test_loss: 0.0064721922
train_loss: 0.005269511
test_loss: 0.0062170434
train_loss: 0.0050568585
test_loss: 0.005946341
train_loss: 0.004658086
test_loss: 0.0057134605
train_loss: 0.004832303
test_loss: 0.0054989015
train_loss: 0.0046815407
test_loss: 0.005300525
train_loss: 0.004371849
test_loss: 0.00519165
train_loss: 0.004153063
test_loss: 0.004941313
train_loss: 0.0040608365
test_loss: 0.004766876
train_loss: 0.0038575535
test_loss: 0.0046371645
train_loss: 0.0038814563
test_loss: 0.00449702
train_loss: 0.003698478
test_loss: 0.004392802
train_loss: 0.0036076186
test_loss: 0.004285583
train_loss: 0.0035140663
test_loss: 0.0041369684
train_loss: 0.0033187238
test_loss: 0.0040601096
train_loss: 0.00332725
test_loss: 0.0039473576
train_loss: 0.0034247574
test_loss: 0.0038919249
train_loss: 0.0032121052
test_loss: 0.003798773
train_loss: 0.0032347913
test_loss: 0.0037210388
train_loss: 0.0030196882
test_loss: 0.0036643771
train_loss: 0.003016036
test_loss: 0.0036213421
train_loss: 0.0031734996
test_loss: 0.0035285533
train_loss: 0.0028732184
test_loss: 0.003510916
train_loss: 0.0029763798
test_loss: 0.0034109666
train_loss: 0.0028981376
test_loss: 0.003448946
train_loss: 0.0028268313
test_loss: 0.003410365
train_loss: 0.0029468276
test_loss: 0.0033448203
train_loss: 0.0028764883
test_loss: 0.003294556
train_loss: 0.002778099
test_loss: 0.0032912174
train_loss: 0.0025941525
test_loss: 0.0032192862
train_loss: 0.0026711258
test_loss: 0.0031788796
train_loss: 0.0027372343
test_loss: 0.00319237
train_loss: 0.0027158295
test_loss: 0.0031466628
train_loss: 0.0026312184
test_loss: 0.0030982448
train_loss: 0.002714217
test_loss: 0.003149023
train_loss: 0.002656568
test_loss: 0.00303356
train_loss: 0.0027159918
test_loss: 0.003105481
train_loss: 0.002661768
test_loss: 0.0030814183
train_loss: 0.0026319372
test_loss: 0.0030099612
train_loss: 0.002692257
test_loss: 0.0031245037
train_loss: 0.002595431
test_loss: 0.0030935958
train_loss: 0.0026400478
test_loss: 0.0030304869
train_loss: 0.0026025018
test_loss: 0.002999099
train_loss: 0.0025914323
test_loss: 0.0030647842
train_loss: 0.0024907766
test_loss: 0.0029756601
train_loss: 0.0026838342
test_loss: 0.0031180514
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80597378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c805978c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c805e7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c804ee400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c8051db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80490840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c8045dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c804907b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80409840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80409b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80409ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80387e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80387bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80352c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c803a40d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c802f8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80321620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c802b3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c802958c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80295c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c8025bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c80295840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c64072730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6405f0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c6405f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63fc3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63f8d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63faf840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63fb7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63fb7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63f08378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63f34510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63ec1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63ef2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63e8f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c63e46598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.25928163e-05
Iter: 2 loss: 2.80024542e-05
Iter: 3 loss: 1.10208139e-05
Iter: 4 loss: 1.00550378e-05
Iter: 5 loss: 1.59477677e-05
Iter: 6 loss: 9.93731919e-06
Iter: 7 loss: 9.7496868e-06
Iter: 8 loss: 9.53801373e-06
Iter: 9 loss: 9.50997492e-06
Iter: 10 loss: 9.17492343e-06
Iter: 11 loss: 1.01565065e-05
Iter: 12 loss: 9.07142294e-06
Iter: 13 loss: 8.80902826e-06
Iter: 14 loss: 9.56722e-06
Iter: 15 loss: 8.72690271e-06
Iter: 16 loss: 8.51590448e-06
Iter: 17 loss: 8.89394232e-06
Iter: 18 loss: 8.42374448e-06
Iter: 19 loss: 8.21232879e-06
Iter: 20 loss: 8.80671359e-06
Iter: 21 loss: 8.14495797e-06
Iter: 22 loss: 7.95622e-06
Iter: 23 loss: 8.39206768e-06
Iter: 24 loss: 7.88588386e-06
Iter: 25 loss: 7.69633061e-06
Iter: 26 loss: 8.61931949e-06
Iter: 27 loss: 7.66341782e-06
Iter: 28 loss: 7.5385642e-06
Iter: 29 loss: 7.67231904e-06
Iter: 30 loss: 7.46993737e-06
Iter: 31 loss: 7.32101898e-06
Iter: 32 loss: 7.9044e-06
Iter: 33 loss: 7.28653777e-06
Iter: 34 loss: 7.16628392e-06
Iter: 35 loss: 7.14785619e-06
Iter: 36 loss: 7.06439778e-06
Iter: 37 loss: 7.20223716e-06
Iter: 38 loss: 7.00186274e-06
Iter: 39 loss: 6.95907238e-06
Iter: 40 loss: 6.89236458e-06
Iter: 41 loss: 6.89160152e-06
Iter: 42 loss: 6.83749477e-06
Iter: 43 loss: 6.86026397e-06
Iter: 44 loss: 6.80085941e-06
Iter: 45 loss: 6.71033922e-06
Iter: 46 loss: 6.98408166e-06
Iter: 47 loss: 6.68282883e-06
Iter: 48 loss: 6.62394359e-06
Iter: 49 loss: 6.76394211e-06
Iter: 50 loss: 6.6023108e-06
Iter: 51 loss: 6.54017094e-06
Iter: 52 loss: 6.62444e-06
Iter: 53 loss: 6.50864195e-06
Iter: 54 loss: 6.43901694e-06
Iter: 55 loss: 6.55814529e-06
Iter: 56 loss: 6.40746521e-06
Iter: 57 loss: 6.33616582e-06
Iter: 58 loss: 6.67480526e-06
Iter: 59 loss: 6.32297906e-06
Iter: 60 loss: 6.27653026e-06
Iter: 61 loss: 6.49898584e-06
Iter: 62 loss: 6.26842211e-06
Iter: 63 loss: 6.22427615e-06
Iter: 64 loss: 6.22374228e-06
Iter: 65 loss: 6.18852937e-06
Iter: 66 loss: 6.13065549e-06
Iter: 67 loss: 6.36088589e-06
Iter: 68 loss: 6.11743644e-06
Iter: 69 loss: 6.074461e-06
Iter: 70 loss: 6.35169e-06
Iter: 71 loss: 6.06968e-06
Iter: 72 loss: 6.0234006e-06
Iter: 73 loss: 6.48936066e-06
Iter: 74 loss: 6.02195041e-06
Iter: 75 loss: 6.0053153e-06
Iter: 76 loss: 5.96561586e-06
Iter: 77 loss: 6.4373653e-06
Iter: 78 loss: 5.96207292e-06
Iter: 79 loss: 5.91627031e-06
Iter: 80 loss: 6.19334241e-06
Iter: 81 loss: 5.91072148e-06
Iter: 82 loss: 5.86934402e-06
Iter: 83 loss: 5.97605958e-06
Iter: 84 loss: 5.85558109e-06
Iter: 85 loss: 5.82344546e-06
Iter: 86 loss: 5.83868859e-06
Iter: 87 loss: 5.80214055e-06
Iter: 88 loss: 5.76557659e-06
Iter: 89 loss: 6.02025057e-06
Iter: 90 loss: 5.76226694e-06
Iter: 91 loss: 5.73695252e-06
Iter: 92 loss: 5.72423642e-06
Iter: 93 loss: 5.71233613e-06
Iter: 94 loss: 5.66904328e-06
Iter: 95 loss: 5.88308922e-06
Iter: 96 loss: 5.66157451e-06
Iter: 97 loss: 5.63156391e-06
Iter: 98 loss: 5.68869518e-06
Iter: 99 loss: 5.61902561e-06
Iter: 100 loss: 5.57820294e-06
Iter: 101 loss: 5.63388494e-06
Iter: 102 loss: 5.55758606e-06
Iter: 103 loss: 5.53136579e-06
Iter: 104 loss: 5.66098652e-06
Iter: 105 loss: 5.52697247e-06
Iter: 106 loss: 5.52665279e-06
Iter: 107 loss: 5.51696257e-06
Iter: 108 loss: 5.50726782e-06
Iter: 109 loss: 5.48106391e-06
Iter: 110 loss: 5.65698974e-06
Iter: 111 loss: 5.47529316e-06
Iter: 112 loss: 5.45440071e-06
Iter: 113 loss: 5.5392984e-06
Iter: 114 loss: 5.44950672e-06
Iter: 115 loss: 5.42646e-06
Iter: 116 loss: 5.50497407e-06
Iter: 117 loss: 5.42026555e-06
Iter: 118 loss: 5.39612211e-06
Iter: 119 loss: 5.39604753e-06
Iter: 120 loss: 5.37704818e-06
Iter: 121 loss: 5.34402625e-06
Iter: 122 loss: 5.42111366e-06
Iter: 123 loss: 5.33189086e-06
Iter: 124 loss: 5.30562693e-06
Iter: 125 loss: 5.51636867e-06
Iter: 126 loss: 5.30411e-06
Iter: 127 loss: 5.28691544e-06
Iter: 128 loss: 5.28674127e-06
Iter: 129 loss: 5.27317479e-06
Iter: 130 loss: 5.25042924e-06
Iter: 131 loss: 5.39207304e-06
Iter: 132 loss: 5.24785492e-06
Iter: 133 loss: 5.23272502e-06
Iter: 134 loss: 5.26064741e-06
Iter: 135 loss: 5.22611754e-06
Iter: 136 loss: 5.20352387e-06
Iter: 137 loss: 5.19959485e-06
Iter: 138 loss: 5.18428715e-06
Iter: 139 loss: 5.17191893e-06
Iter: 140 loss: 5.1712168e-06
Iter: 141 loss: 5.15808642e-06
Iter: 142 loss: 5.25411e-06
Iter: 143 loss: 5.15681313e-06
Iter: 144 loss: 5.14856401e-06
Iter: 145 loss: 5.12472934e-06
Iter: 146 loss: 5.23621929e-06
Iter: 147 loss: 5.11633561e-06
Iter: 148 loss: 5.09929123e-06
Iter: 149 loss: 5.36591051e-06
Iter: 150 loss: 5.09925212e-06
Iter: 151 loss: 5.08088533e-06
Iter: 152 loss: 5.08898893e-06
Iter: 153 loss: 5.06852211e-06
Iter: 154 loss: 5.04902027e-06
Iter: 155 loss: 5.10951577e-06
Iter: 156 loss: 5.04374611e-06
Iter: 157 loss: 5.02858802e-06
Iter: 158 loss: 5.07400864e-06
Iter: 159 loss: 5.0242179e-06
Iter: 160 loss: 5.01031263e-06
Iter: 161 loss: 5.05048138e-06
Iter: 162 loss: 5.00608621e-06
Iter: 163 loss: 4.99065573e-06
Iter: 164 loss: 4.9941109e-06
Iter: 165 loss: 4.97924975e-06
Iter: 166 loss: 4.96268467e-06
Iter: 167 loss: 5.08077574e-06
Iter: 168 loss: 4.96142184e-06
Iter: 169 loss: 4.94488268e-06
Iter: 170 loss: 4.93650487e-06
Iter: 171 loss: 4.92895924e-06
Iter: 172 loss: 4.9052237e-06
Iter: 173 loss: 5.07752293e-06
Iter: 174 loss: 4.9031014e-06
Iter: 175 loss: 4.89628155e-06
Iter: 176 loss: 4.89568356e-06
Iter: 177 loss: 4.88576688e-06
Iter: 178 loss: 4.87768193e-06
Iter: 179 loss: 4.87472e-06
Iter: 180 loss: 4.86434919e-06
Iter: 181 loss: 4.85126657e-06
Iter: 182 loss: 4.85041528e-06
Iter: 183 loss: 4.83628719e-06
Iter: 184 loss: 4.91524588e-06
Iter: 185 loss: 4.834425e-06
Iter: 186 loss: 4.81915367e-06
Iter: 187 loss: 4.89100148e-06
Iter: 188 loss: 4.81629877e-06
Iter: 189 loss: 4.80627796e-06
Iter: 190 loss: 4.80233939e-06
Iter: 191 loss: 4.79696473e-06
Iter: 192 loss: 4.78473066e-06
Iter: 193 loss: 4.86808949e-06
Iter: 194 loss: 4.78344e-06
Iter: 195 loss: 4.77328e-06
Iter: 196 loss: 4.78480615e-06
Iter: 197 loss: 4.7680669e-06
Iter: 198 loss: 4.75375691e-06
Iter: 199 loss: 4.77238109e-06
Iter: 200 loss: 4.74646686e-06
Iter: 201 loss: 4.73694763e-06
Iter: 202 loss: 4.79652772e-06
Iter: 203 loss: 4.7358526e-06
Iter: 204 loss: 4.72458669e-06
Iter: 205 loss: 4.713419e-06
Iter: 206 loss: 4.71086605e-06
Iter: 207 loss: 4.69981524e-06
Iter: 208 loss: 4.69973747e-06
Iter: 209 loss: 4.6976611e-06
Iter: 210 loss: 4.69604947e-06
Iter: 211 loss: 4.69246743e-06
Iter: 212 loss: 4.68157305e-06
Iter: 213 loss: 4.71202293e-06
Iter: 214 loss: 4.67571408e-06
Iter: 215 loss: 4.66468828e-06
Iter: 216 loss: 4.71938938e-06
Iter: 217 loss: 4.66285474e-06
Iter: 218 loss: 4.65294852e-06
Iter: 219 loss: 4.67359e-06
Iter: 220 loss: 4.64902951e-06
Iter: 221 loss: 4.63711331e-06
Iter: 222 loss: 4.7306894e-06
Iter: 223 loss: 4.63619244e-06
Iter: 224 loss: 4.63056e-06
Iter: 225 loss: 4.62064872e-06
Iter: 226 loss: 4.8571128e-06
Iter: 227 loss: 4.62048592e-06
Iter: 228 loss: 4.60793717e-06
Iter: 229 loss: 4.700521e-06
Iter: 230 loss: 4.60676165e-06
Iter: 231 loss: 4.59650028e-06
Iter: 232 loss: 4.61408672e-06
Iter: 233 loss: 4.59181274e-06
Iter: 234 loss: 4.58245086e-06
Iter: 235 loss: 4.6110481e-06
Iter: 236 loss: 4.57967417e-06
Iter: 237 loss: 4.5699e-06
Iter: 238 loss: 4.58070735e-06
Iter: 239 loss: 4.56432736e-06
Iter: 240 loss: 4.55197096e-06
Iter: 241 loss: 4.61026866e-06
Iter: 242 loss: 4.54944256e-06
Iter: 243 loss: 4.5432248e-06
Iter: 244 loss: 4.62871139e-06
Iter: 245 loss: 4.54326482e-06
Iter: 246 loss: 4.53629673e-06
Iter: 247 loss: 4.56692851e-06
Iter: 248 loss: 4.53486609e-06
Iter: 249 loss: 4.52972927e-06
Iter: 250 loss: 4.51642791e-06
Iter: 251 loss: 4.61667878e-06
Iter: 252 loss: 4.51399364e-06
Iter: 253 loss: 4.50412108e-06
Iter: 254 loss: 4.55800455e-06
Iter: 255 loss: 4.50258085e-06
Iter: 256 loss: 4.49391155e-06
Iter: 257 loss: 4.54526162e-06
Iter: 258 loss: 4.49273739e-06
Iter: 259 loss: 4.48349783e-06
Iter: 260 loss: 4.51318647e-06
Iter: 261 loss: 4.48070932e-06
Iter: 262 loss: 4.47349612e-06
Iter: 263 loss: 4.4663293e-06
Iter: 264 loss: 4.46471222e-06
Iter: 265 loss: 4.45572323e-06
Iter: 266 loss: 4.52362474e-06
Iter: 267 loss: 4.45484557e-06
Iter: 268 loss: 4.44583475e-06
Iter: 269 loss: 4.46481272e-06
Iter: 270 loss: 4.44221e-06
Iter: 271 loss: 4.43487215e-06
Iter: 272 loss: 4.44524176e-06
Iter: 273 loss: 4.43117597e-06
Iter: 274 loss: 4.42066448e-06
Iter: 275 loss: 4.44271882e-06
Iter: 276 loss: 4.41639e-06
Iter: 277 loss: 4.40959366e-06
Iter: 278 loss: 4.46701551e-06
Iter: 279 loss: 4.40915892e-06
Iter: 280 loss: 4.40554595e-06
Iter: 281 loss: 4.40547e-06
Iter: 282 loss: 4.40113354e-06
Iter: 283 loss: 4.39074756e-06
Iter: 284 loss: 4.49999106e-06
Iter: 285 loss: 4.38939833e-06
Iter: 286 loss: 4.38160532e-06
Iter: 287 loss: 4.4036633e-06
Iter: 288 loss: 4.37925928e-06
Iter: 289 loss: 4.37211247e-06
Iter: 290 loss: 4.36916844e-06
Iter: 291 loss: 4.36552e-06
Iter: 292 loss: 4.35836e-06
Iter: 293 loss: 4.35798256e-06
Iter: 294 loss: 4.35251332e-06
Iter: 295 loss: 4.35845868e-06
Iter: 296 loss: 4.3495711e-06
Iter: 297 loss: 4.34366893e-06
Iter: 298 loss: 4.33794958e-06
Iter: 299 loss: 4.33658124e-06
Iter: 300 loss: 4.32702e-06
Iter: 301 loss: 4.35795573e-06
Iter: 302 loss: 4.32452816e-06
Iter: 303 loss: 4.31431181e-06
Iter: 304 loss: 4.37655081e-06
Iter: 305 loss: 4.31303488e-06
Iter: 306 loss: 4.30629461e-06
Iter: 307 loss: 4.31491526e-06
Iter: 308 loss: 4.30289492e-06
Iter: 309 loss: 4.29488773e-06
Iter: 310 loss: 4.31381886e-06
Iter: 311 loss: 4.29183183e-06
Iter: 312 loss: 4.28686371e-06
Iter: 313 loss: 4.36082428e-06
Iter: 314 loss: 4.28685053e-06
Iter: 315 loss: 4.28167732e-06
Iter: 316 loss: 4.30921273e-06
Iter: 317 loss: 4.28073872e-06
Iter: 318 loss: 4.27699661e-06
Iter: 319 loss: 4.26909628e-06
Iter: 320 loss: 4.4057565e-06
Iter: 321 loss: 4.26886891e-06
Iter: 322 loss: 4.26311817e-06
Iter: 323 loss: 4.27572e-06
Iter: 324 loss: 4.26086262e-06
Iter: 325 loss: 4.25306916e-06
Iter: 326 loss: 4.25163171e-06
Iter: 327 loss: 4.24623386e-06
Iter: 328 loss: 4.24107566e-06
Iter: 329 loss: 4.24004702e-06
Iter: 330 loss: 4.23538e-06
Iter: 331 loss: 4.23357869e-06
Iter: 332 loss: 4.23096799e-06
Iter: 333 loss: 4.2252168e-06
Iter: 334 loss: 4.2298193e-06
Iter: 335 loss: 4.22175617e-06
Iter: 336 loss: 4.21441473e-06
Iter: 337 loss: 4.22484663e-06
Iter: 338 loss: 4.21061077e-06
Iter: 339 loss: 4.20513788e-06
Iter: 340 loss: 4.20504603e-06
Iter: 341 loss: 4.20079868e-06
Iter: 342 loss: 4.19499247e-06
Iter: 343 loss: 4.19463822e-06
Iter: 344 loss: 4.18552645e-06
Iter: 345 loss: 4.2203942e-06
Iter: 346 loss: 4.1832609e-06
Iter: 347 loss: 4.18336049e-06
Iter: 348 loss: 4.18062382e-06
Iter: 349 loss: 4.17765432e-06
Iter: 350 loss: 4.17392403e-06
Iter: 351 loss: 4.17373212e-06
Iter: 352 loss: 4.16943249e-06
Iter: 353 loss: 4.1640651e-06
Iter: 354 loss: 4.1634803e-06
Iter: 355 loss: 4.15687373e-06
Iter: 356 loss: 4.18716081e-06
Iter: 357 loss: 4.15556406e-06
Iter: 358 loss: 4.14982151e-06
Iter: 359 loss: 4.15932845e-06
Iter: 360 loss: 4.14712395e-06
Iter: 361 loss: 4.14089027e-06
Iter: 362 loss: 4.1711628e-06
Iter: 363 loss: 4.13959378e-06
Iter: 364 loss: 4.13290672e-06
Iter: 365 loss: 4.16698413e-06
Iter: 366 loss: 4.1318558e-06
Iter: 367 loss: 4.12855206e-06
Iter: 368 loss: 4.12402642e-06
Iter: 369 loss: 4.12389181e-06
Iter: 370 loss: 4.11568044e-06
Iter: 371 loss: 4.12267036e-06
Iter: 372 loss: 4.11069232e-06
Iter: 373 loss: 4.10425855e-06
Iter: 374 loss: 4.16674084e-06
Iter: 375 loss: 4.1041626e-06
Iter: 376 loss: 4.09670793e-06
Iter: 377 loss: 4.09362201e-06
Iter: 378 loss: 4.0899331e-06
Iter: 379 loss: 4.08370033e-06
Iter: 380 loss: 4.12896043e-06
Iter: 381 loss: 4.08318465e-06
Iter: 382 loss: 4.08128699e-06
Iter: 383 loss: 4.08027336e-06
Iter: 384 loss: 4.07782045e-06
Iter: 385 loss: 4.07238167e-06
Iter: 386 loss: 4.14159376e-06
Iter: 387 loss: 4.07178231e-06
Iter: 388 loss: 4.06774734e-06
Iter: 389 loss: 4.0721111e-06
Iter: 390 loss: 4.06556592e-06
Iter: 391 loss: 4.0598452e-06
Iter: 392 loss: 4.06834806e-06
Iter: 393 loss: 4.05692481e-06
Iter: 394 loss: 4.04975526e-06
Iter: 395 loss: 4.05694118e-06
Iter: 396 loss: 4.04580442e-06
Iter: 397 loss: 4.04020284e-06
Iter: 398 loss: 4.04010461e-06
Iter: 399 loss: 4.03615104e-06
Iter: 400 loss: 4.05503579e-06
Iter: 401 loss: 4.03554532e-06
Iter: 402 loss: 4.03271315e-06
Iter: 403 loss: 4.02697151e-06
Iter: 404 loss: 4.13595217e-06
Iter: 405 loss: 4.02705427e-06
Iter: 406 loss: 4.02048681e-06
Iter: 407 loss: 4.07238849e-06
Iter: 408 loss: 4.0200548e-06
Iter: 409 loss: 4.01590933e-06
Iter: 410 loss: 4.01669513e-06
Iter: 411 loss: 4.01292e-06
Iter: 412 loss: 4.0075106e-06
Iter: 413 loss: 4.07150583e-06
Iter: 414 loss: 4.00731415e-06
Iter: 415 loss: 4.00410863e-06
Iter: 416 loss: 4.0015143e-06
Iter: 417 loss: 4.0001969e-06
Iter: 418 loss: 3.99788541e-06
Iter: 419 loss: 3.99675264e-06
Iter: 420 loss: 3.99466444e-06
Iter: 421 loss: 3.98939892e-06
Iter: 422 loss: 4.04848879e-06
Iter: 423 loss: 3.98902102e-06
Iter: 424 loss: 3.98566954e-06
Iter: 425 loss: 3.98192697e-06
Iter: 426 loss: 3.9812212e-06
Iter: 427 loss: 3.97432814e-06
Iter: 428 loss: 4.00317595e-06
Iter: 429 loss: 3.972993e-06
Iter: 430 loss: 3.96808537e-06
Iter: 431 loss: 3.98952761e-06
Iter: 432 loss: 3.96719133e-06
Iter: 433 loss: 3.96319729e-06
Iter: 434 loss: 3.97185067e-06
Iter: 435 loss: 3.96172254e-06
Iter: 436 loss: 3.95761e-06
Iter: 437 loss: 3.98187876e-06
Iter: 438 loss: 3.95692359e-06
Iter: 439 loss: 3.9529441e-06
Iter: 440 loss: 3.951689e-06
Iter: 441 loss: 3.94949711e-06
Iter: 442 loss: 3.94496965e-06
Iter: 443 loss: 3.94818335e-06
Iter: 444 loss: 3.94235803e-06
Iter: 445 loss: 3.93586924e-06
Iter: 446 loss: 3.95661e-06
Iter: 447 loss: 3.93398886e-06
Iter: 448 loss: 3.92892025e-06
Iter: 449 loss: 3.92803895e-06
Iter: 450 loss: 3.92452921e-06
Iter: 451 loss: 3.92621405e-06
Iter: 452 loss: 3.92202128e-06
Iter: 453 loss: 3.91961521e-06
Iter: 454 loss: 3.9311717e-06
Iter: 455 loss: 3.91912545e-06
Iter: 456 loss: 3.91791809e-06
Iter: 457 loss: 3.91432332e-06
Iter: 458 loss: 3.93104483e-06
Iter: 459 loss: 3.91291815e-06
Iter: 460 loss: 3.90803962e-06
Iter: 461 loss: 3.9504057e-06
Iter: 462 loss: 3.90786499e-06
Iter: 463 loss: 3.90413106e-06
Iter: 464 loss: 3.90470541e-06
Iter: 465 loss: 3.90127252e-06
Iter: 466 loss: 3.8971566e-06
Iter: 467 loss: 3.90931791e-06
Iter: 468 loss: 3.89607794e-06
Iter: 469 loss: 3.8910448e-06
Iter: 470 loss: 3.90622426e-06
Iter: 471 loss: 3.88959097e-06
Iter: 472 loss: 3.8851922e-06
Iter: 473 loss: 3.93058372e-06
Iter: 474 loss: 3.88510853e-06
Iter: 475 loss: 3.88257058e-06
Iter: 476 loss: 3.88065291e-06
Iter: 477 loss: 3.87983891e-06
Iter: 478 loss: 3.87568207e-06
Iter: 479 loss: 3.88351373e-06
Iter: 480 loss: 3.87398495e-06
Iter: 481 loss: 3.87000182e-06
Iter: 482 loss: 3.89124352e-06
Iter: 483 loss: 3.86935699e-06
Iter: 484 loss: 3.86557167e-06
Iter: 485 loss: 3.86568e-06
Iter: 486 loss: 3.86244119e-06
Iter: 487 loss: 3.86249576e-06
Iter: 488 loss: 3.86061402e-06
Iter: 489 loss: 3.85852672e-06
Iter: 490 loss: 3.85681597e-06
Iter: 491 loss: 3.85593466e-06
Iter: 492 loss: 3.85357407e-06
Iter: 493 loss: 3.84966461e-06
Iter: 494 loss: 3.84944133e-06
Iter: 495 loss: 3.84472787e-06
Iter: 496 loss: 3.86263036e-06
Iter: 497 loss: 3.84364603e-06
Iter: 498 loss: 3.83867564e-06
Iter: 499 loss: 3.85523572e-06
Iter: 500 loss: 3.83717452e-06
Iter: 501 loss: 3.83402767e-06
Iter: 502 loss: 3.84030773e-06
Iter: 503 loss: 3.83286715e-06
Iter: 504 loss: 3.82901362e-06
Iter: 505 loss: 3.84059149e-06
Iter: 506 loss: 3.82797361e-06
Iter: 507 loss: 3.8238627e-06
Iter: 508 loss: 3.8555786e-06
Iter: 509 loss: 3.82365124e-06
Iter: 510 loss: 3.82157486e-06
Iter: 511 loss: 3.81861082e-06
Iter: 512 loss: 3.81849304e-06
Iter: 513 loss: 3.81331665e-06
Iter: 514 loss: 3.82030066e-06
Iter: 515 loss: 3.81057771e-06
Iter: 516 loss: 3.80674646e-06
Iter: 517 loss: 3.84334726e-06
Iter: 518 loss: 3.80667689e-06
Iter: 519 loss: 3.80340771e-06
Iter: 520 loss: 3.80591291e-06
Iter: 521 loss: 3.8014141e-06
Iter: 522 loss: 3.80248707e-06
Iter: 523 loss: 3.79996845e-06
Iter: 524 loss: 3.79879816e-06
Iter: 525 loss: 3.79539711e-06
Iter: 526 loss: 3.80875645e-06
Iter: 527 loss: 3.79415633e-06
Iter: 528 loss: 3.78970026e-06
Iter: 529 loss: 3.7977461e-06
Iter: 530 loss: 3.78792e-06
Iter: 531 loss: 3.78376126e-06
Iter: 532 loss: 3.80023403e-06
Iter: 533 loss: 3.7827017e-06
Iter: 534 loss: 3.77842844e-06
Iter: 535 loss: 3.79263884e-06
Iter: 536 loss: 3.77731e-06
Iter: 537 loss: 3.7737334e-06
Iter: 538 loss: 3.77781612e-06
Iter: 539 loss: 3.77174683e-06
Iter: 540 loss: 3.76825028e-06
Iter: 541 loss: 3.79643848e-06
Iter: 542 loss: 3.76788489e-06
Iter: 543 loss: 3.76449248e-06
Iter: 544 loss: 3.77867013e-06
Iter: 545 loss: 3.76406933e-06
Iter: 546 loss: 3.76185835e-06
Iter: 547 loss: 3.758812e-06
Iter: 548 loss: 3.75861191e-06
Iter: 549 loss: 3.75382888e-06
Iter: 550 loss: 3.76984326e-06
Iter: 551 loss: 3.75213813e-06
Iter: 552 loss: 3.74898696e-06
Iter: 553 loss: 3.76512094e-06
Iter: 554 loss: 3.7484474e-06
Iter: 555 loss: 3.74523916e-06
Iter: 556 loss: 3.76215803e-06
Iter: 557 loss: 3.74492424e-06
Iter: 558 loss: 3.74165e-06
Iter: 559 loss: 3.77273136e-06
Iter: 560 loss: 3.74150272e-06
Iter: 561 loss: 3.74059505e-06
Iter: 562 loss: 3.73801413e-06
Iter: 563 loss: 3.75751983e-06
Iter: 564 loss: 3.73757257e-06
Iter: 565 loss: 3.73457988e-06
Iter: 566 loss: 3.74053798e-06
Iter: 567 loss: 3.73334387e-06
Iter: 568 loss: 3.72901809e-06
Iter: 569 loss: 3.73139278e-06
Iter: 570 loss: 3.726042e-06
Iter: 571 loss: 3.72150316e-06
Iter: 572 loss: 3.77909396e-06
Iter: 573 loss: 3.72155364e-06
Iter: 574 loss: 3.71927968e-06
Iter: 575 loss: 3.7194568e-06
Iter: 576 loss: 3.71757983e-06
Iter: 577 loss: 3.71464739e-06
Iter: 578 loss: 3.74484875e-06
Iter: 579 loss: 3.71453189e-06
Iter: 580 loss: 3.71212536e-06
Iter: 581 loss: 3.71436681e-06
Iter: 582 loss: 3.71065244e-06
Iter: 583 loss: 3.70837211e-06
Iter: 584 loss: 3.70678708e-06
Iter: 585 loss: 3.7059433e-06
Iter: 586 loss: 3.70183784e-06
Iter: 587 loss: 3.72093518e-06
Iter: 588 loss: 3.70113708e-06
Iter: 589 loss: 3.69781e-06
Iter: 590 loss: 3.70758971e-06
Iter: 591 loss: 3.69677514e-06
Iter: 592 loss: 3.69638838e-06
Iter: 593 loss: 3.69521149e-06
Iter: 594 loss: 3.69374561e-06
Iter: 595 loss: 3.69064219e-06
Iter: 596 loss: 3.73895864e-06
Iter: 597 loss: 3.69040617e-06
Iter: 598 loss: 3.68778228e-06
Iter: 599 loss: 3.68621886e-06
Iter: 600 loss: 3.68494943e-06
Iter: 601 loss: 3.68187125e-06
Iter: 602 loss: 3.70440603e-06
Iter: 603 loss: 3.68151859e-06
Iter: 604 loss: 3.67861549e-06
Iter: 605 loss: 3.68134079e-06
Iter: 606 loss: 3.6770266e-06
Iter: 607 loss: 3.67315101e-06
Iter: 608 loss: 3.69278473e-06
Iter: 609 loss: 3.67249413e-06
Iter: 610 loss: 3.66997756e-06
Iter: 611 loss: 3.67603889e-06
Iter: 612 loss: 3.66898098e-06
Iter: 613 loss: 3.66560107e-06
Iter: 614 loss: 3.6768763e-06
Iter: 615 loss: 3.66484232e-06
Iter: 616 loss: 3.66197264e-06
Iter: 617 loss: 3.66604127e-06
Iter: 618 loss: 3.66075574e-06
Iter: 619 loss: 3.65786536e-06
Iter: 620 loss: 3.65507321e-06
Iter: 621 loss: 3.65432152e-06
Iter: 622 loss: 3.64986954e-06
Iter: 623 loss: 3.68416568e-06
Iter: 624 loss: 3.64961238e-06
Iter: 625 loss: 3.64722973e-06
Iter: 626 loss: 3.64725361e-06
Iter: 627 loss: 3.64502398e-06
Iter: 628 loss: 3.65655501e-06
Iter: 629 loss: 3.64464699e-06
Iter: 630 loss: 3.64364814e-06
Iter: 631 loss: 3.64095604e-06
Iter: 632 loss: 3.6681754e-06
Iter: 633 loss: 3.64063408e-06
Iter: 634 loss: 3.63708182e-06
Iter: 635 loss: 3.63801314e-06
Iter: 636 loss: 3.63446907e-06
Iter: 637 loss: 3.63112895e-06
Iter: 638 loss: 3.667996e-06
Iter: 639 loss: 3.63113986e-06
Iter: 640 loss: 3.62860851e-06
Iter: 641 loss: 3.63218714e-06
Iter: 642 loss: 3.62765331e-06
Iter: 643 loss: 3.62419655e-06
Iter: 644 loss: 3.63391246e-06
Iter: 645 loss: 3.6231263e-06
Iter: 646 loss: 3.62096625e-06
Iter: 647 loss: 3.63011327e-06
Iter: 648 loss: 3.62047808e-06
Iter: 649 loss: 3.6173185e-06
Iter: 650 loss: 3.61863295e-06
Iter: 651 loss: 3.61518892e-06
Iter: 652 loss: 3.61180946e-06
Iter: 653 loss: 3.61881757e-06
Iter: 654 loss: 3.61047501e-06
Iter: 655 loss: 3.60738341e-06
Iter: 656 loss: 3.61085768e-06
Iter: 657 loss: 3.60551326e-06
Iter: 658 loss: 3.60299737e-06
Iter: 659 loss: 3.6302763e-06
Iter: 660 loss: 3.60277909e-06
Iter: 661 loss: 3.60219269e-06
Iter: 662 loss: 3.60173908e-06
Iter: 663 loss: 3.60070703e-06
Iter: 664 loss: 3.59862679e-06
Iter: 665 loss: 3.62019887e-06
Iter: 666 loss: 3.59851902e-06
Iter: 667 loss: 3.59593878e-06
Iter: 668 loss: 3.59427486e-06
Iter: 669 loss: 3.59340765e-06
Iter: 670 loss: 3.58885563e-06
Iter: 671 loss: 3.59991986e-06
Iter: 672 loss: 3.58738725e-06
Iter: 673 loss: 3.58400757e-06
Iter: 674 loss: 3.59651767e-06
Iter: 675 loss: 3.58326088e-06
Iter: 676 loss: 3.57951444e-06
Iter: 677 loss: 3.59442356e-06
Iter: 678 loss: 3.57876615e-06
Iter: 679 loss: 3.57618205e-06
Iter: 680 loss: 3.59556543e-06
Iter: 681 loss: 3.57612839e-06
Iter: 682 loss: 3.5747903e-06
Iter: 683 loss: 3.57990621e-06
Iter: 684 loss: 3.57433555e-06
Iter: 685 loss: 3.57250065e-06
Iter: 686 loss: 3.57168665e-06
Iter: 687 loss: 3.57068211e-06
Iter: 688 loss: 3.56784835e-06
Iter: 689 loss: 3.57017075e-06
Iter: 690 loss: 3.5660828e-06
Iter: 691 loss: 3.562958e-06
Iter: 692 loss: 3.56948522e-06
Iter: 693 loss: 3.56174269e-06
Iter: 694 loss: 3.55989414e-06
Iter: 695 loss: 3.55985321e-06
Iter: 696 loss: 3.55767e-06
Iter: 697 loss: 3.56289888e-06
Iter: 698 loss: 3.55685324e-06
Iter: 699 loss: 3.55534326e-06
Iter: 700 loss: 3.55295492e-06
Iter: 701 loss: 3.55307884e-06
Iter: 702 loss: 3.55058523e-06
Iter: 703 loss: 3.5511066e-06
Iter: 704 loss: 3.54879717e-06
Iter: 705 loss: 3.54474423e-06
Iter: 706 loss: 3.55826728e-06
Iter: 707 loss: 3.54370741e-06
Iter: 708 loss: 3.54124518e-06
Iter: 709 loss: 3.54683243e-06
Iter: 710 loss: 3.54017175e-06
Iter: 711 loss: 3.53677979e-06
Iter: 712 loss: 3.55096836e-06
Iter: 713 loss: 3.53623636e-06
Iter: 714 loss: 3.5338544e-06
Iter: 715 loss: 3.54984059e-06
Iter: 716 loss: 3.53368478e-06
Iter: 717 loss: 3.53178439e-06
Iter: 718 loss: 3.53331075e-06
Iter: 719 loss: 3.5306648e-06
Iter: 720 loss: 3.52732695e-06
Iter: 721 loss: 3.53069504e-06
Iter: 722 loss: 3.52545612e-06
Iter: 723 loss: 3.5225944e-06
Iter: 724 loss: 3.52442589e-06
Iter: 725 loss: 3.5208086e-06
Iter: 726 loss: 3.51783228e-06
Iter: 727 loss: 3.53168298e-06
Iter: 728 loss: 3.51721519e-06
Iter: 729 loss: 3.51703375e-06
Iter: 730 loss: 3.51602148e-06
Iter: 731 loss: 3.51497101e-06
Iter: 732 loss: 3.51268022e-06
Iter: 733 loss: 3.53142627e-06
Iter: 734 loss: 3.5121293e-06
Iter: 735 loss: 3.50967571e-06
Iter: 736 loss: 3.5191747e-06
Iter: 737 loss: 3.50931168e-06
Iter: 738 loss: 3.50745404e-06
Iter: 739 loss: 3.50753362e-06
Iter: 740 loss: 3.50597e-06
Iter: 741 loss: 3.50240794e-06
Iter: 742 loss: 3.50672781e-06
Iter: 743 loss: 3.50073969e-06
Iter: 744 loss: 3.49814104e-06
Iter: 745 loss: 3.51300218e-06
Iter: 746 loss: 3.4976747e-06
Iter: 747 loss: 3.49497759e-06
Iter: 748 loss: 3.50228379e-06
Iter: 749 loss: 3.49387119e-06
Iter: 750 loss: 3.49126958e-06
Iter: 751 loss: 3.50651635e-06
Iter: 752 loss: 3.49095444e-06
Iter: 753 loss: 3.48866615e-06
Iter: 754 loss: 3.49589072e-06
Iter: 755 loss: 3.48816e-06
Iter: 756 loss: 3.48582125e-06
Iter: 757 loss: 3.48846311e-06
Iter: 758 loss: 3.48452863e-06
Iter: 759 loss: 3.48217031e-06
Iter: 760 loss: 3.48026879e-06
Iter: 761 loss: 3.47972241e-06
Iter: 762 loss: 3.47920786e-06
Iter: 763 loss: 3.47820469e-06
Iter: 764 loss: 3.47655146e-06
Iter: 765 loss: 3.47811033e-06
Iter: 766 loss: 3.47538275e-06
Iter: 767 loss: 3.47402147e-06
Iter: 768 loss: 3.47097011e-06
Iter: 769 loss: 3.51640142e-06
Iter: 770 loss: 3.47098739e-06
Iter: 771 loss: 3.46827301e-06
Iter: 772 loss: 3.49184802e-06
Iter: 773 loss: 3.46834304e-06
Iter: 774 loss: 3.4661291e-06
Iter: 775 loss: 3.46522302e-06
Iter: 776 loss: 3.46421143e-06
Iter: 777 loss: 3.46089473e-06
Iter: 778 loss: 3.47713694e-06
Iter: 779 loss: 3.46038587e-06
Iter: 780 loss: 3.45778949e-06
Iter: 781 loss: 3.46211959e-06
Iter: 782 loss: 3.45661283e-06
Iter: 783 loss: 3.45345916e-06
Iter: 784 loss: 3.47259493e-06
Iter: 785 loss: 3.45321837e-06
Iter: 786 loss: 3.45095282e-06
Iter: 787 loss: 3.45931198e-06
Iter: 788 loss: 3.45032595e-06
Iter: 789 loss: 3.44873138e-06
Iter: 790 loss: 3.46064439e-06
Iter: 791 loss: 3.44846694e-06
Iter: 792 loss: 3.446954e-06
Iter: 793 loss: 3.44535079e-06
Iter: 794 loss: 3.44515411e-06
Iter: 795 loss: 3.44243608e-06
Iter: 796 loss: 3.44670957e-06
Iter: 797 loss: 3.44101818e-06
Iter: 798 loss: 3.4429213e-06
Iter: 799 loss: 3.43992701e-06
Iter: 800 loss: 3.43937268e-06
Iter: 801 loss: 3.43757642e-06
Iter: 802 loss: 3.44584828e-06
Iter: 803 loss: 3.43700276e-06
Iter: 804 loss: 3.43438023e-06
Iter: 805 loss: 3.43229067e-06
Iter: 806 loss: 3.43134525e-06
Iter: 807 loss: 3.42927797e-06
Iter: 808 loss: 3.42919429e-06
Iter: 809 loss: 3.42731482e-06
Iter: 810 loss: 3.42471276e-06
Iter: 811 loss: 3.42464909e-06
Iter: 812 loss: 3.42212297e-06
Iter: 813 loss: 3.45063745e-06
Iter: 814 loss: 3.42192789e-06
Iter: 815 loss: 3.42013686e-06
Iter: 816 loss: 3.42439535e-06
Iter: 817 loss: 3.4193863e-06
Iter: 818 loss: 3.41720238e-06
Iter: 819 loss: 3.42795829e-06
Iter: 820 loss: 3.41697796e-06
Iter: 821 loss: 3.41517784e-06
Iter: 822 loss: 3.41766622e-06
Iter: 823 loss: 3.41440523e-06
Iter: 824 loss: 3.41237956e-06
Iter: 825 loss: 3.41989562e-06
Iter: 826 loss: 3.4115867e-06
Iter: 827 loss: 3.40959832e-06
Iter: 828 loss: 3.40914175e-06
Iter: 829 loss: 3.40793872e-06
Iter: 830 loss: 3.40533711e-06
Iter: 831 loss: 3.41895679e-06
Iter: 832 loss: 3.40496217e-06
Iter: 833 loss: 3.40356678e-06
Iter: 834 loss: 3.40320094e-06
Iter: 835 loss: 3.40284168e-06
Iter: 836 loss: 3.40093789e-06
Iter: 837 loss: 3.40160614e-06
Iter: 838 loss: 3.39927396e-06
Iter: 839 loss: 3.39604821e-06
Iter: 840 loss: 3.41502573e-06
Iter: 841 loss: 3.39547955e-06
Iter: 842 loss: 3.3931708e-06
Iter: 843 loss: 3.40188399e-06
Iter: 844 loss: 3.39262442e-06
Iter: 845 loss: 3.3899023e-06
Iter: 846 loss: 3.39200119e-06
Iter: 847 loss: 3.38828181e-06
Iter: 848 loss: 3.38592076e-06
Iter: 849 loss: 3.39337248e-06
Iter: 850 loss: 3.3854194e-06
Iter: 851 loss: 3.38269115e-06
Iter: 852 loss: 3.38407654e-06
Iter: 853 loss: 3.38073414e-06
Iter: 854 loss: 3.37946062e-06
Iter: 855 loss: 3.37904953e-06
Iter: 856 loss: 3.37774077e-06
Iter: 857 loss: 3.37616029e-06
Iter: 858 loss: 3.3760457e-06
Iter: 859 loss: 3.37341362e-06
Iter: 860 loss: 3.3871986e-06
Iter: 861 loss: 3.37327947e-06
Iter: 862 loss: 3.37147458e-06
Iter: 863 loss: 3.3729516e-06
Iter: 864 loss: 3.37020106e-06
Iter: 865 loss: 3.36788071e-06
Iter: 866 loss: 3.36902735e-06
Iter: 867 loss: 3.36627772e-06
Iter: 868 loss: 3.3667452e-06
Iter: 869 loss: 3.36499625e-06
Iter: 870 loss: 3.36408334e-06
Iter: 871 loss: 3.36130688e-06
Iter: 872 loss: 3.37126357e-06
Iter: 873 loss: 3.36011726e-06
Iter: 874 loss: 3.3579272e-06
Iter: 875 loss: 3.36156e-06
Iter: 876 loss: 3.35707387e-06
Iter: 877 loss: 3.35448e-06
Iter: 878 loss: 3.35829054e-06
Iter: 879 loss: 3.35290451e-06
Iter: 880 loss: 3.35034292e-06
Iter: 881 loss: 3.36159906e-06
Iter: 882 loss: 3.34982019e-06
Iter: 883 loss: 3.34743368e-06
Iter: 884 loss: 3.35251525e-06
Iter: 885 loss: 3.346227e-06
Iter: 886 loss: 3.3440067e-06
Iter: 887 loss: 3.35851064e-06
Iter: 888 loss: 3.34380047e-06
Iter: 889 loss: 3.34160495e-06
Iter: 890 loss: 3.34633501e-06
Iter: 891 loss: 3.34075457e-06
Iter: 892 loss: 3.33858679e-06
Iter: 893 loss: 3.34014885e-06
Iter: 894 loss: 3.33725711e-06
Iter: 895 loss: 3.33441926e-06
Iter: 896 loss: 3.36065796e-06
Iter: 897 loss: 3.33419916e-06
Iter: 898 loss: 3.3323488e-06
Iter: 899 loss: 3.3416668e-06
Iter: 900 loss: 3.33214325e-06
Iter: 901 loss: 3.33043272e-06
Iter: 902 loss: 3.32968784e-06
Iter: 903 loss: 3.32902664e-06
Iter: 904 loss: 3.32808986e-06
Iter: 905 loss: 3.32747527e-06
Iter: 906 loss: 3.3266756e-06
Iter: 907 loss: 3.32539889e-06
Iter: 908 loss: 3.32539139e-06
Iter: 909 loss: 3.32392551e-06
Iter: 910 loss: 3.32204968e-06
Iter: 911 loss: 3.32201353e-06
Iter: 912 loss: 3.31912e-06
Iter: 913 loss: 3.32875879e-06
Iter: 914 loss: 3.31843694e-06
Iter: 915 loss: 3.31622027e-06
Iter: 916 loss: 3.3160502e-06
Iter: 917 loss: 3.31426486e-06
Iter: 918 loss: 3.3106935e-06
Iter: 919 loss: 3.3259696e-06
Iter: 920 loss: 3.30990883e-06
Iter: 921 loss: 3.30677858e-06
Iter: 922 loss: 3.3191991e-06
Iter: 923 loss: 3.30627131e-06
Iter: 924 loss: 3.30396892e-06
Iter: 925 loss: 3.30809735e-06
Iter: 926 loss: 3.30304e-06
Iter: 927 loss: 3.30021203e-06
Iter: 928 loss: 3.30886519e-06
Iter: 929 loss: 3.29941327e-06
Iter: 930 loss: 3.29724207e-06
Iter: 931 loss: 3.32231048e-06
Iter: 932 loss: 3.29731643e-06
Iter: 933 loss: 3.29547788e-06
Iter: 934 loss: 3.29869249e-06
Iter: 935 loss: 3.29486556e-06
Iter: 936 loss: 3.29314935e-06
Iter: 937 loss: 3.30205e-06
Iter: 938 loss: 3.29278578e-06
Iter: 939 loss: 3.29103068e-06
Iter: 940 loss: 3.30581543e-06
Iter: 941 loss: 3.2910034e-06
Iter: 942 loss: 3.29008935e-06
Iter: 943 loss: 3.28842134e-06
Iter: 944 loss: 3.32282843e-06
Iter: 945 loss: 3.28833e-06
Iter: 946 loss: 3.28644137e-06
Iter: 947 loss: 3.28636384e-06
Iter: 948 loss: 3.28491501e-06
Iter: 949 loss: 3.28255942e-06
Iter: 950 loss: 3.29457e-06
Iter: 951 loss: 3.28208307e-06
Iter: 952 loss: 3.27967246e-06
Iter: 953 loss: 3.2850071e-06
Iter: 954 loss: 3.27866064e-06
Iter: 955 loss: 3.27650014e-06
Iter: 956 loss: 3.27633416e-06
Iter: 957 loss: 3.27462681e-06
Iter: 958 loss: 3.27234375e-06
Iter: 959 loss: 3.29625686e-06
Iter: 960 loss: 3.27220778e-06
Iter: 961 loss: 3.27020325e-06
Iter: 962 loss: 3.26645136e-06
Iter: 963 loss: 3.35689356e-06
Iter: 964 loss: 3.26648342e-06
Iter: 965 loss: 3.26470786e-06
Iter: 966 loss: 3.2642879e-06
Iter: 967 loss: 3.26242684e-06
Iter: 968 loss: 3.26086183e-06
Iter: 969 loss: 3.26032796e-06
Iter: 970 loss: 3.25769315e-06
Iter: 971 loss: 3.25778115e-06
Iter: 972 loss: 3.25648125e-06
Iter: 973 loss: 3.27340013e-06
Iter: 974 loss: 3.25645078e-06
Iter: 975 loss: 3.25547944e-06
Iter: 976 loss: 3.25404289e-06
Iter: 977 loss: 3.25386281e-06
Iter: 978 loss: 3.25276233e-06
Iter: 979 loss: 3.25114343e-06
Iter: 980 loss: 3.25105407e-06
Iter: 981 loss: 3.24886059e-06
Iter: 982 loss: 3.25642031e-06
Iter: 983 loss: 3.2482626e-06
Iter: 984 loss: 3.24555685e-06
Iter: 985 loss: 3.25148631e-06
Iter: 986 loss: 3.24456551e-06
Iter: 987 loss: 3.24201642e-06
Iter: 988 loss: 3.25120618e-06
Iter: 989 loss: 3.2416865e-06
Iter: 990 loss: 3.23956942e-06
Iter: 991 loss: 3.24359212e-06
Iter: 992 loss: 3.23854692e-06
Iter: 993 loss: 3.2363871e-06
Iter: 994 loss: 3.24309667e-06
Iter: 995 loss: 3.2359012e-06
Iter: 996 loss: 3.23365248e-06
Iter: 997 loss: 3.23277709e-06
Iter: 998 loss: 3.23151062e-06
Iter: 999 loss: 3.22871301e-06
Iter: 1000 loss: 3.25357746e-06
Iter: 1001 loss: 3.22876622e-06
Iter: 1002 loss: 3.22668848e-06
Iter: 1003 loss: 3.22831102e-06
Iter: 1004 loss: 3.22527649e-06
Iter: 1005 loss: 3.22377946e-06
Iter: 1006 loss: 3.22393112e-06
Iter: 1007 loss: 3.22204596e-06
Iter: 1008 loss: 3.2321766e-06
Iter: 1009 loss: 3.22178926e-06
Iter: 1010 loss: 3.22091432e-06
Iter: 1011 loss: 3.22189817e-06
Iter: 1012 loss: 3.22036567e-06
Iter: 1013 loss: 3.21949142e-06
Iter: 1014 loss: 3.21776088e-06
Iter: 1015 loss: 3.21779953e-06
Iter: 1016 loss: 3.21535e-06
Iter: 1017 loss: 3.21563198e-06
Iter: 1018 loss: 3.21364519e-06
Iter: 1019 loss: 3.21148332e-06
Iter: 1020 loss: 3.21933908e-06
Iter: 1021 loss: 3.21089351e-06
Iter: 1022 loss: 3.2081573e-06
Iter: 1023 loss: 3.21508196e-06
Iter: 1024 loss: 3.20726963e-06
Iter: 1025 loss: 3.20527852e-06
Iter: 1026 loss: 3.22488859e-06
Iter: 1027 loss: 3.20520871e-06
Iter: 1028 loss: 3.20360914e-06
Iter: 1029 loss: 3.20284198e-06
Iter: 1030 loss: 3.20183881e-06
Iter: 1031 loss: 3.19957735e-06
Iter: 1032 loss: 3.2114749e-06
Iter: 1033 loss: 3.19908668e-06
Iter: 1034 loss: 3.19745595e-06
Iter: 1035 loss: 3.19696437e-06
Iter: 1036 loss: 3.19598485e-06
Iter: 1037 loss: 3.19307264e-06
Iter: 1038 loss: 3.20524123e-06
Iter: 1039 loss: 3.19256878e-06
Iter: 1040 loss: 3.19038236e-06
Iter: 1041 loss: 3.20015215e-06
Iter: 1042 loss: 3.19000037e-06
Iter: 1043 loss: 3.1891143e-06
Iter: 1044 loss: 3.18874345e-06
Iter: 1045 loss: 3.18821822e-06
Iter: 1046 loss: 3.18629918e-06
Iter: 1047 loss: 3.18662342e-06
Iter: 1048 loss: 3.18455272e-06
Iter: 1049 loss: 3.18300044e-06
Iter: 1050 loss: 3.18291359e-06
Iter: 1051 loss: 3.18126831e-06
Iter: 1052 loss: 3.18304728e-06
Iter: 1053 loss: 3.18029061e-06
Iter: 1054 loss: 3.17862873e-06
Iter: 1055 loss: 3.17903164e-06
Iter: 1056 loss: 3.17736294e-06
Iter: 1057 loss: 3.17519061e-06
Iter: 1058 loss: 3.18530147e-06
Iter: 1059 loss: 3.17489e-06
Iter: 1060 loss: 3.17277727e-06
Iter: 1061 loss: 3.17199283e-06
Iter: 1062 loss: 3.17098875e-06
Iter: 1063 loss: 3.16819023e-06
Iter: 1064 loss: 3.1816212e-06
Iter: 1065 loss: 3.16771298e-06
Iter: 1066 loss: 3.16537785e-06
Iter: 1067 loss: 3.17701824e-06
Iter: 1068 loss: 3.16492446e-06
Iter: 1069 loss: 3.1632776e-06
Iter: 1070 loss: 3.16663363e-06
Iter: 1071 loss: 3.16266187e-06
Iter: 1072 loss: 3.16017076e-06
Iter: 1073 loss: 3.16724913e-06
Iter: 1074 loss: 3.15957891e-06
Iter: 1075 loss: 3.15785155e-06
Iter: 1076 loss: 3.16421301e-06
Iter: 1077 loss: 3.15742386e-06
Iter: 1078 loss: 3.15645e-06
Iter: 1079 loss: 3.15632815e-06
Iter: 1080 loss: 3.15568604e-06
Iter: 1081 loss: 3.15356488e-06
Iter: 1082 loss: 3.15883108e-06
Iter: 1083 loss: 3.15244483e-06
Iter: 1084 loss: 3.15036141e-06
Iter: 1085 loss: 3.16473e-06
Iter: 1086 loss: 3.15027273e-06
Iter: 1087 loss: 3.14855015e-06
Iter: 1088 loss: 3.15741181e-06
Iter: 1089 loss: 3.14828685e-06
Iter: 1090 loss: 3.14622662e-06
Iter: 1091 loss: 3.14880072e-06
Iter: 1092 loss: 3.14520776e-06
Iter: 1093 loss: 3.143703e-06
Iter: 1094 loss: 3.1416032e-06
Iter: 1095 loss: 3.14162548e-06
Iter: 1096 loss: 3.13865166e-06
Iter: 1097 loss: 3.1645925e-06
Iter: 1098 loss: 3.13854e-06
Iter: 1099 loss: 3.1364907e-06
Iter: 1100 loss: 3.14150361e-06
Iter: 1101 loss: 3.13589703e-06
Iter: 1102 loss: 3.13405235e-06
Iter: 1103 loss: 3.13914597e-06
Iter: 1104 loss: 3.13360215e-06
Iter: 1105 loss: 3.13191822e-06
Iter: 1106 loss: 3.13493183e-06
Iter: 1107 loss: 3.1311622e-06
Iter: 1108 loss: 3.12927045e-06
Iter: 1109 loss: 3.14109138e-06
Iter: 1110 loss: 3.12893098e-06
Iter: 1111 loss: 3.12788802e-06
Iter: 1112 loss: 3.14058138e-06
Iter: 1113 loss: 3.127843e-06
Iter: 1114 loss: 3.12641737e-06
Iter: 1115 loss: 3.12793395e-06
Iter: 1116 loss: 3.12561156e-06
Iter: 1117 loss: 3.12457109e-06
Iter: 1118 loss: 3.12280758e-06
Iter: 1119 loss: 3.12286693e-06
Iter: 1120 loss: 3.12085126e-06
Iter: 1121 loss: 3.12552834e-06
Iter: 1122 loss: 3.12010934e-06
Iter: 1123 loss: 3.11863846e-06
Iter: 1124 loss: 3.11873237e-06
Iter: 1125 loss: 3.11768e-06
Iter: 1126 loss: 3.11645636e-06
Iter: 1127 loss: 3.11640247e-06
Iter: 1128 loss: 3.114729e-06
Iter: 1129 loss: 3.11900794e-06
Iter: 1130 loss: 3.11403301e-06
Iter: 1131 loss: 3.11210897e-06
Iter: 1132 loss: 3.11078134e-06
Iter: 1133 loss: 3.11017675e-06
Iter: 1134 loss: 3.1069726e-06
Iter: 1135 loss: 3.13247347e-06
Iter: 1136 loss: 3.10685937e-06
Iter: 1137 loss: 3.1048362e-06
Iter: 1138 loss: 3.11071381e-06
Iter: 1139 loss: 3.10406062e-06
Iter: 1140 loss: 3.10174937e-06
Iter: 1141 loss: 3.10400765e-06
Iter: 1142 loss: 3.10033283e-06
Iter: 1143 loss: 3.09877123e-06
Iter: 1144 loss: 3.11732401e-06
Iter: 1145 loss: 3.09864845e-06
Iter: 1146 loss: 3.09789084e-06
Iter: 1147 loss: 3.0979204e-06
Iter: 1148 loss: 3.09703705e-06
Iter: 1149 loss: 3.09487632e-06
Iter: 1150 loss: 3.11924668e-06
Iter: 1151 loss: 3.09481788e-06
Iter: 1152 loss: 3.09308143e-06
Iter: 1153 loss: 3.10098926e-06
Iter: 1154 loss: 3.09259462e-06
Iter: 1155 loss: 3.09116467e-06
Iter: 1156 loss: 3.08928657e-06
Iter: 1157 loss: 3.08922677e-06
Iter: 1158 loss: 3.0874703e-06
Iter: 1159 loss: 3.0874462e-06
Iter: 1160 loss: 3.0856595e-06
Iter: 1161 loss: 3.08672679e-06
Iter: 1162 loss: 3.08462904e-06
Iter: 1163 loss: 3.08314247e-06
Iter: 1164 loss: 3.08272683e-06
Iter: 1165 loss: 3.08191397e-06
Iter: 1166 loss: 3.0792487e-06
Iter: 1167 loss: 3.08411e-06
Iter: 1168 loss: 3.07811433e-06
Iter: 1169 loss: 3.07597e-06
Iter: 1170 loss: 3.08807012e-06
Iter: 1171 loss: 3.07544383e-06
Iter: 1172 loss: 3.07354071e-06
Iter: 1173 loss: 3.07546247e-06
Iter: 1174 loss: 3.07235314e-06
Iter: 1175 loss: 3.07061737e-06
Iter: 1176 loss: 3.08758877e-06
Iter: 1177 loss: 3.07049049e-06
Iter: 1178 loss: 3.0689198e-06
Iter: 1179 loss: 3.07131904e-06
Iter: 1180 loss: 3.06805418e-06
Iter: 1181 loss: 3.06643688e-06
Iter: 1182 loss: 3.06643415e-06
Iter: 1183 loss: 3.06551783e-06
Iter: 1184 loss: 3.06362199e-06
Iter: 1185 loss: 3.09030838e-06
Iter: 1186 loss: 3.06354559e-06
Iter: 1187 loss: 3.06208472e-06
Iter: 1188 loss: 3.06625179e-06
Iter: 1189 loss: 3.06139e-06
Iter: 1190 loss: 3.05946469e-06
Iter: 1191 loss: 3.06097127e-06
Iter: 1192 loss: 3.05821823e-06
Iter: 1193 loss: 3.05617846e-06
Iter: 1194 loss: 3.07171831e-06
Iter: 1195 loss: 3.05617732e-06
Iter: 1196 loss: 3.05437561e-06
Iter: 1197 loss: 3.06271659e-06
Iter: 1198 loss: 3.05411459e-06
Iter: 1199 loss: 3.05282947e-06
Iter: 1200 loss: 3.05268622e-06
Iter: 1201 loss: 3.05190315e-06
Iter: 1202 loss: 3.05029016e-06
Iter: 1203 loss: 3.04945752e-06
Iter: 1204 loss: 3.04865853e-06
Iter: 1205 loss: 3.0465776e-06
Iter: 1206 loss: 3.05825142e-06
Iter: 1207 loss: 3.04617652e-06
Iter: 1208 loss: 3.04351624e-06
Iter: 1209 loss: 3.04517152e-06
Iter: 1210 loss: 3.04180503e-06
Iter: 1211 loss: 3.03924071e-06
Iter: 1212 loss: 3.056683e-06
Iter: 1213 loss: 3.03895422e-06
Iter: 1214 loss: 3.03855222e-06
Iter: 1215 loss: 3.03809065e-06
Iter: 1216 loss: 3.03708634e-06
Iter: 1217 loss: 3.03596289e-06
Iter: 1218 loss: 3.03586057e-06
Iter: 1219 loss: 3.03465049e-06
Iter: 1220 loss: 3.03426168e-06
Iter: 1221 loss: 3.03358274e-06
Iter: 1222 loss: 3.03183151e-06
Iter: 1223 loss: 3.03508386e-06
Iter: 1224 loss: 3.03111119e-06
Iter: 1225 loss: 3.0290862e-06
Iter: 1226 loss: 3.03472279e-06
Iter: 1227 loss: 3.0283943e-06
Iter: 1228 loss: 3.0263659e-06
Iter: 1229 loss: 3.03927231e-06
Iter: 1230 loss: 3.02612648e-06
Iter: 1231 loss: 3.02472e-06
Iter: 1232 loss: 3.0318165e-06
Iter: 1233 loss: 3.02455055e-06
Iter: 1234 loss: 3.02313583e-06
Iter: 1235 loss: 3.02145691e-06
Iter: 1236 loss: 3.02125704e-06
Iter: 1237 loss: 3.01907903e-06
Iter: 1238 loss: 3.02855278e-06
Iter: 1239 loss: 3.01860064e-06
Iter: 1240 loss: 3.01687737e-06
Iter: 1241 loss: 3.01960608e-06
Iter: 1242 loss: 3.01598766e-06
Iter: 1243 loss: 3.01374826e-06
Iter: 1244 loss: 3.01826185e-06
Iter: 1245 loss: 3.01271393e-06
Iter: 1246 loss: 3.01105911e-06
Iter: 1247 loss: 3.02691046e-06
Iter: 1248 loss: 3.01090813e-06
Iter: 1249 loss: 3.00939018e-06
Iter: 1250 loss: 3.03290926e-06
Iter: 1251 loss: 3.0094443e-06
Iter: 1252 loss: 3.00900274e-06
Iter: 1253 loss: 3.00773195e-06
Iter: 1254 loss: 3.01854152e-06
Iter: 1255 loss: 3.00749207e-06
Iter: 1256 loss: 3.00589591e-06
Iter: 1257 loss: 3.00892725e-06
Iter: 1258 loss: 3.00498186e-06
Iter: 1259 loss: 3.00351758e-06
Iter: 1260 loss: 3.01104774e-06
Iter: 1261 loss: 3.00336364e-06
Iter: 1262 loss: 3.00179727e-06
Iter: 1263 loss: 3.00203e-06
Iter: 1264 loss: 3.00056809e-06
Iter: 1265 loss: 2.99833573e-06
Iter: 1266 loss: 3.0181302e-06
Iter: 1267 loss: 2.99830162e-06
Iter: 1268 loss: 2.99699695e-06
Iter: 1269 loss: 3.00142801e-06
Iter: 1270 loss: 2.99670523e-06
Iter: 1271 loss: 2.99546969e-06
Iter: 1272 loss: 2.99435851e-06
Iter: 1273 loss: 2.99416661e-06
Iter: 1274 loss: 2.99239036e-06
Iter: 1275 loss: 2.99739577e-06
Iter: 1276 loss: 2.99170301e-06
Iter: 1277 loss: 2.98995246e-06
Iter: 1278 loss: 2.99657086e-06
Iter: 1279 loss: 2.98944315e-06
Iter: 1280 loss: 2.98769874e-06
Iter: 1281 loss: 2.99026283e-06
Iter: 1282 loss: 2.98691157e-06
Iter: 1283 loss: 2.98882605e-06
Iter: 1284 loss: 2.98642817e-06
Iter: 1285 loss: 2.98605164e-06
Iter: 1286 loss: 2.98482564e-06
Iter: 1287 loss: 2.99047861e-06
Iter: 1288 loss: 2.98437362e-06
Iter: 1289 loss: 2.98284294e-06
Iter: 1290 loss: 2.98273153e-06
Iter: 1291 loss: 2.98142186e-06
Iter: 1292 loss: 2.9801472e-06
Iter: 1293 loss: 2.98020495e-06
Iter: 1294 loss: 2.97904057e-06
Iter: 1295 loss: 2.97817769e-06
Iter: 1296 loss: 2.97794986e-06
Iter: 1297 loss: 2.97633915e-06
Iter: 1298 loss: 2.99398971e-06
Iter: 1299 loss: 2.97622182e-06
Iter: 1300 loss: 2.97517454e-06
Iter: 1301 loss: 2.97969541e-06
Iter: 1302 loss: 2.97498809e-06
Iter: 1303 loss: 2.97390443e-06
Iter: 1304 loss: 2.97315864e-06
Iter: 1305 loss: 2.97303495e-06
Iter: 1306 loss: 2.97116912e-06
Iter: 1307 loss: 2.97305814e-06
Iter: 1308 loss: 2.96992e-06
Iter: 1309 loss: 2.96802978e-06
Iter: 1310 loss: 2.97331326e-06
Iter: 1311 loss: 2.96727785e-06
Iter: 1312 loss: 2.96538292e-06
Iter: 1313 loss: 2.97348879e-06
Iter: 1314 loss: 2.96508756e-06
Iter: 1315 loss: 2.9638793e-06
Iter: 1316 loss: 2.97951783e-06
Iter: 1317 loss: 2.96406301e-06
Iter: 1318 loss: 2.96250869e-06
Iter: 1319 loss: 2.96301619e-06
Iter: 1320 loss: 2.96158714e-06
Iter: 1321 loss: 2.96077246e-06
Iter: 1322 loss: 2.95918926e-06
Iter: 1323 loss: 2.95931636e-06
Iter: 1324 loss: 2.95736277e-06
Iter: 1325 loss: 2.9607213e-06
Iter: 1326 loss: 2.95659697e-06
Iter: 1327 loss: 2.95480754e-06
Iter: 1328 loss: 2.9666121e-06
Iter: 1329 loss: 2.95468112e-06
Iter: 1330 loss: 2.95313157e-06
Iter: 1331 loss: 2.95815607e-06
Iter: 1332 loss: 2.95274e-06
Iter: 1333 loss: 2.95159452e-06
Iter: 1334 loss: 2.95810264e-06
Iter: 1335 loss: 2.95150744e-06
Iter: 1336 loss: 2.95006271e-06
Iter: 1337 loss: 2.94976689e-06
Iter: 1338 loss: 2.948972e-06
Iter: 1339 loss: 2.94741471e-06
Iter: 1340 loss: 2.95444624e-06
Iter: 1341 loss: 2.94720144e-06
Iter: 1342 loss: 2.94563756e-06
Iter: 1343 loss: 2.94466e-06
Iter: 1344 loss: 2.94414076e-06
Iter: 1345 loss: 2.9422531e-06
Iter: 1346 loss: 2.96684266e-06
Iter: 1347 loss: 2.94229312e-06
Iter: 1348 loss: 2.94107622e-06
Iter: 1349 loss: 2.94000438e-06
Iter: 1350 loss: 2.93971175e-06
Iter: 1351 loss: 2.93904623e-06
Iter: 1352 loss: 2.93843e-06
Iter: 1353 loss: 2.93791186e-06
Iter: 1354 loss: 2.93653443e-06
Iter: 1355 loss: 2.94941697e-06
Iter: 1356 loss: 2.93627022e-06
Iter: 1357 loss: 2.93503376e-06
Iter: 1358 loss: 2.93601374e-06
Iter: 1359 loss: 2.93422272e-06
Iter: 1360 loss: 2.93286257e-06
Iter: 1361 loss: 2.93584935e-06
Iter: 1362 loss: 2.93232529e-06
Iter: 1363 loss: 2.9304274e-06
Iter: 1364 loss: 2.9367925e-06
Iter: 1365 loss: 2.92993309e-06
Iter: 1366 loss: 2.92850768e-06
Iter: 1367 loss: 2.93832409e-06
Iter: 1368 loss: 2.92847335e-06
Iter: 1369 loss: 2.92722552e-06
Iter: 1370 loss: 2.92978802e-06
Iter: 1371 loss: 2.92659206e-06
Iter: 1372 loss: 2.92518826e-06
Iter: 1373 loss: 2.9276639e-06
Iter: 1374 loss: 2.92462664e-06
Iter: 1375 loss: 2.9234418e-06
Iter: 1376 loss: 2.92601658e-06
Iter: 1377 loss: 2.92298228e-06
Iter: 1378 loss: 2.92158416e-06
Iter: 1379 loss: 2.92067261e-06
Iter: 1380 loss: 2.92019149e-06
Iter: 1381 loss: 2.91844208e-06
Iter: 1382 loss: 2.91846254e-06
Iter: 1383 loss: 2.9178359e-06
Iter: 1384 loss: 2.9177038e-06
Iter: 1385 loss: 2.91683455e-06
Iter: 1386 loss: 2.91556148e-06
Iter: 1387 loss: 2.91543529e-06
Iter: 1388 loss: 2.91429069e-06
Iter: 1389 loss: 2.91227752e-06
Iter: 1390 loss: 2.96225539e-06
Iter: 1391 loss: 2.91218566e-06
Iter: 1392 loss: 2.91016931e-06
Iter: 1393 loss: 2.92318509e-06
Iter: 1394 loss: 2.91009883e-06
Iter: 1395 loss: 2.90814569e-06
Iter: 1396 loss: 2.90945741e-06
Iter: 1397 loss: 2.90694743e-06
Iter: 1398 loss: 2.90569187e-06
Iter: 1399 loss: 2.90560115e-06
Iter: 1400 loss: 2.90442722e-06
Iter: 1401 loss: 2.90553362e-06
Iter: 1402 loss: 2.90386652e-06
Iter: 1403 loss: 2.90228741e-06
Iter: 1404 loss: 2.90685102e-06
Iter: 1405 loss: 2.9019327e-06
Iter: 1406 loss: 2.90060302e-06
Iter: 1407 loss: 2.90389517e-06
Iter: 1408 loss: 2.90017374e-06
Iter: 1409 loss: 2.89906848e-06
Iter: 1410 loss: 2.89872105e-06
Iter: 1411 loss: 2.89798049e-06
Iter: 1412 loss: 2.89635e-06
Iter: 1413 loss: 2.90205389e-06
Iter: 1414 loss: 2.8958234e-06
Iter: 1415 loss: 2.89432523e-06
Iter: 1416 loss: 2.90332582e-06
Iter: 1417 loss: 2.89420086e-06
Iter: 1418 loss: 2.89292939e-06
Iter: 1419 loss: 2.91291508e-06
Iter: 1420 loss: 2.89290983e-06
Iter: 1421 loss: 2.89212358e-06
Iter: 1422 loss: 2.89076934e-06
Iter: 1423 loss: 2.90565345e-06
Iter: 1424 loss: 2.890622e-06
Iter: 1425 loss: 2.88890283e-06
Iter: 1426 loss: 2.89097989e-06
Iter: 1427 loss: 2.88806609e-06
Iter: 1428 loss: 2.88626e-06
Iter: 1429 loss: 2.88848491e-06
Iter: 1430 loss: 2.88529759e-06
Iter: 1431 loss: 2.88317733e-06
Iter: 1432 loss: 2.89348327e-06
Iter: 1433 loss: 2.88277556e-06
Iter: 1434 loss: 2.8816612e-06
Iter: 1435 loss: 2.90117509e-06
Iter: 1436 loss: 2.88161118e-06
Iter: 1437 loss: 2.88051797e-06
Iter: 1438 loss: 2.88106162e-06
Iter: 1439 loss: 2.87990633e-06
Iter: 1440 loss: 2.87840976e-06
Iter: 1441 loss: 2.88059346e-06
Iter: 1442 loss: 2.87780131e-06
Iter: 1443 loss: 2.87629155e-06
Iter: 1444 loss: 2.88158367e-06
Iter: 1445 loss: 2.8757936e-06
Iter: 1446 loss: 2.87462399e-06
Iter: 1447 loss: 2.87535386e-06
Iter: 1448 loss: 2.87359899e-06
Iter: 1449 loss: 2.87209696e-06
Iter: 1450 loss: 2.87566286e-06
Iter: 1451 loss: 2.87143666e-06
Iter: 1452 loss: 2.87149e-06
Iter: 1453 loss: 2.87067451e-06
Iter: 1454 loss: 2.87010971e-06
Iter: 1455 loss: 2.86936711e-06
Iter: 1456 loss: 2.86927479e-06
Iter: 1457 loss: 2.86862337e-06
Iter: 1458 loss: 2.8671875e-06
Iter: 1459 loss: 2.8916761e-06
Iter: 1460 loss: 2.86722957e-06
Iter: 1461 loss: 2.86549721e-06
Iter: 1462 loss: 2.87879357e-06
Iter: 1463 loss: 2.86535533e-06
Iter: 1464 loss: 2.86423779e-06
Iter: 1465 loss: 2.86343e-06
Iter: 1466 loss: 2.86303407e-06
Iter: 1467 loss: 2.86158024e-06
Iter: 1468 loss: 2.88086403e-06
Iter: 1469 loss: 2.86162231e-06
Iter: 1470 loss: 2.86045542e-06
Iter: 1471 loss: 2.86150771e-06
Iter: 1472 loss: 2.85991723e-06
Iter: 1473 loss: 2.85870601e-06
Iter: 1474 loss: 2.8648542e-06
Iter: 1475 loss: 2.85853548e-06
Iter: 1476 loss: 2.85736405e-06
Iter: 1477 loss: 2.85861574e-06
Iter: 1478 loss: 2.85684837e-06
Iter: 1479 loss: 2.855817e-06
Iter: 1480 loss: 2.85839269e-06
Iter: 1481 loss: 2.8552688e-06
Iter: 1482 loss: 2.85414649e-06
Iter: 1483 loss: 2.85506098e-06
Iter: 1484 loss: 2.8535e-06
Iter: 1485 loss: 2.85235637e-06
Iter: 1486 loss: 2.86635486e-06
Iter: 1487 loss: 2.85236661e-06
Iter: 1488 loss: 2.8509462e-06
Iter: 1489 loss: 2.85347164e-06
Iter: 1490 loss: 2.85036958e-06
Iter: 1491 loss: 2.84962516e-06
Iter: 1492 loss: 2.84855969e-06
Iter: 1493 loss: 2.84850876e-06
Iter: 1494 loss: 2.84696421e-06
Iter: 1495 loss: 2.84808675e-06
Iter: 1496 loss: 2.84609268e-06
Iter: 1497 loss: 2.84422481e-06
Iter: 1498 loss: 2.84806083e-06
Iter: 1499 loss: 2.84361477e-06
Iter: 1500 loss: 2.84213e-06
Iter: 1501 loss: 2.85464421e-06
Iter: 1502 loss: 2.84211092e-06
Iter: 1503 loss: 2.84096882e-06
Iter: 1504 loss: 2.84330895e-06
Iter: 1505 loss: 2.84050429e-06
Iter: 1506 loss: 2.83874533e-06
Iter: 1507 loss: 2.84283578e-06
Iter: 1508 loss: 2.83814234e-06
Iter: 1509 loss: 2.83694044e-06
Iter: 1510 loss: 2.84029784e-06
Iter: 1511 loss: 2.8364052e-06
Iter: 1512 loss: 2.83505642e-06
Iter: 1513 loss: 2.8378131e-06
Iter: 1514 loss: 2.83447071e-06
Iter: 1515 loss: 2.83291411e-06
Iter: 1516 loss: 2.83511963e-06
Iter: 1517 loss: 2.83207919e-06
Iter: 1518 loss: 2.83088775e-06
Iter: 1519 loss: 2.83939789e-06
Iter: 1520 loss: 2.83084501e-06
Iter: 1521 loss: 2.82995506e-06
Iter: 1522 loss: 2.82991732e-06
Iter: 1523 loss: 2.82925203e-06
Iter: 1524 loss: 2.8278555e-06
Iter: 1525 loss: 2.84067437e-06
Iter: 1526 loss: 2.82764813e-06
Iter: 1527 loss: 2.82626502e-06
Iter: 1528 loss: 2.82963401e-06
Iter: 1529 loss: 2.82579686e-06
Iter: 1530 loss: 2.82430392e-06
Iter: 1531 loss: 2.82960195e-06
Iter: 1532 loss: 2.82386736e-06
Iter: 1533 loss: 2.82270094e-06
Iter: 1534 loss: 2.82293149e-06
Iter: 1535 loss: 2.82178644e-06
Iter: 1536 loss: 2.82034716e-06
Iter: 1537 loss: 2.83599e-06
Iter: 1538 loss: 2.82041628e-06
Iter: 1539 loss: 2.81928305e-06
Iter: 1540 loss: 2.82473729e-06
Iter: 1541 loss: 2.8192278e-06
Iter: 1542 loss: 2.81818939e-06
Iter: 1543 loss: 2.81837447e-06
Iter: 1544 loss: 2.81739926e-06
Iter: 1545 loss: 2.81614598e-06
Iter: 1546 loss: 2.81966049e-06
Iter: 1547 loss: 2.81562939e-06
Iter: 1548 loss: 2.81417601e-06
Iter: 1549 loss: 2.81662096e-06
Iter: 1550 loss: 2.81340726e-06
Iter: 1551 loss: 2.81206553e-06
Iter: 1552 loss: 2.81623898e-06
Iter: 1553 loss: 2.8116574e-06
Iter: 1554 loss: 2.81101916e-06
Iter: 1555 loss: 2.81087205e-06
Iter: 1556 loss: 2.81013854e-06
Iter: 1557 loss: 2.80861923e-06
Iter: 1558 loss: 2.83463692e-06
Iter: 1559 loss: 2.80863583e-06
Iter: 1560 loss: 2.80766039e-06
Iter: 1561 loss: 2.80684503e-06
Iter: 1562 loss: 2.80645168e-06
Iter: 1563 loss: 2.80447557e-06
Iter: 1564 loss: 2.81253415e-06
Iter: 1565 loss: 2.80393579e-06
Iter: 1566 loss: 2.8023303e-06
Iter: 1567 loss: 2.80342e-06
Iter: 1568 loss: 2.80153199e-06
Iter: 1569 loss: 2.79934739e-06
Iter: 1570 loss: 2.80769882e-06
Iter: 1571 loss: 2.79890469e-06
Iter: 1572 loss: 2.79745132e-06
Iter: 1573 loss: 2.80886e-06
Iter: 1574 loss: 2.79735832e-06
Iter: 1575 loss: 2.79592541e-06
Iter: 1576 loss: 2.8003451e-06
Iter: 1577 loss: 2.79566211e-06
Iter: 1578 loss: 2.79466849e-06
Iter: 1579 loss: 2.79629444e-06
Iter: 1580 loss: 2.79421351e-06
Iter: 1581 loss: 2.79316873e-06
Iter: 1582 loss: 2.79400865e-06
Iter: 1583 loss: 2.79243841e-06
Iter: 1584 loss: 2.79118103e-06
Iter: 1585 loss: 2.7983881e-06
Iter: 1586 loss: 2.79104142e-06
Iter: 1587 loss: 2.79024971e-06
Iter: 1588 loss: 2.79026517e-06
Iter: 1589 loss: 2.78953075e-06
Iter: 1590 loss: 2.78859284e-06
Iter: 1591 loss: 2.78850348e-06
Iter: 1592 loss: 2.78766606e-06
Iter: 1593 loss: 2.78668222e-06
Iter: 1594 loss: 2.78655898e-06
Iter: 1595 loss: 2.78490324e-06
Iter: 1596 loss: 2.79327901e-06
Iter: 1597 loss: 2.78468e-06
Iter: 1598 loss: 2.78331572e-06
Iter: 1599 loss: 2.78353446e-06
Iter: 1600 loss: 2.78221205e-06
Iter: 1601 loss: 2.78038942e-06
Iter: 1602 loss: 2.79177311e-06
Iter: 1603 loss: 2.78010043e-06
Iter: 1604 loss: 2.77893514e-06
Iter: 1605 loss: 2.78272455e-06
Iter: 1606 loss: 2.77865138e-06
Iter: 1607 loss: 2.77698746e-06
Iter: 1608 loss: 2.78090261e-06
Iter: 1609 loss: 2.7762951e-06
Iter: 1610 loss: 2.7749918e-06
Iter: 1611 loss: 2.77802906e-06
Iter: 1612 loss: 2.77442064e-06
Iter: 1613 loss: 2.77319759e-06
Iter: 1614 loss: 2.77613435e-06
Iter: 1615 loss: 2.772779e-06
Iter: 1616 loss: 2.77134814e-06
Iter: 1617 loss: 2.77495519e-06
Iter: 1618 loss: 2.77098206e-06
Iter: 1619 loss: 2.77030222e-06
Iter: 1620 loss: 2.770229e-06
Iter: 1621 loss: 2.76936e-06
Iter: 1622 loss: 2.7699657e-06
Iter: 1623 loss: 2.76888181e-06
Iter: 1624 loss: 2.76800665e-06
Iter: 1625 loss: 2.76642777e-06
Iter: 1626 loss: 2.792342e-06
Iter: 1627 loss: 2.76631272e-06
Iter: 1628 loss: 2.7645e-06
Iter: 1629 loss: 2.76914943e-06
Iter: 1630 loss: 2.76388255e-06
Iter: 1631 loss: 2.76231685e-06
Iter: 1632 loss: 2.77512663e-06
Iter: 1633 loss: 2.76222863e-06
Iter: 1634 loss: 2.76107062e-06
Iter: 1635 loss: 2.76184119e-06
Iter: 1636 loss: 2.76040441e-06
Iter: 1637 loss: 2.75895081e-06
Iter: 1638 loss: 2.76338869e-06
Iter: 1639 loss: 2.75858338e-06
Iter: 1640 loss: 2.75730599e-06
Iter: 1641 loss: 2.76877586e-06
Iter: 1642 loss: 2.75717593e-06
Iter: 1643 loss: 2.75608681e-06
Iter: 1644 loss: 2.75739626e-06
Iter: 1645 loss: 2.7554604e-06
Iter: 1646 loss: 2.75450816e-06
Iter: 1647 loss: 2.75531193e-06
Iter: 1648 loss: 2.75379261e-06
Iter: 1649 loss: 2.75234447e-06
Iter: 1650 loss: 2.75852017e-06
Iter: 1651 loss: 2.75200046e-06
Iter: 1652 loss: 2.75119191e-06
Iter: 1653 loss: 2.75921821e-06
Iter: 1654 loss: 2.75101479e-06
Iter: 1655 loss: 2.75034336e-06
Iter: 1656 loss: 2.76091032e-06
Iter: 1657 loss: 2.75027e-06
Iter: 1658 loss: 2.74988497e-06
Iter: 1659 loss: 2.74852027e-06
Iter: 1660 loss: 2.75012098e-06
Iter: 1661 loss: 2.74751619e-06
Iter: 1662 loss: 2.74583726e-06
Iter: 1663 loss: 2.76961691e-06
Iter: 1664 loss: 2.74575541e-06
Iter: 1665 loss: 2.74488184e-06
Iter: 1666 loss: 2.74404147e-06
Iter: 1667 loss: 2.7438e-06
Iter: 1668 loss: 2.74217246e-06
Iter: 1669 loss: 2.7553574e-06
Iter: 1670 loss: 2.74212334e-06
Iter: 1671 loss: 2.74072568e-06
Iter: 1672 loss: 2.73999649e-06
Iter: 1673 loss: 2.73933301e-06
Iter: 1674 loss: 2.73804608e-06
Iter: 1675 loss: 2.75747379e-06
Iter: 1676 loss: 2.73805e-06
Iter: 1677 loss: 2.73674732e-06
Iter: 1678 loss: 2.73905198e-06
Iter: 1679 loss: 2.73611795e-06
Iter: 1680 loss: 2.73506885e-06
Iter: 1681 loss: 2.73638238e-06
Iter: 1682 loss: 2.7344588e-06
Iter: 1683 loss: 2.73308547e-06
Iter: 1684 loss: 2.73522096e-06
Iter: 1685 loss: 2.73249316e-06
Iter: 1686 loss: 2.73111709e-06
Iter: 1687 loss: 2.74590366e-06
Iter: 1688 loss: 2.73107662e-06
Iter: 1689 loss: 2.73058458e-06
Iter: 1690 loss: 2.73052365e-06
Iter: 1691 loss: 2.72999682e-06
Iter: 1692 loss: 2.72871603e-06
Iter: 1693 loss: 2.7370761e-06
Iter: 1694 loss: 2.72838111e-06
Iter: 1695 loss: 2.72707166e-06
Iter: 1696 loss: 2.72986699e-06
Iter: 1697 loss: 2.72650595e-06
Iter: 1698 loss: 2.72492889e-06
Iter: 1699 loss: 2.72607326e-06
Iter: 1700 loss: 2.7238857e-06
Iter: 1701 loss: 2.72235366e-06
Iter: 1702 loss: 2.73226e-06
Iter: 1703 loss: 2.7222427e-06
Iter: 1704 loss: 2.72063789e-06
Iter: 1705 loss: 2.72254192e-06
Iter: 1706 loss: 2.71968088e-06
Iter: 1707 loss: 2.71873705e-06
Iter: 1708 loss: 2.72523926e-06
Iter: 1709 loss: 2.71844488e-06
Iter: 1710 loss: 2.71725207e-06
Iter: 1711 loss: 2.723129e-06
Iter: 1712 loss: 2.71710951e-06
Iter: 1713 loss: 2.71579506e-06
Iter: 1714 loss: 2.71649628e-06
Iter: 1715 loss: 2.71521731e-06
Iter: 1716 loss: 2.71375984e-06
Iter: 1717 loss: 2.71505087e-06
Iter: 1718 loss: 2.71299132e-06
Iter: 1719 loss: 2.71179033e-06
Iter: 1720 loss: 2.72669695e-06
Iter: 1721 loss: 2.71171848e-06
Iter: 1722 loss: 2.71108229e-06
Iter: 1723 loss: 2.71111276e-06
Iter: 1724 loss: 2.71036629e-06
Iter: 1725 loss: 2.70894043e-06
Iter: 1726 loss: 2.73917703e-06
Iter: 1727 loss: 2.70892201e-06
Iter: 1728 loss: 2.70792066e-06
Iter: 1729 loss: 2.70842293e-06
Iter: 1730 loss: 2.70716828e-06
Iter: 1731 loss: 2.70575811e-06
Iter: 1732 loss: 2.70582e-06
Iter: 1733 loss: 2.70473174e-06
Iter: 1734 loss: 2.70279634e-06
Iter: 1735 loss: 2.7149913e-06
Iter: 1736 loss: 2.70256396e-06
Iter: 1737 loss: 2.70116288e-06
Iter: 1738 loss: 2.70406031e-06
Iter: 1739 loss: 2.70063856e-06
Iter: 1740 loss: 2.69936572e-06
Iter: 1741 loss: 2.70691339e-06
Iter: 1742 loss: 2.69917905e-06
Iter: 1743 loss: 2.69801512e-06
Iter: 1744 loss: 2.69931752e-06
Iter: 1745 loss: 2.69734574e-06
Iter: 1746 loss: 2.69604516e-06
Iter: 1747 loss: 2.71244085e-06
Iter: 1748 loss: 2.69600764e-06
Iter: 1749 loss: 2.69540851e-06
Iter: 1750 loss: 2.69406473e-06
Iter: 1751 loss: 2.72324132e-06
Iter: 1752 loss: 2.69401835e-06
Iter: 1753 loss: 2.69243537e-06
Iter: 1754 loss: 2.7033243e-06
Iter: 1755 loss: 2.69226121e-06
Iter: 1756 loss: 2.69177281e-06
Iter: 1757 loss: 2.69168368e-06
Iter: 1758 loss: 2.69088423e-06
Iter: 1759 loss: 2.69127713e-06
Iter: 1760 loss: 2.69049178e-06
Iter: 1761 loss: 2.68971326e-06
Iter: 1762 loss: 2.68837744e-06
Iter: 1763 loss: 2.68847225e-06
Iter: 1764 loss: 2.68699978e-06
Iter: 1765 loss: 2.68851772e-06
Iter: 1766 loss: 2.6861826e-06
Iter: 1767 loss: 2.68483336e-06
Iter: 1768 loss: 2.69211546e-06
Iter: 1769 loss: 2.68460894e-06
Iter: 1770 loss: 2.68342342e-06
Iter: 1771 loss: 2.68594454e-06
Iter: 1772 loss: 2.68294571e-06
Iter: 1773 loss: 2.68133317e-06
Iter: 1774 loss: 2.6842531e-06
Iter: 1775 loss: 2.68073745e-06
Iter: 1776 loss: 2.67944347e-06
Iter: 1777 loss: 2.68738768e-06
Iter: 1778 loss: 2.6792211e-06
Iter: 1779 loss: 2.67809537e-06
Iter: 1780 loss: 2.68472513e-06
Iter: 1781 loss: 2.67796213e-06
Iter: 1782 loss: 2.67687642e-06
Iter: 1783 loss: 2.67780752e-06
Iter: 1784 loss: 2.67629775e-06
Iter: 1785 loss: 2.67505538e-06
Iter: 1786 loss: 2.67471182e-06
Iter: 1787 loss: 2.6738885e-06
Iter: 1788 loss: 2.67327505e-06
Iter: 1789 loss: 2.67323912e-06
Iter: 1790 loss: 2.67239284e-06
Iter: 1791 loss: 2.67533301e-06
Iter: 1792 loss: 2.67213704e-06
Iter: 1793 loss: 2.67149335e-06
Iter: 1794 loss: 2.67020414e-06
Iter: 1795 loss: 2.70130067e-06
Iter: 1796 loss: 2.67022961e-06
Iter: 1797 loss: 2.66902043e-06
Iter: 1798 loss: 2.67017049e-06
Iter: 1799 loss: 2.66850611e-06
Iter: 1800 loss: 2.66679626e-06
Iter: 1801 loss: 2.66771804e-06
Iter: 1802 loss: 2.66576035e-06
Iter: 1803 loss: 2.6642731e-06
Iter: 1804 loss: 2.67468431e-06
Iter: 1805 loss: 2.66417874e-06
Iter: 1806 loss: 2.66263669e-06
Iter: 1807 loss: 2.66457641e-06
Iter: 1808 loss: 2.66197321e-06
Iter: 1809 loss: 2.6602595e-06
Iter: 1810 loss: 2.66510574e-06
Iter: 1811 loss: 2.65983977e-06
Iter: 1812 loss: 2.65848212e-06
Iter: 1813 loss: 2.6705452e-06
Iter: 1814 loss: 2.65819858e-06
Iter: 1815 loss: 2.65717335e-06
Iter: 1816 loss: 2.66140478e-06
Iter: 1817 loss: 2.65693552e-06
Iter: 1818 loss: 2.65575363e-06
Iter: 1819 loss: 2.65442054e-06
Iter: 1820 loss: 2.65424114e-06
Iter: 1821 loss: 2.6531327e-06
Iter: 1822 loss: 2.66973666e-06
Iter: 1823 loss: 2.65310837e-06
Iter: 1824 loss: 2.65230142e-06
Iter: 1825 loss: 2.65231984e-06
Iter: 1826 loss: 2.65166136e-06
Iter: 1827 loss: 2.65055e-06
Iter: 1828 loss: 2.67364476e-06
Iter: 1829 loss: 2.65044832e-06
Iter: 1830 loss: 2.64915184e-06
Iter: 1831 loss: 2.65101744e-06
Iter: 1832 loss: 2.64864229e-06
Iter: 1833 loss: 2.64739811e-06
Iter: 1834 loss: 2.64858932e-06
Iter: 1835 loss: 2.64640039e-06
Iter: 1836 loss: 2.64508071e-06
Iter: 1837 loss: 2.646859e-06
Iter: 1838 loss: 2.64437585e-06
Iter: 1839 loss: 2.64276423e-06
Iter: 1840 loss: 2.65434596e-06
Iter: 1841 loss: 2.64248e-06
Iter: 1842 loss: 2.64124901e-06
Iter: 1843 loss: 2.64400182e-06
Iter: 1844 loss: 2.64083974e-06
Iter: 1845 loss: 2.63940024e-06
Iter: 1846 loss: 2.64197979e-06
Iter: 1847 loss: 2.63886295e-06
Iter: 1848 loss: 2.63746483e-06
Iter: 1849 loss: 2.65474591e-06
Iter: 1850 loss: 2.63753691e-06
Iter: 1851 loss: 2.63659604e-06
Iter: 1852 loss: 2.63589e-06
Iter: 1853 loss: 2.63551192e-06
Iter: 1854 loss: 2.63405491e-06
Iter: 1855 loss: 2.63616312e-06
Iter: 1856 loss: 2.63340303e-06
Iter: 1857 loss: 2.63310449e-06
Iter: 1858 loss: 2.63237871e-06
Iter: 1859 loss: 2.63182733e-06
Iter: 1860 loss: 2.63055745e-06
Iter: 1861 loss: 2.63053971e-06
Iter: 1862 loss: 2.62943513e-06
Iter: 1863 loss: 2.63045331e-06
Iter: 1864 loss: 2.62880849e-06
Iter: 1865 loss: 2.62732647e-06
Iter: 1866 loss: 2.62836511e-06
Iter: 1867 loss: 2.62650224e-06
Iter: 1868 loss: 2.62475965e-06
Iter: 1869 loss: 2.62803383e-06
Iter: 1870 loss: 2.62404092e-06
Iter: 1871 loss: 2.62248614e-06
Iter: 1872 loss: 2.62473077e-06
Iter: 1873 loss: 2.62160256e-06
Iter: 1874 loss: 2.6200546e-06
Iter: 1875 loss: 2.63493939e-06
Iter: 1876 loss: 2.62004619e-06
Iter: 1877 loss: 2.61851551e-06
Iter: 1878 loss: 2.61925152e-06
Iter: 1879 loss: 2.61775131e-06
Iter: 1880 loss: 2.61657169e-06
Iter: 1881 loss: 2.63491256e-06
Iter: 1882 loss: 2.61651849e-06
Iter: 1883 loss: 2.61559899e-06
Iter: 1884 loss: 2.61627724e-06
Iter: 1885 loss: 2.61490345e-06
Iter: 1886 loss: 2.6136222e-06
Iter: 1887 loss: 2.61628179e-06
Iter: 1888 loss: 2.61321838e-06
Iter: 1889 loss: 2.61275045e-06
Iter: 1890 loss: 2.61266382e-06
Iter: 1891 loss: 2.61192645e-06
Iter: 1892 loss: 2.61174364e-06
Iter: 1893 loss: 2.61126638e-06
Iter: 1894 loss: 2.61031437e-06
Iter: 1895 loss: 2.60944284e-06
Iter: 1896 loss: 2.60929073e-06
Iter: 1897 loss: 2.60819888e-06
Iter: 1898 loss: 2.61327341e-06
Iter: 1899 loss: 2.60787124e-06
Iter: 1900 loss: 2.60674233e-06
Iter: 1901 loss: 2.6065336e-06
Iter: 1902 loss: 2.60567322e-06
Iter: 1903 loss: 2.60416709e-06
Iter: 1904 loss: 2.61148853e-06
Iter: 1905 loss: 2.60397883e-06
Iter: 1906 loss: 2.60267234e-06
Iter: 1907 loss: 2.60504476e-06
Iter: 1908 loss: 2.60209208e-06
Iter: 1909 loss: 2.6005614e-06
Iter: 1910 loss: 2.60237653e-06
Iter: 1911 loss: 2.59962098e-06
Iter: 1912 loss: 2.5979798e-06
Iter: 1913 loss: 2.61358082e-06
Iter: 1914 loss: 2.59795161e-06
Iter: 1915 loss: 2.5968543e-06
Iter: 1916 loss: 2.60362822e-06
Iter: 1917 loss: 2.59674675e-06
Iter: 1918 loss: 2.59573289e-06
Iter: 1919 loss: 2.59639478e-06
Iter: 1920 loss: 2.59518038e-06
Iter: 1921 loss: 2.59410126e-06
Iter: 1922 loss: 2.59566013e-06
Iter: 1923 loss: 2.59365788e-06
Iter: 1924 loss: 2.5931688e-06
Iter: 1925 loss: 2.59290937e-06
Iter: 1926 loss: 2.5924403e-06
Iter: 1927 loss: 2.59126728e-06
Iter: 1928 loss: 2.60054321e-06
Iter: 1929 loss: 2.59109811e-06
Iter: 1930 loss: 2.58991167e-06
Iter: 1931 loss: 2.59291255e-06
Iter: 1932 loss: 2.58960199e-06
Iter: 1933 loss: 2.5880986e-06
Iter: 1934 loss: 2.58974751e-06
Iter: 1935 loss: 2.58731893e-06
Iter: 1936 loss: 2.58614318e-06
Iter: 1937 loss: 2.59006902e-06
Iter: 1938 loss: 2.58564842e-06
Iter: 1939 loss: 2.58438581e-06
Iter: 1940 loss: 2.58498585e-06
Iter: 1941 loss: 2.58337877e-06
Iter: 1942 loss: 2.58198179e-06
Iter: 1943 loss: 2.59279636e-06
Iter: 1944 loss: 2.5817842e-06
Iter: 1945 loss: 2.58043929e-06
Iter: 1946 loss: 2.58069304e-06
Iter: 1947 loss: 2.57962665e-06
Iter: 1948 loss: 2.57845568e-06
Iter: 1949 loss: 2.57848819e-06
Iter: 1950 loss: 2.57767238e-06
Iter: 1951 loss: 2.58036584e-06
Iter: 1952 loss: 2.57738e-06
Iter: 1953 loss: 2.57650026e-06
Iter: 1954 loss: 2.57617285e-06
Iter: 1955 loss: 2.57559736e-06
Iter: 1956 loss: 2.57509146e-06
Iter: 1957 loss: 2.57497709e-06
Iter: 1958 loss: 2.57417241e-06
Iter: 1959 loss: 2.5732686e-06
Iter: 1960 loss: 2.57303918e-06
Iter: 1961 loss: 2.57228953e-06
Iter: 1962 loss: 2.57282613e-06
Iter: 1963 loss: 2.57178635e-06
Iter: 1964 loss: 2.5707061e-06
Iter: 1965 loss: 2.57084e-06
Iter: 1966 loss: 2.56994758e-06
Iter: 1967 loss: 2.56844578e-06
Iter: 1968 loss: 2.57832244e-06
Iter: 1969 loss: 2.56835415e-06
Iter: 1970 loss: 2.56728026e-06
Iter: 1971 loss: 2.56656358e-06
Iter: 1972 loss: 2.56628505e-06
Iter: 1973 loss: 2.56493513e-06
Iter: 1974 loss: 2.57619195e-06
Iter: 1975 loss: 2.56478938e-06
Iter: 1976 loss: 2.56358362e-06
Iter: 1977 loss: 2.56339172e-06
Iter: 1978 loss: 2.56268891e-06
Iter: 1979 loss: 2.56153135e-06
Iter: 1980 loss: 2.57384704e-06
Iter: 1981 loss: 2.56141766e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.4 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.4
+ date
Sun Nov  8 04:15:07 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2/300_100_100_100_1 --function f1 --psi 1 --phi 2.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.4/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080b42400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080b53400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080b53598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080aab158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080ac27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0809cb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080a22bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080a339d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080983488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080969950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080983bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0808e4e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0808e4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe08088cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080909400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe080939d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe08090b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe08090b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe05d328840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe05d328268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe05d3e0598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe05d34bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe05d2eda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe05d2d7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe05d2e68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe038351378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe038377730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0383949d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe038394620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe038317510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0382c3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0381faa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0381fa1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe03820cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe0382449d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe038260f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 1.9954939
test_loss: 1.9782236
train_loss: 1.9822589
test_loss: 1.9779379
train_loss: 1.9939191
test_loss: 1.9829103
train_loss: 1.9162261
test_loss: 1.9756572
train_loss: 1.988133
test_loss: 1.9764235
train_loss: 1.9938955
test_loss: 1.9832025
train_loss: 1.9765121
test_loss: 1.9774568
train_loss: 1.9969424
test_loss: 1.9831691
train_loss: 1.9742854
test_loss: 1.9760095
train_loss: 1.9382498
test_loss: 1.9793591
train_loss: 1.9713404
test_loss: 1.9733831
train_loss: 1.9734738
test_loss: 1.9666826
train_loss: 1.9733183
test_loss: 1.9822557
train_loss: 1.9870353
test_loss: 1.9826323
train_loss: 1.9934981
test_loss: 1.9876516
train_loss: 1.9835355
test_loss: 1.9834912
train_loss: 1.9976948
test_loss: 1.989704
train_loss: 1.971327
test_loss: 1.9864575
train_loss: 1.9606779
test_loss: 2.0050628
train_loss: 1.0196003
test_loss: 1.0244846
train_loss: 1.012057
test_loss: 1.021337
train_loss: 1.0192555
test_loss: 1.0208675
train_loss: 0.97275376
test_loss: 1.0208292
train_loss: 0.94974184
test_loss: 1.020561
train_loss: 1.049869
test_loss: 1.0203999
train_loss: 0.97406197
test_loss: 1.0202595
train_loss: 1.0028963
test_loss: 1.019763
train_loss: 1.016893
test_loss: 1.0195674
train_loss: 0.993443
test_loss: 1.0192924
train_loss: 1.0060475
test_loss: 1.0188979
train_loss: 1.0119009
test_loss: 1.0189656
train_loss: 0.9909023
test_loss: 1.0181668
train_loss: 1.002968
test_loss: 1.0177845
train_loss: 0.988708
test_loss: 1.0176117
train_loss: 0.94725215
test_loss: 1.0169574
train_loss: 0.984635
test_loss: 1.0164376
train_loss: 0.99199563
test_loss: 1.0163021
train_loss: 0.96490186
test_loss: 1.0158545
train_loss: 1.0106465
test_loss: 1.015321
train_loss: 0.9588795
test_loss: 1.0146266
train_loss: 0.9832741
test_loss: 1.0139524
train_loss: 1.0398502
test_loss: 1.0134058
train_loss: 0.99139774
test_loss: 1.0125903
train_loss: 1.0260224
test_loss: 1.0123115
train_loss: 1.0356476
test_loss: 1.0113732
train_loss: 0.989953
test_loss: 1.0106919
train_loss: 1.0095047
test_loss: 1.0100112
train_loss: 0.99032354
test_loss: 1.0094471
train_loss: 0.9674622
test_loss: 1.0083557
train_loss: 0.97267944
test_loss: 1.0077406
train_loss: 0.99635476
test_loss: 1.0065697
train_loss: 0.98768234
test_loss: 1.0057912
train_loss: 1.0015608
test_loss: 1.0049556
train_loss: 0.9457813
test_loss: 1.0037444
train_loss: 0.9938741
test_loss: 1.0028559
train_loss: 0.9958269
test_loss: 1.0019816
train_loss: 0.98246646
test_loss: 1.0003315
train_loss: 0.9883499
test_loss: 0.99900305
train_loss: 0.9580235
test_loss: 0.99837273
train_loss: 0.9939316
test_loss: 0.9967248
train_loss: 0.98280406
test_loss: 0.99508274
train_loss: 0.9612495
test_loss: 0.99360347
train_loss: 1.0166608
test_loss: 0.99178034
train_loss: 0.9729728
test_loss: 0.9900391
train_loss: 1.0281751
test_loss: 0.98869526
train_loss: 0.9560847
test_loss: 0.9869086
train_loss: 0.941715
test_loss: 0.98489827
train_loss: 0.9562228
test_loss: 0.9831594
train_loss: 0.9631466
test_loss: 0.98112524
train_loss: 0.94011754
test_loss: 0.978822
train_loss: 1.0215931
test_loss: 0.97628164
train_loss: 0.9538193
test_loss: 0.9740662
train_loss: 0.9525619
test_loss: 0.97138596
train_loss: 0.9437358
test_loss: 0.9685994
train_loss: 0.9611286
test_loss: 0.965424
train_loss: 0.9708013
test_loss: 0.96138066
train_loss: 0.9384112
test_loss: 0.95623595
train_loss: 0.94220847
test_loss: 0.9482435
train_loss: 0.92510784
test_loss: 0.93730456
train_loss: 0.9176985
test_loss: 0.92358166
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.4/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 2.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.4/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c9bb400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c9e9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c9e9a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c8fe0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c92f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c92fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c874bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c81c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c81c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c7cbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c8377b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c7b7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c7b7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c76bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c7189d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c730a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c730d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c6e4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c6a8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c34b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b9c6a8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c309f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c309840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c2e5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c2e5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c287598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c2469d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c270620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c2702f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c2709d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c1c79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c21f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c17d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c1b57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c15ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b7c113598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.47155643
Iter: 2 loss: 0.497637331
Iter: 3 loss: 10571.5
Iter: 4 loss: 976.006
Iter: 5 loss: 1.47146082
Iter: 6 loss: 0.707740605
Iter: 7 loss: 0.309327781
Iter: 8 loss: 9283.94531
Iter: 9 loss: 0.309324324
Iter: 10 loss: 0.150205016
Iter: 11 loss: 0.150203496
Iter: 12 loss: 2356695.5
Iter: 13 loss: 413.173401
Iter: 14 loss: 0.127054691
Iter: 15 loss: 0.121268891
Iter: 16 loss: 0.12632
Iter: 17 loss: 0.0859358162
Iter: 18 loss: 2045.84094
Iter: 19 loss: 213.2146
Iter: 20 loss: 0.126317278
Iter: 21 loss: 537.683777
Iter: 22 loss: 0.0843612403
Iter: 23 loss: 0.160460815
Iter: 24 loss: 0.0843171626
Iter: 25 loss: 0.233639076
Iter: 26 loss: 0.0840512365
Iter: 27 loss: 2.97585177
Iter: 28 loss: 740.121948
Iter: 29 loss: 0.0840514153
Iter: 30 loss: 0.173642263
Iter: 31 loss: 0.0840288252
Iter: 32 loss: 0.0838218778
Iter: 33 loss: 0.083594583
Iter: 34 loss: 0.0829715133
Iter: 35 loss: 0.0829514489
Iter: 36 loss: 0.0835862458
Iter: 37 loss: 0.0823003799
Iter: 38 loss: 0.124361709
Iter: 39 loss: 0.0821684375
Iter: 40 loss: 0.0816347823
Iter: 41 loss: 0.0805355459
Iter: 42 loss: 0.0806380585
Iter: 43 loss: 0.0796023756
Iter: 44 loss: 0.0779531375
Iter: 45 loss: 0.0803089291
Iter: 46 loss: 0.0769339
Iter: 47 loss: 0.0753624365
Iter: 48 loss: 0.080523178
Iter: 49 loss: 0.0750117898
Iter: 50 loss: 0.0745943636
Iter: 51 loss: 0.0745502338
Iter: 52 loss: 0.074231185
Iter: 53 loss: 0.0768277273
Iter: 54 loss: 0.0742197
Iter: 55 loss: 0.074055858
Iter: 56 loss: 0.0735919327
Iter: 57 loss: 0.0753105134
Iter: 58 loss: 0.0733854473
Iter: 59 loss: 0.0725748
Iter: 60 loss: 0.0702996626
Iter: 61 loss: 0.0835344866
Iter: 62 loss: 0.0694270134
Iter: 63 loss: 0.0638129935
Iter: 64 loss: 0.0565999076
Iter: 65 loss: 0.0560270399
Iter: 66 loss: 0.0464233905
Iter: 67 loss: 0.0463213474
Iter: 68 loss: 0.103081793
Iter: 69 loss: 0.0461703315
Iter: 70 loss: 0.0399324372
Iter: 71 loss: 0.079099156
Iter: 72 loss: 0.0389105454
Iter: 73 loss: 0.0344188176
Iter: 74 loss: 0.034417849
Iter: 75 loss: 0.0343485251
Iter: 76 loss: 0.032810308
Iter: 77 loss: 0.340812534
Iter: 78 loss: 0.0368465222
Iter: 79 loss: 0.0304720905
Iter: 80 loss: 0.0273879915
Iter: 81 loss: 0.0419170335
Iter: 82 loss: 0.0271441415
Iter: 83 loss: 0.0252513289
Iter: 84 loss: 0.0360387713
Iter: 85 loss: 0.0249116272
Iter: 86 loss: 0.0235450082
Iter: 87 loss: 0.0293051917
Iter: 88 loss: 0.0232484136
Iter: 89 loss: 0.0209398456
Iter: 90 loss: 6048.48535
Iter: 91 loss: 0.0546981171
Iter: 92 loss: 0.0230240934
Iter: 93 loss: 0.0209546704
Iter: 94 loss: 0.0208524186
Iter: 95 loss: 0.0206876956
Iter: 96 loss: 0.0199725162
Iter: 97 loss: 0.0266428906
Iter: 98 loss: 0.0199619401
Iter: 99 loss: 0.0190120507
Iter: 100 loss: 0.0193875376
Iter: 101 loss: 0.0183858536
Iter: 102 loss: 0.0173569843
Iter: 103 loss: 0.0217045266
Iter: 104 loss: 0.017103564
Iter: 105 loss: 0.0160401724
Iter: 106 loss: 0.0227849223
Iter: 107 loss: 0.01600012
Iter: 108 loss: 0.015468251
Iter: 109 loss: 0.0173948631
Iter: 110 loss: 0.0153575009
Iter: 111 loss: 0.0149613526
Iter: 112 loss: 0.0177383404
Iter: 113 loss: 0.0149249174
Iter: 114 loss: 0.0144008808
Iter: 115 loss: 0.0158846807
Iter: 116 loss: 0.0142328832
Iter: 117 loss: 0.0137651898
Iter: 118 loss: 0.0146159939
Iter: 119 loss: 0.0135683408
Iter: 120 loss: 0.0130698439
Iter: 121 loss: 0.0141265225
Iter: 122 loss: 0.012869399
Iter: 123 loss: 0.0124097168
Iter: 124 loss: 0.0142343491
Iter: 125 loss: 0.0123088704
Iter: 126 loss: 0.0120669752
Iter: 127 loss: 0.0128732491
Iter: 128 loss: 0.0119955912
Iter: 129 loss: 0.0118156867
Iter: 130 loss: 0.0123179983
Iter: 131 loss: 0.011764125
Iter: 132 loss: 0.0115881078
Iter: 133 loss: 0.0129123349
Iter: 134 loss: 0.0115680816
Iter: 135 loss: 0.0114688659
Iter: 136 loss: 0.0116997007
Iter: 137 loss: 0.0114315171
Iter: 138 loss: 0.0112786777
Iter: 139 loss: 0.0116733592
Iter: 140 loss: 0.0112225162
Iter: 141 loss: 0.0110601969
Iter: 142 loss: 0.0110738538
Iter: 143 loss: 0.0109384079
Iter: 144 loss: 0.010742153
Iter: 145 loss: 0.0122469878
Iter: 146 loss: 0.0107266083
Iter: 147 loss: 0.0105045056
Iter: 148 loss: 0.0116981873
Iter: 149 loss: 0.0104638161
Iter: 150 loss: 0.0102768242
Iter: 151 loss: 0.0111594433
Iter: 152 loss: 0.0102476664
Iter: 153 loss: 0.0101110972
Iter: 154 loss: 0.0109004332
Iter: 155 loss: 0.0100840684
Iter: 156 loss: 0.00995686464
Iter: 157 loss: 0.010939993
Iter: 158 loss: 0.00994742569
Iter: 159 loss: 0.00979654584
Iter: 160 loss: 0.0101883402
Iter: 161 loss: 0.00973575749
Iter: 162 loss: 0.00957712531
Iter: 163 loss: 0.00957864057
Iter: 164 loss: 0.00945541542
Iter: 165 loss: 0.009292854
Iter: 166 loss: 0.0102454945
Iter: 167 loss: 0.00925634149
Iter: 168 loss: 0.00911447499
Iter: 169 loss: 0.0108322389
Iter: 170 loss: 0.0091121383
Iter: 171 loss: 0.00895139668
Iter: 172 loss: 0.00922225
Iter: 173 loss: 0.00886053126
Iter: 174 loss: 0.00869065151
Iter: 175 loss: 0.00980088674
Iter: 176 loss: 0.00867693312
Iter: 177 loss: 0.00858053192
Iter: 178 loss: 0.00921197701
Iter: 179 loss: 0.00856563635
Iter: 180 loss: 0.00845486112
Iter: 181 loss: 0.00865782704
Iter: 182 loss: 0.00840549823
Iter: 183 loss: 0.00828409381
Iter: 184 loss: 0.00911474787
Iter: 185 loss: 0.00827209465
Iter: 186 loss: 0.00819894485
Iter: 187 loss: 0.00819886
Iter: 188 loss: 0.00813365541
Iter: 189 loss: 0.0081493957
Iter: 190 loss: 0.00808732491
Iter: 191 loss: 0.00797555
Iter: 192 loss: 0.00824456476
Iter: 193 loss: 0.00792725
Iter: 194 loss: 0.00782240648
Iter: 195 loss: 0.00816794671
Iter: 196 loss: 0.00779292732
Iter: 197 loss: 0.00768377678
Iter: 198 loss: 0.00930193812
Iter: 199 loss: 0.00768333906
Iter: 200 loss: 0.00759410486
Iter: 201 loss: 0.00810574554
Iter: 202 loss: 0.00758359674
Iter: 203 loss: 0.00751289912
Iter: 204 loss: 0.0078519294
Iter: 205 loss: 0.00749516767
Iter: 206 loss: 0.00742579764
Iter: 207 loss: 0.00821653567
Iter: 208 loss: 0.00742443698
Iter: 209 loss: 0.00735855
Iter: 210 loss: 0.00748429354
Iter: 211 loss: 0.00732608419
Iter: 212 loss: 0.00721494621
Iter: 213 loss: 0.00774863595
Iter: 214 loss: 0.00719135813
Iter: 215 loss: 0.00709844194
Iter: 216 loss: 0.00709846383
Iter: 217 loss: 0.00703133456
Iter: 218 loss: 0.00714507606
Iter: 219 loss: 0.00699764397
Iter: 220 loss: 0.00692017423
Iter: 221 loss: 0.00702479715
Iter: 222 loss: 0.00687962491
Iter: 223 loss: 0.00679278467
Iter: 224 loss: 0.00754785631
Iter: 225 loss: 0.00678838789
Iter: 226 loss: 0.00670708343
Iter: 227 loss: 0.00690166326
Iter: 228 loss: 0.0066779796
Iter: 229 loss: 0.0066118408
Iter: 230 loss: 0.00841384847
Iter: 231 loss: 0.00661186362
Iter: 232 loss: 0.00654398231
Iter: 233 loss: 0.00670449389
Iter: 234 loss: 0.00652101729
Iter: 235 loss: 0.00644728635
Iter: 236 loss: 0.00749872811
Iter: 237 loss: 0.00644680951
Iter: 238 loss: 0.00639182795
Iter: 239 loss: 0.00647870917
Iter: 240 loss: 0.00636671437
Iter: 241 loss: 0.00629584771
Iter: 242 loss: 0.00642134342
Iter: 243 loss: 0.00626643607
Iter: 244 loss: 0.00619808119
Iter: 245 loss: 0.00639295205
Iter: 246 loss: 0.00617676228
Iter: 247 loss: 0.00610566419
Iter: 248 loss: 0.00749435183
Iter: 249 loss: 0.00610437151
Iter: 250 loss: 0.00603534095
Iter: 251 loss: 0.00659938436
Iter: 252 loss: 0.00603085663
Iter: 253 loss: 0.00597571209
Iter: 254 loss: 0.00622546626
Iter: 255 loss: 0.00596232526
Iter: 256 loss: 0.00589530496
Iter: 257 loss: 0.00654354412
Iter: 258 loss: 0.00589286815
Iter: 259 loss: 0.00583832432
Iter: 260 loss: 0.00601457059
Iter: 261 loss: 0.00582318753
Iter: 262 loss: 0.00575925782
Iter: 263 loss: 0.00592006464
Iter: 264 loss: 0.00573326414
Iter: 265 loss: 0.00568054058
Iter: 266 loss: 0.00610257918
Iter: 267 loss: 0.00567837525
Iter: 268 loss: 0.00562131312
Iter: 269 loss: 0.00660609035
Iter: 270 loss: 0.00562077388
Iter: 271 loss: 0.00557390321
Iter: 272 loss: 0.00569245871
Iter: 273 loss: 0.0055551175
Iter: 274 loss: 0.00550133316
Iter: 275 loss: 0.00569557073
Iter: 276 loss: 0.00548548158
Iter: 277 loss: 0.00542213349
Iter: 278 loss: 0.0058106957
Iter: 279 loss: 0.00541161606
Iter: 280 loss: 0.00535839144
Iter: 281 loss: 0.005421401
Iter: 282 loss: 0.0053297542
Iter: 283 loss: 0.00527483318
Iter: 284 loss: 0.0052724
Iter: 285 loss: 0.005250955
Iter: 286 loss: 0.00522482302
Iter: 287 loss: 0.00517957471
Iter: 288 loss: 0.00545294862
Iter: 289 loss: 0.00517301913
Iter: 290 loss: 0.00514194
Iter: 291 loss: 0.00517975353
Iter: 292 loss: 0.00512596127
Iter: 293 loss: 0.00508592557
Iter: 294 loss: 0.00524077239
Iter: 295 loss: 0.00507667614
Iter: 296 loss: 0.00503745861
Iter: 297 loss: 0.00509971846
Iter: 298 loss: 0.00501891784
Iter: 299 loss: 0.00497022644
Iter: 300 loss: 0.00507665612
Iter: 301 loss: 0.00495037297
Iter: 302 loss: 0.0049083177
Iter: 303 loss: 0.00512647629
Iter: 304 loss: 0.00490251277
Iter: 305 loss: 0.00486825127
Iter: 306 loss: 0.00516207
Iter: 307 loss: 0.00486536697
Iter: 308 loss: 0.00483776163
Iter: 309 loss: 0.0048329886
Iter: 310 loss: 0.00481416471
Iter: 311 loss: 0.00476231612
Iter: 312 loss: 0.00492861774
Iter: 313 loss: 0.00474557839
Iter: 314 loss: 0.00469593797
Iter: 315 loss: 0.00493744528
Iter: 316 loss: 0.00468907785
Iter: 317 loss: 0.00464381464
Iter: 318 loss: 0.00492945779
Iter: 319 loss: 0.004635741
Iter: 320 loss: 0.00459591299
Iter: 321 loss: 0.00468286173
Iter: 322 loss: 0.00457961764
Iter: 323 loss: 0.00452772155
Iter: 324 loss: 0.00465024682
Iter: 325 loss: 0.00450824201
Iter: 326 loss: 0.00446369313
Iter: 327 loss: 0.00446341746
Iter: 328 loss: 0.00443612691
Iter: 329 loss: 0.00470203254
Iter: 330 loss: 0.00443465542
Iter: 331 loss: 0.00440626731
Iter: 332 loss: 0.00449218275
Iter: 333 loss: 0.00439953
Iter: 334 loss: 0.00436952
Iter: 335 loss: 0.0043690009
Iter: 336 loss: 0.00433991
Iter: 337 loss: 0.00440488802
Iter: 338 loss: 0.00432886183
Iter: 339 loss: 0.00429609884
Iter: 340 loss: 0.00434470689
Iter: 341 loss: 0.00428122375
Iter: 342 loss: 0.0042510014
Iter: 343 loss: 0.00437692553
Iter: 344 loss: 0.00424406771
Iter: 345 loss: 0.0042138705
Iter: 346 loss: 0.00433937507
Iter: 347 loss: 0.00420710957
Iter: 348 loss: 0.00417421758
Iter: 349 loss: 0.00419202261
Iter: 350 loss: 0.00415251264
Iter: 351 loss: 0.00410602707
Iter: 352 loss: 0.00437677838
Iter: 353 loss: 0.00409884565
Iter: 354 loss: 0.00406695716
Iter: 355 loss: 0.0041163126
Iter: 356 loss: 0.00405250397
Iter: 357 loss: 0.00402395567
Iter: 358 loss: 0.00419242494
Iter: 359 loss: 0.0040187547
Iter: 360 loss: 0.00398962758
Iter: 361 loss: 0.00430308562
Iter: 362 loss: 0.00398920104
Iter: 363 loss: 0.0039565214
Iter: 364 loss: 0.00399775244
Iter: 365 loss: 0.00393727049
Iter: 366 loss: 0.00386894518
Iter: 367 loss: 0.00408271747
Iter: 368 loss: 0.00384901254
Iter: 369 loss: 0.00380252674
Iter: 370 loss: 0.00414416194
Iter: 371 loss: 0.00379946106
Iter: 372 loss: 0.00376922451
Iter: 373 loss: 0.00397357251
Iter: 374 loss: 0.00376572437
Iter: 375 loss: 0.00374891562
Iter: 376 loss: 0.00382228545
Iter: 377 loss: 0.00374554354
Iter: 378 loss: 0.00371359847
Iter: 379 loss: 0.00381926261
Iter: 380 loss: 0.00370270386
Iter: 381 loss: 0.00367446453
Iter: 382 loss: 0.00375469727
Iter: 383 loss: 0.00366556481
Iter: 384 loss: 0.00364038232
Iter: 385 loss: 0.00364033459
Iter: 386 loss: 0.00361887598
Iter: 387 loss: 0.00369250611
Iter: 388 loss: 0.00361333205
Iter: 389 loss: 0.00359221199
Iter: 390 loss: 0.00356602343
Iter: 391 loss: 0.00356366253
Iter: 392 loss: 0.0035217409
Iter: 393 loss: 0.00378416525
Iter: 394 loss: 0.00351624773
Iter: 395 loss: 0.00349275442
Iter: 396 loss: 0.00381935388
Iter: 397 loss: 0.00349272345
Iter: 398 loss: 0.00347718294
Iter: 399 loss: 0.00347705046
Iter: 400 loss: 0.0034561085
Iter: 401 loss: 0.0034633344
Iter: 402 loss: 0.00344173145
Iter: 403 loss: 0.00341990264
Iter: 404 loss: 0.00345879118
Iter: 405 loss: 0.00340962177
Iter: 406 loss: 0.00339104026
Iter: 407 loss: 0.00340521708
Iter: 408 loss: 0.00337993097
Iter: 409 loss: 0.00335042248
Iter: 410 loss: 0.00337992539
Iter: 411 loss: 0.00333049102
Iter: 412 loss: 0.00330599
Iter: 413 loss: 0.00330321491
Iter: 414 loss: 0.00327747874
Iter: 415 loss: 0.00334244082
Iter: 416 loss: 0.00326794921
Iter: 417 loss: 0.00324903987
Iter: 418 loss: 0.00324752368
Iter: 419 loss: 0.00322655169
Iter: 420 loss: 0.00334364013
Iter: 421 loss: 0.00322396401
Iter: 422 loss: 0.0032024174
Iter: 423 loss: 0.00344010582
Iter: 424 loss: 0.0032017692
Iter: 425 loss: 0.00317913108
Iter: 426 loss: 0.00320816319
Iter: 427 loss: 0.00316731818
Iter: 428 loss: 0.00315879285
Iter: 429 loss: 0.00315555045
Iter: 430 loss: 0.00314839
Iter: 431 loss: 0.00317680417
Iter: 432 loss: 0.00314658135
Iter: 433 loss: 0.00313370791
Iter: 434 loss: 0.00313619012
Iter: 435 loss: 0.0031240941
Iter: 436 loss: 0.00310521573
Iter: 437 loss: 0.00325065572
Iter: 438 loss: 0.00310400594
Iter: 439 loss: 0.00309061352
Iter: 440 loss: 0.00314094871
Iter: 441 loss: 0.00308743399
Iter: 442 loss: 0.0030734418
Iter: 443 loss: 0.00305276457
Iter: 444 loss: 0.00305220322
Iter: 445 loss: 0.00303269317
Iter: 446 loss: 0.00314059807
Iter: 447 loss: 0.00302864565
Iter: 448 loss: 0.0030158665
Iter: 449 loss: 0.00301546161
Iter: 450 loss: 0.0030054457
Iter: 451 loss: 0.00299291988
Iter: 452 loss: 0.00316328974
Iter: 453 loss: 0.00299287355
Iter: 454 loss: 0.00298462762
Iter: 455 loss: 0.00298584881
Iter: 456 loss: 0.00297843292
Iter: 457 loss: 0.00295608514
Iter: 458 loss: 0.00303342403
Iter: 459 loss: 0.00294913212
Iter: 460 loss: 0.00293400837
Iter: 461 loss: 0.00293295877
Iter: 462 loss: 0.00292495708
Iter: 463 loss: 0.00292530609
Iter: 464 loss: 0.00291850045
Iter: 465 loss: 0.00290924986
Iter: 466 loss: 0.00291124638
Iter: 467 loss: 0.00290230894
Iter: 468 loss: 0.00289064832
Iter: 469 loss: 0.00292842695
Iter: 470 loss: 0.00288753654
Iter: 471 loss: 0.00287284097
Iter: 472 loss: 0.00292074634
Iter: 473 loss: 0.00286848145
Iter: 474 loss: 0.00285746437
Iter: 475 loss: 0.00289096823
Iter: 476 loss: 0.00285376469
Iter: 477 loss: 0.00284089963
Iter: 478 loss: 0.00288742
Iter: 479 loss: 0.00283729844
Iter: 480 loss: 0.00282431138
Iter: 481 loss: 0.00288398238
Iter: 482 loss: 0.00282146223
Iter: 483 loss: 0.00281138439
Iter: 484 loss: 0.00284717279
Iter: 485 loss: 0.00280897948
Iter: 486 loss: 0.00279672584
Iter: 487 loss: 0.00287104072
Iter: 488 loss: 0.002795259
Iter: 489 loss: 0.00278308685
Iter: 490 loss: 0.00279548299
Iter: 491 loss: 0.00277552288
Iter: 492 loss: 0.00275911414
Iter: 493 loss: 0.00276101124
Iter: 494 loss: 0.00274642371
Iter: 495 loss: 0.00273374654
Iter: 496 loss: 0.0029115146
Iter: 497 loss: 0.00273359404
Iter: 498 loss: 0.00271892478
Iter: 499 loss: 0.0028205181
Iter: 500 loss: 0.00271733897
Iter: 501 loss: 0.00271068932
Iter: 502 loss: 0.0027260948
Iter: 503 loss: 0.002708229
Iter: 504 loss: 0.00269827247
Iter: 505 loss: 0.00269874
Iter: 506 loss: 0.00269018975
Iter: 507 loss: 0.00267531886
Iter: 508 loss: 0.00268520135
Iter: 509 loss: 0.00266613672
Iter: 510 loss: 0.00265021971
Iter: 511 loss: 0.00265014591
Iter: 512 loss: 0.00263933605
Iter: 513 loss: 0.0027194568
Iter: 514 loss: 0.00263801357
Iter: 515 loss: 0.00262803771
Iter: 516 loss: 0.00263653416
Iter: 517 loss: 0.00262221438
Iter: 518 loss: 0.00261098286
Iter: 519 loss: 0.00261074258
Iter: 520 loss: 0.00259967335
Iter: 521 loss: 0.00264398637
Iter: 522 loss: 0.00259684585
Iter: 523 loss: 0.00258899201
Iter: 524 loss: 0.00260055461
Iter: 525 loss: 0.00258518802
Iter: 526 loss: 0.00257472275
Iter: 527 loss: 0.00265989965
Iter: 528 loss: 0.00257341168
Iter: 529 loss: 0.00256535504
Iter: 530 loss: 0.00259873434
Iter: 531 loss: 0.00256381673
Iter: 532 loss: 0.0025514327
Iter: 533 loss: 0.00264223525
Iter: 534 loss: 0.00254989369
Iter: 535 loss: 0.00253869197
Iter: 536 loss: 0.00259719673
Iter: 537 loss: 0.00253683981
Iter: 538 loss: 0.00252893
Iter: 539 loss: 0.0025288933
Iter: 540 loss: 0.00252210209
Iter: 541 loss: 0.00251821103
Iter: 542 loss: 0.00251540937
Iter: 543 loss: 0.00250596576
Iter: 544 loss: 0.00252579479
Iter: 545 loss: 0.00250119762
Iter: 546 loss: 0.00248805387
Iter: 547 loss: 0.002601285
Iter: 548 loss: 0.00248741
Iter: 549 loss: 0.00247443421
Iter: 550 loss: 0.00260884641
Iter: 551 loss: 0.00247321092
Iter: 552 loss: 0.0024631531
Iter: 553 loss: 0.00251468434
Iter: 554 loss: 0.00246157707
Iter: 555 loss: 0.00245246803
Iter: 556 loss: 0.00245248154
Iter: 557 loss: 0.00244563492
Iter: 558 loss: 0.00246183015
Iter: 559 loss: 0.00244305935
Iter: 560 loss: 0.00243905047
Iter: 561 loss: 0.00245132647
Iter: 562 loss: 0.0024378153
Iter: 563 loss: 0.00243023247
Iter: 564 loss: 0.00246997736
Iter: 565 loss: 0.00242822524
Iter: 566 loss: 0.00241894461
Iter: 567 loss: 0.0024177935
Iter: 568 loss: 0.00240993709
Iter: 569 loss: 0.00253870082
Iter: 570 loss: 0.00240993709
Iter: 571 loss: 0.00240418152
Iter: 572 loss: 0.00240630563
Iter: 573 loss: 0.00240005786
Iter: 574 loss: 0.00239077024
Iter: 575 loss: 0.00245530717
Iter: 576 loss: 0.0023898629
Iter: 577 loss: 0.00238533877
Iter: 578 loss: 0.00240042387
Iter: 579 loss: 0.00238413876
Iter: 580 loss: 0.00237865839
Iter: 581 loss: 0.00236972701
Iter: 582 loss: 0.00236961711
Iter: 583 loss: 0.0023621479
Iter: 584 loss: 0.00240966422
Iter: 585 loss: 0.00236143218
Iter: 586 loss: 0.00235505705
Iter: 587 loss: 0.00235003163
Iter: 588 loss: 0.00234797085
Iter: 589 loss: 0.0023390362
Iter: 590 loss: 0.00250340113
Iter: 591 loss: 0.00233889185
Iter: 592 loss: 0.00233341753
Iter: 593 loss: 0.0023979086
Iter: 594 loss: 0.00233337283
Iter: 595 loss: 0.00232863193
Iter: 596 loss: 0.00232891412
Iter: 597 loss: 0.00232493342
Iter: 598 loss: 0.0023195853
Iter: 599 loss: 0.00231348118
Iter: 600 loss: 0.0023127771
Iter: 601 loss: 0.00230683479
Iter: 602 loss: 0.0023951875
Iter: 603 loss: 0.00230683
Iter: 604 loss: 0.00230172602
Iter: 605 loss: 0.0023198938
Iter: 606 loss: 0.00230040727
Iter: 607 loss: 0.00229777722
Iter: 608 loss: 0.0023002415
Iter: 609 loss: 0.00229618698
Iter: 610 loss: 0.00229112059
Iter: 611 loss: 0.00230433326
Iter: 612 loss: 0.00228944537
Iter: 613 loss: 0.00228152238
Iter: 614 loss: 0.00229638652
Iter: 615 loss: 0.00227801572
Iter: 616 loss: 0.00227025547
Iter: 617 loss: 0.00230781664
Iter: 618 loss: 0.00226898817
Iter: 619 loss: 0.00226603169
Iter: 620 loss: 0.00226560747
Iter: 621 loss: 0.0022621362
Iter: 622 loss: 0.00226680166
Iter: 623 loss: 0.0022602377
Iter: 624 loss: 0.00225597573
Iter: 625 loss: 0.0022530728
Iter: 626 loss: 0.00225137733
Iter: 627 loss: 0.00224487064
Iter: 628 loss: 0.00224823
Iter: 629 loss: 0.00224068924
Iter: 630 loss: 0.00223405054
Iter: 631 loss: 0.00233175652
Iter: 632 loss: 0.00223392737
Iter: 633 loss: 0.00222814642
Iter: 634 loss: 0.00223029498
Iter: 635 loss: 0.00222410634
Iter: 636 loss: 0.00221803342
Iter: 637 loss: 0.00222548516
Iter: 638 loss: 0.0022147526
Iter: 639 loss: 0.00220856559
Iter: 640 loss: 0.00223857583
Iter: 641 loss: 0.00220762473
Iter: 642 loss: 0.00220269291
Iter: 643 loss: 0.00225730147
Iter: 644 loss: 0.00220261
Iter: 645 loss: 0.00219845097
Iter: 646 loss: 0.00220626476
Iter: 647 loss: 0.0021965187
Iter: 648 loss: 0.00219133543
Iter: 649 loss: 0.00220505125
Iter: 650 loss: 0.00218960294
Iter: 651 loss: 0.00218721805
Iter: 652 loss: 0.00219068513
Iter: 653 loss: 0.00218605949
Iter: 654 loss: 0.00218277
Iter: 655 loss: 0.00218128832
Iter: 656 loss: 0.0021796464
Iter: 657 loss: 0.00217934279
Iter: 658 loss: 0.00217624311
Iter: 659 loss: 0.00217202865
Iter: 660 loss: 0.00216810312
Iter: 661 loss: 0.0021670647
Iter: 662 loss: 0.00216035824
Iter: 663 loss: 0.00223119184
Iter: 664 loss: 0.00216013985
Iter: 665 loss: 0.00215609185
Iter: 666 loss: 0.00218286645
Iter: 667 loss: 0.00215563853
Iter: 668 loss: 0.00215189019
Iter: 669 loss: 0.00215082569
Iter: 670 loss: 0.00214856444
Iter: 671 loss: 0.00214188569
Iter: 672 loss: 0.00217923545
Iter: 673 loss: 0.00214094971
Iter: 674 loss: 0.00213712873
Iter: 675 loss: 0.00215805508
Iter: 676 loss: 0.00213682465
Iter: 677 loss: 0.00213155593
Iter: 678 loss: 0.00214807875
Iter: 679 loss: 0.00212995312
Iter: 680 loss: 0.0021270772
Iter: 681 loss: 0.00214129779
Iter: 682 loss: 0.00212655
Iter: 683 loss: 0.00212414842
Iter: 684 loss: 0.00212144037
Iter: 685 loss: 0.00212109485
Iter: 686 loss: 0.00211644638
Iter: 687 loss: 0.00212357566
Iter: 688 loss: 0.00211433787
Iter: 689 loss: 0.00211086776
Iter: 690 loss: 0.0021275233
Iter: 691 loss: 0.00211025728
Iter: 692 loss: 0.00210745889
Iter: 693 loss: 0.0021051988
Iter: 694 loss: 0.00210435409
Iter: 695 loss: 0.00209994405
Iter: 696 loss: 0.00211437186
Iter: 697 loss: 0.00209847256
Iter: 698 loss: 0.00209507952
Iter: 699 loss: 0.00210811268
Iter: 700 loss: 0.00209424179
Iter: 701 loss: 0.0020894187
Iter: 702 loss: 0.00209765788
Iter: 703 loss: 0.00208722637
Iter: 704 loss: 0.00208423706
Iter: 705 loss: 0.0020931263
Iter: 706 loss: 0.00208328641
Iter: 707 loss: 0.00208017393
Iter: 708 loss: 0.00212673564
Iter: 709 loss: 0.00208016508
Iter: 710 loss: 0.00207769917
Iter: 711 loss: 0.00208093179
Iter: 712 loss: 0.00207645423
Iter: 713 loss: 0.00207397481
Iter: 714 loss: 0.00206891075
Iter: 715 loss: 0.00216231379
Iter: 716 loss: 0.00206883228
Iter: 717 loss: 0.00206474913
Iter: 718 loss: 0.00207657111
Iter: 719 loss: 0.00206345902
Iter: 720 loss: 0.00206095376
Iter: 721 loss: 0.00209038099
Iter: 722 loss: 0.0020608881
Iter: 723 loss: 0.00205819588
Iter: 724 loss: 0.00205713278
Iter: 725 loss: 0.0020556706
Iter: 726 loss: 0.00205222704
Iter: 727 loss: 0.00205178373
Iter: 728 loss: 0.00204927102
Iter: 729 loss: 0.00204336387
Iter: 730 loss: 0.00209265249
Iter: 731 loss: 0.00204299204
Iter: 732 loss: 0.00203675637
Iter: 733 loss: 0.00204834761
Iter: 734 loss: 0.00203402899
Iter: 735 loss: 0.00203035492
Iter: 736 loss: 0.00204076339
Iter: 737 loss: 0.00202912441
Iter: 738 loss: 0.00202522427
Iter: 739 loss: 0.00204133918
Iter: 740 loss: 0.00202392414
Iter: 741 loss: 0.00202065893
Iter: 742 loss: 0.00203084946
Iter: 743 loss: 0.00201958767
Iter: 744 loss: 0.00201727869
Iter: 745 loss: 0.00201678742
Iter: 746 loss: 0.00201251148
Iter: 747 loss: 0.00201854436
Iter: 748 loss: 0.00201041903
Iter: 749 loss: 0.00200497033
Iter: 750 loss: 0.0020149902
Iter: 751 loss: 0.00200238451
Iter: 752 loss: 0.00199831114
Iter: 753 loss: 0.00203037122
Iter: 754 loss: 0.0019980208
Iter: 755 loss: 0.00199482124
Iter: 756 loss: 0.0020178745
Iter: 757 loss: 0.00199441914
Iter: 758 loss: 0.00199184241
Iter: 759 loss: 0.00199223217
Iter: 760 loss: 0.00198985706
Iter: 761 loss: 0.00198481837
Iter: 762 loss: 0.00201999187
Iter: 763 loss: 0.00198444678
Iter: 764 loss: 0.00197990402
Iter: 765 loss: 0.00204841513
Iter: 766 loss: 0.0019798344
Iter: 767 loss: 0.00197853544
Iter: 768 loss: 0.00197764626
Iter: 769 loss: 0.00197612541
Iter: 770 loss: 0.00197418197
Iter: 771 loss: 0.00197403575
Iter: 772 loss: 0.00197072211
Iter: 773 loss: 0.00196776516
Iter: 774 loss: 0.0019668038
Iter: 775 loss: 0.00196364149
Iter: 776 loss: 0.00196301937
Iter: 777 loss: 0.00196066685
Iter: 778 loss: 0.00200331025
Iter: 779 loss: 0.00196066638
Iter: 780 loss: 0.00195859023
Iter: 781 loss: 0.00196060818
Iter: 782 loss: 0.00195745681
Iter: 783 loss: 0.00195348938
Iter: 784 loss: 0.00196633022
Iter: 785 loss: 0.00195232313
Iter: 786 loss: 0.00194910064
Iter: 787 loss: 0.00194909
Iter: 788 loss: 0.00194753869
Iter: 789 loss: 0.00194631179
Iter: 790 loss: 0.00194579782
Iter: 791 loss: 0.00194144482
Iter: 792 loss: 0.00195711455
Iter: 793 loss: 0.0019401639
Iter: 794 loss: 0.00193754153
Iter: 795 loss: 0.00194017123
Iter: 796 loss: 0.00193607842
Iter: 797 loss: 0.00193313032
Iter: 798 loss: 0.00194608956
Iter: 799 loss: 0.00193251576
Iter: 800 loss: 0.00192955951
Iter: 801 loss: 0.0019515442
Iter: 802 loss: 0.00192929816
Iter: 803 loss: 0.0019282056
Iter: 804 loss: 0.00192655507
Iter: 805 loss: 0.00192649348
Iter: 806 loss: 0.0019237888
Iter: 807 loss: 0.0019611246
Iter: 808 loss: 0.00192378892
Iter: 809 loss: 0.00192130345
Iter: 810 loss: 0.00192453875
Iter: 811 loss: 0.00192002219
Iter: 812 loss: 0.00191738969
Iter: 813 loss: 0.00191771844
Iter: 814 loss: 0.00191538024
Iter: 815 loss: 0.0019123794
Iter: 816 loss: 0.00191221514
Iter: 817 loss: 0.00190963352
Iter: 818 loss: 0.00191158534
Iter: 819 loss: 0.00190796936
Iter: 820 loss: 0.00190559973
Iter: 821 loss: 0.00193387899
Iter: 822 loss: 0.00190559309
Iter: 823 loss: 0.0019036564
Iter: 824 loss: 0.00190344185
Iter: 825 loss: 0.00190203125
Iter: 826 loss: 0.00189979537
Iter: 827 loss: 0.00190025906
Iter: 828 loss: 0.00189805194
Iter: 829 loss: 0.00189698301
Iter: 830 loss: 0.00189671956
Iter: 831 loss: 0.00189535704
Iter: 832 loss: 0.00190362695
Iter: 833 loss: 0.00189517299
Iter: 834 loss: 0.00189391559
Iter: 835 loss: 0.00189318287
Iter: 836 loss: 0.0018926952
Iter: 837 loss: 0.00188989961
Iter: 838 loss: 0.00190086849
Iter: 839 loss: 0.00188916177
Iter: 840 loss: 0.00188737782
Iter: 841 loss: 0.00188631227
Iter: 842 loss: 0.00188555941
Iter: 843 loss: 0.00188290654
Iter: 844 loss: 0.00188932987
Iter: 845 loss: 0.00188181712
Iter: 846 loss: 0.00188055425
Iter: 847 loss: 0.00188063795
Iter: 848 loss: 0.00187954213
Iter: 849 loss: 0.00187679019
Iter: 850 loss: 0.00189543911
Iter: 851 loss: 0.00187651522
Iter: 852 loss: 0.00187472743
Iter: 853 loss: 0.00188028766
Iter: 854 loss: 0.0018742634
Iter: 855 loss: 0.00187264173
Iter: 856 loss: 0.0018730365
Iter: 857 loss: 0.00187140564
Iter: 858 loss: 0.00186904974
Iter: 859 loss: 0.00187637261
Iter: 860 loss: 0.00186835951
Iter: 861 loss: 0.00186625391
Iter: 862 loss: 0.00186988513
Iter: 863 loss: 0.00186528091
Iter: 864 loss: 0.00186355109
Iter: 865 loss: 0.00187465595
Iter: 866 loss: 0.0018633469
Iter: 867 loss: 0.00186237949
Iter: 868 loss: 0.00186173758
Iter: 869 loss: 0.00186140416
Iter: 870 loss: 0.00185969053
Iter: 871 loss: 0.00186826312
Iter: 872 loss: 0.00185933267
Iter: 873 loss: 0.00185856817
Iter: 874 loss: 0.00185809017
Iter: 875 loss: 0.00185674021
Iter: 876 loss: 0.00185366883
Iter: 877 loss: 0.00189544878
Iter: 878 loss: 0.00185347837
Iter: 879 loss: 0.00185188209
Iter: 880 loss: 0.00186103617
Iter: 881 loss: 0.00185163051
Iter: 882 loss: 0.00185071304
Iter: 883 loss: 0.001848227
Iter: 884 loss: 0.00186449
Iter: 885 loss: 0.00184763793
Iter: 886 loss: 0.00184805086
Iter: 887 loss: 0.00184615608
Iter: 888 loss: 0.00184307201
Iter: 889 loss: 0.00187031063
Iter: 890 loss: 0.00184276048
Iter: 891 loss: 0.00184148364
Iter: 892 loss: 0.00184332801
Iter: 893 loss: 0.00184085686
Iter: 894 loss: 0.00183833367
Iter: 895 loss: 0.00184273976
Iter: 896 loss: 0.00183708523
Iter: 897 loss: 0.0018432762
Iter: 898 loss: 0.00183602981
Iter: 899 loss: 0.00183495623
Iter: 900 loss: 0.00183817418
Iter: 901 loss: 0.00183462177
Iter: 902 loss: 0.00183283712
Iter: 903 loss: 0.00183428626
Iter: 904 loss: 0.00183168496
Iter: 905 loss: 0.0018286889
Iter: 906 loss: 0.00185236381
Iter: 907 loss: 0.00182850705
Iter: 908 loss: 0.00182617945
Iter: 909 loss: 0.00182616815
Iter: 910 loss: 0.00182563951
Iter: 911 loss: 0.00182498549
Iter: 912 loss: 0.00182434707
Iter: 913 loss: 0.00182594312
Iter: 914 loss: 0.00182412425
Iter: 915 loss: 0.00182366488
Iter: 916 loss: 0.00182311749
Iter: 917 loss: 0.00182305416
Iter: 918 loss: 0.00182125787
Iter: 919 loss: 0.00183723914
Iter: 920 loss: 0.00182122597
Iter: 921 loss: 0.00181925728
Iter: 922 loss: 0.00182570086
Iter: 923 loss: 0.00181873876
Iter: 924 loss: 0.00181754876
Iter: 925 loss: 0.00182056986
Iter: 926 loss: 0.0018170994
Iter: 927 loss: 0.00181522628
Iter: 928 loss: 0.0018130776
Iter: 929 loss: 0.00181280635
Iter: 930 loss: 0.00181113963
Iter: 931 loss: 0.00181109121
Iter: 932 loss: 0.00180993648
Iter: 933 loss: 0.00181473733
Iter: 934 loss: 0.00180969294
Iter: 935 loss: 0.00180810504
Iter: 936 loss: 0.00180560246
Iter: 937 loss: 0.00180557347
Iter: 938 loss: 0.00180324749
Iter: 939 loss: 0.00180324109
Iter: 940 loss: 0.00180071942
Iter: 941 loss: 0.00181463163
Iter: 942 loss: 0.00180029951
Iter: 943 loss: 0.00179896387
Iter: 944 loss: 0.00182093284
Iter: 945 loss: 0.00179897365
Iter: 946 loss: 0.00179843465
Iter: 947 loss: 0.00179805304
Iter: 948 loss: 0.00179786747
Iter: 949 loss: 0.00179643417
Iter: 950 loss: 0.00179678248
Iter: 951 loss: 0.00179535535
Iter: 952 loss: 0.00179418596
Iter: 953 loss: 0.00181160122
Iter: 954 loss: 0.0017941962
Iter: 955 loss: 0.00179257849
Iter: 956 loss: 0.00180213351
Iter: 957 loss: 0.00179235
Iter: 958 loss: 0.00179041445
Iter: 959 loss: 0.00178744015
Iter: 960 loss: 0.00178739429
Iter: 961 loss: 0.00178499869
Iter: 962 loss: 0.00179487164
Iter: 963 loss: 0.00178437447
Iter: 964 loss: 0.00178229564
Iter: 965 loss: 0.00177956512
Iter: 966 loss: 0.00177940191
Iter: 967 loss: 0.00178139564
Iter: 968 loss: 0.00177767524
Iter: 969 loss: 0.00177725276
Iter: 970 loss: 0.00177678792
Iter: 971 loss: 0.00177617604
Iter: 972 loss: 0.0017802245
Iter: 973 loss: 0.00177612621
Iter: 974 loss: 0.00177519908
Iter: 975 loss: 0.00177326333
Iter: 976 loss: 0.00180500385
Iter: 977 loss: 0.00177321141
Iter: 978 loss: 0.00177255622
Iter: 979 loss: 0.00177197927
Iter: 980 loss: 0.00177092478
Iter: 981 loss: 0.00177298603
Iter: 982 loss: 0.00177052733
Iter: 983 loss: 0.00176940439
Iter: 984 loss: 0.00177004165
Iter: 985 loss: 0.00176863256
Iter: 986 loss: 0.00176742009
Iter: 987 loss: 0.0017694165
Iter: 988 loss: 0.00176687096
Iter: 989 loss: 0.0017657727
Iter: 990 loss: 0.00177256833
Iter: 991 loss: 0.00176566129
Iter: 992 loss: 0.00176488142
Iter: 993 loss: 0.00176298781
Iter: 994 loss: 0.00178028783
Iter: 995 loss: 0.00176272402
Iter: 996 loss: 0.0017599985
Iter: 997 loss: 0.0017685435
Iter: 998 loss: 0.00175919186
Iter: 999 loss: 0.00175827357
Iter: 1000 loss: 0.00175637123
Iter: 1001 loss: 0.00178842014
Iter: 1002 loss: 0.00175632723
Iter: 1003 loss: 0.00175486528
Iter: 1004 loss: 0.00175472558
Iter: 1005 loss: 0.00175323547
Iter: 1006 loss: 0.00177580887
Iter: 1007 loss: 0.00175321277
Iter: 1008 loss: 0.0017523265
Iter: 1009 loss: 0.00176491449
Iter: 1010 loss: 0.00175231975
Iter: 1011 loss: 0.00175172696
Iter: 1012 loss: 0.00175562745
Iter: 1013 loss: 0.00175167178
Iter: 1014 loss: 0.00175102567
Iter: 1015 loss: 0.00175141124
Iter: 1016 loss: 0.00175058749
Iter: 1017 loss: 0.00175005686
Iter: 1018 loss: 0.0017495309
Iter: 1019 loss: 0.00174940284
Iter: 1020 loss: 0.00174846698
Iter: 1021 loss: 0.00175246317
Iter: 1022 loss: 0.0017482664
Iter: 1023 loss: 0.00174774905
Iter: 1024 loss: 0.0017472856
Iter: 1025 loss: 0.00174714508
Iter: 1026 loss: 0.00174587138
Iter: 1027 loss: 0.00174812204
Iter: 1028 loss: 0.0017453318
Iter: 1029 loss: 0.00174392189
Iter: 1030 loss: 0.0017429078
Iter: 1031 loss: 0.00174242957
Iter: 1032 loss: 0.00173941685
Iter: 1033 loss: 0.0017523882
Iter: 1034 loss: 0.00173863512
Iter: 1035 loss: 0.00173692661
Iter: 1036 loss: 0.0017403427
Iter: 1037 loss: 0.00173624081
Iter: 1038 loss: 0.00173439551
Iter: 1039 loss: 0.00173639692
Iter: 1040 loss: 0.00173332985
Iter: 1041 loss: 0.00173267536
Iter: 1042 loss: 0.00173458178
Iter: 1043 loss: 0.00173248863
Iter: 1044 loss: 0.00173187954
Iter: 1045 loss: 0.00173051143
Iter: 1046 loss: 0.00174875604
Iter: 1047 loss: 0.00173042342
Iter: 1048 loss: 0.00172786193
Iter: 1049 loss: 0.00176458247
Iter: 1050 loss: 0.00172782945
Iter: 1051 loss: 0.00172694866
Iter: 1052 loss: 0.00173494918
Iter: 1053 loss: 0.00172691199
Iter: 1054 loss: 0.00172662991
Iter: 1055 loss: 0.00172646926
Iter: 1056 loss: 0.00172634074
Iter: 1057 loss: 0.00172586
Iter: 1058 loss: 0.00172735972
Iter: 1059 loss: 0.00172569067
Iter: 1060 loss: 0.00172469369
Iter: 1061 loss: 0.00172679382
Iter: 1062 loss: 0.0017243023
Iter: 1063 loss: 0.00172287668
Iter: 1064 loss: 0.00173389225
Iter: 1065 loss: 0.00172275421
Iter: 1066 loss: 0.0017217783
Iter: 1067 loss: 0.0017222095
Iter: 1068 loss: 0.00172111019
Iter: 1069 loss: 0.00171975978
Iter: 1070 loss: 0.00171758572
Iter: 1071 loss: 0.00171756349
Iter: 1072 loss: 0.00171456626
Iter: 1073 loss: 0.00172329647
Iter: 1074 loss: 0.00171356648
Iter: 1075 loss: 0.00171237497
Iter: 1076 loss: 0.00172422244
Iter: 1077 loss: 0.00171233574
Iter: 1078 loss: 0.00171205541
Iter: 1079 loss: 0.00171208428
Iter: 1080 loss: 0.00171183213
Iter: 1081 loss: 0.00171146728
Iter: 1082 loss: 0.00171122956
Iter: 1083 loss: 0.00171108358
Iter: 1084 loss: 0.00171244168
Iter: 1085 loss: 0.00171086681
Iter: 1086 loss: 0.00171036285
Iter: 1087 loss: 0.00171089778
Iter: 1088 loss: 0.00171010301
Iter: 1089 loss: 0.00170976529
Iter: 1090 loss: 0.00170948356
Iter: 1091 loss: 0.00170903711
Iter: 1092 loss: 0.00170857413
Iter: 1093 loss: 0.00170849159
Iter: 1094 loss: 0.00170718227
Iter: 1095 loss: 0.00171112409
Iter: 1096 loss: 0.00170676957
Iter: 1097 loss: 0.00170580763
Iter: 1098 loss: 0.00170906889
Iter: 1099 loss: 0.00170554034
Iter: 1100 loss: 0.0017050124
Iter: 1101 loss: 0.00170394185
Iter: 1102 loss: 0.00172278436
Iter: 1103 loss: 0.00170390832
Iter: 1104 loss: 0.00170322601
Iter: 1105 loss: 0.0017045415
Iter: 1106 loss: 0.00170292368
Iter: 1107 loss: 0.00170274917
Iter: 1108 loss: 0.00170260668
Iter: 1109 loss: 0.0017025558
Iter: 1110 loss: 0.00170170423
Iter: 1111 loss: 0.00171377743
Iter: 1112 loss: 0.00170169701
Iter: 1113 loss: 0.00170046662
Iter: 1114 loss: 0.00170691183
Iter: 1115 loss: 0.00170024973
Iter: 1116 loss: 0.00170008023
Iter: 1117 loss: 0.00170006091
Iter: 1118 loss: 0.00169988861
Iter: 1119 loss: 0.00169931119
Iter: 1120 loss: 0.00169941096
Iter: 1121 loss: 0.00169872842
Iter: 1122 loss: 0.00169770618
Iter: 1123 loss: 0.00169791188
Iter: 1124 loss: 0.00169692235
Iter: 1125 loss: 0.00169630034
Iter: 1126 loss: 0.00169764657
Iter: 1127 loss: 0.00169603387
Iter: 1128 loss: 0.00169577869
Iter: 1129 loss: 0.00169632025
Iter: 1130 loss: 0.00169566181
Iter: 1131 loss: 0.0016953334
Iter: 1132 loss: 0.00169447879
Iter: 1133 loss: 0.00170224067
Iter: 1134 loss: 0.00169436308
Iter: 1135 loss: 0.00169359636
Iter: 1136 loss: 0.00169843831
Iter: 1137 loss: 0.00169351744
Iter: 1138 loss: 0.00169274723
Iter: 1139 loss: 0.00169188459
Iter: 1140 loss: 0.00169175444
Iter: 1141 loss: 0.00168941275
Iter: 1142 loss: 0.00169077585
Iter: 1143 loss: 0.00168784184
Iter: 1144 loss: 0.00168725208
Iter: 1145 loss: 0.00168724591
Iter: 1146 loss: 0.00168697932
Iter: 1147 loss: 0.00168658374
Iter: 1148 loss: 0.00168657699
Iter: 1149 loss: 0.00168620981
Iter: 1150 loss: 0.00168651971
Iter: 1151 loss: 0.00168600143
Iter: 1152 loss: 0.00168575835
Iter: 1153 loss: 0.00168525416
Iter: 1154 loss: 0.00169491116
Iter: 1155 loss: 0.00168524741
Iter: 1156 loss: 0.00168451597
Iter: 1157 loss: 0.00168405124
Iter: 1158 loss: 0.00168375438
Iter: 1159 loss: 0.00168322492
Iter: 1160 loss: 0.0016838701
Iter: 1161 loss: 0.00168294692
Iter: 1162 loss: 0.00168256718
Iter: 1163 loss: 0.00168443355
Iter: 1164 loss: 0.00168250035
Iter: 1165 loss: 0.0016819546
Iter: 1166 loss: 0.00168224273
Iter: 1167 loss: 0.00168160303
Iter: 1168 loss: 0.00168069568
Iter: 1169 loss: 0.00169062731
Iter: 1170 loss: 0.00168066262
Iter: 1171 loss: 0.00167994248
Iter: 1172 loss: 0.00168628874
Iter: 1173 loss: 0.00167992665
Iter: 1174 loss: 0.00167972199
Iter: 1175 loss: 0.00167920068
Iter: 1176 loss: 0.00168520398
Iter: 1177 loss: 0.00167915481
Iter: 1178 loss: 0.00167865993
Iter: 1179 loss: 0.00168089685
Iter: 1180 loss: 0.00167855679
Iter: 1181 loss: 0.00167848193
Iter: 1182 loss: 0.00167851406
Iter: 1183 loss: 0.00167842419
Iter: 1184 loss: 0.00167809974
Iter: 1185 loss: 0.00167722988
Iter: 1186 loss: 0.00168409979
Iter: 1187 loss: 0.00167706911
Iter: 1188 loss: 0.00167685456
Iter: 1189 loss: 0.00167675863
Iter: 1190 loss: 0.00167646445
Iter: 1191 loss: 0.00167741568
Iter: 1192 loss: 0.00167637912
Iter: 1193 loss: 0.0016754315
Iter: 1194 loss: 0.00167753967
Iter: 1195 loss: 0.00167505117
Iter: 1196 loss: 0.00167438842
Iter: 1197 loss: 0.00167437876
Iter: 1198 loss: 0.00167348341
Iter: 1199 loss: 0.00167318713
Iter: 1200 loss: 0.00167266384
Iter: 1201 loss: 0.00167224358
Iter: 1202 loss: 0.00167265756
Iter: 1203 loss: 0.00167198328
Iter: 1204 loss: 0.00167152984
Iter: 1205 loss: 0.0016706693
Iter: 1206 loss: 0.00168916048
Iter: 1207 loss: 0.00167065661
Iter: 1208 loss: 0.00167032448
Iter: 1209 loss: 0.00167193357
Iter: 1210 loss: 0.00167025
Iter: 1211 loss: 0.00167043251
Iter: 1212 loss: 0.00167017616
Iter: 1213 loss: 0.00167004904
Iter: 1214 loss: 0.00167009025
Iter: 1215 loss: 0.00166997639
Iter: 1216 loss: 0.00166978501
Iter: 1217 loss: 0.00167010317
Iter: 1218 loss: 0.00166969758
Iter: 1219 loss: 0.00166948978
Iter: 1220 loss: 0.00167163229
Iter: 1221 loss: 0.00166949118
Iter: 1222 loss: 0.00166909187
Iter: 1223 loss: 0.00166914007
Iter: 1224 loss: 0.0016687914
Iter: 1225 loss: 0.00166857569
Iter: 1226 loss: 0.001668229
Iter: 1227 loss: 0.00166822586
Iter: 1228 loss: 0.00166790443
Iter: 1229 loss: 0.00166817429
Iter: 1230 loss: 0.00166771444
Iter: 1231 loss: 0.0016676751
Iter: 1232 loss: 0.00166766159
Iter: 1233 loss: 0.00166765146
Iter: 1234 loss: 0.00166760711
Iter: 1235 loss: 0.00166750513
Iter: 1236 loss: 0.00166916754
Iter: 1237 loss: 0.00166751735
Iter: 1238 loss: 0.00166725914
Iter: 1239 loss: 0.00166681269
Iter: 1240 loss: 0.00166680617
Iter: 1241 loss: 0.0016667957
Iter: 1242 loss: 0.00166593213
Iter: 1243 loss: 0.00166508893
Iter: 1244 loss: 0.00167358667
Iter: 1245 loss: 0.00166503841
Iter: 1246 loss: 0.00166498765
Iter: 1247 loss: 0.0016648001
Iter: 1248 loss: 0.00166452699
Iter: 1249 loss: 0.00166573643
Iter: 1250 loss: 0.00166447484
Iter: 1251 loss: 0.00166409055
Iter: 1252 loss: 0.00166590954
Iter: 1253 loss: 0.0016640157
Iter: 1254 loss: 0.0016634108
Iter: 1255 loss: 0.00166495109
Iter: 1256 loss: 0.00166320498
Iter: 1257 loss: 0.00166282116
Iter: 1258 loss: 0.00166345702
Iter: 1259 loss: 0.00166264619
Iter: 1260 loss: 0.00166247843
Iter: 1261 loss: 0.00166202709
Iter: 1262 loss: 0.00166524132
Iter: 1263 loss: 0.00166191836
Iter: 1264 loss: 0.00166143826
Iter: 1265 loss: 0.00166451826
Iter: 1266 loss: 0.00166138122
Iter: 1267 loss: 0.0016611123
Iter: 1268 loss: 0.00166156946
Iter: 1269 loss: 0.0016609875
Iter: 1270 loss: 0.00166010449
Iter: 1271 loss: 0.0016639292
Iter: 1272 loss: 0.00165993767
Iter: 1273 loss: 0.00165922928
Iter: 1274 loss: 0.00166424969
Iter: 1275 loss: 0.00165915932
Iter: 1276 loss: 0.00165862474
Iter: 1277 loss: 0.00165929925
Iter: 1278 loss: 0.00165832776
Iter: 1279 loss: 0.00165784452
Iter: 1280 loss: 0.00165862974
Iter: 1281 loss: 0.00165761786
Iter: 1282 loss: 0.00165750261
Iter: 1283 loss: 0.00165890506
Iter: 1284 loss: 0.00165747898
Iter: 1285 loss: 0.0016574224
Iter: 1286 loss: 0.00165728095
Iter: 1287 loss: 0.00165932137
Iter: 1288 loss: 0.00165727187
Iter: 1289 loss: 0.00165715045
Iter: 1290 loss: 0.00165699678
Iter: 1291 loss: 0.00165698514
Iter: 1292 loss: 0.00165672938
Iter: 1293 loss: 0.00165654568
Iter: 1294 loss: 0.00165645138
Iter: 1295 loss: 0.00165803067
Iter: 1296 loss: 0.00165636232
Iter: 1297 loss: 0.0016561778
Iter: 1298 loss: 0.00165590888
Iter: 1299 loss: 0.00165590097
Iter: 1300 loss: 0.00165552099
Iter: 1301 loss: 0.00165549049
Iter: 1302 loss: 0.00165519956
Iter: 1303 loss: 0.00165488571
Iter: 1304 loss: 0.00165436568
Iter: 1305 loss: 0.00165434612
Iter: 1306 loss: 0.00165413215
Iter: 1307 loss: 0.00165377033
Iter: 1308 loss: 0.00165376719
Iter: 1309 loss: 0.00165343122
Iter: 1310 loss: 0.00165350328
Iter: 1311 loss: 0.00165318581
Iter: 1312 loss: 0.00165271235
Iter: 1313 loss: 0.00165217207
Iter: 1314 loss: 0.0016521113
Iter: 1315 loss: 0.00165920821
Iter: 1316 loss: 0.00165130524
Iter: 1317 loss: 0.00165104261
Iter: 1318 loss: 0.00165130722
Iter: 1319 loss: 0.00165090663
Iter: 1320 loss: 0.00166125293
Iter: 1321 loss: 0.00165050547
Iter: 1322 loss: 0.00165009918
Iter: 1323 loss: 0.00165080535
Iter: 1324 loss: 0.00164990826
Iter: 1325 loss: 0.0016496625
Iter: 1326 loss: 0.00165241957
Iter: 1327 loss: 0.00164965913
Iter: 1328 loss: 0.00164894678
Iter: 1329 loss: 0.0016520319
Iter: 1330 loss: 0.00164880173
Iter: 1331 loss: 0.00164805818
Iter: 1332 loss: 0.00165165134
Iter: 1333 loss: 0.00164793991
Iter: 1334 loss: 0.00166184909
Iter: 1335 loss: 0.00164726912
Iter: 1336 loss: 0.00164740626
Iter: 1337 loss: 0.0016469874
Iter: 1338 loss: 0.00164680509
Iter: 1339 loss: 0.0016477477
Iter: 1340 loss: 0.00164679205
Iter: 1341 loss: 0.00164669927
Iter: 1342 loss: 0.00164644909
Iter: 1343 loss: 0.00164806
Iter: 1344 loss: 0.00164639065
Iter: 1345 loss: 0.00164554163
Iter: 1346 loss: 0.00164538063
Iter: 1347 loss: 0.00164448295
Iter: 1348 loss: 0.00164640835
Iter: 1349 loss: 0.00164409
Iter: 1350 loss: 0.00164395059
Iter: 1351 loss: 0.00164393429
Iter: 1352 loss: 0.00164377154
Iter: 1353 loss: 0.0016435791
Iter: 1354 loss: 0.00164356816
Iter: 1355 loss: 0.00164348225
Iter: 1356 loss: 0.00164209108
Iter: 1357 loss: 0.00164174871
Iter: 1358 loss: 0.00164145301
Iter: 1359 loss: 0.00164092425
Iter: 1360 loss: 0.00164224068
Iter: 1361 loss: 0.00164075568
Iter: 1362 loss: 0.0016405629
Iter: 1363 loss: 0.00164117839
Iter: 1364 loss: 0.00164050714
Iter: 1365 loss: 0.00164043496
Iter: 1366 loss: 0.00164089561
Iter: 1367 loss: 0.00164043438
Iter: 1368 loss: 0.00164029677
Iter: 1369 loss: 0.00163984892
Iter: 1370 loss: 0.00164092099
Iter: 1371 loss: 0.00163959013
Iter: 1372 loss: 0.00164054148
Iter: 1373 loss: 0.00163907022
Iter: 1374 loss: 0.00163830328
Iter: 1375 loss: 0.00163852447
Iter: 1376 loss: 0.00163774821
Iter: 1377 loss: 0.00163630163
Iter: 1378 loss: 0.00163668091
Iter: 1379 loss: 0.00163526915
Iter: 1380 loss: 0.00177228265
Iter: 1381 loss: 0.00163516845
Iter: 1382 loss: 0.0016351128
Iter: 1383 loss: 0.00163524307
Iter: 1384 loss: 0.00163509883
Iter: 1385 loss: 0.00163498323
Iter: 1386 loss: 0.00163456262
Iter: 1387 loss: 0.00163363502
Iter: 1388 loss: 0.00163364166
Iter: 1389 loss: 0.00163198402
Iter: 1390 loss: 0.00163174677
Iter: 1391 loss: 0.00163128483
Iter: 1392 loss: 0.00163899094
Iter: 1393 loss: 0.00163128099
Iter: 1394 loss: 0.00163119868
Iter: 1395 loss: 0.00163137016
Iter: 1396 loss: 0.00163117796
Iter: 1397 loss: 0.00163104129
Iter: 1398 loss: 0.00163079938
Iter: 1399 loss: 0.00163709978
Iter: 1400 loss: 0.00163079379
Iter: 1401 loss: 0.00163042312
Iter: 1402 loss: 0.00162980356
Iter: 1403 loss: 0.00162980589
Iter: 1404 loss: 0.00162945746
Iter: 1405 loss: 0.00162946281
Iter: 1406 loss: 0.00162888994
Iter: 1407 loss: 0.00162823196
Iter: 1408 loss: 0.00162815058
Iter: 1409 loss: 0.0016273564
Iter: 1410 loss: 0.00162871508
Iter: 1411 loss: 0.00162703404
Iter: 1412 loss: 0.00162673905
Iter: 1413 loss: 0.00162607746
Iter: 1414 loss: 0.00163480709
Iter: 1415 loss: 0.00162603194
Iter: 1416 loss: 0.00162508176
Iter: 1417 loss: 0.00162518187
Iter: 1418 loss: 0.00162437989
Iter: 1419 loss: 0.00162421155
Iter: 1420 loss: 0.00162439747
Iter: 1421 loss: 0.00162412925
Iter: 1422 loss: 0.00162366591
Iter: 1423 loss: 0.00162800343
Iter: 1424 loss: 0.00162364868
Iter: 1425 loss: 0.00162412017
Iter: 1426 loss: 0.00162347872
Iter: 1427 loss: 0.00162333227
Iter: 1428 loss: 0.00162306
Iter: 1429 loss: 0.00162895932
Iter: 1430 loss: 0.00162305962
Iter: 1431 loss: 0.00162270991
Iter: 1432 loss: 0.00162225147
Iter: 1433 loss: 0.0016222155
Iter: 1434 loss: 0.00162140711
Iter: 1435 loss: 0.00162241107
Iter: 1436 loss: 0.00162099162
Iter: 1437 loss: 0.00162042375
Iter: 1438 loss: 0.00162003818
Iter: 1439 loss: 0.00161983247
Iter: 1440 loss: 0.00161928881
Iter: 1441 loss: 0.0016210787
Iter: 1442 loss: 0.0016191412
Iter: 1443 loss: 0.0016191242
Iter: 1444 loss: 0.00161896355
Iter: 1445 loss: 0.0016191575
Iter: 1446 loss: 0.00161892804
Iter: 1447 loss: 0.00161892339
Iter: 1448 loss: 0.00161891815
Iter: 1449 loss: 0.00161891372
Iter: 1450 loss: 0.00161886355
Iter: 1451 loss: 0.00161877705
Iter: 1452 loss: 0.00161882956
Iter: 1453 loss: 0.00161868683
Iter: 1454 loss: 0.00161880325
Iter: 1455 loss: 0.00161830336
Iter: 1456 loss: 0.00161803316
Iter: 1457 loss: 0.00161762594
Iter: 1458 loss: 0.00161760161
Iter: 1459 loss: 0.00161854411
Iter: 1460 loss: 0.00161614339
Iter: 1461 loss: 0.0016258047
Iter: 1462 loss: 0.00161517039
Iter: 1463 loss: 0.00161398354
Iter: 1464 loss: 0.00161578879
Iter: 1465 loss: 0.00161344092
Iter: 1466 loss: 0.0016130372
Iter: 1467 loss: 0.00161307864
Iter: 1468 loss: 0.00161273801
Iter: 1469 loss: 0.00161234813
Iter: 1470 loss: 0.00161165209
Iter: 1471 loss: 0.0016296606
Iter: 1472 loss: 0.00161165
Iter: 1473 loss: 0.00161141134
Iter: 1474 loss: 0.00161188119
Iter: 1475 loss: 0.00161129772
Iter: 1476 loss: 0.00161135395
Iter: 1477 loss: 0.00161105639
Iter: 1478 loss: 0.0016108047
Iter: 1479 loss: 0.00161247922
Iter: 1480 loss: 0.00161077734
Iter: 1481 loss: 0.00161052053
Iter: 1482 loss: 0.00160982925
Iter: 1483 loss: 0.00161407189
Iter: 1484 loss: 0.00160963042
Iter: 1485 loss: 0.00161277503
Iter: 1486 loss: 0.0016094218
Iter: 1487 loss: 0.00160862238
Iter: 1488 loss: 0.00160998129
Iter: 1489 loss: 0.00160828221
Iter: 1490 loss: 0.00160808116
Iter: 1491 loss: 0.00160757231
Iter: 1492 loss: 0.0016099877
Iter: 1493 loss: 0.00160737941
Iter: 1494 loss: 0.00160682853
Iter: 1495 loss: 0.00160637463
Iter: 1496 loss: 0.00160509453
Iter: 1497 loss: 0.00161212427
Iter: 1498 loss: 0.00160492142
Iter: 1499 loss: 0.00160896638
Iter: 1500 loss: 0.00160487578
Iter: 1501 loss: 0.00160482572
Iter: 1502 loss: 0.00160529127
Iter: 1503 loss: 0.00160483306
Iter: 1504 loss: 0.00160478195
Iter: 1505 loss: 0.00160480733
Iter: 1506 loss: 0.00160477043
Iter: 1507 loss: 0.00160486926
Iter: 1508 loss: 0.00160445704
Iter: 1509 loss: 0.00160340616
Iter: 1510 loss: 0.00161008351
Iter: 1511 loss: 0.00160328811
Iter: 1512 loss: 0.00160271325
Iter: 1513 loss: 0.00160422991
Iter: 1514 loss: 0.00160253141
Iter: 1515 loss: 0.00160250149
Iter: 1516 loss: 0.00160237518
Iter: 1517 loss: 0.0016021186
Iter: 1518 loss: 0.00160203094
Iter: 1519 loss: 0.00160188
Iter: 1520 loss: 0.00160153885
Iter: 1521 loss: 0.00160113187
Iter: 1522 loss: 0.00160107319
Iter: 1523 loss: 0.00160004199
Iter: 1524 loss: 0.0015996251
Iter: 1525 loss: 0.00159906596
Iter: 1526 loss: 0.00159889227
Iter: 1527 loss: 0.00160093768
Iter: 1528 loss: 0.00159888668
Iter: 1529 loss: 0.0015988627
Iter: 1530 loss: 0.00159894861
Iter: 1531 loss: 0.0015988698
Iter: 1532 loss: 0.00159929856
Iter: 1533 loss: 0.00159880368
Iter: 1534 loss: 0.00159845268
Iter: 1535 loss: 0.00159725884
Iter: 1536 loss: 0.00159607409
Iter: 1537 loss: 0.00159558281
Iter: 1538 loss: 0.00159506523
Iter: 1539 loss: 0.00159501727
Iter: 1540 loss: 0.00159464183
Iter: 1541 loss: 0.00159524311
Iter: 1542 loss: 0.00159447198
Iter: 1543 loss: 0.00159436371
Iter: 1544 loss: 0.00159470609
Iter: 1545 loss: 0.00159434834
Iter: 1546 loss: 0.00159430713
Iter: 1547 loss: 0.00159425626
Iter: 1548 loss: 0.00159532344
Iter: 1549 loss: 0.00159424846
Iter: 1550 loss: 0.00159410236
Iter: 1551 loss: 0.00159407197
Iter: 1552 loss: 0.00159371074
Iter: 1553 loss: 0.00159272726
Iter: 1554 loss: 0.00160025584
Iter: 1555 loss: 0.0015925318
Iter: 1556 loss: 0.00159223308
Iter: 1557 loss: 0.00159196276
Iter: 1558 loss: 0.00159978378
Iter: 1559 loss: 0.00159183959
Iter: 1560 loss: 0.00159160385
Iter: 1561 loss: 0.00159308512
Iter: 1562 loss: 0.00159158092
Iter: 1563 loss: 0.00159128022
Iter: 1564 loss: 0.00159626454
Iter: 1565 loss: 0.00159128162
Iter: 1566 loss: 0.00159103877
Iter: 1567 loss: 0.00159089221
Iter: 1568 loss: 0.00159080094
Iter: 1569 loss: 0.00159071793
Iter: 1570 loss: 0.0015905149
Iter: 1571 loss: 0.00159251131
Iter: 1572 loss: 0.00159048266
Iter: 1573 loss: 0.00159011059
Iter: 1574 loss: 0.00158914994
Iter: 1575 loss: 0.00160040974
Iter: 1576 loss: 0.00158902188
Iter: 1577 loss: 0.00158892595
Iter: 1578 loss: 0.0015889369
Iter: 1579 loss: 0.0015900631
Iter: 1580 loss: 0.00158888847
Iter: 1581 loss: 0.00158882025
Iter: 1582 loss: 0.00158865261
Iter: 1583 loss: 0.00158854085
Iter: 1584 loss: 0.00158842665
Iter: 1585 loss: 0.00158816739
Iter: 1586 loss: 0.00158862839
Iter: 1587 loss: 0.00158806785
Iter: 1588 loss: 0.00158795563
Iter: 1589 loss: 0.00158767239
Iter: 1590 loss: 0.00159157906
Iter: 1591 loss: 0.0015876519
Iter: 1592 loss: 0.00158737751
Iter: 1593 loss: 0.00158736901
Iter: 1594 loss: 0.00158709171
Iter: 1595 loss: 0.00158706913
Iter: 1596 loss: 0.00158615992
Iter: 1597 loss: 0.00158615573
Iter: 1598 loss: 0.00158713339
Iter: 1599 loss: 0.00158583547
Iter: 1600 loss: 0.00158618146
Iter: 1601 loss: 0.00158571661
Iter: 1602 loss: 0.00158557645
Iter: 1603 loss: 0.00158616877
Iter: 1604 loss: 0.00158555782
Iter: 1605 loss: 0.0015900596
Iter: 1606 loss: 0.00158540066
Iter: 1607 loss: 0.00158529007
Iter: 1608 loss: 0.00158494513
Iter: 1609 loss: 0.00158576993
Iter: 1610 loss: 0.00158474362
Iter: 1611 loss: 0.00158458063
Iter: 1612 loss: 0.00158454105
Iter: 1613 loss: 0.00158445467
Iter: 1614 loss: 0.00158517668
Iter: 1615 loss: 0.0015844442
Iter: 1616 loss: 0.00158441253
Iter: 1617 loss: 0.00158441113
Iter: 1618 loss: 0.00158437213
Iter: 1619 loss: 0.00158429402
Iter: 1620 loss: 0.00158443023
Iter: 1621 loss: 0.00158423488
Iter: 1622 loss: 0.00158351962
Iter: 1623 loss: 0.00158462068
Iter: 1624 loss: 0.00158316211
Iter: 1625 loss: 0.0015823805
Iter: 1626 loss: 0.00158626749
Iter: 1627 loss: 0.00158226117
Iter: 1628 loss: 0.00158190494
Iter: 1629 loss: 0.00158144964
Iter: 1630 loss: 0.0015814174
Iter: 1631 loss: 0.00158113753
Iter: 1632 loss: 0.00158113148
Iter: 1633 loss: 0.0015809976
Iter: 1634 loss: 0.00158110016
Iter: 1635 loss: 0.00158092042
Iter: 1636 loss: 0.00158129982
Iter: 1637 loss: 0.0015805352
Iter: 1638 loss: 0.00157994824
Iter: 1639 loss: 0.00158215454
Iter: 1640 loss: 0.00157979736
Iter: 1641 loss: 0.00157971191
Iter: 1642 loss: 0.00157956814
Iter: 1643 loss: 0.00157938106
Iter: 1644 loss: 0.00157955359
Iter: 1645 loss: 0.00157926185
Iter: 1646 loss: 0.00157935754
Iter: 1647 loss: 0.00157878653
Iter: 1648 loss: 0.00157814554
Iter: 1649 loss: 0.00157897081
Iter: 1650 loss: 0.00157782284
Iter: 1651 loss: 0.0015776502
Iter: 1652 loss: 0.00157824764
Iter: 1653 loss: 0.00157760037
Iter: 1654 loss: 0.00157753844
Iter: 1655 loss: 0.00157741038
Iter: 1656 loss: 0.00157932984
Iter: 1657 loss: 0.0015774013
Iter: 1658 loss: 0.00157721678
Iter: 1659 loss: 0.0015767226
Iter: 1660 loss: 0.00157952704
Iter: 1661 loss: 0.00157658546
Iter: 1662 loss: 0.0015931474
Iter: 1663 loss: 0.00157651876
Iter: 1664 loss: 0.00157628511
Iter: 1665 loss: 0.001576985
Iter: 1666 loss: 0.00157621317
Iter: 1667 loss: 0.00157615717
Iter: 1668 loss: 0.00157612306
Iter: 1669 loss: 0.00157608034
Iter: 1670 loss: 0.00157599046
Iter: 1671 loss: 0.00157596066
Iter: 1672 loss: 0.00157591968
Iter: 1673 loss: 0.00157613656
Iter: 1674 loss: 0.00157578255
Iter: 1675 loss: 0.00157562143
Iter: 1676 loss: 0.00157544331
Iter: 1677 loss: 0.00157542783
Iter: 1678 loss: 0.00157491886
Iter: 1679 loss: 0.00157494319
Iter: 1680 loss: 0.00157452305
Iter: 1681 loss: 0.00157823798
Iter: 1682 loss: 0.00157435122
Iter: 1683 loss: 0.00157367741
Iter: 1684 loss: 0.0015750227
Iter: 1685 loss: 0.00157337985
Iter: 1686 loss: 0.00157321221
Iter: 1687 loss: 0.00157463318
Iter: 1688 loss: 0.00157320104
Iter: 1689 loss: 0.00157312839
Iter: 1690 loss: 0.00157318648
Iter: 1691 loss: 0.00157309452
Iter: 1692 loss: 0.00157303188
Iter: 1693 loss: 0.0015730852
Iter: 1694 loss: 0.00157298567
Iter: 1695 loss: 0.0016471165
Iter: 1696 loss: 0.00157293561
Iter: 1697 loss: 0.00159610761
Iter: 1698 loss: 0.00157284294
Iter: 1699 loss: 0.00157268229
Iter: 1700 loss: 0.00157282758
Iter: 1701 loss: 0.00157258194
Iter: 1702 loss: 0.0015721065
Iter: 1703 loss: 0.00157322013
Iter: 1704 loss: 0.00157194794
Iter: 1705 loss: 0.00157148368
Iter: 1706 loss: 0.00157131255
Iter: 1707 loss: 0.00157086446
Iter: 1708 loss: 0.001569596
Iter: 1709 loss: 0.00157594506
Iter: 1710 loss: 0.001569174
Iter: 1711 loss: 0.00156841869
Iter: 1712 loss: 0.00156839937
Iter: 1713 loss: 0.00156800426
Iter: 1714 loss: 0.00157449977
Iter: 1715 loss: 0.00156800565
Iter: 1716 loss: 0.0015677663
Iter: 1717 loss: 0.0015674918
Iter: 1718 loss: 0.00156744523
Iter: 1719 loss: 0.0015666266
Iter: 1720 loss: 0.0015662373
Iter: 1721 loss: 0.00156583451
Iter: 1722 loss: 0.00156571134
Iter: 1723 loss: 0.0015676911
Iter: 1724 loss: 0.00156570901
Iter: 1725 loss: 0.00156562391
Iter: 1726 loss: 0.00156612264
Iter: 1727 loss: 0.00156561937
Iter: 1728 loss: 0.00156551669
Iter: 1729 loss: 0.00156525616
Iter: 1730 loss: 0.0015683542
Iter: 1731 loss: 0.00156524219
Iter: 1732 loss: 0.00156474952
Iter: 1733 loss: 0.00156366453
Iter: 1734 loss: 0.0015889596
Iter: 1735 loss: 0.00156361517
Iter: 1736 loss: 0.00156298373
Iter: 1737 loss: 0.0015649402
Iter: 1738 loss: 0.00156281167
Iter: 1739 loss: 0.00156267092
Iter: 1740 loss: 0.00156285102
Iter: 1741 loss: 0.00156257756
Iter: 1742 loss: 0.0015687407
Iter: 1743 loss: 0.00156237523
Iter: 1744 loss: 0.00156215904
Iter: 1745 loss: 0.0015636459
Iter: 1746 loss: 0.00156213436
Iter: 1747 loss: 0.00160827965
Iter: 1748 loss: 0.00156177348
Iter: 1749 loss: 0.00156176114
Iter: 1750 loss: 0.00156171247
Iter: 1751 loss: 0.0015617
Iter: 1752 loss: 0.00156168267
Iter: 1753 loss: 0.00156167534
Iter: 1754 loss: 0.00156289421
Iter: 1755 loss: 0.00156158663
Iter: 1756 loss: 0.00156157487
Iter: 1757 loss: 0.0015615439
Iter: 1758 loss: 0.0015615162
Iter: 1759 loss: 0.00156152295
Iter: 1760 loss: 0.00156149897
Iter: 1761 loss: 0.00156144821
Iter: 1762 loss: 0.00156121701
Iter: 1763 loss: 0.00156077603
Iter: 1764 loss: 0.00156077021
Iter: 1765 loss: 0.00156077812
Iter: 1766 loss: 0.00156066916
Iter: 1767 loss: 0.00156052643
Iter: 1768 loss: 0.00156057393
Iter: 1769 loss: 0.00156043307
Iter: 1770 loss: 0.00156074832
Iter: 1771 loss: 0.00155965541
Iter: 1772 loss: 0.00155873713
Iter: 1773 loss: 0.00156136451
Iter: 1774 loss: 0.00155843224
Iter: 1775 loss: 0.00155965833
Iter: 1776 loss: 0.00155782094
Iter: 1777 loss: 0.00155774225
Iter: 1778 loss: 0.00155891641
Iter: 1779 loss: 0.0015577462
Iter: 1780 loss: 0.00155771803
Iter: 1781 loss: 0.00155768229
Iter: 1782 loss: 0.00155853084
Iter: 1783 loss: 0.00155768252
Iter: 1784 loss: 0.00155749707
Iter: 1785 loss: 0.00155741407
Iter: 1786 loss: 0.00155732583
Iter: 1787 loss: 0.00155726506
Iter: 1788 loss: 0.00155766262
Iter: 1789 loss: 0.0015572448
Iter: 1790 loss: 0.00155717088
Iter: 1791 loss: 0.00155696576
Iter: 1792 loss: 0.00155851687
Iter: 1793 loss: 0.00155692408
Iter: 1794 loss: 0.00155661325
Iter: 1795 loss: 0.00155638065
Iter: 1796 loss: 0.00155628962
Iter: 1797 loss: 0.00157245784
Iter: 1798 loss: 0.0015561576
Iter: 1799 loss: 0.00155611103
Iter: 1800 loss: 0.00155637064
Iter: 1801 loss: 0.00155610591
Iter: 1802 loss: 0.00155600056
Iter: 1803 loss: 0.00155575317
Iter: 1804 loss: 0.0015589057
Iter: 1805 loss: 0.00155572756
Iter: 1806 loss: 0.00155556493
Iter: 1807 loss: 0.00155514595
Iter: 1808 loss: 0.00155835168
Iter: 1809 loss: 0.00155506528
Iter: 1810 loss: 0.00155488425
Iter: 1811 loss: 0.00155605166
Iter: 1812 loss: 0.00155486015
Iter: 1813 loss: 0.00155484746
Iter: 1814 loss: 0.00155481743
Iter: 1815 loss: 0.00155508332
Iter: 1816 loss: 0.00155480346
Iter: 1817 loss: 0.00155472639
Iter: 1818 loss: 0.00155496085
Iter: 1819 loss: 0.00155469414
Iter: 1820 loss: 0.00155460171
Iter: 1821 loss: 0.00155502383
Iter: 1822 loss: 0.00155458355
Iter: 1823 loss: 0.00155450474
Iter: 1824 loss: 0.00155417365
Iter: 1825 loss: 0.0015533244
Iter: 1826 loss: 0.00156940077
Iter: 1827 loss: 0.00155332708
Iter: 1828 loss: 0.00231851311
Iter: 1829 loss: 0.00155328051
Iter: 1830 loss: 0.0015526854
Iter: 1831 loss: 0.00155338249
Iter: 1832 loss: 0.00155236374
Iter: 1833 loss: 0.00155203731
Iter: 1834 loss: 0.00155292591
Iter: 1835 loss: 0.00155192532
Iter: 1836 loss: 0.00155165535
Iter: 1837 loss: 0.001552745
Iter: 1838 loss: 0.00155160192
Iter: 1839 loss: 0.00155127165
Iter: 1840 loss: 0.0015510181
Iter: 1841 loss: 0.00155091961
Iter: 1842 loss: 0.00157243607
Iter: 1843 loss: 0.00155086129
Iter: 1844 loss: 0.0015507834
Iter: 1845 loss: 0.00155162928
Iter: 1846 loss: 0.00155077968
Iter: 1847 loss: 0.00155082101
Iter: 1848 loss: 0.00155074778
Iter: 1849 loss: 0.00155071518
Iter: 1850 loss: 0.00155068631
Iter: 1851 loss: 0.00155068061
Iter: 1852 loss: 0.00155065744
Iter: 1853 loss: 0.00155056873
Iter: 1854 loss: 0.0015507933
Iter: 1855 loss: 0.00155051588
Iter: 1856 loss: 0.00155113044
Iter: 1857 loss: 0.00155036757
Iter: 1858 loss: 0.00155020272
Iter: 1859 loss: 0.00155057851
Iter: 1860 loss: 0.001550138
Iter: 1861 loss: 0.00154980179
Iter: 1862 loss: 0.00154995476
Iter: 1863 loss: 0.00154957408
Iter: 1864 loss: 0.00154936709
Iter: 1865 loss: 0.00155020482
Iter: 1866 loss: 0.00154931017
Iter: 1867 loss: 0.00154918712
Iter: 1868 loss: 0.00154883333
Iter: 1869 loss: 0.00155119854
Iter: 1870 loss: 0.00154875405
Iter: 1871 loss: 0.00159640529
Iter: 1872 loss: 0.00154861016
Iter: 1873 loss: 0.00155018154
Iter: 1874 loss: 0.00154857966
Iter: 1875 loss: 0.00154852855
Iter: 1876 loss: 0.00154879061
Iter: 1877 loss: 0.00154851936
Iter: 1878 loss: 0.00154849293
Iter: 1879 loss: 0.00154850073
Iter: 1880 loss: 0.00154849305
Iter: 1881 loss: 0.0015484636
Iter: 1882 loss: 0.00154835964
Iter: 1883 loss: 0.00155011343
Iter: 1884 loss: 0.00154836383
Iter: 1885 loss: 0.00154818734
Iter: 1886 loss: 0.00154812553
Iter: 1887 loss: 0.00154749898
Iter: 1888 loss: 0.00155020063
Iter: 1889 loss: 0.00154739711
Iter: 1890 loss: 0.00154719525
Iter: 1891 loss: 0.00154703553
Iter: 1892 loss: 0.00154665206
Iter: 1893 loss: 0.00155298179
Iter: 1894 loss: 0.00154664274
Iter: 1895 loss: 0.00154805207
Iter: 1896 loss: 0.00154642912
Iter: 1897 loss: 0.00154633308
Iter: 1898 loss: 0.00154606625
Iter: 1899 loss: 0.00154860783
Iter: 1900 loss: 0.00154603797
Iter: 1901 loss: 0.00154584
Iter: 1902 loss: 0.00154653867
Iter: 1903 loss: 0.00154579047
Iter: 1904 loss: 0.0015457049
Iter: 1905 loss: 0.00154577638
Iter: 1906 loss: 0.00154567161
Iter: 1907 loss: 0.00154543435
Iter: 1908 loss: 0.00154514331
Iter: 1909 loss: 0.00154511561
Iter: 1910 loss: 0.00154494483
Iter: 1911 loss: 0.00154486648
Iter: 1912 loss: 0.00154477917
Iter: 1913 loss: 0.00155087956
Iter: 1914 loss: 0.00154425763
Iter: 1915 loss: 0.00154367089
Iter: 1916 loss: 0.001544995
Iter: 1917 loss: 0.00154345774
Iter: 1918 loss: 0.00154319301
Iter: 1919 loss: 0.00154435134
Iter: 1920 loss: 0.00154314493
Iter: 1921 loss: 0.00154286437
Iter: 1922 loss: 0.00154208927
Iter: 1923 loss: 0.00154633506
Iter: 1924 loss: 0.00154185807
Iter: 1925 loss: 0.00154070603
Iter: 1926 loss: 0.00154165609
Iter: 1927 loss: 0.00154002535
Iter: 1928 loss: 0.00153894827
Iter: 1929 loss: 0.00153921987
Iter: 1930 loss: 0.00153815607
Iter: 1931 loss: 0.00153768517
Iter: 1932 loss: 0.00153765909
Iter: 1933 loss: 0.00153757283
Iter: 1934 loss: 0.00153811893
Iter: 1935 loss: 0.00153755629
Iter: 1936 loss: 0.00153780344
Iter: 1937 loss: 0.00153746188
Iter: 1938 loss: 0.00153735431
Iter: 1939 loss: 0.00153748691
Iter: 1940 loss: 0.00153729529
Iter: 1941 loss: 0.00153722113
Iter: 1942 loss: 0.00153702497
Iter: 1943 loss: 0.00153927575
Iter: 1944 loss: 0.00153700705
Iter: 1945 loss: 0.00153685757
Iter: 1946 loss: 0.00153689622
Iter: 1947 loss: 0.00153674255
Iter: 1948 loss: 0.00153665734
Iter: 1949 loss: 0.00153671158
Iter: 1950 loss: 0.00153660134
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.4/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.8 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.8
+ date
Sun Nov  8 04:59:35 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.4/300_100_100_100_1 --function f1 --psi 1 --phi 2.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.8/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8a1b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8b13510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8af3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8a4eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8a450d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b896ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8a45f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b89088c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b89d5400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b89d5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b89359d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8935b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b8935ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b2686b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b2605400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b2633d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b2631400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b2631598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b259c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b259cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b264b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b88b7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b25349d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b2521950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b25211e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b256e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b24907b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b248a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b24e0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b24cd488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b2460b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b240f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b24062f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b241c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b23639d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc3b236cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.09549456
test_loss: 0.100060925
train_loss: 0.06888013
test_loss: 0.06883639
train_loss: 0.05575917
test_loss: 0.055269223
train_loss: 0.039812148
test_loss: 0.0479607
train_loss: 0.040911652
test_loss: 0.041166797
train_loss: 0.034962133
test_loss: 0.03815595
train_loss: 0.036557347
test_loss: 0.03732713
train_loss: 0.033834696
test_loss: 0.035700724
train_loss: 0.0300763
test_loss: 0.0329395
train_loss: 0.029901339
test_loss: 0.03216921
train_loss: 0.027614703
test_loss: 0.03120657
train_loss: 0.02677523
test_loss: 0.03075332
train_loss: 0.02429001
test_loss: 0.029299945
train_loss: 0.025203193
test_loss: 0.027912475
train_loss: 0.022506343
test_loss: 0.027486892
train_loss: 0.022329982
test_loss: 0.026329894
train_loss: 0.020481344
test_loss: 0.0262258
train_loss: 0.021290515
test_loss: 0.024163103
train_loss: 0.022303583
test_loss: 0.024513096
train_loss: 0.019174805
test_loss: 0.023804858
train_loss: 0.019520234
test_loss: 0.022714958
train_loss: 0.019187797
test_loss: 0.021746725
train_loss: 0.017040538
test_loss: 0.021915287
train_loss: 0.015831858
test_loss: 0.020868286
train_loss: 0.017368197
test_loss: 0.020493109
train_loss: 0.015277693
test_loss: 0.019999584
train_loss: 0.016670113
test_loss: 0.02057036
train_loss: 0.016258284
test_loss: 0.018840192
train_loss: 0.01526838
test_loss: 0.01859435
train_loss: 0.014148464
test_loss: 0.018356606
train_loss: 0.014453085
test_loss: 0.017529253
train_loss: 0.014341324
test_loss: 0.017315743
train_loss: 0.014610285
test_loss: 0.017707048
train_loss: 0.014228514
test_loss: 0.017551776
train_loss: 0.01319737
test_loss: 0.016417416
train_loss: 0.013153812
test_loss: 0.016596327
train_loss: 0.012920376
test_loss: 0.016133748
train_loss: 0.012120543
test_loss: 0.015894879
train_loss: 0.013191072
test_loss: 0.0153028015
train_loss: 0.012731389
test_loss: 0.015562795
train_loss: 0.013453252
test_loss: 0.015402268
train_loss: 0.012118449
test_loss: 0.01495286
train_loss: 0.012920441
test_loss: 0.015110138
train_loss: 0.013139482
test_loss: 0.0146475965
train_loss: 0.011149815
test_loss: 0.014911671
train_loss: 0.0110173505
test_loss: 0.014081689
train_loss: 0.01205997
test_loss: 0.014178731
train_loss: 0.011989583
test_loss: 0.014604379
train_loss: 0.011264135
test_loss: 0.01387751
train_loss: 0.01169222
test_loss: 0.014213335
train_loss: 0.0111736525
test_loss: 0.014326842
train_loss: 0.010401199
test_loss: 0.014001523
train_loss: 0.010920999
test_loss: 0.013713246
train_loss: 0.011548555
test_loss: 0.01404918
train_loss: 0.0107617
test_loss: 0.013316647
train_loss: 0.010427352
test_loss: 0.013941047
train_loss: 0.011413373
test_loss: 0.013468969
train_loss: 0.00984997
test_loss: 0.013022598
train_loss: 0.011170263
test_loss: 0.013594824
train_loss: 0.011024359
test_loss: 0.013921554
train_loss: 0.010149107
test_loss: 0.01286473
train_loss: 0.010127476
test_loss: 0.0128829535
train_loss: 0.01035418
test_loss: 0.012477807
train_loss: 0.010549765
test_loss: 0.013029426
train_loss: 0.01008082
test_loss: 0.012858327
train_loss: 0.009715397
test_loss: 0.012599353
train_loss: 0.009823331
test_loss: 0.0123070795
train_loss: 0.009552208
test_loss: 0.012536894
train_loss: 0.010089092
test_loss: 0.012457604
train_loss: 0.009469028
test_loss: 0.012079201
train_loss: 0.009112127
test_loss: 0.012832423
train_loss: 0.010051543
test_loss: 0.012701153
train_loss: 0.009903529
test_loss: 0.012618257
train_loss: 0.009225117
test_loss: 0.012027753
train_loss: 0.009966885
test_loss: 0.012794437
train_loss: 0.009748471
test_loss: 0.012707285
train_loss: 0.009703737
test_loss: 0.01256058
train_loss: 0.009601394
test_loss: 0.012449484
train_loss: 0.009070776
test_loss: 0.011962118
train_loss: 0.009596945
test_loss: 0.012604306
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.8/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 2.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi2.8/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ff6c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1007c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c1007ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ffa6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ff39488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ff4c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ff4a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0feaf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0feafd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fec8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fe9ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fe3cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fe5e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fe16730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fdc2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fdc2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fdd47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fd6b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fd56620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0fd56bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0bb51bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0bb51b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0bb059d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0bae66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0baba510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0bb51d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ba50730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ba50598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ba6c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0ba6cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0b9d29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0b980400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0b97a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0b993730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0b966a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6c0b969f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.000183584154
Iter: 2 loss: 0.000449002808
Iter: 3 loss: 0.000147573475
Iter: 4 loss: 0.000136619172
Iter: 5 loss: 0.000117735573
Iter: 6 loss: 0.000117722724
Iter: 7 loss: 0.000105262181
Iter: 8 loss: 0.000115577815
Iter: 9 loss: 9.78510361e-05
Iter: 10 loss: 8.99124352e-05
Iter: 11 loss: 0.000104923289
Iter: 12 loss: 8.65542388e-05
Iter: 13 loss: 8.03940566e-05
Iter: 14 loss: 0.000109713648
Iter: 15 loss: 7.92636638e-05
Iter: 16 loss: 7.48297098e-05
Iter: 17 loss: 8.45273898e-05
Iter: 18 loss: 7.31139371e-05
Iter: 19 loss: 7.01670506e-05
Iter: 20 loss: 8.48193449e-05
Iter: 21 loss: 6.96777e-05
Iter: 22 loss: 6.68694775e-05
Iter: 23 loss: 6.91734531e-05
Iter: 24 loss: 6.51836235e-05
Iter: 25 loss: 6.25875691e-05
Iter: 26 loss: 7.22171681e-05
Iter: 27 loss: 6.19557613e-05
Iter: 28 loss: 5.98401311e-05
Iter: 29 loss: 6.22478401e-05
Iter: 30 loss: 5.87034592e-05
Iter: 31 loss: 5.65357368e-05
Iter: 32 loss: 6.15543104e-05
Iter: 33 loss: 5.57284147e-05
Iter: 34 loss: 5.41608388e-05
Iter: 35 loss: 5.50693512e-05
Iter: 36 loss: 5.31442456e-05
Iter: 37 loss: 5.16907057e-05
Iter: 38 loss: 6.69559086e-05
Iter: 39 loss: 5.16518376e-05
Iter: 40 loss: 5.05751377e-05
Iter: 41 loss: 6.761041e-05
Iter: 42 loss: 5.05764183e-05
Iter: 43 loss: 4.99657945e-05
Iter: 44 loss: 4.95242202e-05
Iter: 45 loss: 4.93168845e-05
Iter: 46 loss: 4.84089469e-05
Iter: 47 loss: 5.03837146e-05
Iter: 48 loss: 4.80559393e-05
Iter: 49 loss: 4.72973916e-05
Iter: 50 loss: 4.95010645e-05
Iter: 51 loss: 4.70625637e-05
Iter: 52 loss: 4.63133147e-05
Iter: 53 loss: 4.94862179e-05
Iter: 54 loss: 4.61577e-05
Iter: 55 loss: 4.54409383e-05
Iter: 56 loss: 4.54146502e-05
Iter: 57 loss: 4.48543142e-05
Iter: 58 loss: 4.42916789e-05
Iter: 59 loss: 4.42825622e-05
Iter: 60 loss: 4.3900327e-05
Iter: 61 loss: 4.31942753e-05
Iter: 62 loss: 5.94731246e-05
Iter: 63 loss: 4.31928311e-05
Iter: 64 loss: 4.25318904e-05
Iter: 65 loss: 5.03670926e-05
Iter: 66 loss: 4.25245307e-05
Iter: 67 loss: 4.20629076e-05
Iter: 68 loss: 4.23133752e-05
Iter: 69 loss: 4.17590127e-05
Iter: 70 loss: 4.12324443e-05
Iter: 71 loss: 4.4088596e-05
Iter: 72 loss: 4.11543842e-05
Iter: 73 loss: 4.10070861e-05
Iter: 74 loss: 4.09383065e-05
Iter: 75 loss: 4.07535481e-05
Iter: 76 loss: 4.0515537e-05
Iter: 77 loss: 4.04983148e-05
Iter: 78 loss: 4.01728284e-05
Iter: 79 loss: 4.02977712e-05
Iter: 80 loss: 3.99476776e-05
Iter: 81 loss: 3.95744719e-05
Iter: 82 loss: 4.17876945e-05
Iter: 83 loss: 3.95271818e-05
Iter: 84 loss: 3.92678739e-05
Iter: 85 loss: 3.96180185e-05
Iter: 86 loss: 3.91380381e-05
Iter: 87 loss: 3.87891596e-05
Iter: 88 loss: 3.98572956e-05
Iter: 89 loss: 3.86854954e-05
Iter: 90 loss: 3.8415521e-05
Iter: 91 loss: 3.88853659e-05
Iter: 92 loss: 3.82963517e-05
Iter: 93 loss: 3.79638586e-05
Iter: 94 loss: 3.93743831e-05
Iter: 95 loss: 3.78944678e-05
Iter: 96 loss: 3.76487587e-05
Iter: 97 loss: 3.78236655e-05
Iter: 98 loss: 3.74951414e-05
Iter: 99 loss: 3.72407885e-05
Iter: 100 loss: 3.8019225e-05
Iter: 101 loss: 3.71632887e-05
Iter: 102 loss: 3.68663677e-05
Iter: 103 loss: 3.73407129e-05
Iter: 104 loss: 3.67297216e-05
Iter: 105 loss: 3.65096348e-05
Iter: 106 loss: 3.96135511e-05
Iter: 107 loss: 3.65097512e-05
Iter: 108 loss: 3.62940482e-05
Iter: 109 loss: 3.75429881e-05
Iter: 110 loss: 3.626748e-05
Iter: 111 loss: 3.61352104e-05
Iter: 112 loss: 3.59192854e-05
Iter: 113 loss: 3.59183177e-05
Iter: 114 loss: 3.57124263e-05
Iter: 115 loss: 3.72856521e-05
Iter: 116 loss: 3.56945602e-05
Iter: 117 loss: 3.55245502e-05
Iter: 118 loss: 3.54805416e-05
Iter: 119 loss: 3.53744472e-05
Iter: 120 loss: 3.51186172e-05
Iter: 121 loss: 3.68165929e-05
Iter: 122 loss: 3.50933769e-05
Iter: 123 loss: 3.49278125e-05
Iter: 124 loss: 3.5468649e-05
Iter: 125 loss: 3.48829089e-05
Iter: 126 loss: 3.47391e-05
Iter: 127 loss: 3.49324109e-05
Iter: 128 loss: 3.46657362e-05
Iter: 129 loss: 3.44816654e-05
Iter: 130 loss: 3.52075076e-05
Iter: 131 loss: 3.44377913e-05
Iter: 132 loss: 3.42971907e-05
Iter: 133 loss: 3.41958148e-05
Iter: 134 loss: 3.41459927e-05
Iter: 135 loss: 3.38797036e-05
Iter: 136 loss: 3.46005545e-05
Iter: 137 loss: 3.37912643e-05
Iter: 138 loss: 3.36217e-05
Iter: 139 loss: 3.54741242e-05
Iter: 140 loss: 3.36185294e-05
Iter: 141 loss: 3.35281147e-05
Iter: 142 loss: 3.35266923e-05
Iter: 143 loss: 3.34381111e-05
Iter: 144 loss: 3.3299093e-05
Iter: 145 loss: 3.32973941e-05
Iter: 146 loss: 3.31722513e-05
Iter: 147 loss: 3.32260133e-05
Iter: 148 loss: 3.30869952e-05
Iter: 149 loss: 3.29304603e-05
Iter: 150 loss: 3.40841652e-05
Iter: 151 loss: 3.29170944e-05
Iter: 152 loss: 3.27893358e-05
Iter: 153 loss: 3.2795142e-05
Iter: 154 loss: 3.26897352e-05
Iter: 155 loss: 3.25408255e-05
Iter: 156 loss: 3.42892454e-05
Iter: 157 loss: 3.25400833e-05
Iter: 158 loss: 3.24562861e-05
Iter: 159 loss: 3.24030188e-05
Iter: 160 loss: 3.23706045e-05
Iter: 161 loss: 3.22098967e-05
Iter: 162 loss: 3.28332499e-05
Iter: 163 loss: 3.21732368e-05
Iter: 164 loss: 3.20370345e-05
Iter: 165 loss: 3.23873319e-05
Iter: 166 loss: 3.19903156e-05
Iter: 167 loss: 3.18720813e-05
Iter: 168 loss: 3.19294522e-05
Iter: 169 loss: 3.17922677e-05
Iter: 170 loss: 3.16672376e-05
Iter: 171 loss: 3.22073138e-05
Iter: 172 loss: 3.16411242e-05
Iter: 173 loss: 3.15378275e-05
Iter: 174 loss: 3.26597146e-05
Iter: 175 loss: 3.15367979e-05
Iter: 176 loss: 3.14285789e-05
Iter: 177 loss: 3.18681123e-05
Iter: 178 loss: 3.14051067e-05
Iter: 179 loss: 3.13400888e-05
Iter: 180 loss: 3.12409029e-05
Iter: 181 loss: 3.12392258e-05
Iter: 182 loss: 3.11191543e-05
Iter: 183 loss: 3.13928467e-05
Iter: 184 loss: 3.10743308e-05
Iter: 185 loss: 3.09694187e-05
Iter: 186 loss: 3.20382351e-05
Iter: 187 loss: 3.09666066e-05
Iter: 188 loss: 3.08916206e-05
Iter: 189 loss: 3.08669187e-05
Iter: 190 loss: 3.08241e-05
Iter: 191 loss: 3.07000118e-05
Iter: 192 loss: 3.12899647e-05
Iter: 193 loss: 3.0677922e-05
Iter: 194 loss: 3.05874273e-05
Iter: 195 loss: 3.07931259e-05
Iter: 196 loss: 3.05519898e-05
Iter: 197 loss: 3.04625173e-05
Iter: 198 loss: 3.07295049e-05
Iter: 199 loss: 3.04350415e-05
Iter: 200 loss: 3.03218858e-05
Iter: 201 loss: 3.03566503e-05
Iter: 202 loss: 3.02421431e-05
Iter: 203 loss: 3.01388955e-05
Iter: 204 loss: 3.03330526e-05
Iter: 205 loss: 3.00944885e-05
Iter: 206 loss: 2.99851145e-05
Iter: 207 loss: 3.03757879e-05
Iter: 208 loss: 2.99580934e-05
Iter: 209 loss: 2.99338644e-05
Iter: 210 loss: 2.99083822e-05
Iter: 211 loss: 2.98621853e-05
Iter: 212 loss: 2.97982133e-05
Iter: 213 loss: 2.97948191e-05
Iter: 214 loss: 2.97208589e-05
Iter: 215 loss: 2.96773851e-05
Iter: 216 loss: 2.96449471e-05
Iter: 217 loss: 2.95518475e-05
Iter: 218 loss: 3.02298249e-05
Iter: 219 loss: 2.95424325e-05
Iter: 220 loss: 2.94677011e-05
Iter: 221 loss: 2.97089246e-05
Iter: 222 loss: 2.94472975e-05
Iter: 223 loss: 2.93674202e-05
Iter: 224 loss: 2.95091686e-05
Iter: 225 loss: 2.93318917e-05
Iter: 226 loss: 2.92613e-05
Iter: 227 loss: 2.96367562e-05
Iter: 228 loss: 2.92493187e-05
Iter: 229 loss: 2.91834967e-05
Iter: 230 loss: 2.92397144e-05
Iter: 231 loss: 2.91456745e-05
Iter: 232 loss: 2.9068673e-05
Iter: 233 loss: 2.93258072e-05
Iter: 234 loss: 2.90477838e-05
Iter: 235 loss: 2.89782802e-05
Iter: 236 loss: 2.9306384e-05
Iter: 237 loss: 2.89651362e-05
Iter: 238 loss: 2.89063555e-05
Iter: 239 loss: 2.88161464e-05
Iter: 240 loss: 2.88138253e-05
Iter: 241 loss: 2.87083021e-05
Iter: 242 loss: 2.896e-05
Iter: 243 loss: 2.86712966e-05
Iter: 244 loss: 2.8720855e-05
Iter: 245 loss: 2.86369705e-05
Iter: 246 loss: 2.85981823e-05
Iter: 247 loss: 2.85251372e-05
Iter: 248 loss: 2.99836938e-05
Iter: 249 loss: 2.85242168e-05
Iter: 250 loss: 2.84681828e-05
Iter: 251 loss: 2.84783146e-05
Iter: 252 loss: 2.84273119e-05
Iter: 253 loss: 2.83489262e-05
Iter: 254 loss: 2.86069462e-05
Iter: 255 loss: 2.83284498e-05
Iter: 256 loss: 2.82693509e-05
Iter: 257 loss: 2.86888626e-05
Iter: 258 loss: 2.82642814e-05
Iter: 259 loss: 2.8202292e-05
Iter: 260 loss: 2.82613146e-05
Iter: 261 loss: 2.81661e-05
Iter: 262 loss: 2.80964668e-05
Iter: 263 loss: 2.85297538e-05
Iter: 264 loss: 2.8089069e-05
Iter: 265 loss: 2.804828e-05
Iter: 266 loss: 2.8036482e-05
Iter: 267 loss: 2.80115601e-05
Iter: 268 loss: 2.79342948e-05
Iter: 269 loss: 2.81975335e-05
Iter: 270 loss: 2.79128326e-05
Iter: 271 loss: 2.78532825e-05
Iter: 272 loss: 2.81051671e-05
Iter: 273 loss: 2.78409607e-05
Iter: 274 loss: 2.77942963e-05
Iter: 275 loss: 2.77348881e-05
Iter: 276 loss: 2.77322051e-05
Iter: 277 loss: 2.76807241e-05
Iter: 278 loss: 2.76784849e-05
Iter: 279 loss: 2.76408646e-05
Iter: 280 loss: 2.82168876e-05
Iter: 281 loss: 2.76408937e-05
Iter: 282 loss: 2.76174833e-05
Iter: 283 loss: 2.75683851e-05
Iter: 284 loss: 2.8264205e-05
Iter: 285 loss: 2.75650236e-05
Iter: 286 loss: 2.75029397e-05
Iter: 287 loss: 2.76591745e-05
Iter: 288 loss: 2.74804e-05
Iter: 289 loss: 2.74210342e-05
Iter: 290 loss: 2.73794103e-05
Iter: 291 loss: 2.73574278e-05
Iter: 292 loss: 2.72823418e-05
Iter: 293 loss: 2.77584477e-05
Iter: 294 loss: 2.72739926e-05
Iter: 295 loss: 2.72074194e-05
Iter: 296 loss: 2.76096525e-05
Iter: 297 loss: 2.71997797e-05
Iter: 298 loss: 2.71489862e-05
Iter: 299 loss: 2.74777849e-05
Iter: 300 loss: 2.71435238e-05
Iter: 301 loss: 2.70991586e-05
Iter: 302 loss: 2.71123718e-05
Iter: 303 loss: 2.70659075e-05
Iter: 304 loss: 2.70100172e-05
Iter: 305 loss: 2.7128799e-05
Iter: 306 loss: 2.69877164e-05
Iter: 307 loss: 2.69325046e-05
Iter: 308 loss: 2.70716009e-05
Iter: 309 loss: 2.69136108e-05
Iter: 310 loss: 2.68664899e-05
Iter: 311 loss: 2.71956669e-05
Iter: 312 loss: 2.68629556e-05
Iter: 313 loss: 2.68206495e-05
Iter: 314 loss: 2.70556593e-05
Iter: 315 loss: 2.68144431e-05
Iter: 316 loss: 2.67771502e-05
Iter: 317 loss: 2.70891633e-05
Iter: 318 loss: 2.67744763e-05
Iter: 319 loss: 2.67546093e-05
Iter: 320 loss: 2.66973111e-05
Iter: 321 loss: 2.69231e-05
Iter: 322 loss: 2.66734023e-05
Iter: 323 loss: 2.65966082e-05
Iter: 324 loss: 2.71297031e-05
Iter: 325 loss: 2.65891613e-05
Iter: 326 loss: 2.65398521e-05
Iter: 327 loss: 2.64813352e-05
Iter: 328 loss: 2.64751397e-05
Iter: 329 loss: 2.64196842e-05
Iter: 330 loss: 2.64185455e-05
Iter: 331 loss: 2.63696529e-05
Iter: 332 loss: 2.65084309e-05
Iter: 333 loss: 2.63523234e-05
Iter: 334 loss: 2.62972e-05
Iter: 335 loss: 2.65359504e-05
Iter: 336 loss: 2.62857175e-05
Iter: 337 loss: 2.62437134e-05
Iter: 338 loss: 2.63282727e-05
Iter: 339 loss: 2.62271824e-05
Iter: 340 loss: 2.61830828e-05
Iter: 341 loss: 2.61882724e-05
Iter: 342 loss: 2.61500099e-05
Iter: 343 loss: 2.6095091e-05
Iter: 344 loss: 2.64109312e-05
Iter: 345 loss: 2.60864927e-05
Iter: 346 loss: 2.60468678e-05
Iter: 347 loss: 2.64274931e-05
Iter: 348 loss: 2.60440811e-05
Iter: 349 loss: 2.60188754e-05
Iter: 350 loss: 2.63692891e-05
Iter: 351 loss: 2.60178749e-05
Iter: 352 loss: 2.59974495e-05
Iter: 353 loss: 2.59499848e-05
Iter: 354 loss: 2.66109328e-05
Iter: 355 loss: 2.5947e-05
Iter: 356 loss: 2.5901405e-05
Iter: 357 loss: 2.60247e-05
Iter: 358 loss: 2.58867749e-05
Iter: 359 loss: 2.58396449e-05
Iter: 360 loss: 2.5952304e-05
Iter: 361 loss: 2.58221171e-05
Iter: 362 loss: 2.57665724e-05
Iter: 363 loss: 2.58269029e-05
Iter: 364 loss: 2.57352403e-05
Iter: 365 loss: 2.5683792e-05
Iter: 366 loss: 2.57475986e-05
Iter: 367 loss: 2.56573949e-05
Iter: 368 loss: 2.5592235e-05
Iter: 369 loss: 2.58383916e-05
Iter: 370 loss: 2.55757768e-05
Iter: 371 loss: 2.55375144e-05
Iter: 372 loss: 2.55370851e-05
Iter: 373 loss: 2.5500638e-05
Iter: 374 loss: 2.54603692e-05
Iter: 375 loss: 2.54551e-05
Iter: 376 loss: 2.54060724e-05
Iter: 377 loss: 2.54519891e-05
Iter: 378 loss: 2.53774342e-05
Iter: 379 loss: 2.53219823e-05
Iter: 380 loss: 2.58124928e-05
Iter: 381 loss: 2.5320538e-05
Iter: 382 loss: 2.52957234e-05
Iter: 383 loss: 2.52934042e-05
Iter: 384 loss: 2.52699301e-05
Iter: 385 loss: 2.52632599e-05
Iter: 386 loss: 2.52477439e-05
Iter: 387 loss: 2.5218018e-05
Iter: 388 loss: 2.5200934e-05
Iter: 389 loss: 2.51879e-05
Iter: 390 loss: 2.51457896e-05
Iter: 391 loss: 2.53013623e-05
Iter: 392 loss: 2.51361143e-05
Iter: 393 loss: 2.50999274e-05
Iter: 394 loss: 2.51049296e-05
Iter: 395 loss: 2.50726771e-05
Iter: 396 loss: 2.50265039e-05
Iter: 397 loss: 2.52518621e-05
Iter: 398 loss: 2.50174671e-05
Iter: 399 loss: 2.49830446e-05
Iter: 400 loss: 2.50810335e-05
Iter: 401 loss: 2.49717832e-05
Iter: 402 loss: 2.49300429e-05
Iter: 403 loss: 2.50714747e-05
Iter: 404 loss: 2.49191125e-05
Iter: 405 loss: 2.48860069e-05
Iter: 406 loss: 2.49438963e-05
Iter: 407 loss: 2.48726119e-05
Iter: 408 loss: 2.4831792e-05
Iter: 409 loss: 2.50914673e-05
Iter: 410 loss: 2.48269207e-05
Iter: 411 loss: 2.47940206e-05
Iter: 412 loss: 2.47901735e-05
Iter: 413 loss: 2.47662101e-05
Iter: 414 loss: 2.47246116e-05
Iter: 415 loss: 2.47852531e-05
Iter: 416 loss: 2.47058088e-05
Iter: 417 loss: 2.47143362e-05
Iter: 418 loss: 2.46898544e-05
Iter: 419 loss: 2.46739128e-05
Iter: 420 loss: 2.46325271e-05
Iter: 421 loss: 2.48614706e-05
Iter: 422 loss: 2.46200962e-05
Iter: 423 loss: 2.45825249e-05
Iter: 424 loss: 2.48120741e-05
Iter: 425 loss: 2.45780884e-05
Iter: 426 loss: 2.45388583e-05
Iter: 427 loss: 2.46382624e-05
Iter: 428 loss: 2.4526129e-05
Iter: 429 loss: 2.44964231e-05
Iter: 430 loss: 2.44898583e-05
Iter: 431 loss: 2.44718649e-05
Iter: 432 loss: 2.44257644e-05
Iter: 433 loss: 2.46201125e-05
Iter: 434 loss: 2.44159237e-05
Iter: 435 loss: 2.43826435e-05
Iter: 436 loss: 2.44753264e-05
Iter: 437 loss: 2.43732266e-05
Iter: 438 loss: 2.43308677e-05
Iter: 439 loss: 2.43789091e-05
Iter: 440 loss: 2.43084432e-05
Iter: 441 loss: 2.42745537e-05
Iter: 442 loss: 2.45839037e-05
Iter: 443 loss: 2.4273475e-05
Iter: 444 loss: 2.42404894e-05
Iter: 445 loss: 2.42998722e-05
Iter: 446 loss: 2.42254318e-05
Iter: 447 loss: 2.41937123e-05
Iter: 448 loss: 2.42176229e-05
Iter: 449 loss: 2.41744856e-05
Iter: 450 loss: 2.41399794e-05
Iter: 451 loss: 2.43566428e-05
Iter: 452 loss: 2.41360322e-05
Iter: 453 loss: 2.41150738e-05
Iter: 454 loss: 2.41148646e-05
Iter: 455 loss: 2.4093777e-05
Iter: 456 loss: 2.4070534e-05
Iter: 457 loss: 2.40665613e-05
Iter: 458 loss: 2.40419486e-05
Iter: 459 loss: 2.4041894e-05
Iter: 460 loss: 2.40218469e-05
Iter: 461 loss: 2.39873807e-05
Iter: 462 loss: 2.39742403e-05
Iter: 463 loss: 2.39558485e-05
Iter: 464 loss: 2.39294277e-05
Iter: 465 loss: 2.39267029e-05
Iter: 466 loss: 2.39030633e-05
Iter: 467 loss: 2.38958637e-05
Iter: 468 loss: 2.38813973e-05
Iter: 469 loss: 2.38420871e-05
Iter: 470 loss: 2.38675202e-05
Iter: 471 loss: 2.38169741e-05
Iter: 472 loss: 2.37872046e-05
Iter: 473 loss: 2.40191057e-05
Iter: 474 loss: 2.37844724e-05
Iter: 475 loss: 2.37549502e-05
Iter: 476 loss: 2.37869881e-05
Iter: 477 loss: 2.37392978e-05
Iter: 478 loss: 2.37088607e-05
Iter: 479 loss: 2.38053963e-05
Iter: 480 loss: 2.36997312e-05
Iter: 481 loss: 2.36669966e-05
Iter: 482 loss: 2.37236836e-05
Iter: 483 loss: 2.36525e-05
Iter: 484 loss: 2.36254291e-05
Iter: 485 loss: 2.40191039e-05
Iter: 486 loss: 2.36248707e-05
Iter: 487 loss: 2.36034321e-05
Iter: 488 loss: 2.3775041e-05
Iter: 489 loss: 2.36013966e-05
Iter: 490 loss: 2.35816879e-05
Iter: 491 loss: 2.35702064e-05
Iter: 492 loss: 2.356195e-05
Iter: 493 loss: 2.35405787e-05
Iter: 494 loss: 2.36125816e-05
Iter: 495 loss: 2.35356747e-05
Iter: 496 loss: 2.35124608e-05
Iter: 497 loss: 2.34838444e-05
Iter: 498 loss: 2.34810432e-05
Iter: 499 loss: 2.34460058e-05
Iter: 500 loss: 2.36004798e-05
Iter: 501 loss: 2.34389317e-05
Iter: 502 loss: 2.34073777e-05
Iter: 503 loss: 2.34422732e-05
Iter: 504 loss: 2.33901465e-05
Iter: 505 loss: 2.33566461e-05
Iter: 506 loss: 2.38184875e-05
Iter: 507 loss: 2.33562278e-05
Iter: 508 loss: 2.3335182e-05
Iter: 509 loss: 2.33625924e-05
Iter: 510 loss: 2.33238261e-05
Iter: 511 loss: 2.33000901e-05
Iter: 512 loss: 2.32678267e-05
Iter: 513 loss: 2.32659659e-05
Iter: 514 loss: 2.32315506e-05
Iter: 515 loss: 2.35106072e-05
Iter: 516 loss: 2.32297116e-05
Iter: 517 loss: 2.31959384e-05
Iter: 518 loss: 2.32681014e-05
Iter: 519 loss: 2.31842259e-05
Iter: 520 loss: 2.31560152e-05
Iter: 521 loss: 2.34896579e-05
Iter: 522 loss: 2.31555714e-05
Iter: 523 loss: 2.31339218e-05
Iter: 524 loss: 2.33821738e-05
Iter: 525 loss: 2.31333615e-05
Iter: 526 loss: 2.31228223e-05
Iter: 527 loss: 2.30993392e-05
Iter: 528 loss: 2.34791332e-05
Iter: 529 loss: 2.3098848e-05
Iter: 530 loss: 2.30680434e-05
Iter: 531 loss: 2.31818813e-05
Iter: 532 loss: 2.30607875e-05
Iter: 533 loss: 2.3032153e-05
Iter: 534 loss: 2.30753903e-05
Iter: 535 loss: 2.30198784e-05
Iter: 536 loss: 2.29942816e-05
Iter: 537 loss: 2.29644393e-05
Iter: 538 loss: 2.29610159e-05
Iter: 539 loss: 2.2931401e-05
Iter: 540 loss: 2.29304642e-05
Iter: 541 loss: 2.29044344e-05
Iter: 542 loss: 2.29305624e-05
Iter: 543 loss: 2.28888421e-05
Iter: 544 loss: 2.28586978e-05
Iter: 545 loss: 2.29610596e-05
Iter: 546 loss: 2.28500976e-05
Iter: 547 loss: 2.28240569e-05
Iter: 548 loss: 2.29443413e-05
Iter: 549 loss: 2.28184326e-05
Iter: 550 loss: 2.27929104e-05
Iter: 551 loss: 2.27905966e-05
Iter: 552 loss: 2.27715282e-05
Iter: 553 loss: 2.27386463e-05
Iter: 554 loss: 2.27989494e-05
Iter: 555 loss: 2.27245637e-05
Iter: 556 loss: 2.2694654e-05
Iter: 557 loss: 2.292305e-05
Iter: 558 loss: 2.26921911e-05
Iter: 559 loss: 2.26686807e-05
Iter: 560 loss: 2.26679e-05
Iter: 561 loss: 2.26569409e-05
Iter: 562 loss: 2.26252014e-05
Iter: 563 loss: 2.27791352e-05
Iter: 564 loss: 2.2613709e-05
Iter: 565 loss: 2.25875301e-05
Iter: 566 loss: 2.2587581e-05
Iter: 567 loss: 2.25668191e-05
Iter: 568 loss: 2.25895947e-05
Iter: 569 loss: 2.25554013e-05
Iter: 570 loss: 2.25289459e-05
Iter: 571 loss: 2.25306685e-05
Iter: 572 loss: 2.25080876e-05
Iter: 573 loss: 2.24745891e-05
Iter: 574 loss: 2.26296361e-05
Iter: 575 loss: 2.24688592e-05
Iter: 576 loss: 2.24445394e-05
Iter: 577 loss: 2.24956384e-05
Iter: 578 loss: 2.24354262e-05
Iter: 579 loss: 2.24063915e-05
Iter: 580 loss: 2.24448759e-05
Iter: 581 loss: 2.23925508e-05
Iter: 582 loss: 2.23613679e-05
Iter: 583 loss: 2.27061573e-05
Iter: 584 loss: 2.23607258e-05
Iter: 585 loss: 2.23393581e-05
Iter: 586 loss: 2.23035095e-05
Iter: 587 loss: 2.23037823e-05
Iter: 588 loss: 2.22728486e-05
Iter: 589 loss: 2.25818058e-05
Iter: 590 loss: 2.22722483e-05
Iter: 591 loss: 2.22529488e-05
Iter: 592 loss: 2.244598e-05
Iter: 593 loss: 2.22526251e-05
Iter: 594 loss: 2.22308e-05
Iter: 595 loss: 2.23166335e-05
Iter: 596 loss: 2.22265626e-05
Iter: 597 loss: 2.22134295e-05
Iter: 598 loss: 2.21995779e-05
Iter: 599 loss: 2.2197517e-05
Iter: 600 loss: 2.21714436e-05
Iter: 601 loss: 2.21484261e-05
Iter: 602 loss: 2.21420069e-05
Iter: 603 loss: 2.21104838e-05
Iter: 604 loss: 2.24423311e-05
Iter: 605 loss: 2.2108763e-05
Iter: 606 loss: 2.20852089e-05
Iter: 607 loss: 2.22453309e-05
Iter: 608 loss: 2.20829425e-05
Iter: 609 loss: 2.20626353e-05
Iter: 610 loss: 2.20364691e-05
Iter: 611 loss: 2.20341481e-05
Iter: 612 loss: 2.20035326e-05
Iter: 613 loss: 2.21877635e-05
Iter: 614 loss: 2.2000062e-05
Iter: 615 loss: 2.1971724e-05
Iter: 616 loss: 2.20002803e-05
Iter: 617 loss: 2.19559533e-05
Iter: 618 loss: 2.19255162e-05
Iter: 619 loss: 2.20701222e-05
Iter: 620 loss: 2.19201938e-05
Iter: 621 loss: 2.1891763e-05
Iter: 622 loss: 2.18883688e-05
Iter: 623 loss: 2.18673795e-05
Iter: 624 loss: 2.18371133e-05
Iter: 625 loss: 2.19663834e-05
Iter: 626 loss: 2.18316527e-05
Iter: 627 loss: 2.18247042e-05
Iter: 628 loss: 2.18163223e-05
Iter: 629 loss: 2.18023342e-05
Iter: 630 loss: 2.17922025e-05
Iter: 631 loss: 2.17874658e-05
Iter: 632 loss: 2.17691086e-05
Iter: 633 loss: 2.17804045e-05
Iter: 634 loss: 2.17587367e-05
Iter: 635 loss: 2.17330016e-05
Iter: 636 loss: 2.17360794e-05
Iter: 637 loss: 2.17140623e-05
Iter: 638 loss: 2.16851113e-05
Iter: 639 loss: 2.18993664e-05
Iter: 640 loss: 2.16823119e-05
Iter: 641 loss: 2.16593871e-05
Iter: 642 loss: 2.16757799e-05
Iter: 643 loss: 2.16450298e-05
Iter: 644 loss: 2.16171e-05
Iter: 645 loss: 2.16536209e-05
Iter: 646 loss: 2.1603566e-05
Iter: 647 loss: 2.15780401e-05
Iter: 648 loss: 2.18185414e-05
Iter: 649 loss: 2.15765467e-05
Iter: 650 loss: 2.15531527e-05
Iter: 651 loss: 2.16134431e-05
Iter: 652 loss: 2.15455057e-05
Iter: 653 loss: 2.15240507e-05
Iter: 654 loss: 2.15318851e-05
Iter: 655 loss: 2.15100972e-05
Iter: 656 loss: 2.14833362e-05
Iter: 657 loss: 2.15687487e-05
Iter: 658 loss: 2.14758675e-05
Iter: 659 loss: 2.14485572e-05
Iter: 660 loss: 2.14643078e-05
Iter: 661 loss: 2.14312531e-05
Iter: 662 loss: 2.13978165e-05
Iter: 663 loss: 2.14968768e-05
Iter: 664 loss: 2.13877756e-05
Iter: 665 loss: 2.13856147e-05
Iter: 666 loss: 2.13746698e-05
Iter: 667 loss: 2.13612439e-05
Iter: 668 loss: 2.1347365e-05
Iter: 669 loss: 2.13445528e-05
Iter: 670 loss: 2.13305466e-05
Iter: 671 loss: 2.13046387e-05
Iter: 672 loss: 2.19438334e-05
Iter: 673 loss: 2.13044896e-05
Iter: 674 loss: 2.12776e-05
Iter: 675 loss: 2.1277483e-05
Iter: 676 loss: 2.1263033e-05
Iter: 677 loss: 2.12472496e-05
Iter: 678 loss: 2.12448322e-05
Iter: 679 loss: 2.12119885e-05
Iter: 680 loss: 2.13549065e-05
Iter: 681 loss: 2.12052346e-05
Iter: 682 loss: 2.11829247e-05
Iter: 683 loss: 2.12601626e-05
Iter: 684 loss: 2.11772822e-05
Iter: 685 loss: 2.11578936e-05
Iter: 686 loss: 2.11982842e-05
Iter: 687 loss: 2.11499118e-05
Iter: 688 loss: 2.11260376e-05
Iter: 689 loss: 2.12419109e-05
Iter: 690 loss: 2.11213955e-05
Iter: 691 loss: 2.1103413e-05
Iter: 692 loss: 2.11058432e-05
Iter: 693 loss: 2.10911694e-05
Iter: 694 loss: 2.10656726e-05
Iter: 695 loss: 2.10892576e-05
Iter: 696 loss: 2.10507787e-05
Iter: 697 loss: 2.10254348e-05
Iter: 698 loss: 2.12533614e-05
Iter: 699 loss: 2.10240432e-05
Iter: 700 loss: 2.1005324e-05
Iter: 701 loss: 2.09967839e-05
Iter: 702 loss: 2.09877053e-05
Iter: 703 loss: 2.09871541e-05
Iter: 704 loss: 2.09737154e-05
Iter: 705 loss: 2.0964857e-05
Iter: 706 loss: 2.09436403e-05
Iter: 707 loss: 2.11458027e-05
Iter: 708 loss: 2.09418504e-05
Iter: 709 loss: 2.09209102e-05
Iter: 710 loss: 2.09342652e-05
Iter: 711 loss: 2.09066238e-05
Iter: 712 loss: 2.08820329e-05
Iter: 713 loss: 2.11196439e-05
Iter: 714 loss: 2.08807651e-05
Iter: 715 loss: 2.08615529e-05
Iter: 716 loss: 2.08883739e-05
Iter: 717 loss: 2.08517267e-05
Iter: 718 loss: 2.08329075e-05
Iter: 719 loss: 2.08676247e-05
Iter: 720 loss: 2.0825235e-05
Iter: 721 loss: 2.07998128e-05
Iter: 722 loss: 2.08669608e-05
Iter: 723 loss: 2.07910234e-05
Iter: 724 loss: 2.07695666e-05
Iter: 725 loss: 2.076501e-05
Iter: 726 loss: 2.07500416e-05
Iter: 727 loss: 2.07321646e-05
Iter: 728 loss: 2.07300363e-05
Iter: 729 loss: 2.07157063e-05
Iter: 730 loss: 2.06943296e-05
Iter: 731 loss: 2.0693089e-05
Iter: 732 loss: 2.06676814e-05
Iter: 733 loss: 2.07584126e-05
Iter: 734 loss: 2.06602672e-05
Iter: 735 loss: 2.06367e-05
Iter: 736 loss: 2.06812292e-05
Iter: 737 loss: 2.06257264e-05
Iter: 738 loss: 2.0599e-05
Iter: 739 loss: 2.07410176e-05
Iter: 740 loss: 2.05948199e-05
Iter: 741 loss: 2.05850538e-05
Iter: 742 loss: 2.05844572e-05
Iter: 743 loss: 2.05730066e-05
Iter: 744 loss: 2.05728265e-05
Iter: 745 loss: 2.05633369e-05
Iter: 746 loss: 2.05502438e-05
Iter: 747 loss: 2.05304204e-05
Iter: 748 loss: 2.05295291e-05
Iter: 749 loss: 2.05084561e-05
Iter: 750 loss: 2.05826636e-05
Iter: 751 loss: 2.05029883e-05
Iter: 752 loss: 2.04781372e-05
Iter: 753 loss: 2.06206732e-05
Iter: 754 loss: 2.04747012e-05
Iter: 755 loss: 2.0460102e-05
Iter: 756 loss: 2.04850294e-05
Iter: 757 loss: 2.04535336e-05
Iter: 758 loss: 2.04341395e-05
Iter: 759 loss: 2.0456082e-05
Iter: 760 loss: 2.04233365e-05
Iter: 761 loss: 2.03998388e-05
Iter: 762 loss: 2.04783792e-05
Iter: 763 loss: 2.03926957e-05
Iter: 764 loss: 2.03758518e-05
Iter: 765 loss: 2.04438729e-05
Iter: 766 loss: 2.0371388e-05
Iter: 767 loss: 2.03531636e-05
Iter: 768 loss: 2.04367079e-05
Iter: 769 loss: 2.03497038e-05
Iter: 770 loss: 2.03338604e-05
Iter: 771 loss: 2.03144846e-05
Iter: 772 loss: 2.03123673e-05
Iter: 773 loss: 2.02867504e-05
Iter: 774 loss: 2.0345451e-05
Iter: 775 loss: 2.02772717e-05
Iter: 776 loss: 2.02478604e-05
Iter: 777 loss: 2.04384614e-05
Iter: 778 loss: 2.02449373e-05
Iter: 779 loss: 2.02227384e-05
Iter: 780 loss: 2.0237494e-05
Iter: 781 loss: 2.02087158e-05
Iter: 782 loss: 2.01849434e-05
Iter: 783 loss: 2.03062755e-05
Iter: 784 loss: 2.01807961e-05
Iter: 785 loss: 2.01748226e-05
Iter: 786 loss: 2.01711482e-05
Iter: 787 loss: 2.01601924e-05
Iter: 788 loss: 2.01409021e-05
Iter: 789 loss: 2.0563326e-05
Iter: 790 loss: 2.01408566e-05
Iter: 791 loss: 2.01223702e-05
Iter: 792 loss: 2.02014562e-05
Iter: 793 loss: 2.01187104e-05
Iter: 794 loss: 2.01056664e-05
Iter: 795 loss: 2.01254679e-05
Iter: 796 loss: 2.00970753e-05
Iter: 797 loss: 2.00807299e-05
Iter: 798 loss: 2.0090687e-05
Iter: 799 loss: 2.00699433e-05
Iter: 800 loss: 2.00496215e-05
Iter: 801 loss: 2.02049232e-05
Iter: 802 loss: 2.00480972e-05
Iter: 803 loss: 2.00333961e-05
Iter: 804 loss: 2.00123122e-05
Iter: 805 loss: 2.00117029e-05
Iter: 806 loss: 1.99912556e-05
Iter: 807 loss: 1.99907372e-05
Iter: 808 loss: 1.99762762e-05
Iter: 809 loss: 1.99763617e-05
Iter: 810 loss: 1.99652932e-05
Iter: 811 loss: 1.99459682e-05
Iter: 812 loss: 1.99257374e-05
Iter: 813 loss: 1.99218066e-05
Iter: 814 loss: 1.98945017e-05
Iter: 815 loss: 2.01410367e-05
Iter: 816 loss: 1.98931411e-05
Iter: 817 loss: 1.98704693e-05
Iter: 818 loss: 1.99501865e-05
Iter: 819 loss: 1.98646339e-05
Iter: 820 loss: 1.98516973e-05
Iter: 821 loss: 1.98510697e-05
Iter: 822 loss: 1.98365487e-05
Iter: 823 loss: 1.9871095e-05
Iter: 824 loss: 1.98317e-05
Iter: 825 loss: 1.98233411e-05
Iter: 826 loss: 1.98031285e-05
Iter: 827 loss: 2.00863942e-05
Iter: 828 loss: 1.98029284e-05
Iter: 829 loss: 1.97811787e-05
Iter: 830 loss: 1.98170674e-05
Iter: 831 loss: 1.97715181e-05
Iter: 832 loss: 1.97494755e-05
Iter: 833 loss: 1.99689857e-05
Iter: 834 loss: 1.97482368e-05
Iter: 835 loss: 1.97309746e-05
Iter: 836 loss: 1.97541976e-05
Iter: 837 loss: 1.97222798e-05
Iter: 838 loss: 1.97004374e-05
Iter: 839 loss: 1.97470381e-05
Iter: 840 loss: 1.96913679e-05
Iter: 841 loss: 1.96702422e-05
Iter: 842 loss: 1.98040234e-05
Iter: 843 loss: 1.966743e-05
Iter: 844 loss: 1.9650297e-05
Iter: 845 loss: 1.96593537e-05
Iter: 846 loss: 1.96387336e-05
Iter: 847 loss: 1.9618079e-05
Iter: 848 loss: 1.96746951e-05
Iter: 849 loss: 1.96122346e-05
Iter: 850 loss: 1.95911343e-05
Iter: 851 loss: 1.97959143e-05
Iter: 852 loss: 1.95903704e-05
Iter: 853 loss: 1.95814391e-05
Iter: 854 loss: 1.9559e-05
Iter: 855 loss: 1.98489324e-05
Iter: 856 loss: 1.95575012e-05
Iter: 857 loss: 1.95600533e-05
Iter: 858 loss: 1.954662e-05
Iter: 859 loss: 1.95348584e-05
Iter: 860 loss: 1.95340763e-05
Iter: 861 loss: 1.95256471e-05
Iter: 862 loss: 1.95163684e-05
Iter: 863 loss: 1.94952609e-05
Iter: 864 loss: 1.98151938e-05
Iter: 865 loss: 1.94940549e-05
Iter: 866 loss: 1.94711265e-05
Iter: 867 loss: 1.97234258e-05
Iter: 868 loss: 1.94706408e-05
Iter: 869 loss: 1.9455043e-05
Iter: 870 loss: 1.94555178e-05
Iter: 871 loss: 1.94427157e-05
Iter: 872 loss: 1.94218846e-05
Iter: 873 loss: 1.94870445e-05
Iter: 874 loss: 1.94159802e-05
Iter: 875 loss: 1.93966844e-05
Iter: 876 loss: 1.94701861e-05
Iter: 877 loss: 1.9392417e-05
Iter: 878 loss: 1.93717115e-05
Iter: 879 loss: 1.94282948e-05
Iter: 880 loss: 1.93653941e-05
Iter: 881 loss: 1.93443848e-05
Iter: 882 loss: 1.936634e-05
Iter: 883 loss: 1.93325468e-05
Iter: 884 loss: 1.93118576e-05
Iter: 885 loss: 1.94928434e-05
Iter: 886 loss: 1.93103588e-05
Iter: 887 loss: 1.92928874e-05
Iter: 888 loss: 1.93488759e-05
Iter: 889 loss: 1.92882617e-05
Iter: 890 loss: 1.92739317e-05
Iter: 891 loss: 1.9279596e-05
Iter: 892 loss: 1.9263769e-05
Iter: 893 loss: 1.92535e-05
Iter: 894 loss: 1.92519947e-05
Iter: 895 loss: 1.92424613e-05
Iter: 896 loss: 1.92542957e-05
Iter: 897 loss: 1.92364569e-05
Iter: 898 loss: 1.92250372e-05
Iter: 899 loss: 1.92122643e-05
Iter: 900 loss: 1.92100797e-05
Iter: 901 loss: 1.91913859e-05
Iter: 902 loss: 1.91834879e-05
Iter: 903 loss: 1.91745148e-05
Iter: 904 loss: 1.91516683e-05
Iter: 905 loss: 1.93348187e-05
Iter: 906 loss: 1.91502313e-05
Iter: 907 loss: 1.91305335e-05
Iter: 908 loss: 1.91544059e-05
Iter: 909 loss: 1.91208583e-05
Iter: 910 loss: 1.90985083e-05
Iter: 911 loss: 1.91500112e-05
Iter: 912 loss: 1.90919218e-05
Iter: 913 loss: 1.90678202e-05
Iter: 914 loss: 1.90897481e-05
Iter: 915 loss: 1.90543178e-05
Iter: 916 loss: 1.90304854e-05
Iter: 917 loss: 1.918001e-05
Iter: 918 loss: 1.90275059e-05
Iter: 919 loss: 1.90084102e-05
Iter: 920 loss: 1.90980754e-05
Iter: 921 loss: 1.90051596e-05
Iter: 922 loss: 1.89863822e-05
Iter: 923 loss: 1.90654027e-05
Iter: 924 loss: 1.89834209e-05
Iter: 925 loss: 1.89707971e-05
Iter: 926 loss: 1.90488463e-05
Iter: 927 loss: 1.89689672e-05
Iter: 928 loss: 1.89579387e-05
Iter: 929 loss: 1.90131504e-05
Iter: 930 loss: 1.89562543e-05
Iter: 931 loss: 1.89421335e-05
Iter: 932 loss: 1.89494131e-05
Iter: 933 loss: 1.89331477e-05
Iter: 934 loss: 1.89210987e-05
Iter: 935 loss: 1.89070088e-05
Iter: 936 loss: 1.89049788e-05
Iter: 937 loss: 1.88850845e-05
Iter: 938 loss: 1.89726088e-05
Iter: 939 loss: 1.888119e-05
Iter: 940 loss: 1.88642407e-05
Iter: 941 loss: 1.89865896e-05
Iter: 942 loss: 1.8863293e-05
Iter: 943 loss: 1.88518461e-05
Iter: 944 loss: 1.8826624e-05
Iter: 945 loss: 1.92656153e-05
Iter: 946 loss: 1.88257745e-05
Iter: 947 loss: 1.88067606e-05
Iter: 948 loss: 1.91069012e-05
Iter: 949 loss: 1.88071426e-05
Iter: 950 loss: 1.87892219e-05
Iter: 951 loss: 1.87926653e-05
Iter: 952 loss: 1.87762325e-05
Iter: 953 loss: 1.87534442e-05
Iter: 954 loss: 1.88223439e-05
Iter: 955 loss: 1.87466976e-05
Iter: 956 loss: 1.8728173e-05
Iter: 957 loss: 1.87727419e-05
Iter: 958 loss: 1.87217156e-05
Iter: 959 loss: 1.87010828e-05
Iter: 960 loss: 1.87508231e-05
Iter: 961 loss: 1.86934485e-05
Iter: 962 loss: 1.86762663e-05
Iter: 963 loss: 1.88288741e-05
Iter: 964 loss: 1.86752586e-05
Iter: 965 loss: 1.8658171e-05
Iter: 966 loss: 1.86860034e-05
Iter: 967 loss: 1.86513225e-05
Iter: 968 loss: 1.86399429e-05
Iter: 969 loss: 1.86390916e-05
Iter: 970 loss: 1.86295911e-05
Iter: 971 loss: 1.86300822e-05
Iter: 972 loss: 1.86229972e-05
Iter: 973 loss: 1.86107645e-05
Iter: 974 loss: 1.86198922e-05
Iter: 975 loss: 1.86050529e-05
Iter: 976 loss: 1.85916015e-05
Iter: 977 loss: 1.85816643e-05
Iter: 978 loss: 1.85769422e-05
Iter: 979 loss: 1.85609115e-05
Iter: 980 loss: 1.87112983e-05
Iter: 981 loss: 1.85602e-05
Iter: 982 loss: 1.85445533e-05
Iter: 983 loss: 1.85578137e-05
Iter: 984 loss: 1.8534578e-05
Iter: 985 loss: 1.85177923e-05
Iter: 986 loss: 1.85371046e-05
Iter: 987 loss: 1.85087574e-05
Iter: 988 loss: 1.84891123e-05
Iter: 989 loss: 1.85260415e-05
Iter: 990 loss: 1.84811015e-05
Iter: 991 loss: 1.84619312e-05
Iter: 992 loss: 1.85651515e-05
Iter: 993 loss: 1.8458275e-05
Iter: 994 loss: 1.8438468e-05
Iter: 995 loss: 1.8441795e-05
Iter: 996 loss: 1.84228102e-05
Iter: 997 loss: 1.84026958e-05
Iter: 998 loss: 1.8433142e-05
Iter: 999 loss: 1.83929915e-05
Iter: 1000 loss: 1.83691918e-05
Iter: 1001 loss: 1.85195859e-05
Iter: 1002 loss: 1.83660704e-05
Iter: 1003 loss: 1.83658631e-05
Iter: 1004 loss: 1.83588782e-05
Iter: 1005 loss: 1.83514967e-05
Iter: 1006 loss: 1.83404118e-05
Iter: 1007 loss: 1.83405555e-05
Iter: 1008 loss: 1.8325949e-05
Iter: 1009 loss: 1.83280863e-05
Iter: 1010 loss: 1.8315126e-05
Iter: 1011 loss: 1.82982767e-05
Iter: 1012 loss: 1.8380586e-05
Iter: 1013 loss: 1.82957665e-05
Iter: 1014 loss: 1.82818931e-05
Iter: 1015 loss: 1.83534703e-05
Iter: 1016 loss: 1.82797339e-05
Iter: 1017 loss: 1.82666772e-05
Iter: 1018 loss: 1.82558542e-05
Iter: 1019 loss: 1.82519689e-05
Iter: 1020 loss: 1.82351123e-05
Iter: 1021 loss: 1.82887034e-05
Iter: 1022 loss: 1.82305303e-05
Iter: 1023 loss: 1.82143958e-05
Iter: 1024 loss: 1.83387292e-05
Iter: 1025 loss: 1.82125223e-05
Iter: 1026 loss: 1.819924e-05
Iter: 1027 loss: 1.82102121e-05
Iter: 1028 loss: 1.81905834e-05
Iter: 1029 loss: 1.81767409e-05
Iter: 1030 loss: 1.82050553e-05
Iter: 1031 loss: 1.81712021e-05
Iter: 1032 loss: 1.81555424e-05
Iter: 1033 loss: 1.81880587e-05
Iter: 1034 loss: 1.81493306e-05
Iter: 1035 loss: 1.8131188e-05
Iter: 1036 loss: 1.81731812e-05
Iter: 1037 loss: 1.81249e-05
Iter: 1038 loss: 1.81126252e-05
Iter: 1039 loss: 1.82934637e-05
Iter: 1040 loss: 1.81122796e-05
Iter: 1041 loss: 1.80962779e-05
Iter: 1042 loss: 1.80933275e-05
Iter: 1043 loss: 1.80827938e-05
Iter: 1044 loss: 1.80725474e-05
Iter: 1045 loss: 1.80567349e-05
Iter: 1046 loss: 1.80558345e-05
Iter: 1047 loss: 1.80425195e-05
Iter: 1048 loss: 1.80436964e-05
Iter: 1049 loss: 1.80308707e-05
Iter: 1050 loss: 1.80355783e-05
Iter: 1051 loss: 1.80222196e-05
Iter: 1052 loss: 1.8007262e-05
Iter: 1053 loss: 1.80456409e-05
Iter: 1054 loss: 1.80025254e-05
Iter: 1055 loss: 1.79891194e-05
Iter: 1056 loss: 1.80528623e-05
Iter: 1057 loss: 1.79879207e-05
Iter: 1058 loss: 1.79741437e-05
Iter: 1059 loss: 1.79655181e-05
Iter: 1060 loss: 1.79605104e-05
Iter: 1061 loss: 1.79436247e-05
Iter: 1062 loss: 1.81530795e-05
Iter: 1063 loss: 1.79433864e-05
Iter: 1064 loss: 1.79314e-05
Iter: 1065 loss: 1.79301242e-05
Iter: 1066 loss: 1.79208982e-05
Iter: 1067 loss: 1.79030139e-05
Iter: 1068 loss: 1.79228336e-05
Iter: 1069 loss: 1.78928949e-05
Iter: 1070 loss: 1.78756054e-05
Iter: 1071 loss: 1.79189519e-05
Iter: 1072 loss: 1.78684604e-05
Iter: 1073 loss: 1.78656283e-05
Iter: 1074 loss: 1.78589398e-05
Iter: 1075 loss: 1.78515293e-05
Iter: 1076 loss: 1.78346127e-05
Iter: 1077 loss: 1.80351562e-05
Iter: 1078 loss: 1.78329738e-05
Iter: 1079 loss: 1.78177161e-05
Iter: 1080 loss: 1.78450664e-05
Iter: 1081 loss: 1.7811104e-05
Iter: 1082 loss: 1.77933362e-05
Iter: 1083 loss: 1.78468872e-05
Iter: 1084 loss: 1.77874681e-05
Iter: 1085 loss: 1.77729689e-05
Iter: 1086 loss: 1.78499595e-05
Iter: 1087 loss: 1.77712845e-05
Iter: 1088 loss: 1.77570728e-05
Iter: 1089 loss: 1.78148221e-05
Iter: 1090 loss: 1.77532183e-05
Iter: 1091 loss: 1.77408474e-05
Iter: 1092 loss: 1.77235597e-05
Iter: 1093 loss: 1.77229267e-05
Iter: 1094 loss: 1.77087895e-05
Iter: 1095 loss: 1.7708855e-05
Iter: 1096 loss: 1.76949052e-05
Iter: 1097 loss: 1.76852518e-05
Iter: 1098 loss: 1.76807825e-05
Iter: 1099 loss: 1.76632984e-05
Iter: 1100 loss: 1.7806291e-05
Iter: 1101 loss: 1.76619797e-05
Iter: 1102 loss: 1.7646762e-05
Iter: 1103 loss: 1.76502454e-05
Iter: 1104 loss: 1.76350368e-05
Iter: 1105 loss: 1.76178182e-05
Iter: 1106 loss: 1.76914928e-05
Iter: 1107 loss: 1.76145204e-05
Iter: 1108 loss: 1.76031172e-05
Iter: 1109 loss: 1.76020094e-05
Iter: 1110 loss: 1.7595894e-05
Iter: 1111 loss: 1.7577242e-05
Iter: 1112 loss: 1.76726226e-05
Iter: 1113 loss: 1.75709047e-05
Iter: 1114 loss: 1.75496498e-05
Iter: 1115 loss: 1.76222457e-05
Iter: 1116 loss: 1.7544533e-05
Iter: 1117 loss: 1.75241985e-05
Iter: 1118 loss: 1.75624664e-05
Iter: 1119 loss: 1.75159767e-05
Iter: 1120 loss: 1.7499633e-05
Iter: 1121 loss: 1.74993529e-05
Iter: 1122 loss: 1.7486238e-05
Iter: 1123 loss: 1.74975685e-05
Iter: 1124 loss: 1.74784891e-05
Iter: 1125 loss: 1.74618872e-05
Iter: 1126 loss: 1.7499493e-05
Iter: 1127 loss: 1.74563611e-05
Iter: 1128 loss: 1.74422657e-05
Iter: 1129 loss: 1.7449991e-05
Iter: 1130 loss: 1.74331508e-05
Iter: 1131 loss: 1.74123761e-05
Iter: 1132 loss: 1.74846209e-05
Iter: 1133 loss: 1.74061079e-05
Iter: 1134 loss: 1.73920726e-05
Iter: 1135 loss: 1.75707792e-05
Iter: 1136 loss: 1.73924309e-05
Iter: 1137 loss: 1.73820517e-05
Iter: 1138 loss: 1.73635017e-05
Iter: 1139 loss: 1.7806311e-05
Iter: 1140 loss: 1.73636236e-05
Iter: 1141 loss: 1.73495209e-05
Iter: 1142 loss: 1.73491208e-05
Iter: 1143 loss: 1.7336657e-05
Iter: 1144 loss: 1.74391935e-05
Iter: 1145 loss: 1.73355966e-05
Iter: 1146 loss: 1.73278258e-05
Iter: 1147 loss: 1.73155877e-05
Iter: 1148 loss: 1.73149219e-05
Iter: 1149 loss: 1.72997807e-05
Iter: 1150 loss: 1.72883083e-05
Iter: 1151 loss: 1.72838336e-05
Iter: 1152 loss: 1.72622495e-05
Iter: 1153 loss: 1.73111839e-05
Iter: 1154 loss: 1.72540895e-05
Iter: 1155 loss: 1.72333021e-05
Iter: 1156 loss: 1.73662193e-05
Iter: 1157 loss: 1.72308901e-05
Iter: 1158 loss: 1.72140481e-05
Iter: 1159 loss: 1.73836197e-05
Iter: 1160 loss: 1.72134278e-05
Iter: 1161 loss: 1.71991123e-05
Iter: 1162 loss: 1.71863558e-05
Iter: 1163 loss: 1.71827905e-05
Iter: 1164 loss: 1.71673746e-05
Iter: 1165 loss: 1.72351793e-05
Iter: 1166 loss: 1.71639476e-05
Iter: 1167 loss: 1.71475476e-05
Iter: 1168 loss: 1.71821393e-05
Iter: 1169 loss: 1.71406518e-05
Iter: 1170 loss: 1.71226311e-05
Iter: 1171 loss: 1.72329419e-05
Iter: 1172 loss: 1.71205083e-05
Iter: 1173 loss: 1.71070333e-05
Iter: 1174 loss: 1.7104785e-05
Iter: 1175 loss: 1.70954263e-05
Iter: 1176 loss: 1.70802068e-05
Iter: 1177 loss: 1.70799867e-05
Iter: 1178 loss: 1.70696749e-05
Iter: 1179 loss: 1.71771062e-05
Iter: 1180 loss: 1.70695021e-05
Iter: 1181 loss: 1.70645526e-05
Iter: 1182 loss: 1.70519779e-05
Iter: 1183 loss: 1.71537649e-05
Iter: 1184 loss: 1.70492513e-05
Iter: 1185 loss: 1.70306921e-05
Iter: 1186 loss: 1.70614767e-05
Iter: 1187 loss: 1.70221228e-05
Iter: 1188 loss: 1.70036183e-05
Iter: 1189 loss: 1.71160536e-05
Iter: 1190 loss: 1.70013591e-05
Iter: 1191 loss: 1.69864361e-05
Iter: 1192 loss: 1.69991417e-05
Iter: 1193 loss: 1.69767227e-05
Iter: 1194 loss: 1.6960159e-05
Iter: 1195 loss: 1.70150979e-05
Iter: 1196 loss: 1.69558261e-05
Iter: 1197 loss: 1.69387349e-05
Iter: 1198 loss: 1.71222673e-05
Iter: 1199 loss: 1.69385366e-05
Iter: 1200 loss: 1.69284067e-05
Iter: 1201 loss: 1.69094892e-05
Iter: 1202 loss: 1.73468161e-05
Iter: 1203 loss: 1.69095456e-05
Iter: 1204 loss: 1.68886727e-05
Iter: 1205 loss: 1.69522209e-05
Iter: 1206 loss: 1.68822753e-05
Iter: 1207 loss: 1.68673741e-05
Iter: 1208 loss: 1.68671268e-05
Iter: 1209 loss: 1.6855196e-05
Iter: 1210 loss: 1.68511851e-05
Iter: 1211 loss: 1.68447586e-05
Iter: 1212 loss: 1.68366787e-05
Iter: 1213 loss: 1.68351962e-05
Iter: 1214 loss: 1.68257102e-05
Iter: 1215 loss: 1.68194983e-05
Iter: 1216 loss: 1.68154838e-05
Iter: 1217 loss: 1.68054266e-05
Iter: 1218 loss: 1.6795384e-05
Iter: 1219 loss: 1.67932503e-05
Iter: 1220 loss: 1.67755334e-05
Iter: 1221 loss: 1.68615152e-05
Iter: 1222 loss: 1.677197e-05
Iter: 1223 loss: 1.6759197e-05
Iter: 1224 loss: 1.67951875e-05
Iter: 1225 loss: 1.67548551e-05
Iter: 1226 loss: 1.67413236e-05
Iter: 1227 loss: 1.67414746e-05
Iter: 1228 loss: 1.67304624e-05
Iter: 1229 loss: 1.67116e-05
Iter: 1230 loss: 1.68761e-05
Iter: 1231 loss: 1.67104663e-05
Iter: 1232 loss: 1.6698028e-05
Iter: 1233 loss: 1.67639555e-05
Iter: 1234 loss: 1.66966893e-05
Iter: 1235 loss: 1.66840782e-05
Iter: 1236 loss: 1.66795544e-05
Iter: 1237 loss: 1.66731843e-05
Iter: 1238 loss: 1.66554273e-05
Iter: 1239 loss: 1.67038925e-05
Iter: 1240 loss: 1.66497812e-05
Iter: 1241 loss: 1.66345e-05
Iter: 1242 loss: 1.66309983e-05
Iter: 1243 loss: 1.66207774e-05
Iter: 1244 loss: 1.660829e-05
Iter: 1245 loss: 1.66074678e-05
Iter: 1246 loss: 1.65971978e-05
Iter: 1247 loss: 1.66412574e-05
Iter: 1248 loss: 1.65951569e-05
Iter: 1249 loss: 1.65827641e-05
Iter: 1250 loss: 1.66005175e-05
Iter: 1251 loss: 1.65763431e-05
Iter: 1252 loss: 1.6566104e-05
Iter: 1253 loss: 1.65488582e-05
Iter: 1254 loss: 1.6968841e-05
Iter: 1255 loss: 1.65495039e-05
Iter: 1256 loss: 1.65318907e-05
Iter: 1257 loss: 1.6545524e-05
Iter: 1258 loss: 1.65215788e-05
Iter: 1259 loss: 1.65047859e-05
Iter: 1260 loss: 1.67115704e-05
Iter: 1261 loss: 1.65049241e-05
Iter: 1262 loss: 1.64903886e-05
Iter: 1263 loss: 1.65255351e-05
Iter: 1264 loss: 1.64853464e-05
Iter: 1265 loss: 1.64720404e-05
Iter: 1266 loss: 1.64731973e-05
Iter: 1267 loss: 1.64620433e-05
Iter: 1268 loss: 1.64467747e-05
Iter: 1269 loss: 1.66342e-05
Iter: 1270 loss: 1.64471403e-05
Iter: 1271 loss: 1.64339363e-05
Iter: 1272 loss: 1.64558642e-05
Iter: 1273 loss: 1.64285939e-05
Iter: 1274 loss: 1.64150752e-05
Iter: 1275 loss: 1.64271823e-05
Iter: 1276 loss: 1.64068279e-05
Iter: 1277 loss: 1.63922396e-05
Iter: 1278 loss: 1.64370103e-05
Iter: 1279 loss: 1.63882469e-05
Iter: 1280 loss: 1.63746372e-05
Iter: 1281 loss: 1.64087251e-05
Iter: 1282 loss: 1.63694385e-05
Iter: 1283 loss: 1.63639434e-05
Iter: 1284 loss: 1.63625609e-05
Iter: 1285 loss: 1.63545228e-05
Iter: 1286 loss: 1.63440454e-05
Iter: 1287 loss: 1.63434888e-05
Iter: 1288 loss: 1.63287459e-05
Iter: 1289 loss: 1.6362621e-05
Iter: 1290 loss: 1.63231853e-05
Iter: 1291 loss: 1.63136883e-05
Iter: 1292 loss: 1.63098011e-05
Iter: 1293 loss: 1.63043223e-05
Iter: 1294 loss: 1.62867655e-05
Iter: 1295 loss: 1.63002405e-05
Iter: 1296 loss: 1.62759043e-05
Iter: 1297 loss: 1.62575161e-05
Iter: 1298 loss: 1.62682445e-05
Iter: 1299 loss: 1.62456981e-05
Iter: 1300 loss: 1.62283104e-05
Iter: 1301 loss: 1.62282013e-05
Iter: 1302 loss: 1.6216165e-05
Iter: 1303 loss: 1.62794531e-05
Iter: 1304 loss: 1.62137712e-05
Iter: 1305 loss: 1.62032902e-05
Iter: 1306 loss: 1.62087417e-05
Iter: 1307 loss: 1.61957869e-05
Iter: 1308 loss: 1.61818134e-05
Iter: 1309 loss: 1.62878496e-05
Iter: 1310 loss: 1.61807911e-05
Iter: 1311 loss: 1.6171758e-05
Iter: 1312 loss: 1.6152102e-05
Iter: 1313 loss: 1.64716839e-05
Iter: 1314 loss: 1.61518183e-05
Iter: 1315 loss: 1.6129854e-05
Iter: 1316 loss: 1.63035147e-05
Iter: 1317 loss: 1.61285352e-05
Iter: 1318 loss: 1.61245662e-05
Iter: 1319 loss: 1.61195785e-05
Iter: 1320 loss: 1.61142088e-05
Iter: 1321 loss: 1.61061507e-05
Iter: 1322 loss: 1.61061089e-05
Iter: 1323 loss: 1.60943819e-05
Iter: 1324 loss: 1.61001917e-05
Iter: 1325 loss: 1.60873496e-05
Iter: 1326 loss: 1.60750096e-05
Iter: 1327 loss: 1.61165826e-05
Iter: 1328 loss: 1.60718482e-05
Iter: 1329 loss: 1.6059932e-05
Iter: 1330 loss: 1.60606178e-05
Iter: 1331 loss: 1.6049551e-05
Iter: 1332 loss: 1.60334439e-05
Iter: 1333 loss: 1.60751479e-05
Iter: 1334 loss: 1.60270683e-05
Iter: 1335 loss: 1.60091986e-05
Iter: 1336 loss: 1.60388881e-05
Iter: 1337 loss: 1.59999654e-05
Iter: 1338 loss: 1.59848332e-05
Iter: 1339 loss: 1.60802101e-05
Iter: 1340 loss: 1.5983398e-05
Iter: 1341 loss: 1.59686824e-05
Iter: 1342 loss: 1.60618383e-05
Iter: 1343 loss: 1.59678675e-05
Iter: 1344 loss: 1.59558786e-05
Iter: 1345 loss: 1.5983358e-05
Iter: 1346 loss: 1.59521987e-05
Iter: 1347 loss: 1.59410702e-05
Iter: 1348 loss: 1.5954367e-05
Iter: 1349 loss: 1.59363099e-05
Iter: 1350 loss: 1.59225092e-05
Iter: 1351 loss: 1.59596875e-05
Iter: 1352 loss: 1.59175852e-05
Iter: 1353 loss: 1.59134834e-05
Iter: 1354 loss: 1.59116917e-05
Iter: 1355 loss: 1.5905729e-05
Iter: 1356 loss: 1.5889138e-05
Iter: 1357 loss: 1.60339e-05
Iter: 1358 loss: 1.58862094e-05
Iter: 1359 loss: 1.58716648e-05
Iter: 1360 loss: 1.59121573e-05
Iter: 1361 loss: 1.58657313e-05
Iter: 1362 loss: 1.58532457e-05
Iter: 1363 loss: 1.60210875e-05
Iter: 1364 loss: 1.58525218e-05
Iter: 1365 loss: 1.58450894e-05
Iter: 1366 loss: 1.58276362e-05
Iter: 1367 loss: 1.60787749e-05
Iter: 1368 loss: 1.58272105e-05
Iter: 1369 loss: 1.58099392e-05
Iter: 1370 loss: 1.5937434e-05
Iter: 1371 loss: 1.58081675e-05
Iter: 1372 loss: 1.57920695e-05
Iter: 1373 loss: 1.58340445e-05
Iter: 1374 loss: 1.57859049e-05
Iter: 1375 loss: 1.57691466e-05
Iter: 1376 loss: 1.58304647e-05
Iter: 1377 loss: 1.57653703e-05
Iter: 1378 loss: 1.57537615e-05
Iter: 1379 loss: 1.58256953e-05
Iter: 1380 loss: 1.57528029e-05
Iter: 1381 loss: 1.57407685e-05
Iter: 1382 loss: 1.57627728e-05
Iter: 1383 loss: 1.57352952e-05
Iter: 1384 loss: 1.57249578e-05
Iter: 1385 loss: 1.57391314e-05
Iter: 1386 loss: 1.57193535e-05
Iter: 1387 loss: 1.57067625e-05
Iter: 1388 loss: 1.57554423e-05
Iter: 1389 loss: 1.57039431e-05
Iter: 1390 loss: 1.56927272e-05
Iter: 1391 loss: 1.56926326e-05
Iter: 1392 loss: 1.56853966e-05
Iter: 1393 loss: 1.56753158e-05
Iter: 1394 loss: 1.56742753e-05
Iter: 1395 loss: 1.56640308e-05
Iter: 1396 loss: 1.56613733e-05
Iter: 1397 loss: 1.56553378e-05
Iter: 1398 loss: 1.56430342e-05
Iter: 1399 loss: 1.57522027e-05
Iter: 1400 loss: 1.56423812e-05
Iter: 1401 loss: 1.56307215e-05
Iter: 1402 loss: 1.56438873e-05
Iter: 1403 loss: 1.5624646e-05
Iter: 1404 loss: 1.56098613e-05
Iter: 1405 loss: 1.56077076e-05
Iter: 1406 loss: 1.5598e-05
Iter: 1407 loss: 1.55828093e-05
Iter: 1408 loss: 1.56025853e-05
Iter: 1409 loss: 1.55745656e-05
Iter: 1410 loss: 1.55531252e-05
Iter: 1411 loss: 1.56211936e-05
Iter: 1412 loss: 1.55474081e-05
Iter: 1413 loss: 1.55317375e-05
Iter: 1414 loss: 1.56688056e-05
Iter: 1415 loss: 1.55314592e-05
Iter: 1416 loss: 1.55158614e-05
Iter: 1417 loss: 1.55568541e-05
Iter: 1418 loss: 1.55110611e-05
Iter: 1419 loss: 1.55000653e-05
Iter: 1420 loss: 1.55501475e-05
Iter: 1421 loss: 1.5497284e-05
Iter: 1422 loss: 1.54869158e-05
Iter: 1423 loss: 1.54932914e-05
Iter: 1424 loss: 1.54806658e-05
Iter: 1425 loss: 1.5472031e-05
Iter: 1426 loss: 1.54711288e-05
Iter: 1427 loss: 1.5467278e-05
Iter: 1428 loss: 1.54546451e-05
Iter: 1429 loss: 1.54987356e-05
Iter: 1430 loss: 1.54491136e-05
Iter: 1431 loss: 1.5432086e-05
Iter: 1432 loss: 1.55824036e-05
Iter: 1433 loss: 1.54306581e-05
Iter: 1434 loss: 1.54198315e-05
Iter: 1435 loss: 1.54327317e-05
Iter: 1436 loss: 1.54141817e-05
Iter: 1437 loss: 1.54002846e-05
Iter: 1438 loss: 1.54730169e-05
Iter: 1439 loss: 1.53974761e-05
Iter: 1440 loss: 1.53850378e-05
Iter: 1441 loss: 1.53816018e-05
Iter: 1442 loss: 1.53743895e-05
Iter: 1443 loss: 1.53588e-05
Iter: 1444 loss: 1.53763394e-05
Iter: 1445 loss: 1.5350106e-05
Iter: 1446 loss: 1.53287401e-05
Iter: 1447 loss: 1.53971741e-05
Iter: 1448 loss: 1.53228757e-05
Iter: 1449 loss: 1.53080073e-05
Iter: 1450 loss: 1.53573164e-05
Iter: 1451 loss: 1.53034453e-05
Iter: 1452 loss: 1.52877437e-05
Iter: 1453 loss: 1.54604732e-05
Iter: 1454 loss: 1.5287118e-05
Iter: 1455 loss: 1.52767989e-05
Iter: 1456 loss: 1.52894245e-05
Iter: 1457 loss: 1.52712892e-05
Iter: 1458 loss: 1.52633202e-05
Iter: 1459 loss: 1.5357653e-05
Iter: 1460 loss: 1.52634384e-05
Iter: 1461 loss: 1.52531256e-05
Iter: 1462 loss: 1.52460179e-05
Iter: 1463 loss: 1.52430821e-05
Iter: 1464 loss: 1.52321318e-05
Iter: 1465 loss: 1.52445755e-05
Iter: 1466 loss: 1.52261282e-05
Iter: 1467 loss: 1.52141738e-05
Iter: 1468 loss: 1.5209208e-05
Iter: 1469 loss: 1.52022194e-05
Iter: 1470 loss: 1.51895492e-05
Iter: 1471 loss: 1.51896766e-05
Iter: 1472 loss: 1.51799086e-05
Iter: 1473 loss: 1.51894174e-05
Iter: 1474 loss: 1.51751383e-05
Iter: 1475 loss: 1.51635286e-05
Iter: 1476 loss: 1.51871036e-05
Iter: 1477 loss: 1.51584209e-05
Iter: 1478 loss: 1.51444538e-05
Iter: 1479 loss: 1.51582117e-05
Iter: 1480 loss: 1.51365748e-05
Iter: 1481 loss: 1.51205359e-05
Iter: 1482 loss: 1.51277209e-05
Iter: 1483 loss: 1.51103886e-05
Iter: 1484 loss: 1.50920214e-05
Iter: 1485 loss: 1.51413133e-05
Iter: 1486 loss: 1.50861915e-05
Iter: 1487 loss: 1.50750375e-05
Iter: 1488 loss: 1.50746037e-05
Iter: 1489 loss: 1.50636306e-05
Iter: 1490 loss: 1.50795495e-05
Iter: 1491 loss: 1.50575852e-05
Iter: 1492 loss: 1.50519409e-05
Iter: 1493 loss: 1.50511614e-05
Iter: 1494 loss: 1.50449396e-05
Iter: 1495 loss: 1.50308597e-05
Iter: 1496 loss: 1.52550256e-05
Iter: 1497 loss: 1.50307214e-05
Iter: 1498 loss: 1.50190463e-05
Iter: 1499 loss: 1.50424139e-05
Iter: 1500 loss: 1.50141223e-05
Iter: 1501 loss: 1.5002006e-05
Iter: 1502 loss: 1.50368014e-05
Iter: 1503 loss: 1.49985408e-05
Iter: 1504 loss: 1.49861153e-05
Iter: 1505 loss: 1.502327e-05
Iter: 1506 loss: 1.49818334e-05
Iter: 1507 loss: 1.4971426e-05
Iter: 1508 loss: 1.50216601e-05
Iter: 1509 loss: 1.49697935e-05
Iter: 1510 loss: 1.49581701e-05
Iter: 1511 loss: 1.49582047e-05
Iter: 1512 loss: 1.49487796e-05
Iter: 1513 loss: 1.49357129e-05
Iter: 1514 loss: 1.49951356e-05
Iter: 1515 loss: 1.49332609e-05
Iter: 1516 loss: 1.49209618e-05
Iter: 1517 loss: 1.49309362e-05
Iter: 1518 loss: 1.49134949e-05
Iter: 1519 loss: 1.4898691e-05
Iter: 1520 loss: 1.4967959e-05
Iter: 1521 loss: 1.48956105e-05
Iter: 1522 loss: 1.48851423e-05
Iter: 1523 loss: 1.48867493e-05
Iter: 1524 loss: 1.48763047e-05
Iter: 1525 loss: 1.48629942e-05
Iter: 1526 loss: 1.50269207e-05
Iter: 1527 loss: 1.48629961e-05
Iter: 1528 loss: 1.48530362e-05
Iter: 1529 loss: 1.49820144e-05
Iter: 1530 loss: 1.48529452e-05
Iter: 1531 loss: 1.48474383e-05
Iter: 1532 loss: 1.48610025e-05
Iter: 1533 loss: 1.48458603e-05
Iter: 1534 loss: 1.48409e-05
Iter: 1535 loss: 1.48272193e-05
Iter: 1536 loss: 1.4909092e-05
Iter: 1537 loss: 1.48234922e-05
Iter: 1538 loss: 1.48085765e-05
Iter: 1539 loss: 1.48725185e-05
Iter: 1540 loss: 1.48052713e-05
Iter: 1541 loss: 1.47917544e-05
Iter: 1542 loss: 1.48703493e-05
Iter: 1543 loss: 1.47902219e-05
Iter: 1544 loss: 1.47776291e-05
Iter: 1545 loss: 1.48126892e-05
Iter: 1546 loss: 1.47734563e-05
Iter: 1547 loss: 1.47607952e-05
Iter: 1548 loss: 1.47892306e-05
Iter: 1549 loss: 1.47555711e-05
Iter: 1550 loss: 1.474278e-05
Iter: 1551 loss: 1.47851233e-05
Iter: 1552 loss: 1.4739755e-05
Iter: 1553 loss: 1.47271894e-05
Iter: 1554 loss: 1.47905821e-05
Iter: 1555 loss: 1.4726118e-05
Iter: 1556 loss: 1.47142273e-05
Iter: 1557 loss: 1.47169612e-05
Iter: 1558 loss: 1.47054761e-05
Iter: 1559 loss: 1.4692976e-05
Iter: 1560 loss: 1.4762225e-05
Iter: 1561 loss: 1.46907296e-05
Iter: 1562 loss: 1.46790208e-05
Iter: 1563 loss: 1.46767115e-05
Iter: 1564 loss: 1.46684743e-05
Iter: 1565 loss: 1.46672792e-05
Iter: 1566 loss: 1.46617967e-05
Iter: 1567 loss: 1.46546299e-05
Iter: 1568 loss: 1.46422781e-05
Iter: 1569 loss: 1.46424854e-05
Iter: 1570 loss: 1.4630803e-05
Iter: 1571 loss: 1.46223556e-05
Iter: 1572 loss: 1.46183447e-05
Iter: 1573 loss: 1.46026932e-05
Iter: 1574 loss: 1.46265811e-05
Iter: 1575 loss: 1.45946506e-05
Iter: 1576 loss: 1.45842014e-05
Iter: 1577 loss: 1.45828672e-05
Iter: 1578 loss: 1.45751528e-05
Iter: 1579 loss: 1.45697504e-05
Iter: 1580 loss: 1.45665108e-05
Iter: 1581 loss: 1.45531949e-05
Iter: 1582 loss: 1.45690292e-05
Iter: 1583 loss: 1.45467748e-05
Iter: 1584 loss: 1.45331869e-05
Iter: 1585 loss: 1.46212915e-05
Iter: 1586 loss: 1.45312652e-05
Iter: 1587 loss: 1.45204995e-05
Iter: 1588 loss: 1.45296035e-05
Iter: 1589 loss: 1.45145486e-05
Iter: 1590 loss: 1.45013619e-05
Iter: 1591 loss: 1.45329423e-05
Iter: 1592 loss: 1.44961596e-05
Iter: 1593 loss: 1.44823798e-05
Iter: 1594 loss: 1.45264403e-05
Iter: 1595 loss: 1.44784335e-05
Iter: 1596 loss: 1.44660398e-05
Iter: 1597 loss: 1.45542845e-05
Iter: 1598 loss: 1.44648793e-05
Iter: 1599 loss: 1.44573869e-05
Iter: 1600 loss: 1.44572296e-05
Iter: 1601 loss: 1.44527457e-05
Iter: 1602 loss: 1.44445694e-05
Iter: 1603 loss: 1.46116e-05
Iter: 1604 loss: 1.44441492e-05
Iter: 1605 loss: 1.44327623e-05
Iter: 1606 loss: 1.44704063e-05
Iter: 1607 loss: 1.44299511e-05
Iter: 1608 loss: 1.44199676e-05
Iter: 1609 loss: 1.44124588e-05
Iter: 1610 loss: 1.44089408e-05
Iter: 1611 loss: 1.43936759e-05
Iter: 1612 loss: 1.44111254e-05
Iter: 1613 loss: 1.43859761e-05
Iter: 1614 loss: 1.43720208e-05
Iter: 1615 loss: 1.4585672e-05
Iter: 1616 loss: 1.43724546e-05
Iter: 1617 loss: 1.43609795e-05
Iter: 1618 loss: 1.44053411e-05
Iter: 1619 loss: 1.43584166e-05
Iter: 1620 loss: 1.43478301e-05
Iter: 1621 loss: 1.43316047e-05
Iter: 1622 loss: 1.43311108e-05
Iter: 1623 loss: 1.43160642e-05
Iter: 1624 loss: 1.43964e-05
Iter: 1625 loss: 1.43130837e-05
Iter: 1626 loss: 1.42977542e-05
Iter: 1627 loss: 1.43746438e-05
Iter: 1628 loss: 1.4294973e-05
Iter: 1629 loss: 1.42837889e-05
Iter: 1630 loss: 1.43193693e-05
Iter: 1631 loss: 1.42802892e-05
Iter: 1632 loss: 1.42706358e-05
Iter: 1633 loss: 1.43236994e-05
Iter: 1634 loss: 1.42685867e-05
Iter: 1635 loss: 1.42566869e-05
Iter: 1636 loss: 1.43419575e-05
Iter: 1637 loss: 1.42555364e-05
Iter: 1638 loss: 1.42488007e-05
Iter: 1639 loss: 1.42394983e-05
Iter: 1640 loss: 1.42389626e-05
Iter: 1641 loss: 1.4228247e-05
Iter: 1642 loss: 1.42496438e-05
Iter: 1643 loss: 1.42239642e-05
Iter: 1644 loss: 1.4211686e-05
Iter: 1645 loss: 1.42533754e-05
Iter: 1646 loss: 1.42083845e-05
Iter: 1647 loss: 1.41970777e-05
Iter: 1648 loss: 1.42456865e-05
Iter: 1649 loss: 1.4194351e-05
Iter: 1650 loss: 1.41839209e-05
Iter: 1651 loss: 1.41787368e-05
Iter: 1652 loss: 1.41744204e-05
Iter: 1653 loss: 1.4159149e-05
Iter: 1654 loss: 1.41709361e-05
Iter: 1655 loss: 1.41502023e-05
Iter: 1656 loss: 1.41373603e-05
Iter: 1657 loss: 1.41374603e-05
Iter: 1658 loss: 1.41260089e-05
Iter: 1659 loss: 1.41423861e-05
Iter: 1660 loss: 1.41207829e-05
Iter: 1661 loss: 1.41104e-05
Iter: 1662 loss: 1.40963875e-05
Iter: 1663 loss: 1.40954589e-05
Iter: 1664 loss: 1.40785896e-05
Iter: 1665 loss: 1.42212666e-05
Iter: 1666 loss: 1.40777611e-05
Iter: 1667 loss: 1.40661941e-05
Iter: 1668 loss: 1.41628398e-05
Iter: 1669 loss: 1.40662414e-05
Iter: 1670 loss: 1.40542115e-05
Iter: 1671 loss: 1.4131122e-05
Iter: 1672 loss: 1.40528473e-05
Iter: 1673 loss: 1.40457e-05
Iter: 1674 loss: 1.4038309e-05
Iter: 1675 loss: 1.40371503e-05
Iter: 1676 loss: 1.40274169e-05
Iter: 1677 loss: 1.40237635e-05
Iter: 1678 loss: 1.40186321e-05
Iter: 1679 loss: 1.40028787e-05
Iter: 1680 loss: 1.40989114e-05
Iter: 1681 loss: 1.40017073e-05
Iter: 1682 loss: 1.39910107e-05
Iter: 1683 loss: 1.40023885e-05
Iter: 1684 loss: 1.39846434e-05
Iter: 1685 loss: 1.39704262e-05
Iter: 1686 loss: 1.40185148e-05
Iter: 1687 loss: 1.39666881e-05
Iter: 1688 loss: 1.39552667e-05
Iter: 1689 loss: 1.40743823e-05
Iter: 1690 loss: 1.39550175e-05
Iter: 1691 loss: 1.39471331e-05
Iter: 1692 loss: 1.39367676e-05
Iter: 1693 loss: 1.39360318e-05
Iter: 1694 loss: 1.39200774e-05
Iter: 1695 loss: 1.39548301e-05
Iter: 1696 loss: 1.39136991e-05
Iter: 1697 loss: 1.3902827e-05
Iter: 1698 loss: 1.39030599e-05
Iter: 1699 loss: 1.38921987e-05
Iter: 1700 loss: 1.38805717e-05
Iter: 1701 loss: 1.38786581e-05
Iter: 1702 loss: 1.38657706e-05
Iter: 1703 loss: 1.39042813e-05
Iter: 1704 loss: 1.38619962e-05
Iter: 1705 loss: 1.38557371e-05
Iter: 1706 loss: 1.38531823e-05
Iter: 1707 loss: 1.38488967e-05
Iter: 1708 loss: 1.3835348e-05
Iter: 1709 loss: 1.38908053e-05
Iter: 1710 loss: 1.38300029e-05
Iter: 1711 loss: 1.38149826e-05
Iter: 1712 loss: 1.39668218e-05
Iter: 1713 loss: 1.38144624e-05
Iter: 1714 loss: 1.3804528e-05
Iter: 1715 loss: 1.38156756e-05
Iter: 1716 loss: 1.37992238e-05
Iter: 1717 loss: 1.37863481e-05
Iter: 1718 loss: 1.38204205e-05
Iter: 1719 loss: 1.37825418e-05
Iter: 1720 loss: 1.37699917e-05
Iter: 1721 loss: 1.37975967e-05
Iter: 1722 loss: 1.37653842e-05
Iter: 1723 loss: 1.37526467e-05
Iter: 1724 loss: 1.38017995e-05
Iter: 1725 loss: 1.37492425e-05
Iter: 1726 loss: 1.37383249e-05
Iter: 1727 loss: 1.37486422e-05
Iter: 1728 loss: 1.37314273e-05
Iter: 1729 loss: 1.371896e-05
Iter: 1730 loss: 1.38607093e-05
Iter: 1731 loss: 1.37183706e-05
Iter: 1732 loss: 1.37090829e-05
Iter: 1733 loss: 1.37047555e-05
Iter: 1734 loss: 1.37005482e-05
Iter: 1735 loss: 1.36866165e-05
Iter: 1736 loss: 1.37171273e-05
Iter: 1737 loss: 1.36812423e-05
Iter: 1738 loss: 1.36726358e-05
Iter: 1739 loss: 1.37953275e-05
Iter: 1740 loss: 1.36716626e-05
Iter: 1741 loss: 1.36623466e-05
Iter: 1742 loss: 1.3655258e-05
Iter: 1743 loss: 1.36516437e-05
Iter: 1744 loss: 1.36417711e-05
Iter: 1745 loss: 1.37396255e-05
Iter: 1746 loss: 1.3640828e-05
Iter: 1747 loss: 1.36298968e-05
Iter: 1748 loss: 1.36711442e-05
Iter: 1749 loss: 1.36267827e-05
Iter: 1750 loss: 1.36211856e-05
Iter: 1751 loss: 1.36046565e-05
Iter: 1752 loss: 1.36844319e-05
Iter: 1753 loss: 1.35991741e-05
Iter: 1754 loss: 1.35826513e-05
Iter: 1755 loss: 1.37135539e-05
Iter: 1756 loss: 1.35821092e-05
Iter: 1757 loss: 1.35671044e-05
Iter: 1758 loss: 1.36361059e-05
Iter: 1759 loss: 1.35641021e-05
Iter: 1760 loss: 1.35526334e-05
Iter: 1761 loss: 1.35953878e-05
Iter: 1762 loss: 1.3550085e-05
Iter: 1763 loss: 1.35385981e-05
Iter: 1764 loss: 1.35438404e-05
Iter: 1765 loss: 1.35309401e-05
Iter: 1766 loss: 1.35184473e-05
Iter: 1767 loss: 1.36550088e-05
Iter: 1768 loss: 1.35181381e-05
Iter: 1769 loss: 1.35096425e-05
Iter: 1770 loss: 1.35210612e-05
Iter: 1771 loss: 1.35047276e-05
Iter: 1772 loss: 1.34931452e-05
Iter: 1773 loss: 1.35186619e-05
Iter: 1774 loss: 1.34884422e-05
Iter: 1775 loss: 1.34771435e-05
Iter: 1776 loss: 1.35294731e-05
Iter: 1777 loss: 1.34758038e-05
Iter: 1778 loss: 1.34672755e-05
Iter: 1779 loss: 1.3469883e-05
Iter: 1780 loss: 1.34609145e-05
Iter: 1781 loss: 1.34529546e-05
Iter: 1782 loss: 1.345289e-05
Iter: 1783 loss: 1.34456832e-05
Iter: 1784 loss: 1.34677839e-05
Iter: 1785 loss: 1.34436978e-05
Iter: 1786 loss: 1.34373322e-05
Iter: 1787 loss: 1.34343081e-05
Iter: 1788 loss: 1.34304792e-05
Iter: 1789 loss: 1.34224138e-05
Iter: 1790 loss: 1.34068232e-05
Iter: 1791 loss: 1.37605557e-05
Iter: 1792 loss: 1.34074407e-05
Iter: 1793 loss: 1.33914609e-05
Iter: 1794 loss: 1.34850188e-05
Iter: 1795 loss: 1.3389561e-05
Iter: 1796 loss: 1.33761332e-05
Iter: 1797 loss: 1.34025177e-05
Iter: 1798 loss: 1.33700496e-05
Iter: 1799 loss: 1.33575259e-05
Iter: 1800 loss: 1.34608945e-05
Iter: 1801 loss: 1.3356972e-05
Iter: 1802 loss: 1.33455824e-05
Iter: 1803 loss: 1.33641151e-05
Iter: 1804 loss: 1.33405683e-05
Iter: 1805 loss: 1.33303893e-05
Iter: 1806 loss: 1.33674239e-05
Iter: 1807 loss: 1.33276772e-05
Iter: 1808 loss: 1.33168305e-05
Iter: 1809 loss: 1.33688582e-05
Iter: 1810 loss: 1.33148706e-05
Iter: 1811 loss: 1.33073845e-05
Iter: 1812 loss: 1.3324503e-05
Iter: 1813 loss: 1.33041813e-05
Iter: 1814 loss: 1.32953983e-05
Iter: 1815 loss: 1.33104322e-05
Iter: 1816 loss: 1.32918649e-05
Iter: 1817 loss: 1.32813348e-05
Iter: 1818 loss: 1.32957039e-05
Iter: 1819 loss: 1.32756213e-05
Iter: 1820 loss: 1.32699934e-05
Iter: 1821 loss: 1.32683899e-05
Iter: 1822 loss: 1.32633604e-05
Iter: 1823 loss: 1.32620735e-05
Iter: 1824 loss: 1.32598489e-05
Iter: 1825 loss: 1.32519717e-05
Iter: 1826 loss: 1.32427404e-05
Iter: 1827 loss: 1.32410623e-05
Iter: 1828 loss: 1.32292971e-05
Iter: 1829 loss: 1.32670166e-05
Iter: 1830 loss: 1.32248833e-05
Iter: 1831 loss: 1.32153746e-05
Iter: 1832 loss: 1.32045352e-05
Iter: 1833 loss: 1.32030036e-05
Iter: 1834 loss: 1.3187534e-05
Iter: 1835 loss: 1.32592613e-05
Iter: 1836 loss: 1.31844417e-05
Iter: 1837 loss: 1.31700817e-05
Iter: 1838 loss: 1.33045978e-05
Iter: 1839 loss: 1.31692395e-05
Iter: 1840 loss: 1.31586985e-05
Iter: 1841 loss: 1.31748211e-05
Iter: 1842 loss: 1.31543029e-05
Iter: 1843 loss: 1.31429515e-05
Iter: 1844 loss: 1.31902734e-05
Iter: 1845 loss: 1.31405322e-05
Iter: 1846 loss: 1.31289853e-05
Iter: 1847 loss: 1.3163798e-05
Iter: 1848 loss: 1.31251554e-05
Iter: 1849 loss: 1.31150582e-05
Iter: 1850 loss: 1.31234947e-05
Iter: 1851 loss: 1.31095394e-05
Iter: 1852 loss: 1.30971475e-05
Iter: 1853 loss: 1.31683682e-05
Iter: 1854 loss: 1.30951857e-05
Iter: 1855 loss: 1.30899734e-05
Iter: 1856 loss: 1.30894705e-05
Iter: 1857 loss: 1.30837307e-05
Iter: 1858 loss: 1.30731623e-05
Iter: 1859 loss: 1.32586729e-05
Iter: 1860 loss: 1.30734243e-05
Iter: 1861 loss: 1.3060695e-05
Iter: 1862 loss: 1.31188972e-05
Iter: 1863 loss: 1.30577937e-05
Iter: 1864 loss: 1.30480557e-05
Iter: 1865 loss: 1.3050254e-05
Iter: 1866 loss: 1.30411263e-05
Iter: 1867 loss: 1.30289645e-05
Iter: 1868 loss: 1.30238714e-05
Iter: 1869 loss: 1.30181934e-05
Iter: 1870 loss: 1.30016833e-05
Iter: 1871 loss: 1.31318684e-05
Iter: 1872 loss: 1.30005646e-05
Iter: 1873 loss: 1.29888031e-05
Iter: 1874 loss: 1.29825476e-05
Iter: 1875 loss: 1.29770378e-05
Iter: 1876 loss: 1.29629989e-05
Iter: 1877 loss: 1.2962957e-05
Iter: 1878 loss: 1.29538221e-05
Iter: 1879 loss: 1.29723912e-05
Iter: 1880 loss: 1.29509617e-05
Iter: 1881 loss: 1.29390337e-05
Iter: 1882 loss: 1.29534092e-05
Iter: 1883 loss: 1.29337159e-05
Iter: 1884 loss: 1.29222444e-05
Iter: 1885 loss: 1.3023574e-05
Iter: 1886 loss: 1.2921505e-05
Iter: 1887 loss: 1.29140481e-05
Iter: 1888 loss: 1.29017644e-05
Iter: 1889 loss: 1.29014497e-05
Iter: 1890 loss: 1.28968222e-05
Iter: 1891 loss: 1.28928041e-05
Iter: 1892 loss: 1.28862921e-05
Iter: 1893 loss: 1.29129248e-05
Iter: 1894 loss: 1.28858946e-05
Iter: 1895 loss: 1.28813899e-05
Iter: 1896 loss: 1.28735501e-05
Iter: 1897 loss: 1.28736683e-05
Iter: 1898 loss: 1.28630763e-05
Iter: 1899 loss: 1.29166683e-05
Iter: 1900 loss: 1.2862014e-05
Iter: 1901 loss: 1.28527881e-05
Iter: 1902 loss: 1.28450301e-05
Iter: 1903 loss: 1.28436805e-05
Iter: 1904 loss: 1.28312513e-05
Iter: 1905 loss: 1.28619668e-05
Iter: 1906 loss: 1.28273741e-05
Iter: 1907 loss: 1.2815126e-05
Iter: 1908 loss: 1.28261154e-05
Iter: 1909 loss: 1.28086976e-05
Iter: 1910 loss: 1.27945978e-05
Iter: 1911 loss: 1.28929851e-05
Iter: 1912 loss: 1.27928179e-05
Iter: 1913 loss: 1.27819321e-05
Iter: 1914 loss: 1.28018874e-05
Iter: 1915 loss: 1.27769526e-05
Iter: 1916 loss: 1.27647436e-05
Iter: 1917 loss: 1.28731153e-05
Iter: 1918 loss: 1.27643134e-05
Iter: 1919 loss: 1.27563944e-05
Iter: 1920 loss: 1.27704516e-05
Iter: 1921 loss: 1.27525554e-05
Iter: 1922 loss: 1.27435687e-05
Iter: 1923 loss: 1.27660605e-05
Iter: 1924 loss: 1.27397925e-05
Iter: 1925 loss: 1.27304274e-05
Iter: 1926 loss: 1.27536623e-05
Iter: 1927 loss: 1.27272551e-05
Iter: 1928 loss: 1.27237836e-05
Iter: 1929 loss: 1.27231551e-05
Iter: 1930 loss: 1.27190497e-05
Iter: 1931 loss: 1.27132944e-05
Iter: 1932 loss: 1.27124931e-05
Iter: 1933 loss: 1.27036637e-05
Iter: 1934 loss: 1.27108224e-05
Iter: 1935 loss: 1.2698034e-05
Iter: 1936 loss: 1.26895593e-05
Iter: 1937 loss: 1.27354269e-05
Iter: 1938 loss: 1.26887135e-05
Iter: 1939 loss: 1.26804225e-05
Iter: 1940 loss: 1.26705017e-05
Iter: 1941 loss: 1.26698915e-05
Iter: 1942 loss: 1.26572868e-05
Iter: 1943 loss: 1.27075e-05
Iter: 1944 loss: 1.26540144e-05
Iter: 1945 loss: 1.26437317e-05
Iter: 1946 loss: 1.26386403e-05
Iter: 1947 loss: 1.2633589e-05
Iter: 1948 loss: 1.26202958e-05
Iter: 1949 loss: 1.27583553e-05
Iter: 1950 loss: 1.26200694e-05
Iter: 1951 loss: 1.26091e-05
Iter: 1952 loss: 1.26090417e-05
Iter: 1953 loss: 1.26002269e-05
Iter: 1954 loss: 1.25894203e-05
Iter: 1955 loss: 1.25898787e-05
Iter: 1956 loss: 1.25812367e-05
Iter: 1957 loss: 1.25831648e-05
Iter: 1958 loss: 1.25759207e-05
Iter: 1959 loss: 1.25642391e-05
Iter: 1960 loss: 1.26202649e-05
Iter: 1961 loss: 1.256207e-05
Iter: 1962 loss: 1.25562165e-05
Iter: 1963 loss: 1.25559181e-05
Iter: 1964 loss: 1.25509596e-05
Iter: 1965 loss: 1.25642391e-05
Iter: 1966 loss: 1.25491406e-05
Iter: 1967 loss: 1.2543378e-05
Iter: 1968 loss: 1.25364786e-05
Iter: 1969 loss: 1.25353035e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.8/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi3
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi3
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi3 /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi3
+ date
Sun Nov  8 05:42:50 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi3/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi2.8/300_100_100_100_1 --function f1 --psi 1 --phi 3 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi3/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2790737620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f279083b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f279076b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2790774e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27907777b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27907778c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f279063ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27906a1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27906a1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27906808c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f279057f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f279060d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f279060d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27905c58c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27906d32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27906dad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27906a4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27906a4e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f276f01b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f276f001620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f276efd7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f276efd7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f276f0b2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27486fd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27486fd400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27486b57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27486cef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f276ef91620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f276ef91400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2748674400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27485b2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27485ba488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27486452f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f274862ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27485288c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f27485f1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0072123995
test_loss: 0.008718912
train_loss: 0.0072930604
test_loss: 0.008143232
train_loss: 0.006551213
test_loss: 0.0076518445
train_loss: 0.006441033
test_loss: 0.007732162
train_loss: 0.006582275
test_loss: 0.007861851
train_loss: 0.0068014795
test_loss: 0.008027868
train_loss: 0.006437473
test_loss: 0.007540293
train_loss: 0.006591413
test_loss: 0.0076353317
train_loss: 0.006537257
test_loss: 0.0075045153
train_loss: 0.006631357
test_loss: 0.0075563164
train_loss: 0.0062718275
test_loss: 0.0072389366
train_loss: 0.0062989597
test_loss: 0.0072216825
train_loss: 0.00597429
test_loss: 0.007313253
train_loss: 0.006015334
test_loss: 0.007318999
train_loss: 0.0060405773
test_loss: 0.0073346035
train_loss: 0.0061131557
test_loss: 0.0070409058
train_loss: 0.006802081
test_loss: 0.0070843156
train_loss: 0.0061505926
test_loss: 0.007724424
train_loss: 0.0058439085
test_loss: 0.0070692543
train_loss: 0.0056716446
test_loss: 0.0071239374
train_loss: 0.005584427
test_loss: 0.0070086345
train_loss: 0.005904691
test_loss: 0.0069462773
train_loss: 0.0061070872
test_loss: 0.006806469
train_loss: 0.0055185836
test_loss: 0.0068298574
train_loss: 0.006542262
test_loss: 0.0068836925
train_loss: 0.005871218
test_loss: 0.007589026
train_loss: 0.0059528556
test_loss: 0.0067672417
train_loss: 0.00612613
test_loss: 0.007040937
train_loss: 0.005604279
test_loss: 0.00696821
train_loss: 0.0058537247
test_loss: 0.0068014553
train_loss: 0.005851512
test_loss: 0.0067703845
train_loss: 0.0055763014
test_loss: 0.0069657364
train_loss: 0.0056714388
test_loss: 0.006807036
train_loss: 0.0058738566
test_loss: 0.0071702385
train_loss: 0.0059367022
test_loss: 0.006924921
train_loss: 0.005603531
test_loss: 0.0068871025
train_loss: 0.005975359
test_loss: 0.007144407
train_loss: 0.00540864
test_loss: 0.0067731054
train_loss: 0.0055351676
test_loss: 0.0065985
train_loss: 0.0056074345
test_loss: 0.006405843
train_loss: 0.0054618106
test_loss: 0.0065521086
train_loss: 0.0055615283
test_loss: 0.0074711847
train_loss: 0.004985947
test_loss: 0.0065414365
train_loss: 0.0057637235
test_loss: 0.006660004
train_loss: 0.006065461
test_loss: 0.0066635413
train_loss: 0.0050693746
test_loss: 0.006590101
train_loss: 0.0053026145
test_loss: 0.006337135
train_loss: 0.0052342154
test_loss: 0.0064720456
train_loss: 0.0052771512
test_loss: 0.006533339
train_loss: 0.0054987264
test_loss: 0.0063440227
train_loss: 0.0053889654
test_loss: 0.006327248
train_loss: 0.005447072
test_loss: 0.0062842523
train_loss: 0.005003594
test_loss: 0.0063088085
train_loss: 0.005473465
test_loss: 0.0062785153
train_loss: 0.004977392
test_loss: 0.0063482737
train_loss: 0.0054449514
test_loss: 0.0066224043
train_loss: 0.0054329867
test_loss: 0.006735321
train_loss: 0.0050725816
test_loss: 0.006176115
train_loss: 0.005083515
test_loss: 0.0063935337
train_loss: 0.0056383545
test_loss: 0.006533432
train_loss: 0.0050597037
test_loss: 0.006248944
train_loss: 0.0051272847
test_loss: 0.0061815083
train_loss: 0.005479165
test_loss: 0.006393092
train_loss: 0.004941628
test_loss: 0.006158168
train_loss: 0.0053891446
test_loss: 0.0063190274
train_loss: 0.004949439
test_loss: 0.0060357247
train_loss: 0.004923703
test_loss: 0.006181383
train_loss: 0.0050096903
test_loss: 0.0063154963
train_loss: 0.0050798636
test_loss: 0.0062301857
train_loss: 0.0044173044
test_loss: 0.0059157205
train_loss: 0.0050795097
test_loss: 0.00629936
train_loss: 0.0048519555
test_loss: 0.006208533
train_loss: 0.0050668297
test_loss: 0.006150894
train_loss: 0.004578692
test_loss: 0.0059466935
train_loss: 0.004926144
test_loss: 0.0060206633
train_loss: 0.0048324848
test_loss: 0.0062430464
train_loss: 0.0047235666
test_loss: 0.0061230124
train_loss: 0.005076752
test_loss: 0.0061472
train_loss: 0.0046520066
test_loss: 0.005952305
train_loss: 0.005113303
test_loss: 0.0062635215
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi3/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi3/300_100_100_100_1 --optimizer lbfgs --function f1 --psi 1 --phi 3 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f1_psi1_phi3/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb835848d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb835893f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb835848158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8357b61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8357e7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8357e7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb835754ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8356d3840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8356d3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8356ebd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8356a4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8356ea620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb83566cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8355f1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8355b99d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8355cad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8355ee6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8355b9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb83553d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb81634f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb816362510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb816302ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb816334950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8162e6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8162e6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb81628b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb81624b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb81625f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8161ff620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb81621f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8161cc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8161f61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8161ccae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8161b26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb81615b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8160fd1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.50217922e-05
Iter: 2 loss: 3.96548821e-05
Iter: 3 loss: 3.8944454e-05
Iter: 4 loss: 3.52666611e-05
Iter: 5 loss: 5.28547316e-05
Iter: 6 loss: 3.46166307e-05
Iter: 7 loss: 3.30147e-05
Iter: 8 loss: 3.09103198e-05
Iter: 9 loss: 3.0779076e-05
Iter: 10 loss: 2.84201615e-05
Iter: 11 loss: 4.25392427e-05
Iter: 12 loss: 2.8124754e-05
Iter: 13 loss: 2.66943716e-05
Iter: 14 loss: 2.73564165e-05
Iter: 15 loss: 2.57271568e-05
Iter: 16 loss: 2.36379474e-05
Iter: 17 loss: 3.68251e-05
Iter: 18 loss: 2.33959763e-05
Iter: 19 loss: 2.22761719e-05
Iter: 20 loss: 2.62964822e-05
Iter: 21 loss: 2.19913745e-05
Iter: 22 loss: 2.09428435e-05
Iter: 23 loss: 2.29812231e-05
Iter: 24 loss: 2.05099586e-05
Iter: 25 loss: 1.9560237e-05
Iter: 26 loss: 2.14040338e-05
Iter: 27 loss: 1.9164363e-05
Iter: 28 loss: 1.84660512e-05
Iter: 29 loss: 2.02446026e-05
Iter: 30 loss: 1.82245112e-05
Iter: 31 loss: 1.75608275e-05
Iter: 32 loss: 1.89431594e-05
Iter: 33 loss: 1.72971886e-05
Iter: 34 loss: 1.65912097e-05
Iter: 35 loss: 2.03370892e-05
Iter: 36 loss: 1.64826524e-05
Iter: 37 loss: 1.60845266e-05
Iter: 38 loss: 1.79681701e-05
Iter: 39 loss: 1.60125619e-05
Iter: 40 loss: 1.57586401e-05
Iter: 41 loss: 1.57331451e-05
Iter: 42 loss: 1.55701018e-05
Iter: 43 loss: 1.52162565e-05
Iter: 44 loss: 2.06209079e-05
Iter: 45 loss: 1.52023586e-05
Iter: 46 loss: 1.49066527e-05
Iter: 47 loss: 1.55061025e-05
Iter: 48 loss: 1.47861774e-05
Iter: 49 loss: 1.4495241e-05
Iter: 50 loss: 1.7637085e-05
Iter: 51 loss: 1.44881906e-05
Iter: 52 loss: 1.4309604e-05
Iter: 53 loss: 1.44529386e-05
Iter: 54 loss: 1.42015951e-05
Iter: 55 loss: 1.39813947e-05
Iter: 56 loss: 1.496803e-05
Iter: 57 loss: 1.39379008e-05
Iter: 58 loss: 1.3754975e-05
Iter: 59 loss: 1.44776341e-05
Iter: 60 loss: 1.37132192e-05
Iter: 61 loss: 1.35699838e-05
Iter: 62 loss: 1.33559461e-05
Iter: 63 loss: 1.33518133e-05
Iter: 64 loss: 1.31751513e-05
Iter: 65 loss: 1.31721472e-05
Iter: 66 loss: 1.30388307e-05
Iter: 67 loss: 1.29870141e-05
Iter: 68 loss: 1.29145947e-05
Iter: 69 loss: 1.27551521e-05
Iter: 70 loss: 1.41121327e-05
Iter: 71 loss: 1.27460571e-05
Iter: 72 loss: 1.26393234e-05
Iter: 73 loss: 1.26028408e-05
Iter: 74 loss: 1.25416582e-05
Iter: 75 loss: 1.26176219e-05
Iter: 76 loss: 1.24789422e-05
Iter: 77 loss: 1.24502121e-05
Iter: 78 loss: 1.23602113e-05
Iter: 79 loss: 1.25104552e-05
Iter: 80 loss: 1.22987713e-05
Iter: 81 loss: 1.21401717e-05
Iter: 82 loss: 1.24294929e-05
Iter: 83 loss: 1.20715522e-05
Iter: 84 loss: 1.19284286e-05
Iter: 85 loss: 1.25187489e-05
Iter: 86 loss: 1.18968655e-05
Iter: 87 loss: 1.1808248e-05
Iter: 88 loss: 1.30963572e-05
Iter: 89 loss: 1.18075504e-05
Iter: 90 loss: 1.17266209e-05
Iter: 91 loss: 1.18361058e-05
Iter: 92 loss: 1.16859028e-05
Iter: 93 loss: 1.16113551e-05
Iter: 94 loss: 1.17599157e-05
Iter: 95 loss: 1.15804942e-05
Iter: 96 loss: 1.15052781e-05
Iter: 97 loss: 1.17676991e-05
Iter: 98 loss: 1.1485281e-05
Iter: 99 loss: 1.14021568e-05
Iter: 100 loss: 1.15586072e-05
Iter: 101 loss: 1.13664237e-05
Iter: 102 loss: 1.1296439e-05
Iter: 103 loss: 1.14005561e-05
Iter: 104 loss: 1.12629968e-05
Iter: 105 loss: 1.11812597e-05
Iter: 106 loss: 1.13294664e-05
Iter: 107 loss: 1.11462596e-05
Iter: 108 loss: 1.10872979e-05
Iter: 109 loss: 1.14153409e-05
Iter: 110 loss: 1.10793553e-05
Iter: 111 loss: 1.10319488e-05
Iter: 112 loss: 1.16230358e-05
Iter: 113 loss: 1.10313067e-05
Iter: 114 loss: 1.09805169e-05
Iter: 115 loss: 1.11017598e-05
Iter: 116 loss: 1.09618577e-05
Iter: 117 loss: 1.09378743e-05
Iter: 118 loss: 1.09091561e-05
Iter: 119 loss: 1.09062112e-05
Iter: 120 loss: 1.08483973e-05
Iter: 121 loss: 1.08290733e-05
Iter: 122 loss: 1.07956675e-05
Iter: 123 loss: 1.07337646e-05
Iter: 124 loss: 1.08454669e-05
Iter: 125 loss: 1.07075603e-05
Iter: 126 loss: 1.06337429e-05
Iter: 127 loss: 1.11577829e-05
Iter: 128 loss: 1.06272473e-05
Iter: 129 loss: 1.05821764e-05
Iter: 130 loss: 1.11515874e-05
Iter: 131 loss: 1.05818945e-05
Iter: 132 loss: 1.05508425e-05
Iter: 133 loss: 1.04758574e-05
Iter: 134 loss: 1.12670423e-05
Iter: 135 loss: 1.04672981e-05
Iter: 136 loss: 1.04347555e-05
Iter: 137 loss: 1.042453e-05
Iter: 138 loss: 1.03930461e-05
Iter: 139 loss: 1.03956172e-05
Iter: 140 loss: 1.0368929e-05
Iter: 141 loss: 1.03229695e-05
Iter: 142 loss: 1.03471375e-05
Iter: 143 loss: 1.02923968e-05
Iter: 144 loss: 1.02375088e-05
Iter: 145 loss: 1.03809971e-05
Iter: 146 loss: 1.02188988e-05
Iter: 147 loss: 1.01885598e-05
Iter: 148 loss: 1.06576599e-05
Iter: 149 loss: 1.01880669e-05
Iter: 150 loss: 1.01557462e-05
Iter: 151 loss: 1.03388111e-05
Iter: 152 loss: 1.01514252e-05
Iter: 153 loss: 1.0130545e-05
Iter: 154 loss: 1.00913931e-05
Iter: 155 loss: 1.09311732e-05
Iter: 156 loss: 1.0091303e-05
Iter: 157 loss: 1.00534853e-05
Iter: 158 loss: 1.01076694e-05
Iter: 159 loss: 1.00352281e-05
Iter: 160 loss: 1.00002344e-05
Iter: 161 loss: 1.04113224e-05
Iter: 162 loss: 9.99988e-06
Iter: 163 loss: 9.97558618e-06
Iter: 164 loss: 9.95437404e-06
Iter: 165 loss: 9.94793118e-06
Iter: 166 loss: 9.90528133e-06
Iter: 167 loss: 1.01732767e-05
Iter: 168 loss: 9.90074659e-06
Iter: 169 loss: 9.86875057e-06
Iter: 170 loss: 1.01227961e-05
Iter: 171 loss: 9.86642226e-06
Iter: 172 loss: 9.84231519e-06
Iter: 173 loss: 9.82748315e-06
Iter: 174 loss: 9.81774338e-06
Iter: 175 loss: 9.78313074e-06
Iter: 176 loss: 9.8895971e-06
Iter: 177 loss: 9.77301715e-06
Iter: 178 loss: 9.73945862e-06
Iter: 179 loss: 9.83389e-06
Iter: 180 loss: 9.72842645e-06
Iter: 181 loss: 9.68787299e-06
Iter: 182 loss: 9.83379778e-06
Iter: 183 loss: 9.67800679e-06
Iter: 184 loss: 9.65203617e-06
Iter: 185 loss: 9.63199636e-06
Iter: 186 loss: 9.62443755e-06
Iter: 187 loss: 9.64073388e-06
Iter: 188 loss: 9.6064141e-06
Iter: 189 loss: 9.59800673e-06
Iter: 190 loss: 9.57951761e-06
Iter: 191 loss: 9.82215352e-06
Iter: 192 loss: 9.57840348e-06
Iter: 193 loss: 9.55596624e-06
Iter: 194 loss: 9.51444e-06
Iter: 195 loss: 1.04734909e-05
Iter: 196 loss: 9.51424772e-06
Iter: 197 loss: 9.48188244e-06
Iter: 198 loss: 9.93227331e-06
Iter: 199 loss: 9.48210072e-06
Iter: 200 loss: 9.45024567e-06
Iter: 201 loss: 9.50355e-06
Iter: 202 loss: 9.43618397e-06
Iter: 203 loss: 9.40624523e-06
Iter: 204 loss: 9.58744113e-06
Iter: 205 loss: 9.40264e-06
Iter: 206 loss: 9.38043377e-06
Iter: 207 loss: 9.45240481e-06
Iter: 208 loss: 9.37418918e-06
Iter: 209 loss: 9.34955642e-06
Iter: 210 loss: 9.44038493e-06
Iter: 211 loss: 9.34361833e-06
Iter: 212 loss: 9.32542935e-06
Iter: 213 loss: 9.30575152e-06
Iter: 214 loss: 9.30274109e-06
Iter: 215 loss: 9.27296787e-06
Iter: 216 loss: 9.45589727e-06
Iter: 217 loss: 9.27003e-06
Iter: 218 loss: 9.2431e-06
Iter: 219 loss: 9.33802767e-06
Iter: 220 loss: 9.23633706e-06
Iter: 221 loss: 9.21569e-06
Iter: 222 loss: 9.3427916e-06
Iter: 223 loss: 9.21312676e-06
Iter: 224 loss: 9.20119601e-06
Iter: 225 loss: 9.2938426e-06
Iter: 226 loss: 9.19994818e-06
Iter: 227 loss: 9.18325804e-06
Iter: 228 loss: 9.17161e-06
Iter: 229 loss: 9.16582576e-06
Iter: 230 loss: 9.15034434e-06
Iter: 231 loss: 9.15141118e-06
Iter: 232 loss: 9.13797521e-06
Iter: 233 loss: 9.1176862e-06
Iter: 234 loss: 9.0989e-06
Iter: 235 loss: 9.09388473e-06
Iter: 236 loss: 9.06468449e-06
Iter: 237 loss: 9.35627486e-06
Iter: 238 loss: 9.06393507e-06
Iter: 239 loss: 9.03925502e-06
Iter: 240 loss: 9.05180241e-06
Iter: 241 loss: 9.02263491e-06
Iter: 242 loss: 8.99969837e-06
Iter: 243 loss: 8.99985389e-06
Iter: 244 loss: 8.98609414e-06
Iter: 245 loss: 9.00564191e-06
Iter: 246 loss: 8.97978134e-06
Iter: 247 loss: 8.96050369e-06
Iter: 248 loss: 8.9896339e-06
Iter: 249 loss: 8.95121866e-06
Iter: 250 loss: 8.93476863e-06
Iter: 251 loss: 8.99138649e-06
Iter: 252 loss: 8.93036486e-06
Iter: 253 loss: 8.91424588e-06
Iter: 254 loss: 8.8949464e-06
Iter: 255 loss: 8.89318289e-06
Iter: 256 loss: 8.87748138e-06
Iter: 257 loss: 8.87627e-06
Iter: 258 loss: 8.8624447e-06
Iter: 259 loss: 8.91694799e-06
Iter: 260 loss: 8.85934151e-06
Iter: 261 loss: 8.8409306e-06
Iter: 262 loss: 8.87073475e-06
Iter: 263 loss: 8.83274515e-06
Iter: 264 loss: 8.82007771e-06
Iter: 265 loss: 8.81189e-06
Iter: 266 loss: 8.80737389e-06
Iter: 267 loss: 8.79006348e-06
Iter: 268 loss: 8.77708226e-06
Iter: 269 loss: 8.77123784e-06
Iter: 270 loss: 8.7472481e-06
Iter: 271 loss: 8.91929812e-06
Iter: 272 loss: 8.7452363e-06
Iter: 273 loss: 8.72567853e-06
Iter: 274 loss: 8.81025608e-06
Iter: 275 loss: 8.72226701e-06
Iter: 276 loss: 8.7050812e-06
Iter: 277 loss: 8.69435644e-06
Iter: 278 loss: 8.68846382e-06
Iter: 279 loss: 8.67712515e-06
Iter: 280 loss: 8.67374365e-06
Iter: 281 loss: 8.66232403e-06
Iter: 282 loss: 8.65483707e-06
Iter: 283 loss: 8.6506916e-06
Iter: 284 loss: 8.63356763e-06
Iter: 285 loss: 8.71833072e-06
Iter: 286 loss: 8.63077184e-06
Iter: 287 loss: 8.61524859e-06
Iter: 288 loss: 8.61214903e-06
Iter: 289 loss: 8.60211367e-06
Iter: 290 loss: 8.58228e-06
Iter: 291 loss: 8.68725783e-06
Iter: 292 loss: 8.57942177e-06
Iter: 293 loss: 8.57481427e-06
Iter: 294 loss: 8.57187388e-06
Iter: 295 loss: 8.56468705e-06
Iter: 296 loss: 8.55411872e-06
Iter: 297 loss: 8.55361395e-06
Iter: 298 loss: 8.53965412e-06
Iter: 299 loss: 8.5551037e-06
Iter: 300 loss: 8.53180609e-06
Iter: 301 loss: 8.51787627e-06
Iter: 302 loss: 8.52928e-06
Iter: 303 loss: 8.50942e-06
Iter: 304 loss: 8.49028493e-06
Iter: 305 loss: 8.49034768e-06
Iter: 306 loss: 8.47469164e-06
Iter: 307 loss: 8.45732848e-06
Iter: 308 loss: 8.54617338e-06
Iter: 309 loss: 8.45471732e-06
Iter: 310 loss: 8.4335079e-06
Iter: 311 loss: 8.45271825e-06
Iter: 312 loss: 8.42135159e-06
Iter: 313 loss: 8.40428402e-06
Iter: 314 loss: 8.54396058e-06
Iter: 315 loss: 8.40344183e-06
Iter: 316 loss: 8.38860433e-06
Iter: 317 loss: 8.47663068e-06
Iter: 318 loss: 8.38635424e-06
Iter: 319 loss: 8.37494554e-06
Iter: 320 loss: 8.4188332e-06
Iter: 321 loss: 8.37252446e-06
Iter: 322 loss: 8.36381e-06
Iter: 323 loss: 8.34861657e-06
Iter: 324 loss: 8.72770488e-06
Iter: 325 loss: 8.3487821e-06
Iter: 326 loss: 8.32537626e-06
Iter: 327 loss: 8.47984666e-06
Iter: 328 loss: 8.32319165e-06
Iter: 329 loss: 8.31578109e-06
Iter: 330 loss: 8.31461512e-06
Iter: 331 loss: 8.30634144e-06
Iter: 332 loss: 8.30083536e-06
Iter: 333 loss: 8.29760938e-06
Iter: 334 loss: 8.28739485e-06
Iter: 335 loss: 8.28477823e-06
Iter: 336 loss: 8.27831173e-06
Iter: 337 loss: 8.2661345e-06
Iter: 338 loss: 8.32856222e-06
Iter: 339 loss: 8.26389532e-06
Iter: 340 loss: 8.25244933e-06
Iter: 341 loss: 8.26776704e-06
Iter: 342 loss: 8.24650488e-06
Iter: 343 loss: 8.23391e-06
Iter: 344 loss: 8.2225306e-06
Iter: 345 loss: 8.21915273e-06
Iter: 346 loss: 8.20487e-06
Iter: 347 loss: 8.3857376e-06
Iter: 348 loss: 8.20476907e-06
Iter: 349 loss: 8.19193338e-06
Iter: 350 loss: 8.19101115e-06
Iter: 351 loss: 8.18151329e-06
Iter: 352 loss: 8.16784177e-06
Iter: 353 loss: 8.2640945e-06
Iter: 354 loss: 8.16695501e-06
Iter: 355 loss: 8.15534622e-06
Iter: 356 loss: 8.24328708e-06
Iter: 357 loss: 8.15424482e-06
Iter: 358 loss: 8.14358e-06
Iter: 359 loss: 8.15899421e-06
Iter: 360 loss: 8.13868064e-06
Iter: 361 loss: 8.12928829e-06
Iter: 362 loss: 8.12634244e-06
Iter: 363 loss: 8.12117105e-06
Iter: 364 loss: 8.11192513e-06
Iter: 365 loss: 8.11136488e-06
Iter: 366 loss: 8.1025355e-06
Iter: 367 loss: 8.1219423e-06
Iter: 368 loss: 8.09910125e-06
Iter: 369 loss: 8.09402081e-06
Iter: 370 loss: 8.0873e-06
Iter: 371 loss: 8.08673576e-06
Iter: 372 loss: 8.07523702e-06
Iter: 373 loss: 8.07914876e-06
Iter: 374 loss: 8.0665277e-06
Iter: 375 loss: 8.05532909e-06
Iter: 376 loss: 8.14823761e-06
Iter: 377 loss: 8.05464879e-06
Iter: 378 loss: 8.04349565e-06
Iter: 379 loss: 8.04744e-06
Iter: 380 loss: 8.03601051e-06
Iter: 381 loss: 8.02391151e-06
Iter: 382 loss: 8.06775915e-06
Iter: 383 loss: 8.02058821e-06
Iter: 384 loss: 8.00786529e-06
Iter: 385 loss: 8.00114685e-06
Iter: 386 loss: 7.99521786e-06
Iter: 387 loss: 7.98067504e-06
Iter: 388 loss: 8.08829827e-06
Iter: 389 loss: 7.97922166e-06
Iter: 390 loss: 7.96685345e-06
Iter: 391 loss: 8.01147144e-06
Iter: 392 loss: 7.96359927e-06
Iter: 393 loss: 7.95599e-06
Iter: 394 loss: 7.95595588e-06
Iter: 395 loss: 7.9487445e-06
Iter: 396 loss: 7.94012158e-06
Iter: 397 loss: 7.93922845e-06
Iter: 398 loss: 7.93320578e-06
Iter: 399 loss: 7.93319668e-06
Iter: 400 loss: 7.92521496e-06
Iter: 401 loss: 7.92081119e-06
Iter: 402 loss: 7.91735e-06
Iter: 403 loss: 7.90937156e-06
Iter: 404 loss: 7.90854574e-06
Iter: 405 loss: 7.90315062e-06
Iter: 406 loss: 7.89186379e-06
Iter: 407 loss: 7.92148239e-06
Iter: 408 loss: 7.88804573e-06
Iter: 409 loss: 7.87617228e-06
Iter: 410 loss: 7.89579826e-06
Iter: 411 loss: 7.87066165e-06
Iter: 412 loss: 7.85939665e-06
Iter: 413 loss: 7.90234299e-06
Iter: 414 loss: 7.85695738e-06
Iter: 415 loss: 7.84588701e-06
Iter: 416 loss: 7.89545174e-06
Iter: 417 loss: 7.84398162e-06
Iter: 418 loss: 7.83582891e-06
Iter: 419 loss: 7.84511212e-06
Iter: 420 loss: 7.83182895e-06
Iter: 421 loss: 7.82060761e-06
Iter: 422 loss: 7.82207644e-06
Iter: 423 loss: 7.81195195e-06
Iter: 424 loss: 7.80056325e-06
Iter: 425 loss: 7.86007149e-06
Iter: 426 loss: 7.79858874e-06
Iter: 427 loss: 7.78684262e-06
Iter: 428 loss: 7.80294431e-06
Iter: 429 loss: 7.78082358e-06
Iter: 430 loss: 7.77328387e-06
Iter: 431 loss: 7.77269815e-06
Iter: 432 loss: 7.76717388e-06
Iter: 433 loss: 7.76228262e-06
Iter: 434 loss: 7.76091565e-06
Iter: 435 loss: 7.75081116e-06
Iter: 436 loss: 7.87287172e-06
Iter: 437 loss: 7.75069748e-06
Iter: 438 loss: 7.74581713e-06
Iter: 439 loss: 7.73916e-06
Iter: 440 loss: 7.738985e-06
Iter: 441 loss: 7.73218653e-06
Iter: 442 loss: 7.71861232e-06
Iter: 443 loss: 8.01180249e-06
Iter: 444 loss: 7.71851228e-06
Iter: 445 loss: 7.71237501e-06
Iter: 446 loss: 7.710727e-06
Iter: 447 loss: 7.70329461e-06
Iter: 448 loss: 7.69825328e-06
Iter: 449 loss: 7.69578764e-06
Iter: 450 loss: 7.68358132e-06
Iter: 451 loss: 7.731408e-06
Iter: 452 loss: 7.68065183e-06
Iter: 453 loss: 7.67103938e-06
Iter: 454 loss: 7.71208397e-06
Iter: 455 loss: 7.6687611e-06
Iter: 456 loss: 7.65950608e-06
Iter: 457 loss: 7.6766064e-06
Iter: 458 loss: 7.65525783e-06
Iter: 459 loss: 7.64547895e-06
Iter: 460 loss: 7.64636206e-06
Iter: 461 loss: 7.63729895e-06
Iter: 462 loss: 7.62649233e-06
Iter: 463 loss: 7.6934848e-06
Iter: 464 loss: 7.62526633e-06
Iter: 465 loss: 7.61510273e-06
Iter: 466 loss: 7.68998871e-06
Iter: 467 loss: 7.61435831e-06
Iter: 468 loss: 7.60770536e-06
Iter: 469 loss: 7.66978701e-06
Iter: 470 loss: 7.60734656e-06
Iter: 471 loss: 7.60142348e-06
Iter: 472 loss: 7.61792126e-06
Iter: 473 loss: 7.59992145e-06
Iter: 474 loss: 7.59563818e-06
Iter: 475 loss: 7.58557235e-06
Iter: 476 loss: 7.67727e-06
Iter: 477 loss: 7.58400392e-06
Iter: 478 loss: 7.57217e-06
Iter: 479 loss: 7.63887692e-06
Iter: 480 loss: 7.57034195e-06
Iter: 481 loss: 7.56070676e-06
Iter: 482 loss: 7.55074325e-06
Iter: 483 loss: 7.54900975e-06
Iter: 484 loss: 7.54204075e-06
Iter: 485 loss: 7.5402877e-06
Iter: 486 loss: 7.53463655e-06
Iter: 487 loss: 7.54310349e-06
Iter: 488 loss: 7.5316625e-06
Iter: 489 loss: 7.52329788e-06
Iter: 490 loss: 7.52167307e-06
Iter: 491 loss: 7.51621064e-06
Iter: 492 loss: 7.50969139e-06
Iter: 493 loss: 7.57895486e-06
Iter: 494 loss: 7.50938716e-06
Iter: 495 loss: 7.50257232e-06
Iter: 496 loss: 7.49885112e-06
Iter: 497 loss: 7.49579431e-06
Iter: 498 loss: 7.48656657e-06
Iter: 499 loss: 7.52898222e-06
Iter: 500 loss: 7.48493403e-06
Iter: 501 loss: 7.47763806e-06
Iter: 502 loss: 7.52894903e-06
Iter: 503 loss: 7.47722061e-06
Iter: 504 loss: 7.47045351e-06
Iter: 505 loss: 7.53892755e-06
Iter: 506 loss: 7.47010108e-06
Iter: 507 loss: 7.46654496e-06
Iter: 508 loss: 7.47094145e-06
Iter: 509 loss: 7.46402839e-06
Iter: 510 loss: 7.45986199e-06
Iter: 511 loss: 7.45292846e-06
Iter: 512 loss: 7.45296575e-06
Iter: 513 loss: 7.44515273e-06
Iter: 514 loss: 7.44042336e-06
Iter: 515 loss: 7.43713372e-06
Iter: 516 loss: 7.42702878e-06
Iter: 517 loss: 7.54414259e-06
Iter: 518 loss: 7.42677366e-06
Iter: 519 loss: 7.41850408e-06
Iter: 520 loss: 7.41190661e-06
Iter: 521 loss: 7.40957694e-06
Iter: 522 loss: 7.40484938e-06
Iter: 523 loss: 7.4028635e-06
Iter: 524 loss: 7.39845063e-06
Iter: 525 loss: 7.39493134e-06
Iter: 526 loss: 7.39327288e-06
Iter: 527 loss: 7.38637664e-06
Iter: 528 loss: 7.41582062e-06
Iter: 529 loss: 7.38478502e-06
Iter: 530 loss: 7.37894379e-06
Iter: 531 loss: 7.39015286e-06
Iter: 532 loss: 7.37682058e-06
Iter: 533 loss: 7.36992797e-06
Iter: 534 loss: 7.38988638e-06
Iter: 535 loss: 7.36798393e-06
Iter: 536 loss: 7.3624542e-06
Iter: 537 loss: 7.42999828e-06
Iter: 538 loss: 7.36235552e-06
Iter: 539 loss: 7.35728781e-06
Iter: 540 loss: 7.37738e-06
Iter: 541 loss: 7.35583717e-06
Iter: 542 loss: 7.35231333e-06
Iter: 543 loss: 7.34710829e-06
Iter: 544 loss: 7.34674859e-06
Iter: 545 loss: 7.33996148e-06
Iter: 546 loss: 7.38564631e-06
Iter: 547 loss: 7.33947763e-06
Iter: 548 loss: 7.33471461e-06
Iter: 549 loss: 7.32510125e-06
Iter: 550 loss: 7.49709625e-06
Iter: 551 loss: 7.324953e-06
Iter: 552 loss: 7.31549926e-06
Iter: 553 loss: 7.41833719e-06
Iter: 554 loss: 7.3151682e-06
Iter: 555 loss: 7.30829379e-06
Iter: 556 loss: 7.3042097e-06
Iter: 557 loss: 7.30141619e-06
Iter: 558 loss: 7.29252952e-06
Iter: 559 loss: 7.3518886e-06
Iter: 560 loss: 7.2918815e-06
Iter: 561 loss: 7.28393024e-06
Iter: 562 loss: 7.30547617e-06
Iter: 563 loss: 7.2816897e-06
Iter: 564 loss: 7.27393126e-06
Iter: 565 loss: 7.2720577e-06
Iter: 566 loss: 7.26761573e-06
Iter: 567 loss: 7.25995505e-06
Iter: 568 loss: 7.25961127e-06
Iter: 569 loss: 7.25247219e-06
Iter: 570 loss: 7.2603043e-06
Iter: 571 loss: 7.24858455e-06
Iter: 572 loss: 7.24624533e-06
Iter: 573 loss: 7.24545907e-06
Iter: 574 loss: 7.24190522e-06
Iter: 575 loss: 7.24015e-06
Iter: 576 loss: 7.23833909e-06
Iter: 577 loss: 7.23462517e-06
Iter: 578 loss: 7.23134099e-06
Iter: 579 loss: 7.23032645e-06
Iter: 580 loss: 7.22430059e-06
Iter: 581 loss: 7.27446377e-06
Iter: 582 loss: 7.22418645e-06
Iter: 583 loss: 7.21934975e-06
Iter: 584 loss: 7.21685319e-06
Iter: 585 loss: 7.21469269e-06
Iter: 586 loss: 7.2054936e-06
Iter: 587 loss: 7.23159337e-06
Iter: 588 loss: 7.20265734e-06
Iter: 589 loss: 7.19656055e-06
Iter: 590 loss: 7.20893422e-06
Iter: 591 loss: 7.19400123e-06
Iter: 592 loss: 7.1870254e-06
Iter: 593 loss: 7.18795764e-06
Iter: 594 loss: 7.18179035e-06
Iter: 595 loss: 7.17421335e-06
Iter: 596 loss: 7.20049411e-06
Iter: 597 loss: 7.172187e-06
Iter: 598 loss: 7.16288332e-06
Iter: 599 loss: 7.18938918e-06
Iter: 600 loss: 7.15959823e-06
Iter: 601 loss: 7.15353463e-06
Iter: 602 loss: 7.16881959e-06
Iter: 603 loss: 7.15089118e-06
Iter: 604 loss: 7.14397947e-06
Iter: 605 loss: 7.21331071e-06
Iter: 606 loss: 7.14390899e-06
Iter: 607 loss: 7.13873396e-06
Iter: 608 loss: 7.19969194e-06
Iter: 609 loss: 7.13887493e-06
Iter: 610 loss: 7.13484133e-06
Iter: 611 loss: 7.13180725e-06
Iter: 612 loss: 7.13030749e-06
Iter: 613 loss: 7.12595102e-06
Iter: 614 loss: 7.12920655e-06
Iter: 615 loss: 7.12333031e-06
Iter: 616 loss: 7.11781922e-06
Iter: 617 loss: 7.12936117e-06
Iter: 618 loss: 7.11570692e-06
Iter: 619 loss: 7.10893437e-06
Iter: 620 loss: 7.14489488e-06
Iter: 621 loss: 7.10797394e-06
Iter: 622 loss: 7.10370296e-06
Iter: 623 loss: 7.10188669e-06
Iter: 624 loss: 7.09954e-06
Iter: 625 loss: 7.09273945e-06
Iter: 626 loss: 7.11413713e-06
Iter: 627 loss: 7.09065944e-06
Iter: 628 loss: 7.0846836e-06
Iter: 629 loss: 7.11385383e-06
Iter: 630 loss: 7.08383732e-06
Iter: 631 loss: 7.07776826e-06
Iter: 632 loss: 7.07232448e-06
Iter: 633 loss: 7.07075969e-06
Iter: 634 loss: 7.06405763e-06
Iter: 635 loss: 7.1301065e-06
Iter: 636 loss: 7.06396895e-06
Iter: 637 loss: 7.0582937e-06
Iter: 638 loss: 7.05289585e-06
Iter: 639 loss: 7.05133516e-06
Iter: 640 loss: 7.046679e-06
Iter: 641 loss: 7.04637614e-06
Iter: 642 loss: 7.04158219e-06
Iter: 643 loss: 7.07754862e-06
Iter: 644 loss: 7.04164e-06
Iter: 645 loss: 7.03884825e-06
Iter: 646 loss: 7.03155411e-06
Iter: 647 loss: 7.07109848e-06
Iter: 648 loss: 7.02939269e-06
Iter: 649 loss: 7.02371653e-06
Iter: 650 loss: 7.02358875e-06
Iter: 651 loss: 7.01849149e-06
Iter: 652 loss: 7.02320176e-06
Iter: 653 loss: 7.01551e-06
Iter: 654 loss: 7.00970668e-06
Iter: 655 loss: 7.02671559e-06
Iter: 656 loss: 7.00814917e-06
Iter: 657 loss: 7.0021465e-06
Iter: 658 loss: 7.02339321e-06
Iter: 659 loss: 7.00016972e-06
Iter: 660 loss: 6.9951675e-06
Iter: 661 loss: 6.99785141e-06
Iter: 662 loss: 6.99194061e-06
Iter: 663 loss: 6.98570057e-06
Iter: 664 loss: 6.98856093e-06
Iter: 665 loss: 6.98153144e-06
Iter: 666 loss: 6.97398764e-06
Iter: 667 loss: 6.99378052e-06
Iter: 668 loss: 6.97126688e-06
Iter: 669 loss: 6.96217421e-06
Iter: 670 loss: 7.00665623e-06
Iter: 671 loss: 6.96087227e-06
Iter: 672 loss: 6.95538438e-06
Iter: 673 loss: 6.95961126e-06
Iter: 674 loss: 6.95206563e-06
Iter: 675 loss: 6.94712844e-06
Iter: 676 loss: 6.94644814e-06
Iter: 677 loss: 6.94208438e-06
Iter: 678 loss: 6.94862047e-06
Iter: 679 loss: 6.93971378e-06
Iter: 680 loss: 6.9364537e-06
Iter: 681 loss: 6.93222091e-06
Iter: 682 loss: 6.9320713e-06
Iter: 683 loss: 6.9246e-06
Iter: 684 loss: 6.92810181e-06
Iter: 685 loss: 6.91950754e-06
Iter: 686 loss: 6.91341029e-06
Iter: 687 loss: 7.00046894e-06
Iter: 688 loss: 6.91362e-06
Iter: 689 loss: 6.90821616e-06
Iter: 690 loss: 6.91614832e-06
Iter: 691 loss: 6.90579964e-06
Iter: 692 loss: 6.90036904e-06
Iter: 693 loss: 6.90803427e-06
Iter: 694 loss: 6.89785111e-06
Iter: 695 loss: 6.89252829e-06
Iter: 696 loss: 6.92391268e-06
Iter: 697 loss: 6.89215585e-06
Iter: 698 loss: 6.88688806e-06
Iter: 699 loss: 6.88700175e-06
Iter: 700 loss: 6.8833042e-06
Iter: 701 loss: 6.87666e-06
Iter: 702 loss: 6.88269211e-06
Iter: 703 loss: 6.87308238e-06
Iter: 704 loss: 6.86628482e-06
Iter: 705 loss: 6.88451564e-06
Iter: 706 loss: 6.86415842e-06
Iter: 707 loss: 6.85586519e-06
Iter: 708 loss: 6.87462762e-06
Iter: 709 loss: 6.85259192e-06
Iter: 710 loss: 6.85553e-06
Iter: 711 loss: 6.84985844e-06
Iter: 712 loss: 6.84728184e-06
Iter: 713 loss: 6.84161e-06
Iter: 714 loss: 6.92685671e-06
Iter: 715 loss: 6.84113274e-06
Iter: 716 loss: 6.83537564e-06
Iter: 717 loss: 6.83966937e-06
Iter: 718 loss: 6.83223243e-06
Iter: 719 loss: 6.82677364e-06
Iter: 720 loss: 6.8458362e-06
Iter: 721 loss: 6.82586779e-06
Iter: 722 loss: 6.81991241e-06
Iter: 723 loss: 6.8320328e-06
Iter: 724 loss: 6.81721713e-06
Iter: 725 loss: 6.81261281e-06
Iter: 726 loss: 6.85385066e-06
Iter: 727 loss: 6.81243091e-06
Iter: 728 loss: 6.80782478e-06
Iter: 729 loss: 6.81247e-06
Iter: 730 loss: 6.80575795e-06
Iter: 731 loss: 6.80072299e-06
Iter: 732 loss: 6.80593075e-06
Iter: 733 loss: 6.79779123e-06
Iter: 734 loss: 6.79261257e-06
Iter: 735 loss: 6.79597497e-06
Iter: 736 loss: 6.7893111e-06
Iter: 737 loss: 6.78377364e-06
Iter: 738 loss: 6.84093e-06
Iter: 739 loss: 6.78398101e-06
Iter: 740 loss: 6.77986918e-06
Iter: 741 loss: 6.78781407e-06
Iter: 742 loss: 6.77803746e-06
Iter: 743 loss: 6.77269509e-06
Iter: 744 loss: 6.77430762e-06
Iter: 745 loss: 6.76860509e-06
Iter: 746 loss: 6.7679166e-06
Iter: 747 loss: 6.76627724e-06
Iter: 748 loss: 6.7634428e-06
Iter: 749 loss: 6.75754245e-06
Iter: 750 loss: 6.85089708e-06
Iter: 751 loss: 6.75700539e-06
Iter: 752 loss: 6.75226784e-06
Iter: 753 loss: 6.75054162e-06
Iter: 754 loss: 6.74778175e-06
Iter: 755 loss: 6.74092507e-06
Iter: 756 loss: 6.76848867e-06
Iter: 757 loss: 6.73914292e-06
Iter: 758 loss: 6.73318027e-06
Iter: 759 loss: 6.75380534e-06
Iter: 760 loss: 6.73150225e-06
Iter: 761 loss: 6.72733495e-06
Iter: 762 loss: 6.7802639e-06
Iter: 763 loss: 6.7273e-06
Iter: 764 loss: 6.7235037e-06
Iter: 765 loss: 6.7227611e-06
Iter: 766 loss: 6.71991666e-06
Iter: 767 loss: 6.71447424e-06
Iter: 768 loss: 6.71562657e-06
Iter: 769 loss: 6.71057524e-06
Iter: 770 loss: 6.70592e-06
Iter: 771 loss: 6.75259525e-06
Iter: 772 loss: 6.70585632e-06
Iter: 773 loss: 6.70127747e-06
Iter: 774 loss: 6.69807741e-06
Iter: 775 loss: 6.69612564e-06
Iter: 776 loss: 6.69087513e-06
Iter: 777 loss: 6.74192688e-06
Iter: 778 loss: 6.69043493e-06
Iter: 779 loss: 6.68582379e-06
Iter: 780 loss: 6.69802375e-06
Iter: 781 loss: 6.68444e-06
Iter: 782 loss: 6.68031043e-06
Iter: 783 loss: 6.68023131e-06
Iter: 784 loss: 6.67817358e-06
Iter: 785 loss: 6.67741369e-06
Iter: 786 loss: 6.67568656e-06
Iter: 787 loss: 6.67279164e-06
Iter: 788 loss: 6.66685264e-06
Iter: 789 loss: 6.77909e-06
Iter: 790 loss: 6.66675896e-06
Iter: 791 loss: 6.65985681e-06
Iter: 792 loss: 6.70864483e-06
Iter: 793 loss: 6.65912467e-06
Iter: 794 loss: 6.65402467e-06
Iter: 795 loss: 6.65175094e-06
Iter: 796 loss: 6.64930576e-06
Iter: 797 loss: 6.64321351e-06
Iter: 798 loss: 6.72630085e-06
Iter: 799 loss: 6.64291974e-06
Iter: 800 loss: 6.63899709e-06
Iter: 801 loss: 6.6603593e-06
Iter: 802 loss: 6.63841456e-06
Iter: 803 loss: 6.63434e-06
Iter: 804 loss: 6.64214394e-06
Iter: 805 loss: 6.63268838e-06
Iter: 806 loss: 6.62880848e-06
Iter: 807 loss: 6.62458751e-06
Iter: 808 loss: 6.62390948e-06
Iter: 809 loss: 6.61815e-06
Iter: 810 loss: 6.65132029e-06
Iter: 811 loss: 6.61720105e-06
Iter: 812 loss: 6.61163631e-06
Iter: 813 loss: 6.63925721e-06
Iter: 814 loss: 6.61061449e-06
Iter: 815 loss: 6.60650448e-06
Iter: 816 loss: 6.62242201e-06
Iter: 817 loss: 6.60543401e-06
Iter: 818 loss: 6.60281648e-06
Iter: 819 loss: 6.60279602e-06
Iter: 820 loss: 6.6008879e-06
Iter: 821 loss: 6.59528223e-06
Iter: 822 loss: 6.64130766e-06
Iter: 823 loss: 6.59402531e-06
Iter: 824 loss: 6.58962e-06
Iter: 825 loss: 6.6373841e-06
Iter: 826 loss: 6.58950421e-06
Iter: 827 loss: 6.58607632e-06
Iter: 828 loss: 6.58495901e-06
Iter: 829 loss: 6.58269346e-06
Iter: 830 loss: 6.577146e-06
Iter: 831 loss: 6.58844965e-06
Iter: 832 loss: 6.57489818e-06
Iter: 833 loss: 6.56948032e-06
Iter: 834 loss: 6.57308055e-06
Iter: 835 loss: 6.56614611e-06
Iter: 836 loss: 6.55874283e-06
Iter: 837 loss: 6.59338184e-06
Iter: 838 loss: 6.557083e-06
Iter: 839 loss: 6.55306212e-06
Iter: 840 loss: 6.55311396e-06
Iter: 841 loss: 6.54938867e-06
Iter: 842 loss: 6.54934684e-06
Iter: 843 loss: 6.54659789e-06
Iter: 844 loss: 6.54266842e-06
Iter: 845 loss: 6.54109544e-06
Iter: 846 loss: 6.53898314e-06
Iter: 847 loss: 6.53305233e-06
Iter: 848 loss: 6.56780139e-06
Iter: 849 loss: 6.5318186e-06
Iter: 850 loss: 6.53051029e-06
Iter: 851 loss: 6.52989456e-06
Iter: 852 loss: 6.52762265e-06
Iter: 853 loss: 6.52367316e-06
Iter: 854 loss: 6.52364633e-06
Iter: 855 loss: 6.51994196e-06
Iter: 856 loss: 6.53065172e-06
Iter: 857 loss: 6.51868231e-06
Iter: 858 loss: 6.51525761e-06
Iter: 859 loss: 6.51620076e-06
Iter: 860 loss: 6.51287e-06
Iter: 861 loss: 6.50829907e-06
Iter: 862 loss: 6.52202107e-06
Iter: 863 loss: 6.50677157e-06
Iter: 864 loss: 6.50175616e-06
Iter: 865 loss: 6.51375103e-06
Iter: 866 loss: 6.50035645e-06
Iter: 867 loss: 6.49562162e-06
Iter: 868 loss: 6.51450409e-06
Iter: 869 loss: 6.49472167e-06
Iter: 870 loss: 6.49078811e-06
Iter: 871 loss: 6.48713194e-06
Iter: 872 loss: 6.48659e-06
Iter: 873 loss: 6.48133891e-06
Iter: 874 loss: 6.48150854e-06
Iter: 875 loss: 6.47743764e-06
Iter: 876 loss: 6.49183403e-06
Iter: 877 loss: 6.47642401e-06
Iter: 878 loss: 6.47259094e-06
Iter: 879 loss: 6.47132856e-06
Iter: 880 loss: 6.46896069e-06
Iter: 881 loss: 6.46478566e-06
Iter: 882 loss: 6.46994249e-06
Iter: 883 loss: 6.4623373e-06
Iter: 884 loss: 6.45963519e-06
Iter: 885 loss: 6.45899308e-06
Iter: 886 loss: 6.45545333e-06
Iter: 887 loss: 6.45005548e-06
Iter: 888 loss: 6.44987722e-06
Iter: 889 loss: 6.44656893e-06
Iter: 890 loss: 6.44534339e-06
Iter: 891 loss: 6.4436058e-06
Iter: 892 loss: 6.43895692e-06
Iter: 893 loss: 6.47472689e-06
Iter: 894 loss: 6.4386204e-06
Iter: 895 loss: 6.43529802e-06
Iter: 896 loss: 6.44798683e-06
Iter: 897 loss: 6.43438852e-06
Iter: 898 loss: 6.43124304e-06
Iter: 899 loss: 6.42645819e-06
Iter: 900 loss: 6.42628947e-06
Iter: 901 loss: 6.42002487e-06
Iter: 902 loss: 6.45676482e-06
Iter: 903 loss: 6.41943734e-06
Iter: 904 loss: 6.41486486e-06
Iter: 905 loss: 6.43163e-06
Iter: 906 loss: 6.41359293e-06
Iter: 907 loss: 6.40932649e-06
Iter: 908 loss: 6.43526027e-06
Iter: 909 loss: 6.40852522e-06
Iter: 910 loss: 6.40506551e-06
Iter: 911 loss: 6.41628094e-06
Iter: 912 loss: 6.40412736e-06
Iter: 913 loss: 6.40066537e-06
Iter: 914 loss: 6.40887174e-06
Iter: 915 loss: 6.39953805e-06
Iter: 916 loss: 6.39609607e-06
Iter: 917 loss: 6.39277278e-06
Iter: 918 loss: 6.39213704e-06
Iter: 919 loss: 6.39288464e-06
Iter: 920 loss: 6.3896432e-06
Iter: 921 loss: 6.38776146e-06
Iter: 922 loss: 6.38421534e-06
Iter: 923 loss: 6.45482669e-06
Iter: 924 loss: 6.38419078e-06
Iter: 925 loss: 6.38026631e-06
Iter: 926 loss: 6.37597259e-06
Iter: 927 loss: 6.37518951e-06
Iter: 928 loss: 6.37093854e-06
Iter: 929 loss: 6.39864311e-06
Iter: 930 loss: 6.3702355e-06
Iter: 931 loss: 6.36533196e-06
Iter: 932 loss: 6.37996709e-06
Iter: 933 loss: 6.36379218e-06
Iter: 934 loss: 6.35998913e-06
Iter: 935 loss: 6.39805421e-06
Iter: 936 loss: 6.36006143e-06
Iter: 937 loss: 6.35741389e-06
Iter: 938 loss: 6.35238894e-06
Iter: 939 loss: 6.45316732e-06
Iter: 940 loss: 6.35214883e-06
Iter: 941 loss: 6.34714115e-06
Iter: 942 loss: 6.38618803e-06
Iter: 943 loss: 6.34677599e-06
Iter: 944 loss: 6.34219168e-06
Iter: 945 loss: 6.35207925e-06
Iter: 946 loss: 6.34043226e-06
Iter: 947 loss: 6.33681702e-06
Iter: 948 loss: 6.3888092e-06
Iter: 949 loss: 6.33650689e-06
Iter: 950 loss: 6.33343052e-06
Iter: 951 loss: 6.33093669e-06
Iter: 952 loss: 6.32996034e-06
Iter: 953 loss: 6.32725096e-06
Iter: 954 loss: 6.32716547e-06
Iter: 955 loss: 6.32372939e-06
Iter: 956 loss: 6.33477475e-06
Iter: 957 loss: 6.32303181e-06
Iter: 958 loss: 6.32075671e-06
Iter: 959 loss: 6.31566854e-06
Iter: 960 loss: 6.3708967e-06
Iter: 961 loss: 6.31497642e-06
Iter: 962 loss: 6.3104726e-06
Iter: 963 loss: 6.35800097e-06
Iter: 964 loss: 6.31035755e-06
Iter: 965 loss: 6.30634258e-06
Iter: 966 loss: 6.31101193e-06
Iter: 967 loss: 6.30421255e-06
Iter: 968 loss: 6.30009481e-06
Iter: 969 loss: 6.30356044e-06
Iter: 970 loss: 6.29807573e-06
Iter: 971 loss: 6.2928134e-06
Iter: 972 loss: 6.31477269e-06
Iter: 973 loss: 6.29185e-06
Iter: 974 loss: 6.28732914e-06
Iter: 975 loss: 6.29185615e-06
Iter: 976 loss: 6.28499492e-06
Iter: 977 loss: 6.27982627e-06
Iter: 978 loss: 6.33384025e-06
Iter: 979 loss: 6.27942791e-06
Iter: 980 loss: 6.27605277e-06
Iter: 981 loss: 6.27749068e-06
Iter: 982 loss: 6.27334248e-06
Iter: 983 loss: 6.26852898e-06
Iter: 984 loss: 6.26972678e-06
Iter: 985 loss: 6.26510382e-06
Iter: 986 loss: 6.25997745e-06
Iter: 987 loss: 6.30690192e-06
Iter: 988 loss: 6.25970733e-06
Iter: 989 loss: 6.25540088e-06
Iter: 990 loss: 6.28361704e-06
Iter: 991 loss: 6.2552308e-06
Iter: 992 loss: 6.25161647e-06
Iter: 993 loss: 6.27729287e-06
Iter: 994 loss: 6.25147686e-06
Iter: 995 loss: 6.24846507e-06
Iter: 996 loss: 6.25419034e-06
Iter: 997 loss: 6.24748191e-06
Iter: 998 loss: 6.24558379e-06
Iter: 999 loss: 6.24065524e-06
Iter: 1000 loss: 6.25966413e-06
Iter: 1001 loss: 6.23815504e-06
Iter: 1002 loss: 6.23225151e-06
Iter: 1003 loss: 6.30434079e-06
Iter: 1004 loss: 6.23200413e-06
Iter: 1005 loss: 6.22733751e-06
Iter: 1006 loss: 6.25040457e-06
Iter: 1007 loss: 6.22621883e-06
Iter: 1008 loss: 6.22233892e-06
Iter: 1009 loss: 6.23250799e-06
Iter: 1010 loss: 6.22108109e-06
Iter: 1011 loss: 6.2170925e-06
Iter: 1012 loss: 6.22120342e-06
Iter: 1013 loss: 6.21526169e-06
Iter: 1014 loss: 6.21051095e-06
Iter: 1015 loss: 6.21384515e-06
Iter: 1016 loss: 6.20785977e-06
Iter: 1017 loss: 6.20238461e-06
Iter: 1018 loss: 6.24627137e-06
Iter: 1019 loss: 6.20230821e-06
Iter: 1020 loss: 6.19827824e-06
Iter: 1021 loss: 6.20220635e-06
Iter: 1022 loss: 6.19611865e-06
Iter: 1023 loss: 6.19176853e-06
Iter: 1024 loss: 6.24278709e-06
Iter: 1025 loss: 6.19179809e-06
Iter: 1026 loss: 6.18889771e-06
Iter: 1027 loss: 6.18997547e-06
Iter: 1028 loss: 6.18763e-06
Iter: 1029 loss: 6.18284776e-06
Iter: 1030 loss: 6.21527397e-06
Iter: 1031 loss: 6.18286367e-06
Iter: 1032 loss: 6.1804717e-06
Iter: 1033 loss: 6.17875048e-06
Iter: 1034 loss: 6.17816568e-06
Iter: 1035 loss: 6.17460819e-06
Iter: 1036 loss: 6.18646891e-06
Iter: 1037 loss: 6.17374371e-06
Iter: 1038 loss: 6.17037949e-06
Iter: 1039 loss: 6.165993e-06
Iter: 1040 loss: 6.16547504e-06
Iter: 1041 loss: 6.16090074e-06
Iter: 1042 loss: 6.18772e-06
Iter: 1043 loss: 6.15991394e-06
Iter: 1044 loss: 6.1558394e-06
Iter: 1045 loss: 6.16325906e-06
Iter: 1046 loss: 6.15404497e-06
Iter: 1047 loss: 6.14967439e-06
Iter: 1048 loss: 6.17597743e-06
Iter: 1049 loss: 6.14960209e-06
Iter: 1050 loss: 6.14564124e-06
Iter: 1051 loss: 6.1496371e-06
Iter: 1052 loss: 6.14334522e-06
Iter: 1053 loss: 6.13929205e-06
Iter: 1054 loss: 6.15059344e-06
Iter: 1055 loss: 6.13797e-06
Iter: 1056 loss: 6.13327165e-06
Iter: 1057 loss: 6.13300926e-06
Iter: 1058 loss: 6.12944677e-06
Iter: 1059 loss: 6.12438907e-06
Iter: 1060 loss: 6.16193165e-06
Iter: 1061 loss: 6.12414442e-06
Iter: 1062 loss: 6.12230451e-06
Iter: 1063 loss: 6.12196573e-06
Iter: 1064 loss: 6.11973792e-06
Iter: 1065 loss: 6.12007625e-06
Iter: 1066 loss: 6.11779433e-06
Iter: 1067 loss: 6.11574e-06
Iter: 1068 loss: 6.1154733e-06
Iter: 1069 loss: 6.11356973e-06
Iter: 1070 loss: 6.11047199e-06
Iter: 1071 loss: 6.11779888e-06
Iter: 1072 loss: 6.10901861e-06
Iter: 1073 loss: 6.10595634e-06
Iter: 1074 loss: 6.10858842e-06
Iter: 1075 loss: 6.10383313e-06
Iter: 1076 loss: 6.09901872e-06
Iter: 1077 loss: 6.1256851e-06
Iter: 1078 loss: 6.09846438e-06
Iter: 1079 loss: 6.09521067e-06
Iter: 1080 loss: 6.09760536e-06
Iter: 1081 loss: 6.09355311e-06
Iter: 1082 loss: 6.08861546e-06
Iter: 1083 loss: 6.08671326e-06
Iter: 1084 loss: 6.08449909e-06
Iter: 1085 loss: 6.07998209e-06
Iter: 1086 loss: 6.11256246e-06
Iter: 1087 loss: 6.07967559e-06
Iter: 1088 loss: 6.074662e-06
Iter: 1089 loss: 6.08299615e-06
Iter: 1090 loss: 6.0722723e-06
Iter: 1091 loss: 6.06872254e-06
Iter: 1092 loss: 6.10758525e-06
Iter: 1093 loss: 6.06865e-06
Iter: 1094 loss: 6.06611957e-06
Iter: 1095 loss: 6.061151e-06
Iter: 1096 loss: 6.06107824e-06
Iter: 1097 loss: 6.06149661e-06
Iter: 1098 loss: 6.05913056e-06
Iter: 1099 loss: 6.05652713e-06
Iter: 1100 loss: 6.05356763e-06
Iter: 1101 loss: 6.0531811e-06
Iter: 1102 loss: 6.05012247e-06
Iter: 1103 loss: 6.04916568e-06
Iter: 1104 loss: 6.04742081e-06
Iter: 1105 loss: 6.04363049e-06
Iter: 1106 loss: 6.06441972e-06
Iter: 1107 loss: 6.04352e-06
Iter: 1108 loss: 6.04022398e-06
Iter: 1109 loss: 6.05284504e-06
Iter: 1110 loss: 6.03929493e-06
Iter: 1111 loss: 6.03631361e-06
Iter: 1112 loss: 6.03624358e-06
Iter: 1113 loss: 6.03357e-06
Iter: 1114 loss: 6.03039916e-06
Iter: 1115 loss: 6.06695176e-06
Iter: 1116 loss: 6.03021908e-06
Iter: 1117 loss: 6.02762884e-06
Iter: 1118 loss: 6.02707132e-06
Iter: 1119 loss: 6.02546515e-06
Iter: 1120 loss: 6.02092132e-06
Iter: 1121 loss: 6.01885586e-06
Iter: 1122 loss: 6.01700731e-06
Iter: 1123 loss: 6.01182364e-06
Iter: 1124 loss: 6.04770867e-06
Iter: 1125 loss: 6.01128113e-06
Iter: 1126 loss: 6.00647445e-06
Iter: 1127 loss: 6.01477859e-06
Iter: 1128 loss: 6.00451449e-06
Iter: 1129 loss: 6.00130261e-06
Iter: 1130 loss: 6.01863485e-06
Iter: 1131 loss: 6.00054045e-06
Iter: 1132 loss: 5.99895702e-06
Iter: 1133 loss: 5.99874238e-06
Iter: 1134 loss: 5.99668556e-06
Iter: 1135 loss: 5.99420537e-06
Iter: 1136 loss: 5.99384566e-06
Iter: 1137 loss: 5.99107352e-06
Iter: 1138 loss: 5.98924817e-06
Iter: 1139 loss: 5.98851329e-06
Iter: 1140 loss: 5.98362203e-06
Iter: 1141 loss: 6.01639476e-06
Iter: 1142 loss: 5.98356792e-06
Iter: 1143 loss: 5.98035422e-06
Iter: 1144 loss: 5.98261977e-06
Iter: 1145 loss: 5.97828875e-06
Iter: 1146 loss: 5.97439157e-06
Iter: 1147 loss: 6.00450403e-06
Iter: 1148 loss: 5.97426151e-06
Iter: 1149 loss: 5.97123244e-06
Iter: 1150 loss: 5.97578901e-06
Iter: 1151 loss: 5.96994596e-06
Iter: 1152 loss: 5.96689551e-06
Iter: 1153 loss: 5.96553718e-06
Iter: 1154 loss: 5.96415111e-06
Iter: 1155 loss: 5.96030395e-06
Iter: 1156 loss: 6.01205556e-06
Iter: 1157 loss: 5.96036125e-06
Iter: 1158 loss: 5.95744814e-06
Iter: 1159 loss: 5.95382608e-06
Iter: 1160 loss: 5.9535023e-06
Iter: 1161 loss: 5.94924086e-06
Iter: 1162 loss: 5.96431619e-06
Iter: 1163 loss: 5.94784524e-06
Iter: 1164 loss: 5.94326912e-06
Iter: 1165 loss: 5.95559e-06
Iter: 1166 loss: 5.94201447e-06
Iter: 1167 loss: 5.9408776e-06
Iter: 1168 loss: 5.94004e-06
Iter: 1169 loss: 5.93749701e-06
Iter: 1170 loss: 5.93393952e-06
Iter: 1171 loss: 5.93381128e-06
Iter: 1172 loss: 5.93069035e-06
Iter: 1173 loss: 5.9310205e-06
Iter: 1174 loss: 5.92861079e-06
Iter: 1175 loss: 5.92418564e-06
Iter: 1176 loss: 5.92603e-06
Iter: 1177 loss: 5.920891e-06
Iter: 1178 loss: 5.9170552e-06
Iter: 1179 loss: 5.96042582e-06
Iter: 1180 loss: 5.91710204e-06
Iter: 1181 loss: 5.91277239e-06
Iter: 1182 loss: 5.91440676e-06
Iter: 1183 loss: 5.91021e-06
Iter: 1184 loss: 5.905732e-06
Iter: 1185 loss: 5.95284837e-06
Iter: 1186 loss: 5.90529817e-06
Iter: 1187 loss: 5.90268974e-06
Iter: 1188 loss: 5.90978e-06
Iter: 1189 loss: 5.90181526e-06
Iter: 1190 loss: 5.89863157e-06
Iter: 1191 loss: 5.89821866e-06
Iter: 1192 loss: 5.89611591e-06
Iter: 1193 loss: 5.89319461e-06
Iter: 1194 loss: 5.90777108e-06
Iter: 1195 loss: 5.8925034e-06
Iter: 1196 loss: 5.88941e-06
Iter: 1197 loss: 5.88666262e-06
Iter: 1198 loss: 5.88586909e-06
Iter: 1199 loss: 5.88277544e-06
Iter: 1200 loss: 5.88297871e-06
Iter: 1201 loss: 5.88041803e-06
Iter: 1202 loss: 5.89595675e-06
Iter: 1203 loss: 5.88040893e-06
Iter: 1204 loss: 5.87768182e-06
Iter: 1205 loss: 5.88267858e-06
Iter: 1206 loss: 5.87696e-06
Iter: 1207 loss: 5.87498107e-06
Iter: 1208 loss: 5.87334216e-06
Iter: 1209 loss: 5.87278555e-06
Iter: 1210 loss: 5.86975602e-06
Iter: 1211 loss: 5.86909573e-06
Iter: 1212 loss: 5.86743226e-06
Iter: 1213 loss: 5.86363331e-06
Iter: 1214 loss: 5.87299564e-06
Iter: 1215 loss: 5.86212445e-06
Iter: 1216 loss: 5.85835278e-06
Iter: 1217 loss: 5.89069896e-06
Iter: 1218 loss: 5.85834778e-06
Iter: 1219 loss: 5.85527778e-06
Iter: 1220 loss: 5.867455e-06
Iter: 1221 loss: 5.85447e-06
Iter: 1222 loss: 5.85129465e-06
Iter: 1223 loss: 5.85281168e-06
Iter: 1224 loss: 5.84916643e-06
Iter: 1225 loss: 5.84598e-06
Iter: 1226 loss: 5.85996168e-06
Iter: 1227 loss: 5.84586587e-06
Iter: 1228 loss: 5.84287227e-06
Iter: 1229 loss: 5.84198096e-06
Iter: 1230 loss: 5.84007421e-06
Iter: 1231 loss: 5.83600104e-06
Iter: 1232 loss: 5.85381622e-06
Iter: 1233 loss: 5.8352216e-06
Iter: 1234 loss: 5.83141e-06
Iter: 1235 loss: 5.83421252e-06
Iter: 1236 loss: 5.82905932e-06
Iter: 1237 loss: 5.83026213e-06
Iter: 1238 loss: 5.8270557e-06
Iter: 1239 loss: 5.82599e-06
Iter: 1240 loss: 5.82381972e-06
Iter: 1241 loss: 5.85791622e-06
Iter: 1242 loss: 5.82376333e-06
Iter: 1243 loss: 5.82087841e-06
Iter: 1244 loss: 5.82523717e-06
Iter: 1245 loss: 5.81960694e-06
Iter: 1246 loss: 5.81666882e-06
Iter: 1247 loss: 5.82046732e-06
Iter: 1248 loss: 5.81547238e-06
Iter: 1249 loss: 5.81166842e-06
Iter: 1250 loss: 5.8090327e-06
Iter: 1251 loss: 5.80779943e-06
Iter: 1252 loss: 5.80297274e-06
Iter: 1253 loss: 5.835509e-06
Iter: 1254 loss: 5.80235519e-06
Iter: 1255 loss: 5.79853531e-06
Iter: 1256 loss: 5.83302062e-06
Iter: 1257 loss: 5.79832977e-06
Iter: 1258 loss: 5.79509333e-06
Iter: 1259 loss: 5.8012e-06
Iter: 1260 loss: 5.79381413e-06
Iter: 1261 loss: 5.79094376e-06
Iter: 1262 loss: 5.79180096e-06
Iter: 1263 loss: 5.78890695e-06
Iter: 1264 loss: 5.78540858e-06
Iter: 1265 loss: 5.79846164e-06
Iter: 1266 loss: 5.78432901e-06
Iter: 1267 loss: 5.78088202e-06
Iter: 1268 loss: 5.79314292e-06
Iter: 1269 loss: 5.77986293e-06
Iter: 1270 loss: 5.7770003e-06
Iter: 1271 loss: 5.79536027e-06
Iter: 1272 loss: 5.77696801e-06
Iter: 1273 loss: 5.77378387e-06
Iter: 1274 loss: 5.79334119e-06
Iter: 1275 loss: 5.77348237e-06
Iter: 1276 loss: 5.77160245e-06
Iter: 1277 loss: 5.76842649e-06
Iter: 1278 loss: 5.82916164e-06
Iter: 1279 loss: 5.76848e-06
Iter: 1280 loss: 5.76562206e-06
Iter: 1281 loss: 5.78593699e-06
Iter: 1282 loss: 5.76569846e-06
Iter: 1283 loss: 5.7624311e-06
Iter: 1284 loss: 5.76176899e-06
Iter: 1285 loss: 5.75984723e-06
Iter: 1286 loss: 5.75673857e-06
Iter: 1287 loss: 5.76857337e-06
Iter: 1288 loss: 5.75611739e-06
Iter: 1289 loss: 5.75259219e-06
Iter: 1290 loss: 5.75126614e-06
Iter: 1291 loss: 5.74936257e-06
Iter: 1292 loss: 5.74614933e-06
Iter: 1293 loss: 5.74626e-06
Iter: 1294 loss: 5.74345e-06
Iter: 1295 loss: 5.74921705e-06
Iter: 1296 loss: 5.74248179e-06
Iter: 1297 loss: 5.73943e-06
Iter: 1298 loss: 5.73784291e-06
Iter: 1299 loss: 5.73632315e-06
Iter: 1300 loss: 5.73314082e-06
Iter: 1301 loss: 5.73684702e-06
Iter: 1302 loss: 5.73101897e-06
Iter: 1303 loss: 5.72748377e-06
Iter: 1304 loss: 5.77388619e-06
Iter: 1305 loss: 5.72750105e-06
Iter: 1306 loss: 5.7258012e-06
Iter: 1307 loss: 5.7256093e-06
Iter: 1308 loss: 5.72387398e-06
Iter: 1309 loss: 5.72129e-06
Iter: 1310 loss: 5.78506751e-06
Iter: 1311 loss: 5.72119279e-06
Iter: 1312 loss: 5.71797727e-06
Iter: 1313 loss: 5.71936152e-06
Iter: 1314 loss: 5.71538976e-06
Iter: 1315 loss: 5.71195233e-06
Iter: 1316 loss: 5.72310364e-06
Iter: 1317 loss: 5.71083228e-06
Iter: 1318 loss: 5.70746488e-06
Iter: 1319 loss: 5.72638919e-06
Iter: 1320 loss: 5.70689144e-06
Iter: 1321 loss: 5.7037214e-06
Iter: 1322 loss: 5.70214024e-06
Iter: 1323 loss: 5.70052862e-06
Iter: 1324 loss: 5.69733038e-06
Iter: 1325 loss: 5.7297957e-06
Iter: 1326 loss: 5.69700933e-06
Iter: 1327 loss: 5.69476197e-06
Iter: 1328 loss: 5.69531e-06
Iter: 1329 loss: 5.69303393e-06
Iter: 1330 loss: 5.68981795e-06
Iter: 1331 loss: 5.73042144e-06
Iter: 1332 loss: 5.68986161e-06
Iter: 1333 loss: 5.68797168e-06
Iter: 1334 loss: 5.68452742e-06
Iter: 1335 loss: 5.6847266e-06
Iter: 1336 loss: 5.68030146e-06
Iter: 1337 loss: 5.69806616e-06
Iter: 1338 loss: 5.67964344e-06
Iter: 1339 loss: 5.67816551e-06
Iter: 1340 loss: 5.67797542e-06
Iter: 1341 loss: 5.67545521e-06
Iter: 1342 loss: 5.67413508e-06
Iter: 1343 loss: 5.67336974e-06
Iter: 1344 loss: 5.67116649e-06
Iter: 1345 loss: 5.67648203e-06
Iter: 1346 loss: 5.6701374e-06
Iter: 1347 loss: 5.66738e-06
Iter: 1348 loss: 5.66377457e-06
Iter: 1349 loss: 5.66387189e-06
Iter: 1350 loss: 5.65984692e-06
Iter: 1351 loss: 5.71876808e-06
Iter: 1352 loss: 5.65986056e-06
Iter: 1353 loss: 5.65779965e-06
Iter: 1354 loss: 5.66302424e-06
Iter: 1355 loss: 5.6568656e-06
Iter: 1356 loss: 5.65379e-06
Iter: 1357 loss: 5.65268238e-06
Iter: 1358 loss: 5.6509607e-06
Iter: 1359 loss: 5.64751099e-06
Iter: 1360 loss: 5.66247218e-06
Iter: 1361 loss: 5.6463482e-06
Iter: 1362 loss: 5.64343054e-06
Iter: 1363 loss: 5.67551933e-06
Iter: 1364 loss: 5.64349057e-06
Iter: 1365 loss: 5.64079801e-06
Iter: 1366 loss: 5.64558104e-06
Iter: 1367 loss: 5.63961e-06
Iter: 1368 loss: 5.63738377e-06
Iter: 1369 loss: 5.63626145e-06
Iter: 1370 loss: 5.63509639e-06
Iter: 1371 loss: 5.63158892e-06
Iter: 1372 loss: 5.64551283e-06
Iter: 1373 loss: 5.63118e-06
Iter: 1374 loss: 5.62883679e-06
Iter: 1375 loss: 5.62829791e-06
Iter: 1376 loss: 5.62740297e-06
Iter: 1377 loss: 5.62512105e-06
Iter: 1378 loss: 5.67421e-06
Iter: 1379 loss: 5.62506284e-06
Iter: 1380 loss: 5.62277501e-06
Iter: 1381 loss: 5.62565356e-06
Iter: 1382 loss: 5.62143123e-06
Iter: 1383 loss: 5.6175536e-06
Iter: 1384 loss: 5.61818024e-06
Iter: 1385 loss: 5.61451088e-06
Iter: 1386 loss: 5.61114393e-06
Iter: 1387 loss: 5.63189496e-06
Iter: 1388 loss: 5.61050547e-06
Iter: 1389 loss: 5.60701938e-06
Iter: 1390 loss: 5.61973138e-06
Iter: 1391 loss: 5.6060062e-06
Iter: 1392 loss: 5.60376611e-06
Iter: 1393 loss: 5.60436092e-06
Iter: 1394 loss: 5.6020076e-06
Iter: 1395 loss: 5.59866612e-06
Iter: 1396 loss: 5.60365606e-06
Iter: 1397 loss: 5.5969158e-06
Iter: 1398 loss: 5.59415912e-06
Iter: 1399 loss: 5.59413365e-06
Iter: 1400 loss: 5.59192176e-06
Iter: 1401 loss: 5.58884039e-06
Iter: 1402 loss: 5.5889841e-06
Iter: 1403 loss: 5.58555166e-06
Iter: 1404 loss: 5.5944638e-06
Iter: 1405 loss: 5.58446618e-06
Iter: 1406 loss: 5.58215288e-06
Iter: 1407 loss: 5.58211104e-06
Iter: 1408 loss: 5.5799228e-06
Iter: 1409 loss: 5.58719239e-06
Iter: 1410 loss: 5.57927251e-06
Iter: 1411 loss: 5.57804924e-06
Iter: 1412 loss: 5.57521253e-06
Iter: 1413 loss: 5.60289209e-06
Iter: 1414 loss: 5.57477324e-06
Iter: 1415 loss: 5.57103158e-06
Iter: 1416 loss: 5.60869603e-06
Iter: 1417 loss: 5.5711771e-06
Iter: 1418 loss: 5.56861369e-06
Iter: 1419 loss: 5.56840905e-06
Iter: 1420 loss: 5.56652185e-06
Iter: 1421 loss: 5.5631881e-06
Iter: 1422 loss: 5.58478223e-06
Iter: 1423 loss: 5.56290797e-06
Iter: 1424 loss: 5.56040141e-06
Iter: 1425 loss: 5.56412397e-06
Iter: 1426 loss: 5.55910765e-06
Iter: 1427 loss: 5.55563565e-06
Iter: 1428 loss: 5.5606406e-06
Iter: 1429 loss: 5.55422412e-06
Iter: 1430 loss: 5.5508167e-06
Iter: 1431 loss: 5.54985581e-06
Iter: 1432 loss: 5.5478904e-06
Iter: 1433 loss: 5.54319195e-06
Iter: 1434 loss: 5.58588e-06
Iter: 1435 loss: 5.54278176e-06
Iter: 1436 loss: 5.5405917e-06
Iter: 1437 loss: 5.55777342e-06
Iter: 1438 loss: 5.54011831e-06
Iter: 1439 loss: 5.53753398e-06
Iter: 1440 loss: 5.5396049e-06
Iter: 1441 loss: 5.53562086e-06
Iter: 1442 loss: 5.53413247e-06
Iter: 1443 loss: 5.54226517e-06
Iter: 1444 loss: 5.53367681e-06
Iter: 1445 loss: 5.53143218e-06
Iter: 1446 loss: 5.54371809e-06
Iter: 1447 loss: 5.53112e-06
Iter: 1448 loss: 5.52911115e-06
Iter: 1449 loss: 5.52497841e-06
Iter: 1450 loss: 5.56943633e-06
Iter: 1451 loss: 5.52465599e-06
Iter: 1452 loss: 5.52110487e-06
Iter: 1453 loss: 5.52632355e-06
Iter: 1454 loss: 5.51930498e-06
Iter: 1455 loss: 5.51534413e-06
Iter: 1456 loss: 5.54536791e-06
Iter: 1457 loss: 5.51508128e-06
Iter: 1458 loss: 5.51225685e-06
Iter: 1459 loss: 5.51436506e-06
Iter: 1460 loss: 5.51032372e-06
Iter: 1461 loss: 5.50685763e-06
Iter: 1462 loss: 5.53871905e-06
Iter: 1463 loss: 5.50652794e-06
Iter: 1464 loss: 5.50368895e-06
Iter: 1465 loss: 5.50537652e-06
Iter: 1466 loss: 5.50169534e-06
Iter: 1467 loss: 5.49846618e-06
Iter: 1468 loss: 5.5105711e-06
Iter: 1469 loss: 5.49759534e-06
Iter: 1470 loss: 5.493966e-06
Iter: 1471 loss: 5.49725701e-06
Iter: 1472 loss: 5.49196147e-06
Iter: 1473 loss: 5.48811977e-06
Iter: 1474 loss: 5.52205802e-06
Iter: 1475 loss: 5.48796606e-06
Iter: 1476 loss: 5.48542766e-06
Iter: 1477 loss: 5.49017113e-06
Iter: 1478 loss: 5.48439584e-06
Iter: 1479 loss: 5.48126172e-06
Iter: 1480 loss: 5.49702872e-06
Iter: 1481 loss: 5.48066919e-06
Iter: 1482 loss: 5.47877335e-06
Iter: 1483 loss: 5.4789416e-06
Iter: 1484 loss: 5.47784703e-06
Iter: 1485 loss: 5.47503305e-06
Iter: 1486 loss: 5.49592096e-06
Iter: 1487 loss: 5.47443415e-06
Iter: 1488 loss: 5.47125319e-06
Iter: 1489 loss: 5.47462287e-06
Iter: 1490 loss: 5.4693428e-06
Iter: 1491 loss: 5.46570845e-06
Iter: 1492 loss: 5.47544914e-06
Iter: 1493 loss: 5.46458705e-06
Iter: 1494 loss: 5.46041338e-06
Iter: 1495 loss: 5.46781393e-06
Iter: 1496 loss: 5.4584425e-06
Iter: 1497 loss: 5.45432977e-06
Iter: 1498 loss: 5.4602524e-06
Iter: 1499 loss: 5.45214925e-06
Iter: 1500 loss: 5.44870591e-06
Iter: 1501 loss: 5.49538618e-06
Iter: 1502 loss: 5.44858358e-06
Iter: 1503 loss: 5.44627164e-06
Iter: 1504 loss: 5.45124249e-06
Iter: 1505 loss: 5.44531349e-06
Iter: 1506 loss: 5.44184059e-06
Iter: 1507 loss: 5.45134071e-06
Iter: 1508 loss: 5.44059912e-06
Iter: 1509 loss: 5.43824808e-06
Iter: 1510 loss: 5.43963142e-06
Iter: 1511 loss: 5.43711e-06
Iter: 1512 loss: 5.43436363e-06
Iter: 1513 loss: 5.46413776e-06
Iter: 1514 loss: 5.43391343e-06
Iter: 1515 loss: 5.43203896e-06
Iter: 1516 loss: 5.45024e-06
Iter: 1517 loss: 5.43201941e-06
Iter: 1518 loss: 5.43027272e-06
Iter: 1519 loss: 5.43194619e-06
Iter: 1520 loss: 5.42927137e-06
Iter: 1521 loss: 5.42770658e-06
Iter: 1522 loss: 5.42365e-06
Iter: 1523 loss: 5.49202559e-06
Iter: 1524 loss: 5.42372391e-06
Iter: 1525 loss: 5.41967393e-06
Iter: 1526 loss: 5.43080387e-06
Iter: 1527 loss: 5.41827831e-06
Iter: 1528 loss: 5.41499048e-06
Iter: 1529 loss: 5.44227805e-06
Iter: 1530 loss: 5.414925e-06
Iter: 1531 loss: 5.41224563e-06
Iter: 1532 loss: 5.41556892e-06
Iter: 1533 loss: 5.41089e-06
Iter: 1534 loss: 5.40766905e-06
Iter: 1535 loss: 5.42098769e-06
Iter: 1536 loss: 5.40709334e-06
Iter: 1537 loss: 5.40480914e-06
Iter: 1538 loss: 5.40099791e-06
Iter: 1539 loss: 5.40084056e-06
Iter: 1540 loss: 5.3973763e-06
Iter: 1541 loss: 5.39734538e-06
Iter: 1542 loss: 5.3945887e-06
Iter: 1543 loss: 5.3925819e-06
Iter: 1544 loss: 5.39163193e-06
Iter: 1545 loss: 5.3890044e-06
Iter: 1546 loss: 5.38887616e-06
Iter: 1547 loss: 5.38717859e-06
Iter: 1548 loss: 5.38576251e-06
Iter: 1549 loss: 5.38550194e-06
Iter: 1550 loss: 5.38402037e-06
Iter: 1551 loss: 5.38367613e-06
Iter: 1552 loss: 5.38216636e-06
Iter: 1553 loss: 5.37945289e-06
Iter: 1554 loss: 5.42866837e-06
Iter: 1555 loss: 5.37943151e-06
Iter: 1556 loss: 5.37685673e-06
Iter: 1557 loss: 5.37848973e-06
Iter: 1558 loss: 5.37520236e-06
Iter: 1559 loss: 5.37230471e-06
Iter: 1560 loss: 5.40673955e-06
Iter: 1561 loss: 5.37234837e-06
Iter: 1562 loss: 5.37016604e-06
Iter: 1563 loss: 5.36841708e-06
Iter: 1564 loss: 5.36787502e-06
Iter: 1565 loss: 5.36468951e-06
Iter: 1566 loss: 5.36988182e-06
Iter: 1567 loss: 5.36287962e-06
Iter: 1568 loss: 5.35924846e-06
Iter: 1569 loss: 5.37900542e-06
Iter: 1570 loss: 5.35885e-06
Iter: 1571 loss: 5.35609342e-06
Iter: 1572 loss: 5.3667568e-06
Iter: 1573 loss: 5.35545087e-06
Iter: 1574 loss: 5.35251411e-06
Iter: 1575 loss: 5.35426307e-06
Iter: 1576 loss: 5.35093432e-06
Iter: 1577 loss: 5.34784249e-06
Iter: 1578 loss: 5.36216567e-06
Iter: 1579 loss: 5.3474314e-06
Iter: 1580 loss: 5.34473247e-06
Iter: 1581 loss: 5.34980654e-06
Iter: 1582 loss: 5.34367291e-06
Iter: 1583 loss: 5.34128685e-06
Iter: 1584 loss: 5.37637789e-06
Iter: 1585 loss: 5.34130868e-06
Iter: 1586 loss: 5.33935327e-06
Iter: 1587 loss: 5.35309573e-06
Iter: 1588 loss: 5.33903949e-06
Iter: 1589 loss: 5.33790353e-06
Iter: 1590 loss: 5.33510593e-06
Iter: 1591 loss: 5.37550568e-06
Iter: 1592 loss: 5.33509819e-06
Iter: 1593 loss: 5.33208595e-06
Iter: 1594 loss: 5.34142873e-06
Iter: 1595 loss: 5.33110824e-06
Iter: 1596 loss: 5.32891727e-06
Iter: 1597 loss: 5.35535582e-06
Iter: 1598 loss: 5.32887634e-06
Iter: 1599 loss: 5.32677495e-06
Iter: 1600 loss: 5.323192e-06
Iter: 1601 loss: 5.40942756e-06
Iter: 1602 loss: 5.3232543e-06
Iter: 1603 loss: 5.31952583e-06
Iter: 1604 loss: 5.33050297e-06
Iter: 1605 loss: 5.31852265e-06
Iter: 1606 loss: 5.31489422e-06
Iter: 1607 loss: 5.32434933e-06
Iter: 1608 loss: 5.31332353e-06
Iter: 1609 loss: 5.31012483e-06
Iter: 1610 loss: 5.32648482e-06
Iter: 1611 loss: 5.30979378e-06
Iter: 1612 loss: 5.30638044e-06
Iter: 1613 loss: 5.31684782e-06
Iter: 1614 loss: 5.30562284e-06
Iter: 1615 loss: 5.30284888e-06
Iter: 1616 loss: 5.30783336e-06
Iter: 1617 loss: 5.30163607e-06
Iter: 1618 loss: 5.29887029e-06
Iter: 1619 loss: 5.3147669e-06
Iter: 1620 loss: 5.298617e-06
Iter: 1621 loss: 5.2973819e-06
Iter: 1622 loss: 5.2973237e-06
Iter: 1623 loss: 5.29615045e-06
Iter: 1624 loss: 5.29444242e-06
Iter: 1625 loss: 5.29432236e-06
Iter: 1626 loss: 5.29240879e-06
Iter: 1627 loss: 5.29657427e-06
Iter: 1628 loss: 5.29154659e-06
Iter: 1629 loss: 5.28913733e-06
Iter: 1630 loss: 5.28748114e-06
Iter: 1631 loss: 5.28700048e-06
Iter: 1632 loss: 5.28421151e-06
Iter: 1633 loss: 5.28419559e-06
Iter: 1634 loss: 5.28221426e-06
Iter: 1635 loss: 5.28182409e-06
Iter: 1636 loss: 5.28050714e-06
Iter: 1637 loss: 5.27672955e-06
Iter: 1638 loss: 5.27393513e-06
Iter: 1639 loss: 5.27289876e-06
Iter: 1640 loss: 5.26912618e-06
Iter: 1641 loss: 5.28467808e-06
Iter: 1642 loss: 5.26853728e-06
Iter: 1643 loss: 5.26476379e-06
Iter: 1644 loss: 5.27521479e-06
Iter: 1645 loss: 5.26336771e-06
Iter: 1646 loss: 5.26006033e-06
Iter: 1647 loss: 5.27392876e-06
Iter: 1648 loss: 5.25972155e-06
Iter: 1649 loss: 5.25628911e-06
Iter: 1650 loss: 5.27051e-06
Iter: 1651 loss: 5.25560245e-06
Iter: 1652 loss: 5.25328414e-06
Iter: 1653 loss: 5.27163138e-06
Iter: 1654 loss: 5.25304313e-06
Iter: 1655 loss: 5.25007817e-06
Iter: 1656 loss: 5.25858104e-06
Iter: 1657 loss: 5.24917914e-06
Iter: 1658 loss: 5.24757888e-06
Iter: 1659 loss: 5.24614279e-06
Iter: 1660 loss: 5.24574807e-06
Iter: 1661 loss: 5.24375673e-06
Iter: 1662 loss: 5.25321957e-06
Iter: 1663 loss: 5.24296593e-06
Iter: 1664 loss: 5.2406449e-06
Iter: 1665 loss: 5.24205507e-06
Iter: 1666 loss: 5.23941708e-06
Iter: 1667 loss: 5.23674e-06
Iter: 1668 loss: 5.2538835e-06
Iter: 1669 loss: 5.23604e-06
Iter: 1670 loss: 5.23415929e-06
Iter: 1671 loss: 5.23457493e-06
Iter: 1672 loss: 5.23230074e-06
Iter: 1673 loss: 5.22987557e-06
Iter: 1674 loss: 5.23015251e-06
Iter: 1675 loss: 5.22800201e-06
Iter: 1676 loss: 5.22385835e-06
Iter: 1677 loss: 5.2360665e-06
Iter: 1678 loss: 5.22290247e-06
Iter: 1679 loss: 5.2195e-06
Iter: 1680 loss: 5.21983748e-06
Iter: 1681 loss: 5.21656375e-06
Iter: 1682 loss: 5.21339553e-06
Iter: 1683 loss: 5.21348284e-06
Iter: 1684 loss: 5.21122274e-06
Iter: 1685 loss: 5.21675065e-06
Iter: 1686 loss: 5.21010406e-06
Iter: 1687 loss: 5.20733875e-06
Iter: 1688 loss: 5.24040752e-06
Iter: 1689 loss: 5.20733829e-06
Iter: 1690 loss: 5.20599451e-06
Iter: 1691 loss: 5.20556932e-06
Iter: 1692 loss: 5.20462254e-06
Iter: 1693 loss: 5.20282447e-06
Iter: 1694 loss: 5.20095e-06
Iter: 1695 loss: 5.20088679e-06
Iter: 1696 loss: 5.19743389e-06
Iter: 1697 loss: 5.21419861e-06
Iter: 1698 loss: 5.19688547e-06
Iter: 1699 loss: 5.19414061e-06
Iter: 1700 loss: 5.20624053e-06
Iter: 1701 loss: 5.19349851e-06
Iter: 1702 loss: 5.19108471e-06
Iter: 1703 loss: 5.19472633e-06
Iter: 1704 loss: 5.18983416e-06
Iter: 1705 loss: 5.18684874e-06
Iter: 1706 loss: 5.19600599e-06
Iter: 1707 loss: 5.1859779e-06
Iter: 1708 loss: 5.18327397e-06
Iter: 1709 loss: 5.18462275e-06
Iter: 1710 loss: 5.18154866e-06
Iter: 1711 loss: 5.17840635e-06
Iter: 1712 loss: 5.17844046e-06
Iter: 1713 loss: 5.17594435e-06
Iter: 1714 loss: 5.17186754e-06
Iter: 1715 loss: 5.20268713e-06
Iter: 1716 loss: 5.1716579e-06
Iter: 1717 loss: 5.16860791e-06
Iter: 1718 loss: 5.17054468e-06
Iter: 1719 loss: 5.16693035e-06
Iter: 1720 loss: 5.16783666e-06
Iter: 1721 loss: 5.16544424e-06
Iter: 1722 loss: 5.16412547e-06
Iter: 1723 loss: 5.16201453e-06
Iter: 1724 loss: 5.16209093e-06
Iter: 1725 loss: 5.15947158e-06
Iter: 1726 loss: 5.16142791e-06
Iter: 1727 loss: 5.15786815e-06
Iter: 1728 loss: 5.15557394e-06
Iter: 1729 loss: 5.16293312e-06
Iter: 1730 loss: 5.15473403e-06
Iter: 1731 loss: 5.15254214e-06
Iter: 1732 loss: 5.15742522e-06
Iter: 1733 loss: 5.15184456e-06
Iter: 1734 loss: 5.14884732e-06
Iter: 1735 loss: 5.15686224e-06
Iter: 1736 loss: 5.14802559e-06
Iter: 1737 loss: 5.14563544e-06
Iter: 1738 loss: 5.15196871e-06
Iter: 1739 loss: 5.14459862e-06
Iter: 1740 loss: 5.14191743e-06
Iter: 1741 loss: 5.14689327e-06
Iter: 1742 loss: 5.14107796e-06
Iter: 1743 loss: 5.13853365e-06
Iter: 1744 loss: 5.14484191e-06
Iter: 1745 loss: 5.13759278e-06
Iter: 1746 loss: 5.1349034e-06
Iter: 1747 loss: 5.13187388e-06
Iter: 1748 loss: 5.13166924e-06
Iter: 1749 loss: 5.12742145e-06
Iter: 1750 loss: 5.16514774e-06
Iter: 1751 loss: 5.12738279e-06
Iter: 1752 loss: 5.12427277e-06
Iter: 1753 loss: 5.13523719e-06
Iter: 1754 loss: 5.12393763e-06
Iter: 1755 loss: 5.12213364e-06
Iter: 1756 loss: 5.12191309e-06
Iter: 1757 loss: 5.12096e-06
Iter: 1758 loss: 5.11856842e-06
Iter: 1759 loss: 5.14558269e-06
Iter: 1760 loss: 5.11842063e-06
Iter: 1761 loss: 5.11642202e-06
Iter: 1762 loss: 5.12619317e-06
Iter: 1763 loss: 5.11616417e-06
Iter: 1764 loss: 5.11386133e-06
Iter: 1765 loss: 5.11444614e-06
Iter: 1766 loss: 5.11223243e-06
Iter: 1767 loss: 5.10945e-06
Iter: 1768 loss: 5.11963844e-06
Iter: 1769 loss: 5.10823202e-06
Iter: 1770 loss: 5.10643895e-06
Iter: 1771 loss: 5.12727274e-06
Iter: 1772 loss: 5.10644668e-06
Iter: 1773 loss: 5.10413838e-06
Iter: 1774 loss: 5.10052678e-06
Iter: 1775 loss: 5.10074278e-06
Iter: 1776 loss: 5.09817e-06
Iter: 1777 loss: 5.09809797e-06
Iter: 1778 loss: 5.09623487e-06
Iter: 1779 loss: 5.09449274e-06
Iter: 1780 loss: 5.09397069e-06
Iter: 1781 loss: 5.09062602e-06
Iter: 1782 loss: 5.10908239e-06
Iter: 1783 loss: 5.09024676e-06
Iter: 1784 loss: 5.08752964e-06
Iter: 1785 loss: 5.08281755e-06
Iter: 1786 loss: 5.08277026e-06
Iter: 1787 loss: 5.08649509e-06
Iter: 1788 loss: 5.08149333e-06
Iter: 1789 loss: 5.08027824e-06
Iter: 1790 loss: 5.08179482e-06
Iter: 1791 loss: 5.07909408e-06
Iter: 1792 loss: 5.07824552e-06
Iter: 1793 loss: 5.07568075e-06
Iter: 1794 loss: 5.11672351e-06
Iter: 1795 loss: 5.07534742e-06
Iter: 1796 loss: 5.07278355e-06
Iter: 1797 loss: 5.10466543e-06
Iter: 1798 loss: 5.07278855e-06
Iter: 1799 loss: 5.07089226e-06
Iter: 1800 loss: 5.06951e-06
Iter: 1801 loss: 5.06870765e-06
Iter: 1802 loss: 5.06543256e-06
Iter: 1803 loss: 5.07437881e-06
Iter: 1804 loss: 5.06401284e-06
Iter: 1805 loss: 5.06124206e-06
Iter: 1806 loss: 5.07895629e-06
Iter: 1807 loss: 5.06076776e-06
Iter: 1808 loss: 5.05797652e-06
Iter: 1809 loss: 5.06517063e-06
Iter: 1810 loss: 5.05699609e-06
Iter: 1811 loss: 5.05469234e-06
Iter: 1812 loss: 5.05599701e-06
Iter: 1813 loss: 5.05337357e-06
Iter: 1814 loss: 5.05060416e-06
Iter: 1815 loss: 5.05511252e-06
Iter: 1816 loss: 5.04963828e-06
Iter: 1817 loss: 5.04675609e-06
Iter: 1818 loss: 5.06535116e-06
Iter: 1819 loss: 5.04637546e-06
Iter: 1820 loss: 5.04397849e-06
Iter: 1821 loss: 5.04816762e-06
Iter: 1822 loss: 5.04287664e-06
Iter: 1823 loss: 5.04177569e-06
Iter: 1824 loss: 5.04152513e-06
Iter: 1825 loss: 5.03982437e-06
Iter: 1826 loss: 5.03741285e-06
Iter: 1827 loss: 5.03739193e-06
Iter: 1828 loss: 5.03550109e-06
Iter: 1829 loss: 5.03781166e-06
Iter: 1830 loss: 5.03456431e-06
Iter: 1831 loss: 5.03203546e-06
Iter: 1832 loss: 5.03276806e-06
Iter: 1833 loss: 5.03034698e-06
Iter: 1834 loss: 5.02807825e-06
Iter: 1835 loss: 5.05906246e-06
Iter: 1836 loss: 5.02799821e-06
Iter: 1837 loss: 5.025679e-06
Iter: 1838 loss: 5.02366402e-06
Iter: 1839 loss: 5.02294733e-06
Iter: 1840 loss: 5.02066314e-06
Iter: 1841 loss: 5.05143817e-06
Iter: 1842 loss: 5.02080366e-06
Iter: 1843 loss: 5.01852082e-06
Iter: 1844 loss: 5.02224066e-06
Iter: 1845 loss: 5.01745035e-06
Iter: 1846 loss: 5.01539898e-06
Iter: 1847 loss: 5.01739578e-06
Iter: 1848 loss: 5.01404202e-06
Iter: 1849 loss: 5.01192198e-06
Iter: 1850 loss: 5.00925671e-06
Iter: 1851 loss: 5.00881333e-06
Iter: 1852 loss: 5.00656188e-06
Iter: 1853 loss: 5.00655187e-06
Iter: 1854 loss: 5.00484111e-06
Iter: 1855 loss: 5.00801161e-06
Iter: 1856 loss: 5.00415308e-06
Iter: 1857 loss: 5.00248e-06
Iter: 1858 loss: 5.02775038e-06
Iter: 1859 loss: 5.00262558e-06
Iter: 1860 loss: 5.00120404e-06
Iter: 1861 loss: 4.99922862e-06
Iter: 1862 loss: 4.99908811e-06
Iter: 1863 loss: 4.99708221e-06
Iter: 1864 loss: 4.9961327e-06
Iter: 1865 loss: 4.99542057e-06
Iter: 1866 loss: 4.99201542e-06
Iter: 1867 loss: 5.00017813e-06
Iter: 1868 loss: 4.99112502e-06
Iter: 1869 loss: 4.98828513e-06
Iter: 1870 loss: 5.00134684e-06
Iter: 1871 loss: 4.98771351e-06
Iter: 1872 loss: 4.98539066e-06
Iter: 1873 loss: 4.99161e-06
Iter: 1874 loss: 4.984523e-06
Iter: 1875 loss: 4.98142754e-06
Iter: 1876 loss: 4.99151747e-06
Iter: 1877 loss: 4.98032296e-06
Iter: 1878 loss: 4.97760084e-06
Iter: 1879 loss: 4.98676445e-06
Iter: 1880 loss: 4.9767209e-06
Iter: 1881 loss: 4.97447763e-06
Iter: 1882 loss: 4.98076542e-06
Iter: 1883 loss: 4.97342353e-06
Iter: 1884 loss: 4.97087422e-06
Iter: 1885 loss: 4.97725432e-06
Iter: 1886 loss: 4.96997563e-06
Iter: 1887 loss: 4.96791381e-06
Iter: 1888 loss: 4.96633675e-06
Iter: 1889 loss: 4.96576513e-06
Iter: 1890 loss: 4.96393159e-06
Iter: 1891 loss: 4.96355324e-06
Iter: 1892 loss: 4.96183338e-06
Iter: 1893 loss: 4.97409837e-06
Iter: 1894 loss: 4.96182383e-06
Iter: 1895 loss: 4.96063331e-06
Iter: 1896 loss: 4.95913173e-06
Iter: 1897 loss: 4.95879885e-06
Iter: 1898 loss: 4.95668837e-06
Iter: 1899 loss: 4.96144366e-06
Iter: 1900 loss: 4.95581116e-06
Iter: 1901 loss: 4.95368522e-06
Iter: 1902 loss: 4.95197401e-06
Iter: 1903 loss: 4.95119411e-06
Iter: 1904 loss: 4.94791311e-06
Iter: 1905 loss: 4.97565634e-06
Iter: 1906 loss: 4.94768756e-06
Iter: 1907 loss: 4.94523101e-06
Iter: 1908 loss: 4.94286815e-06
Iter: 1909 loss: 4.94231563e-06
Iter: 1910 loss: 4.93927837e-06
Iter: 1911 loss: 4.93939342e-06
Iter: 1912 loss: 4.93708285e-06
Iter: 1913 loss: 4.9457758e-06
Iter: 1914 loss: 4.93694552e-06
Iter: 1915 loss: 4.93422795e-06
Iter: 1916 loss: 4.93703465e-06
Iter: 1917 loss: 4.93280822e-06
Iter: 1918 loss: 4.93048492e-06
Iter: 1919 loss: 4.93438529e-06
Iter: 1920 loss: 4.92968775e-06
Iter: 1921 loss: 4.92737354e-06
Iter: 1922 loss: 4.93929656e-06
Iter: 1923 loss: 4.92727941e-06
Iter: 1924 loss: 4.92564686e-06
Iter: 1925 loss: 4.93565358e-06
Iter: 1926 loss: 4.92540266e-06
Iter: 1927 loss: 4.92362415e-06
Iter: 1928 loss: 4.93373864e-06
Iter: 1929 loss: 4.92329582e-06
Iter: 1930 loss: 4.92230583e-06
Iter: 1931 loss: 4.92101617e-06
Iter: 1932 loss: 4.92073104e-06
Iter: 1933 loss: 4.91910941e-06
Iter: 1934 loss: 4.91567243e-06
Iter: 1935 loss: 4.915707e-06
Iter: 1936 loss: 4.91272385e-06
Iter: 1937 loss: 4.91266883e-06
Iter: 1938 loss: 4.91089077e-06
Iter: 1939 loss: 4.91490846e-06
Iter: 1940 loss: 4.90967795e-06
Iter: 1941 loss: 4.90685215e-06
Iter: 1942 loss: 4.91103037e-06
Iter: 1943 loss: 4.90552338e-06
Iter: 1944 loss: 4.90314915e-06
Iter: 1945 loss: 4.90350612e-06
Iter: 1946 loss: 4.90124648e-06
Iter: 1947 loss: 4.89819604e-06
Iter: 1948 loss: 4.92242452e-06
Iter: 1949 loss: 4.89775357e-06
Iter: 1950 loss: 4.89594186e-06
Iter: 1951 loss: 4.91678475e-06
Iter: 1952 loss: 4.89596459e-06
Iter: 1953 loss: 4.89420472e-06
Iter: 1954 loss: 4.89432932e-06
Iter: 1955 loss: 4.89249851e-06
Iter: 1956 loss: 4.89074409e-06
Iter: 1957 loss: 4.89092645e-06
Iter: 1958 loss: 4.88929936e-06
Iter: 1959 loss: 4.88773321e-06
Iter: 1960 loss: 4.88758496e-06
Iter: 1961 loss: 4.88561955e-06
Iter: 1962 loss: 4.89064678e-06
Iter: 1963 loss: 4.88476599e-06
Iter: 1964 loss: 4.88383557e-06
Iter: 1965 loss: 4.88292881e-06
Iter: 1966 loss: 4.88272553e-06
Iter: 1967 loss: 4.88008209e-06
Iter: 1968 loss: 4.87920715e-06
Iter: 1969 loss: 4.87799571e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f1_psi1_phi3/300_100_100_100_1
+ for fn in f1 f2
+ case $fn in
+ OPT=--alpha
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0
+ date
Sun Nov  8 06:25:25 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1 --function f2 --psi 0 --alpha 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc80167b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc7ff9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc80cdc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc810f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc80fe1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc80e5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc80396a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc7fd0158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc7fb2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc7f98620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef99a550d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef99a4fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef99a0a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef99a31048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef99a08950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef999f3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef999d8ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef999b48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef74245378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef74241d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef741fb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef742152f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef7420dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef741d97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef74191268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef74192c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef99aa1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc7f411e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fefc7f1dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef740af6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef740ca158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef740b2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef740f0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef740340d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef74037ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fef607dd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0014022897
test_loss: 0.0012390342
train_loss: 0.0012046505
test_loss: 0.0013208846
train_loss: 0.0011142113
test_loss: 0.0012389485
train_loss: 0.0013460538
test_loss: 0.001090409
train_loss: 0.0010151342
test_loss: 0.0011049967
train_loss: 0.0011758669
test_loss: 0.0010562948
train_loss: 0.0011730627
test_loss: 0.0011628703
train_loss: 0.0011858831
test_loss: 0.001111874
train_loss: 0.0010284178
test_loss: 0.0011410792
train_loss: 0.0010865777
test_loss: 0.0013150134
train_loss: 0.0015192451
test_loss: 0.001209545
train_loss: 0.0011380619
test_loss: 0.0011266685
train_loss: 0.0010626767
test_loss: 0.0011148388
train_loss: 0.0010200052
test_loss: 0.0011731571
train_loss: 0.0012415318
test_loss: 0.0015412924
train_loss: 0.0013004516
test_loss: 0.0018018484
train_loss: 0.0013408831
test_loss: 0.0014606683
train_loss: 0.0009813419
test_loss: 0.0012422481
train_loss: 0.001060466
test_loss: 0.001141796
train_loss: 0.0010849719
test_loss: 0.000978933
train_loss: 0.0010485165
test_loss: 0.0010330302
train_loss: 0.0017149766
test_loss: 0.0014554177
train_loss: 0.0015085529
test_loss: 0.0012871634
train_loss: 0.0012799595
test_loss: 0.0012200273
train_loss: 0.00095884706
test_loss: 0.0009590124
train_loss: 0.0011437346
test_loss: 0.0013673215
train_loss: 0.0011016161
test_loss: 0.0010593917
train_loss: 0.0016589838
test_loss: 0.0013304816
train_loss: 0.00096222735
test_loss: 0.0010385734
train_loss: 0.0011649712
test_loss: 0.0012819828
train_loss: 0.0009803349
test_loss: 0.00095470913
train_loss: 0.0011907606
test_loss: 0.0010814973
train_loss: 0.00096874643
test_loss: 0.0010059638
train_loss: 0.0014068612
test_loss: 0.0010586386
train_loss: 0.0010530493
test_loss: 0.0010745558
train_loss: 0.0010966549
test_loss: 0.001195819
train_loss: 0.0014441088
test_loss: 0.0014423736
train_loss: 0.0012066761
test_loss: 0.0013078479
train_loss: 0.0009729052
test_loss: 0.0010853867
train_loss: 0.0014415116
test_loss: 0.0010845357
train_loss: 0.00095510087
test_loss: 0.0011639359
train_loss: 0.001002776
test_loss: 0.0010379603
train_loss: 0.00096599804
test_loss: 0.001154971
train_loss: 0.0012373243
test_loss: 0.0010699758
train_loss: 0.0013253198
test_loss: 0.0010669718
train_loss: 0.0010426473
test_loss: 0.0010606769
train_loss: 0.0010645309
test_loss: 0.0009507927
train_loss: 0.001061948
test_loss: 0.0012182568
train_loss: 0.0010696665
test_loss: 0.0012699175
train_loss: 0.0009909568
test_loss: 0.00097179716
train_loss: 0.001064603
test_loss: 0.0009315667
train_loss: 0.0010232538
test_loss: 0.0009299922
train_loss: 0.0014591384
test_loss: 0.0010829681
train_loss: 0.0014114004
test_loss: 0.0012284812
train_loss: 0.0012025057
test_loss: 0.0011942593
train_loss: 0.0010247205
test_loss: 0.0009837688
train_loss: 0.0011301914
test_loss: 0.0009521506
train_loss: 0.0012963848
test_loss: 0.0011280476
train_loss: 0.0011338524
test_loss: 0.0010399828
train_loss: 0.00097207027
test_loss: 0.0009979912
train_loss: 0.0011382567
test_loss: 0.0011281058
train_loss: 0.0011007689
test_loss: 0.0010191972
train_loss: 0.0010020584
test_loss: 0.0010493898
train_loss: 0.001403687
test_loss: 0.001599938
train_loss: 0.0011864988
test_loss: 0.0010984077
train_loss: 0.00096232997
test_loss: 0.0008901825
train_loss: 0.00089592254
test_loss: 0.0009314168
train_loss: 0.0015087374
test_loss: 0.0011966634
train_loss: 0.0011961459
test_loss: 0.0013651
train_loss: 0.00094979664
test_loss: 0.001351831
train_loss: 0.0012552952
test_loss: 0.0010339725
train_loss: 0.0009653497
test_loss: 0.0011428416
train_loss: 0.00095947547
test_loss: 0.0011240579
train_loss: 0.0010611948
test_loss: 0.0009780228
train_loss: 0.00090440706
test_loss: 0.00090520247
train_loss: 0.0009372317
test_loss: 0.001277108
train_loss: 0.0010825503
test_loss: 0.0011718968
train_loss: 0.0009191668
test_loss: 0.0011580384
train_loss: 0.0011082259
test_loss: 0.0012027096
train_loss: 0.000983165
test_loss: 0.0010966051
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182af8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182a382f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182a14d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182b147b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182b47268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182a4ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182a85730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81829ea1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182a06bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81829b86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f818295b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f818296fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182930620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f818293d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182941ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81828f8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81828a4048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81828b89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f818287b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182878ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f818281d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f818283c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a371e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a3288c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a349378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a34ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a300840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a2b22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a2c8d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f816a2687b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8182a1e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8144322bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81443466a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81442e9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81442ffb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f81442b0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.74429101e-06
Iter: 2 loss: 9.95104529e-06
Iter: 3 loss: 1.05110098e-06
Iter: 4 loss: 9.26226221e-07
Iter: 5 loss: 8.61825242e-07
Iter: 6 loss: 8.03976945e-07
Iter: 7 loss: 7.52473056e-07
Iter: 8 loss: 1.34724223e-06
Iter: 9 loss: 7.51654852e-07
Iter: 10 loss: 6.9326677e-07
Iter: 11 loss: 6.63360765e-07
Iter: 12 loss: 6.36239236e-07
Iter: 13 loss: 6.16118e-07
Iter: 14 loss: 6.14439728e-07
Iter: 15 loss: 6.02070088e-07
Iter: 16 loss: 6.55199528e-07
Iter: 17 loss: 5.99517193e-07
Iter: 18 loss: 5.95677761e-07
Iter: 19 loss: 5.883212e-07
Iter: 20 loss: 7.43396413e-07
Iter: 21 loss: 5.88275157e-07
Iter: 22 loss: 5.8919494e-07
Iter: 23 loss: 5.86507497e-07
Iter: 24 loss: 5.84795e-07
Iter: 25 loss: 5.8553286e-07
Iter: 26 loss: 5.83614224e-07
Iter: 27 loss: 5.82425344e-07
Iter: 28 loss: 5.82566031e-07
Iter: 29 loss: 5.81521476e-07
Iter: 30 loss: 5.80668939e-07
Iter: 31 loss: 5.80613573e-07
Iter: 32 loss: 5.79945379e-07
Iter: 33 loss: 5.79013e-07
Iter: 34 loss: 5.77122307e-07
Iter: 35 loss: 6.15034082e-07
Iter: 36 loss: 5.77119295e-07
Iter: 37 loss: 5.75464e-07
Iter: 38 loss: 5.78587333e-07
Iter: 39 loss: 5.7474756e-07
Iter: 40 loss: 5.72783108e-07
Iter: 41 loss: 5.85477778e-07
Iter: 42 loss: 5.72559202e-07
Iter: 43 loss: 5.71530563e-07
Iter: 44 loss: 5.83609847e-07
Iter: 45 loss: 5.71529199e-07
Iter: 46 loss: 5.70063776e-07
Iter: 47 loss: 5.68243081e-07
Iter: 48 loss: 5.68117116e-07
Iter: 49 loss: 5.67248321e-07
Iter: 50 loss: 5.67212339e-07
Iter: 51 loss: 5.66430117e-07
Iter: 52 loss: 5.66520839e-07
Iter: 53 loss: 5.65828316e-07
Iter: 54 loss: 5.64877098e-07
Iter: 55 loss: 5.624712e-07
Iter: 56 loss: 5.86198269e-07
Iter: 57 loss: 5.62165383e-07
Iter: 58 loss: 5.61494403e-07
Iter: 59 loss: 5.61074444e-07
Iter: 60 loss: 5.602908e-07
Iter: 61 loss: 5.68498194e-07
Iter: 62 loss: 5.6028091e-07
Iter: 63 loss: 5.59796e-07
Iter: 64 loss: 5.5916e-07
Iter: 65 loss: 5.59125112e-07
Iter: 66 loss: 5.59193495e-07
Iter: 67 loss: 5.58854595e-07
Iter: 68 loss: 5.58725901e-07
Iter: 69 loss: 5.582923e-07
Iter: 70 loss: 5.59432067e-07
Iter: 71 loss: 5.5802991e-07
Iter: 72 loss: 5.57407304e-07
Iter: 73 loss: 5.59383125e-07
Iter: 74 loss: 5.57186468e-07
Iter: 75 loss: 5.56528278e-07
Iter: 76 loss: 5.55530846e-07
Iter: 77 loss: 5.55493841e-07
Iter: 78 loss: 5.55577458e-07
Iter: 79 loss: 5.54830194e-07
Iter: 80 loss: 5.5438818e-07
Iter: 81 loss: 5.53385576e-07
Iter: 82 loss: 5.6542774e-07
Iter: 83 loss: 5.53283257e-07
Iter: 84 loss: 5.52252e-07
Iter: 85 loss: 5.51904122e-07
Iter: 86 loss: 5.51296807e-07
Iter: 87 loss: 5.50815514e-07
Iter: 88 loss: 5.5311159e-07
Iter: 89 loss: 5.5072644e-07
Iter: 90 loss: 5.50388108e-07
Iter: 91 loss: 5.52598522e-07
Iter: 92 loss: 5.50378843e-07
Iter: 93 loss: 5.50031359e-07
Iter: 94 loss: 5.49629135e-07
Iter: 95 loss: 5.49605261e-07
Iter: 96 loss: 5.493049e-07
Iter: 97 loss: 5.51621611e-07
Iter: 98 loss: 5.49282163e-07
Iter: 99 loss: 5.49087758e-07
Iter: 100 loss: 5.48470553e-07
Iter: 101 loss: 5.5085269e-07
Iter: 102 loss: 5.48197875e-07
Iter: 103 loss: 5.48067192e-07
Iter: 104 loss: 5.47784907e-07
Iter: 105 loss: 5.47422644e-07
Iter: 106 loss: 5.49606739e-07
Iter: 107 loss: 5.47404909e-07
Iter: 108 loss: 5.47093862e-07
Iter: 109 loss: 5.46469721e-07
Iter: 110 loss: 5.55103952e-07
Iter: 111 loss: 5.4644039e-07
Iter: 112 loss: 5.4576708e-07
Iter: 113 loss: 5.46752233e-07
Iter: 114 loss: 5.45478713e-07
Iter: 115 loss: 5.45243722e-07
Iter: 116 loss: 5.45032265e-07
Iter: 117 loss: 5.44700356e-07
Iter: 118 loss: 5.44192062e-07
Iter: 119 loss: 5.44139709e-07
Iter: 120 loss: 5.43715828e-07
Iter: 121 loss: 5.43647502e-07
Iter: 122 loss: 5.43342e-07
Iter: 123 loss: 5.43078045e-07
Iter: 124 loss: 5.42958617e-07
Iter: 125 loss: 5.42810767e-07
Iter: 126 loss: 5.42835437e-07
Iter: 127 loss: 5.4273346e-07
Iter: 128 loss: 5.42595046e-07
Iter: 129 loss: 5.43744932e-07
Iter: 130 loss: 5.4260147e-07
Iter: 131 loss: 5.42455552e-07
Iter: 132 loss: 5.42263535e-07
Iter: 133 loss: 5.42254611e-07
Iter: 134 loss: 5.42106704e-07
Iter: 135 loss: 5.42123189e-07
Iter: 136 loss: 5.42020302e-07
Iter: 137 loss: 5.41792588e-07
Iter: 138 loss: 5.42484372e-07
Iter: 139 loss: 5.41739269e-07
Iter: 140 loss: 5.41541112e-07
Iter: 141 loss: 5.41533041e-07
Iter: 142 loss: 5.41426743e-07
Iter: 143 loss: 5.41086e-07
Iter: 144 loss: 5.42252053e-07
Iter: 145 loss: 5.40973588e-07
Iter: 146 loss: 5.40383496e-07
Iter: 147 loss: 5.43652618e-07
Iter: 148 loss: 5.40344672e-07
Iter: 149 loss: 5.39971325e-07
Iter: 150 loss: 5.39983944e-07
Iter: 151 loss: 5.39788061e-07
Iter: 152 loss: 5.39375264e-07
Iter: 153 loss: 5.42107e-07
Iter: 154 loss: 5.39255382e-07
Iter: 155 loss: 5.39128e-07
Iter: 156 loss: 5.39026075e-07
Iter: 157 loss: 5.3882161e-07
Iter: 158 loss: 5.38984864e-07
Iter: 159 loss: 5.38719064e-07
Iter: 160 loss: 5.38516417e-07
Iter: 161 loss: 5.38887775e-07
Iter: 162 loss: 5.38468498e-07
Iter: 163 loss: 5.38290692e-07
Iter: 164 loss: 5.38302345e-07
Iter: 165 loss: 5.38264e-07
Iter: 166 loss: 5.38127e-07
Iter: 167 loss: 5.39224e-07
Iter: 168 loss: 5.38103109e-07
Iter: 169 loss: 5.37890287e-07
Iter: 170 loss: 5.38119707e-07
Iter: 171 loss: 5.37784388e-07
Iter: 172 loss: 5.37735843e-07
Iter: 173 loss: 5.37727146e-07
Iter: 174 loss: 5.37602091e-07
Iter: 175 loss: 5.37484368e-07
Iter: 176 loss: 5.37483402e-07
Iter: 177 loss: 5.37348e-07
Iter: 178 loss: 5.37302185e-07
Iter: 179 loss: 5.37241476e-07
Iter: 180 loss: 5.37151152e-07
Iter: 181 loss: 5.37100334e-07
Iter: 182 loss: 5.37034509e-07
Iter: 183 loss: 5.36754101e-07
Iter: 184 loss: 5.38962e-07
Iter: 185 loss: 5.36714083e-07
Iter: 186 loss: 5.36491712e-07
Iter: 187 loss: 5.36772916e-07
Iter: 188 loss: 5.36367452e-07
Iter: 189 loss: 5.36122457e-07
Iter: 190 loss: 5.3909929e-07
Iter: 191 loss: 5.36124162e-07
Iter: 192 loss: 5.35984498e-07
Iter: 193 loss: 5.35945048e-07
Iter: 194 loss: 5.3587155e-07
Iter: 195 loss: 5.35770369e-07
Iter: 196 loss: 5.35765139e-07
Iter: 197 loss: 5.35653896e-07
Iter: 198 loss: 5.35641846e-07
Iter: 199 loss: 5.35549646e-07
Iter: 200 loss: 5.35488766e-07
Iter: 201 loss: 5.35567949e-07
Iter: 202 loss: 5.35420327e-07
Iter: 203 loss: 5.35339268e-07
Iter: 204 loss: 5.35402592e-07
Iter: 205 loss: 5.35315166e-07
Iter: 206 loss: 5.35213132e-07
Iter: 207 loss: 5.3614292e-07
Iter: 208 loss: 5.3520921e-07
Iter: 209 loss: 5.35151116e-07
Iter: 210 loss: 5.35080915e-07
Iter: 211 loss: 5.35095637e-07
Iter: 212 loss: 5.34979904e-07
Iter: 213 loss: 5.35256731e-07
Iter: 214 loss: 5.34939943e-07
Iter: 215 loss: 5.34765604e-07
Iter: 216 loss: 5.34882417e-07
Iter: 217 loss: 5.34665844e-07
Iter: 218 loss: 5.34524474e-07
Iter: 219 loss: 5.34349056e-07
Iter: 220 loss: 5.34343485e-07
Iter: 221 loss: 5.34233209e-07
Iter: 222 loss: 5.34188e-07
Iter: 223 loss: 5.34089509e-07
Iter: 224 loss: 5.33919433e-07
Iter: 225 loss: 5.33915227e-07
Iter: 226 loss: 5.3375868e-07
Iter: 227 loss: 5.35987738e-07
Iter: 228 loss: 5.33763853e-07
Iter: 229 loss: 5.33635614e-07
Iter: 230 loss: 5.33810862e-07
Iter: 231 loss: 5.33580931e-07
Iter: 232 loss: 5.335e-07
Iter: 233 loss: 5.33572631e-07
Iter: 234 loss: 5.33461105e-07
Iter: 235 loss: 5.33361685e-07
Iter: 236 loss: 5.33365892e-07
Iter: 237 loss: 5.33279433e-07
Iter: 238 loss: 5.33178763e-07
Iter: 239 loss: 5.34439e-07
Iter: 240 loss: 5.3318e-07
Iter: 241 loss: 5.33132493e-07
Iter: 242 loss: 5.33082357e-07
Iter: 243 loss: 5.33048933e-07
Iter: 244 loss: 5.32955482e-07
Iter: 245 loss: 5.33016077e-07
Iter: 246 loss: 5.32890965e-07
Iter: 247 loss: 5.32817239e-07
Iter: 248 loss: 5.32795241e-07
Iter: 249 loss: 5.32751301e-07
Iter: 250 loss: 5.32655235e-07
Iter: 251 loss: 5.32892727e-07
Iter: 252 loss: 5.32592708e-07
Iter: 253 loss: 5.3250352e-07
Iter: 254 loss: 5.32483057e-07
Iter: 255 loss: 5.32391823e-07
Iter: 256 loss: 5.32411036e-07
Iter: 257 loss: 5.32327363e-07
Iter: 258 loss: 5.32227659e-07
Iter: 259 loss: 5.3261e-07
Iter: 260 loss: 5.32221861e-07
Iter: 261 loss: 5.32077593e-07
Iter: 262 loss: 5.32176e-07
Iter: 263 loss: 5.32024046e-07
Iter: 264 loss: 5.31874889e-07
Iter: 265 loss: 5.32178319e-07
Iter: 266 loss: 5.31789567e-07
Iter: 267 loss: 5.31639387e-07
Iter: 268 loss: 5.31704472e-07
Iter: 269 loss: 5.31541048e-07
Iter: 270 loss: 5.31323906e-07
Iter: 271 loss: 5.32710942e-07
Iter: 272 loss: 5.31327146e-07
Iter: 273 loss: 5.31180774e-07
Iter: 274 loss: 5.31061687e-07
Iter: 275 loss: 5.31034e-07
Iter: 276 loss: 5.30879163e-07
Iter: 277 loss: 5.31647402e-07
Iter: 278 loss: 5.30847501e-07
Iter: 279 loss: 5.30835393e-07
Iter: 280 loss: 5.30786338e-07
Iter: 281 loss: 5.30778323e-07
Iter: 282 loss: 5.3067356e-07
Iter: 283 loss: 5.31683952e-07
Iter: 284 loss: 5.30650823e-07
Iter: 285 loss: 5.30579484e-07
Iter: 286 loss: 5.31547528e-07
Iter: 287 loss: 5.30566467e-07
Iter: 288 loss: 5.30536624e-07
Iter: 289 loss: 5.30936347e-07
Iter: 290 loss: 5.30511215e-07
Iter: 291 loss: 5.3048069e-07
Iter: 292 loss: 5.3049007e-07
Iter: 293 loss: 5.30476541e-07
Iter: 294 loss: 5.30420323e-07
Iter: 295 loss: 5.30585908e-07
Iter: 296 loss: 5.30395141e-07
Iter: 297 loss: 5.30370244e-07
Iter: 298 loss: 5.30437148e-07
Iter: 299 loss: 5.3034762e-07
Iter: 300 loss: 5.30284296e-07
Iter: 301 loss: 5.30308171e-07
Iter: 302 loss: 5.30256841e-07
Iter: 303 loss: 5.30224838e-07
Iter: 304 loss: 5.30539467e-07
Iter: 305 loss: 5.30186753e-07
Iter: 306 loss: 5.30129057e-07
Iter: 307 loss: 5.30133377e-07
Iter: 308 loss: 5.30093303e-07
Iter: 309 loss: 5.30020543e-07
Iter: 310 loss: 5.29952842e-07
Iter: 311 loss: 5.29925842e-07
Iter: 312 loss: 5.29881618e-07
Iter: 313 loss: 5.29880424e-07
Iter: 314 loss: 5.29803401e-07
Iter: 315 loss: 5.29719102e-07
Iter: 316 loss: 5.29712622e-07
Iter: 317 loss: 5.29588874e-07
Iter: 318 loss: 5.29771e-07
Iter: 319 loss: 5.29528791e-07
Iter: 320 loss: 5.29437955e-07
Iter: 321 loss: 5.29441763e-07
Iter: 322 loss: 5.29383044e-07
Iter: 323 loss: 5.29281294e-07
Iter: 324 loss: 5.29300166e-07
Iter: 325 loss: 5.29223428e-07
Iter: 326 loss: 5.29215e-07
Iter: 327 loss: 5.29162776e-07
Iter: 328 loss: 5.29244176e-07
Iter: 329 loss: 5.29133104e-07
Iter: 330 loss: 5.29078079e-07
Iter: 331 loss: 5.29073645e-07
Iter: 332 loss: 5.29011572e-07
Iter: 333 loss: 5.28943247e-07
Iter: 334 loss: 5.29341492e-07
Iter: 335 loss: 5.2897542e-07
Iter: 336 loss: 5.28871965e-07
Iter: 337 loss: 5.28984117e-07
Iter: 338 loss: 5.28834846e-07
Iter: 339 loss: 5.28768112e-07
Iter: 340 loss: 5.28700696e-07
Iter: 341 loss: 5.28689213e-07
Iter: 342 loss: 5.28626458e-07
Iter: 343 loss: 5.28606392e-07
Iter: 344 loss: 5.28553755e-07
Iter: 345 loss: 5.28539488e-07
Iter: 346 loss: 5.28502312e-07
Iter: 347 loss: 5.28431883e-07
Iter: 348 loss: 5.28323653e-07
Iter: 349 loss: 5.28304497e-07
Iter: 350 loss: 5.28272267e-07
Iter: 351 loss: 5.28231681e-07
Iter: 352 loss: 5.28169664e-07
Iter: 353 loss: 5.28013857e-07
Iter: 354 loss: 5.30021566e-07
Iter: 355 loss: 5.279785e-07
Iter: 356 loss: 5.27913755e-07
Iter: 357 loss: 5.27868565e-07
Iter: 358 loss: 5.27834e-07
Iter: 359 loss: 5.27862767e-07
Iter: 360 loss: 5.27785801e-07
Iter: 361 loss: 5.27689849e-07
Iter: 362 loss: 5.27695647e-07
Iter: 363 loss: 5.27608108e-07
Iter: 364 loss: 5.27504199e-07
Iter: 365 loss: 5.28715816e-07
Iter: 366 loss: 5.27529323e-07
Iter: 367 loss: 5.27416375e-07
Iter: 368 loss: 5.27521195e-07
Iter: 369 loss: 5.27363e-07
Iter: 370 loss: 5.27270686e-07
Iter: 371 loss: 5.27191332e-07
Iter: 372 loss: 5.2715842e-07
Iter: 373 loss: 5.27128464e-07
Iter: 374 loss: 5.27121074e-07
Iter: 375 loss: 5.27080658e-07
Iter: 376 loss: 5.2723766e-07
Iter: 377 loss: 5.27079237e-07
Iter: 378 loss: 5.27034445e-07
Iter: 379 loss: 5.26976692e-07
Iter: 380 loss: 5.27934617e-07
Iter: 381 loss: 5.26971462e-07
Iter: 382 loss: 5.26982831e-07
Iter: 383 loss: 5.2697095e-07
Iter: 384 loss: 5.26951453e-07
Iter: 385 loss: 5.26906604e-07
Iter: 386 loss: 5.26925533e-07
Iter: 387 loss: 5.26882047e-07
Iter: 388 loss: 5.27036377e-07
Iter: 389 loss: 5.26876647e-07
Iter: 390 loss: 5.26850499e-07
Iter: 391 loss: 5.26853114e-07
Iter: 392 loss: 5.26828899e-07
Iter: 393 loss: 5.26760516e-07
Iter: 394 loss: 5.26682072e-07
Iter: 395 loss: 5.26672522e-07
Iter: 396 loss: 5.26571398e-07
Iter: 397 loss: 5.27528584e-07
Iter: 398 loss: 5.26571398e-07
Iter: 399 loss: 5.26444467e-07
Iter: 400 loss: 5.26672125e-07
Iter: 401 loss: 5.26429233e-07
Iter: 402 loss: 5.26344309e-07
Iter: 403 loss: 5.26258475e-07
Iter: 404 loss: 5.26260351e-07
Iter: 405 loss: 5.2613359e-07
Iter: 406 loss: 5.26706e-07
Iter: 407 loss: 5.26132339e-07
Iter: 408 loss: 5.26090389e-07
Iter: 409 loss: 5.26070892e-07
Iter: 410 loss: 5.26070323e-07
Iter: 411 loss: 5.25982955e-07
Iter: 412 loss: 5.27105385e-07
Iter: 413 loss: 5.25991254e-07
Iter: 414 loss: 5.25960218e-07
Iter: 415 loss: 5.26308099e-07
Iter: 416 loss: 5.25973178e-07
Iter: 417 loss: 5.259148e-07
Iter: 418 loss: 5.26047415e-07
Iter: 419 loss: 5.25931569e-07
Iter: 420 loss: 5.25905762e-07
Iter: 421 loss: 5.25901271e-07
Iter: 422 loss: 5.25915e-07
Iter: 423 loss: 5.25877283e-07
Iter: 424 loss: 5.26200381e-07
Iter: 425 loss: 5.25850851e-07
Iter: 426 loss: 5.25851647e-07
Iter: 427 loss: 5.25868586e-07
Iter: 428 loss: 5.25863584e-07
Iter: 429 loss: 5.25848e-07
Iter: 430 loss: 5.25856649e-07
Iter: 431 loss: 5.25868927e-07
Iter: 432 loss: 5.25860173e-07
Iter: 433 loss: 5.25877226e-07
Iter: 434 loss: 5.25867847e-07
Iter: 435 loss: 5.25859889e-07
Iter: 436 loss: 5.25858468e-07
Iter: 437 loss: 5.2585807e-07
Iter: 438 loss: 5.25857786e-07
Iter: 439 loss: 5.25854261e-07
Iter: 440 loss: 5.25853579e-07
Iter: 441 loss: 5.25850737e-07
Iter: 442 loss: 5.25851419e-07
Iter: 443 loss: 5.25852158e-07
Iter: 444 loss: 5.25851817e-07
Iter: 445 loss: 5.25851e-07
Iter: 446 loss: 5.25851874e-07
Iter: 447 loss: 5.25851874e-07
Iter: 448 loss: 5.25851476e-07
Iter: 449 loss: 5.25851e-07
Iter: 450 loss: 5.25851e-07
Iter: 451 loss: 5.25851476e-07
Iter: 452 loss: 5.25851e-07
Iter: 453 loss: 5.25851476e-07
Iter: 454 loss: 5.25781729e-07
Iter: 455 loss: 5.26810823e-07
Iter: 456 loss: 5.25782866e-07
Iter: 457 loss: 5.25734265e-07
Iter: 458 loss: 5.25851419e-07
Iter: 459 loss: 5.25719429e-07
Iter: 460 loss: 5.25669179e-07
Iter: 461 loss: 5.2631782e-07
Iter: 462 loss: 5.25659971e-07
Iter: 463 loss: 5.25637461e-07
Iter: 464 loss: 5.25569533e-07
Iter: 465 loss: 5.25557198e-07
Iter: 466 loss: 5.25535768e-07
Iter: 467 loss: 5.2552366e-07
Iter: 468 loss: 5.25489497e-07
Iter: 469 loss: 5.2547631e-07
Iter: 470 loss: 5.25469545e-07
Iter: 471 loss: 5.2540571e-07
Iter: 472 loss: 5.25665087e-07
Iter: 473 loss: 5.25413043e-07
Iter: 474 loss: 5.25355119e-07
Iter: 475 loss: 5.25458233e-07
Iter: 476 loss: 5.25334258e-07
Iter: 477 loss: 5.25270536e-07
Iter: 478 loss: 5.25303e-07
Iter: 479 loss: 5.25218525e-07
Iter: 480 loss: 5.25171572e-07
Iter: 481 loss: 5.25177256e-07
Iter: 482 loss: 5.25142411e-07
Iter: 483 loss: 5.2513e-07
Iter: 484 loss: 5.25115581e-07
Iter: 485 loss: 5.25076757e-07
Iter: 486 loss: 5.25031e-07
Iter: 487 loss: 5.2654508e-07
Iter: 488 loss: 5.25040264e-07
Iter: 489 loss: 5.24959319e-07
Iter: 490 loss: 5.25141331e-07
Iter: 491 loss: 5.24951247e-07
Iter: 492 loss: 5.24881159e-07
Iter: 493 loss: 5.25035603e-07
Iter: 494 loss: 5.24865641e-07
Iter: 495 loss: 5.2484711e-07
Iter: 496 loss: 5.24839038e-07
Iter: 497 loss: 5.248055e-07
Iter: 498 loss: 5.24763266e-07
Iter: 499 loss: 5.25384166e-07
Iter: 500 loss: 5.24759969e-07
Iter: 501 loss: 5.24700908e-07
Iter: 502 loss: 5.2487735e-07
Iter: 503 loss: 5.24690904e-07
Iter: 504 loss: 5.24578638e-07
Iter: 505 loss: 5.24601148e-07
Iter: 506 loss: 5.24512473e-07
Iter: 507 loss: 5.2444426e-07
Iter: 508 loss: 5.24767188e-07
Iter: 509 loss: 5.24457164e-07
Iter: 510 loss: 5.24401571e-07
Iter: 511 loss: 5.24458642e-07
Iter: 512 loss: 5.24351549e-07
Iter: 513 loss: 5.24313577e-07
Iter: 514 loss: 5.24238828e-07
Iter: 515 loss: 5.24252528e-07
Iter: 516 loss: 5.24244399e-07
Iter: 517 loss: 5.2421359e-07
Iter: 518 loss: 5.24172606e-07
Iter: 519 loss: 5.24128041e-07
Iter: 520 loss: 5.24122811e-07
Iter: 521 loss: 5.24087739e-07
Iter: 522 loss: 5.24176471e-07
Iter: 523 loss: 5.24059374e-07
Iter: 524 loss: 5.24038398e-07
Iter: 525 loss: 5.24047891e-07
Iter: 526 loss: 5.24046754e-07
Iter: 527 loss: 5.23991616e-07
Iter: 528 loss: 5.24164932e-07
Iter: 529 loss: 5.23984909e-07
Iter: 530 loss: 5.23962854e-07
Iter: 531 loss: 5.2395967e-07
Iter: 532 loss: 5.23946142e-07
Iter: 533 loss: 5.23918061e-07
Iter: 534 loss: 5.23908227e-07
Iter: 535 loss: 5.23912661e-07
Iter: 536 loss: 5.23906863e-07
Iter: 537 loss: 5.23913059e-07
Iter: 538 loss: 5.23906579e-07
Iter: 539 loss: 5.2391789e-07
Iter: 540 loss: 5.2393176e-07
Iter: 541 loss: 5.23915446e-07
Iter: 542 loss: 5.23913343e-07
Iter: 543 loss: 5.23913059e-07
Iter: 544 loss: 5.23914537e-07
Iter: 545 loss: 5.23904873e-07
Iter: 546 loss: 5.23920448e-07
Iter: 547 loss: 5.23912945e-07
Iter: 548 loss: 5.2390476e-07
Iter: 549 loss: 5.239e-07
Iter: 550 loss: 5.23912206e-07
Iter: 551 loss: 5.23899757e-07
Iter: 552 loss: 5.23897086e-07
Iter: 553 loss: 5.23910614e-07
Iter: 554 loss: 5.23910217e-07
Iter: 555 loss: 5.23910444e-07
Iter: 556 loss: 5.23910444e-07
Iter: 557 loss: 5.23901349e-07
Iter: 558 loss: 5.2391e-07
Iter: 559 loss: 5.23911183e-07
Iter: 560 loss: 5.23911297e-07
Iter: 561 loss: 5.23911297e-07
Iter: 562 loss: 5.23901349e-07
Iter: 563 loss: 5.23804545e-07
Iter: 564 loss: 5.24498887e-07
Iter: 565 loss: 5.2383524e-07
Iter: 566 loss: 5.23835581e-07
Iter: 567 loss: 5.2384263e-07
Iter: 568 loss: 5.23821541e-07
Iter: 569 loss: 5.23823871e-07
Iter: 570 loss: 5.23826202e-07
Iter: 571 loss: 5.23839788e-07
Iter: 572 loss: 5.23824e-07
Iter: 573 loss: 5.2382336e-07
Iter: 574 loss: 5.23820404e-07
Iter: 575 loss: 5.2382552e-07
Iter: 576 loss: 5.23819722e-07
Iter: 577 loss: 5.23819892e-07
Iter: 578 loss: 5.23829044e-07
Iter: 579 loss: 5.23837912e-07
Iter: 580 loss: 5.23830181e-07
Iter: 581 loss: 5.23834274e-07
Iter: 582 loss: 5.23836093e-07
Iter: 583 loss: 5.23834842e-07
Iter: 584 loss: 5.23836661e-07
Iter: 585 loss: 5.23837e-07
Iter: 586 loss: 5.2383507e-07
Iter: 587 loss: 5.23836718e-07
Iter: 588 loss: 5.23836093e-07
Iter: 589 loss: 5.23836093e-07
Iter: 590 loss: 5.23835752e-07
Iter: 591 loss: 5.23835752e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.4 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.4
+ date
Sun Nov  8 07:04:42 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0/300_100_100_100_1 --function f2 --psi 0 --alpha 0.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.4/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8044b6ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8044b6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb80440b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804432f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804432e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb80433a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804343488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804343a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804343598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8044676a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804465378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804305a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804305ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8042446a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804203488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8042037b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804203620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804290048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb80418d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8041a8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8041a8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8041749d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804119bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804119598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8040ba510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8040e9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb80433a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8042e8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8043426a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb80407c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb80407c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7f078a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7f0782400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8040768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb804076b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb8040767b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.041675035
test_loss: 0.04100735
train_loss: 0.021821339
test_loss: 0.023012605
train_loss: 0.018952629
test_loss: 0.019455088
train_loss: 0.016797584
test_loss: 0.017122477
train_loss: 0.014336278
test_loss: 0.0148402555
train_loss: 0.011897523
test_loss: 0.012472649
train_loss: 0.010337432
test_loss: 0.010210854
train_loss: 0.008633262
test_loss: 0.008544448
train_loss: 0.008210991
test_loss: 0.008630707
train_loss: 0.0071563898
test_loss: 0.0075492547
train_loss: 0.0068230797
test_loss: 0.007168484
train_loss: 0.006621541
test_loss: 0.007162569
train_loss: 0.0067723487
test_loss: 0.0068616476
train_loss: 0.0063399975
test_loss: 0.006510968
train_loss: 0.0063324636
test_loss: 0.006503387
train_loss: 0.0061673434
test_loss: 0.0065871733
train_loss: 0.0059678955
test_loss: 0.0062112054
train_loss: 0.00621361
test_loss: 0.00643753
train_loss: 0.0060701873
test_loss: 0.006450819
train_loss: 0.005900634
test_loss: 0.0062688943
train_loss: 0.006174808
test_loss: 0.0064133387
train_loss: 0.0059245573
test_loss: 0.006102526
train_loss: 0.005820712
test_loss: 0.0062556365
train_loss: 0.0061813295
test_loss: 0.005955829
train_loss: 0.005678286
test_loss: 0.005864891
train_loss: 0.0057789064
test_loss: 0.005892938
train_loss: 0.005704686
test_loss: 0.005904682
train_loss: 0.0055467775
test_loss: 0.005972088
train_loss: 0.0057986816
test_loss: 0.0061785798
train_loss: 0.0056775426
test_loss: 0.0059653916
train_loss: 0.0053777643
test_loss: 0.0057411306
train_loss: 0.0052629393
test_loss: 0.0060049538
train_loss: 0.0053641098
test_loss: 0.0057698977
train_loss: 0.005583504
test_loss: 0.0058970633
train_loss: 0.005578965
test_loss: 0.0058506243
train_loss: 0.0055764616
test_loss: 0.0058880653
train_loss: 0.005358941
test_loss: 0.005639
train_loss: 0.0052171303
test_loss: 0.0055708736
train_loss: 0.0055341367
test_loss: 0.005704115
train_loss: 0.0053977845
test_loss: 0.005517512
train_loss: 0.0052399533
test_loss: 0.00546328
train_loss: 0.0055944514
test_loss: 0.0056840177
train_loss: 0.005019765
test_loss: 0.005551031
train_loss: 0.005248606
test_loss: 0.0056477673
train_loss: 0.00561417
test_loss: 0.0055522667
train_loss: 0.004955291
test_loss: 0.005382615
train_loss: 0.00513236
test_loss: 0.005457877
train_loss: 0.0052228095
test_loss: 0.005497514
train_loss: 0.0050066765
test_loss: 0.0053290757
train_loss: 0.005232006
test_loss: 0.0056772907
train_loss: 0.0051666745
test_loss: 0.005434857
train_loss: 0.005038407
test_loss: 0.0053033573
train_loss: 0.0050374563
test_loss: 0.0052472
train_loss: 0.0049084644
test_loss: 0.0053663086
train_loss: 0.0048942002
test_loss: 0.0052484586
train_loss: 0.004815642
test_loss: 0.0052378327
train_loss: 0.004746031
test_loss: 0.0052030943
train_loss: 0.004742935
test_loss: 0.0053638457
train_loss: 0.004909317
test_loss: 0.0052414075
train_loss: 0.00446085
test_loss: 0.0050352784
train_loss: 0.0046730274
test_loss: 0.005149145
train_loss: 0.004826515
test_loss: 0.0050563277
train_loss: 0.00455799
test_loss: 0.005188926
train_loss: 0.004716793
test_loss: 0.0051058787
train_loss: 0.0049462407
test_loss: 0.0053774198
train_loss: 0.0045113624
test_loss: 0.0051120305
train_loss: 0.0050216764
test_loss: 0.0052736932
train_loss: 0.004715957
test_loss: 0.0051185577
train_loss: 0.0044965246
test_loss: 0.0050187605
train_loss: 0.0047820234
test_loss: 0.004921903
train_loss: 0.0045675174
test_loss: 0.00496713
train_loss: 0.0043369876
test_loss: 0.0049200705
train_loss: 0.0046255556
test_loss: 0.0051115653
train_loss: 0.0046253246
test_loss: 0.0048853704
train_loss: 0.0045400052
test_loss: 0.0050263605
train_loss: 0.0042747124
test_loss: 0.004900483
train_loss: 0.0044764155
test_loss: 0.0049623945
train_loss: 0.0043847454
test_loss: 0.0050072744
train_loss: 0.0044389684
test_loss: 0.004960521
train_loss: 0.0043074004
test_loss: 0.0048258374
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.4/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 0.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.4/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe8178c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe817488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe817598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe817950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe77b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe77b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe7600d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe744d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe70f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe70f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe6c5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe6a5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe6a5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe670598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededaf6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fedfe817ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededb26a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededae3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededae3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededae3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededa84840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded9f76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededa12bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededa12840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fededa12ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded9ca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded9e1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded98f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded98fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded96d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded98f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded8de6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded8e4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded8a57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded8a5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feded8de488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.91501146e-05
Iter: 2 loss: 2.68379335e-05
Iter: 3 loss: 2.51406618e-05
Iter: 4 loss: 2.35265143e-05
Iter: 5 loss: 4.54543624e-05
Iter: 6 loss: 2.35197e-05
Iter: 7 loss: 2.2796643e-05
Iter: 8 loss: 2.13581807e-05
Iter: 9 loss: 4.88733167e-05
Iter: 10 loss: 2.1341375e-05
Iter: 11 loss: 2.09723112e-05
Iter: 12 loss: 2.07276389e-05
Iter: 13 loss: 2.02818646e-05
Iter: 14 loss: 2.14540451e-05
Iter: 15 loss: 2.01312869e-05
Iter: 16 loss: 1.98674279e-05
Iter: 17 loss: 1.96535984e-05
Iter: 18 loss: 1.95750781e-05
Iter: 19 loss: 1.91386189e-05
Iter: 20 loss: 2.38286666e-05
Iter: 21 loss: 1.91284853e-05
Iter: 22 loss: 1.87597834e-05
Iter: 23 loss: 1.82705189e-05
Iter: 24 loss: 1.82422045e-05
Iter: 25 loss: 1.77759957e-05
Iter: 26 loss: 1.80532952e-05
Iter: 27 loss: 1.74751658e-05
Iter: 28 loss: 1.70442763e-05
Iter: 29 loss: 2.29714642e-05
Iter: 30 loss: 1.70427629e-05
Iter: 31 loss: 1.67752205e-05
Iter: 32 loss: 2.10363942e-05
Iter: 33 loss: 1.67751405e-05
Iter: 34 loss: 1.66668178e-05
Iter: 35 loss: 1.6426915e-05
Iter: 36 loss: 1.98884391e-05
Iter: 37 loss: 1.64158082e-05
Iter: 38 loss: 1.61761691e-05
Iter: 39 loss: 1.72176169e-05
Iter: 40 loss: 1.6127342e-05
Iter: 41 loss: 1.60104137e-05
Iter: 42 loss: 1.60014752e-05
Iter: 43 loss: 1.5856036e-05
Iter: 44 loss: 1.55250054e-05
Iter: 45 loss: 1.98846847e-05
Iter: 46 loss: 1.55038506e-05
Iter: 47 loss: 1.53099354e-05
Iter: 48 loss: 1.7912831e-05
Iter: 49 loss: 1.53091878e-05
Iter: 50 loss: 1.51682834e-05
Iter: 51 loss: 1.67274484e-05
Iter: 52 loss: 1.51656e-05
Iter: 53 loss: 1.50754822e-05
Iter: 54 loss: 1.48509553e-05
Iter: 55 loss: 1.6978056e-05
Iter: 56 loss: 1.48197696e-05
Iter: 57 loss: 1.47563524e-05
Iter: 58 loss: 1.46974244e-05
Iter: 59 loss: 1.46098319e-05
Iter: 60 loss: 1.46334787e-05
Iter: 61 loss: 1.45463455e-05
Iter: 62 loss: 1.44550404e-05
Iter: 63 loss: 1.43639536e-05
Iter: 64 loss: 1.43450543e-05
Iter: 65 loss: 1.41891223e-05
Iter: 66 loss: 1.47549536e-05
Iter: 67 loss: 1.41499841e-05
Iter: 68 loss: 1.40633683e-05
Iter: 69 loss: 1.40614475e-05
Iter: 70 loss: 1.3972649e-05
Iter: 71 loss: 1.39312688e-05
Iter: 72 loss: 1.38874921e-05
Iter: 73 loss: 1.38082623e-05
Iter: 74 loss: 1.38412743e-05
Iter: 75 loss: 1.37536936e-05
Iter: 76 loss: 1.3653198e-05
Iter: 77 loss: 1.37990282e-05
Iter: 78 loss: 1.36041563e-05
Iter: 79 loss: 1.36054814e-05
Iter: 80 loss: 1.35531209e-05
Iter: 81 loss: 1.35251503e-05
Iter: 82 loss: 1.34452694e-05
Iter: 83 loss: 1.38315681e-05
Iter: 84 loss: 1.34176607e-05
Iter: 85 loss: 1.33772792e-05
Iter: 86 loss: 1.33648482e-05
Iter: 87 loss: 1.33098647e-05
Iter: 88 loss: 1.32916903e-05
Iter: 89 loss: 1.32599616e-05
Iter: 90 loss: 1.32091045e-05
Iter: 91 loss: 1.3206256e-05
Iter: 92 loss: 1.31673914e-05
Iter: 93 loss: 1.3118316e-05
Iter: 94 loss: 1.31150609e-05
Iter: 95 loss: 1.30883618e-05
Iter: 96 loss: 1.30439075e-05
Iter: 97 loss: 1.30437929e-05
Iter: 98 loss: 1.29876835e-05
Iter: 99 loss: 1.29305754e-05
Iter: 100 loss: 1.29196105e-05
Iter: 101 loss: 1.29507735e-05
Iter: 102 loss: 1.28852116e-05
Iter: 103 loss: 1.28582114e-05
Iter: 104 loss: 1.28108213e-05
Iter: 105 loss: 1.2811015e-05
Iter: 106 loss: 1.27488265e-05
Iter: 107 loss: 1.26833202e-05
Iter: 108 loss: 1.26721634e-05
Iter: 109 loss: 1.26356445e-05
Iter: 110 loss: 1.26290051e-05
Iter: 111 loss: 1.25968945e-05
Iter: 112 loss: 1.287542e-05
Iter: 113 loss: 1.25951919e-05
Iter: 114 loss: 1.25683109e-05
Iter: 115 loss: 1.25320803e-05
Iter: 116 loss: 1.25300494e-05
Iter: 117 loss: 1.25010974e-05
Iter: 118 loss: 1.28266347e-05
Iter: 119 loss: 1.25006536e-05
Iter: 120 loss: 1.24723319e-05
Iter: 121 loss: 1.2569164e-05
Iter: 122 loss: 1.24649741e-05
Iter: 123 loss: 1.24415456e-05
Iter: 124 loss: 1.2382985e-05
Iter: 125 loss: 1.29373648e-05
Iter: 126 loss: 1.23749542e-05
Iter: 127 loss: 1.23686204e-05
Iter: 128 loss: 1.23460632e-05
Iter: 129 loss: 1.23215177e-05
Iter: 130 loss: 1.23078462e-05
Iter: 131 loss: 1.22969195e-05
Iter: 132 loss: 1.22671936e-05
Iter: 133 loss: 1.22362817e-05
Iter: 134 loss: 1.22304918e-05
Iter: 135 loss: 1.22138936e-05
Iter: 136 loss: 1.22093234e-05
Iter: 137 loss: 1.21855719e-05
Iter: 138 loss: 1.21806115e-05
Iter: 139 loss: 1.21649755e-05
Iter: 140 loss: 1.21344756e-05
Iter: 141 loss: 1.21024841e-05
Iter: 142 loss: 1.20970753e-05
Iter: 143 loss: 1.20482755e-05
Iter: 144 loss: 1.21532703e-05
Iter: 145 loss: 1.20295172e-05
Iter: 146 loss: 1.2029157e-05
Iter: 147 loss: 1.20077639e-05
Iter: 148 loss: 1.19914221e-05
Iter: 149 loss: 1.1963979e-05
Iter: 150 loss: 1.1964039e-05
Iter: 151 loss: 1.19439655e-05
Iter: 152 loss: 1.20981331e-05
Iter: 153 loss: 1.19426586e-05
Iter: 154 loss: 1.19186197e-05
Iter: 155 loss: 1.19603028e-05
Iter: 156 loss: 1.19078231e-05
Iter: 157 loss: 1.18893149e-05
Iter: 158 loss: 1.18720209e-05
Iter: 159 loss: 1.18677272e-05
Iter: 160 loss: 1.18433e-05
Iter: 161 loss: 1.22127267e-05
Iter: 162 loss: 1.18432326e-05
Iter: 163 loss: 1.18196949e-05
Iter: 164 loss: 1.18153403e-05
Iter: 165 loss: 1.17994468e-05
Iter: 166 loss: 1.17727395e-05
Iter: 167 loss: 1.17855034e-05
Iter: 168 loss: 1.1754867e-05
Iter: 169 loss: 1.17216623e-05
Iter: 170 loss: 1.1749039e-05
Iter: 171 loss: 1.17019554e-05
Iter: 172 loss: 1.17035906e-05
Iter: 173 loss: 1.16847559e-05
Iter: 174 loss: 1.16772171e-05
Iter: 175 loss: 1.1657402e-05
Iter: 176 loss: 1.18086336e-05
Iter: 177 loss: 1.16535412e-05
Iter: 178 loss: 1.16234551e-05
Iter: 179 loss: 1.1638951e-05
Iter: 180 loss: 1.16034807e-05
Iter: 181 loss: 1.15979065e-05
Iter: 182 loss: 1.15890807e-05
Iter: 183 loss: 1.15738221e-05
Iter: 184 loss: 1.15559569e-05
Iter: 185 loss: 1.15541588e-05
Iter: 186 loss: 1.15254361e-05
Iter: 187 loss: 1.15084149e-05
Iter: 188 loss: 1.14964241e-05
Iter: 189 loss: 1.14830837e-05
Iter: 190 loss: 1.14721415e-05
Iter: 191 loss: 1.14649638e-05
Iter: 192 loss: 1.14460527e-05
Iter: 193 loss: 1.15867606e-05
Iter: 194 loss: 1.14420545e-05
Iter: 195 loss: 1.14225904e-05
Iter: 196 loss: 1.16886085e-05
Iter: 197 loss: 1.14225404e-05
Iter: 198 loss: 1.14031873e-05
Iter: 199 loss: 1.14439663e-05
Iter: 200 loss: 1.13955375e-05
Iter: 201 loss: 1.13846863e-05
Iter: 202 loss: 1.13605938e-05
Iter: 203 loss: 1.17043473e-05
Iter: 204 loss: 1.13593569e-05
Iter: 205 loss: 1.13277783e-05
Iter: 206 loss: 1.14954864e-05
Iter: 207 loss: 1.13229871e-05
Iter: 208 loss: 1.13082424e-05
Iter: 209 loss: 1.13059659e-05
Iter: 210 loss: 1.12945054e-05
Iter: 211 loss: 1.12808957e-05
Iter: 212 loss: 1.12793405e-05
Iter: 213 loss: 1.12625748e-05
Iter: 214 loss: 1.13006572e-05
Iter: 215 loss: 1.12562029e-05
Iter: 216 loss: 1.12403523e-05
Iter: 217 loss: 1.12371044e-05
Iter: 218 loss: 1.12267826e-05
Iter: 219 loss: 1.12082507e-05
Iter: 220 loss: 1.14135419e-05
Iter: 221 loss: 1.12078378e-05
Iter: 222 loss: 1.11909958e-05
Iter: 223 loss: 1.13404076e-05
Iter: 224 loss: 1.11900572e-05
Iter: 225 loss: 1.11819563e-05
Iter: 226 loss: 1.11637019e-05
Iter: 227 loss: 1.14004015e-05
Iter: 228 loss: 1.1162294e-05
Iter: 229 loss: 1.11569152e-05
Iter: 230 loss: 1.11507397e-05
Iter: 231 loss: 1.11439567e-05
Iter: 232 loss: 1.11255722e-05
Iter: 233 loss: 1.12537928e-05
Iter: 234 loss: 1.11213576e-05
Iter: 235 loss: 1.11010086e-05
Iter: 236 loss: 1.12577991e-05
Iter: 237 loss: 1.1099627e-05
Iter: 238 loss: 1.10800183e-05
Iter: 239 loss: 1.12216057e-05
Iter: 240 loss: 1.10783458e-05
Iter: 241 loss: 1.10695046e-05
Iter: 242 loss: 1.10495512e-05
Iter: 243 loss: 1.13441947e-05
Iter: 244 loss: 1.1048809e-05
Iter: 245 loss: 1.1026088e-05
Iter: 246 loss: 1.11537975e-05
Iter: 247 loss: 1.10226201e-05
Iter: 248 loss: 1.10138799e-05
Iter: 249 loss: 1.10114524e-05
Iter: 250 loss: 1.10061992e-05
Iter: 251 loss: 1.09914545e-05
Iter: 252 loss: 1.10566452e-05
Iter: 253 loss: 1.0985711e-05
Iter: 254 loss: 1.09684706e-05
Iter: 255 loss: 1.1129684e-05
Iter: 256 loss: 1.09677567e-05
Iter: 257 loss: 1.09564908e-05
Iter: 258 loss: 1.09852981e-05
Iter: 259 loss: 1.0952811e-05
Iter: 260 loss: 1.09351986e-05
Iter: 261 loss: 1.09935645e-05
Iter: 262 loss: 1.09302882e-05
Iter: 263 loss: 1.09187094e-05
Iter: 264 loss: 1.09259527e-05
Iter: 265 loss: 1.0911177e-05
Iter: 266 loss: 1.09008206e-05
Iter: 267 loss: 1.10272358e-05
Iter: 268 loss: 1.0900605e-05
Iter: 269 loss: 1.08894874e-05
Iter: 270 loss: 1.08764525e-05
Iter: 271 loss: 1.08749082e-05
Iter: 272 loss: 1.08625027e-05
Iter: 273 loss: 1.08949262e-05
Iter: 274 loss: 1.08582617e-05
Iter: 275 loss: 1.08512495e-05
Iter: 276 loss: 1.08508739e-05
Iter: 277 loss: 1.08442491e-05
Iter: 278 loss: 1.0829579e-05
Iter: 279 loss: 1.10369429e-05
Iter: 280 loss: 1.08290369e-05
Iter: 281 loss: 1.08160702e-05
Iter: 282 loss: 1.0850832e-05
Iter: 283 loss: 1.0811993e-05
Iter: 284 loss: 1.08012609e-05
Iter: 285 loss: 1.09566427e-05
Iter: 286 loss: 1.08011573e-05
Iter: 287 loss: 1.07891019e-05
Iter: 288 loss: 1.07783726e-05
Iter: 289 loss: 1.07753413e-05
Iter: 290 loss: 1.07629421e-05
Iter: 291 loss: 1.07667847e-05
Iter: 292 loss: 1.07542983e-05
Iter: 293 loss: 1.07379383e-05
Iter: 294 loss: 1.07979358e-05
Iter: 295 loss: 1.07339483e-05
Iter: 296 loss: 1.07329151e-05
Iter: 297 loss: 1.07275791e-05
Iter: 298 loss: 1.07234609e-05
Iter: 299 loss: 1.07126607e-05
Iter: 300 loss: 1.07903506e-05
Iter: 301 loss: 1.07101077e-05
Iter: 302 loss: 1.07021478e-05
Iter: 303 loss: 1.07018914e-05
Iter: 304 loss: 1.06924845e-05
Iter: 305 loss: 1.06822827e-05
Iter: 306 loss: 1.06808384e-05
Iter: 307 loss: 1.06696716e-05
Iter: 308 loss: 1.06681246e-05
Iter: 309 loss: 1.06601183e-05
Iter: 310 loss: 1.06572024e-05
Iter: 311 loss: 1.06529878e-05
Iter: 312 loss: 1.06475118e-05
Iter: 313 loss: 1.06355328e-05
Iter: 314 loss: 1.08229151e-05
Iter: 315 loss: 1.06352682e-05
Iter: 316 loss: 1.06233674e-05
Iter: 317 loss: 1.06582984e-05
Iter: 318 loss: 1.06196985e-05
Iter: 319 loss: 1.06126463e-05
Iter: 320 loss: 1.0612036e-05
Iter: 321 loss: 1.06077587e-05
Iter: 322 loss: 1.05986019e-05
Iter: 323 loss: 1.07429714e-05
Iter: 324 loss: 1.05982735e-05
Iter: 325 loss: 1.05855343e-05
Iter: 326 loss: 1.05966174e-05
Iter: 327 loss: 1.05777617e-05
Iter: 328 loss: 1.05665158e-05
Iter: 329 loss: 1.06706157e-05
Iter: 330 loss: 1.05660019e-05
Iter: 331 loss: 1.05602576e-05
Iter: 332 loss: 1.05601139e-05
Iter: 333 loss: 1.05550644e-05
Iter: 334 loss: 1.05427471e-05
Iter: 335 loss: 1.06612679e-05
Iter: 336 loss: 1.05409135e-05
Iter: 337 loss: 1.05352101e-05
Iter: 338 loss: 1.05344398e-05
Iter: 339 loss: 1.05280014e-05
Iter: 340 loss: 1.05332074e-05
Iter: 341 loss: 1.05240051e-05
Iter: 342 loss: 1.05167583e-05
Iter: 343 loss: 1.05000581e-05
Iter: 344 loss: 1.06984471e-05
Iter: 345 loss: 1.04987012e-05
Iter: 346 loss: 1.04871269e-05
Iter: 347 loss: 1.04871642e-05
Iter: 348 loss: 1.04758619e-05
Iter: 349 loss: 1.05434719e-05
Iter: 350 loss: 1.04743604e-05
Iter: 351 loss: 1.04677811e-05
Iter: 352 loss: 1.04576739e-05
Iter: 353 loss: 1.04574419e-05
Iter: 354 loss: 1.04485971e-05
Iter: 355 loss: 1.05394693e-05
Iter: 356 loss: 1.04484452e-05
Iter: 357 loss: 1.04407609e-05
Iter: 358 loss: 1.04989304e-05
Iter: 359 loss: 1.04402952e-05
Iter: 360 loss: 1.04360088e-05
Iter: 361 loss: 1.04264909e-05
Iter: 362 loss: 1.0572081e-05
Iter: 363 loss: 1.04262235e-05
Iter: 364 loss: 1.04130786e-05
Iter: 365 loss: 1.04138144e-05
Iter: 366 loss: 1.04028531e-05
Iter: 367 loss: 1.03918119e-05
Iter: 368 loss: 1.03913962e-05
Iter: 369 loss: 1.03819239e-05
Iter: 370 loss: 1.04517458e-05
Iter: 371 loss: 1.0381048e-05
Iter: 372 loss: 1.03745933e-05
Iter: 373 loss: 1.03654074e-05
Iter: 374 loss: 1.03650509e-05
Iter: 375 loss: 1.03599405e-05
Iter: 376 loss: 1.03593256e-05
Iter: 377 loss: 1.03543953e-05
Iter: 378 loss: 1.03548509e-05
Iter: 379 loss: 1.03506045e-05
Iter: 380 loss: 1.03452494e-05
Iter: 381 loss: 1.03347129e-05
Iter: 382 loss: 1.0543612e-05
Iter: 383 loss: 1.03346383e-05
Iter: 384 loss: 1.03253897e-05
Iter: 385 loss: 1.03254715e-05
Iter: 386 loss: 1.03160928e-05
Iter: 387 loss: 1.03501843e-05
Iter: 388 loss: 1.03138482e-05
Iter: 389 loss: 1.03066741e-05
Iter: 390 loss: 1.02892163e-05
Iter: 391 loss: 1.04787923e-05
Iter: 392 loss: 1.02874355e-05
Iter: 393 loss: 1.02764197e-05
Iter: 394 loss: 1.02763952e-05
Iter: 395 loss: 1.0269383e-05
Iter: 396 loss: 1.02692993e-05
Iter: 397 loss: 1.02646509e-05
Iter: 398 loss: 1.02535378e-05
Iter: 399 loss: 1.0375501e-05
Iter: 400 loss: 1.02524364e-05
Iter: 401 loss: 1.02434933e-05
Iter: 402 loss: 1.02737376e-05
Iter: 403 loss: 1.02409176e-05
Iter: 404 loss: 1.02342101e-05
Iter: 405 loss: 1.02342474e-05
Iter: 406 loss: 1.02266367e-05
Iter: 407 loss: 1.02227104e-05
Iter: 408 loss: 1.0219359e-05
Iter: 409 loss: 1.02135509e-05
Iter: 410 loss: 1.02343838e-05
Iter: 411 loss: 1.02121203e-05
Iter: 412 loss: 1.0205169e-05
Iter: 413 loss: 1.0241909e-05
Iter: 414 loss: 1.02039185e-05
Iter: 415 loss: 1.01993492e-05
Iter: 416 loss: 1.01937239e-05
Iter: 417 loss: 1.01930746e-05
Iter: 418 loss: 1.01846117e-05
Iter: 419 loss: 1.01980349e-05
Iter: 420 loss: 1.01808964e-05
Iter: 421 loss: 1.01747328e-05
Iter: 422 loss: 1.01746118e-05
Iter: 423 loss: 1.01687747e-05
Iter: 424 loss: 1.0163104e-05
Iter: 425 loss: 1.01618916e-05
Iter: 426 loss: 1.01539799e-05
Iter: 427 loss: 1.01476644e-05
Iter: 428 loss: 1.0145287e-05
Iter: 429 loss: 1.01373371e-05
Iter: 430 loss: 1.01371852e-05
Iter: 431 loss: 1.01309342e-05
Iter: 432 loss: 1.01774676e-05
Iter: 433 loss: 1.01302739e-05
Iter: 434 loss: 1.01269798e-05
Iter: 435 loss: 1.01180303e-05
Iter: 436 loss: 1.01882097e-05
Iter: 437 loss: 1.01164187e-05
Iter: 438 loss: 1.01074129e-05
Iter: 439 loss: 1.01877758e-05
Iter: 440 loss: 1.01070564e-05
Iter: 441 loss: 1.01016794e-05
Iter: 442 loss: 1.01015394e-05
Iter: 443 loss: 1.00976695e-05
Iter: 444 loss: 1.00884636e-05
Iter: 445 loss: 1.01903734e-05
Iter: 446 loss: 1.00875386e-05
Iter: 447 loss: 1.00837733e-05
Iter: 448 loss: 1.00829966e-05
Iter: 449 loss: 1.00777334e-05
Iter: 450 loss: 1.00666894e-05
Iter: 451 loss: 1.02587146e-05
Iter: 452 loss: 1.00665693e-05
Iter: 453 loss: 1.00571233e-05
Iter: 454 loss: 1.00987e-05
Iter: 455 loss: 1.00551979e-05
Iter: 456 loss: 1.00493735e-05
Iter: 457 loss: 1.00652032e-05
Iter: 458 loss: 1.00475736e-05
Iter: 459 loss: 1.00405523e-05
Iter: 460 loss: 1.01034148e-05
Iter: 461 loss: 1.00402603e-05
Iter: 462 loss: 1.00348261e-05
Iter: 463 loss: 1.00316565e-05
Iter: 464 loss: 1.00292582e-05
Iter: 465 loss: 1.00233301e-05
Iter: 466 loss: 1.00261786e-05
Iter: 467 loss: 1.00192201e-05
Iter: 468 loss: 1.00108682e-05
Iter: 469 loss: 1.00420239e-05
Iter: 470 loss: 1.00086372e-05
Iter: 471 loss: 1.0001103e-05
Iter: 472 loss: 1.01101978e-05
Iter: 473 loss: 1.00011075e-05
Iter: 474 loss: 9.99748954e-06
Iter: 475 loss: 9.98981e-06
Iter: 476 loss: 1.01063388e-05
Iter: 477 loss: 9.98967334e-06
Iter: 478 loss: 9.98173164e-06
Iter: 479 loss: 1.00025627e-05
Iter: 480 loss: 9.97898587e-06
Iter: 481 loss: 9.97032112e-06
Iter: 482 loss: 9.9820918e-06
Iter: 483 loss: 9.96611197e-06
Iter: 484 loss: 9.96380368e-06
Iter: 485 loss: 9.96074596e-06
Iter: 486 loss: 9.95693335e-06
Iter: 487 loss: 9.94973652e-06
Iter: 488 loss: 1.01140886e-05
Iter: 489 loss: 9.94971469e-06
Iter: 490 loss: 9.94455331e-06
Iter: 491 loss: 9.99152144e-06
Iter: 492 loss: 9.94436323e-06
Iter: 493 loss: 9.93805861e-06
Iter: 494 loss: 9.9453755e-06
Iter: 495 loss: 9.93478716e-06
Iter: 496 loss: 9.93022149e-06
Iter: 497 loss: 9.92486275e-06
Iter: 498 loss: 9.92422065e-06
Iter: 499 loss: 9.91722118e-06
Iter: 500 loss: 9.93258618e-06
Iter: 501 loss: 9.91455818e-06
Iter: 502 loss: 9.90828175e-06
Iter: 503 loss: 9.97235838e-06
Iter: 504 loss: 9.90794069e-06
Iter: 505 loss: 9.90189437e-06
Iter: 506 loss: 9.93292815e-06
Iter: 507 loss: 9.90082e-06
Iter: 508 loss: 9.89531e-06
Iter: 509 loss: 9.89023465e-06
Iter: 510 loss: 9.88875581e-06
Iter: 511 loss: 9.88223655e-06
Iter: 512 loss: 9.90208355e-06
Iter: 513 loss: 9.88037391e-06
Iter: 514 loss: 9.8751525e-06
Iter: 515 loss: 9.93821595e-06
Iter: 516 loss: 9.8751625e-06
Iter: 517 loss: 9.86922896e-06
Iter: 518 loss: 9.86667419e-06
Iter: 519 loss: 9.86380837e-06
Iter: 520 loss: 9.85901352e-06
Iter: 521 loss: 9.8608507e-06
Iter: 522 loss: 9.85564475e-06
Iter: 523 loss: 9.8483024e-06
Iter: 524 loss: 9.84781218e-06
Iter: 525 loss: 9.84217877e-06
Iter: 526 loss: 9.84804865e-06
Iter: 527 loss: 9.839001e-06
Iter: 528 loss: 9.83684276e-06
Iter: 529 loss: 9.83053542e-06
Iter: 530 loss: 9.87270869e-06
Iter: 531 loss: 9.82926849e-06
Iter: 532 loss: 9.82365e-06
Iter: 533 loss: 9.82355323e-06
Iter: 534 loss: 9.81833819e-06
Iter: 535 loss: 9.83132122e-06
Iter: 536 loss: 9.81627545e-06
Iter: 537 loss: 9.81290759e-06
Iter: 538 loss: 9.80463301e-06
Iter: 539 loss: 9.90497574e-06
Iter: 540 loss: 9.80370169e-06
Iter: 541 loss: 9.79451579e-06
Iter: 542 loss: 9.86270061e-06
Iter: 543 loss: 9.7935208e-06
Iter: 544 loss: 9.79032848e-06
Iter: 545 loss: 9.789449e-06
Iter: 546 loss: 9.78669686e-06
Iter: 547 loss: 9.78042772e-06
Iter: 548 loss: 9.85443694e-06
Iter: 549 loss: 9.78007392e-06
Iter: 550 loss: 9.77372838e-06
Iter: 551 loss: 9.80042932e-06
Iter: 552 loss: 9.77233685e-06
Iter: 553 loss: 9.76866795e-06
Iter: 554 loss: 9.76861338e-06
Iter: 555 loss: 9.76532829e-06
Iter: 556 loss: 9.76318097e-06
Iter: 557 loss: 9.76185584e-06
Iter: 558 loss: 9.75736475e-06
Iter: 559 loss: 9.75736111e-06
Iter: 560 loss: 9.75370949e-06
Iter: 561 loss: 9.7465e-06
Iter: 562 loss: 9.74804152e-06
Iter: 563 loss: 9.74117302e-06
Iter: 564 loss: 9.73941133e-06
Iter: 565 loss: 9.73661918e-06
Iter: 566 loss: 9.73273382e-06
Iter: 567 loss: 9.72736507e-06
Iter: 568 loss: 9.72711678e-06
Iter: 569 loss: 9.72239468e-06
Iter: 570 loss: 9.74219256e-06
Iter: 571 loss: 9.72132148e-06
Iter: 572 loss: 9.71505e-06
Iter: 573 loss: 9.74017348e-06
Iter: 574 loss: 9.71374e-06
Iter: 575 loss: 9.71079135e-06
Iter: 576 loss: 9.70567817e-06
Iter: 577 loss: 9.70559631e-06
Iter: 578 loss: 9.69841221e-06
Iter: 579 loss: 9.69861321e-06
Iter: 580 loss: 9.69280336e-06
Iter: 581 loss: 9.69279608e-06
Iter: 582 loss: 9.68918539e-06
Iter: 583 loss: 9.68557924e-06
Iter: 584 loss: 9.67844426e-06
Iter: 585 loss: 9.83123755e-06
Iter: 586 loss: 9.67842243e-06
Iter: 587 loss: 9.67045162e-06
Iter: 588 loss: 9.67913547e-06
Iter: 589 loss: 9.66613061e-06
Iter: 590 loss: 9.66248263e-06
Iter: 591 loss: 9.66248263e-06
Iter: 592 loss: 9.6584281e-06
Iter: 593 loss: 9.66716834e-06
Iter: 594 loss: 9.65704e-06
Iter: 595 loss: 9.65308755e-06
Iter: 596 loss: 9.64660194e-06
Iter: 597 loss: 9.6466556e-06
Iter: 598 loss: 9.64031096e-06
Iter: 599 loss: 9.65399886e-06
Iter: 600 loss: 9.63782441e-06
Iter: 601 loss: 9.63020466e-06
Iter: 602 loss: 9.66372954e-06
Iter: 603 loss: 9.62845206e-06
Iter: 604 loss: 9.6232061e-06
Iter: 605 loss: 9.62303784e-06
Iter: 606 loss: 9.61987644e-06
Iter: 607 loss: 9.61285878e-06
Iter: 608 loss: 9.70649853e-06
Iter: 609 loss: 9.61228e-06
Iter: 610 loss: 9.61181468e-06
Iter: 611 loss: 9.6093454e-06
Iter: 612 loss: 9.60677062e-06
Iter: 613 loss: 9.60188845e-06
Iter: 614 loss: 9.70267592e-06
Iter: 615 loss: 9.6018839e-06
Iter: 616 loss: 9.59701356e-06
Iter: 617 loss: 9.59486351e-06
Iter: 618 loss: 9.5922469e-06
Iter: 619 loss: 9.58769488e-06
Iter: 620 loss: 9.58779492e-06
Iter: 621 loss: 9.5828791e-06
Iter: 622 loss: 9.59482259e-06
Iter: 623 loss: 9.58128658e-06
Iter: 624 loss: 9.57728935e-06
Iter: 625 loss: 9.57082375e-06
Iter: 626 loss: 9.57080283e-06
Iter: 627 loss: 9.56522945e-06
Iter: 628 loss: 9.63996536e-06
Iter: 629 loss: 9.56518488e-06
Iter: 630 loss: 9.56062831e-06
Iter: 631 loss: 9.58981855e-06
Iter: 632 loss: 9.56011354e-06
Iter: 633 loss: 9.55643554e-06
Iter: 634 loss: 9.55301584e-06
Iter: 635 loss: 9.55214455e-06
Iter: 636 loss: 9.54721145e-06
Iter: 637 loss: 9.55248197e-06
Iter: 638 loss: 9.54461939e-06
Iter: 639 loss: 9.53796462e-06
Iter: 640 loss: 9.54278e-06
Iter: 641 loss: 9.53376184e-06
Iter: 642 loss: 9.53476501e-06
Iter: 643 loss: 9.5305013e-06
Iter: 644 loss: 9.52827668e-06
Iter: 645 loss: 9.52333357e-06
Iter: 646 loss: 9.59571844e-06
Iter: 647 loss: 9.52292066e-06
Iter: 648 loss: 9.51908078e-06
Iter: 649 loss: 9.56833628e-06
Iter: 650 loss: 9.51904e-06
Iter: 651 loss: 9.51492075e-06
Iter: 652 loss: 9.52454866e-06
Iter: 653 loss: 9.51331094e-06
Iter: 654 loss: 9.51100537e-06
Iter: 655 loss: 9.506075e-06
Iter: 656 loss: 9.59678619e-06
Iter: 657 loss: 9.50595859e-06
Iter: 658 loss: 9.49956666e-06
Iter: 659 loss: 9.51737911e-06
Iter: 660 loss: 9.49739842e-06
Iter: 661 loss: 9.49482092e-06
Iter: 662 loss: 9.49375863e-06
Iter: 663 loss: 9.49127207e-06
Iter: 664 loss: 9.48462184e-06
Iter: 665 loss: 9.52721621e-06
Iter: 666 loss: 9.48291381e-06
Iter: 667 loss: 9.47435728e-06
Iter: 668 loss: 9.51732181e-06
Iter: 669 loss: 9.4728739e-06
Iter: 670 loss: 9.47132685e-06
Iter: 671 loss: 9.47007538e-06
Iter: 672 loss: 9.46785076e-06
Iter: 673 loss: 9.46360433e-06
Iter: 674 loss: 9.55520227e-06
Iter: 675 loss: 9.46369619e-06
Iter: 676 loss: 9.459578e-06
Iter: 677 loss: 9.47057197e-06
Iter: 678 loss: 9.45818465e-06
Iter: 679 loss: 9.45392276e-06
Iter: 680 loss: 9.46060663e-06
Iter: 681 loss: 9.4518382e-06
Iter: 682 loss: 9.44857857e-06
Iter: 683 loss: 9.44844942e-06
Iter: 684 loss: 9.44501789e-06
Iter: 685 loss: 9.43958821e-06
Iter: 686 loss: 9.43954183e-06
Iter: 687 loss: 9.43424493e-06
Iter: 688 loss: 9.46712771e-06
Iter: 689 loss: 9.43352734e-06
Iter: 690 loss: 9.42698171e-06
Iter: 691 loss: 9.43965915e-06
Iter: 692 loss: 9.42429415e-06
Iter: 693 loss: 9.42087627e-06
Iter: 694 loss: 9.41927465e-06
Iter: 695 loss: 9.41758572e-06
Iter: 696 loss: 9.41544749e-06
Iter: 697 loss: 9.41503276e-06
Iter: 698 loss: 9.41241706e-06
Iter: 699 loss: 9.40776954e-06
Iter: 700 loss: 9.51105267e-06
Iter: 701 loss: 9.40779864e-06
Iter: 702 loss: 9.40336849e-06
Iter: 703 loss: 9.41209e-06
Iter: 704 loss: 9.40160135e-06
Iter: 705 loss: 9.39783604e-06
Iter: 706 loss: 9.3978615e-06
Iter: 707 loss: 9.3946e-06
Iter: 708 loss: 9.38877383e-06
Iter: 709 loss: 9.38884114e-06
Iter: 710 loss: 9.38343692e-06
Iter: 711 loss: 9.38826e-06
Iter: 712 loss: 9.38026096e-06
Iter: 713 loss: 9.37459663e-06
Iter: 714 loss: 9.44113e-06
Iter: 715 loss: 9.37432742e-06
Iter: 716 loss: 9.37049663e-06
Iter: 717 loss: 9.42036422e-06
Iter: 718 loss: 9.37051846e-06
Iter: 719 loss: 9.3684539e-06
Iter: 720 loss: 9.36518609e-06
Iter: 721 loss: 9.36518518e-06
Iter: 722 loss: 9.36161268e-06
Iter: 723 loss: 9.39949e-06
Iter: 724 loss: 9.36141259e-06
Iter: 725 loss: 9.35746539e-06
Iter: 726 loss: 9.3565377e-06
Iter: 727 loss: 9.35399657e-06
Iter: 728 loss: 9.35121534e-06
Iter: 729 loss: 9.35488788e-06
Iter: 730 loss: 9.34966465e-06
Iter: 731 loss: 9.34534273e-06
Iter: 732 loss: 9.36979e-06
Iter: 733 loss: 9.34475156e-06
Iter: 734 loss: 9.34133095e-06
Iter: 735 loss: 9.33572392e-06
Iter: 736 loss: 9.33559386e-06
Iter: 737 loss: 9.33236242e-06
Iter: 738 loss: 9.33218053e-06
Iter: 739 loss: 9.32925559e-06
Iter: 740 loss: 9.33977753e-06
Iter: 741 loss: 9.32847615e-06
Iter: 742 loss: 9.32597868e-06
Iter: 743 loss: 9.3201761e-06
Iter: 744 loss: 9.38991889e-06
Iter: 745 loss: 9.31973227e-06
Iter: 746 loss: 9.31467548e-06
Iter: 747 loss: 9.36322886e-06
Iter: 748 loss: 9.31455634e-06
Iter: 749 loss: 9.31098748e-06
Iter: 750 loss: 9.35393e-06
Iter: 751 loss: 9.31102386e-06
Iter: 752 loss: 9.30729402e-06
Iter: 753 loss: 9.30443912e-06
Iter: 754 loss: 9.30343867e-06
Iter: 755 loss: 9.29986436e-06
Iter: 756 loss: 9.3313156e-06
Iter: 757 loss: 9.29972521e-06
Iter: 758 loss: 9.29637827e-06
Iter: 759 loss: 9.30435726e-06
Iter: 760 loss: 9.2950595e-06
Iter: 761 loss: 9.2916689e-06
Iter: 762 loss: 9.28637292e-06
Iter: 763 loss: 9.28621193e-06
Iter: 764 loss: 9.28491e-06
Iter: 765 loss: 9.28364534e-06
Iter: 766 loss: 9.28142435e-06
Iter: 767 loss: 9.27677138e-06
Iter: 768 loss: 9.35580283e-06
Iter: 769 loss: 9.27664951e-06
Iter: 770 loss: 9.27151814e-06
Iter: 771 loss: 9.28847567e-06
Iter: 772 loss: 9.27030669e-06
Iter: 773 loss: 9.26735538e-06
Iter: 774 loss: 9.26711073e-06
Iter: 775 loss: 9.26505163e-06
Iter: 776 loss: 9.26029497e-06
Iter: 777 loss: 9.32662078e-06
Iter: 778 loss: 9.26022221e-06
Iter: 779 loss: 9.25513632e-06
Iter: 780 loss: 9.2711125e-06
Iter: 781 loss: 9.25362838e-06
Iter: 782 loss: 9.25112e-06
Iter: 783 loss: 9.25088e-06
Iter: 784 loss: 9.24799861e-06
Iter: 785 loss: 9.24789401e-06
Iter: 786 loss: 9.24561209e-06
Iter: 787 loss: 9.24248798e-06
Iter: 788 loss: 9.24668439e-06
Iter: 789 loss: 9.24092637e-06
Iter: 790 loss: 9.23731386e-06
Iter: 791 loss: 9.27404199e-06
Iter: 792 loss: 9.23707e-06
Iter: 793 loss: 9.23416701e-06
Iter: 794 loss: 9.22921936e-06
Iter: 795 loss: 9.22922845e-06
Iter: 796 loss: 9.2252576e-06
Iter: 797 loss: 9.26768735e-06
Iter: 798 loss: 9.22510208e-06
Iter: 799 loss: 9.22139589e-06
Iter: 800 loss: 9.23492462e-06
Iter: 801 loss: 9.22039726e-06
Iter: 802 loss: 9.21782703e-06
Iter: 803 loss: 9.21303945e-06
Iter: 804 loss: 9.31334762e-06
Iter: 805 loss: 9.2130249e-06
Iter: 806 loss: 9.2102955e-06
Iter: 807 loss: 9.20941238e-06
Iter: 808 loss: 9.20668663e-06
Iter: 809 loss: 9.20649109e-06
Iter: 810 loss: 9.20433558e-06
Iter: 811 loss: 9.20115235e-06
Iter: 812 loss: 9.19658214e-06
Iter: 813 loss: 9.19644e-06
Iter: 814 loss: 9.19083323e-06
Iter: 815 loss: 9.25825589e-06
Iter: 816 loss: 9.19068589e-06
Iter: 817 loss: 9.18666e-06
Iter: 818 loss: 9.23412517e-06
Iter: 819 loss: 9.18647856e-06
Iter: 820 loss: 9.18424485e-06
Iter: 821 loss: 9.17995294e-06
Iter: 822 loss: 9.26639223e-06
Iter: 823 loss: 9.17982106e-06
Iter: 824 loss: 9.175983e-06
Iter: 825 loss: 9.17588659e-06
Iter: 826 loss: 9.17277794e-06
Iter: 827 loss: 9.17331181e-06
Iter: 828 loss: 9.17049e-06
Iter: 829 loss: 9.16763747e-06
Iter: 830 loss: 9.16923454e-06
Iter: 831 loss: 9.16582849e-06
Iter: 832 loss: 9.16199951e-06
Iter: 833 loss: 9.19823833e-06
Iter: 834 loss: 9.16184581e-06
Iter: 835 loss: 9.15885175e-06
Iter: 836 loss: 9.1541242e-06
Iter: 837 loss: 9.15400778e-06
Iter: 838 loss: 9.15011242e-06
Iter: 839 loss: 9.17821399e-06
Iter: 840 loss: 9.14971224e-06
Iter: 841 loss: 9.14496923e-06
Iter: 842 loss: 9.15609053e-06
Iter: 843 loss: 9.14341308e-06
Iter: 844 loss: 9.13976e-06
Iter: 845 loss: 9.13691292e-06
Iter: 846 loss: 9.13596341e-06
Iter: 847 loss: 9.13093572e-06
Iter: 848 loss: 9.14367229e-06
Iter: 849 loss: 9.12935e-06
Iter: 850 loss: 9.12584073e-06
Iter: 851 loss: 9.1255788e-06
Iter: 852 loss: 9.12305131e-06
Iter: 853 loss: 9.11982e-06
Iter: 854 loss: 9.11961615e-06
Iter: 855 loss: 9.11674397e-06
Iter: 856 loss: 9.15146575e-06
Iter: 857 loss: 9.11684401e-06
Iter: 858 loss: 9.11404186e-06
Iter: 859 loss: 9.11296684e-06
Iter: 860 loss: 9.11138341e-06
Iter: 861 loss: 9.10714698e-06
Iter: 862 loss: 9.10901235e-06
Iter: 863 loss: 9.10432391e-06
Iter: 864 loss: 9.1019765e-06
Iter: 865 loss: 9.10169729e-06
Iter: 866 loss: 9.09947903e-06
Iter: 867 loss: 9.09576102e-06
Iter: 868 loss: 9.09574192e-06
Iter: 869 loss: 9.09108894e-06
Iter: 870 loss: 9.09323535e-06
Iter: 871 loss: 9.08785478e-06
Iter: 872 loss: 9.08676702e-06
Iter: 873 loss: 9.08513539e-06
Iter: 874 loss: 9.08364746e-06
Iter: 875 loss: 9.07926642e-06
Iter: 876 loss: 9.10711151e-06
Iter: 877 loss: 9.07801768e-06
Iter: 878 loss: 9.07220874e-06
Iter: 879 loss: 9.09110349e-06
Iter: 880 loss: 9.07047706e-06
Iter: 881 loss: 9.06809873e-06
Iter: 882 loss: 9.06788046e-06
Iter: 883 loss: 9.06506375e-06
Iter: 884 loss: 9.06120295e-06
Iter: 885 loss: 9.061e-06
Iter: 886 loss: 9.05698926e-06
Iter: 887 loss: 9.07746562e-06
Iter: 888 loss: 9.0565245e-06
Iter: 889 loss: 9.05307752e-06
Iter: 890 loss: 9.08798484e-06
Iter: 891 loss: 9.05311754e-06
Iter: 892 loss: 9.05109573e-06
Iter: 893 loss: 9.04712761e-06
Iter: 894 loss: 9.11862571e-06
Iter: 895 loss: 9.04701665e-06
Iter: 896 loss: 9.04298395e-06
Iter: 897 loss: 9.09044411e-06
Iter: 898 loss: 9.04282388e-06
Iter: 899 loss: 9.03930231e-06
Iter: 900 loss: 9.04881927e-06
Iter: 901 loss: 9.03819455e-06
Iter: 902 loss: 9.03555338e-06
Iter: 903 loss: 9.03216278e-06
Iter: 904 loss: 9.03197815e-06
Iter: 905 loss: 9.02843567e-06
Iter: 906 loss: 9.02835563e-06
Iter: 907 loss: 9.02456e-06
Iter: 908 loss: 9.02200918e-06
Iter: 909 loss: 9.02057e-06
Iter: 910 loss: 9.01732255e-06
Iter: 911 loss: 9.01857675e-06
Iter: 912 loss: 9.01507701e-06
Iter: 913 loss: 9.01135263e-06
Iter: 914 loss: 9.05881461e-06
Iter: 915 loss: 9.01134445e-06
Iter: 916 loss: 9.0076e-06
Iter: 917 loss: 9.01591739e-06
Iter: 918 loss: 9.00610576e-06
Iter: 919 loss: 9.00371379e-06
Iter: 920 loss: 9.00301e-06
Iter: 921 loss: 9.00157283e-06
Iter: 922 loss: 8.99816405e-06
Iter: 923 loss: 9.04066292e-06
Iter: 924 loss: 8.99813767e-06
Iter: 925 loss: 8.99560837e-06
Iter: 926 loss: 8.99086444e-06
Iter: 927 loss: 8.99101e-06
Iter: 928 loss: 8.98716917e-06
Iter: 929 loss: 9.02789907e-06
Iter: 930 loss: 8.98705184e-06
Iter: 931 loss: 8.98387862e-06
Iter: 932 loss: 8.99811857e-06
Iter: 933 loss: 8.98324106e-06
Iter: 934 loss: 8.98088456e-06
Iter: 935 loss: 8.97809878e-06
Iter: 936 loss: 8.97773589e-06
Iter: 937 loss: 8.97415339e-06
Iter: 938 loss: 8.99178849e-06
Iter: 939 loss: 8.97361861e-06
Iter: 940 loss: 8.96924575e-06
Iter: 941 loss: 8.98571307e-06
Iter: 942 loss: 8.96820075e-06
Iter: 943 loss: 8.96546499e-06
Iter: 944 loss: 8.96099846e-06
Iter: 945 loss: 8.96097117e-06
Iter: 946 loss: 8.95639278e-06
Iter: 947 loss: 8.99705265e-06
Iter: 948 loss: 8.95613266e-06
Iter: 949 loss: 8.95164885e-06
Iter: 950 loss: 8.98379403e-06
Iter: 951 loss: 8.95129e-06
Iter: 952 loss: 8.94881578e-06
Iter: 953 loss: 8.94672667e-06
Iter: 954 loss: 8.94590266e-06
Iter: 955 loss: 8.94404e-06
Iter: 956 loss: 8.94385903e-06
Iter: 957 loss: 8.94189907e-06
Iter: 958 loss: 8.93766628e-06
Iter: 959 loss: 9.0085432e-06
Iter: 960 loss: 8.93760625e-06
Iter: 961 loss: 8.93282868e-06
Iter: 962 loss: 8.95378071e-06
Iter: 963 loss: 8.93192646e-06
Iter: 964 loss: 8.9291043e-06
Iter: 965 loss: 8.92893604e-06
Iter: 966 loss: 8.92736352e-06
Iter: 967 loss: 8.92368917e-06
Iter: 968 loss: 8.99293264e-06
Iter: 969 loss: 8.92358185e-06
Iter: 970 loss: 8.91867239e-06
Iter: 971 loss: 8.92461e-06
Iter: 972 loss: 8.91623858e-06
Iter: 973 loss: 8.91299715e-06
Iter: 974 loss: 8.91239324e-06
Iter: 975 loss: 8.91053696e-06
Iter: 976 loss: 8.90595311e-06
Iter: 977 loss: 8.95549692e-06
Iter: 978 loss: 8.90549381e-06
Iter: 979 loss: 8.90025694e-06
Iter: 980 loss: 8.92182288e-06
Iter: 981 loss: 8.89912735e-06
Iter: 982 loss: 8.89707917e-06
Iter: 983 loss: 8.89634248e-06
Iter: 984 loss: 8.89489638e-06
Iter: 985 loss: 8.89210787e-06
Iter: 986 loss: 8.95019457e-06
Iter: 987 loss: 8.89205239e-06
Iter: 988 loss: 8.88930845e-06
Iter: 989 loss: 8.91816399e-06
Iter: 990 loss: 8.88923296e-06
Iter: 991 loss: 8.88609793e-06
Iter: 992 loss: 8.88548311e-06
Iter: 993 loss: 8.8833167e-06
Iter: 994 loss: 8.88048635e-06
Iter: 995 loss: 8.8847728e-06
Iter: 996 loss: 8.878882e-06
Iter: 997 loss: 8.87572423e-06
Iter: 998 loss: 8.91215677e-06
Iter: 999 loss: 8.87574606e-06
Iter: 1000 loss: 8.87311e-06
Iter: 1001 loss: 8.86975158e-06
Iter: 1002 loss: 8.86943235e-06
Iter: 1003 loss: 8.86564794e-06
Iter: 1004 loss: 8.8756733e-06
Iter: 1005 loss: 8.86448288e-06
Iter: 1006 loss: 8.86199177e-06
Iter: 1007 loss: 8.86190355e-06
Iter: 1008 loss: 8.8593788e-06
Iter: 1009 loss: 8.85415557e-06
Iter: 1010 loss: 8.94635e-06
Iter: 1011 loss: 8.85398094e-06
Iter: 1012 loss: 8.84954e-06
Iter: 1013 loss: 8.86465659e-06
Iter: 1014 loss: 8.84848e-06
Iter: 1015 loss: 8.84564543e-06
Iter: 1016 loss: 8.84562451e-06
Iter: 1017 loss: 8.84290603e-06
Iter: 1018 loss: 8.83731536e-06
Iter: 1019 loss: 8.95400808e-06
Iter: 1020 loss: 8.83742541e-06
Iter: 1021 loss: 8.83447319e-06
Iter: 1022 loss: 8.8345223e-06
Iter: 1023 loss: 8.83206e-06
Iter: 1024 loss: 8.83979828e-06
Iter: 1025 loss: 8.83109715e-06
Iter: 1026 loss: 8.82915356e-06
Iter: 1027 loss: 8.82589484e-06
Iter: 1028 loss: 8.82599215e-06
Iter: 1029 loss: 8.82322911e-06
Iter: 1030 loss: 8.82297172e-06
Iter: 1031 loss: 8.8206034e-06
Iter: 1032 loss: 8.82065069e-06
Iter: 1033 loss: 8.818477e-06
Iter: 1034 loss: 8.81559e-06
Iter: 1035 loss: 8.81232882e-06
Iter: 1036 loss: 8.81171218e-06
Iter: 1037 loss: 8.80746302e-06
Iter: 1038 loss: 8.87371243e-06
Iter: 1039 loss: 8.80751213e-06
Iter: 1040 loss: 8.8029974e-06
Iter: 1041 loss: 8.80723655e-06
Iter: 1042 loss: 8.80066727e-06
Iter: 1043 loss: 8.79780055e-06
Iter: 1044 loss: 8.793706e-06
Iter: 1045 loss: 8.79354229e-06
Iter: 1046 loss: 8.79078743e-06
Iter: 1047 loss: 8.79032177e-06
Iter: 1048 loss: 8.78718947e-06
Iter: 1049 loss: 8.79163e-06
Iter: 1050 loss: 8.78570063e-06
Iter: 1051 loss: 8.78366154e-06
Iter: 1052 loss: 8.78144874e-06
Iter: 1053 loss: 8.78110313e-06
Iter: 1054 loss: 8.77761e-06
Iter: 1055 loss: 8.77756247e-06
Iter: 1056 loss: 8.77568618e-06
Iter: 1057 loss: 8.77204729e-06
Iter: 1058 loss: 8.85093505e-06
Iter: 1059 loss: 8.77214188e-06
Iter: 1060 loss: 8.76820286e-06
Iter: 1061 loss: 8.79121217e-06
Iter: 1062 loss: 8.76751e-06
Iter: 1063 loss: 8.76283775e-06
Iter: 1064 loss: 8.77596e-06
Iter: 1065 loss: 8.7612716e-06
Iter: 1066 loss: 8.75786645e-06
Iter: 1067 loss: 8.75770365e-06
Iter: 1068 loss: 8.75517071e-06
Iter: 1069 loss: 8.7515964e-06
Iter: 1070 loss: 8.77308e-06
Iter: 1071 loss: 8.75103433e-06
Iter: 1072 loss: 8.74721627e-06
Iter: 1073 loss: 8.76681315e-06
Iter: 1074 loss: 8.74657871e-06
Iter: 1075 loss: 8.74407851e-06
Iter: 1076 loss: 8.73993758e-06
Iter: 1077 loss: 8.7399012e-06
Iter: 1078 loss: 8.73600948e-06
Iter: 1079 loss: 8.76563809e-06
Iter: 1080 loss: 8.73573845e-06
Iter: 1081 loss: 8.73177487e-06
Iter: 1082 loss: 8.76226841e-06
Iter: 1083 loss: 8.73151203e-06
Iter: 1084 loss: 8.72908458e-06
Iter: 1085 loss: 8.72439159e-06
Iter: 1086 loss: 8.81297638e-06
Iter: 1087 loss: 8.7243825e-06
Iter: 1088 loss: 8.72245255e-06
Iter: 1089 loss: 8.72151213e-06
Iter: 1090 loss: 8.719162e-06
Iter: 1091 loss: 8.71453e-06
Iter: 1092 loss: 8.80651714e-06
Iter: 1093 loss: 8.71441262e-06
Iter: 1094 loss: 8.71061729e-06
Iter: 1095 loss: 8.73722274e-06
Iter: 1096 loss: 8.71026896e-06
Iter: 1097 loss: 8.7071e-06
Iter: 1098 loss: 8.73663521e-06
Iter: 1099 loss: 8.70699205e-06
Iter: 1100 loss: 8.7046983e-06
Iter: 1101 loss: 8.70084386e-06
Iter: 1102 loss: 8.70078293e-06
Iter: 1103 loss: 8.69698852e-06
Iter: 1104 loss: 8.71826342e-06
Iter: 1105 loss: 8.69649557e-06
Iter: 1106 loss: 8.69306677e-06
Iter: 1107 loss: 8.72158853e-06
Iter: 1108 loss: 8.69293763e-06
Iter: 1109 loss: 8.68987354e-06
Iter: 1110 loss: 8.68398092e-06
Iter: 1111 loss: 8.80772313e-06
Iter: 1112 loss: 8.68406642e-06
Iter: 1113 loss: 8.6798791e-06
Iter: 1114 loss: 8.71479187e-06
Iter: 1115 loss: 8.67958806e-06
Iter: 1116 loss: 8.67704512e-06
Iter: 1117 loss: 8.67691688e-06
Iter: 1118 loss: 8.67498238e-06
Iter: 1119 loss: 8.67046765e-06
Iter: 1120 loss: 8.72933e-06
Iter: 1121 loss: 8.67020935e-06
Iter: 1122 loss: 8.66851224e-06
Iter: 1123 loss: 8.66808477e-06
Iter: 1124 loss: 8.66568371e-06
Iter: 1125 loss: 8.6640357e-06
Iter: 1126 loss: 8.66326627e-06
Iter: 1127 loss: 8.66001756e-06
Iter: 1128 loss: 8.65849142e-06
Iter: 1129 loss: 8.65705897e-06
Iter: 1130 loss: 8.65374204e-06
Iter: 1131 loss: 8.65349648e-06
Iter: 1132 loss: 8.65088441e-06
Iter: 1133 loss: 8.64805406e-06
Iter: 1134 loss: 8.64761932e-06
Iter: 1135 loss: 8.6433829e-06
Iter: 1136 loss: 8.64883805e-06
Iter: 1137 loss: 8.6412474e-06
Iter: 1138 loss: 8.63849527e-06
Iter: 1139 loss: 8.63848163e-06
Iter: 1140 loss: 8.63597324e-06
Iter: 1141 loss: 8.63464629e-06
Iter: 1142 loss: 8.63368678e-06
Iter: 1143 loss: 8.63074729e-06
Iter: 1144 loss: 8.62770321e-06
Iter: 1145 loss: 8.62699926e-06
Iter: 1146 loss: 8.6270129e-06
Iter: 1147 loss: 8.62490924e-06
Iter: 1148 loss: 8.62326578e-06
Iter: 1149 loss: 8.62068464e-06
Iter: 1150 loss: 8.62064189e-06
Iter: 1151 loss: 8.61731496e-06
Iter: 1152 loss: 8.61626086e-06
Iter: 1153 loss: 8.61442641e-06
Iter: 1154 loss: 8.60773616e-06
Iter: 1155 loss: 8.64918911e-06
Iter: 1156 loss: 8.60702e-06
Iter: 1157 loss: 8.60443288e-06
Iter: 1158 loss: 8.60102409e-06
Iter: 1159 loss: 8.6007085e-06
Iter: 1160 loss: 8.59683223e-06
Iter: 1161 loss: 8.65416e-06
Iter: 1162 loss: 8.59683132e-06
Iter: 1163 loss: 8.59320608e-06
Iter: 1164 loss: 8.59460397e-06
Iter: 1165 loss: 8.59072134e-06
Iter: 1166 loss: 8.58776093e-06
Iter: 1167 loss: 8.59355714e-06
Iter: 1168 loss: 8.5867523e-06
Iter: 1169 loss: 8.58425301e-06
Iter: 1170 loss: 8.6075579e-06
Iter: 1171 loss: 8.58400472e-06
Iter: 1172 loss: 8.5812917e-06
Iter: 1173 loss: 8.58026669e-06
Iter: 1174 loss: 8.57875148e-06
Iter: 1175 loss: 8.57515624e-06
Iter: 1176 loss: 8.5735237e-06
Iter: 1177 loss: 8.57171381e-06
Iter: 1178 loss: 8.5691654e-06
Iter: 1179 loss: 8.56887527e-06
Iter: 1180 loss: 8.56572478e-06
Iter: 1181 loss: 8.56262068e-06
Iter: 1182 loss: 8.56196857e-06
Iter: 1183 loss: 8.55763665e-06
Iter: 1184 loss: 8.55935741e-06
Iter: 1185 loss: 8.55455073e-06
Iter: 1186 loss: 8.55161579e-06
Iter: 1187 loss: 8.55114922e-06
Iter: 1188 loss: 8.54902646e-06
Iter: 1189 loss: 8.54461359e-06
Iter: 1190 loss: 8.59856846e-06
Iter: 1191 loss: 8.54417431e-06
Iter: 1192 loss: 8.54112841e-06
Iter: 1193 loss: 8.54116843e-06
Iter: 1194 loss: 8.53789152e-06
Iter: 1195 loss: 8.54270183e-06
Iter: 1196 loss: 8.5365009e-06
Iter: 1197 loss: 8.53330494e-06
Iter: 1198 loss: 8.53072288e-06
Iter: 1199 loss: 8.52972335e-06
Iter: 1200 loss: 8.52604626e-06
Iter: 1201 loss: 8.55934195e-06
Iter: 1202 loss: 8.52591256e-06
Iter: 1203 loss: 8.52230551e-06
Iter: 1204 loss: 8.53385609e-06
Iter: 1205 loss: 8.52105495e-06
Iter: 1206 loss: 8.51761433e-06
Iter: 1207 loss: 8.51215555e-06
Iter: 1208 loss: 8.51206278e-06
Iter: 1209 loss: 8.50831e-06
Iter: 1210 loss: 8.50838478e-06
Iter: 1211 loss: 8.50480319e-06
Iter: 1212 loss: 8.51896493e-06
Iter: 1213 loss: 8.50378183e-06
Iter: 1214 loss: 8.50098877e-06
Iter: 1215 loss: 8.49522257e-06
Iter: 1216 loss: 8.60341515e-06
Iter: 1217 loss: 8.49512162e-06
Iter: 1218 loss: 8.49574826e-06
Iter: 1219 loss: 8.49278877e-06
Iter: 1220 loss: 8.49109438e-06
Iter: 1221 loss: 8.48728087e-06
Iter: 1222 loss: 8.55250619e-06
Iter: 1223 loss: 8.48732179e-06
Iter: 1224 loss: 8.48362288e-06
Iter: 1225 loss: 8.49412754e-06
Iter: 1226 loss: 8.48251784e-06
Iter: 1227 loss: 8.47928277e-06
Iter: 1228 loss: 8.52937865e-06
Iter: 1229 loss: 8.47925367e-06
Iter: 1230 loss: 8.47750925e-06
Iter: 1231 loss: 8.47477804e-06
Iter: 1232 loss: 8.47463616e-06
Iter: 1233 loss: 8.47058618e-06
Iter: 1234 loss: 8.47757292e-06
Iter: 1235 loss: 8.46873081e-06
Iter: 1236 loss: 8.46461262e-06
Iter: 1237 loss: 8.52443372e-06
Iter: 1238 loss: 8.46477633e-06
Iter: 1239 loss: 8.46205785e-06
Iter: 1240 loss: 8.45884097e-06
Iter: 1241 loss: 8.45859176e-06
Iter: 1242 loss: 8.45415616e-06
Iter: 1243 loss: 8.45698e-06
Iter: 1244 loss: 8.45149589e-06
Iter: 1245 loss: 8.44815531e-06
Iter: 1246 loss: 8.447445e-06
Iter: 1247 loss: 8.44544593e-06
Iter: 1248 loss: 8.44174701e-06
Iter: 1249 loss: 8.53125493e-06
Iter: 1250 loss: 8.44190436e-06
Iter: 1251 loss: 8.43915132e-06
Iter: 1252 loss: 8.47093361e-06
Iter: 1253 loss: 8.43910857e-06
Iter: 1254 loss: 8.43560247e-06
Iter: 1255 loss: 8.43651378e-06
Iter: 1256 loss: 8.43324233e-06
Iter: 1257 loss: 8.43058388e-06
Iter: 1258 loss: 8.42975714e-06
Iter: 1259 loss: 8.42834197e-06
Iter: 1260 loss: 8.42478585e-06
Iter: 1261 loss: 8.47600131e-06
Iter: 1262 loss: 8.42487316e-06
Iter: 1263 loss: 8.42185091e-06
Iter: 1264 loss: 8.41679e-06
Iter: 1265 loss: 8.41680048e-06
Iter: 1266 loss: 8.41243491e-06
Iter: 1267 loss: 8.43940143e-06
Iter: 1268 loss: 8.41177553e-06
Iter: 1269 loss: 8.40885696e-06
Iter: 1270 loss: 8.44928672e-06
Iter: 1271 loss: 8.40887697e-06
Iter: 1272 loss: 8.40631856e-06
Iter: 1273 loss: 8.40266512e-06
Iter: 1274 loss: 8.4025578e-06
Iter: 1275 loss: 8.39840322e-06
Iter: 1276 loss: 8.40604753e-06
Iter: 1277 loss: 8.39685254e-06
Iter: 1278 loss: 8.39498e-06
Iter: 1279 loss: 8.39457789e-06
Iter: 1280 loss: 8.39248514e-06
Iter: 1281 loss: 8.38846518e-06
Iter: 1282 loss: 8.48200943e-06
Iter: 1283 loss: 8.38851702e-06
Iter: 1284 loss: 8.38501819e-06
Iter: 1285 loss: 8.39434051e-06
Iter: 1286 loss: 8.38392953e-06
Iter: 1287 loss: 8.38004871e-06
Iter: 1288 loss: 8.42540521e-06
Iter: 1289 loss: 8.38008782e-06
Iter: 1290 loss: 8.37764128e-06
Iter: 1291 loss: 8.37264088e-06
Iter: 1292 loss: 8.44279384e-06
Iter: 1293 loss: 8.37236439e-06
Iter: 1294 loss: 8.37028892e-06
Iter: 1295 loss: 8.36974777e-06
Iter: 1296 loss: 8.36699655e-06
Iter: 1297 loss: 8.36393338e-06
Iter: 1298 loss: 8.36350682e-06
Iter: 1299 loss: 8.35958235e-06
Iter: 1300 loss: 8.36657455e-06
Iter: 1301 loss: 8.35782612e-06
Iter: 1302 loss: 8.3551331e-06
Iter: 1303 loss: 8.35505398e-06
Iter: 1304 loss: 8.35240189e-06
Iter: 1305 loss: 8.35255105e-06
Iter: 1306 loss: 8.35052742e-06
Iter: 1307 loss: 8.34702951e-06
Iter: 1308 loss: 8.34495586e-06
Iter: 1309 loss: 8.34354887e-06
Iter: 1310 loss: 8.33998365e-06
Iter: 1311 loss: 8.39450058e-06
Iter: 1312 loss: 8.34011735e-06
Iter: 1313 loss: 8.3365685e-06
Iter: 1314 loss: 8.34580624e-06
Iter: 1315 loss: 8.33531794e-06
Iter: 1316 loss: 8.33293052e-06
Iter: 1317 loss: 8.32855403e-06
Iter: 1318 loss: 8.42766894e-06
Iter: 1319 loss: 8.32837577e-06
Iter: 1320 loss: 8.3275e-06
Iter: 1321 loss: 8.32587557e-06
Iter: 1322 loss: 8.32380738e-06
Iter: 1323 loss: 8.31898251e-06
Iter: 1324 loss: 8.38052e-06
Iter: 1325 loss: 8.31879242e-06
Iter: 1326 loss: 8.31447687e-06
Iter: 1327 loss: 8.35076662e-06
Iter: 1328 loss: 8.31437865e-06
Iter: 1329 loss: 8.31072066e-06
Iter: 1330 loss: 8.33493232e-06
Iter: 1331 loss: 8.31028228e-06
Iter: 1332 loss: 8.3081577e-06
Iter: 1333 loss: 8.30406225e-06
Iter: 1334 loss: 8.38103915e-06
Iter: 1335 loss: 8.30397767e-06
Iter: 1336 loss: 8.29935743e-06
Iter: 1337 loss: 8.34560888e-06
Iter: 1338 loss: 8.29923647e-06
Iter: 1339 loss: 8.29571582e-06
Iter: 1340 loss: 8.32174e-06
Iter: 1341 loss: 8.29535e-06
Iter: 1342 loss: 8.29335477e-06
Iter: 1343 loss: 8.29009241e-06
Iter: 1344 loss: 8.29001874e-06
Iter: 1345 loss: 8.28521206e-06
Iter: 1346 loss: 8.29517921e-06
Iter: 1347 loss: 8.28340853e-06
Iter: 1348 loss: 8.28025622e-06
Iter: 1349 loss: 8.27989152e-06
Iter: 1350 loss: 8.27827e-06
Iter: 1351 loss: 8.27429e-06
Iter: 1352 loss: 8.30728641e-06
Iter: 1353 loss: 8.27356052e-06
Iter: 1354 loss: 8.26981159e-06
Iter: 1355 loss: 8.26975702e-06
Iter: 1356 loss: 8.26577e-06
Iter: 1357 loss: 8.2697934e-06
Iter: 1358 loss: 8.26361884e-06
Iter: 1359 loss: 8.261125e-06
Iter: 1360 loss: 8.26195e-06
Iter: 1361 loss: 8.25938696e-06
Iter: 1362 loss: 8.25623283e-06
Iter: 1363 loss: 8.29374312e-06
Iter: 1364 loss: 8.25608367e-06
Iter: 1365 loss: 8.25417555e-06
Iter: 1366 loss: 8.250674e-06
Iter: 1367 loss: 8.25067946e-06
Iter: 1368 loss: 8.24709605e-06
Iter: 1369 loss: 8.26179894e-06
Iter: 1370 loss: 8.24635936e-06
Iter: 1371 loss: 8.24247e-06
Iter: 1372 loss: 8.27765689e-06
Iter: 1373 loss: 8.24229846e-06
Iter: 1374 loss: 8.23922255e-06
Iter: 1375 loss: 8.23490609e-06
Iter: 1376 loss: 8.23477e-06
Iter: 1377 loss: 8.23034497e-06
Iter: 1378 loss: 8.24728886e-06
Iter: 1379 loss: 8.22928541e-06
Iter: 1380 loss: 8.22653328e-06
Iter: 1381 loss: 8.22638231e-06
Iter: 1382 loss: 8.22410311e-06
Iter: 1383 loss: 8.21942285e-06
Iter: 1384 loss: 8.32398473e-06
Iter: 1385 loss: 8.21932827e-06
Iter: 1386 loss: 8.21606136e-06
Iter: 1387 loss: 8.23122718e-06
Iter: 1388 loss: 8.21553567e-06
Iter: 1389 loss: 8.21223e-06
Iter: 1390 loss: 8.24167182e-06
Iter: 1391 loss: 8.21203e-06
Iter: 1392 loss: 8.20991681e-06
Iter: 1393 loss: 8.20577861e-06
Iter: 1394 loss: 8.28345e-06
Iter: 1395 loss: 8.20572131e-06
Iter: 1396 loss: 8.20322384e-06
Iter: 1397 loss: 8.20299283e-06
Iter: 1398 loss: 8.20047171e-06
Iter: 1399 loss: 8.19510387e-06
Iter: 1400 loss: 8.2804936e-06
Iter: 1401 loss: 8.19486377e-06
Iter: 1402 loss: 8.18885e-06
Iter: 1403 loss: 8.2002025e-06
Iter: 1404 loss: 8.18630542e-06
Iter: 1405 loss: 8.18418175e-06
Iter: 1406 loss: 8.18306216e-06
Iter: 1407 loss: 8.18061e-06
Iter: 1408 loss: 8.17792e-06
Iter: 1409 loss: 8.17744694e-06
Iter: 1410 loss: 8.17388354e-06
Iter: 1411 loss: 8.18009175e-06
Iter: 1412 loss: 8.1724e-06
Iter: 1413 loss: 8.16967076e-06
Iter: 1414 loss: 8.2043789e-06
Iter: 1415 loss: 8.1696e-06
Iter: 1416 loss: 8.16644297e-06
Iter: 1417 loss: 8.16619831e-06
Iter: 1418 loss: 8.16395732e-06
Iter: 1419 loss: 8.160785e-06
Iter: 1420 loss: 8.16034662e-06
Iter: 1421 loss: 8.15798e-06
Iter: 1422 loss: 8.15614476e-06
Iter: 1423 loss: 8.15585554e-06
Iter: 1424 loss: 8.15362546e-06
Iter: 1425 loss: 8.14848136e-06
Iter: 1426 loss: 8.20189052e-06
Iter: 1427 loss: 8.14765917e-06
Iter: 1428 loss: 8.14496525e-06
Iter: 1429 loss: 8.14481245e-06
Iter: 1430 loss: 8.14216219e-06
Iter: 1431 loss: 8.14727082e-06
Iter: 1432 loss: 8.14109626e-06
Iter: 1433 loss: 8.13887164e-06
Iter: 1434 loss: 8.13404768e-06
Iter: 1435 loss: 8.20505466e-06
Iter: 1436 loss: 8.13376573e-06
Iter: 1437 loss: 8.12860162e-06
Iter: 1438 loss: 8.18465924e-06
Iter: 1439 loss: 8.12854523e-06
Iter: 1440 loss: 8.12543476e-06
Iter: 1441 loss: 8.12549388e-06
Iter: 1442 loss: 8.12356211e-06
Iter: 1443 loss: 8.11854261e-06
Iter: 1444 loss: 8.14848681e-06
Iter: 1445 loss: 8.11694645e-06
Iter: 1446 loss: 8.11137397e-06
Iter: 1447 loss: 8.1945318e-06
Iter: 1448 loss: 8.11139762e-06
Iter: 1449 loss: 8.10931851e-06
Iter: 1450 loss: 8.10925485e-06
Iter: 1451 loss: 8.10799156e-06
Iter: 1452 loss: 8.10467645e-06
Iter: 1453 loss: 8.12478083e-06
Iter: 1454 loss: 8.10381e-06
Iter: 1455 loss: 8.10040274e-06
Iter: 1456 loss: 8.13802308e-06
Iter: 1457 loss: 8.10033907e-06
Iter: 1458 loss: 8.09707126e-06
Iter: 1459 loss: 8.11760219e-06
Iter: 1460 loss: 8.09677113e-06
Iter: 1461 loss: 8.09502399e-06
Iter: 1462 loss: 8.09071844e-06
Iter: 1463 loss: 8.13487713e-06
Iter: 1464 loss: 8.09024277e-06
Iter: 1465 loss: 8.08753248e-06
Iter: 1466 loss: 8.08672394e-06
Iter: 1467 loss: 8.08455297e-06
Iter: 1468 loss: 8.08007735e-06
Iter: 1469 loss: 8.17939599e-06
Iter: 1470 loss: 8.07999095e-06
Iter: 1471 loss: 8.07572633e-06
Iter: 1472 loss: 8.08219829e-06
Iter: 1473 loss: 8.07375818e-06
Iter: 1474 loss: 8.07180368e-06
Iter: 1475 loss: 8.07147717e-06
Iter: 1476 loss: 8.06920798e-06
Iter: 1477 loss: 8.06898061e-06
Iter: 1478 loss: 8.06745084e-06
Iter: 1479 loss: 8.06520893e-06
Iter: 1480 loss: 8.06477328e-06
Iter: 1481 loss: 8.06313892e-06
Iter: 1482 loss: 8.06061325e-06
Iter: 1483 loss: 8.06051503e-06
Iter: 1484 loss: 8.05834134e-06
Iter: 1485 loss: 8.05965374e-06
Iter: 1486 loss: 8.05688614e-06
Iter: 1487 loss: 8.05439413e-06
Iter: 1488 loss: 8.04955653e-06
Iter: 1489 loss: 8.14974101e-06
Iter: 1490 loss: 8.04953379e-06
Iter: 1491 loss: 8.04829324e-06
Iter: 1492 loss: 8.046517e-06
Iter: 1493 loss: 8.04460797e-06
Iter: 1494 loss: 8.04254796e-06
Iter: 1495 loss: 8.04216234e-06
Iter: 1496 loss: 8.04014508e-06
Iter: 1497 loss: 8.04429237e-06
Iter: 1498 loss: 8.03906369e-06
Iter: 1499 loss: 8.03572766e-06
Iter: 1500 loss: 8.04822412e-06
Iter: 1501 loss: 8.03498278e-06
Iter: 1502 loss: 8.03245712e-06
Iter: 1503 loss: 8.02908471e-06
Iter: 1504 loss: 8.0289592e-06
Iter: 1505 loss: 8.02431e-06
Iter: 1506 loss: 8.02756222e-06
Iter: 1507 loss: 8.02173599e-06
Iter: 1508 loss: 8.02223713e-06
Iter: 1509 loss: 8.01938768e-06
Iter: 1510 loss: 8.01785154e-06
Iter: 1511 loss: 8.013978e-06
Iter: 1512 loss: 8.04847059e-06
Iter: 1513 loss: 8.01344231e-06
Iter: 1514 loss: 8.00986072e-06
Iter: 1515 loss: 8.04751926e-06
Iter: 1516 loss: 8.00984526e-06
Iter: 1517 loss: 8.00788803e-06
Iter: 1518 loss: 8.00796442e-06
Iter: 1519 loss: 8.00673843e-06
Iter: 1520 loss: 8.0041691e-06
Iter: 1521 loss: 8.04493538e-06
Iter: 1522 loss: 8.00426278e-06
Iter: 1523 loss: 8.00106318e-06
Iter: 1524 loss: 8.00735779e-06
Iter: 1525 loss: 7.99948612e-06
Iter: 1526 loss: 7.9966976e-06
Iter: 1527 loss: 7.99668851e-06
Iter: 1528 loss: 7.9950587e-06
Iter: 1529 loss: 7.99082e-06
Iter: 1530 loss: 8.01795522e-06
Iter: 1531 loss: 7.98952078e-06
Iter: 1532 loss: 7.98772726e-06
Iter: 1533 loss: 7.98689234e-06
Iter: 1534 loss: 7.98431756e-06
Iter: 1535 loss: 7.98545e-06
Iter: 1536 loss: 7.98286692e-06
Iter: 1537 loss: 7.98058136e-06
Iter: 1538 loss: 7.97667053e-06
Iter: 1539 loss: 7.97676057e-06
Iter: 1540 loss: 7.97356461e-06
Iter: 1541 loss: 8.01842725e-06
Iter: 1542 loss: 7.97352277e-06
Iter: 1543 loss: 7.97123e-06
Iter: 1544 loss: 8.00525868e-06
Iter: 1545 loss: 7.97132179e-06
Iter: 1546 loss: 7.96959648e-06
Iter: 1547 loss: 7.96533823e-06
Iter: 1548 loss: 7.99703776e-06
Iter: 1549 loss: 7.96441873e-06
Iter: 1550 loss: 7.95985579e-06
Iter: 1551 loss: 7.98729434e-06
Iter: 1552 loss: 7.95930282e-06
Iter: 1553 loss: 7.95732194e-06
Iter: 1554 loss: 7.95723918e-06
Iter: 1555 loss: 7.95472806e-06
Iter: 1556 loss: 7.95035885e-06
Iter: 1557 loss: 7.95034157e-06
Iter: 1558 loss: 7.94820517e-06
Iter: 1559 loss: 7.96749646e-06
Iter: 1560 loss: 7.94806328e-06
Iter: 1561 loss: 7.94620701e-06
Iter: 1562 loss: 7.95925916e-06
Iter: 1563 loss: 7.94581e-06
Iter: 1564 loss: 7.94417065e-06
Iter: 1565 loss: 7.94147491e-06
Iter: 1566 loss: 7.94125845e-06
Iter: 1567 loss: 7.93839354e-06
Iter: 1568 loss: 7.95649521e-06
Iter: 1569 loss: 7.93802428e-06
Iter: 1570 loss: 7.9352485e-06
Iter: 1571 loss: 7.95588949e-06
Iter: 1572 loss: 7.93489744e-06
Iter: 1573 loss: 7.93307663e-06
Iter: 1574 loss: 7.92830815e-06
Iter: 1575 loss: 7.98320616e-06
Iter: 1576 loss: 7.92770697e-06
Iter: 1577 loss: 7.92341507e-06
Iter: 1578 loss: 7.93898107e-06
Iter: 1579 loss: 7.92228457e-06
Iter: 1580 loss: 7.91914863e-06
Iter: 1581 loss: 7.95849701e-06
Iter: 1582 loss: 7.91920866e-06
Iter: 1583 loss: 7.91684215e-06
Iter: 1584 loss: 7.94372409e-06
Iter: 1585 loss: 7.91694765e-06
Iter: 1586 loss: 7.91571256e-06
Iter: 1587 loss: 7.91261937e-06
Iter: 1588 loss: 7.93403342e-06
Iter: 1589 loss: 7.91166349e-06
Iter: 1590 loss: 7.90839113e-06
Iter: 1591 loss: 7.94898e-06
Iter: 1592 loss: 7.90825561e-06
Iter: 1593 loss: 7.90551712e-06
Iter: 1594 loss: 7.9358424e-06
Iter: 1595 loss: 7.90532249e-06
Iter: 1596 loss: 7.90402919e-06
Iter: 1597 loss: 7.90031936e-06
Iter: 1598 loss: 7.92727587e-06
Iter: 1599 loss: 7.89954629e-06
Iter: 1600 loss: 7.89874139e-06
Iter: 1601 loss: 7.89707155e-06
Iter: 1602 loss: 7.89585283e-06
Iter: 1603 loss: 7.89370642e-06
Iter: 1604 loss: 7.89365458e-06
Iter: 1605 loss: 7.89137812e-06
Iter: 1606 loss: 7.89470141e-06
Iter: 1607 loss: 7.89018486e-06
Iter: 1608 loss: 7.88705256e-06
Iter: 1609 loss: 7.91256298e-06
Iter: 1610 loss: 7.88685247e-06
Iter: 1611 loss: 7.88501802e-06
Iter: 1612 loss: 7.88302532e-06
Iter: 1613 loss: 7.88251418e-06
Iter: 1614 loss: 7.87894078e-06
Iter: 1615 loss: 7.87943645e-06
Iter: 1616 loss: 7.87616e-06
Iter: 1617 loss: 7.8714329e-06
Iter: 1618 loss: 7.89061596e-06
Iter: 1619 loss: 7.87042154e-06
Iter: 1620 loss: 7.86676082e-06
Iter: 1621 loss: 7.8727162e-06
Iter: 1622 loss: 7.86488727e-06
Iter: 1623 loss: 7.86177952e-06
Iter: 1624 loss: 7.87937643e-06
Iter: 1625 loss: 7.86145392e-06
Iter: 1626 loss: 7.85838074e-06
Iter: 1627 loss: 7.85820521e-06
Iter: 1628 loss: 7.85564771e-06
Iter: 1629 loss: 7.85424527e-06
Iter: 1630 loss: 7.8531184e-06
Iter: 1631 loss: 7.85184056e-06
Iter: 1632 loss: 7.84876374e-06
Iter: 1633 loss: 7.86783676e-06
Iter: 1634 loss: 7.84785061e-06
Iter: 1635 loss: 7.8458379e-06
Iter: 1636 loss: 7.84542e-06
Iter: 1637 loss: 7.84323493e-06
Iter: 1638 loss: 7.84068379e-06
Iter: 1639 loss: 7.84049098e-06
Iter: 1640 loss: 7.83790256e-06
Iter: 1641 loss: 7.84147596e-06
Iter: 1642 loss: 7.83690666e-06
Iter: 1643 loss: 7.83434371e-06
Iter: 1644 loss: 7.87239151e-06
Iter: 1645 loss: 7.83440373e-06
Iter: 1646 loss: 7.83260202e-06
Iter: 1647 loss: 7.83014821e-06
Iter: 1648 loss: 7.82993175e-06
Iter: 1649 loss: 7.82716415e-06
Iter: 1650 loss: 7.82733605e-06
Iter: 1651 loss: 7.82472489e-06
Iter: 1652 loss: 7.82210918e-06
Iter: 1653 loss: 7.82183088e-06
Iter: 1654 loss: 7.81931612e-06
Iter: 1655 loss: 7.81880681e-06
Iter: 1656 loss: 7.81717608e-06
Iter: 1657 loss: 7.81418e-06
Iter: 1658 loss: 7.81457311e-06
Iter: 1659 loss: 7.81196741e-06
Iter: 1660 loss: 7.80797654e-06
Iter: 1661 loss: 7.81576273e-06
Iter: 1662 loss: 7.80626942e-06
Iter: 1663 loss: 7.80301161e-06
Iter: 1664 loss: 7.81380913e-06
Iter: 1665 loss: 7.80208302e-06
Iter: 1666 loss: 7.7991881e-06
Iter: 1667 loss: 7.79911352e-06
Iter: 1668 loss: 7.79720176e-06
Iter: 1669 loss: 7.79310085e-06
Iter: 1670 loss: 7.86364581e-06
Iter: 1671 loss: 7.79303627e-06
Iter: 1672 loss: 7.79110451e-06
Iter: 1673 loss: 7.7909981e-06
Iter: 1674 loss: 7.78862341e-06
Iter: 1675 loss: 7.78392678e-06
Iter: 1676 loss: 7.87511271e-06
Iter: 1677 loss: 7.78393223e-06
Iter: 1678 loss: 7.78050526e-06
Iter: 1679 loss: 7.79127913e-06
Iter: 1680 loss: 7.77941568e-06
Iter: 1681 loss: 7.77730293e-06
Iter: 1682 loss: 7.77717e-06
Iter: 1683 loss: 7.77521745e-06
Iter: 1684 loss: 7.77069454e-06
Iter: 1685 loss: 7.8328394e-06
Iter: 1686 loss: 7.77048444e-06
Iter: 1687 loss: 7.7665527e-06
Iter: 1688 loss: 7.76876732e-06
Iter: 1689 loss: 7.76388242e-06
Iter: 1690 loss: 7.76025718e-06
Iter: 1691 loss: 7.76021807e-06
Iter: 1692 loss: 7.7567347e-06
Iter: 1693 loss: 7.76988145e-06
Iter: 1694 loss: 7.75584249e-06
Iter: 1695 loss: 7.754119e-06
Iter: 1696 loss: 7.74980435e-06
Iter: 1697 loss: 7.8198027e-06
Iter: 1698 loss: 7.74967157e-06
Iter: 1699 loss: 7.74523323e-06
Iter: 1700 loss: 7.78224603e-06
Iter: 1701 loss: 7.74496948e-06
Iter: 1702 loss: 7.74303408e-06
Iter: 1703 loss: 7.74306136e-06
Iter: 1704 loss: 7.74113869e-06
Iter: 1705 loss: 7.74019645e-06
Iter: 1706 loss: 7.7390614e-06
Iter: 1707 loss: 7.73609645e-06
Iter: 1708 loss: 7.73486772e-06
Iter: 1709 loss: 7.7334189e-06
Iter: 1710 loss: 7.73156353e-06
Iter: 1711 loss: 7.73101237e-06
Iter: 1712 loss: 7.72933618e-06
Iter: 1713 loss: 7.7256409e-06
Iter: 1714 loss: 7.79438233e-06
Iter: 1715 loss: 7.72563e-06
Iter: 1716 loss: 7.72184831e-06
Iter: 1717 loss: 7.73177453e-06
Iter: 1718 loss: 7.72061412e-06
Iter: 1719 loss: 7.71944178e-06
Iter: 1720 loss: 7.71887062e-06
Iter: 1721 loss: 7.71782e-06
Iter: 1722 loss: 7.71501891e-06
Iter: 1723 loss: 7.72409385e-06
Iter: 1724 loss: 7.71347914e-06
Iter: 1725 loss: 7.71019586e-06
Iter: 1726 loss: 7.7360819e-06
Iter: 1727 loss: 7.71004215e-06
Iter: 1728 loss: 7.70729639e-06
Iter: 1729 loss: 7.74072669e-06
Iter: 1730 loss: 7.70725092e-06
Iter: 1731 loss: 7.70424867e-06
Iter: 1732 loss: 7.70036422e-06
Iter: 1733 loss: 7.70024326e-06
Iter: 1734 loss: 7.69642429e-06
Iter: 1735 loss: 7.69936923e-06
Iter: 1736 loss: 7.69430153e-06
Iter: 1737 loss: 7.69077906e-06
Iter: 1738 loss: 7.72868225e-06
Iter: 1739 loss: 7.69059443e-06
Iter: 1740 loss: 7.68703103e-06
Iter: 1741 loss: 7.70766565e-06
Iter: 1742 loss: 7.68651353e-06
Iter: 1743 loss: 7.6854194e-06
Iter: 1744 loss: 7.68318205e-06
Iter: 1745 loss: 7.68311293e-06
Iter: 1746 loss: 7.68128575e-06
Iter: 1747 loss: 7.6811275e-06
Iter: 1748 loss: 7.67970596e-06
Iter: 1749 loss: 7.67742131e-06
Iter: 1750 loss: 7.6773249e-06
Iter: 1751 loss: 7.67455913e-06
Iter: 1752 loss: 7.67784059e-06
Iter: 1753 loss: 7.67321308e-06
Iter: 1754 loss: 7.67014444e-06
Iter: 1755 loss: 7.70641054e-06
Iter: 1756 loss: 7.67010351e-06
Iter: 1757 loss: 7.66743e-06
Iter: 1758 loss: 7.66653284e-06
Iter: 1759 loss: 7.665054e-06
Iter: 1760 loss: 7.66248922e-06
Iter: 1761 loss: 7.65977165e-06
Iter: 1762 loss: 7.65928235e-06
Iter: 1763 loss: 7.65621826e-06
Iter: 1764 loss: 7.65630193e-06
Iter: 1765 loss: 7.6538181e-06
Iter: 1766 loss: 7.67445454e-06
Iter: 1767 loss: 7.65349432e-06
Iter: 1768 loss: 7.65224e-06
Iter: 1769 loss: 7.64891047e-06
Iter: 1770 loss: 7.67885194e-06
Iter: 1771 loss: 7.64825927e-06
Iter: 1772 loss: 7.64432843e-06
Iter: 1773 loss: 7.66990161e-06
Iter: 1774 loss: 7.64405559e-06
Iter: 1775 loss: 7.64266406e-06
Iter: 1776 loss: 7.64221113e-06
Iter: 1777 loss: 7.64089873e-06
Iter: 1778 loss: 7.63760727e-06
Iter: 1779 loss: 7.67122e-06
Iter: 1780 loss: 7.63737444e-06
Iter: 1781 loss: 7.63516073e-06
Iter: 1782 loss: 7.63527351e-06
Iter: 1783 loss: 7.63302523e-06
Iter: 1784 loss: 7.63644221e-06
Iter: 1785 loss: 7.6321212e-06
Iter: 1786 loss: 7.63008575e-06
Iter: 1787 loss: 7.62605305e-06
Iter: 1788 loss: 7.70150291e-06
Iter: 1789 loss: 7.62597301e-06
Iter: 1790 loss: 7.62394802e-06
Iter: 1791 loss: 7.62363925e-06
Iter: 1792 loss: 7.62129821e-06
Iter: 1793 loss: 7.62646869e-06
Iter: 1794 loss: 7.62044601e-06
Iter: 1795 loss: 7.61828733e-06
Iter: 1796 loss: 7.61534329e-06
Iter: 1797 loss: 7.61525052e-06
Iter: 1798 loss: 7.61288538e-06
Iter: 1799 loss: 7.63916523e-06
Iter: 1800 loss: 7.61270257e-06
Iter: 1801 loss: 7.61079173e-06
Iter: 1802 loss: 7.62254695e-06
Iter: 1803 loss: 7.61060437e-06
Iter: 1804 loss: 7.60844341e-06
Iter: 1805 loss: 7.60821331e-06
Iter: 1806 loss: 7.60660214e-06
Iter: 1807 loss: 7.60461444e-06
Iter: 1808 loss: 7.60436387e-06
Iter: 1809 loss: 7.60304465e-06
Iter: 1810 loss: 7.60089733e-06
Iter: 1811 loss: 7.6009037e-06
Iter: 1812 loss: 7.59850627e-06
Iter: 1813 loss: 7.59644581e-06
Iter: 1814 loss: 7.59567683e-06
Iter: 1815 loss: 7.59329578e-06
Iter: 1816 loss: 7.59384511e-06
Iter: 1817 loss: 7.59152545e-06
Iter: 1818 loss: 7.58943679e-06
Iter: 1819 loss: 7.58936494e-06
Iter: 1820 loss: 7.58720398e-06
Iter: 1821 loss: 7.58448687e-06
Iter: 1822 loss: 7.58441092e-06
Iter: 1823 loss: 7.58179431e-06
Iter: 1824 loss: 7.58231454e-06
Iter: 1825 loss: 7.58021906e-06
Iter: 1826 loss: 7.57834732e-06
Iter: 1827 loss: 7.57798443e-06
Iter: 1828 loss: 7.5763578e-06
Iter: 1829 loss: 7.57372163e-06
Iter: 1830 loss: 7.57366888e-06
Iter: 1831 loss: 7.57098269e-06
Iter: 1832 loss: 7.57066482e-06
Iter: 1833 loss: 7.56861391e-06
Iter: 1834 loss: 7.56853842e-06
Iter: 1835 loss: 7.56683312e-06
Iter: 1836 loss: 7.5657972e-06
Iter: 1837 loss: 7.5638136e-06
Iter: 1838 loss: 7.56380859e-06
Iter: 1839 loss: 7.56123382e-06
Iter: 1840 loss: 7.56119e-06
Iter: 1841 loss: 7.5591588e-06
Iter: 1842 loss: 7.55587871e-06
Iter: 1843 loss: 7.57407497e-06
Iter: 1844 loss: 7.55546444e-06
Iter: 1845 loss: 7.55388464e-06
Iter: 1846 loss: 7.55381e-06
Iter: 1847 loss: 7.55186329e-06
Iter: 1848 loss: 7.54886696e-06
Iter: 1849 loss: 7.54878511e-06
Iter: 1850 loss: 7.54636e-06
Iter: 1851 loss: 7.55110887e-06
Iter: 1852 loss: 7.54522762e-06
Iter: 1853 loss: 7.54378925e-06
Iter: 1854 loss: 7.54381153e-06
Iter: 1855 loss: 7.5423095e-06
Iter: 1856 loss: 7.5401e-06
Iter: 1857 loss: 7.54004759e-06
Iter: 1858 loss: 7.53779932e-06
Iter: 1859 loss: 7.53750101e-06
Iter: 1860 loss: 7.53588e-06
Iter: 1861 loss: 7.53281256e-06
Iter: 1862 loss: 7.54909206e-06
Iter: 1863 loss: 7.53217364e-06
Iter: 1864 loss: 7.52887445e-06
Iter: 1865 loss: 7.55689462e-06
Iter: 1866 loss: 7.52866208e-06
Iter: 1867 loss: 7.52723736e-06
Iter: 1868 loss: 7.52424603e-06
Iter: 1869 loss: 7.568819e-06
Iter: 1870 loss: 7.52409915e-06
Iter: 1871 loss: 7.52110418e-06
Iter: 1872 loss: 7.55932706e-06
Iter: 1873 loss: 7.52112828e-06
Iter: 1874 loss: 7.51886637e-06
Iter: 1875 loss: 7.54101029e-06
Iter: 1876 loss: 7.51866219e-06
Iter: 1877 loss: 7.5177777e-06
Iter: 1878 loss: 7.51577863e-06
Iter: 1879 loss: 7.55132714e-06
Iter: 1880 loss: 7.5158232e-06
Iter: 1881 loss: 7.51319112e-06
Iter: 1882 loss: 7.51755942e-06
Iter: 1883 loss: 7.51213156e-06
Iter: 1884 loss: 7.5108e-06
Iter: 1885 loss: 7.51039443e-06
Iter: 1886 loss: 7.50920708e-06
Iter: 1887 loss: 7.50618892e-06
Iter: 1888 loss: 7.52562937e-06
Iter: 1889 loss: 7.50556273e-06
Iter: 1890 loss: 7.50186155e-06
Iter: 1891 loss: 7.52563437e-06
Iter: 1892 loss: 7.50137406e-06
Iter: 1893 loss: 7.49974697e-06
Iter: 1894 loss: 7.49975925e-06
Iter: 1895 loss: 7.49829951e-06
Iter: 1896 loss: 7.49584524e-06
Iter: 1897 loss: 7.54558459e-06
Iter: 1898 loss: 7.49571154e-06
Iter: 1899 loss: 7.49309584e-06
Iter: 1900 loss: 7.4992895e-06
Iter: 1901 loss: 7.4922882e-06
Iter: 1902 loss: 7.4911768e-06
Iter: 1903 loss: 7.49109404e-06
Iter: 1904 loss: 7.4898071e-06
Iter: 1905 loss: 7.48715865e-06
Iter: 1906 loss: 7.52584583e-06
Iter: 1907 loss: 7.48716957e-06
Iter: 1908 loss: 7.48422144e-06
Iter: 1909 loss: 7.48633e-06
Iter: 1910 loss: 7.48236516e-06
Iter: 1911 loss: 7.48151524e-06
Iter: 1912 loss: 7.48082675e-06
Iter: 1913 loss: 7.4792988e-06
Iter: 1914 loss: 7.47603e-06
Iter: 1915 loss: 7.52782762e-06
Iter: 1916 loss: 7.47582089e-06
Iter: 1917 loss: 7.47338527e-06
Iter: 1918 loss: 7.47855665e-06
Iter: 1919 loss: 7.47226386e-06
Iter: 1920 loss: 7.46975365e-06
Iter: 1921 loss: 7.49002629e-06
Iter: 1922 loss: 7.46980822e-06
Iter: 1923 loss: 7.46725073e-06
Iter: 1924 loss: 7.48213188e-06
Iter: 1925 loss: 7.46679689e-06
Iter: 1926 loss: 7.46564092e-06
Iter: 1927 loss: 7.46210344e-06
Iter: 1928 loss: 7.48737602e-06
Iter: 1929 loss: 7.4613713e-06
Iter: 1930 loss: 7.4578038e-06
Iter: 1931 loss: 7.45788657e-06
Iter: 1932 loss: 7.45544094e-06
Iter: 1933 loss: 7.47928198e-06
Iter: 1934 loss: 7.45530224e-06
Iter: 1935 loss: 7.45414854e-06
Iter: 1936 loss: 7.45167608e-06
Iter: 1937 loss: 7.4963732e-06
Iter: 1938 loss: 7.45173929e-06
Iter: 1939 loss: 7.44865429e-06
Iter: 1940 loss: 7.45765419e-06
Iter: 1941 loss: 7.44771114e-06
Iter: 1942 loss: 7.44673025e-06
Iter: 1943 loss: 7.44650833e-06
Iter: 1944 loss: 7.44542876e-06
Iter: 1945 loss: 7.44426325e-06
Iter: 1946 loss: 7.44402405e-06
Iter: 1947 loss: 7.44209683e-06
Iter: 1948 loss: 7.43986584e-06
Iter: 1949 loss: 7.43969531e-06
Iter: 1950 loss: 7.43709734e-06
Iter: 1951 loss: 7.46741e-06
Iter: 1952 loss: 7.43690498e-06
Iter: 1953 loss: 7.43416786e-06
Iter: 1954 loss: 7.44255158e-06
Iter: 1955 loss: 7.43334e-06
Iter: 1956 loss: 7.43160626e-06
Iter: 1957 loss: 7.43005739e-06
Iter: 1958 loss: 7.42959719e-06
Iter: 1959 loss: 7.42762131e-06
Iter: 1960 loss: 7.44914e-06
Iter: 1961 loss: 7.4276918e-06
Iter: 1962 loss: 7.42525e-06
Iter: 1963 loss: 7.42858174e-06
Iter: 1964 loss: 7.42418115e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.4/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.8 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.8
+ date
Sun Nov  8 07:46:20 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.4/300_100_100_100_1 --function f2 --psi 0 --alpha 0.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.8/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd968b9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd96880400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91e27e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91e27bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd96807510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9680dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91d851e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91d858c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9680df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91dc7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91dc7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91d806a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91d80ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91c8ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91cac6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91cac950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91c352f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91ce5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91ce5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91bef510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91bef9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91b4b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91b52ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91b52488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9684b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9683da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9683e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9683d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd9683d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91abdf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91aa30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91a12378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91a12598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91ad88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91a1c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdd91ad8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.014277343
test_loss: 0.014751018
train_loss: 0.0122390315
test_loss: 0.012690194
train_loss: 0.0119735375
test_loss: 0.012382583
train_loss: 0.01111903
test_loss: 0.012050658
train_loss: 0.011058447
test_loss: 0.011531427
train_loss: 0.010226698
test_loss: 0.011274512
train_loss: 0.010259486
test_loss: 0.011194885
train_loss: 0.010364354
test_loss: 0.011723664
train_loss: 0.010422313
test_loss: 0.011190227
train_loss: 0.009714701
test_loss: 0.010819208
train_loss: 0.009225834
test_loss: 0.010610917
train_loss: 0.0092433095
test_loss: 0.010601271
train_loss: 0.009854821
test_loss: 0.010890831
train_loss: 0.008741993
test_loss: 0.010153708
train_loss: 0.00948911
test_loss: 0.010245753
train_loss: 0.008985725
test_loss: 0.010754468
train_loss: 0.009341992
test_loss: 0.010240048
train_loss: 0.009048341
test_loss: 0.01025593
train_loss: 0.009131081
test_loss: 0.010159453
train_loss: 0.008944842
test_loss: 0.010157871
train_loss: 0.009119949
test_loss: 0.010091982
train_loss: 0.008712325
test_loss: 0.0098427925
train_loss: 0.009487911
test_loss: 0.010431721
train_loss: 0.00861166
test_loss: 0.010016754
train_loss: 0.0085665155
test_loss: 0.009937916
train_loss: 0.008693166
test_loss: 0.009770229
train_loss: 0.008452939
test_loss: 0.009937299
train_loss: 0.00839034
test_loss: 0.009659458
train_loss: 0.008521616
test_loss: 0.009821365
train_loss: 0.008714037
test_loss: 0.009861303
train_loss: 0.008621435
test_loss: 0.009781246
train_loss: 0.008594741
test_loss: 0.0095793465
train_loss: 0.008700763
test_loss: 0.009885616
train_loss: 0.008745761
test_loss: 0.009645111
train_loss: 0.008080469
test_loss: 0.010051882
train_loss: 0.008339367
test_loss: 0.009563615
train_loss: 0.00836905
test_loss: 0.009310837
train_loss: 0.007912725
test_loss: 0.009314865
train_loss: 0.008691746
test_loss: 0.009583418
train_loss: 0.007944018
test_loss: 0.009437055
train_loss: 0.007855446
test_loss: 0.009568206
train_loss: 0.008208194
test_loss: 0.009570448
train_loss: 0.007905555
test_loss: 0.009248034
train_loss: 0.008034055
test_loss: 0.009413876
train_loss: 0.0076975445
test_loss: 0.008970663
train_loss: 0.007542861
test_loss: 0.009263196
train_loss: 0.0074792323
test_loss: 0.009051969
train_loss: 0.00757479
test_loss: 0.008992006
train_loss: 0.0075880783
test_loss: 0.009106975
train_loss: 0.0069418736
test_loss: 0.008676718
train_loss: 0.007726338
test_loss: 0.008911733
train_loss: 0.007766239
test_loss: 0.009254816
train_loss: 0.00690988
test_loss: 0.008690696
train_loss: 0.007633989
test_loss: 0.008963037
train_loss: 0.0071758674
test_loss: 0.008965568
train_loss: 0.007538458
test_loss: 0.009091573
train_loss: 0.0077199177
test_loss: 0.009162409
train_loss: 0.0070763733
test_loss: 0.008652283
train_loss: 0.00801179
test_loss: 0.008938917
train_loss: 0.007327597
test_loss: 0.008928538
train_loss: 0.007420734
test_loss: 0.009063144
train_loss: 0.007081086
test_loss: 0.008895264
train_loss: 0.007334887
test_loss: 0.008802179
train_loss: 0.0075011854
test_loss: 0.009056821
train_loss: 0.007473388
test_loss: 0.008758091
train_loss: 0.00697341
test_loss: 0.008798568
train_loss: 0.007303557
test_loss: 0.008536158
train_loss: 0.006864355
test_loss: 0.008738086
train_loss: 0.0071567073
test_loss: 0.008511612
train_loss: 0.007023057
test_loss: 0.008559632
train_loss: 0.0072485483
test_loss: 0.008590369
train_loss: 0.0067397365
test_loss: 0.008506109
train_loss: 0.007165467
test_loss: 0.009062265
train_loss: 0.0071206754
test_loss: 0.008307677
train_loss: 0.0066589117
test_loss: 0.008370334
train_loss: 0.007752613
test_loss: 0.009009278
train_loss: 0.006556199
test_loss: 0.008368571
train_loss: 0.0074089393
test_loss: 0.008566603
train_loss: 0.0067209355
test_loss: 0.008142829
train_loss: 0.006664544
test_loss: 0.008269913
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.8/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 0.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi0.8/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f1729510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f1715730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f16e4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f16e1f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f16a4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f16bb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f167c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f16bb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f1630400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f167c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f167c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d72bc950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d72bcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d726b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d720e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37f167c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d720e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d71fc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d71fc598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d71fc488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d71a7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d710d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d712db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d712dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d712d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d70e5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d70f4e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d70bc268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d70bcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d70bc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d7088158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d6ff1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d6ffb510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d6fc4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d6fc4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f37d6fc4268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 7.77925452e-05
Iter: 2 loss: 7.18544834e-05
Iter: 3 loss: 6.59401849e-05
Iter: 4 loss: 6.06039248e-05
Iter: 5 loss: 7.13507688e-05
Iter: 6 loss: 5.84764093e-05
Iter: 7 loss: 5.35695144e-05
Iter: 8 loss: 6.45382752e-05
Iter: 9 loss: 5.16834225e-05
Iter: 10 loss: 4.82089927e-05
Iter: 11 loss: 7.59055474e-05
Iter: 12 loss: 4.79724768e-05
Iter: 13 loss: 4.54169276e-05
Iter: 14 loss: 5.20738649e-05
Iter: 15 loss: 4.45536753e-05
Iter: 16 loss: 4.31693297e-05
Iter: 17 loss: 4.28012791e-05
Iter: 18 loss: 4.19428579e-05
Iter: 19 loss: 4.03425074e-05
Iter: 20 loss: 4.03348822e-05
Iter: 21 loss: 3.93787886e-05
Iter: 22 loss: 3.84600062e-05
Iter: 23 loss: 3.82470862e-05
Iter: 24 loss: 3.72109353e-05
Iter: 25 loss: 4.50090301e-05
Iter: 26 loss: 3.71307469e-05
Iter: 27 loss: 3.60967169e-05
Iter: 28 loss: 4.06920808e-05
Iter: 29 loss: 3.58928664e-05
Iter: 30 loss: 3.53192372e-05
Iter: 31 loss: 3.47411769e-05
Iter: 32 loss: 3.46261586e-05
Iter: 33 loss: 3.37984311e-05
Iter: 34 loss: 3.565714e-05
Iter: 35 loss: 3.34868819e-05
Iter: 36 loss: 3.28717688e-05
Iter: 37 loss: 4.06127729e-05
Iter: 38 loss: 3.28662318e-05
Iter: 39 loss: 3.23213062e-05
Iter: 40 loss: 3.41912164e-05
Iter: 41 loss: 3.21762418e-05
Iter: 42 loss: 3.17906051e-05
Iter: 43 loss: 3.3205928e-05
Iter: 44 loss: 3.16952101e-05
Iter: 45 loss: 3.13360506e-05
Iter: 46 loss: 3.25067595e-05
Iter: 47 loss: 3.12358497e-05
Iter: 48 loss: 3.08642193e-05
Iter: 49 loss: 3.14119316e-05
Iter: 50 loss: 3.06846268e-05
Iter: 51 loss: 3.03864908e-05
Iter: 52 loss: 3.08710587e-05
Iter: 53 loss: 3.0250123e-05
Iter: 54 loss: 3.00195934e-05
Iter: 55 loss: 3.00192751e-05
Iter: 56 loss: 2.98419527e-05
Iter: 57 loss: 2.95128029e-05
Iter: 58 loss: 3.70292291e-05
Iter: 59 loss: 2.95125828e-05
Iter: 60 loss: 2.92961577e-05
Iter: 61 loss: 3.2704138e-05
Iter: 62 loss: 2.92963196e-05
Iter: 63 loss: 2.90776916e-05
Iter: 64 loss: 2.94648307e-05
Iter: 65 loss: 2.89819673e-05
Iter: 66 loss: 2.87916118e-05
Iter: 67 loss: 2.86248905e-05
Iter: 68 loss: 2.85743063e-05
Iter: 69 loss: 2.82991587e-05
Iter: 70 loss: 2.92561144e-05
Iter: 71 loss: 2.82270066e-05
Iter: 72 loss: 2.80104759e-05
Iter: 73 loss: 3.14299905e-05
Iter: 74 loss: 2.80103468e-05
Iter: 75 loss: 2.78460102e-05
Iter: 76 loss: 2.80768927e-05
Iter: 77 loss: 2.77651543e-05
Iter: 78 loss: 2.76265764e-05
Iter: 79 loss: 2.83968366e-05
Iter: 80 loss: 2.76070969e-05
Iter: 81 loss: 2.74766262e-05
Iter: 82 loss: 2.76547689e-05
Iter: 83 loss: 2.7411721e-05
Iter: 84 loss: 2.72627403e-05
Iter: 85 loss: 2.74873455e-05
Iter: 86 loss: 2.71921963e-05
Iter: 87 loss: 2.70557284e-05
Iter: 88 loss: 2.7444461e-05
Iter: 89 loss: 2.70126457e-05
Iter: 90 loss: 2.68660824e-05
Iter: 91 loss: 2.77909403e-05
Iter: 92 loss: 2.68492731e-05
Iter: 93 loss: 2.67377982e-05
Iter: 94 loss: 2.65685048e-05
Iter: 95 loss: 2.65655744e-05
Iter: 96 loss: 2.64759583e-05
Iter: 97 loss: 2.64636619e-05
Iter: 98 loss: 2.63612128e-05
Iter: 99 loss: 2.62712892e-05
Iter: 100 loss: 2.62445119e-05
Iter: 101 loss: 2.61139539e-05
Iter: 102 loss: 2.61164569e-05
Iter: 103 loss: 2.60100824e-05
Iter: 104 loss: 2.58790587e-05
Iter: 105 loss: 2.7282249e-05
Iter: 106 loss: 2.5876132e-05
Iter: 107 loss: 2.57511019e-05
Iter: 108 loss: 2.63425554e-05
Iter: 109 loss: 2.57281372e-05
Iter: 110 loss: 2.56380426e-05
Iter: 111 loss: 2.5831614e-05
Iter: 112 loss: 2.56031708e-05
Iter: 113 loss: 2.5523168e-05
Iter: 114 loss: 2.60484376e-05
Iter: 115 loss: 2.55147861e-05
Iter: 116 loss: 2.54439165e-05
Iter: 117 loss: 2.5404137e-05
Iter: 118 loss: 2.53735707e-05
Iter: 119 loss: 2.5255762e-05
Iter: 120 loss: 2.55428349e-05
Iter: 121 loss: 2.52137615e-05
Iter: 122 loss: 2.51295041e-05
Iter: 123 loss: 2.5990872e-05
Iter: 124 loss: 2.51269e-05
Iter: 125 loss: 2.50520388e-05
Iter: 126 loss: 2.50713329e-05
Iter: 127 loss: 2.49973036e-05
Iter: 128 loss: 2.49148652e-05
Iter: 129 loss: 2.49172044e-05
Iter: 130 loss: 2.48493525e-05
Iter: 131 loss: 2.47856115e-05
Iter: 132 loss: 2.47773278e-05
Iter: 133 loss: 2.47353055e-05
Iter: 134 loss: 2.46514173e-05
Iter: 135 loss: 2.6224785e-05
Iter: 136 loss: 2.46503187e-05
Iter: 137 loss: 2.45558149e-05
Iter: 138 loss: 2.46198906e-05
Iter: 139 loss: 2.44964576e-05
Iter: 140 loss: 2.44532785e-05
Iter: 141 loss: 2.44351668e-05
Iter: 142 loss: 2.43840586e-05
Iter: 143 loss: 2.43622908e-05
Iter: 144 loss: 2.43356517e-05
Iter: 145 loss: 2.42713959e-05
Iter: 146 loss: 2.46804757e-05
Iter: 147 loss: 2.42639526e-05
Iter: 148 loss: 2.42024453e-05
Iter: 149 loss: 2.4276389e-05
Iter: 150 loss: 2.41701819e-05
Iter: 151 loss: 2.4105324e-05
Iter: 152 loss: 2.42152601e-05
Iter: 153 loss: 2.40762984e-05
Iter: 154 loss: 2.40138743e-05
Iter: 155 loss: 2.42979841e-05
Iter: 156 loss: 2.40019745e-05
Iter: 157 loss: 2.39508863e-05
Iter: 158 loss: 2.42824644e-05
Iter: 159 loss: 2.39456494e-05
Iter: 160 loss: 2.39029268e-05
Iter: 161 loss: 2.38413686e-05
Iter: 162 loss: 2.38394314e-05
Iter: 163 loss: 2.37765926e-05
Iter: 164 loss: 2.44260882e-05
Iter: 165 loss: 2.3775021e-05
Iter: 166 loss: 2.37102104e-05
Iter: 167 loss: 2.38321845e-05
Iter: 168 loss: 2.36824817e-05
Iter: 169 loss: 2.36339474e-05
Iter: 170 loss: 2.35761981e-05
Iter: 171 loss: 2.3570341e-05
Iter: 172 loss: 2.34961062e-05
Iter: 173 loss: 2.39253095e-05
Iter: 174 loss: 2.34860727e-05
Iter: 175 loss: 2.34370018e-05
Iter: 176 loss: 2.3436507e-05
Iter: 177 loss: 2.34077761e-05
Iter: 178 loss: 2.33731771e-05
Iter: 179 loss: 2.33699939e-05
Iter: 180 loss: 2.33147093e-05
Iter: 181 loss: 2.37460354e-05
Iter: 182 loss: 2.33107421e-05
Iter: 183 loss: 2.32700586e-05
Iter: 184 loss: 2.32656e-05
Iter: 185 loss: 2.32360544e-05
Iter: 186 loss: 2.31827053e-05
Iter: 187 loss: 2.33688843e-05
Iter: 188 loss: 2.31689246e-05
Iter: 189 loss: 2.3121409e-05
Iter: 190 loss: 2.3373741e-05
Iter: 191 loss: 2.3113691e-05
Iter: 192 loss: 2.30660171e-05
Iter: 193 loss: 2.31109716e-05
Iter: 194 loss: 2.30380792e-05
Iter: 195 loss: 2.29951711e-05
Iter: 196 loss: 2.30566784e-05
Iter: 197 loss: 2.29740708e-05
Iter: 198 loss: 2.29348152e-05
Iter: 199 loss: 2.34940799e-05
Iter: 200 loss: 2.29347061e-05
Iter: 201 loss: 2.29000671e-05
Iter: 202 loss: 2.28332756e-05
Iter: 203 loss: 2.4237379e-05
Iter: 204 loss: 2.28329718e-05
Iter: 205 loss: 2.27804467e-05
Iter: 206 loss: 2.29643465e-05
Iter: 207 loss: 2.27670353e-05
Iter: 208 loss: 2.27269829e-05
Iter: 209 loss: 2.32494749e-05
Iter: 210 loss: 2.27264409e-05
Iter: 211 loss: 2.26827833e-05
Iter: 212 loss: 2.26820521e-05
Iter: 213 loss: 2.26473894e-05
Iter: 214 loss: 2.26129596e-05
Iter: 215 loss: 2.29748184e-05
Iter: 216 loss: 2.2611981e-05
Iter: 217 loss: 2.25802105e-05
Iter: 218 loss: 2.25867989e-05
Iter: 219 loss: 2.25572312e-05
Iter: 220 loss: 2.25158365e-05
Iter: 221 loss: 2.25266431e-05
Iter: 222 loss: 2.24859141e-05
Iter: 223 loss: 2.24334508e-05
Iter: 224 loss: 2.28506287e-05
Iter: 225 loss: 2.24298419e-05
Iter: 226 loss: 2.2395e-05
Iter: 227 loss: 2.25877102e-05
Iter: 228 loss: 2.23899497e-05
Iter: 229 loss: 2.23602656e-05
Iter: 230 loss: 2.23220286e-05
Iter: 231 loss: 2.23193274e-05
Iter: 232 loss: 2.22819399e-05
Iter: 233 loss: 2.28100162e-05
Iter: 234 loss: 2.22817707e-05
Iter: 235 loss: 2.22492163e-05
Iter: 236 loss: 2.23320749e-05
Iter: 237 loss: 2.22376948e-05
Iter: 238 loss: 2.2210148e-05
Iter: 239 loss: 2.21552637e-05
Iter: 240 loss: 2.31845588e-05
Iter: 241 loss: 2.2154305e-05
Iter: 242 loss: 2.21063165e-05
Iter: 243 loss: 2.26722223e-05
Iter: 244 loss: 2.21060818e-05
Iter: 245 loss: 2.20746078e-05
Iter: 246 loss: 2.25346084e-05
Iter: 247 loss: 2.20745605e-05
Iter: 248 loss: 2.20508937e-05
Iter: 249 loss: 2.2008302e-05
Iter: 250 loss: 2.30170954e-05
Iter: 251 loss: 2.20081e-05
Iter: 252 loss: 2.19666836e-05
Iter: 253 loss: 2.19666126e-05
Iter: 254 loss: 2.19410103e-05
Iter: 255 loss: 2.19255526e-05
Iter: 256 loss: 2.19150934e-05
Iter: 257 loss: 2.18836831e-05
Iter: 258 loss: 2.2028049e-05
Iter: 259 loss: 2.1877222e-05
Iter: 260 loss: 2.18426521e-05
Iter: 261 loss: 2.19353988e-05
Iter: 262 loss: 2.18313689e-05
Iter: 263 loss: 2.17954985e-05
Iter: 264 loss: 2.18907298e-05
Iter: 265 loss: 2.17839515e-05
Iter: 266 loss: 2.17549314e-05
Iter: 267 loss: 2.17626693e-05
Iter: 268 loss: 2.17341512e-05
Iter: 269 loss: 2.17028628e-05
Iter: 270 loss: 2.21936243e-05
Iter: 271 loss: 2.17029919e-05
Iter: 272 loss: 2.16781282e-05
Iter: 273 loss: 2.16330027e-05
Iter: 274 loss: 2.27063083e-05
Iter: 275 loss: 2.16329554e-05
Iter: 276 loss: 2.15890905e-05
Iter: 277 loss: 2.16992739e-05
Iter: 278 loss: 2.15734508e-05
Iter: 279 loss: 2.15480777e-05
Iter: 280 loss: 2.15475593e-05
Iter: 281 loss: 2.15201544e-05
Iter: 282 loss: 2.15242144e-05
Iter: 283 loss: 2.14994488e-05
Iter: 284 loss: 2.1472455e-05
Iter: 285 loss: 2.1584181e-05
Iter: 286 loss: 2.14667707e-05
Iter: 287 loss: 2.14343472e-05
Iter: 288 loss: 2.14804368e-05
Iter: 289 loss: 2.14184802e-05
Iter: 290 loss: 2.13876e-05
Iter: 291 loss: 2.13901149e-05
Iter: 292 loss: 2.13640506e-05
Iter: 293 loss: 2.13321746e-05
Iter: 294 loss: 2.17772831e-05
Iter: 295 loss: 2.13321418e-05
Iter: 296 loss: 2.13064777e-05
Iter: 297 loss: 2.13138192e-05
Iter: 298 loss: 2.12879859e-05
Iter: 299 loss: 2.12505347e-05
Iter: 300 loss: 2.13051e-05
Iter: 301 loss: 2.12325467e-05
Iter: 302 loss: 2.12070772e-05
Iter: 303 loss: 2.14420888e-05
Iter: 304 loss: 2.12062732e-05
Iter: 305 loss: 2.11815241e-05
Iter: 306 loss: 2.12256236e-05
Iter: 307 loss: 2.11708448e-05
Iter: 308 loss: 2.1148644e-05
Iter: 309 loss: 2.11219922e-05
Iter: 310 loss: 2.11193346e-05
Iter: 311 loss: 2.10847575e-05
Iter: 312 loss: 2.11913357e-05
Iter: 313 loss: 2.10750059e-05
Iter: 314 loss: 2.10443322e-05
Iter: 315 loss: 2.10441503e-05
Iter: 316 loss: 2.10226754e-05
Iter: 317 loss: 2.09913123e-05
Iter: 318 loss: 2.09903119e-05
Iter: 319 loss: 2.09637292e-05
Iter: 320 loss: 2.09633363e-05
Iter: 321 loss: 2.09442023e-05
Iter: 322 loss: 2.09152076e-05
Iter: 323 loss: 2.09146892e-05
Iter: 324 loss: 2.08825586e-05
Iter: 325 loss: 2.10618746e-05
Iter: 326 loss: 2.08782039e-05
Iter: 327 loss: 2.08501e-05
Iter: 328 loss: 2.103519e-05
Iter: 329 loss: 2.08470901e-05
Iter: 330 loss: 2.08279525e-05
Iter: 331 loss: 2.08426172e-05
Iter: 332 loss: 2.08163492e-05
Iter: 333 loss: 2.07908415e-05
Iter: 334 loss: 2.08091351e-05
Iter: 335 loss: 2.07748089e-05
Iter: 336 loss: 2.07493758e-05
Iter: 337 loss: 2.1099384e-05
Iter: 338 loss: 2.0749354e-05
Iter: 339 loss: 2.07277099e-05
Iter: 340 loss: 2.06958157e-05
Iter: 341 loss: 2.06950317e-05
Iter: 342 loss: 2.06597397e-05
Iter: 343 loss: 2.0705309e-05
Iter: 344 loss: 2.06419063e-05
Iter: 345 loss: 2.06167933e-05
Iter: 346 loss: 2.06166187e-05
Iter: 347 loss: 2.05913548e-05
Iter: 348 loss: 2.06283021e-05
Iter: 349 loss: 2.05790893e-05
Iter: 350 loss: 2.05588603e-05
Iter: 351 loss: 2.05970537e-05
Iter: 352 loss: 2.05505821e-05
Iter: 353 loss: 2.05242177e-05
Iter: 354 loss: 2.06343248e-05
Iter: 355 loss: 2.05189135e-05
Iter: 356 loss: 2.05020951e-05
Iter: 357 loss: 2.04854696e-05
Iter: 358 loss: 2.04819116e-05
Iter: 359 loss: 2.04561657e-05
Iter: 360 loss: 2.07640423e-05
Iter: 361 loss: 2.04558019e-05
Iter: 362 loss: 2.04341286e-05
Iter: 363 loss: 2.04456555e-05
Iter: 364 loss: 2.04195057e-05
Iter: 365 loss: 2.03966138e-05
Iter: 366 loss: 2.04684711e-05
Iter: 367 loss: 2.03897853e-05
Iter: 368 loss: 2.03677555e-05
Iter: 369 loss: 2.04321623e-05
Iter: 370 loss: 2.03606451e-05
Iter: 371 loss: 2.0336367e-05
Iter: 372 loss: 2.04622083e-05
Iter: 373 loss: 2.03323e-05
Iter: 374 loss: 2.03164909e-05
Iter: 375 loss: 2.02864103e-05
Iter: 376 loss: 2.09412283e-05
Iter: 377 loss: 2.02862393e-05
Iter: 378 loss: 2.02497758e-05
Iter: 379 loss: 2.03899726e-05
Iter: 380 loss: 2.02412684e-05
Iter: 381 loss: 2.02210431e-05
Iter: 382 loss: 2.02188312e-05
Iter: 383 loss: 2.02030824e-05
Iter: 384 loss: 2.0174426e-05
Iter: 385 loss: 2.08650199e-05
Iter: 386 loss: 2.01746079e-05
Iter: 387 loss: 2.01490893e-05
Iter: 388 loss: 2.01489329e-05
Iter: 389 loss: 2.0128633e-05
Iter: 390 loss: 2.01184666e-05
Iter: 391 loss: 2.01086223e-05
Iter: 392 loss: 2.00883169e-05
Iter: 393 loss: 2.01587609e-05
Iter: 394 loss: 2.00829745e-05
Iter: 395 loss: 2.00577924e-05
Iter: 396 loss: 2.01601597e-05
Iter: 397 loss: 2.00524282e-05
Iter: 398 loss: 2.00321774e-05
Iter: 399 loss: 2.00400791e-05
Iter: 400 loss: 2.00179511e-05
Iter: 401 loss: 1.99931783e-05
Iter: 402 loss: 2.01009316e-05
Iter: 403 loss: 1.99883198e-05
Iter: 404 loss: 1.99665465e-05
Iter: 405 loss: 2.00832746e-05
Iter: 406 loss: 1.99632741e-05
Iter: 407 loss: 1.99413189e-05
Iter: 408 loss: 1.99291571e-05
Iter: 409 loss: 1.99192637e-05
Iter: 410 loss: 1.98946909e-05
Iter: 411 loss: 1.99032329e-05
Iter: 412 loss: 1.98773814e-05
Iter: 413 loss: 1.98532034e-05
Iter: 414 loss: 2.02274132e-05
Iter: 415 loss: 1.98532907e-05
Iter: 416 loss: 1.98285816e-05
Iter: 417 loss: 1.98713769e-05
Iter: 418 loss: 1.98176494e-05
Iter: 419 loss: 1.98007092e-05
Iter: 420 loss: 1.98327798e-05
Iter: 421 loss: 1.97931276e-05
Iter: 422 loss: 1.97700156e-05
Iter: 423 loss: 1.98462567e-05
Iter: 424 loss: 1.97636291e-05
Iter: 425 loss: 1.97443878e-05
Iter: 426 loss: 1.97276422e-05
Iter: 427 loss: 1.97225399e-05
Iter: 428 loss: 1.97059271e-05
Iter: 429 loss: 1.97047957e-05
Iter: 430 loss: 1.96896654e-05
Iter: 431 loss: 1.96752808e-05
Iter: 432 loss: 1.96717483e-05
Iter: 433 loss: 1.96463589e-05
Iter: 434 loss: 1.97009031e-05
Iter: 435 loss: 1.96363289e-05
Iter: 436 loss: 1.96101828e-05
Iter: 437 loss: 1.98112393e-05
Iter: 438 loss: 1.96085912e-05
Iter: 439 loss: 1.95894972e-05
Iter: 440 loss: 1.96555702e-05
Iter: 441 loss: 1.95844132e-05
Iter: 442 loss: 1.95673711e-05
Iter: 443 loss: 1.95352986e-05
Iter: 444 loss: 2.02485389e-05
Iter: 445 loss: 1.95353896e-05
Iter: 446 loss: 1.95030952e-05
Iter: 447 loss: 1.97276786e-05
Iter: 448 loss: 1.95000794e-05
Iter: 449 loss: 1.94843524e-05
Iter: 450 loss: 1.9482939e-05
Iter: 451 loss: 1.94724107e-05
Iter: 452 loss: 1.94533786e-05
Iter: 453 loss: 1.99139795e-05
Iter: 454 loss: 1.94533914e-05
Iter: 455 loss: 1.94359309e-05
Iter: 456 loss: 1.97063237e-05
Iter: 457 loss: 1.94357526e-05
Iter: 458 loss: 1.94203876e-05
Iter: 459 loss: 1.93980359e-05
Iter: 460 loss: 1.93973065e-05
Iter: 461 loss: 1.93753604e-05
Iter: 462 loss: 1.95104967e-05
Iter: 463 loss: 1.93724918e-05
Iter: 464 loss: 1.93503274e-05
Iter: 465 loss: 1.947079e-05
Iter: 466 loss: 1.93471496e-05
Iter: 467 loss: 1.93323285e-05
Iter: 468 loss: 1.9325822e-05
Iter: 469 loss: 1.93177802e-05
Iter: 470 loss: 1.92953812e-05
Iter: 471 loss: 1.94163276e-05
Iter: 472 loss: 1.92918396e-05
Iter: 473 loss: 1.92698935e-05
Iter: 474 loss: 1.93419946e-05
Iter: 475 loss: 1.92637308e-05
Iter: 476 loss: 1.92440348e-05
Iter: 477 loss: 1.92668467e-05
Iter: 478 loss: 1.92332427e-05
Iter: 479 loss: 1.92126954e-05
Iter: 480 loss: 1.91902182e-05
Iter: 481 loss: 1.91867202e-05
Iter: 482 loss: 1.91761064e-05
Iter: 483 loss: 1.91701602e-05
Iter: 484 loss: 1.91543095e-05
Iter: 485 loss: 1.91479048e-05
Iter: 486 loss: 1.91394211e-05
Iter: 487 loss: 1.91208183e-05
Iter: 488 loss: 1.91687359e-05
Iter: 489 loss: 1.91142e-05
Iter: 490 loss: 1.9088202e-05
Iter: 491 loss: 1.91501495e-05
Iter: 492 loss: 1.90788596e-05
Iter: 493 loss: 1.90604787e-05
Iter: 494 loss: 1.90650753e-05
Iter: 495 loss: 1.9047382e-05
Iter: 496 loss: 1.90305182e-05
Iter: 497 loss: 1.903054e-05
Iter: 498 loss: 1.90156388e-05
Iter: 499 loss: 1.89928505e-05
Iter: 500 loss: 1.89926122e-05
Iter: 501 loss: 1.89721359e-05
Iter: 502 loss: 1.918208e-05
Iter: 503 loss: 1.89718521e-05
Iter: 504 loss: 1.89557086e-05
Iter: 505 loss: 1.90164155e-05
Iter: 506 loss: 1.89520651e-05
Iter: 507 loss: 1.89346e-05
Iter: 508 loss: 1.89315324e-05
Iter: 509 loss: 1.89195325e-05
Iter: 510 loss: 1.88952909e-05
Iter: 511 loss: 1.89415168e-05
Iter: 512 loss: 1.88846861e-05
Iter: 513 loss: 1.88660342e-05
Iter: 514 loss: 1.89009206e-05
Iter: 515 loss: 1.88577869e-05
Iter: 516 loss: 1.88350605e-05
Iter: 517 loss: 1.90928185e-05
Iter: 518 loss: 1.88346421e-05
Iter: 519 loss: 1.88215708e-05
Iter: 520 loss: 1.88066333e-05
Iter: 521 loss: 1.88046324e-05
Iter: 522 loss: 1.87881033e-05
Iter: 523 loss: 1.87881378e-05
Iter: 524 loss: 1.87756232e-05
Iter: 525 loss: 1.87497317e-05
Iter: 526 loss: 1.92027564e-05
Iter: 527 loss: 1.87491241e-05
Iter: 528 loss: 1.87276619e-05
Iter: 529 loss: 1.90364844e-05
Iter: 530 loss: 1.872754e-05
Iter: 531 loss: 1.87088881e-05
Iter: 532 loss: 1.87665919e-05
Iter: 533 loss: 1.87033838e-05
Iter: 534 loss: 1.86899124e-05
Iter: 535 loss: 1.8679053e-05
Iter: 536 loss: 1.86748348e-05
Iter: 537 loss: 1.8654453e-05
Iter: 538 loss: 1.89055318e-05
Iter: 539 loss: 1.86542729e-05
Iter: 540 loss: 1.86389498e-05
Iter: 541 loss: 1.86631769e-05
Iter: 542 loss: 1.86317175e-05
Iter: 543 loss: 1.86153538e-05
Iter: 544 loss: 1.86215184e-05
Iter: 545 loss: 1.86040852e-05
Iter: 546 loss: 1.85829431e-05
Iter: 547 loss: 1.85952013e-05
Iter: 548 loss: 1.85691424e-05
Iter: 549 loss: 1.85566569e-05
Iter: 550 loss: 1.85547069e-05
Iter: 551 loss: 1.85415956e-05
Iter: 552 loss: 1.85283789e-05
Iter: 553 loss: 1.85256649e-05
Iter: 554 loss: 1.85102253e-05
Iter: 555 loss: 1.86097623e-05
Iter: 556 loss: 1.8508832e-05
Iter: 557 loss: 1.84910605e-05
Iter: 558 loss: 1.85004246e-05
Iter: 559 loss: 1.84795281e-05
Iter: 560 loss: 1.84616347e-05
Iter: 561 loss: 1.84648306e-05
Iter: 562 loss: 1.84484979e-05
Iter: 563 loss: 1.84315577e-05
Iter: 564 loss: 1.84313631e-05
Iter: 565 loss: 1.84194323e-05
Iter: 566 loss: 1.83998072e-05
Iter: 567 loss: 1.83996453e-05
Iter: 568 loss: 1.83812699e-05
Iter: 569 loss: 1.85731533e-05
Iter: 570 loss: 1.83807351e-05
Iter: 571 loss: 1.83643588e-05
Iter: 572 loss: 1.84137079e-05
Iter: 573 loss: 1.83594948e-05
Iter: 574 loss: 1.83444536e-05
Iter: 575 loss: 1.83516568e-05
Iter: 576 loss: 1.83339689e-05
Iter: 577 loss: 1.83141674e-05
Iter: 578 loss: 1.83316079e-05
Iter: 579 loss: 1.83024749e-05
Iter: 580 loss: 1.82826552e-05
Iter: 581 loss: 1.83918601e-05
Iter: 582 loss: 1.82798722e-05
Iter: 583 loss: 1.82598415e-05
Iter: 584 loss: 1.83995326e-05
Iter: 585 loss: 1.82578333e-05
Iter: 586 loss: 1.82465556e-05
Iter: 587 loss: 1.82336826e-05
Iter: 588 loss: 1.82321855e-05
Iter: 589 loss: 1.82143594e-05
Iter: 590 loss: 1.84498167e-05
Iter: 591 loss: 1.82142085e-05
Iter: 592 loss: 1.82013973e-05
Iter: 593 loss: 1.81842079e-05
Iter: 594 loss: 1.81830801e-05
Iter: 595 loss: 1.81677751e-05
Iter: 596 loss: 1.83512366e-05
Iter: 597 loss: 1.8167595e-05
Iter: 598 loss: 1.81497799e-05
Iter: 599 loss: 1.81435425e-05
Iter: 600 loss: 1.81336018e-05
Iter: 601 loss: 1.81146424e-05
Iter: 602 loss: 1.81713258e-05
Iter: 603 loss: 1.81091e-05
Iter: 604 loss: 1.80937241e-05
Iter: 605 loss: 1.82846179e-05
Iter: 606 loss: 1.80937241e-05
Iter: 607 loss: 1.80807183e-05
Iter: 608 loss: 1.80657225e-05
Iter: 609 loss: 1.80640873e-05
Iter: 610 loss: 1.80406278e-05
Iter: 611 loss: 1.81256328e-05
Iter: 612 loss: 1.80346469e-05
Iter: 613 loss: 1.80189272e-05
Iter: 614 loss: 1.80586358e-05
Iter: 615 loss: 1.80134466e-05
Iter: 616 loss: 1.79998e-05
Iter: 617 loss: 1.81882715e-05
Iter: 618 loss: 1.79997787e-05
Iter: 619 loss: 1.79870403e-05
Iter: 620 loss: 1.79607141e-05
Iter: 621 loss: 1.84310775e-05
Iter: 622 loss: 1.79599665e-05
Iter: 623 loss: 1.79464441e-05
Iter: 624 loss: 1.79452636e-05
Iter: 625 loss: 1.79320741e-05
Iter: 626 loss: 1.79250601e-05
Iter: 627 loss: 1.79190447e-05
Iter: 628 loss: 1.79018316e-05
Iter: 629 loss: 1.79152812e-05
Iter: 630 loss: 1.78915761e-05
Iter: 631 loss: 1.78734463e-05
Iter: 632 loss: 1.78738592e-05
Iter: 633 loss: 1.7863591e-05
Iter: 634 loss: 1.78424652e-05
Iter: 635 loss: 1.8222463e-05
Iter: 636 loss: 1.78419414e-05
Iter: 637 loss: 1.78208975e-05
Iter: 638 loss: 1.80920706e-05
Iter: 639 loss: 1.7820521e-05
Iter: 640 loss: 1.78014961e-05
Iter: 641 loss: 1.7836488e-05
Iter: 642 loss: 1.779374e-05
Iter: 643 loss: 1.77779821e-05
Iter: 644 loss: 1.77968104e-05
Iter: 645 loss: 1.77696984e-05
Iter: 646 loss: 1.77503462e-05
Iter: 647 loss: 1.77749116e-05
Iter: 648 loss: 1.77403581e-05
Iter: 649 loss: 1.7723718e-05
Iter: 650 loss: 1.7906983e-05
Iter: 651 loss: 1.77233924e-05
Iter: 652 loss: 1.77070124e-05
Iter: 653 loss: 1.77306301e-05
Iter: 654 loss: 1.76988651e-05
Iter: 655 loss: 1.76865506e-05
Iter: 656 loss: 1.76929716e-05
Iter: 657 loss: 1.76790454e-05
Iter: 658 loss: 1.76611902e-05
Iter: 659 loss: 1.77936854e-05
Iter: 660 loss: 1.76599315e-05
Iter: 661 loss: 1.76481844e-05
Iter: 662 loss: 1.76318408e-05
Iter: 663 loss: 1.76314443e-05
Iter: 664 loss: 1.76164722e-05
Iter: 665 loss: 1.76164394e-05
Iter: 666 loss: 1.76016893e-05
Iter: 667 loss: 1.75899113e-05
Iter: 668 loss: 1.75855912e-05
Iter: 669 loss: 1.75693076e-05
Iter: 670 loss: 1.76144e-05
Iter: 671 loss: 1.75638597e-05
Iter: 672 loss: 1.75451023e-05
Iter: 673 loss: 1.76828471e-05
Iter: 674 loss: 1.75436289e-05
Iter: 675 loss: 1.75294517e-05
Iter: 676 loss: 1.75211699e-05
Iter: 677 loss: 1.75152945e-05
Iter: 678 loss: 1.74958113e-05
Iter: 679 loss: 1.75756122e-05
Iter: 680 loss: 1.74916313e-05
Iter: 681 loss: 1.74747547e-05
Iter: 682 loss: 1.75072182e-05
Iter: 683 loss: 1.74675333e-05
Iter: 684 loss: 1.74507877e-05
Iter: 685 loss: 1.76770191e-05
Iter: 686 loss: 1.74506968e-05
Iter: 687 loss: 1.74399247e-05
Iter: 688 loss: 1.74211473e-05
Iter: 689 loss: 1.74211636e-05
Iter: 690 loss: 1.74059478e-05
Iter: 691 loss: 1.74060478e-05
Iter: 692 loss: 1.73914395e-05
Iter: 693 loss: 1.73749213e-05
Iter: 694 loss: 1.73731787e-05
Iter: 695 loss: 1.73555927e-05
Iter: 696 loss: 1.74515335e-05
Iter: 697 loss: 1.7352897e-05
Iter: 698 loss: 1.73360604e-05
Iter: 699 loss: 1.74526031e-05
Iter: 700 loss: 1.73344633e-05
Iter: 701 loss: 1.73228473e-05
Iter: 702 loss: 1.73015942e-05
Iter: 703 loss: 1.77846268e-05
Iter: 704 loss: 1.73014814e-05
Iter: 705 loss: 1.72920954e-05
Iter: 706 loss: 1.7288683e-05
Iter: 707 loss: 1.7279126e-05
Iter: 708 loss: 1.72719e-05
Iter: 709 loss: 1.72687724e-05
Iter: 710 loss: 1.72536675e-05
Iter: 711 loss: 1.72644886e-05
Iter: 712 loss: 1.72441614e-05
Iter: 713 loss: 1.7223223e-05
Iter: 714 loss: 1.73016488e-05
Iter: 715 loss: 1.72182317e-05
Iter: 716 loss: 1.72051368e-05
Iter: 717 loss: 1.73793487e-05
Iter: 718 loss: 1.72052787e-05
Iter: 719 loss: 1.71927877e-05
Iter: 720 loss: 1.71833599e-05
Iter: 721 loss: 1.7179178e-05
Iter: 722 loss: 1.71632673e-05
Iter: 723 loss: 1.72045293e-05
Iter: 724 loss: 1.71578813e-05
Iter: 725 loss: 1.7139957e-05
Iter: 726 loss: 1.72570144e-05
Iter: 727 loss: 1.71380689e-05
Iter: 728 loss: 1.71269548e-05
Iter: 729 loss: 1.71127067e-05
Iter: 730 loss: 1.7111699e-05
Iter: 731 loss: 1.7097891e-05
Iter: 732 loss: 1.70978274e-05
Iter: 733 loss: 1.70848198e-05
Iter: 734 loss: 1.70668827e-05
Iter: 735 loss: 1.70661751e-05
Iter: 736 loss: 1.70469502e-05
Iter: 737 loss: 1.71423126e-05
Iter: 738 loss: 1.70440744e-05
Iter: 739 loss: 1.70242856e-05
Iter: 740 loss: 1.71572447e-05
Iter: 741 loss: 1.70225248e-05
Iter: 742 loss: 1.70126077e-05
Iter: 743 loss: 1.7005932e-05
Iter: 744 loss: 1.70023031e-05
Iter: 745 loss: 1.69844716e-05
Iter: 746 loss: 1.70182648e-05
Iter: 747 loss: 1.69768391e-05
Iter: 748 loss: 1.69578379e-05
Iter: 749 loss: 1.70723924e-05
Iter: 750 loss: 1.69556442e-05
Iter: 751 loss: 1.69395789e-05
Iter: 752 loss: 1.705264e-05
Iter: 753 loss: 1.69380983e-05
Iter: 754 loss: 1.69275099e-05
Iter: 755 loss: 1.69093819e-05
Iter: 756 loss: 1.69093546e-05
Iter: 757 loss: 1.68936331e-05
Iter: 758 loss: 1.68932347e-05
Iter: 759 loss: 1.68804254e-05
Iter: 760 loss: 1.68642837e-05
Iter: 761 loss: 1.68631395e-05
Iter: 762 loss: 1.68468032e-05
Iter: 763 loss: 1.69459363e-05
Iter: 764 loss: 1.68450169e-05
Iter: 765 loss: 1.68277838e-05
Iter: 766 loss: 1.69048253e-05
Iter: 767 loss: 1.68243478e-05
Iter: 768 loss: 1.68126899e-05
Iter: 769 loss: 1.68022416e-05
Iter: 770 loss: 1.6799162e-05
Iter: 771 loss: 1.6785747e-05
Iter: 772 loss: 1.67855742e-05
Iter: 773 loss: 1.67738599e-05
Iter: 774 loss: 1.67549169e-05
Iter: 775 loss: 1.67548133e-05
Iter: 776 loss: 1.67372891e-05
Iter: 777 loss: 1.68371662e-05
Iter: 778 loss: 1.67347807e-05
Iter: 779 loss: 1.67176295e-05
Iter: 780 loss: 1.67563376e-05
Iter: 781 loss: 1.67111466e-05
Iter: 782 loss: 1.66939099e-05
Iter: 783 loss: 1.6859447e-05
Iter: 784 loss: 1.66933569e-05
Iter: 785 loss: 1.66803529e-05
Iter: 786 loss: 1.66776081e-05
Iter: 787 loss: 1.66693062e-05
Iter: 788 loss: 1.66569462e-05
Iter: 789 loss: 1.67197286e-05
Iter: 790 loss: 1.66546288e-05
Iter: 791 loss: 1.66397294e-05
Iter: 792 loss: 1.66631144e-05
Iter: 793 loss: 1.66328537e-05
Iter: 794 loss: 1.66200734e-05
Iter: 795 loss: 1.66115642e-05
Iter: 796 loss: 1.66068057e-05
Iter: 797 loss: 1.65960919e-05
Iter: 798 loss: 1.65947895e-05
Iter: 799 loss: 1.65852507e-05
Iter: 800 loss: 1.6567772e-05
Iter: 801 loss: 1.6957667e-05
Iter: 802 loss: 1.65677848e-05
Iter: 803 loss: 1.65510901e-05
Iter: 804 loss: 1.66982427e-05
Iter: 805 loss: 1.65500533e-05
Iter: 806 loss: 1.65335114e-05
Iter: 807 loss: 1.65877827e-05
Iter: 808 loss: 1.65289421e-05
Iter: 809 loss: 1.65166202e-05
Iter: 810 loss: 1.65014844e-05
Iter: 811 loss: 1.6500042e-05
Iter: 812 loss: 1.64832891e-05
Iter: 813 loss: 1.67026246e-05
Iter: 814 loss: 1.64831545e-05
Iter: 815 loss: 1.64713783e-05
Iter: 816 loss: 1.65208876e-05
Iter: 817 loss: 1.64687735e-05
Iter: 818 loss: 1.6455193e-05
Iter: 819 loss: 1.64710109e-05
Iter: 820 loss: 1.6447686e-05
Iter: 821 loss: 1.64348021e-05
Iter: 822 loss: 1.64425528e-05
Iter: 823 loss: 1.64266894e-05
Iter: 824 loss: 1.64132762e-05
Iter: 825 loss: 1.65913607e-05
Iter: 826 loss: 1.64131779e-05
Iter: 827 loss: 1.64032081e-05
Iter: 828 loss: 1.63828081e-05
Iter: 829 loss: 1.67529706e-05
Iter: 830 loss: 1.63824661e-05
Iter: 831 loss: 1.63659333e-05
Iter: 832 loss: 1.66254486e-05
Iter: 833 loss: 1.63658551e-05
Iter: 834 loss: 1.63494387e-05
Iter: 835 loss: 1.63691329e-05
Iter: 836 loss: 1.63406967e-05
Iter: 837 loss: 1.63262157e-05
Iter: 838 loss: 1.63202603e-05
Iter: 839 loss: 1.63123659e-05
Iter: 840 loss: 1.62990564e-05
Iter: 841 loss: 1.62980614e-05
Iter: 842 loss: 1.62897468e-05
Iter: 843 loss: 1.62769447e-05
Iter: 844 loss: 1.6276661e-05
Iter: 845 loss: 1.62622528e-05
Iter: 846 loss: 1.63076365e-05
Iter: 847 loss: 1.62580654e-05
Iter: 848 loss: 1.62450233e-05
Iter: 849 loss: 1.63741643e-05
Iter: 850 loss: 1.62445504e-05
Iter: 851 loss: 1.62347878e-05
Iter: 852 loss: 1.62712749e-05
Iter: 853 loss: 1.62323886e-05
Iter: 854 loss: 1.62218039e-05
Iter: 855 loss: 1.62065699e-05
Iter: 856 loss: 1.62060715e-05
Iter: 857 loss: 1.61901953e-05
Iter: 858 loss: 1.63857076e-05
Iter: 859 loss: 1.61900134e-05
Iter: 860 loss: 1.61761818e-05
Iter: 861 loss: 1.61985954e-05
Iter: 862 loss: 1.61701864e-05
Iter: 863 loss: 1.61596308e-05
Iter: 864 loss: 1.61551252e-05
Iter: 865 loss: 1.61497883e-05
Iter: 866 loss: 1.61341613e-05
Iter: 867 loss: 1.63474888e-05
Iter: 868 loss: 1.61341413e-05
Iter: 869 loss: 1.61243661e-05
Iter: 870 loss: 1.61117987e-05
Iter: 871 loss: 1.61106691e-05
Iter: 872 loss: 1.60986583e-05
Iter: 873 loss: 1.62699107e-05
Iter: 874 loss: 1.60985801e-05
Iter: 875 loss: 1.60854161e-05
Iter: 876 loss: 1.60726267e-05
Iter: 877 loss: 1.60698619e-05
Iter: 878 loss: 1.60516138e-05
Iter: 879 loss: 1.60817381e-05
Iter: 880 loss: 1.60433556e-05
Iter: 881 loss: 1.60315321e-05
Iter: 882 loss: 1.6031634e-05
Iter: 883 loss: 1.60222698e-05
Iter: 884 loss: 1.60522941e-05
Iter: 885 loss: 1.60198306e-05
Iter: 886 loss: 1.60094387e-05
Iter: 887 loss: 1.60090131e-05
Iter: 888 loss: 1.60010932e-05
Iter: 889 loss: 1.59888805e-05
Iter: 890 loss: 1.6020811e-05
Iter: 891 loss: 1.5984886e-05
Iter: 892 loss: 1.59717383e-05
Iter: 893 loss: 1.60609761e-05
Iter: 894 loss: 1.59704123e-05
Iter: 895 loss: 1.59604751e-05
Iter: 896 loss: 1.59456849e-05
Iter: 897 loss: 1.59454976e-05
Iter: 898 loss: 1.5936268e-05
Iter: 899 loss: 1.59353949e-05
Iter: 900 loss: 1.59258416e-05
Iter: 901 loss: 1.5913145e-05
Iter: 902 loss: 1.59123447e-05
Iter: 903 loss: 1.58967814e-05
Iter: 904 loss: 1.59461233e-05
Iter: 905 loss: 1.58919356e-05
Iter: 906 loss: 1.58765761e-05
Iter: 907 loss: 1.60483251e-05
Iter: 908 loss: 1.58764578e-05
Iter: 909 loss: 1.58684925e-05
Iter: 910 loss: 1.58529474e-05
Iter: 911 loss: 1.6143842e-05
Iter: 912 loss: 1.58524417e-05
Iter: 913 loss: 1.58333569e-05
Iter: 914 loss: 1.59279844e-05
Iter: 915 loss: 1.58302209e-05
Iter: 916 loss: 1.58159692e-05
Iter: 917 loss: 1.60342879e-05
Iter: 918 loss: 1.58161292e-05
Iter: 919 loss: 1.58067814e-05
Iter: 920 loss: 1.58203147e-05
Iter: 921 loss: 1.58021394e-05
Iter: 922 loss: 1.57927971e-05
Iter: 923 loss: 1.57922859e-05
Iter: 924 loss: 1.57850263e-05
Iter: 925 loss: 1.57740233e-05
Iter: 926 loss: 1.58967814e-05
Iter: 927 loss: 1.57739014e-05
Iter: 928 loss: 1.57641371e-05
Iter: 929 loss: 1.57525028e-05
Iter: 930 loss: 1.57510149e-05
Iter: 931 loss: 1.57360319e-05
Iter: 932 loss: 1.57922477e-05
Iter: 933 loss: 1.57325121e-05
Iter: 934 loss: 1.57171453e-05
Iter: 935 loss: 1.58406e-05
Iter: 936 loss: 1.57157192e-05
Iter: 937 loss: 1.57070099e-05
Iter: 938 loss: 1.56936949e-05
Iter: 939 loss: 1.56934057e-05
Iter: 940 loss: 1.56808164e-05
Iter: 941 loss: 1.568074e-05
Iter: 942 loss: 1.56703609e-05
Iter: 943 loss: 1.56590286e-05
Iter: 944 loss: 1.56576752e-05
Iter: 945 loss: 1.5643207e-05
Iter: 946 loss: 1.56484475e-05
Iter: 947 loss: 1.56332062e-05
Iter: 948 loss: 1.56203059e-05
Iter: 949 loss: 1.56199185e-05
Iter: 950 loss: 1.56089882e-05
Iter: 951 loss: 1.56281112e-05
Iter: 952 loss: 1.56040242e-05
Iter: 953 loss: 1.55928465e-05
Iter: 954 loss: 1.56013775e-05
Iter: 955 loss: 1.55858615e-05
Iter: 956 loss: 1.55735652e-05
Iter: 957 loss: 1.56211609e-05
Iter: 958 loss: 1.55708658e-05
Iter: 959 loss: 1.55575726e-05
Iter: 960 loss: 1.56053e-05
Iter: 961 loss: 1.55545749e-05
Iter: 962 loss: 1.55447324e-05
Iter: 963 loss: 1.55346497e-05
Iter: 964 loss: 1.55326798e-05
Iter: 965 loss: 1.55223e-05
Iter: 966 loss: 1.55218331e-05
Iter: 967 loss: 1.55131129e-05
Iter: 968 loss: 1.55029047e-05
Iter: 969 loss: 1.55017715e-05
Iter: 970 loss: 1.54914615e-05
Iter: 971 loss: 1.55701855e-05
Iter: 972 loss: 1.54905756e-05
Iter: 973 loss: 1.54785321e-05
Iter: 974 loss: 1.54918562e-05
Iter: 975 loss: 1.54723675e-05
Iter: 976 loss: 1.5461168e-05
Iter: 977 loss: 1.54568806e-05
Iter: 978 loss: 1.54509762e-05
Iter: 979 loss: 1.5438236e-05
Iter: 980 loss: 1.55137641e-05
Iter: 981 loss: 1.54364789e-05
Iter: 982 loss: 1.54229674e-05
Iter: 983 loss: 1.55071029e-05
Iter: 984 loss: 1.5421203e-05
Iter: 985 loss: 1.54108784e-05
Iter: 986 loss: 1.5418198e-05
Iter: 987 loss: 1.54043137e-05
Iter: 988 loss: 1.53923647e-05
Iter: 989 loss: 1.54179652e-05
Iter: 990 loss: 1.53875808e-05
Iter: 991 loss: 1.53757337e-05
Iter: 992 loss: 1.54570407e-05
Iter: 993 loss: 1.53746078e-05
Iter: 994 loss: 1.53641486e-05
Iter: 995 loss: 1.53571018e-05
Iter: 996 loss: 1.53534129e-05
Iter: 997 loss: 1.53418423e-05
Iter: 998 loss: 1.5416641e-05
Iter: 999 loss: 1.5340378e-05
Iter: 1000 loss: 1.53273522e-05
Iter: 1001 loss: 1.53571091e-05
Iter: 1002 loss: 1.53223355e-05
Iter: 1003 loss: 1.53115179e-05
Iter: 1004 loss: 1.53075362e-05
Iter: 1005 loss: 1.53016827e-05
Iter: 1006 loss: 1.52918801e-05
Iter: 1007 loss: 1.52912e-05
Iter: 1008 loss: 1.52838547e-05
Iter: 1009 loss: 1.52681441e-05
Iter: 1010 loss: 1.55207308e-05
Iter: 1011 loss: 1.52675202e-05
Iter: 1012 loss: 1.52507228e-05
Iter: 1013 loss: 1.52986831e-05
Iter: 1014 loss: 1.52453722e-05
Iter: 1015 loss: 1.52369958e-05
Iter: 1016 loss: 1.52359571e-05
Iter: 1017 loss: 1.52273369e-05
Iter: 1018 loss: 1.52239427e-05
Iter: 1019 loss: 1.52195989e-05
Iter: 1020 loss: 1.52078665e-05
Iter: 1021 loss: 1.52391895e-05
Iter: 1022 loss: 1.52041976e-05
Iter: 1023 loss: 1.51930544e-05
Iter: 1024 loss: 1.52386801e-05
Iter: 1025 loss: 1.5190757e-05
Iter: 1026 loss: 1.51799277e-05
Iter: 1027 loss: 1.5203449e-05
Iter: 1028 loss: 1.51753957e-05
Iter: 1029 loss: 1.51649101e-05
Iter: 1030 loss: 1.5157525e-05
Iter: 1031 loss: 1.51536242e-05
Iter: 1032 loss: 1.51441682e-05
Iter: 1033 loss: 1.51432923e-05
Iter: 1034 loss: 1.51356398e-05
Iter: 1035 loss: 1.51250379e-05
Iter: 1036 loss: 1.51245022e-05
Iter: 1037 loss: 1.51121849e-05
Iter: 1038 loss: 1.51766671e-05
Iter: 1039 loss: 1.51103541e-05
Iter: 1040 loss: 1.50951573e-05
Iter: 1041 loss: 1.51199038e-05
Iter: 1042 loss: 1.50880924e-05
Iter: 1043 loss: 1.50778205e-05
Iter: 1044 loss: 1.5071515e-05
Iter: 1045 loss: 1.50672395e-05
Iter: 1046 loss: 1.50521146e-05
Iter: 1047 loss: 1.51396425e-05
Iter: 1048 loss: 1.50501019e-05
Iter: 1049 loss: 1.50351243e-05
Iter: 1050 loss: 1.51547911e-05
Iter: 1051 loss: 1.50341248e-05
Iter: 1052 loss: 1.50255237e-05
Iter: 1053 loss: 1.50233927e-05
Iter: 1054 loss: 1.50178703e-05
Iter: 1055 loss: 1.50051546e-05
Iter: 1056 loss: 1.50594078e-05
Iter: 1057 loss: 1.50025971e-05
Iter: 1058 loss: 1.49927209e-05
Iter: 1059 loss: 1.50534615e-05
Iter: 1060 loss: 1.4991424e-05
Iter: 1061 loss: 1.49832676e-05
Iter: 1062 loss: 1.49755933e-05
Iter: 1063 loss: 1.49737443e-05
Iter: 1064 loss: 1.49614725e-05
Iter: 1065 loss: 1.50331907e-05
Iter: 1066 loss: 1.49598463e-05
Iter: 1067 loss: 1.49463567e-05
Iter: 1068 loss: 1.49855396e-05
Iter: 1069 loss: 1.49423395e-05
Iter: 1070 loss: 1.49334819e-05
Iter: 1071 loss: 1.49369707e-05
Iter: 1072 loss: 1.4927261e-05
Iter: 1073 loss: 1.4917985e-05
Iter: 1074 loss: 1.50511969e-05
Iter: 1075 loss: 1.49179414e-05
Iter: 1076 loss: 1.49101134e-05
Iter: 1077 loss: 1.48912695e-05
Iter: 1078 loss: 1.51131762e-05
Iter: 1079 loss: 1.48898653e-05
Iter: 1080 loss: 1.48738927e-05
Iter: 1081 loss: 1.49812122e-05
Iter: 1082 loss: 1.48723138e-05
Iter: 1083 loss: 1.48612726e-05
Iter: 1084 loss: 1.48613526e-05
Iter: 1085 loss: 1.48513172e-05
Iter: 1086 loss: 1.48411691e-05
Iter: 1087 loss: 1.48394656e-05
Iter: 1088 loss: 1.48274403e-05
Iter: 1089 loss: 1.49193947e-05
Iter: 1090 loss: 1.48262716e-05
Iter: 1091 loss: 1.48163281e-05
Iter: 1092 loss: 1.48370018e-05
Iter: 1093 loss: 1.48120071e-05
Iter: 1094 loss: 1.48003282e-05
Iter: 1095 loss: 1.48310683e-05
Iter: 1096 loss: 1.4796422e-05
Iter: 1097 loss: 1.4787066e-05
Iter: 1098 loss: 1.47893752e-05
Iter: 1099 loss: 1.47802402e-05
Iter: 1100 loss: 1.476946e-05
Iter: 1101 loss: 1.49249163e-05
Iter: 1102 loss: 1.47695764e-05
Iter: 1103 loss: 1.47614874e-05
Iter: 1104 loss: 1.47483897e-05
Iter: 1105 loss: 1.4748437e-05
Iter: 1106 loss: 1.47379942e-05
Iter: 1107 loss: 1.47380761e-05
Iter: 1108 loss: 1.47288e-05
Iter: 1109 loss: 1.47348383e-05
Iter: 1110 loss: 1.47226456e-05
Iter: 1111 loss: 1.47136761e-05
Iter: 1112 loss: 1.47039373e-05
Iter: 1113 loss: 1.47023675e-05
Iter: 1114 loss: 1.4691821e-05
Iter: 1115 loss: 1.469166e-05
Iter: 1116 loss: 1.46806633e-05
Iter: 1117 loss: 1.46977709e-05
Iter: 1118 loss: 1.46751845e-05
Iter: 1119 loss: 1.46657367e-05
Iter: 1120 loss: 1.46754592e-05
Iter: 1121 loss: 1.46604389e-05
Iter: 1122 loss: 1.46507264e-05
Iter: 1123 loss: 1.47306846e-05
Iter: 1124 loss: 1.46498669e-05
Iter: 1125 loss: 1.46424363e-05
Iter: 1126 loss: 1.4650559e-05
Iter: 1127 loss: 1.46382072e-05
Iter: 1128 loss: 1.46276216e-05
Iter: 1129 loss: 1.46249404e-05
Iter: 1130 loss: 1.46180791e-05
Iter: 1131 loss: 1.46068032e-05
Iter: 1132 loss: 1.47289156e-05
Iter: 1133 loss: 1.46065904e-05
Iter: 1134 loss: 1.45953354e-05
Iter: 1135 loss: 1.46019629e-05
Iter: 1136 loss: 1.45881886e-05
Iter: 1137 loss: 1.45774602e-05
Iter: 1138 loss: 1.45835711e-05
Iter: 1139 loss: 1.45709009e-05
Iter: 1140 loss: 1.45563154e-05
Iter: 1141 loss: 1.46944503e-05
Iter: 1142 loss: 1.45559625e-05
Iter: 1143 loss: 1.45473896e-05
Iter: 1144 loss: 1.45381055e-05
Iter: 1145 loss: 1.45365266e-05
Iter: 1146 loss: 1.45240592e-05
Iter: 1147 loss: 1.45396471e-05
Iter: 1148 loss: 1.45172598e-05
Iter: 1149 loss: 1.45092772e-05
Iter: 1150 loss: 1.45079102e-05
Iter: 1151 loss: 1.45020203e-05
Iter: 1152 loss: 1.44936221e-05
Iter: 1153 loss: 1.44934456e-05
Iter: 1154 loss: 1.44837904e-05
Iter: 1155 loss: 1.45436625e-05
Iter: 1156 loss: 1.44826963e-05
Iter: 1157 loss: 1.44730475e-05
Iter: 1158 loss: 1.44902897e-05
Iter: 1159 loss: 1.44689739e-05
Iter: 1160 loss: 1.44594915e-05
Iter: 1161 loss: 1.44883807e-05
Iter: 1162 loss: 1.44566338e-05
Iter: 1163 loss: 1.44478481e-05
Iter: 1164 loss: 1.44527075e-05
Iter: 1165 loss: 1.4442162e-05
Iter: 1166 loss: 1.44311389e-05
Iter: 1167 loss: 1.45336771e-05
Iter: 1168 loss: 1.44304095e-05
Iter: 1169 loss: 1.4422013e-05
Iter: 1170 loss: 1.44093583e-05
Iter: 1171 loss: 1.44090791e-05
Iter: 1172 loss: 1.44004853e-05
Iter: 1173 loss: 1.44000433e-05
Iter: 1174 loss: 1.43914876e-05
Iter: 1175 loss: 1.43820071e-05
Iter: 1176 loss: 1.4380701e-05
Iter: 1177 loss: 1.4367808e-05
Iter: 1178 loss: 1.43701482e-05
Iter: 1179 loss: 1.43581974e-05
Iter: 1180 loss: 1.43505076e-05
Iter: 1181 loss: 1.43493298e-05
Iter: 1182 loss: 1.43407206e-05
Iter: 1183 loss: 1.43444868e-05
Iter: 1184 loss: 1.43349735e-05
Iter: 1185 loss: 1.43262851e-05
Iter: 1186 loss: 1.43277812e-05
Iter: 1187 loss: 1.43198804e-05
Iter: 1188 loss: 1.43069028e-05
Iter: 1189 loss: 1.4390801e-05
Iter: 1190 loss: 1.43053212e-05
Iter: 1191 loss: 1.42952558e-05
Iter: 1192 loss: 1.43123943e-05
Iter: 1193 loss: 1.42907447e-05
Iter: 1194 loss: 1.42807e-05
Iter: 1195 loss: 1.43026773e-05
Iter: 1196 loss: 1.42768158e-05
Iter: 1197 loss: 1.42677236e-05
Iter: 1198 loss: 1.43182324e-05
Iter: 1199 loss: 1.42665067e-05
Iter: 1200 loss: 1.42561648e-05
Iter: 1201 loss: 1.4255882e-05
Iter: 1202 loss: 1.42475201e-05
Iter: 1203 loss: 1.42370045e-05
Iter: 1204 loss: 1.42656645e-05
Iter: 1205 loss: 1.42332929e-05
Iter: 1206 loss: 1.42221561e-05
Iter: 1207 loss: 1.43152374e-05
Iter: 1208 loss: 1.42212475e-05
Iter: 1209 loss: 1.42139907e-05
Iter: 1210 loss: 1.41983946e-05
Iter: 1211 loss: 1.44489177e-05
Iter: 1212 loss: 1.4197919e-05
Iter: 1213 loss: 1.41822175e-05
Iter: 1214 loss: 1.43034304e-05
Iter: 1215 loss: 1.41811743e-05
Iter: 1216 loss: 1.41726805e-05
Iter: 1217 loss: 1.41721293e-05
Iter: 1218 loss: 1.41667169e-05
Iter: 1219 loss: 1.41532728e-05
Iter: 1220 loss: 1.42987319e-05
Iter: 1221 loss: 1.41519367e-05
Iter: 1222 loss: 1.41394912e-05
Iter: 1223 loss: 1.41395058e-05
Iter: 1224 loss: 1.41297987e-05
Iter: 1225 loss: 1.41435657e-05
Iter: 1226 loss: 1.41248474e-05
Iter: 1227 loss: 1.41143946e-05
Iter: 1228 loss: 1.4128942e-05
Iter: 1229 loss: 1.41092987e-05
Iter: 1230 loss: 1.40967168e-05
Iter: 1231 loss: 1.41276669e-05
Iter: 1232 loss: 1.40924094e-05
Iter: 1233 loss: 1.40814154e-05
Iter: 1234 loss: 1.42012168e-05
Iter: 1235 loss: 1.40811735e-05
Iter: 1236 loss: 1.40748853e-05
Iter: 1237 loss: 1.40654438e-05
Iter: 1238 loss: 1.40650027e-05
Iter: 1239 loss: 1.40557386e-05
Iter: 1240 loss: 1.40556613e-05
Iter: 1241 loss: 1.40476195e-05
Iter: 1242 loss: 1.40419288e-05
Iter: 1243 loss: 1.40390239e-05
Iter: 1244 loss: 1.40294342e-05
Iter: 1245 loss: 1.40234979e-05
Iter: 1246 loss: 1.40194852e-05
Iter: 1247 loss: 1.40085476e-05
Iter: 1248 loss: 1.4008132e-05
Iter: 1249 loss: 1.39968779e-05
Iter: 1250 loss: 1.3995179e-05
Iter: 1251 loss: 1.39875465e-05
Iter: 1252 loss: 1.39780223e-05
Iter: 1253 loss: 1.40011889e-05
Iter: 1254 loss: 1.39745343e-05
Iter: 1255 loss: 1.39635604e-05
Iter: 1256 loss: 1.40323646e-05
Iter: 1257 loss: 1.39624e-05
Iter: 1258 loss: 1.39538115e-05
Iter: 1259 loss: 1.39562289e-05
Iter: 1260 loss: 1.39478398e-05
Iter: 1261 loss: 1.39376471e-05
Iter: 1262 loss: 1.39851691e-05
Iter: 1263 loss: 1.39358754e-05
Iter: 1264 loss: 1.3928031e-05
Iter: 1265 loss: 1.39696513e-05
Iter: 1266 loss: 1.39269159e-05
Iter: 1267 loss: 1.39181993e-05
Iter: 1268 loss: 1.3912846e-05
Iter: 1269 loss: 1.39091981e-05
Iter: 1270 loss: 1.38993528e-05
Iter: 1271 loss: 1.39501262e-05
Iter: 1272 loss: 1.38978667e-05
Iter: 1273 loss: 1.38868236e-05
Iter: 1274 loss: 1.39193489e-05
Iter: 1275 loss: 1.38832038e-05
Iter: 1276 loss: 1.38744372e-05
Iter: 1277 loss: 1.38666373e-05
Iter: 1278 loss: 1.38644218e-05
Iter: 1279 loss: 1.38536643e-05
Iter: 1280 loss: 1.39176209e-05
Iter: 1281 loss: 1.38522755e-05
Iter: 1282 loss: 1.38407786e-05
Iter: 1283 loss: 1.39252934e-05
Iter: 1284 loss: 1.38398409e-05
Iter: 1285 loss: 1.38324103e-05
Iter: 1286 loss: 1.38206779e-05
Iter: 1287 loss: 1.38204359e-05
Iter: 1288 loss: 1.38115947e-05
Iter: 1289 loss: 1.38113928e-05
Iter: 1290 loss: 1.3803432e-05
Iter: 1291 loss: 1.37991783e-05
Iter: 1292 loss: 1.37954885e-05
Iter: 1293 loss: 1.37840425e-05
Iter: 1294 loss: 1.3820194e-05
Iter: 1295 loss: 1.3780882e-05
Iter: 1296 loss: 1.37699335e-05
Iter: 1297 loss: 1.38202377e-05
Iter: 1298 loss: 1.37682637e-05
Iter: 1299 loss: 1.3758483e-05
Iter: 1300 loss: 1.38013274e-05
Iter: 1301 loss: 1.37568641e-05
Iter: 1302 loss: 1.37491e-05
Iter: 1303 loss: 1.37425368e-05
Iter: 1304 loss: 1.37406842e-05
Iter: 1305 loss: 1.37332972e-05
Iter: 1306 loss: 1.37332563e-05
Iter: 1307 loss: 1.3726868e-05
Iter: 1308 loss: 1.37158077e-05
Iter: 1309 loss: 1.37157e-05
Iter: 1310 loss: 1.37036022e-05
Iter: 1311 loss: 1.37148263e-05
Iter: 1312 loss: 1.36964463e-05
Iter: 1313 loss: 1.36909475e-05
Iter: 1314 loss: 1.36887675e-05
Iter: 1315 loss: 1.36817625e-05
Iter: 1316 loss: 1.36715316e-05
Iter: 1317 loss: 1.36713106e-05
Iter: 1318 loss: 1.3660786e-05
Iter: 1319 loss: 1.36911558e-05
Iter: 1320 loss: 1.36577246e-05
Iter: 1321 loss: 1.36455274e-05
Iter: 1322 loss: 1.37263e-05
Iter: 1323 loss: 1.36444733e-05
Iter: 1324 loss: 1.36359649e-05
Iter: 1325 loss: 1.36347699e-05
Iter: 1326 loss: 1.36291701e-05
Iter: 1327 loss: 1.36188828e-05
Iter: 1328 loss: 1.3690792e-05
Iter: 1329 loss: 1.3617695e-05
Iter: 1330 loss: 1.36094877e-05
Iter: 1331 loss: 1.36392191e-05
Iter: 1332 loss: 1.36074841e-05
Iter: 1333 loss: 1.35987229e-05
Iter: 1334 loss: 1.36029348e-05
Iter: 1335 loss: 1.35927767e-05
Iter: 1336 loss: 1.3582965e-05
Iter: 1337 loss: 1.36045837e-05
Iter: 1338 loss: 1.35791224e-05
Iter: 1339 loss: 1.3566193e-05
Iter: 1340 loss: 1.36241979e-05
Iter: 1341 loss: 1.35633964e-05
Iter: 1342 loss: 1.35556584e-05
Iter: 1343 loss: 1.35464188e-05
Iter: 1344 loss: 1.3545412e-05
Iter: 1345 loss: 1.35334558e-05
Iter: 1346 loss: 1.361865e-05
Iter: 1347 loss: 1.35325436e-05
Iter: 1348 loss: 1.35215796e-05
Iter: 1349 loss: 1.36141198e-05
Iter: 1350 loss: 1.35208202e-05
Iter: 1351 loss: 1.35155369e-05
Iter: 1352 loss: 1.35058308e-05
Iter: 1353 loss: 1.37312036e-05
Iter: 1354 loss: 1.35057599e-05
Iter: 1355 loss: 1.34968159e-05
Iter: 1356 loss: 1.34969405e-05
Iter: 1357 loss: 1.34889069e-05
Iter: 1358 loss: 1.34850516e-05
Iter: 1359 loss: 1.34811944e-05
Iter: 1360 loss: 1.34711381e-05
Iter: 1361 loss: 1.35037599e-05
Iter: 1362 loss: 1.34684306e-05
Iter: 1363 loss: 1.34577367e-05
Iter: 1364 loss: 1.3511074e-05
Iter: 1365 loss: 1.3456096e-05
Iter: 1366 loss: 1.34470938e-05
Iter: 1367 loss: 1.34735155e-05
Iter: 1368 loss: 1.34444936e-05
Iter: 1369 loss: 1.34362681e-05
Iter: 1370 loss: 1.34346337e-05
Iter: 1371 loss: 1.34290667e-05
Iter: 1372 loss: 1.34191678e-05
Iter: 1373 loss: 1.35439959e-05
Iter: 1374 loss: 1.34189622e-05
Iter: 1375 loss: 1.34108632e-05
Iter: 1376 loss: 1.34014244e-05
Iter: 1377 loss: 1.34004813e-05
Iter: 1378 loss: 1.33903231e-05
Iter: 1379 loss: 1.34206775e-05
Iter: 1380 loss: 1.33875146e-05
Iter: 1381 loss: 1.33806616e-05
Iter: 1382 loss: 1.33805825e-05
Iter: 1383 loss: 1.33739077e-05
Iter: 1384 loss: 1.33622325e-05
Iter: 1385 loss: 1.36493582e-05
Iter: 1386 loss: 1.33621061e-05
Iter: 1387 loss: 1.33539397e-05
Iter: 1388 loss: 1.34128059e-05
Iter: 1389 loss: 1.33528765e-05
Iter: 1390 loss: 1.33432859e-05
Iter: 1391 loss: 1.33632784e-05
Iter: 1392 loss: 1.33393514e-05
Iter: 1393 loss: 1.333004e-05
Iter: 1394 loss: 1.33318736e-05
Iter: 1395 loss: 1.3322926e-05
Iter: 1396 loss: 1.33131489e-05
Iter: 1397 loss: 1.3425024e-05
Iter: 1398 loss: 1.33130943e-05
Iter: 1399 loss: 1.33050098e-05
Iter: 1400 loss: 1.33140329e-05
Iter: 1401 loss: 1.3300516e-05
Iter: 1402 loss: 1.32910245e-05
Iter: 1403 loss: 1.33123394e-05
Iter: 1404 loss: 1.32871774e-05
Iter: 1405 loss: 1.32798414e-05
Iter: 1406 loss: 1.33166186e-05
Iter: 1407 loss: 1.32785026e-05
Iter: 1408 loss: 1.32700534e-05
Iter: 1409 loss: 1.32766299e-05
Iter: 1410 loss: 1.32650348e-05
Iter: 1411 loss: 1.32557152e-05
Iter: 1412 loss: 1.32494024e-05
Iter: 1413 loss: 1.32458954e-05
Iter: 1414 loss: 1.32381383e-05
Iter: 1415 loss: 1.3238051e-05
Iter: 1416 loss: 1.32295863e-05
Iter: 1417 loss: 1.32394371e-05
Iter: 1418 loss: 1.32252517e-05
Iter: 1419 loss: 1.32172572e-05
Iter: 1420 loss: 1.32090663e-05
Iter: 1421 loss: 1.32074501e-05
Iter: 1422 loss: 1.32026689e-05
Iter: 1423 loss: 1.32008654e-05
Iter: 1424 loss: 1.31956967e-05
Iter: 1425 loss: 1.31857378e-05
Iter: 1426 loss: 1.34055599e-05
Iter: 1427 loss: 1.3185776e-05
Iter: 1428 loss: 1.31759789e-05
Iter: 1429 loss: 1.3259556e-05
Iter: 1430 loss: 1.31753595e-05
Iter: 1431 loss: 1.31670276e-05
Iter: 1432 loss: 1.3199382e-05
Iter: 1433 loss: 1.31650022e-05
Iter: 1434 loss: 1.31575307e-05
Iter: 1435 loss: 1.31679808e-05
Iter: 1436 loss: 1.31536644e-05
Iter: 1437 loss: 1.31450006e-05
Iter: 1438 loss: 1.31579654e-05
Iter: 1439 loss: 1.31408042e-05
Iter: 1440 loss: 1.31316538e-05
Iter: 1441 loss: 1.32080595e-05
Iter: 1442 loss: 1.3131058e-05
Iter: 1443 loss: 1.3123913e-05
Iter: 1444 loss: 1.31120978e-05
Iter: 1445 loss: 1.31120214e-05
Iter: 1446 loss: 1.31000379e-05
Iter: 1447 loss: 1.31525194e-05
Iter: 1448 loss: 1.30975195e-05
Iter: 1449 loss: 1.30904446e-05
Iter: 1450 loss: 1.30899634e-05
Iter: 1451 loss: 1.30848393e-05
Iter: 1452 loss: 1.30734425e-05
Iter: 1453 loss: 1.32395253e-05
Iter: 1454 loss: 1.30730332e-05
Iter: 1455 loss: 1.30627323e-05
Iter: 1456 loss: 1.3148845e-05
Iter: 1457 loss: 1.30619846e-05
Iter: 1458 loss: 1.30520511e-05
Iter: 1459 loss: 1.30966473e-05
Iter: 1460 loss: 1.30501294e-05
Iter: 1461 loss: 1.30432181e-05
Iter: 1462 loss: 1.30351655e-05
Iter: 1463 loss: 1.30340413e-05
Iter: 1464 loss: 1.30232456e-05
Iter: 1465 loss: 1.31795305e-05
Iter: 1466 loss: 1.30230101e-05
Iter: 1467 loss: 1.30148946e-05
Iter: 1468 loss: 1.30203925e-05
Iter: 1469 loss: 1.30099979e-05
Iter: 1470 loss: 1.300039e-05
Iter: 1471 loss: 1.30282633e-05
Iter: 1472 loss: 1.29975551e-05
Iter: 1473 loss: 1.29884938e-05
Iter: 1474 loss: 1.30214685e-05
Iter: 1475 loss: 1.29864147e-05
Iter: 1476 loss: 1.29765385e-05
Iter: 1477 loss: 1.29898726e-05
Iter: 1478 loss: 1.29715409e-05
Iter: 1479 loss: 1.29631926e-05
Iter: 1480 loss: 1.29608543e-05
Iter: 1481 loss: 1.29557111e-05
Iter: 1482 loss: 1.29486343e-05
Iter: 1483 loss: 1.29482851e-05
Iter: 1484 loss: 1.29407699e-05
Iter: 1485 loss: 1.29398668e-05
Iter: 1486 loss: 1.29339405e-05
Iter: 1487 loss: 1.2926319e-05
Iter: 1488 loss: 1.29259333e-05
Iter: 1489 loss: 1.29201026e-05
Iter: 1490 loss: 1.29113751e-05
Iter: 1491 loss: 1.30487979e-05
Iter: 1492 loss: 1.29112268e-05
Iter: 1493 loss: 1.29031241e-05
Iter: 1494 loss: 1.28923139e-05
Iter: 1495 loss: 1.28916181e-05
Iter: 1496 loss: 1.28814954e-05
Iter: 1497 loss: 1.29639e-05
Iter: 1498 loss: 1.28805659e-05
Iter: 1499 loss: 1.28695629e-05
Iter: 1500 loss: 1.28960346e-05
Iter: 1501 loss: 1.28656375e-05
Iter: 1502 loss: 1.28561915e-05
Iter: 1503 loss: 1.28766151e-05
Iter: 1504 loss: 1.28521206e-05
Iter: 1505 loss: 1.28431784e-05
Iter: 1506 loss: 1.2881399e-05
Iter: 1507 loss: 1.28411193e-05
Iter: 1508 loss: 1.28336451e-05
Iter: 1509 loss: 1.28716547e-05
Iter: 1510 loss: 1.28326374e-05
Iter: 1511 loss: 1.28256888e-05
Iter: 1512 loss: 1.28163765e-05
Iter: 1513 loss: 1.28160555e-05
Iter: 1514 loss: 1.28044558e-05
Iter: 1515 loss: 1.28427364e-05
Iter: 1516 loss: 1.28013744e-05
Iter: 1517 loss: 1.27944058e-05
Iter: 1518 loss: 1.27936437e-05
Iter: 1519 loss: 1.2788727e-05
Iter: 1520 loss: 1.27762869e-05
Iter: 1521 loss: 1.28798993e-05
Iter: 1522 loss: 1.27740695e-05
Iter: 1523 loss: 1.27627954e-05
Iter: 1524 loss: 1.29128457e-05
Iter: 1525 loss: 1.27627081e-05
Iter: 1526 loss: 1.27536423e-05
Iter: 1527 loss: 1.2807438e-05
Iter: 1528 loss: 1.27521653e-05
Iter: 1529 loss: 1.27460225e-05
Iter: 1530 loss: 1.27379708e-05
Iter: 1531 loss: 1.27374387e-05
Iter: 1532 loss: 1.27294516e-05
Iter: 1533 loss: 1.27294843e-05
Iter: 1534 loss: 1.27226913e-05
Iter: 1535 loss: 1.27164385e-05
Iter: 1536 loss: 1.27148778e-05
Iter: 1537 loss: 1.27048352e-05
Iter: 1538 loss: 1.27735411e-05
Iter: 1539 loss: 1.27039357e-05
Iter: 1540 loss: 1.26969062e-05
Iter: 1541 loss: 1.2723538e-05
Iter: 1542 loss: 1.26953155e-05
Iter: 1543 loss: 1.26880341e-05
Iter: 1544 loss: 1.26922987e-05
Iter: 1545 loss: 1.26831501e-05
Iter: 1546 loss: 1.2674529e-05
Iter: 1547 loss: 1.26729265e-05
Iter: 1548 loss: 1.26671466e-05
Iter: 1549 loss: 1.2660269e-05
Iter: 1550 loss: 1.26600471e-05
Iter: 1551 loss: 1.26527248e-05
Iter: 1552 loss: 1.26540626e-05
Iter: 1553 loss: 1.26472514e-05
Iter: 1554 loss: 1.26393152e-05
Iter: 1555 loss: 1.2629449e-05
Iter: 1556 loss: 1.26286486e-05
Iter: 1557 loss: 1.26208561e-05
Iter: 1558 loss: 1.26198538e-05
Iter: 1559 loss: 1.26126833e-05
Iter: 1560 loss: 1.26055065e-05
Iter: 1561 loss: 1.26041341e-05
Iter: 1562 loss: 1.25947408e-05
Iter: 1563 loss: 1.2639659e-05
Iter: 1564 loss: 1.25931856e-05
Iter: 1565 loss: 1.25835923e-05
Iter: 1566 loss: 1.26368977e-05
Iter: 1567 loss: 1.25822489e-05
Iter: 1568 loss: 1.25761544e-05
Iter: 1569 loss: 1.25780125e-05
Iter: 1570 loss: 1.25717088e-05
Iter: 1571 loss: 1.25632005e-05
Iter: 1572 loss: 1.26044661e-05
Iter: 1573 loss: 1.25617134e-05
Iter: 1574 loss: 1.25547249e-05
Iter: 1575 loss: 1.25781007e-05
Iter: 1576 loss: 1.2552644e-05
Iter: 1577 loss: 1.2545891e-05
Iter: 1578 loss: 1.25437182e-05
Iter: 1579 loss: 1.2539771e-05
Iter: 1580 loss: 1.25296856e-05
Iter: 1581 loss: 1.25341885e-05
Iter: 1582 loss: 1.25230526e-05
Iter: 1583 loss: 1.2515331e-05
Iter: 1584 loss: 1.25142687e-05
Iter: 1585 loss: 1.25092101e-05
Iter: 1586 loss: 1.25009346e-05
Iter: 1587 loss: 1.25008946e-05
Iter: 1588 loss: 1.24932376e-05
Iter: 1589 loss: 1.25249435e-05
Iter: 1590 loss: 1.24913295e-05
Iter: 1591 loss: 1.24812077e-05
Iter: 1592 loss: 1.2519723e-05
Iter: 1593 loss: 1.24790504e-05
Iter: 1594 loss: 1.2471477e-05
Iter: 1595 loss: 1.2468663e-05
Iter: 1596 loss: 1.2464483e-05
Iter: 1597 loss: 1.24582439e-05
Iter: 1598 loss: 1.24581602e-05
Iter: 1599 loss: 1.24526441e-05
Iter: 1600 loss: 1.24465005e-05
Iter: 1601 loss: 1.24455073e-05
Iter: 1602 loss: 1.24374583e-05
Iter: 1603 loss: 1.24853905e-05
Iter: 1604 loss: 1.24364178e-05
Iter: 1605 loss: 1.2428256e-05
Iter: 1606 loss: 1.24420876e-05
Iter: 1607 loss: 1.24242706e-05
Iter: 1608 loss: 1.24152684e-05
Iter: 1609 loss: 1.24365542e-05
Iter: 1610 loss: 1.24118415e-05
Iter: 1611 loss: 1.24036815e-05
Iter: 1612 loss: 1.24115049e-05
Iter: 1613 loss: 1.23990449e-05
Iter: 1614 loss: 1.23922455e-05
Iter: 1615 loss: 1.2454082e-05
Iter: 1616 loss: 1.23921182e-05
Iter: 1617 loss: 1.2383689e-05
Iter: 1618 loss: 1.23792415e-05
Iter: 1619 loss: 1.23752361e-05
Iter: 1620 loss: 1.23661466e-05
Iter: 1621 loss: 1.23754717e-05
Iter: 1622 loss: 1.23609789e-05
Iter: 1623 loss: 1.23552363e-05
Iter: 1624 loss: 1.23548562e-05
Iter: 1625 loss: 1.23495083e-05
Iter: 1626 loss: 1.23404143e-05
Iter: 1627 loss: 1.23403051e-05
Iter: 1628 loss: 1.23295795e-05
Iter: 1629 loss: 1.23742157e-05
Iter: 1630 loss: 1.23272057e-05
Iter: 1631 loss: 1.23183308e-05
Iter: 1632 loss: 1.24287944e-05
Iter: 1633 loss: 1.23181962e-05
Iter: 1634 loss: 1.23135924e-05
Iter: 1635 loss: 1.23076716e-05
Iter: 1636 loss: 1.2307386e-05
Iter: 1637 loss: 1.22987367e-05
Iter: 1638 loss: 1.23754862e-05
Iter: 1639 loss: 1.2298342e-05
Iter: 1640 loss: 1.22918791e-05
Iter: 1641 loss: 1.22980155e-05
Iter: 1642 loss: 1.22882575e-05
Iter: 1643 loss: 1.22804213e-05
Iter: 1644 loss: 1.22904748e-05
Iter: 1645 loss: 1.22764641e-05
Iter: 1646 loss: 1.22679548e-05
Iter: 1647 loss: 1.22779584e-05
Iter: 1648 loss: 1.22632982e-05
Iter: 1649 loss: 1.2257321e-05
Iter: 1650 loss: 1.22568035e-05
Iter: 1651 loss: 1.2252578e-05
Iter: 1652 loss: 1.22426318e-05
Iter: 1653 loss: 1.2371449e-05
Iter: 1654 loss: 1.22419442e-05
Iter: 1655 loss: 1.22324172e-05
Iter: 1656 loss: 1.22903248e-05
Iter: 1657 loss: 1.22309757e-05
Iter: 1658 loss: 1.22214624e-05
Iter: 1659 loss: 1.22954389e-05
Iter: 1660 loss: 1.2220622e-05
Iter: 1661 loss: 1.22150377e-05
Iter: 1662 loss: 1.22070924e-05
Iter: 1663 loss: 1.22067649e-05
Iter: 1664 loss: 1.22004922e-05
Iter: 1665 loss: 1.22001729e-05
Iter: 1666 loss: 1.21948051e-05
Iter: 1667 loss: 1.21929606e-05
Iter: 1668 loss: 1.21900939e-05
Iter: 1669 loss: 1.21838184e-05
Iter: 1670 loss: 1.22035581e-05
Iter: 1671 loss: 1.21820631e-05
Iter: 1672 loss: 1.21738703e-05
Iter: 1673 loss: 1.2189631e-05
Iter: 1674 loss: 1.21703324e-05
Iter: 1675 loss: 1.21624144e-05
Iter: 1676 loss: 1.2175833e-05
Iter: 1677 loss: 1.21587564e-05
Iter: 1678 loss: 1.21499334e-05
Iter: 1679 loss: 1.21642579e-05
Iter: 1680 loss: 1.21459234e-05
Iter: 1681 loss: 1.21376142e-05
Iter: 1682 loss: 1.21931052e-05
Iter: 1683 loss: 1.21370067e-05
Iter: 1684 loss: 1.21272133e-05
Iter: 1685 loss: 1.21338107e-05
Iter: 1686 loss: 1.21209032e-05
Iter: 1687 loss: 1.21134972e-05
Iter: 1688 loss: 1.21144749e-05
Iter: 1689 loss: 1.21079156e-05
Iter: 1690 loss: 1.21018938e-05
Iter: 1691 loss: 1.21017993e-05
Iter: 1692 loss: 1.2095813e-05
Iter: 1693 loss: 1.2088447e-05
Iter: 1694 loss: 1.20878012e-05
Iter: 1695 loss: 1.20803616e-05
Iter: 1696 loss: 1.21190606e-05
Iter: 1697 loss: 1.20790028e-05
Iter: 1698 loss: 1.20706491e-05
Iter: 1699 loss: 1.21068933e-05
Iter: 1700 loss: 1.20686618e-05
Iter: 1701 loss: 1.20622663e-05
Iter: 1702 loss: 1.2058581e-05
Iter: 1703 loss: 1.20556342e-05
Iter: 1704 loss: 1.20479453e-05
Iter: 1705 loss: 1.2162749e-05
Iter: 1706 loss: 1.20482009e-05
Iter: 1707 loss: 1.2042291e-05
Iter: 1708 loss: 1.20389559e-05
Iter: 1709 loss: 1.2036382e-05
Iter: 1710 loss: 1.20280183e-05
Iter: 1711 loss: 1.20574323e-05
Iter: 1712 loss: 1.20257255e-05
Iter: 1713 loss: 1.20181066e-05
Iter: 1714 loss: 1.20375253e-05
Iter: 1715 loss: 1.20154109e-05
Iter: 1716 loss: 1.20088625e-05
Iter: 1717 loss: 1.20931127e-05
Iter: 1718 loss: 1.20088989e-05
Iter: 1719 loss: 1.2003984e-05
Iter: 1720 loss: 1.19933866e-05
Iter: 1721 loss: 1.21629455e-05
Iter: 1722 loss: 1.19931228e-05
Iter: 1723 loss: 1.19831875e-05
Iter: 1724 loss: 1.20345667e-05
Iter: 1725 loss: 1.19815486e-05
Iter: 1726 loss: 1.19708484e-05
Iter: 1727 loss: 1.20482509e-05
Iter: 1728 loss: 1.1970089e-05
Iter: 1729 loss: 1.1963306e-05
Iter: 1730 loss: 1.19596771e-05
Iter: 1731 loss: 1.19568695e-05
Iter: 1732 loss: 1.19514716e-05
Iter: 1733 loss: 1.19513379e-05
Iter: 1734 loss: 1.19458527e-05
Iter: 1735 loss: 1.19362758e-05
Iter: 1736 loss: 1.21739422e-05
Iter: 1737 loss: 1.19360166e-05
Iter: 1738 loss: 1.1929209e-05
Iter: 1739 loss: 1.19293345e-05
Iter: 1740 loss: 1.19233764e-05
Iter: 1741 loss: 1.1930144e-05
Iter: 1742 loss: 1.19202477e-05
Iter: 1743 loss: 1.19131091e-05
Iter: 1744 loss: 1.19118e-05
Iter: 1745 loss: 1.19072483e-05
Iter: 1746 loss: 1.18975931e-05
Iter: 1747 loss: 1.19542619e-05
Iter: 1748 loss: 1.18960779e-05
Iter: 1749 loss: 1.18903099e-05
Iter: 1750 loss: 1.19452607e-05
Iter: 1751 loss: 1.18902408e-05
Iter: 1752 loss: 1.18839871e-05
Iter: 1753 loss: 1.18775497e-05
Iter: 1754 loss: 1.1876723e-05
Iter: 1755 loss: 1.18674898e-05
Iter: 1756 loss: 1.18731496e-05
Iter: 1757 loss: 1.18618063e-05
Iter: 1758 loss: 1.18566941e-05
Iter: 1759 loss: 1.18558355e-05
Iter: 1760 loss: 1.18509524e-05
Iter: 1761 loss: 1.18447451e-05
Iter: 1762 loss: 1.18441303e-05
Iter: 1763 loss: 1.18363441e-05
Iter: 1764 loss: 1.18618173e-05
Iter: 1765 loss: 1.18344597e-05
Iter: 1766 loss: 1.18261705e-05
Iter: 1767 loss: 1.18914686e-05
Iter: 1768 loss: 1.18257249e-05
Iter: 1769 loss: 1.18210683e-05
Iter: 1770 loss: 1.18134694e-05
Iter: 1771 loss: 1.18134794e-05
Iter: 1772 loss: 1.18056223e-05
Iter: 1773 loss: 1.18056141e-05
Iter: 1774 loss: 1.18003236e-05
Iter: 1775 loss: 1.17953423e-05
Iter: 1776 loss: 1.1794109e-05
Iter: 1777 loss: 1.17858572e-05
Iter: 1778 loss: 1.18180569e-05
Iter: 1779 loss: 1.17839727e-05
Iter: 1780 loss: 1.17768104e-05
Iter: 1781 loss: 1.1812469e-05
Iter: 1782 loss: 1.17755098e-05
Iter: 1783 loss: 1.17693635e-05
Iter: 1784 loss: 1.18095541e-05
Iter: 1785 loss: 1.17686523e-05
Iter: 1786 loss: 1.17639775e-05
Iter: 1787 loss: 1.17551335e-05
Iter: 1788 loss: 1.19417673e-05
Iter: 1789 loss: 1.17550826e-05
Iter: 1790 loss: 1.17467735e-05
Iter: 1791 loss: 1.17998625e-05
Iter: 1792 loss: 1.17457403e-05
Iter: 1793 loss: 1.173897e-05
Iter: 1794 loss: 1.18166827e-05
Iter: 1795 loss: 1.17387781e-05
Iter: 1796 loss: 1.17335276e-05
Iter: 1797 loss: 1.17230829e-05
Iter: 1798 loss: 1.19178694e-05
Iter: 1799 loss: 1.17228656e-05
Iter: 1800 loss: 1.17163663e-05
Iter: 1801 loss: 1.17159689e-05
Iter: 1802 loss: 1.17097625e-05
Iter: 1803 loss: 1.17056816e-05
Iter: 1804 loss: 1.1703416e-05
Iter: 1805 loss: 1.16962856e-05
Iter: 1806 loss: 1.17150212e-05
Iter: 1807 loss: 1.16937881e-05
Iter: 1808 loss: 1.16844676e-05
Iter: 1809 loss: 1.17259406e-05
Iter: 1810 loss: 1.16827268e-05
Iter: 1811 loss: 1.16772426e-05
Iter: 1812 loss: 1.16778065e-05
Iter: 1813 loss: 1.16729771e-05
Iter: 1814 loss: 1.16658139e-05
Iter: 1815 loss: 1.17021482e-05
Iter: 1816 loss: 1.16647607e-05
Iter: 1817 loss: 1.1658055e-05
Iter: 1818 loss: 1.16905867e-05
Iter: 1819 loss: 1.16569299e-05
Iter: 1820 loss: 1.16500432e-05
Iter: 1821 loss: 1.1656708e-05
Iter: 1822 loss: 1.16462052e-05
Iter: 1823 loss: 1.16400543e-05
Iter: 1824 loss: 1.16323899e-05
Iter: 1825 loss: 1.16317433e-05
Iter: 1826 loss: 1.16245401e-05
Iter: 1827 loss: 1.16244282e-05
Iter: 1828 loss: 1.16170959e-05
Iter: 1829 loss: 1.16267665e-05
Iter: 1830 loss: 1.16132487e-05
Iter: 1831 loss: 1.16075644e-05
Iter: 1832 loss: 1.16111805e-05
Iter: 1833 loss: 1.16037872e-05
Iter: 1834 loss: 1.15963157e-05
Iter: 1835 loss: 1.16740193e-05
Iter: 1836 loss: 1.15961157e-05
Iter: 1837 loss: 1.15905841e-05
Iter: 1838 loss: 1.15840812e-05
Iter: 1839 loss: 1.15832781e-05
Iter: 1840 loss: 1.15773964e-05
Iter: 1841 loss: 1.16617566e-05
Iter: 1842 loss: 1.15771545e-05
Iter: 1843 loss: 1.1570588e-05
Iter: 1844 loss: 1.15627608e-05
Iter: 1845 loss: 1.15619696e-05
Iter: 1846 loss: 1.15534676e-05
Iter: 1847 loss: 1.1593469e-05
Iter: 1848 loss: 1.1552027e-05
Iter: 1849 loss: 1.15456132e-05
Iter: 1850 loss: 1.16081765e-05
Iter: 1851 loss: 1.15454432e-05
Iter: 1852 loss: 1.15401399e-05
Iter: 1853 loss: 1.15512812e-05
Iter: 1854 loss: 1.15379171e-05
Iter: 1855 loss: 1.15317443e-05
Iter: 1856 loss: 1.15271605e-05
Iter: 1857 loss: 1.15251223e-05
Iter: 1858 loss: 1.15167713e-05
Iter: 1859 loss: 1.15235916e-05
Iter: 1860 loss: 1.15119801e-05
Iter: 1861 loss: 1.15056573e-05
Iter: 1862 loss: 1.15050971e-05
Iter: 1863 loss: 1.14998966e-05
Iter: 1864 loss: 1.14921604e-05
Iter: 1865 loss: 1.14918603e-05
Iter: 1866 loss: 1.14848726e-05
Iter: 1867 loss: 1.1549424e-05
Iter: 1868 loss: 1.14846462e-05
Iter: 1869 loss: 1.14770473e-05
Iter: 1870 loss: 1.14822024e-05
Iter: 1871 loss: 1.14722498e-05
Iter: 1872 loss: 1.1465434e-05
Iter: 1873 loss: 1.14776776e-05
Iter: 1874 loss: 1.14623581e-05
Iter: 1875 loss: 1.14568902e-05
Iter: 1876 loss: 1.15377461e-05
Iter: 1877 loss: 1.1457043e-05
Iter: 1878 loss: 1.14523318e-05
Iter: 1879 loss: 1.14421564e-05
Iter: 1880 loss: 1.15847233e-05
Iter: 1881 loss: 1.1441587e-05
Iter: 1882 loss: 1.14325612e-05
Iter: 1883 loss: 1.15377479e-05
Iter: 1884 loss: 1.14323875e-05
Iter: 1885 loss: 1.14254181e-05
Iter: 1886 loss: 1.1469936e-05
Iter: 1887 loss: 1.14247714e-05
Iter: 1888 loss: 1.14193681e-05
Iter: 1889 loss: 1.14248814e-05
Iter: 1890 loss: 1.1416354e-05
Iter: 1891 loss: 1.14095292e-05
Iter: 1892 loss: 1.14038203e-05
Iter: 1893 loss: 1.14018858e-05
Iter: 1894 loss: 1.13927154e-05
Iter: 1895 loss: 1.1446049e-05
Iter: 1896 loss: 1.13917977e-05
Iter: 1897 loss: 1.13852111e-05
Iter: 1898 loss: 1.14791346e-05
Iter: 1899 loss: 1.13850247e-05
Iter: 1900 loss: 1.13809692e-05
Iter: 1901 loss: 1.13728365e-05
Iter: 1902 loss: 1.15300836e-05
Iter: 1903 loss: 1.13727456e-05
Iter: 1904 loss: 1.13673341e-05
Iter: 1905 loss: 1.13669212e-05
Iter: 1906 loss: 1.13615988e-05
Iter: 1907 loss: 1.13529095e-05
Iter: 1908 loss: 1.13528131e-05
Iter: 1909 loss: 1.13459264e-05
Iter: 1910 loss: 1.14153663e-05
Iter: 1911 loss: 1.13458136e-05
Iter: 1912 loss: 1.13392543e-05
Iter: 1913 loss: 1.13583801e-05
Iter: 1914 loss: 1.13373571e-05
Iter: 1915 loss: 1.13317055e-05
Iter: 1916 loss: 1.13245469e-05
Iter: 1917 loss: 1.13239676e-05
Iter: 1918 loss: 1.13175292e-05
Iter: 1919 loss: 1.13173191e-05
Iter: 1920 loss: 1.13113356e-05
Iter: 1921 loss: 1.13136375e-05
Iter: 1922 loss: 1.13072338e-05
Iter: 1923 loss: 1.12995967e-05
Iter: 1924 loss: 1.13107726e-05
Iter: 1925 loss: 1.12959206e-05
Iter: 1926 loss: 1.12883881e-05
Iter: 1927 loss: 1.12989183e-05
Iter: 1928 loss: 1.1284621e-05
Iter: 1929 loss: 1.1278591e-05
Iter: 1930 loss: 1.13361475e-05
Iter: 1931 loss: 1.12782891e-05
Iter: 1932 loss: 1.12717626e-05
Iter: 1933 loss: 1.12786392e-05
Iter: 1934 loss: 1.12680991e-05
Iter: 1935 loss: 1.12619527e-05
Iter: 1936 loss: 1.12600201e-05
Iter: 1937 loss: 1.1256423e-05
Iter: 1938 loss: 1.12490179e-05
Iter: 1939 loss: 1.12487869e-05
Iter: 1940 loss: 1.12441303e-05
Iter: 1941 loss: 1.1235752e-05
Iter: 1942 loss: 1.12355838e-05
Iter: 1943 loss: 1.12291782e-05
Iter: 1944 loss: 1.122913e-05
Iter: 1945 loss: 1.12228927e-05
Iter: 1946 loss: 1.12222478e-05
Iter: 1947 loss: 1.12179896e-05
Iter: 1948 loss: 1.12109228e-05
Iter: 1949 loss: 1.12163179e-05
Iter: 1950 loss: 1.12068501e-05
Iter: 1951 loss: 1.12001962e-05
Iter: 1952 loss: 1.12001489e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.8/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.2 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.2
+ date
Sun Nov  8 08:28:01 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi0.8/300_100_100_100_1 --function f2 --psi 0 --alpha 1.2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.2/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89f82268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89f82400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89f820d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89ee7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89f82048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f647587b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f646f21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f64758400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f646f2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89ed5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f646a1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89e77488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89e779d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89ee22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f64625400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645dd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645dd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645f4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f64561ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645381e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f64538488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645ca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645cebf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645ce2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f644c1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f89f540d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f64507ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f645ce510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f64678ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f644c1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f646789d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f643cc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f643cc0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f6437c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f643ba400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7f6437c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.017367944
test_loss: 0.020668572
train_loss: 0.013427079
test_loss: 0.014439179
train_loss: 0.012820231
test_loss: 0.014046209
train_loss: 0.011648152
test_loss: 0.013018599
train_loss: 0.012024526
test_loss: 0.013600697
train_loss: 0.010600369
test_loss: 0.012842666
train_loss: 0.010463806
test_loss: 0.012582211
train_loss: 0.011491193
test_loss: 0.012635583
train_loss: 0.0110618705
test_loss: 0.01268105
train_loss: 0.010645276
test_loss: 0.012525898
train_loss: 0.009930945
test_loss: 0.012368021
train_loss: 0.009980749
test_loss: 0.012138997
train_loss: 0.010223785
test_loss: 0.012047232
train_loss: 0.011166483
test_loss: 0.012820091
train_loss: 0.009815589
test_loss: 0.012257332
train_loss: 0.0095499875
test_loss: 0.012130032
train_loss: 0.009811588
test_loss: 0.012385581
train_loss: 0.009855358
test_loss: 0.011604423
train_loss: 0.009600312
test_loss: 0.012249232
train_loss: 0.009634459
test_loss: 0.012264357
train_loss: 0.009920361
test_loss: 0.012222435
train_loss: 0.0093975
test_loss: 0.01141082
train_loss: 0.009456006
test_loss: 0.011842543
train_loss: 0.010025655
test_loss: 0.011616211
train_loss: 0.008983044
test_loss: 0.011567041
train_loss: 0.008801907
test_loss: 0.011395101
train_loss: 0.009460159
test_loss: 0.011559834
train_loss: 0.009210953
test_loss: 0.011434778
train_loss: 0.008471138
test_loss: 0.011032195
train_loss: 0.009341414
test_loss: 0.011524493
train_loss: 0.008812808
test_loss: 0.011244503
train_loss: 0.009451972
test_loss: 0.011340846
train_loss: 0.0089540575
test_loss: 0.011094373
train_loss: 0.0091979
test_loss: 0.011885733
train_loss: 0.008796647
test_loss: 0.011297314
train_loss: 0.008686745
test_loss: 0.010833404
train_loss: 0.0095224995
test_loss: 0.011839293
train_loss: 0.008839259
test_loss: 0.01088184
train_loss: 0.009011481
test_loss: 0.011208891
train_loss: 0.009399415
test_loss: 0.011008138
train_loss: 0.008487213
test_loss: 0.0109607885
train_loss: 0.008044837
test_loss: 0.010865961
train_loss: 0.009274413
test_loss: 0.01086199
train_loss: 0.008823958
test_loss: 0.011512297
train_loss: 0.00884752
test_loss: 0.010819329
train_loss: 0.008118652
test_loss: 0.010562161
train_loss: 0.0081228055
test_loss: 0.010718828
train_loss: 0.007988391
test_loss: 0.01063278
train_loss: 0.008811504
test_loss: 0.0116735175
train_loss: 0.007944472
test_loss: 0.010630672
train_loss: 0.008311147
test_loss: 0.010797993
train_loss: 0.008082114
test_loss: 0.010459409
train_loss: 0.008528399
test_loss: 0.010593783
train_loss: 0.008352628
test_loss: 0.010525041
train_loss: 0.008149535
test_loss: 0.01060798
train_loss: 0.008401522
test_loss: 0.010589947
train_loss: 0.0084890295
test_loss: 0.010688469
train_loss: 0.008028459
test_loss: 0.010431644
train_loss: 0.007821081
test_loss: 0.010412914
train_loss: 0.007701967
test_loss: 0.010324502
train_loss: 0.0077897576
test_loss: 0.010270248
train_loss: 0.007959363
test_loss: 0.010417678
train_loss: 0.007850309
test_loss: 0.010600461
train_loss: 0.007998137
test_loss: 0.010260121
train_loss: 0.00828173
test_loss: 0.010659535
train_loss: 0.007568828
test_loss: 0.010385865
train_loss: 0.0080508115
test_loss: 0.01039171
train_loss: 0.00763831
test_loss: 0.010296274
train_loss: 0.007820701
test_loss: 0.010341272
train_loss: 0.007852954
test_loss: 0.010109702
train_loss: 0.007391314
test_loss: 0.010036643
train_loss: 0.0076660533
test_loss: 0.010032984
train_loss: 0.007469403
test_loss: 0.010033312
train_loss: 0.0077626053
test_loss: 0.01035778
train_loss: 0.00786436
test_loss: 0.01019406
train_loss: 0.008043929
test_loss: 0.010090261
train_loss: 0.007745738
test_loss: 0.010460996
train_loss: 0.0076874383
test_loss: 0.010337711
train_loss: 0.0077858404
test_loss: 0.010041246
train_loss: 0.007853866
test_loss: 0.010014819
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.2/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 1.2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.2/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e85780840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e85780510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e85780048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e857af620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e856ff510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e8570d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e856d8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e856d8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e85686158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e856839d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e85636a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e8561c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e8561c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e855e66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e85780ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e856e10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e855e97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e468b3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e468b3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e468b3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e468348c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e46889378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e467f7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e46849510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e46849400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e467b8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e467b8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e467b87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e20701c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e206b77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e20670d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e20631400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e20642400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e205fa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e205faa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2e205fa158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.87485837e-05
Iter: 2 loss: 8.48827622e-05
Iter: 3 loss: 0.000187435158
Iter: 4 loss: 8.37429689e-05
Iter: 5 loss: 7.36692746e-05
Iter: 6 loss: 0.000132662419
Iter: 7 loss: 7.23668054e-05
Iter: 8 loss: 6.65272892e-05
Iter: 9 loss: 6.75432166e-05
Iter: 10 loss: 6.21614454e-05
Iter: 11 loss: 5.82672656e-05
Iter: 12 loss: 5.82531902e-05
Iter: 13 loss: 5.56148298e-05
Iter: 14 loss: 6.28669586e-05
Iter: 15 loss: 5.47530944e-05
Iter: 16 loss: 5.2711126e-05
Iter: 17 loss: 5.98767365e-05
Iter: 18 loss: 5.21757174e-05
Iter: 19 loss: 4.97810324e-05
Iter: 20 loss: 5.2918509e-05
Iter: 21 loss: 4.8566355e-05
Iter: 22 loss: 4.701539e-05
Iter: 23 loss: 5.64241491e-05
Iter: 24 loss: 4.68281723e-05
Iter: 25 loss: 4.54184919e-05
Iter: 26 loss: 4.72909705e-05
Iter: 27 loss: 4.47044586e-05
Iter: 28 loss: 4.33489331e-05
Iter: 29 loss: 5.17047192e-05
Iter: 30 loss: 4.31856715e-05
Iter: 31 loss: 4.2126896e-05
Iter: 32 loss: 4.27661726e-05
Iter: 33 loss: 4.14470123e-05
Iter: 34 loss: 4.03514787e-05
Iter: 35 loss: 4.23370948e-05
Iter: 36 loss: 3.9875682e-05
Iter: 37 loss: 3.90499881e-05
Iter: 38 loss: 5.17163608e-05
Iter: 39 loss: 3.90491587e-05
Iter: 40 loss: 3.82941944e-05
Iter: 41 loss: 4.10800385e-05
Iter: 42 loss: 3.81089e-05
Iter: 43 loss: 3.7589627e-05
Iter: 44 loss: 3.77555043e-05
Iter: 45 loss: 3.72201685e-05
Iter: 46 loss: 3.68198525e-05
Iter: 47 loss: 3.68168621e-05
Iter: 48 loss: 3.64835723e-05
Iter: 49 loss: 3.61856364e-05
Iter: 50 loss: 3.61008679e-05
Iter: 51 loss: 3.56442e-05
Iter: 52 loss: 4.09136192e-05
Iter: 53 loss: 3.56368218e-05
Iter: 54 loss: 3.52951247e-05
Iter: 55 loss: 3.53828582e-05
Iter: 56 loss: 3.50466507e-05
Iter: 57 loss: 3.47094574e-05
Iter: 58 loss: 3.63255422e-05
Iter: 59 loss: 3.46487759e-05
Iter: 60 loss: 3.43111824e-05
Iter: 61 loss: 3.50280752e-05
Iter: 62 loss: 3.41782797e-05
Iter: 63 loss: 3.38908212e-05
Iter: 64 loss: 3.50464361e-05
Iter: 65 loss: 3.38264799e-05
Iter: 66 loss: 3.35389159e-05
Iter: 67 loss: 3.352977e-05
Iter: 68 loss: 3.33059033e-05
Iter: 69 loss: 3.29935428e-05
Iter: 70 loss: 3.30709372e-05
Iter: 71 loss: 3.27655507e-05
Iter: 72 loss: 3.26016343e-05
Iter: 73 loss: 3.25581459e-05
Iter: 74 loss: 3.23756321e-05
Iter: 75 loss: 3.24298308e-05
Iter: 76 loss: 3.22443484e-05
Iter: 77 loss: 3.20390282e-05
Iter: 78 loss: 3.21831103e-05
Iter: 79 loss: 3.19114624e-05
Iter: 80 loss: 3.17291e-05
Iter: 81 loss: 3.17279228e-05
Iter: 82 loss: 3.16091646e-05
Iter: 83 loss: 3.15856e-05
Iter: 84 loss: 3.15066573e-05
Iter: 85 loss: 3.13407691e-05
Iter: 86 loss: 3.24311914e-05
Iter: 87 loss: 3.13233359e-05
Iter: 88 loss: 3.11806143e-05
Iter: 89 loss: 3.10763207e-05
Iter: 90 loss: 3.10275573e-05
Iter: 91 loss: 3.08582057e-05
Iter: 92 loss: 3.25934088e-05
Iter: 93 loss: 3.08531853e-05
Iter: 94 loss: 3.07009359e-05
Iter: 95 loss: 3.07391965e-05
Iter: 96 loss: 3.05898284e-05
Iter: 97 loss: 3.04368587e-05
Iter: 98 loss: 3.14703029e-05
Iter: 99 loss: 3.04213536e-05
Iter: 100 loss: 3.02946191e-05
Iter: 101 loss: 3.02258886e-05
Iter: 102 loss: 3.01695636e-05
Iter: 103 loss: 2.99924941e-05
Iter: 104 loss: 3.0336405e-05
Iter: 105 loss: 2.99187141e-05
Iter: 106 loss: 2.98144805e-05
Iter: 107 loss: 2.98088598e-05
Iter: 108 loss: 2.9705865e-05
Iter: 109 loss: 2.96303624e-05
Iter: 110 loss: 2.95958653e-05
Iter: 111 loss: 2.94526271e-05
Iter: 112 loss: 2.97672414e-05
Iter: 113 loss: 2.93978828e-05
Iter: 114 loss: 2.92753939e-05
Iter: 115 loss: 2.92753321e-05
Iter: 116 loss: 2.92060704e-05
Iter: 117 loss: 2.91755314e-05
Iter: 118 loss: 2.91403558e-05
Iter: 119 loss: 2.90229109e-05
Iter: 120 loss: 2.96216058e-05
Iter: 121 loss: 2.90041389e-05
Iter: 122 loss: 2.89095515e-05
Iter: 123 loss: 2.88488027e-05
Iter: 124 loss: 2.88122337e-05
Iter: 125 loss: 2.87010535e-05
Iter: 126 loss: 3.02964472e-05
Iter: 127 loss: 2.87004987e-05
Iter: 128 loss: 2.86174636e-05
Iter: 129 loss: 2.85749447e-05
Iter: 130 loss: 2.85360056e-05
Iter: 131 loss: 2.84192138e-05
Iter: 132 loss: 2.90246426e-05
Iter: 133 loss: 2.84009711e-05
Iter: 134 loss: 2.83032641e-05
Iter: 135 loss: 2.83575137e-05
Iter: 136 loss: 2.82393503e-05
Iter: 137 loss: 2.81255725e-05
Iter: 138 loss: 2.83622085e-05
Iter: 139 loss: 2.80805671e-05
Iter: 140 loss: 2.8004104e-05
Iter: 141 loss: 2.80039312e-05
Iter: 142 loss: 2.79293308e-05
Iter: 143 loss: 2.79421147e-05
Iter: 144 loss: 2.78730367e-05
Iter: 145 loss: 2.77988456e-05
Iter: 146 loss: 2.78470561e-05
Iter: 147 loss: 2.77517611e-05
Iter: 148 loss: 2.76535175e-05
Iter: 149 loss: 2.88214851e-05
Iter: 150 loss: 2.76526407e-05
Iter: 151 loss: 2.76014562e-05
Iter: 152 loss: 2.75957209e-05
Iter: 153 loss: 2.75588591e-05
Iter: 154 loss: 2.74727572e-05
Iter: 155 loss: 2.78056414e-05
Iter: 156 loss: 2.74524809e-05
Iter: 157 loss: 2.73852893e-05
Iter: 158 loss: 2.73808055e-05
Iter: 159 loss: 2.73301775e-05
Iter: 160 loss: 2.72554498e-05
Iter: 161 loss: 2.82222973e-05
Iter: 162 loss: 2.72552243e-05
Iter: 163 loss: 2.71984973e-05
Iter: 164 loss: 2.7154656e-05
Iter: 165 loss: 2.71364916e-05
Iter: 166 loss: 2.7062646e-05
Iter: 167 loss: 2.75622351e-05
Iter: 168 loss: 2.70551318e-05
Iter: 169 loss: 2.69880966e-05
Iter: 170 loss: 2.69775046e-05
Iter: 171 loss: 2.69316497e-05
Iter: 172 loss: 2.68464628e-05
Iter: 173 loss: 2.70387027e-05
Iter: 174 loss: 2.68145341e-05
Iter: 175 loss: 2.67366704e-05
Iter: 176 loss: 2.76632927e-05
Iter: 177 loss: 2.67359665e-05
Iter: 178 loss: 2.66642674e-05
Iter: 179 loss: 2.66943316e-05
Iter: 180 loss: 2.66145362e-05
Iter: 181 loss: 2.6546446e-05
Iter: 182 loss: 2.66955685e-05
Iter: 183 loss: 2.65202889e-05
Iter: 184 loss: 2.64580121e-05
Iter: 185 loss: 2.733988e-05
Iter: 186 loss: 2.64578175e-05
Iter: 187 loss: 2.64197279e-05
Iter: 188 loss: 2.63761594e-05
Iter: 189 loss: 2.63703932e-05
Iter: 190 loss: 2.63060792e-05
Iter: 191 loss: 2.69269858e-05
Iter: 192 loss: 2.63030815e-05
Iter: 193 loss: 2.6257605e-05
Iter: 194 loss: 2.62042959e-05
Iter: 195 loss: 2.61985133e-05
Iter: 196 loss: 2.61420337e-05
Iter: 197 loss: 2.61420573e-05
Iter: 198 loss: 2.60949018e-05
Iter: 199 loss: 2.60355155e-05
Iter: 200 loss: 2.60304478e-05
Iter: 201 loss: 2.59609642e-05
Iter: 202 loss: 2.63293441e-05
Iter: 203 loss: 2.59504777e-05
Iter: 204 loss: 2.5881387e-05
Iter: 205 loss: 2.60175293e-05
Iter: 206 loss: 2.58528235e-05
Iter: 207 loss: 2.57846841e-05
Iter: 208 loss: 2.58011205e-05
Iter: 209 loss: 2.57341671e-05
Iter: 210 loss: 2.56889489e-05
Iter: 211 loss: 2.56839885e-05
Iter: 212 loss: 2.56415424e-05
Iter: 213 loss: 2.56188523e-05
Iter: 214 loss: 2.56001e-05
Iter: 215 loss: 2.5545196e-05
Iter: 216 loss: 2.56687345e-05
Iter: 217 loss: 2.55241794e-05
Iter: 218 loss: 2.54660208e-05
Iter: 219 loss: 2.60831221e-05
Iter: 220 loss: 2.54644729e-05
Iter: 221 loss: 2.54305523e-05
Iter: 222 loss: 2.54186416e-05
Iter: 223 loss: 2.53992839e-05
Iter: 224 loss: 2.53542385e-05
Iter: 225 loss: 2.57170141e-05
Iter: 226 loss: 2.53514554e-05
Iter: 227 loss: 2.53127091e-05
Iter: 228 loss: 2.52639e-05
Iter: 229 loss: 2.52600839e-05
Iter: 230 loss: 2.52039354e-05
Iter: 231 loss: 2.5817717e-05
Iter: 232 loss: 2.52027021e-05
Iter: 233 loss: 2.51480924e-05
Iter: 234 loss: 2.51369947e-05
Iter: 235 loss: 2.51003385e-05
Iter: 236 loss: 2.5050922e-05
Iter: 237 loss: 2.51426791e-05
Iter: 238 loss: 2.50296944e-05
Iter: 239 loss: 2.4967876e-05
Iter: 240 loss: 2.52726932e-05
Iter: 241 loss: 2.49574514e-05
Iter: 242 loss: 2.49097338e-05
Iter: 243 loss: 2.49643017e-05
Iter: 244 loss: 2.4884137e-05
Iter: 245 loss: 2.48426186e-05
Iter: 246 loss: 2.53416729e-05
Iter: 247 loss: 2.48422148e-05
Iter: 248 loss: 2.48028882e-05
Iter: 249 loss: 2.4793153e-05
Iter: 250 loss: 2.47681346e-05
Iter: 251 loss: 2.4714609e-05
Iter: 252 loss: 2.48010929e-05
Iter: 253 loss: 2.46899363e-05
Iter: 254 loss: 2.4651963e-05
Iter: 255 loss: 2.46503932e-05
Iter: 256 loss: 2.46268719e-05
Iter: 257 loss: 2.45752635e-05
Iter: 258 loss: 2.53252801e-05
Iter: 259 loss: 2.45729589e-05
Iter: 260 loss: 2.45189476e-05
Iter: 261 loss: 2.53290364e-05
Iter: 262 loss: 2.45187439e-05
Iter: 263 loss: 2.44836756e-05
Iter: 264 loss: 2.4467874e-05
Iter: 265 loss: 2.44502044e-05
Iter: 266 loss: 2.44119801e-05
Iter: 267 loss: 2.47679382e-05
Iter: 268 loss: 2.44099829e-05
Iter: 269 loss: 2.43712584e-05
Iter: 270 loss: 2.43590875e-05
Iter: 271 loss: 2.43364157e-05
Iter: 272 loss: 2.42910228e-05
Iter: 273 loss: 2.43269678e-05
Iter: 274 loss: 2.42638926e-05
Iter: 275 loss: 2.42158367e-05
Iter: 276 loss: 2.46603522e-05
Iter: 277 loss: 2.42135611e-05
Iter: 278 loss: 2.4171768e-05
Iter: 279 loss: 2.4180059e-05
Iter: 280 loss: 2.41404887e-05
Iter: 281 loss: 2.40928384e-05
Iter: 282 loss: 2.4490344e-05
Iter: 283 loss: 2.40899826e-05
Iter: 284 loss: 2.40477675e-05
Iter: 285 loss: 2.41847865e-05
Iter: 286 loss: 2.40357567e-05
Iter: 287 loss: 2.40047448e-05
Iter: 288 loss: 2.39855617e-05
Iter: 289 loss: 2.39731489e-05
Iter: 290 loss: 2.39309957e-05
Iter: 291 loss: 2.39307665e-05
Iter: 292 loss: 2.39060319e-05
Iter: 293 loss: 2.38771881e-05
Iter: 294 loss: 2.38740922e-05
Iter: 295 loss: 2.38368229e-05
Iter: 296 loss: 2.41587168e-05
Iter: 297 loss: 2.38345474e-05
Iter: 298 loss: 2.37994864e-05
Iter: 299 loss: 2.3798395e-05
Iter: 300 loss: 2.37707027e-05
Iter: 301 loss: 2.37301592e-05
Iter: 302 loss: 2.38469784e-05
Iter: 303 loss: 2.37174427e-05
Iter: 304 loss: 2.36694759e-05
Iter: 305 loss: 2.38954381e-05
Iter: 306 loss: 2.36606083e-05
Iter: 307 loss: 2.36279375e-05
Iter: 308 loss: 2.3590288e-05
Iter: 309 loss: 2.35855077e-05
Iter: 310 loss: 2.35328971e-05
Iter: 311 loss: 2.37855202e-05
Iter: 312 loss: 2.35233183e-05
Iter: 313 loss: 2.34777617e-05
Iter: 314 loss: 2.38563844e-05
Iter: 315 loss: 2.34751824e-05
Iter: 316 loss: 2.34454528e-05
Iter: 317 loss: 2.34849667e-05
Iter: 318 loss: 2.34301224e-05
Iter: 319 loss: 2.33890532e-05
Iter: 320 loss: 2.35794741e-05
Iter: 321 loss: 2.33813862e-05
Iter: 322 loss: 2.33536539e-05
Iter: 323 loss: 2.33433548e-05
Iter: 324 loss: 2.33280171e-05
Iter: 325 loss: 2.32898783e-05
Iter: 326 loss: 2.38038338e-05
Iter: 327 loss: 2.328954e-05
Iter: 328 loss: 2.3262688e-05
Iter: 329 loss: 2.32282109e-05
Iter: 330 loss: 2.32257262e-05
Iter: 331 loss: 2.31910926e-05
Iter: 332 loss: 2.3519664e-05
Iter: 333 loss: 2.31894501e-05
Iter: 334 loss: 2.31530539e-05
Iter: 335 loss: 2.31531085e-05
Iter: 336 loss: 2.31240156e-05
Iter: 337 loss: 2.30867463e-05
Iter: 338 loss: 2.32359362e-05
Iter: 339 loss: 2.30788064e-05
Iter: 340 loss: 2.30405185e-05
Iter: 341 loss: 2.32122438e-05
Iter: 342 loss: 2.30332407e-05
Iter: 343 loss: 2.30044679e-05
Iter: 344 loss: 2.29813522e-05
Iter: 345 loss: 2.29725229e-05
Iter: 346 loss: 2.29257239e-05
Iter: 347 loss: 2.30423066e-05
Iter: 348 loss: 2.29100442e-05
Iter: 349 loss: 2.28775461e-05
Iter: 350 loss: 2.33428909e-05
Iter: 351 loss: 2.28775825e-05
Iter: 352 loss: 2.28490717e-05
Iter: 353 loss: 2.28577701e-05
Iter: 354 loss: 2.28287827e-05
Iter: 355 loss: 2.27923665e-05
Iter: 356 loss: 2.30516562e-05
Iter: 357 loss: 2.27888904e-05
Iter: 358 loss: 2.27590663e-05
Iter: 359 loss: 2.27396886e-05
Iter: 360 loss: 2.27280889e-05
Iter: 361 loss: 2.27008459e-05
Iter: 362 loss: 2.26999728e-05
Iter: 363 loss: 2.26773118e-05
Iter: 364 loss: 2.26340599e-05
Iter: 365 loss: 2.35354273e-05
Iter: 366 loss: 2.26335505e-05
Iter: 367 loss: 2.26018674e-05
Iter: 368 loss: 2.29786056e-05
Iter: 369 loss: 2.26012671e-05
Iter: 370 loss: 2.25669683e-05
Iter: 371 loss: 2.25729473e-05
Iter: 372 loss: 2.25412077e-05
Iter: 373 loss: 2.25074582e-05
Iter: 374 loss: 2.2611066e-05
Iter: 375 loss: 2.24977448e-05
Iter: 376 loss: 2.24597225e-05
Iter: 377 loss: 2.26253014e-05
Iter: 378 loss: 2.24519499e-05
Iter: 379 loss: 2.24203795e-05
Iter: 380 loss: 2.24138785e-05
Iter: 381 loss: 2.23933203e-05
Iter: 382 loss: 2.23519091e-05
Iter: 383 loss: 2.23679308e-05
Iter: 384 loss: 2.23233692e-05
Iter: 385 loss: 2.22810449e-05
Iter: 386 loss: 2.29434372e-05
Iter: 387 loss: 2.22811e-05
Iter: 388 loss: 2.22484741e-05
Iter: 389 loss: 2.23484622e-05
Iter: 390 loss: 2.22389026e-05
Iter: 391 loss: 2.221063e-05
Iter: 392 loss: 2.23243296e-05
Iter: 393 loss: 2.22044619e-05
Iter: 394 loss: 2.21766713e-05
Iter: 395 loss: 2.21837254e-05
Iter: 396 loss: 2.21563459e-05
Iter: 397 loss: 2.21254559e-05
Iter: 398 loss: 2.24357791e-05
Iter: 399 loss: 2.21244663e-05
Iter: 400 loss: 2.20959155e-05
Iter: 401 loss: 2.20667971e-05
Iter: 402 loss: 2.20610127e-05
Iter: 403 loss: 2.20309303e-05
Iter: 404 loss: 2.21725641e-05
Iter: 405 loss: 2.20251768e-05
Iter: 406 loss: 2.19893882e-05
Iter: 407 loss: 2.20979127e-05
Iter: 408 loss: 2.19783469e-05
Iter: 409 loss: 2.19494104e-05
Iter: 410 loss: 2.19549365e-05
Iter: 411 loss: 2.19279027e-05
Iter: 412 loss: 2.18932437e-05
Iter: 413 loss: 2.22425369e-05
Iter: 414 loss: 2.18921214e-05
Iter: 415 loss: 2.18644127e-05
Iter: 416 loss: 2.18458972e-05
Iter: 417 loss: 2.18356217e-05
Iter: 418 loss: 2.17979268e-05
Iter: 419 loss: 2.18371933e-05
Iter: 420 loss: 2.17768811e-05
Iter: 421 loss: 2.17413108e-05
Iter: 422 loss: 2.20521724e-05
Iter: 423 loss: 2.17393554e-05
Iter: 424 loss: 2.17061279e-05
Iter: 425 loss: 2.18643436e-05
Iter: 426 loss: 2.16999324e-05
Iter: 427 loss: 2.16746193e-05
Iter: 428 loss: 2.1732747e-05
Iter: 429 loss: 2.16649532e-05
Iter: 430 loss: 2.16359458e-05
Iter: 431 loss: 2.16836434e-05
Iter: 432 loss: 2.16223962e-05
Iter: 433 loss: 2.15931595e-05
Iter: 434 loss: 2.17781453e-05
Iter: 435 loss: 2.15894324e-05
Iter: 436 loss: 2.15627661e-05
Iter: 437 loss: 2.15826294e-05
Iter: 438 loss: 2.15465843e-05
Iter: 439 loss: 2.15223045e-05
Iter: 440 loss: 2.15173241e-05
Iter: 441 loss: 2.15015643e-05
Iter: 442 loss: 2.14641259e-05
Iter: 443 loss: 2.18573987e-05
Iter: 444 loss: 2.14632473e-05
Iter: 445 loss: 2.14408137e-05
Iter: 446 loss: 2.14280226e-05
Iter: 447 loss: 2.14185256e-05
Iter: 448 loss: 2.13896583e-05
Iter: 449 loss: 2.16143835e-05
Iter: 450 loss: 2.13874282e-05
Iter: 451 loss: 2.13562616e-05
Iter: 452 loss: 2.13405201e-05
Iter: 453 loss: 2.13259336e-05
Iter: 454 loss: 2.1293903e-05
Iter: 455 loss: 2.13613366e-05
Iter: 456 loss: 2.12814e-05
Iter: 457 loss: 2.12454397e-05
Iter: 458 loss: 2.13148123e-05
Iter: 459 loss: 2.12305968e-05
Iter: 460 loss: 2.12028499e-05
Iter: 461 loss: 2.12023806e-05
Iter: 462 loss: 2.11799343e-05
Iter: 463 loss: 2.11691549e-05
Iter: 464 loss: 2.115795e-05
Iter: 465 loss: 2.11296428e-05
Iter: 466 loss: 2.13429666e-05
Iter: 467 loss: 2.11271454e-05
Iter: 468 loss: 2.11016086e-05
Iter: 469 loss: 2.1133128e-05
Iter: 470 loss: 2.10885592e-05
Iter: 471 loss: 2.10572907e-05
Iter: 472 loss: 2.11705083e-05
Iter: 473 loss: 2.10494927e-05
Iter: 474 loss: 2.10278649e-05
Iter: 475 loss: 2.10188373e-05
Iter: 476 loss: 2.1007625e-05
Iter: 477 loss: 2.0980151e-05
Iter: 478 loss: 2.12880186e-05
Iter: 479 loss: 2.09798018e-05
Iter: 480 loss: 2.0954154e-05
Iter: 481 loss: 2.09520367e-05
Iter: 482 loss: 2.09329937e-05
Iter: 483 loss: 2.09080099e-05
Iter: 484 loss: 2.09781283e-05
Iter: 485 loss: 2.08997189e-05
Iter: 486 loss: 2.086735e-05
Iter: 487 loss: 2.09786522e-05
Iter: 488 loss: 2.08582496e-05
Iter: 489 loss: 2.08340971e-05
Iter: 490 loss: 2.08243036e-05
Iter: 491 loss: 2.08116835e-05
Iter: 492 loss: 2.07768735e-05
Iter: 493 loss: 2.08162055e-05
Iter: 494 loss: 2.07584253e-05
Iter: 495 loss: 2.07338562e-05
Iter: 496 loss: 2.0732441e-05
Iter: 497 loss: 2.07082285e-05
Iter: 498 loss: 2.07072517e-05
Iter: 499 loss: 2.06885597e-05
Iter: 500 loss: 2.06627628e-05
Iter: 501 loss: 2.08195925e-05
Iter: 502 loss: 2.06597288e-05
Iter: 503 loss: 2.06368804e-05
Iter: 504 loss: 2.07045232e-05
Iter: 505 loss: 2.06294462e-05
Iter: 506 loss: 2.06057102e-05
Iter: 507 loss: 2.06270761e-05
Iter: 508 loss: 2.05919041e-05
Iter: 509 loss: 2.0562773e-05
Iter: 510 loss: 2.0618676e-05
Iter: 511 loss: 2.05504966e-05
Iter: 512 loss: 2.05257602e-05
Iter: 513 loss: 2.06152472e-05
Iter: 514 loss: 2.05194883e-05
Iter: 515 loss: 2.0493786e-05
Iter: 516 loss: 2.06406039e-05
Iter: 517 loss: 2.04902517e-05
Iter: 518 loss: 2.04734297e-05
Iter: 519 loss: 2.04494827e-05
Iter: 520 loss: 2.04483331e-05
Iter: 521 loss: 2.04214393e-05
Iter: 522 loss: 2.08246402e-05
Iter: 523 loss: 2.04213193e-05
Iter: 524 loss: 2.03983618e-05
Iter: 525 loss: 2.0371459e-05
Iter: 526 loss: 2.0368203e-05
Iter: 527 loss: 2.03351738e-05
Iter: 528 loss: 2.03458039e-05
Iter: 529 loss: 2.0311767e-05
Iter: 530 loss: 2.02911506e-05
Iter: 531 loss: 2.02875108e-05
Iter: 532 loss: 2.02646879e-05
Iter: 533 loss: 2.02782903e-05
Iter: 534 loss: 2.02500887e-05
Iter: 535 loss: 2.02265328e-05
Iter: 536 loss: 2.02971314e-05
Iter: 537 loss: 2.02195115e-05
Iter: 538 loss: 2.01959829e-05
Iter: 539 loss: 2.0350717e-05
Iter: 540 loss: 2.01938565e-05
Iter: 541 loss: 2.01759503e-05
Iter: 542 loss: 2.01632956e-05
Iter: 543 loss: 2.01571638e-05
Iter: 544 loss: 2.01241328e-05
Iter: 545 loss: 2.02148694e-05
Iter: 546 loss: 2.01138e-05
Iter: 547 loss: 2.00871073e-05
Iter: 548 loss: 2.01746698e-05
Iter: 549 loss: 2.00800059e-05
Iter: 550 loss: 2.00551513e-05
Iter: 551 loss: 2.02446899e-05
Iter: 552 loss: 2.00531013e-05
Iter: 553 loss: 2.00379163e-05
Iter: 554 loss: 2.00177947e-05
Iter: 555 loss: 2.00162358e-05
Iter: 556 loss: 1.99867936e-05
Iter: 557 loss: 2.01745679e-05
Iter: 558 loss: 1.9983072e-05
Iter: 559 loss: 1.9954372e-05
Iter: 560 loss: 2.0016796e-05
Iter: 561 loss: 1.9943358e-05
Iter: 562 loss: 1.99195183e-05
Iter: 563 loss: 1.98933776e-05
Iter: 564 loss: 1.98892831e-05
Iter: 565 loss: 1.9855077e-05
Iter: 566 loss: 2.01173189e-05
Iter: 567 loss: 1.98521593e-05
Iter: 568 loss: 1.98282451e-05
Iter: 569 loss: 1.98283869e-05
Iter: 570 loss: 1.98121379e-05
Iter: 571 loss: 1.97880145e-05
Iter: 572 loss: 1.97872778e-05
Iter: 573 loss: 1.97669506e-05
Iter: 574 loss: 1.97662957e-05
Iter: 575 loss: 1.97502522e-05
Iter: 576 loss: 1.97222234e-05
Iter: 577 loss: 1.97220652e-05
Iter: 578 loss: 1.96952642e-05
Iter: 579 loss: 1.99576534e-05
Iter: 580 loss: 1.96940964e-05
Iter: 581 loss: 1.96732344e-05
Iter: 582 loss: 1.96970086e-05
Iter: 583 loss: 1.96621586e-05
Iter: 584 loss: 1.96404308e-05
Iter: 585 loss: 1.97993231e-05
Iter: 586 loss: 1.963877e-05
Iter: 587 loss: 1.96185538e-05
Iter: 588 loss: 1.96039673e-05
Iter: 589 loss: 1.95970897e-05
Iter: 590 loss: 1.95747016e-05
Iter: 591 loss: 1.96917681e-05
Iter: 592 loss: 1.9570698e-05
Iter: 593 loss: 1.95446119e-05
Iter: 594 loss: 1.95941975e-05
Iter: 595 loss: 1.95331377e-05
Iter: 596 loss: 1.95053672e-05
Iter: 597 loss: 1.9510353e-05
Iter: 598 loss: 1.94846471e-05
Iter: 599 loss: 1.94547392e-05
Iter: 600 loss: 1.95541452e-05
Iter: 601 loss: 1.94469467e-05
Iter: 602 loss: 1.94274544e-05
Iter: 603 loss: 1.94274144e-05
Iter: 604 loss: 1.9408506e-05
Iter: 605 loss: 1.93986689e-05
Iter: 606 loss: 1.93900087e-05
Iter: 607 loss: 1.93707074e-05
Iter: 608 loss: 1.95189532e-05
Iter: 609 loss: 1.93690175e-05
Iter: 610 loss: 1.93482119e-05
Iter: 611 loss: 1.9361989e-05
Iter: 612 loss: 1.9334926e-05
Iter: 613 loss: 1.9314899e-05
Iter: 614 loss: 1.93147134e-05
Iter: 615 loss: 1.92989883e-05
Iter: 616 loss: 1.92719872e-05
Iter: 617 loss: 1.95171815e-05
Iter: 618 loss: 1.92708976e-05
Iter: 619 loss: 1.92506122e-05
Iter: 620 loss: 1.92788666e-05
Iter: 621 loss: 1.92405969e-05
Iter: 622 loss: 1.92171319e-05
Iter: 623 loss: 1.9322033e-05
Iter: 624 loss: 1.92126063e-05
Iter: 625 loss: 1.91933541e-05
Iter: 626 loss: 1.91787658e-05
Iter: 627 loss: 1.91725867e-05
Iter: 628 loss: 1.91520285e-05
Iter: 629 loss: 1.91517647e-05
Iter: 630 loss: 1.91323943e-05
Iter: 631 loss: 1.91058716e-05
Iter: 632 loss: 1.91047238e-05
Iter: 633 loss: 1.9076404e-05
Iter: 634 loss: 1.91430408e-05
Iter: 635 loss: 1.90659448e-05
Iter: 636 loss: 1.90419105e-05
Iter: 637 loss: 1.90422143e-05
Iter: 638 loss: 1.9020421e-05
Iter: 639 loss: 1.90183346e-05
Iter: 640 loss: 1.90024111e-05
Iter: 641 loss: 1.89792554e-05
Iter: 642 loss: 1.91051186e-05
Iter: 643 loss: 1.89757557e-05
Iter: 644 loss: 1.89532366e-05
Iter: 645 loss: 1.9027877e-05
Iter: 646 loss: 1.89472084e-05
Iter: 647 loss: 1.89309e-05
Iter: 648 loss: 1.89054372e-05
Iter: 649 loss: 1.89049952e-05
Iter: 650 loss: 1.88838494e-05
Iter: 651 loss: 1.88834674e-05
Iter: 652 loss: 1.88652048e-05
Iter: 653 loss: 1.88662889e-05
Iter: 654 loss: 1.88507311e-05
Iter: 655 loss: 1.88281738e-05
Iter: 656 loss: 1.89795137e-05
Iter: 657 loss: 1.88262602e-05
Iter: 658 loss: 1.8808536e-05
Iter: 659 loss: 1.87984551e-05
Iter: 660 loss: 1.87909573e-05
Iter: 661 loss: 1.87645983e-05
Iter: 662 loss: 1.88921331e-05
Iter: 663 loss: 1.87598962e-05
Iter: 664 loss: 1.8731e-05
Iter: 665 loss: 1.87976639e-05
Iter: 666 loss: 1.87204132e-05
Iter: 667 loss: 1.86983962e-05
Iter: 668 loss: 1.87056285e-05
Iter: 669 loss: 1.86826692e-05
Iter: 670 loss: 1.8654915e-05
Iter: 671 loss: 1.87292371e-05
Iter: 672 loss: 1.86454454e-05
Iter: 673 loss: 1.86195393e-05
Iter: 674 loss: 1.86195066e-05
Iter: 675 loss: 1.86067064e-05
Iter: 676 loss: 1.85874942e-05
Iter: 677 loss: 1.85867648e-05
Iter: 678 loss: 1.85611716e-05
Iter: 679 loss: 1.88333524e-05
Iter: 680 loss: 1.85601384e-05
Iter: 681 loss: 1.85435e-05
Iter: 682 loss: 1.85235313e-05
Iter: 683 loss: 1.8521323e-05
Iter: 684 loss: 1.84935161e-05
Iter: 685 loss: 1.85732169e-05
Iter: 686 loss: 1.84848213e-05
Iter: 687 loss: 1.8461109e-05
Iter: 688 loss: 1.8796989e-05
Iter: 689 loss: 1.84609653e-05
Iter: 690 loss: 1.84459022e-05
Iter: 691 loss: 1.84301898e-05
Iter: 692 loss: 1.8427696e-05
Iter: 693 loss: 1.84015225e-05
Iter: 694 loss: 1.85879544e-05
Iter: 695 loss: 1.8399287e-05
Iter: 696 loss: 1.83813536e-05
Iter: 697 loss: 1.83795291e-05
Iter: 698 loss: 1.83663869e-05
Iter: 699 loss: 1.83451484e-05
Iter: 700 loss: 1.85947356e-05
Iter: 701 loss: 1.83445882e-05
Iter: 702 loss: 1.83266966e-05
Iter: 703 loss: 1.8299037e-05
Iter: 704 loss: 1.82986732e-05
Iter: 705 loss: 1.82695749e-05
Iter: 706 loss: 1.83829034e-05
Iter: 707 loss: 1.82623735e-05
Iter: 708 loss: 1.824623e-05
Iter: 709 loss: 1.82449257e-05
Iter: 710 loss: 1.82306321e-05
Iter: 711 loss: 1.82034491e-05
Iter: 712 loss: 1.87627029e-05
Iter: 713 loss: 1.82034528e-05
Iter: 714 loss: 1.81871183e-05
Iter: 715 loss: 1.81858195e-05
Iter: 716 loss: 1.81718788e-05
Iter: 717 loss: 1.81564174e-05
Iter: 718 loss: 1.81544237e-05
Iter: 719 loss: 1.81317882e-05
Iter: 720 loss: 1.81431769e-05
Iter: 721 loss: 1.81164687e-05
Iter: 722 loss: 1.80963725e-05
Iter: 723 loss: 1.80961797e-05
Iter: 724 loss: 1.80793686e-05
Iter: 725 loss: 1.80714069e-05
Iter: 726 loss: 1.80630468e-05
Iter: 727 loss: 1.80398856e-05
Iter: 728 loss: 1.81039704e-05
Iter: 729 loss: 1.80320312e-05
Iter: 730 loss: 1.80071147e-05
Iter: 731 loss: 1.81027117e-05
Iter: 732 loss: 1.80009392e-05
Iter: 733 loss: 1.79818417e-05
Iter: 734 loss: 1.8028255e-05
Iter: 735 loss: 1.79750732e-05
Iter: 736 loss: 1.79544895e-05
Iter: 737 loss: 1.80401967e-05
Iter: 738 loss: 1.79498038e-05
Iter: 739 loss: 1.79306953e-05
Iter: 740 loss: 1.79181552e-05
Iter: 741 loss: 1.79108902e-05
Iter: 742 loss: 1.78962291e-05
Iter: 743 loss: 1.78961891e-05
Iter: 744 loss: 1.78796727e-05
Iter: 745 loss: 1.7873519e-05
Iter: 746 loss: 1.78644e-05
Iter: 747 loss: 1.78429873e-05
Iter: 748 loss: 1.78813334e-05
Iter: 749 loss: 1.78331647e-05
Iter: 750 loss: 1.78111513e-05
Iter: 751 loss: 1.8048715e-05
Iter: 752 loss: 1.7810602e-05
Iter: 753 loss: 1.77986767e-05
Iter: 754 loss: 1.77755064e-05
Iter: 755 loss: 1.82549047e-05
Iter: 756 loss: 1.77753227e-05
Iter: 757 loss: 1.77519305e-05
Iter: 758 loss: 1.79428316e-05
Iter: 759 loss: 1.77502134e-05
Iter: 760 loss: 1.77271722e-05
Iter: 761 loss: 1.78320988e-05
Iter: 762 loss: 1.77225702e-05
Iter: 763 loss: 1.77045622e-05
Iter: 764 loss: 1.76955473e-05
Iter: 765 loss: 1.76870017e-05
Iter: 766 loss: 1.76656431e-05
Iter: 767 loss: 1.78388182e-05
Iter: 768 loss: 1.76643643e-05
Iter: 769 loss: 1.76439971e-05
Iter: 770 loss: 1.76660924e-05
Iter: 771 loss: 1.76326848e-05
Iter: 772 loss: 1.76121048e-05
Iter: 773 loss: 1.76809954e-05
Iter: 774 loss: 1.76066969e-05
Iter: 775 loss: 1.758289e-05
Iter: 776 loss: 1.76297799e-05
Iter: 777 loss: 1.75730238e-05
Iter: 778 loss: 1.755622e-05
Iter: 779 loss: 1.75859859e-05
Iter: 780 loss: 1.75486894e-05
Iter: 781 loss: 1.75261957e-05
Iter: 782 loss: 1.76992344e-05
Iter: 783 loss: 1.7524435e-05
Iter: 784 loss: 1.7510245e-05
Iter: 785 loss: 1.74942215e-05
Iter: 786 loss: 1.74921661e-05
Iter: 787 loss: 1.74768484e-05
Iter: 788 loss: 1.74764937e-05
Iter: 789 loss: 1.74640409e-05
Iter: 790 loss: 1.74364832e-05
Iter: 791 loss: 1.78402861e-05
Iter: 792 loss: 1.7435239e-05
Iter: 793 loss: 1.74118777e-05
Iter: 794 loss: 1.75614732e-05
Iter: 795 loss: 1.7409302e-05
Iter: 796 loss: 1.73891149e-05
Iter: 797 loss: 1.76040758e-05
Iter: 798 loss: 1.73886074e-05
Iter: 799 loss: 1.7374763e-05
Iter: 800 loss: 1.73547633e-05
Iter: 801 loss: 1.73538974e-05
Iter: 802 loss: 1.73292829e-05
Iter: 803 loss: 1.74701363e-05
Iter: 804 loss: 1.73260105e-05
Iter: 805 loss: 1.73065091e-05
Iter: 806 loss: 1.74432625e-05
Iter: 807 loss: 1.73046064e-05
Iter: 808 loss: 1.7290211e-05
Iter: 809 loss: 1.72915788e-05
Iter: 810 loss: 1.72791606e-05
Iter: 811 loss: 1.72593464e-05
Iter: 812 loss: 1.73631088e-05
Iter: 813 loss: 1.72562613e-05
Iter: 814 loss: 1.72383134e-05
Iter: 815 loss: 1.72486361e-05
Iter: 816 loss: 1.72268119e-05
Iter: 817 loss: 1.72129166e-05
Iter: 818 loss: 1.72128421e-05
Iter: 819 loss: 1.72007603e-05
Iter: 820 loss: 1.71797747e-05
Iter: 821 loss: 1.71795418e-05
Iter: 822 loss: 1.71630163e-05
Iter: 823 loss: 1.73560184e-05
Iter: 824 loss: 1.71627271e-05
Iter: 825 loss: 1.71451229e-05
Iter: 826 loss: 1.71442898e-05
Iter: 827 loss: 1.71307402e-05
Iter: 828 loss: 1.71118518e-05
Iter: 829 loss: 1.71420834e-05
Iter: 830 loss: 1.71030642e-05
Iter: 831 loss: 1.70853473e-05
Iter: 832 loss: 1.7178776e-05
Iter: 833 loss: 1.70827207e-05
Iter: 834 loss: 1.70621097e-05
Iter: 835 loss: 1.71214015e-05
Iter: 836 loss: 1.70554158e-05
Iter: 837 loss: 1.70427102e-05
Iter: 838 loss: 1.70293824e-05
Iter: 839 loss: 1.70268395e-05
Iter: 840 loss: 1.70062485e-05
Iter: 841 loss: 1.72173368e-05
Iter: 842 loss: 1.7005761e-05
Iter: 843 loss: 1.6987764e-05
Iter: 844 loss: 1.70217663e-05
Iter: 845 loss: 1.69801169e-05
Iter: 846 loss: 1.69633749e-05
Iter: 847 loss: 1.69783543e-05
Iter: 848 loss: 1.69535979e-05
Iter: 849 loss: 1.69328378e-05
Iter: 850 loss: 1.7076818e-05
Iter: 851 loss: 1.6930815e-05
Iter: 852 loss: 1.6916194e-05
Iter: 853 loss: 1.69629511e-05
Iter: 854 loss: 1.69118885e-05
Iter: 855 loss: 1.68932129e-05
Iter: 856 loss: 1.6919239e-05
Iter: 857 loss: 1.6884067e-05
Iter: 858 loss: 1.68696752e-05
Iter: 859 loss: 1.68775641e-05
Iter: 860 loss: 1.68600927e-05
Iter: 861 loss: 1.68435872e-05
Iter: 862 loss: 1.70589465e-05
Iter: 863 loss: 1.68438e-05
Iter: 864 loss: 1.68326405e-05
Iter: 865 loss: 1.68080624e-05
Iter: 866 loss: 1.71609518e-05
Iter: 867 loss: 1.68069073e-05
Iter: 868 loss: 1.67839989e-05
Iter: 869 loss: 1.69572377e-05
Iter: 870 loss: 1.67823637e-05
Iter: 871 loss: 1.67620401e-05
Iter: 872 loss: 1.69506675e-05
Iter: 873 loss: 1.67613362e-05
Iter: 874 loss: 1.67489234e-05
Iter: 875 loss: 1.67269154e-05
Iter: 876 loss: 1.72760647e-05
Iter: 877 loss: 1.67268445e-05
Iter: 878 loss: 1.67027374e-05
Iter: 879 loss: 1.68626248e-05
Iter: 880 loss: 1.6700229e-05
Iter: 881 loss: 1.66827449e-05
Iter: 882 loss: 1.68619117e-05
Iter: 883 loss: 1.66821937e-05
Iter: 884 loss: 1.6668695e-05
Iter: 885 loss: 1.66496739e-05
Iter: 886 loss: 1.66489444e-05
Iter: 887 loss: 1.66314821e-05
Iter: 888 loss: 1.66315585e-05
Iter: 889 loss: 1.66175541e-05
Iter: 890 loss: 1.66411028e-05
Iter: 891 loss: 1.66113241e-05
Iter: 892 loss: 1.65954661e-05
Iter: 893 loss: 1.66661157e-05
Iter: 894 loss: 1.65923193e-05
Iter: 895 loss: 1.657955e-05
Iter: 896 loss: 1.65645797e-05
Iter: 897 loss: 1.65629717e-05
Iter: 898 loss: 1.65445763e-05
Iter: 899 loss: 1.67909384e-05
Iter: 900 loss: 1.65445563e-05
Iter: 901 loss: 1.65294368e-05
Iter: 902 loss: 1.65379024e-05
Iter: 903 loss: 1.65192141e-05
Iter: 904 loss: 1.65035872e-05
Iter: 905 loss: 1.64866251e-05
Iter: 906 loss: 1.64837984e-05
Iter: 907 loss: 1.64647463e-05
Iter: 908 loss: 1.64645953e-05
Iter: 909 loss: 1.644648e-05
Iter: 910 loss: 1.64621561e-05
Iter: 911 loss: 1.64357025e-05
Iter: 912 loss: 1.6421267e-05
Iter: 913 loss: 1.64179801e-05
Iter: 914 loss: 1.64087942e-05
Iter: 915 loss: 1.63897566e-05
Iter: 916 loss: 1.65146703e-05
Iter: 917 loss: 1.63877758e-05
Iter: 918 loss: 1.63692239e-05
Iter: 919 loss: 1.64510711e-05
Iter: 920 loss: 1.63655241e-05
Iter: 921 loss: 1.63499317e-05
Iter: 922 loss: 1.63492841e-05
Iter: 923 loss: 1.63371496e-05
Iter: 924 loss: 1.63204641e-05
Iter: 925 loss: 1.65422352e-05
Iter: 926 loss: 1.63202385e-05
Iter: 927 loss: 1.63054592e-05
Iter: 928 loss: 1.63198019e-05
Iter: 929 loss: 1.62971082e-05
Iter: 930 loss: 1.62821416e-05
Iter: 931 loss: 1.63174336e-05
Iter: 932 loss: 1.62768047e-05
Iter: 933 loss: 1.62598517e-05
Iter: 934 loss: 1.62808428e-05
Iter: 935 loss: 1.62512661e-05
Iter: 936 loss: 1.62375036e-05
Iter: 937 loss: 1.63919085e-05
Iter: 938 loss: 1.62370834e-05
Iter: 939 loss: 1.6224405e-05
Iter: 940 loss: 1.62067845e-05
Iter: 941 loss: 1.62061151e-05
Iter: 942 loss: 1.6185204e-05
Iter: 943 loss: 1.62073411e-05
Iter: 944 loss: 1.6173708e-05
Iter: 945 loss: 1.61541975e-05
Iter: 946 loss: 1.61535736e-05
Iter: 947 loss: 1.61416083e-05
Iter: 948 loss: 1.61203916e-05
Iter: 949 loss: 1.61204698e-05
Iter: 950 loss: 1.60982472e-05
Iter: 951 loss: 1.61509051e-05
Iter: 952 loss: 1.60903292e-05
Iter: 953 loss: 1.60724412e-05
Iter: 954 loss: 1.60724503e-05
Iter: 955 loss: 1.60573909e-05
Iter: 956 loss: 1.60489708e-05
Iter: 957 loss: 1.60424606e-05
Iter: 958 loss: 1.60271593e-05
Iter: 959 loss: 1.62001943e-05
Iter: 960 loss: 1.6027e-05
Iter: 961 loss: 1.60121454e-05
Iter: 962 loss: 1.60310501e-05
Iter: 963 loss: 1.60042655e-05
Iter: 964 loss: 1.59899064e-05
Iter: 965 loss: 1.60052368e-05
Iter: 966 loss: 1.59816645e-05
Iter: 967 loss: 1.59645897e-05
Iter: 968 loss: 1.6040085e-05
Iter: 969 loss: 1.59610026e-05
Iter: 970 loss: 1.59473202e-05
Iter: 971 loss: 1.59944429e-05
Iter: 972 loss: 1.59440151e-05
Iter: 973 loss: 1.5929003e-05
Iter: 974 loss: 1.59533956e-05
Iter: 975 loss: 1.59223291e-05
Iter: 976 loss: 1.59073e-05
Iter: 977 loss: 1.58955336e-05
Iter: 978 loss: 1.58909224e-05
Iter: 979 loss: 1.58768762e-05
Iter: 980 loss: 1.58760049e-05
Iter: 981 loss: 1.58626062e-05
Iter: 982 loss: 1.585469e-05
Iter: 983 loss: 1.58489347e-05
Iter: 984 loss: 1.5831487e-05
Iter: 985 loss: 1.58319453e-05
Iter: 986 loss: 1.58176881e-05
Iter: 987 loss: 1.57987924e-05
Iter: 988 loss: 1.59564443e-05
Iter: 989 loss: 1.57976101e-05
Iter: 990 loss: 1.57790691e-05
Iter: 991 loss: 1.58562634e-05
Iter: 992 loss: 1.57747563e-05
Iter: 993 loss: 1.57592913e-05
Iter: 994 loss: 1.57760587e-05
Iter: 995 loss: 1.57511822e-05
Iter: 996 loss: 1.5736714e-05
Iter: 997 loss: 1.59405281e-05
Iter: 998 loss: 1.57369323e-05
Iter: 999 loss: 1.57263403e-05
Iter: 1000 loss: 1.57076283e-05
Iter: 1001 loss: 1.61697735e-05
Iter: 1002 loss: 1.5707672e-05
Iter: 1003 loss: 1.56882179e-05
Iter: 1004 loss: 1.58282382e-05
Iter: 1005 loss: 1.5686659e-05
Iter: 1006 loss: 1.56707501e-05
Iter: 1007 loss: 1.5747717e-05
Iter: 1008 loss: 1.56678398e-05
Iter: 1009 loss: 1.56559017e-05
Iter: 1010 loss: 1.56828464e-05
Iter: 1011 loss: 1.56513761e-05
Iter: 1012 loss: 1.56362476e-05
Iter: 1013 loss: 1.56364986e-05
Iter: 1014 loss: 1.56242822e-05
Iter: 1015 loss: 1.56061433e-05
Iter: 1016 loss: 1.56563e-05
Iter: 1017 loss: 1.56000679e-05
Iter: 1018 loss: 1.55844918e-05
Iter: 1019 loss: 1.57753348e-05
Iter: 1020 loss: 1.55840971e-05
Iter: 1021 loss: 1.55718499e-05
Iter: 1022 loss: 1.55522248e-05
Iter: 1023 loss: 1.55519247e-05
Iter: 1024 loss: 1.5533129e-05
Iter: 1025 loss: 1.55611415e-05
Iter: 1026 loss: 1.55240377e-05
Iter: 1027 loss: 1.55073976e-05
Iter: 1028 loss: 1.55073794e-05
Iter: 1029 loss: 1.54915942e-05
Iter: 1030 loss: 1.5493737e-05
Iter: 1031 loss: 1.54795143e-05
Iter: 1032 loss: 1.546778e-05
Iter: 1033 loss: 1.54676291e-05
Iter: 1034 loss: 1.54565059e-05
Iter: 1035 loss: 1.54435766e-05
Iter: 1036 loss: 1.54421505e-05
Iter: 1037 loss: 1.5426187e-05
Iter: 1038 loss: 1.54513582e-05
Iter: 1039 loss: 1.54186637e-05
Iter: 1040 loss: 1.54001573e-05
Iter: 1041 loss: 1.55586367e-05
Iter: 1042 loss: 1.53990241e-05
Iter: 1043 loss: 1.53848177e-05
Iter: 1044 loss: 1.53968267e-05
Iter: 1045 loss: 1.53762448e-05
Iter: 1046 loss: 1.53609344e-05
Iter: 1047 loss: 1.54325498e-05
Iter: 1048 loss: 1.53581095e-05
Iter: 1049 loss: 1.5344478e-05
Iter: 1050 loss: 1.53346664e-05
Iter: 1051 loss: 1.53299625e-05
Iter: 1052 loss: 1.53162546e-05
Iter: 1053 loss: 1.53158762e-05
Iter: 1054 loss: 1.53041128e-05
Iter: 1055 loss: 1.5288846e-05
Iter: 1056 loss: 1.52881748e-05
Iter: 1057 loss: 1.52709508e-05
Iter: 1058 loss: 1.5310221e-05
Iter: 1059 loss: 1.52644388e-05
Iter: 1060 loss: 1.52448329e-05
Iter: 1061 loss: 1.52772627e-05
Iter: 1062 loss: 1.52361645e-05
Iter: 1063 loss: 1.52255707e-05
Iter: 1064 loss: 1.52240264e-05
Iter: 1065 loss: 1.52147113e-05
Iter: 1066 loss: 1.52059165e-05
Iter: 1067 loss: 1.52038965e-05
Iter: 1068 loss: 1.51904696e-05
Iter: 1069 loss: 1.53607725e-05
Iter: 1070 loss: 1.5190215e-05
Iter: 1071 loss: 1.51810082e-05
Iter: 1072 loss: 1.51630929e-05
Iter: 1073 loss: 1.55057241e-05
Iter: 1074 loss: 1.51627546e-05
Iter: 1075 loss: 1.51478343e-05
Iter: 1076 loss: 1.53854307e-05
Iter: 1077 loss: 1.51478489e-05
Iter: 1078 loss: 1.51347494e-05
Iter: 1079 loss: 1.51532413e-05
Iter: 1080 loss: 1.5128262e-05
Iter: 1081 loss: 1.51141103e-05
Iter: 1082 loss: 1.51252725e-05
Iter: 1083 loss: 1.51054455e-05
Iter: 1084 loss: 1.50890583e-05
Iter: 1085 loss: 1.51788099e-05
Iter: 1086 loss: 1.5086759e-05
Iter: 1087 loss: 1.50733867e-05
Iter: 1088 loss: 1.50845899e-05
Iter: 1089 loss: 1.50655233e-05
Iter: 1090 loss: 1.50495607e-05
Iter: 1091 loss: 1.51932154e-05
Iter: 1092 loss: 1.50489432e-05
Iter: 1093 loss: 1.50384967e-05
Iter: 1094 loss: 1.50264896e-05
Iter: 1095 loss: 1.50252254e-05
Iter: 1096 loss: 1.50082305e-05
Iter: 1097 loss: 1.5019521e-05
Iter: 1098 loss: 1.49970092e-05
Iter: 1099 loss: 1.49832467e-05
Iter: 1100 loss: 1.49829648e-05
Iter: 1101 loss: 1.49675734e-05
Iter: 1102 loss: 1.49684693e-05
Iter: 1103 loss: 1.49554035e-05
Iter: 1104 loss: 1.49427051e-05
Iter: 1105 loss: 1.5128232e-05
Iter: 1106 loss: 1.49427151e-05
Iter: 1107 loss: 1.49324442e-05
Iter: 1108 loss: 1.49219859e-05
Iter: 1109 loss: 1.49204543e-05
Iter: 1110 loss: 1.49046464e-05
Iter: 1111 loss: 1.49267835e-05
Iter: 1112 loss: 1.48970084e-05
Iter: 1113 loss: 1.48821382e-05
Iter: 1114 loss: 1.48821928e-05
Iter: 1115 loss: 1.48733561e-05
Iter: 1116 loss: 1.48604049e-05
Iter: 1117 loss: 1.48601257e-05
Iter: 1118 loss: 1.4845009e-05
Iter: 1119 loss: 1.49801954e-05
Iter: 1120 loss: 1.48444688e-05
Iter: 1121 loss: 1.48324652e-05
Iter: 1122 loss: 1.48482568e-05
Iter: 1123 loss: 1.4826539e-05
Iter: 1124 loss: 1.48127183e-05
Iter: 1125 loss: 1.48750532e-05
Iter: 1126 loss: 1.4809616e-05
Iter: 1127 loss: 1.4795256e-05
Iter: 1128 loss: 1.47952178e-05
Iter: 1129 loss: 1.4783689e-05
Iter: 1130 loss: 1.4768013e-05
Iter: 1131 loss: 1.47848368e-05
Iter: 1132 loss: 1.47589581e-05
Iter: 1133 loss: 1.47407391e-05
Iter: 1134 loss: 1.48104327e-05
Iter: 1135 loss: 1.47363799e-05
Iter: 1136 loss: 1.47212995e-05
Iter: 1137 loss: 1.47214141e-05
Iter: 1138 loss: 1.47118526e-05
Iter: 1139 loss: 1.47103365e-05
Iter: 1140 loss: 1.470395e-05
Iter: 1141 loss: 1.46922539e-05
Iter: 1142 loss: 1.47985247e-05
Iter: 1143 loss: 1.4691781e-05
Iter: 1144 loss: 1.4683239e-05
Iter: 1145 loss: 1.46625935e-05
Iter: 1146 loss: 1.48770623e-05
Iter: 1147 loss: 1.4660086e-05
Iter: 1148 loss: 1.46531984e-05
Iter: 1149 loss: 1.46484917e-05
Iter: 1150 loss: 1.46380553e-05
Iter: 1151 loss: 1.46228467e-05
Iter: 1152 loss: 1.46224793e-05
Iter: 1153 loss: 1.46059829e-05
Iter: 1154 loss: 1.46666362e-05
Iter: 1155 loss: 1.4601892e-05
Iter: 1156 loss: 1.45850527e-05
Iter: 1157 loss: 1.46820039e-05
Iter: 1158 loss: 1.45827426e-05
Iter: 1159 loss: 1.45704007e-05
Iter: 1160 loss: 1.46048333e-05
Iter: 1161 loss: 1.45666982e-05
Iter: 1162 loss: 1.45533877e-05
Iter: 1163 loss: 1.45832337e-05
Iter: 1164 loss: 1.45483282e-05
Iter: 1165 loss: 1.45358354e-05
Iter: 1166 loss: 1.45254189e-05
Iter: 1167 loss: 1.45220065e-05
Iter: 1168 loss: 1.4502948e-05
Iter: 1169 loss: 1.45646854e-05
Iter: 1170 loss: 1.4497441e-05
Iter: 1171 loss: 1.44874621e-05
Iter: 1172 loss: 1.44863752e-05
Iter: 1173 loss: 1.44775686e-05
Iter: 1174 loss: 1.44730984e-05
Iter: 1175 loss: 1.44689502e-05
Iter: 1176 loss: 1.44572095e-05
Iter: 1177 loss: 1.45183758e-05
Iter: 1178 loss: 1.44553278e-05
Iter: 1179 loss: 1.44425458e-05
Iter: 1180 loss: 1.44381947e-05
Iter: 1181 loss: 1.44311189e-05
Iter: 1182 loss: 1.44159185e-05
Iter: 1183 loss: 1.44626929e-05
Iter: 1184 loss: 1.44112419e-05
Iter: 1185 loss: 1.43996676e-05
Iter: 1186 loss: 1.45726208e-05
Iter: 1187 loss: 1.4399835e-05
Iter: 1188 loss: 1.43910647e-05
Iter: 1189 loss: 1.43723637e-05
Iter: 1190 loss: 1.46560378e-05
Iter: 1191 loss: 1.43712468e-05
Iter: 1192 loss: 1.43549187e-05
Iter: 1193 loss: 1.45305194e-05
Iter: 1194 loss: 1.43544958e-05
Iter: 1195 loss: 1.43396164e-05
Iter: 1196 loss: 1.44061542e-05
Iter: 1197 loss: 1.43367697e-05
Iter: 1198 loss: 1.43255511e-05
Iter: 1199 loss: 1.43424168e-05
Iter: 1200 loss: 1.43201942e-05
Iter: 1201 loss: 1.43062935e-05
Iter: 1202 loss: 1.43314264e-05
Iter: 1203 loss: 1.43000943e-05
Iter: 1204 loss: 1.42859826e-05
Iter: 1205 loss: 1.42827348e-05
Iter: 1206 loss: 1.42738154e-05
Iter: 1207 loss: 1.42614444e-05
Iter: 1208 loss: 1.44527057e-05
Iter: 1209 loss: 1.42613299e-05
Iter: 1210 loss: 1.42482895e-05
Iter: 1211 loss: 1.42809786e-05
Iter: 1212 loss: 1.42435256e-05
Iter: 1213 loss: 1.4234216e-05
Iter: 1214 loss: 1.42424842e-05
Iter: 1215 loss: 1.42287681e-05
Iter: 1216 loss: 1.42151021e-05
Iter: 1217 loss: 1.42603585e-05
Iter: 1218 loss: 1.42112185e-05
Iter: 1219 loss: 1.42009258e-05
Iter: 1220 loss: 1.41984192e-05
Iter: 1221 loss: 1.41918454e-05
Iter: 1222 loss: 1.4178142e-05
Iter: 1223 loss: 1.43172911e-05
Iter: 1224 loss: 1.41775272e-05
Iter: 1225 loss: 1.41651244e-05
Iter: 1226 loss: 1.41704168e-05
Iter: 1227 loss: 1.41568471e-05
Iter: 1228 loss: 1.41445908e-05
Iter: 1229 loss: 1.41422697e-05
Iter: 1230 loss: 1.41341079e-05
Iter: 1231 loss: 1.41226046e-05
Iter: 1232 loss: 1.41223036e-05
Iter: 1233 loss: 1.4113034e-05
Iter: 1234 loss: 1.4108613e-05
Iter: 1235 loss: 1.41039018e-05
Iter: 1236 loss: 1.40926159e-05
Iter: 1237 loss: 1.41625696e-05
Iter: 1238 loss: 1.40914326e-05
Iter: 1239 loss: 1.40806897e-05
Iter: 1240 loss: 1.40778238e-05
Iter: 1241 loss: 1.40713728e-05
Iter: 1242 loss: 1.40568891e-05
Iter: 1243 loss: 1.41007504e-05
Iter: 1244 loss: 1.40528418e-05
Iter: 1245 loss: 1.40428829e-05
Iter: 1246 loss: 1.40427037e-05
Iter: 1247 loss: 1.40348238e-05
Iter: 1248 loss: 1.40211168e-05
Iter: 1249 loss: 1.40208931e-05
Iter: 1250 loss: 1.40081247e-05
Iter: 1251 loss: 1.41481596e-05
Iter: 1252 loss: 1.40079674e-05
Iter: 1253 loss: 1.39962785e-05
Iter: 1254 loss: 1.40009488e-05
Iter: 1255 loss: 1.39882959e-05
Iter: 1256 loss: 1.39761287e-05
Iter: 1257 loss: 1.39988952e-05
Iter: 1258 loss: 1.39711337e-05
Iter: 1259 loss: 1.39572658e-05
Iter: 1260 loss: 1.40763059e-05
Iter: 1261 loss: 1.39566582e-05
Iter: 1262 loss: 1.39467584e-05
Iter: 1263 loss: 1.39336717e-05
Iter: 1264 loss: 1.39331487e-05
Iter: 1265 loss: 1.39183521e-05
Iter: 1266 loss: 1.39916929e-05
Iter: 1267 loss: 1.39156946e-05
Iter: 1268 loss: 1.39043132e-05
Iter: 1269 loss: 1.40582315e-05
Iter: 1270 loss: 1.39040903e-05
Iter: 1271 loss: 1.38957339e-05
Iter: 1272 loss: 1.38803216e-05
Iter: 1273 loss: 1.42529416e-05
Iter: 1274 loss: 1.38803871e-05
Iter: 1275 loss: 1.38679616e-05
Iter: 1276 loss: 1.38681644e-05
Iter: 1277 loss: 1.38579908e-05
Iter: 1278 loss: 1.38491832e-05
Iter: 1279 loss: 1.38461855e-05
Iter: 1280 loss: 1.38352443e-05
Iter: 1281 loss: 1.38353153e-05
Iter: 1282 loss: 1.38233909e-05
Iter: 1283 loss: 1.38274672e-05
Iter: 1284 loss: 1.38154492e-05
Iter: 1285 loss: 1.38057676e-05
Iter: 1286 loss: 1.38169917e-05
Iter: 1287 loss: 1.38006235e-05
Iter: 1288 loss: 1.37861171e-05
Iter: 1289 loss: 1.38388532e-05
Iter: 1290 loss: 1.37824391e-05
Iter: 1291 loss: 1.3770521e-05
Iter: 1292 loss: 1.37813349e-05
Iter: 1293 loss: 1.37635088e-05
Iter: 1294 loss: 1.37529678e-05
Iter: 1295 loss: 1.38707492e-05
Iter: 1296 loss: 1.37527213e-05
Iter: 1297 loss: 1.37431034e-05
Iter: 1298 loss: 1.3737108e-05
Iter: 1299 loss: 1.37334127e-05
Iter: 1300 loss: 1.37204706e-05
Iter: 1301 loss: 1.37223033e-05
Iter: 1302 loss: 1.37104271e-05
Iter: 1303 loss: 1.36991112e-05
Iter: 1304 loss: 1.36988338e-05
Iter: 1305 loss: 1.36886965e-05
Iter: 1306 loss: 1.37041516e-05
Iter: 1307 loss: 1.36839808e-05
Iter: 1308 loss: 1.36735725e-05
Iter: 1309 loss: 1.36635299e-05
Iter: 1310 loss: 1.36611561e-05
Iter: 1311 loss: 1.36485141e-05
Iter: 1312 loss: 1.3848301e-05
Iter: 1313 loss: 1.36484796e-05
Iter: 1314 loss: 1.36385888e-05
Iter: 1315 loss: 1.3640175e-05
Iter: 1316 loss: 1.36308836e-05
Iter: 1317 loss: 1.36205217e-05
Iter: 1318 loss: 1.36206136e-05
Iter: 1319 loss: 1.36123781e-05
Iter: 1320 loss: 1.35954469e-05
Iter: 1321 loss: 1.38771011e-05
Iter: 1322 loss: 1.35949012e-05
Iter: 1323 loss: 1.35808095e-05
Iter: 1324 loss: 1.37545248e-05
Iter: 1325 loss: 1.35808705e-05
Iter: 1326 loss: 1.35684795e-05
Iter: 1327 loss: 1.35966684e-05
Iter: 1328 loss: 1.35637674e-05
Iter: 1329 loss: 1.35539867e-05
Iter: 1330 loss: 1.35564751e-05
Iter: 1331 loss: 1.35470154e-05
Iter: 1332 loss: 1.35330483e-05
Iter: 1333 loss: 1.36599547e-05
Iter: 1334 loss: 1.35323262e-05
Iter: 1335 loss: 1.35245737e-05
Iter: 1336 loss: 1.35148994e-05
Iter: 1337 loss: 1.35142327e-05
Iter: 1338 loss: 1.35012251e-05
Iter: 1339 loss: 1.35570881e-05
Iter: 1340 loss: 1.34985567e-05
Iter: 1341 loss: 1.3487941e-05
Iter: 1342 loss: 1.3613575e-05
Iter: 1343 loss: 1.34876409e-05
Iter: 1344 loss: 1.34787806e-05
Iter: 1345 loss: 1.34671591e-05
Iter: 1346 loss: 1.34664679e-05
Iter: 1347 loss: 1.34516631e-05
Iter: 1348 loss: 1.3486916e-05
Iter: 1349 loss: 1.34463726e-05
Iter: 1350 loss: 1.34325983e-05
Iter: 1351 loss: 1.35829087e-05
Iter: 1352 loss: 1.34325546e-05
Iter: 1353 loss: 1.34228358e-05
Iter: 1354 loss: 1.34515476e-05
Iter: 1355 loss: 1.34200563e-05
Iter: 1356 loss: 1.34088887e-05
Iter: 1357 loss: 1.34349848e-05
Iter: 1358 loss: 1.34047095e-05
Iter: 1359 loss: 1.33956682e-05
Iter: 1360 loss: 1.33837266e-05
Iter: 1361 loss: 1.33828507e-05
Iter: 1362 loss: 1.33720805e-05
Iter: 1363 loss: 1.33716821e-05
Iter: 1364 loss: 1.33633666e-05
Iter: 1365 loss: 1.3357956e-05
Iter: 1366 loss: 1.33548801e-05
Iter: 1367 loss: 1.33425165e-05
Iter: 1368 loss: 1.33928643e-05
Iter: 1369 loss: 1.33399762e-05
Iter: 1370 loss: 1.3326e-05
Iter: 1371 loss: 1.33641697e-05
Iter: 1372 loss: 1.3321408e-05
Iter: 1373 loss: 1.33101621e-05
Iter: 1374 loss: 1.33056274e-05
Iter: 1375 loss: 1.3299581e-05
Iter: 1376 loss: 1.3287281e-05
Iter: 1377 loss: 1.33785943e-05
Iter: 1378 loss: 1.32863897e-05
Iter: 1379 loss: 1.32730529e-05
Iter: 1380 loss: 1.33250451e-05
Iter: 1381 loss: 1.32702162e-05
Iter: 1382 loss: 1.32609666e-05
Iter: 1383 loss: 1.32543864e-05
Iter: 1384 loss: 1.32509749e-05
Iter: 1385 loss: 1.32377536e-05
Iter: 1386 loss: 1.3282599e-05
Iter: 1387 loss: 1.32343766e-05
Iter: 1388 loss: 1.32207806e-05
Iter: 1389 loss: 1.33641706e-05
Iter: 1390 loss: 1.32204123e-05
Iter: 1391 loss: 1.32127607e-05
Iter: 1392 loss: 1.32378163e-05
Iter: 1393 loss: 1.32103141e-05
Iter: 1394 loss: 1.32016721e-05
Iter: 1395 loss: 1.31913239e-05
Iter: 1396 loss: 1.31902261e-05
Iter: 1397 loss: 1.31766183e-05
Iter: 1398 loss: 1.32251753e-05
Iter: 1399 loss: 1.31730958e-05
Iter: 1400 loss: 1.31610059e-05
Iter: 1401 loss: 1.32849036e-05
Iter: 1402 loss: 1.31605229e-05
Iter: 1403 loss: 1.31523166e-05
Iter: 1404 loss: 1.31444558e-05
Iter: 1405 loss: 1.31423849e-05
Iter: 1406 loss: 1.31306952e-05
Iter: 1407 loss: 1.32663263e-05
Iter: 1408 loss: 1.31304505e-05
Iter: 1409 loss: 1.3120185e-05
Iter: 1410 loss: 1.31136867e-05
Iter: 1411 loss: 1.31094394e-05
Iter: 1412 loss: 1.30976787e-05
Iter: 1413 loss: 1.31278939e-05
Iter: 1414 loss: 1.30933267e-05
Iter: 1415 loss: 1.30835906e-05
Iter: 1416 loss: 1.31912921e-05
Iter: 1417 loss: 1.30833541e-05
Iter: 1418 loss: 1.30735698e-05
Iter: 1419 loss: 1.30732433e-05
Iter: 1420 loss: 1.30656435e-05
Iter: 1421 loss: 1.30538092e-05
Iter: 1422 loss: 1.30490371e-05
Iter: 1423 loss: 1.30426433e-05
Iter: 1424 loss: 1.3029764e-05
Iter: 1425 loss: 1.32280711e-05
Iter: 1426 loss: 1.30297349e-05
Iter: 1427 loss: 1.30184944e-05
Iter: 1428 loss: 1.3068161e-05
Iter: 1429 loss: 1.30161088e-05
Iter: 1430 loss: 1.30086437e-05
Iter: 1431 loss: 1.30141116e-05
Iter: 1432 loss: 1.30040726e-05
Iter: 1433 loss: 1.29918626e-05
Iter: 1434 loss: 1.29904492e-05
Iter: 1435 loss: 1.29817081e-05
Iter: 1436 loss: 1.29719419e-05
Iter: 1437 loss: 1.30646786e-05
Iter: 1438 loss: 1.2971529e-05
Iter: 1439 loss: 1.29614655e-05
Iter: 1440 loss: 1.29774071e-05
Iter: 1441 loss: 1.2956616e-05
Iter: 1442 loss: 1.29474975e-05
Iter: 1443 loss: 1.29531854e-05
Iter: 1444 loss: 1.29416576e-05
Iter: 1445 loss: 1.29280816e-05
Iter: 1446 loss: 1.30086237e-05
Iter: 1447 loss: 1.29262698e-05
Iter: 1448 loss: 1.29170012e-05
Iter: 1449 loss: 1.29107921e-05
Iter: 1450 loss: 1.29071605e-05
Iter: 1451 loss: 1.28932052e-05
Iter: 1452 loss: 1.29266555e-05
Iter: 1453 loss: 1.28879274e-05
Iter: 1454 loss: 1.28763741e-05
Iter: 1455 loss: 1.28763459e-05
Iter: 1456 loss: 1.28684042e-05
Iter: 1457 loss: 1.28538559e-05
Iter: 1458 loss: 1.31759816e-05
Iter: 1459 loss: 1.28539059e-05
Iter: 1460 loss: 1.28404754e-05
Iter: 1461 loss: 1.2944919e-05
Iter: 1462 loss: 1.28394249e-05
Iter: 1463 loss: 1.28299671e-05
Iter: 1464 loss: 1.29458876e-05
Iter: 1465 loss: 1.28298016e-05
Iter: 1466 loss: 1.28208476e-05
Iter: 1467 loss: 1.28076063e-05
Iter: 1468 loss: 1.28072916e-05
Iter: 1469 loss: 1.27949661e-05
Iter: 1470 loss: 1.29201935e-05
Iter: 1471 loss: 1.27945441e-05
Iter: 1472 loss: 1.27846952e-05
Iter: 1473 loss: 1.27838757e-05
Iter: 1474 loss: 1.27764633e-05
Iter: 1475 loss: 1.27665789e-05
Iter: 1476 loss: 1.2882314e-05
Iter: 1477 loss: 1.27664734e-05
Iter: 1478 loss: 1.27565454e-05
Iter: 1479 loss: 1.27539333e-05
Iter: 1480 loss: 1.27480371e-05
Iter: 1481 loss: 1.27380445e-05
Iter: 1482 loss: 1.27970579e-05
Iter: 1483 loss: 1.27368712e-05
Iter: 1484 loss: 1.27252315e-05
Iter: 1485 loss: 1.27331796e-05
Iter: 1486 loss: 1.27181947e-05
Iter: 1487 loss: 1.2706083e-05
Iter: 1488 loss: 1.2716393e-05
Iter: 1489 loss: 1.26989489e-05
Iter: 1490 loss: 1.26865507e-05
Iter: 1491 loss: 1.27566591e-05
Iter: 1492 loss: 1.2684779e-05
Iter: 1493 loss: 1.26731957e-05
Iter: 1494 loss: 1.27539606e-05
Iter: 1495 loss: 1.26723171e-05
Iter: 1496 loss: 1.26647219e-05
Iter: 1497 loss: 1.26481409e-05
Iter: 1498 loss: 1.28923684e-05
Iter: 1499 loss: 1.26470986e-05
Iter: 1500 loss: 1.26349587e-05
Iter: 1501 loss: 1.26348104e-05
Iter: 1502 loss: 1.26224513e-05
Iter: 1503 loss: 1.26742252e-05
Iter: 1504 loss: 1.26198829e-05
Iter: 1505 loss: 1.26123268e-05
Iter: 1506 loss: 1.26028972e-05
Iter: 1507 loss: 1.26020259e-05
Iter: 1508 loss: 1.25880451e-05
Iter: 1509 loss: 1.27049043e-05
Iter: 1510 loss: 1.25874267e-05
Iter: 1511 loss: 1.25782735e-05
Iter: 1512 loss: 1.25871702e-05
Iter: 1513 loss: 1.25731567e-05
Iter: 1514 loss: 1.25631759e-05
Iter: 1515 loss: 1.26470495e-05
Iter: 1516 loss: 1.25623737e-05
Iter: 1517 loss: 1.25543511e-05
Iter: 1518 loss: 1.2546685e-05
Iter: 1519 loss: 1.25446095e-05
Iter: 1520 loss: 1.25329398e-05
Iter: 1521 loss: 1.26356263e-05
Iter: 1522 loss: 1.25322131e-05
Iter: 1523 loss: 1.25210618e-05
Iter: 1524 loss: 1.25280258e-05
Iter: 1525 loss: 1.25140305e-05
Iter: 1526 loss: 1.25032875e-05
Iter: 1527 loss: 1.25116512e-05
Iter: 1528 loss: 1.24967191e-05
Iter: 1529 loss: 1.24859253e-05
Iter: 1530 loss: 1.26394953e-05
Iter: 1531 loss: 1.24857588e-05
Iter: 1532 loss: 1.24763465e-05
Iter: 1533 loss: 1.24750422e-05
Iter: 1534 loss: 1.24686167e-05
Iter: 1535 loss: 1.24575599e-05
Iter: 1536 loss: 1.24581711e-05
Iter: 1537 loss: 1.24489134e-05
Iter: 1538 loss: 1.24431408e-05
Iter: 1539 loss: 1.24414437e-05
Iter: 1540 loss: 1.24342005e-05
Iter: 1541 loss: 1.24247081e-05
Iter: 1542 loss: 1.24241069e-05
Iter: 1543 loss: 1.24132357e-05
Iter: 1544 loss: 1.24200387e-05
Iter: 1545 loss: 1.24060844e-05
Iter: 1546 loss: 1.23930386e-05
Iter: 1547 loss: 1.25481765e-05
Iter: 1548 loss: 1.23929713e-05
Iter: 1549 loss: 1.23848267e-05
Iter: 1550 loss: 1.23904256e-05
Iter: 1551 loss: 1.23800473e-05
Iter: 1552 loss: 1.23688624e-05
Iter: 1553 loss: 1.24280623e-05
Iter: 1554 loss: 1.23669543e-05
Iter: 1555 loss: 1.23588725e-05
Iter: 1556 loss: 1.23564923e-05
Iter: 1557 loss: 1.23513473e-05
Iter: 1558 loss: 1.23406735e-05
Iter: 1559 loss: 1.24492144e-05
Iter: 1560 loss: 1.23404279e-05
Iter: 1561 loss: 1.23314885e-05
Iter: 1562 loss: 1.23201671e-05
Iter: 1563 loss: 1.23193749e-05
Iter: 1564 loss: 1.23071159e-05
Iter: 1565 loss: 1.23815407e-05
Iter: 1566 loss: 1.23055306e-05
Iter: 1567 loss: 1.22961919e-05
Iter: 1568 loss: 1.23943937e-05
Iter: 1569 loss: 1.22958054e-05
Iter: 1570 loss: 1.22882775e-05
Iter: 1571 loss: 1.2278294e-05
Iter: 1572 loss: 1.2277751e-05
Iter: 1573 loss: 1.22664733e-05
Iter: 1574 loss: 1.231241e-05
Iter: 1575 loss: 1.22639258e-05
Iter: 1576 loss: 1.22551864e-05
Iter: 1577 loss: 1.22551082e-05
Iter: 1578 loss: 1.22485762e-05
Iter: 1579 loss: 1.22339807e-05
Iter: 1580 loss: 1.24485905e-05
Iter: 1581 loss: 1.22330912e-05
Iter: 1582 loss: 1.22200327e-05
Iter: 1583 loss: 1.2285881e-05
Iter: 1584 loss: 1.22180127e-05
Iter: 1585 loss: 1.22056354e-05
Iter: 1586 loss: 1.23062837e-05
Iter: 1587 loss: 1.22049987e-05
Iter: 1588 loss: 1.21962803e-05
Iter: 1589 loss: 1.22045194e-05
Iter: 1590 loss: 1.21912453e-05
Iter: 1591 loss: 1.2179411e-05
Iter: 1592 loss: 1.22257534e-05
Iter: 1593 loss: 1.21766716e-05
Iter: 1594 loss: 1.21679041e-05
Iter: 1595 loss: 1.21771536e-05
Iter: 1596 loss: 1.21627127e-05
Iter: 1597 loss: 1.21517205e-05
Iter: 1598 loss: 1.22048768e-05
Iter: 1599 loss: 1.21498042e-05
Iter: 1600 loss: 1.21394087e-05
Iter: 1601 loss: 1.21446283e-05
Iter: 1602 loss: 1.21323374e-05
Iter: 1603 loss: 1.21209105e-05
Iter: 1604 loss: 1.2130713e-05
Iter: 1605 loss: 1.21145395e-05
Iter: 1606 loss: 1.21027479e-05
Iter: 1607 loss: 1.21026187e-05
Iter: 1608 loss: 1.20964414e-05
Iter: 1609 loss: 1.20822333e-05
Iter: 1610 loss: 1.22614765e-05
Iter: 1611 loss: 1.20811537e-05
Iter: 1612 loss: 1.2070479e-05
Iter: 1613 loss: 1.20703644e-05
Iter: 1614 loss: 1.20601071e-05
Iter: 1615 loss: 1.20944133e-05
Iter: 1616 loss: 1.20573086e-05
Iter: 1617 loss: 1.20509603e-05
Iter: 1618 loss: 1.20376808e-05
Iter: 1619 loss: 1.22801885e-05
Iter: 1620 loss: 1.20374762e-05
Iter: 1621 loss: 1.20244504e-05
Iter: 1622 loss: 1.21574067e-05
Iter: 1623 loss: 1.20240074e-05
Iter: 1624 loss: 1.20125533e-05
Iter: 1625 loss: 1.20666919e-05
Iter: 1626 loss: 1.20106897e-05
Iter: 1627 loss: 1.20014192e-05
Iter: 1628 loss: 1.20182794e-05
Iter: 1629 loss: 1.19971191e-05
Iter: 1630 loss: 1.19862852e-05
Iter: 1631 loss: 1.20166524e-05
Iter: 1632 loss: 1.19824263e-05
Iter: 1633 loss: 1.19724536e-05
Iter: 1634 loss: 1.19885244e-05
Iter: 1635 loss: 1.19678716e-05
Iter: 1636 loss: 1.19575097e-05
Iter: 1637 loss: 1.20240929e-05
Iter: 1638 loss: 1.19562665e-05
Iter: 1639 loss: 1.19479155e-05
Iter: 1640 loss: 1.19411952e-05
Iter: 1641 loss: 1.19384258e-05
Iter: 1642 loss: 1.19282995e-05
Iter: 1643 loss: 1.20216719e-05
Iter: 1644 loss: 1.19279612e-05
Iter: 1645 loss: 1.19189435e-05
Iter: 1646 loss: 1.19573006e-05
Iter: 1647 loss: 1.19171282e-05
Iter: 1648 loss: 1.19091783e-05
Iter: 1649 loss: 1.1896248e-05
Iter: 1650 loss: 1.18965072e-05
Iter: 1651 loss: 1.1888229e-05
Iter: 1652 loss: 1.18876933e-05
Iter: 1653 loss: 1.18789567e-05
Iter: 1654 loss: 1.18819244e-05
Iter: 1655 loss: 1.18725584e-05
Iter: 1656 loss: 1.18642238e-05
Iter: 1657 loss: 1.18514845e-05
Iter: 1658 loss: 1.18512307e-05
Iter: 1659 loss: 1.18382022e-05
Iter: 1660 loss: 1.19715824e-05
Iter: 1661 loss: 1.18378393e-05
Iter: 1662 loss: 1.1826809e-05
Iter: 1663 loss: 1.19063234e-05
Iter: 1664 loss: 1.18257676e-05
Iter: 1665 loss: 1.18184707e-05
Iter: 1666 loss: 1.18240623e-05
Iter: 1667 loss: 1.18141179e-05
Iter: 1668 loss: 1.18030093e-05
Iter: 1669 loss: 1.18271346e-05
Iter: 1670 loss: 1.17986383e-05
Iter: 1671 loss: 1.17896534e-05
Iter: 1672 loss: 1.18180669e-05
Iter: 1673 loss: 1.17870368e-05
Iter: 1674 loss: 1.17772097e-05
Iter: 1675 loss: 1.18044754e-05
Iter: 1676 loss: 1.17740492e-05
Iter: 1677 loss: 1.17638592e-05
Iter: 1678 loss: 1.17651589e-05
Iter: 1679 loss: 1.17563759e-05
Iter: 1680 loss: 1.17459822e-05
Iter: 1681 loss: 1.18288135e-05
Iter: 1682 loss: 1.17451109e-05
Iter: 1683 loss: 1.17344443e-05
Iter: 1684 loss: 1.17558129e-05
Iter: 1685 loss: 1.17302625e-05
Iter: 1686 loss: 1.1722319e-05
Iter: 1687 loss: 1.17188556e-05
Iter: 1688 loss: 1.17146374e-05
Iter: 1689 loss: 1.17065347e-05
Iter: 1690 loss: 1.17062309e-05
Iter: 1691 loss: 1.16991214e-05
Iter: 1692 loss: 1.1693649e-05
Iter: 1693 loss: 1.16915844e-05
Iter: 1694 loss: 1.16820993e-05
Iter: 1695 loss: 1.16728243e-05
Iter: 1696 loss: 1.16708325e-05
Iter: 1697 loss: 1.16561578e-05
Iter: 1698 loss: 1.17389782e-05
Iter: 1699 loss: 1.16539122e-05
Iter: 1700 loss: 1.16449701e-05
Iter: 1701 loss: 1.16448864e-05
Iter: 1702 loss: 1.16374358e-05
Iter: 1703 loss: 1.16347728e-05
Iter: 1704 loss: 1.1630591e-05
Iter: 1705 loss: 1.16202064e-05
Iter: 1706 loss: 1.16743186e-05
Iter: 1707 loss: 1.16186e-05
Iter: 1708 loss: 1.16095653e-05
Iter: 1709 loss: 1.16248757e-05
Iter: 1710 loss: 1.16052506e-05
Iter: 1711 loss: 1.15958537e-05
Iter: 1712 loss: 1.16202418e-05
Iter: 1713 loss: 1.15929497e-05
Iter: 1714 loss: 1.15823032e-05
Iter: 1715 loss: 1.16160318e-05
Iter: 1716 loss: 1.15796247e-05
Iter: 1717 loss: 1.15716093e-05
Iter: 1718 loss: 1.15706498e-05
Iter: 1719 loss: 1.15650419e-05
Iter: 1720 loss: 1.15539533e-05
Iter: 1721 loss: 1.16900583e-05
Iter: 1722 loss: 1.15539078e-05
Iter: 1723 loss: 1.1546791e-05
Iter: 1724 loss: 1.15353077e-05
Iter: 1725 loss: 1.15352104e-05
Iter: 1726 loss: 1.15279126e-05
Iter: 1727 loss: 1.15275925e-05
Iter: 1728 loss: 1.15193861e-05
Iter: 1729 loss: 1.15149105e-05
Iter: 1730 loss: 1.15109542e-05
Iter: 1731 loss: 1.15022103e-05
Iter: 1732 loss: 1.14984105e-05
Iter: 1733 loss: 1.14938302e-05
Iter: 1734 loss: 1.14812801e-05
Iter: 1735 loss: 1.15377607e-05
Iter: 1736 loss: 1.147886e-05
Iter: 1737 loss: 1.14714385e-05
Iter: 1738 loss: 1.14714185e-05
Iter: 1739 loss: 1.14644063e-05
Iter: 1740 loss: 1.14574977e-05
Iter: 1741 loss: 1.14560908e-05
Iter: 1742 loss: 1.14444902e-05
Iter: 1743 loss: 1.15103012e-05
Iter: 1744 loss: 1.14431932e-05
Iter: 1745 loss: 1.14334271e-05
Iter: 1746 loss: 1.14594759e-05
Iter: 1747 loss: 1.14300683e-05
Iter: 1748 loss: 1.14219893e-05
Iter: 1749 loss: 1.14382738e-05
Iter: 1750 loss: 1.14185905e-05
Iter: 1751 loss: 1.14081067e-05
Iter: 1752 loss: 1.14319737e-05
Iter: 1753 loss: 1.1404245e-05
Iter: 1754 loss: 1.13944952e-05
Iter: 1755 loss: 1.14116983e-05
Iter: 1756 loss: 1.13901842e-05
Iter: 1757 loss: 1.138274e-05
Iter: 1758 loss: 1.13826009e-05
Iter: 1759 loss: 1.13771857e-05
Iter: 1760 loss: 1.13653059e-05
Iter: 1761 loss: 1.15462299e-05
Iter: 1762 loss: 1.13649621e-05
Iter: 1763 loss: 1.13565766e-05
Iter: 1764 loss: 1.13563947e-05
Iter: 1765 loss: 1.13474862e-05
Iter: 1766 loss: 1.1350251e-05
Iter: 1767 loss: 1.13409369e-05
Iter: 1768 loss: 1.13329725e-05
Iter: 1769 loss: 1.13260849e-05
Iter: 1770 loss: 1.13235865e-05
Iter: 1771 loss: 1.1309703e-05
Iter: 1772 loss: 1.13271826e-05
Iter: 1773 loss: 1.13025671e-05
Iter: 1774 loss: 1.12910475e-05
Iter: 1775 loss: 1.13587803e-05
Iter: 1776 loss: 1.12895723e-05
Iter: 1777 loss: 1.12783746e-05
Iter: 1778 loss: 1.13848055e-05
Iter: 1779 loss: 1.12777971e-05
Iter: 1780 loss: 1.12695707e-05
Iter: 1781 loss: 1.12718408e-05
Iter: 1782 loss: 1.12633843e-05
Iter: 1783 loss: 1.12543603e-05
Iter: 1784 loss: 1.13443284e-05
Iter: 1785 loss: 1.12541848e-05
Iter: 1786 loss: 1.12476446e-05
Iter: 1787 loss: 1.12484067e-05
Iter: 1788 loss: 1.12426978e-05
Iter: 1789 loss: 1.1232818e-05
Iter: 1790 loss: 1.12696871e-05
Iter: 1791 loss: 1.12304551e-05
Iter: 1792 loss: 1.12214038e-05
Iter: 1793 loss: 1.12362859e-05
Iter: 1794 loss: 1.12175221e-05
Iter: 1795 loss: 1.12091138e-05
Iter: 1796 loss: 1.12113885e-05
Iter: 1797 loss: 1.12030739e-05
Iter: 1798 loss: 1.11926829e-05
Iter: 1799 loss: 1.13442038e-05
Iter: 1800 loss: 1.11924783e-05
Iter: 1801 loss: 1.11857426e-05
Iter: 1802 loss: 1.11774216e-05
Iter: 1803 loss: 1.11767358e-05
Iter: 1804 loss: 1.11698728e-05
Iter: 1805 loss: 1.11695172e-05
Iter: 1806 loss: 1.11635791e-05
Iter: 1807 loss: 1.11528989e-05
Iter: 1808 loss: 1.14040849e-05
Iter: 1809 loss: 1.11529116e-05
Iter: 1810 loss: 1.1141974e-05
Iter: 1811 loss: 1.11589725e-05
Iter: 1812 loss: 1.11368045e-05
Iter: 1813 loss: 1.11259233e-05
Iter: 1814 loss: 1.11559693e-05
Iter: 1815 loss: 1.11224417e-05
Iter: 1816 loss: 1.11147947e-05
Iter: 1817 loss: 1.11147938e-05
Iter: 1818 loss: 1.11069676e-05
Iter: 1819 loss: 1.11002391e-05
Iter: 1820 loss: 1.10981828e-05
Iter: 1821 loss: 1.10880583e-05
Iter: 1822 loss: 1.1148928e-05
Iter: 1823 loss: 1.10868405e-05
Iter: 1824 loss: 1.1077118e-05
Iter: 1825 loss: 1.11095032e-05
Iter: 1826 loss: 1.10743604e-05
Iter: 1827 loss: 1.10666306e-05
Iter: 1828 loss: 1.10689616e-05
Iter: 1829 loss: 1.10610308e-05
Iter: 1830 loss: 1.1051221e-05
Iter: 1831 loss: 1.1105838e-05
Iter: 1832 loss: 1.10499386e-05
Iter: 1833 loss: 1.10404089e-05
Iter: 1834 loss: 1.10602905e-05
Iter: 1835 loss: 1.10370511e-05
Iter: 1836 loss: 1.10297642e-05
Iter: 1837 loss: 1.1100502e-05
Iter: 1838 loss: 1.10293804e-05
Iter: 1839 loss: 1.10233395e-05
Iter: 1840 loss: 1.10153433e-05
Iter: 1841 loss: 1.10150932e-05
Iter: 1842 loss: 1.1005739e-05
Iter: 1843 loss: 1.10057254e-05
Iter: 1844 loss: 1.09997973e-05
Iter: 1845 loss: 1.09881476e-05
Iter: 1846 loss: 1.12018806e-05
Iter: 1847 loss: 1.09879384e-05
Iter: 1848 loss: 1.09751436e-05
Iter: 1849 loss: 1.10004048e-05
Iter: 1850 loss: 1.09699649e-05
Iter: 1851 loss: 1.09582843e-05
Iter: 1852 loss: 1.10299698e-05
Iter: 1853 loss: 1.09568937e-05
Iter: 1854 loss: 1.09468638e-05
Iter: 1855 loss: 1.10491255e-05
Iter: 1856 loss: 1.09465545e-05
Iter: 1857 loss: 1.09387875e-05
Iter: 1858 loss: 1.09356206e-05
Iter: 1859 loss: 1.09315315e-05
Iter: 1860 loss: 1.09229022e-05
Iter: 1861 loss: 1.09895354e-05
Iter: 1862 loss: 1.09221301e-05
Iter: 1863 loss: 1.09138109e-05
Iter: 1864 loss: 1.09257671e-05
Iter: 1865 loss: 1.0909529e-05
Iter: 1866 loss: 1.09018638e-05
Iter: 1867 loss: 1.09033317e-05
Iter: 1868 loss: 1.08956201e-05
Iter: 1869 loss: 1.08874065e-05
Iter: 1870 loss: 1.10014307e-05
Iter: 1871 loss: 1.08872518e-05
Iter: 1872 loss: 1.08805671e-05
Iter: 1873 loss: 1.08855957e-05
Iter: 1874 loss: 1.08764962e-05
Iter: 1875 loss: 1.08681834e-05
Iter: 1876 loss: 1.09070397e-05
Iter: 1877 loss: 1.08667646e-05
Iter: 1878 loss: 1.08598042e-05
Iter: 1879 loss: 1.0873322e-05
Iter: 1880 loss: 1.08567892e-05
Iter: 1881 loss: 1.08498771e-05
Iter: 1882 loss: 1.0891039e-05
Iter: 1883 loss: 1.08491386e-05
Iter: 1884 loss: 1.08433851e-05
Iter: 1885 loss: 1.08306813e-05
Iter: 1886 loss: 1.1007578e-05
Iter: 1887 loss: 1.08301092e-05
Iter: 1888 loss: 1.08176109e-05
Iter: 1889 loss: 1.08564591e-05
Iter: 1890 loss: 1.0813781e-05
Iter: 1891 loss: 1.08054355e-05
Iter: 1892 loss: 1.0805159e-05
Iter: 1893 loss: 1.07970072e-05
Iter: 1894 loss: 1.08122331e-05
Iter: 1895 loss: 1.07936639e-05
Iter: 1896 loss: 1.07865726e-05
Iter: 1897 loss: 1.07892783e-05
Iter: 1898 loss: 1.07817741e-05
Iter: 1899 loss: 1.0773846e-05
Iter: 1900 loss: 1.08745498e-05
Iter: 1901 loss: 1.07735941e-05
Iter: 1902 loss: 1.07680871e-05
Iter: 1903 loss: 1.07595524e-05
Iter: 1904 loss: 1.07594569e-05
Iter: 1905 loss: 1.07502556e-05
Iter: 1906 loss: 1.08315908e-05
Iter: 1907 loss: 1.07496453e-05
Iter: 1908 loss: 1.07411042e-05
Iter: 1909 loss: 1.07732149e-05
Iter: 1910 loss: 1.07389624e-05
Iter: 1911 loss: 1.07318374e-05
Iter: 1912 loss: 1.07479373e-05
Iter: 1913 loss: 1.07293126e-05
Iter: 1914 loss: 1.07216947e-05
Iter: 1915 loss: 1.07477281e-05
Iter: 1916 loss: 1.07196684e-05
Iter: 1917 loss: 1.071322e-05
Iter: 1918 loss: 1.07296755e-05
Iter: 1919 loss: 1.07108581e-05
Iter: 1920 loss: 1.0703181e-05
Iter: 1921 loss: 1.07037486e-05
Iter: 1922 loss: 1.0697082e-05
Iter: 1923 loss: 1.06887e-05
Iter: 1924 loss: 1.06851394e-05
Iter: 1925 loss: 1.06808766e-05
Iter: 1926 loss: 1.06679945e-05
Iter: 1927 loss: 1.07120522e-05
Iter: 1928 loss: 1.06642856e-05
Iter: 1929 loss: 1.06576745e-05
Iter: 1930 loss: 1.06568305e-05
Iter: 1931 loss: 1.06509033e-05
Iter: 1932 loss: 1.06429816e-05
Iter: 1933 loss: 1.06425578e-05
Iter: 1934 loss: 1.06340776e-05
Iter: 1935 loss: 1.07052183e-05
Iter: 1936 loss: 1.06335929e-05
Iter: 1937 loss: 1.06259358e-05
Iter: 1938 loss: 1.06450807e-05
Iter: 1939 loss: 1.06232528e-05
Iter: 1940 loss: 1.06167e-05
Iter: 1941 loss: 1.06128364e-05
Iter: 1942 loss: 1.06099742e-05
Iter: 1943 loss: 1.06028328e-05
Iter: 1944 loss: 1.06027092e-05
Iter: 1945 loss: 1.05974696e-05
Iter: 1946 loss: 1.05980907e-05
Iter: 1947 loss: 1.05931849e-05
Iter: 1948 loss: 1.05865938e-05
Iter: 1949 loss: 1.06187472e-05
Iter: 1950 loss: 1.05854569e-05
Iter: 1951 loss: 1.05783092e-05
Iter: 1952 loss: 1.05810195e-05
Iter: 1953 loss: 1.05733116e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.2/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.6
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.6
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.6 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.6
+ date
Sun Nov  8 09:09:58 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.6/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.2/300_100_100_100_1 --function f2 --psi 0 --alpha 1.6 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.6/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb850400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb91ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb80dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb80d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb80db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbdaa8d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb747158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb747a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb7a32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb7d5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb7d1488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbdaa1b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbdaa1b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbdaa0f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbda9da488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbda977ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbda9778c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbda95b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb40579d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb40a8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb40a8e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba07f37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb4047b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb4047598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb4047bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbfb80dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba06fdd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb4047ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba073c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbb4047730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba073c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0671840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba0671400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba075d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba075dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcba075d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.013751392
test_loss: 0.014882366
train_loss: 0.011452024
test_loss: 0.013152215
train_loss: 0.011187072
test_loss: 0.012415618
train_loss: 0.010636726
test_loss: 0.012492363
train_loss: 0.010245713
test_loss: 0.012326927
train_loss: 0.010140503
test_loss: 0.01211181
train_loss: 0.009970546
test_loss: 0.011717365
train_loss: 0.0101373065
test_loss: 0.012724253
train_loss: 0.009617084
test_loss: 0.012059183
train_loss: 0.009897198
test_loss: 0.011611437
train_loss: 0.009180926
test_loss: 0.01138164
train_loss: 0.009524344
test_loss: 0.011286628
train_loss: 0.009544988
test_loss: 0.011402969
train_loss: 0.009338316
test_loss: 0.011412734
train_loss: 0.009292088
test_loss: 0.011447398
train_loss: 0.008833135
test_loss: 0.011419536
train_loss: 0.008942854
test_loss: 0.011083633
train_loss: 0.009451549
test_loss: 0.011145677
train_loss: 0.008957646
test_loss: 0.011375736
train_loss: 0.009588156
test_loss: 0.010868231
train_loss: 0.0094722295
test_loss: 0.011080472
train_loss: 0.008811811
test_loss: 0.010908836
train_loss: 0.008449871
test_loss: 0.010704437
train_loss: 0.008908205
test_loss: 0.010901777
train_loss: 0.008311214
test_loss: 0.010775984
train_loss: 0.008480461
test_loss: 0.010851764
train_loss: 0.0082844375
test_loss: 0.010906544
train_loss: 0.00815258
test_loss: 0.0106815975
train_loss: 0.009244293
test_loss: 0.011090095
train_loss: 0.008363922
test_loss: 0.010956564
train_loss: 0.008951411
test_loss: 0.010579658
train_loss: 0.008528554
test_loss: 0.010657004
train_loss: 0.008197844
test_loss: 0.0107315965
train_loss: 0.008542368
test_loss: 0.010702736
train_loss: 0.0084110955
test_loss: 0.010601897
train_loss: 0.008381879
test_loss: 0.010823255
train_loss: 0.008025505
test_loss: 0.010233626
train_loss: 0.00815347
test_loss: 0.010525625
train_loss: 0.008424384
test_loss: 0.010577091
train_loss: 0.008122211
test_loss: 0.010190519
train_loss: 0.00825843
test_loss: 0.010499902
train_loss: 0.008099598
test_loss: 0.010530795
train_loss: 0.008582292
test_loss: 0.0108487
train_loss: 0.008089018
test_loss: 0.010432819
train_loss: 0.0075540286
test_loss: 0.010041517
train_loss: 0.008176214
test_loss: 0.01043781
train_loss: 0.007721572
test_loss: 0.01020801
train_loss: 0.008887419
test_loss: 0.010382689
train_loss: 0.008506376
test_loss: 0.010514514
train_loss: 0.00753438
test_loss: 0.010011177
train_loss: 0.008156383
test_loss: 0.010318334
train_loss: 0.007979533
test_loss: 0.010207302
train_loss: 0.007600895
test_loss: 0.010058879
train_loss: 0.0077904454
test_loss: 0.010167465
train_loss: 0.0075754775
test_loss: 0.010201103
train_loss: 0.008352491
test_loss: 0.010342646
train_loss: 0.0074866535
test_loss: 0.00991557
train_loss: 0.008010692
test_loss: 0.010065619
train_loss: 0.0075112553
test_loss: 0.010384759
train_loss: 0.008118836
test_loss: 0.010115239
train_loss: 0.007381258
test_loss: 0.0101628555
train_loss: 0.007518368
test_loss: 0.010097151
train_loss: 0.007964848
test_loss: 0.00994936
train_loss: 0.0076366905
test_loss: 0.010223607
train_loss: 0.007610238
test_loss: 0.010103657
train_loss: 0.007804429
test_loss: 0.009899709
train_loss: 0.007757685
test_loss: 0.010102858
train_loss: 0.007884102
test_loss: 0.010221012
train_loss: 0.0077447766
test_loss: 0.010174638
train_loss: 0.007273838
test_loss: 0.009854121
train_loss: 0.007016198
test_loss: 0.009898826
train_loss: 0.007445974
test_loss: 0.009734721
train_loss: 0.0073710997
test_loss: 0.009916969
train_loss: 0.0076079066
test_loss: 0.009955059
train_loss: 0.0071679857
test_loss: 0.009820099
train_loss: 0.0070661213
test_loss: 0.009863317
train_loss: 0.00726937
test_loss: 0.010108307
train_loss: 0.0077712135
test_loss: 0.010046004
train_loss: 0.007614188
test_loss: 0.010160208
train_loss: 0.0070872293
test_loss: 0.009795208
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.6/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.6/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 1.6 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi1.6/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7195520510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71954f2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71954be840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71954bec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71954f29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71954a4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7195449598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7195471f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7195410488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7195410510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71953c2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71586ff950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71586ff840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71586b9400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7158666378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f715865a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f715865a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71586330d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7158633730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71586338c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71585f6840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7130404620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71303a5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71303a57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71303a5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f713036ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f713036b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71303312f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7130331b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71302f79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71302c2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f71302717b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7130274598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f713023d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f713023db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f713023d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.00442683e-05
Iter: 2 loss: 7.96376262e-05
Iter: 3 loss: 7.93193831e-05
Iter: 4 loss: 7.36539077e-05
Iter: 5 loss: 7.32630579e-05
Iter: 6 loss: 6.89905e-05
Iter: 7 loss: 6.19840648e-05
Iter: 8 loss: 9.35324351e-05
Iter: 9 loss: 6.05795e-05
Iter: 10 loss: 5.52251731e-05
Iter: 11 loss: 8.16779066e-05
Iter: 12 loss: 5.43041097e-05
Iter: 13 loss: 5.18146553e-05
Iter: 14 loss: 5.5726945e-05
Iter: 15 loss: 5.0659859e-05
Iter: 16 loss: 4.82564283e-05
Iter: 17 loss: 6.19315833e-05
Iter: 18 loss: 4.79207265e-05
Iter: 19 loss: 4.57097267e-05
Iter: 20 loss: 4.63531615e-05
Iter: 21 loss: 4.41213815e-05
Iter: 22 loss: 4.23079327e-05
Iter: 23 loss: 5.42188936e-05
Iter: 24 loss: 4.2117681e-05
Iter: 25 loss: 4.05594546e-05
Iter: 26 loss: 4.71423846e-05
Iter: 27 loss: 4.02284095e-05
Iter: 28 loss: 3.90191126e-05
Iter: 29 loss: 3.99468918e-05
Iter: 30 loss: 3.82824146e-05
Iter: 31 loss: 3.75728923e-05
Iter: 32 loss: 3.75436721e-05
Iter: 33 loss: 3.6936508e-05
Iter: 34 loss: 3.67808352e-05
Iter: 35 loss: 3.64009029e-05
Iter: 36 loss: 3.56694654e-05
Iter: 37 loss: 3.58275065e-05
Iter: 38 loss: 3.51285125e-05
Iter: 39 loss: 3.44634027e-05
Iter: 40 loss: 4.45427067e-05
Iter: 41 loss: 3.44630753e-05
Iter: 42 loss: 3.39145226e-05
Iter: 43 loss: 3.72943505e-05
Iter: 44 loss: 3.38494938e-05
Iter: 45 loss: 3.35632067e-05
Iter: 46 loss: 3.37119927e-05
Iter: 47 loss: 3.33740536e-05
Iter: 48 loss: 3.29483e-05
Iter: 49 loss: 3.43681968e-05
Iter: 50 loss: 3.28312126e-05
Iter: 51 loss: 3.24973807e-05
Iter: 52 loss: 3.23866661e-05
Iter: 53 loss: 3.21938132e-05
Iter: 54 loss: 3.18335296e-05
Iter: 55 loss: 3.54586264e-05
Iter: 56 loss: 3.1822372e-05
Iter: 57 loss: 3.14936697e-05
Iter: 58 loss: 3.17557242e-05
Iter: 59 loss: 3.12953962e-05
Iter: 60 loss: 3.09986e-05
Iter: 61 loss: 3.17055783e-05
Iter: 62 loss: 3.08909839e-05
Iter: 63 loss: 3.05838294e-05
Iter: 64 loss: 3.23293061e-05
Iter: 65 loss: 3.05415524e-05
Iter: 66 loss: 3.0289164e-05
Iter: 67 loss: 3.07115042e-05
Iter: 68 loss: 3.01748132e-05
Iter: 69 loss: 2.99401181e-05
Iter: 70 loss: 3.13030469e-05
Iter: 71 loss: 2.99087333e-05
Iter: 72 loss: 2.96908584e-05
Iter: 73 loss: 3.03488814e-05
Iter: 74 loss: 2.96252492e-05
Iter: 75 loss: 2.94441234e-05
Iter: 76 loss: 2.94415786e-05
Iter: 77 loss: 2.92987679e-05
Iter: 78 loss: 2.90856533e-05
Iter: 79 loss: 2.98026389e-05
Iter: 80 loss: 2.9027864e-05
Iter: 81 loss: 2.88473548e-05
Iter: 82 loss: 2.88468818e-05
Iter: 83 loss: 2.87406619e-05
Iter: 84 loss: 2.85469177e-05
Iter: 85 loss: 3.31623596e-05
Iter: 86 loss: 2.85468814e-05
Iter: 87 loss: 2.83861482e-05
Iter: 88 loss: 2.83855952e-05
Iter: 89 loss: 2.82528235e-05
Iter: 90 loss: 2.80828426e-05
Iter: 91 loss: 2.807075e-05
Iter: 92 loss: 2.79031829e-05
Iter: 93 loss: 2.85813949e-05
Iter: 94 loss: 2.78658572e-05
Iter: 95 loss: 2.76999745e-05
Iter: 96 loss: 2.89167328e-05
Iter: 97 loss: 2.76864157e-05
Iter: 98 loss: 2.75671409e-05
Iter: 99 loss: 2.75066213e-05
Iter: 100 loss: 2.74513259e-05
Iter: 101 loss: 2.73092446e-05
Iter: 102 loss: 2.83068366e-05
Iter: 103 loss: 2.72962698e-05
Iter: 104 loss: 2.71697863e-05
Iter: 105 loss: 2.75620987e-05
Iter: 106 loss: 2.71331737e-05
Iter: 107 loss: 2.70077144e-05
Iter: 108 loss: 2.73248243e-05
Iter: 109 loss: 2.69639295e-05
Iter: 110 loss: 2.68496988e-05
Iter: 111 loss: 2.75680795e-05
Iter: 112 loss: 2.68364493e-05
Iter: 113 loss: 2.67443756e-05
Iter: 114 loss: 2.67379328e-05
Iter: 115 loss: 2.66691059e-05
Iter: 116 loss: 2.6545089e-05
Iter: 117 loss: 2.66779243e-05
Iter: 118 loss: 2.6476966e-05
Iter: 119 loss: 2.64006321e-05
Iter: 120 loss: 2.63870625e-05
Iter: 121 loss: 2.63295078e-05
Iter: 122 loss: 2.62311751e-05
Iter: 123 loss: 2.62311078e-05
Iter: 124 loss: 2.61161458e-05
Iter: 125 loss: 2.64713544e-05
Iter: 126 loss: 2.60827601e-05
Iter: 127 loss: 2.59637909e-05
Iter: 128 loss: 2.68970307e-05
Iter: 129 loss: 2.59552835e-05
Iter: 130 loss: 2.58969885e-05
Iter: 131 loss: 2.57933971e-05
Iter: 132 loss: 2.83483278e-05
Iter: 133 loss: 2.57932188e-05
Iter: 134 loss: 2.56643871e-05
Iter: 135 loss: 2.65441558e-05
Iter: 136 loss: 2.56519579e-05
Iter: 137 loss: 2.55473424e-05
Iter: 138 loss: 2.63069123e-05
Iter: 139 loss: 2.55386149e-05
Iter: 140 loss: 2.54725237e-05
Iter: 141 loss: 2.5403082e-05
Iter: 142 loss: 2.53910184e-05
Iter: 143 loss: 2.52835234e-05
Iter: 144 loss: 2.60984889e-05
Iter: 145 loss: 2.52753271e-05
Iter: 146 loss: 2.51885103e-05
Iter: 147 loss: 2.55985524e-05
Iter: 148 loss: 2.51727979e-05
Iter: 149 loss: 2.50999601e-05
Iter: 150 loss: 2.52651662e-05
Iter: 151 loss: 2.5072608e-05
Iter: 152 loss: 2.50002377e-05
Iter: 153 loss: 2.52519512e-05
Iter: 154 loss: 2.49814984e-05
Iter: 155 loss: 2.49124205e-05
Iter: 156 loss: 2.49185505e-05
Iter: 157 loss: 2.48590113e-05
Iter: 158 loss: 2.4787736e-05
Iter: 159 loss: 2.54403094e-05
Iter: 160 loss: 2.47847966e-05
Iter: 161 loss: 2.47105854e-05
Iter: 162 loss: 2.49038967e-05
Iter: 163 loss: 2.46857144e-05
Iter: 164 loss: 2.46366071e-05
Iter: 165 loss: 2.45890405e-05
Iter: 166 loss: 2.45786159e-05
Iter: 167 loss: 2.45073152e-05
Iter: 168 loss: 2.53630024e-05
Iter: 169 loss: 2.45063165e-05
Iter: 170 loss: 2.44475686e-05
Iter: 171 loss: 2.44950934e-05
Iter: 172 loss: 2.44119183e-05
Iter: 173 loss: 2.43486975e-05
Iter: 174 loss: 2.43125178e-05
Iter: 175 loss: 2.4284851e-05
Iter: 176 loss: 2.42071783e-05
Iter: 177 loss: 2.49165223e-05
Iter: 178 loss: 2.42034257e-05
Iter: 179 loss: 2.41261223e-05
Iter: 180 loss: 2.43354152e-05
Iter: 181 loss: 2.41005728e-05
Iter: 182 loss: 2.40410736e-05
Iter: 183 loss: 2.40289337e-05
Iter: 184 loss: 2.39895271e-05
Iter: 185 loss: 2.39079855e-05
Iter: 186 loss: 2.45533593e-05
Iter: 187 loss: 2.39025539e-05
Iter: 188 loss: 2.38373977e-05
Iter: 189 loss: 2.41617763e-05
Iter: 190 loss: 2.38266257e-05
Iter: 191 loss: 2.37709937e-05
Iter: 192 loss: 2.37995882e-05
Iter: 193 loss: 2.3734241e-05
Iter: 194 loss: 2.36649557e-05
Iter: 195 loss: 2.39929504e-05
Iter: 196 loss: 2.36524884e-05
Iter: 197 loss: 2.35963525e-05
Iter: 198 loss: 2.36338456e-05
Iter: 199 loss: 2.3561186e-05
Iter: 200 loss: 2.35080333e-05
Iter: 201 loss: 2.4189867e-05
Iter: 202 loss: 2.35076623e-05
Iter: 203 loss: 2.34567233e-05
Iter: 204 loss: 2.34766085e-05
Iter: 205 loss: 2.34208019e-05
Iter: 206 loss: 2.33745013e-05
Iter: 207 loss: 2.33526116e-05
Iter: 208 loss: 2.33299506e-05
Iter: 209 loss: 2.32717066e-05
Iter: 210 loss: 2.32715029e-05
Iter: 211 loss: 2.32280654e-05
Iter: 212 loss: 2.31974e-05
Iter: 213 loss: 2.31819449e-05
Iter: 214 loss: 2.31237045e-05
Iter: 215 loss: 2.31126796e-05
Iter: 216 loss: 2.30738588e-05
Iter: 217 loss: 2.30176756e-05
Iter: 218 loss: 2.30158385e-05
Iter: 219 loss: 2.29746965e-05
Iter: 220 loss: 2.29834041e-05
Iter: 221 loss: 2.2944485e-05
Iter: 222 loss: 2.2891596e-05
Iter: 223 loss: 2.29947036e-05
Iter: 224 loss: 2.28698736e-05
Iter: 225 loss: 2.28152403e-05
Iter: 226 loss: 2.29992238e-05
Iter: 227 loss: 2.28004355e-05
Iter: 228 loss: 2.27379569e-05
Iter: 229 loss: 2.30620644e-05
Iter: 230 loss: 2.27284436e-05
Iter: 231 loss: 2.26915108e-05
Iter: 232 loss: 2.26851662e-05
Iter: 233 loss: 2.26602169e-05
Iter: 234 loss: 2.25958e-05
Iter: 235 loss: 2.28389508e-05
Iter: 236 loss: 2.25801032e-05
Iter: 237 loss: 2.25320273e-05
Iter: 238 loss: 2.25737422e-05
Iter: 239 loss: 2.25039275e-05
Iter: 240 loss: 2.24710293e-05
Iter: 241 loss: 2.24676478e-05
Iter: 242 loss: 2.24421856e-05
Iter: 243 loss: 2.23956595e-05
Iter: 244 loss: 2.35026127e-05
Iter: 245 loss: 2.23957013e-05
Iter: 246 loss: 2.23461138e-05
Iter: 247 loss: 2.25460153e-05
Iter: 248 loss: 2.23352417e-05
Iter: 249 loss: 2.22838662e-05
Iter: 250 loss: 2.25919e-05
Iter: 251 loss: 2.22777162e-05
Iter: 252 loss: 2.22429699e-05
Iter: 253 loss: 2.22113904e-05
Iter: 254 loss: 2.22025956e-05
Iter: 255 loss: 2.21504251e-05
Iter: 256 loss: 2.23633415e-05
Iter: 257 loss: 2.21385017e-05
Iter: 258 loss: 2.20882484e-05
Iter: 259 loss: 2.2308699e-05
Iter: 260 loss: 2.20780894e-05
Iter: 261 loss: 2.20250658e-05
Iter: 262 loss: 2.21564e-05
Iter: 263 loss: 2.20068632e-05
Iter: 264 loss: 2.19700087e-05
Iter: 265 loss: 2.19834565e-05
Iter: 266 loss: 2.19446702e-05
Iter: 267 loss: 2.18968325e-05
Iter: 268 loss: 2.23434181e-05
Iter: 269 loss: 2.18950954e-05
Iter: 270 loss: 2.1853848e-05
Iter: 271 loss: 2.19170179e-05
Iter: 272 loss: 2.18344794e-05
Iter: 273 loss: 2.17989145e-05
Iter: 274 loss: 2.18121695e-05
Iter: 275 loss: 2.17742636e-05
Iter: 276 loss: 2.17182605e-05
Iter: 277 loss: 2.19817666e-05
Iter: 278 loss: 2.17081633e-05
Iter: 279 loss: 2.16787321e-05
Iter: 280 loss: 2.17717516e-05
Iter: 281 loss: 2.16702956e-05
Iter: 282 loss: 2.16324606e-05
Iter: 283 loss: 2.17936577e-05
Iter: 284 loss: 2.16245735e-05
Iter: 285 loss: 2.15952241e-05
Iter: 286 loss: 2.15627915e-05
Iter: 287 loss: 2.15581822e-05
Iter: 288 loss: 2.1516491e-05
Iter: 289 loss: 2.18960777e-05
Iter: 290 loss: 2.15144973e-05
Iter: 291 loss: 2.14768479e-05
Iter: 292 loss: 2.15492819e-05
Iter: 293 loss: 2.14611737e-05
Iter: 294 loss: 2.14230167e-05
Iter: 295 loss: 2.14153843e-05
Iter: 296 loss: 2.13903404e-05
Iter: 297 loss: 2.1344149e-05
Iter: 298 loss: 2.14424908e-05
Iter: 299 loss: 2.13256862e-05
Iter: 300 loss: 2.1280659e-05
Iter: 301 loss: 2.18318819e-05
Iter: 302 loss: 2.12804e-05
Iter: 303 loss: 2.12461364e-05
Iter: 304 loss: 2.12546911e-05
Iter: 305 loss: 2.12211853e-05
Iter: 306 loss: 2.11836141e-05
Iter: 307 loss: 2.12265149e-05
Iter: 308 loss: 2.1163607e-05
Iter: 309 loss: 2.11139268e-05
Iter: 310 loss: 2.15468026e-05
Iter: 311 loss: 2.11111546e-05
Iter: 312 loss: 2.10771359e-05
Iter: 313 loss: 2.10952094e-05
Iter: 314 loss: 2.10544531e-05
Iter: 315 loss: 2.10172257e-05
Iter: 316 loss: 2.10721046e-05
Iter: 317 loss: 2.09988721e-05
Iter: 318 loss: 2.09506179e-05
Iter: 319 loss: 2.11884253e-05
Iter: 320 loss: 2.09419159e-05
Iter: 321 loss: 2.09135287e-05
Iter: 322 loss: 2.11169026e-05
Iter: 323 loss: 2.09110385e-05
Iter: 324 loss: 2.08807014e-05
Iter: 325 loss: 2.09128939e-05
Iter: 326 loss: 2.08642705e-05
Iter: 327 loss: 2.08327438e-05
Iter: 328 loss: 2.08092861e-05
Iter: 329 loss: 2.07982885e-05
Iter: 330 loss: 2.07644189e-05
Iter: 331 loss: 2.07641369e-05
Iter: 332 loss: 2.0736039e-05
Iter: 333 loss: 2.07472931e-05
Iter: 334 loss: 2.07165394e-05
Iter: 335 loss: 2.0684929e-05
Iter: 336 loss: 2.06856312e-05
Iter: 337 loss: 2.06593e-05
Iter: 338 loss: 2.06101504e-05
Iter: 339 loss: 2.07079902e-05
Iter: 340 loss: 2.05899596e-05
Iter: 341 loss: 2.05540273e-05
Iter: 342 loss: 2.05534707e-05
Iter: 343 loss: 2.05292745e-05
Iter: 344 loss: 2.05114666e-05
Iter: 345 loss: 2.05032375e-05
Iter: 346 loss: 2.04635598e-05
Iter: 347 loss: 2.05578508e-05
Iter: 348 loss: 2.04495791e-05
Iter: 349 loss: 2.04055668e-05
Iter: 350 loss: 2.08119818e-05
Iter: 351 loss: 2.04036405e-05
Iter: 352 loss: 2.03838335e-05
Iter: 353 loss: 2.03655054e-05
Iter: 354 loss: 2.03608324e-05
Iter: 355 loss: 2.03271447e-05
Iter: 356 loss: 2.0481415e-05
Iter: 357 loss: 2.03207692e-05
Iter: 358 loss: 2.0287087e-05
Iter: 359 loss: 2.04400312e-05
Iter: 360 loss: 2.02804804e-05
Iter: 361 loss: 2.0254487e-05
Iter: 362 loss: 2.04358439e-05
Iter: 363 loss: 2.02521496e-05
Iter: 364 loss: 2.02289448e-05
Iter: 365 loss: 2.01978437e-05
Iter: 366 loss: 2.01958519e-05
Iter: 367 loss: 2.01599287e-05
Iter: 368 loss: 2.0335332e-05
Iter: 369 loss: 2.01535113e-05
Iter: 370 loss: 2.01218281e-05
Iter: 371 loss: 2.02745796e-05
Iter: 372 loss: 2.01162311e-05
Iter: 373 loss: 2.0081603e-05
Iter: 374 loss: 2.00778813e-05
Iter: 375 loss: 2.00528739e-05
Iter: 376 loss: 2.00207814e-05
Iter: 377 loss: 2.00349132e-05
Iter: 378 loss: 1.99985134e-05
Iter: 379 loss: 1.99576898e-05
Iter: 380 loss: 2.02376505e-05
Iter: 381 loss: 1.99534134e-05
Iter: 382 loss: 1.99126298e-05
Iter: 383 loss: 2.00879476e-05
Iter: 384 loss: 1.99040569e-05
Iter: 385 loss: 1.98800972e-05
Iter: 386 loss: 1.987209e-05
Iter: 387 loss: 1.9858162e-05
Iter: 388 loss: 1.98213311e-05
Iter: 389 loss: 2.020795e-05
Iter: 390 loss: 1.98201815e-05
Iter: 391 loss: 1.9793406e-05
Iter: 392 loss: 1.98003472e-05
Iter: 393 loss: 1.97736535e-05
Iter: 394 loss: 1.97422487e-05
Iter: 395 loss: 1.97748959e-05
Iter: 396 loss: 1.97248719e-05
Iter: 397 loss: 1.96940091e-05
Iter: 398 loss: 1.99919305e-05
Iter: 399 loss: 1.96928304e-05
Iter: 400 loss: 1.96637175e-05
Iter: 401 loss: 1.9739764e-05
Iter: 402 loss: 1.96537712e-05
Iter: 403 loss: 1.9625626e-05
Iter: 404 loss: 1.9708863e-05
Iter: 405 loss: 1.96172223e-05
Iter: 406 loss: 1.95923712e-05
Iter: 407 loss: 1.95899465e-05
Iter: 408 loss: 1.95714329e-05
Iter: 409 loss: 1.9537958e-05
Iter: 410 loss: 1.96537476e-05
Iter: 411 loss: 1.95290886e-05
Iter: 412 loss: 1.94965105e-05
Iter: 413 loss: 1.97342542e-05
Iter: 414 loss: 1.94935856e-05
Iter: 415 loss: 1.94724671e-05
Iter: 416 loss: 1.94406784e-05
Iter: 417 loss: 1.94401528e-05
Iter: 418 loss: 1.93987726e-05
Iter: 419 loss: 1.94784552e-05
Iter: 420 loss: 1.93815722e-05
Iter: 421 loss: 1.9353567e-05
Iter: 422 loss: 1.93520773e-05
Iter: 423 loss: 1.93295946e-05
Iter: 424 loss: 1.93014494e-05
Iter: 425 loss: 1.9298901e-05
Iter: 426 loss: 1.92668485e-05
Iter: 427 loss: 1.96196961e-05
Iter: 428 loss: 1.92659863e-05
Iter: 429 loss: 1.92400748e-05
Iter: 430 loss: 1.93123651e-05
Iter: 431 loss: 1.92319203e-05
Iter: 432 loss: 1.92042171e-05
Iter: 433 loss: 1.91846357e-05
Iter: 434 loss: 1.91745567e-05
Iter: 435 loss: 1.91432919e-05
Iter: 436 loss: 1.93058768e-05
Iter: 437 loss: 1.91383515e-05
Iter: 438 loss: 1.91061281e-05
Iter: 439 loss: 1.93686665e-05
Iter: 440 loss: 1.9104129e-05
Iter: 441 loss: 1.90814681e-05
Iter: 442 loss: 1.90930768e-05
Iter: 443 loss: 1.9066556e-05
Iter: 444 loss: 1.90409883e-05
Iter: 445 loss: 1.91173131e-05
Iter: 446 loss: 1.90331411e-05
Iter: 447 loss: 1.90060109e-05
Iter: 448 loss: 1.90023657e-05
Iter: 449 loss: 1.89827078e-05
Iter: 450 loss: 1.89561069e-05
Iter: 451 loss: 1.89560033e-05
Iter: 452 loss: 1.89352977e-05
Iter: 453 loss: 1.89132552e-05
Iter: 454 loss: 1.89096972e-05
Iter: 455 loss: 1.88751783e-05
Iter: 456 loss: 1.89097518e-05
Iter: 457 loss: 1.88557478e-05
Iter: 458 loss: 1.88197537e-05
Iter: 459 loss: 1.90387509e-05
Iter: 460 loss: 1.88148333e-05
Iter: 461 loss: 1.87865735e-05
Iter: 462 loss: 1.90418068e-05
Iter: 463 loss: 1.8785262e-05
Iter: 464 loss: 1.87636906e-05
Iter: 465 loss: 1.87563e-05
Iter: 466 loss: 1.87437417e-05
Iter: 467 loss: 1.87155019e-05
Iter: 468 loss: 1.89300081e-05
Iter: 469 loss: 1.87135047e-05
Iter: 470 loss: 1.86851175e-05
Iter: 471 loss: 1.86942307e-05
Iter: 472 loss: 1.86652214e-05
Iter: 473 loss: 1.86359084e-05
Iter: 474 loss: 1.86801044e-05
Iter: 475 loss: 1.86220059e-05
Iter: 476 loss: 1.85945391e-05
Iter: 477 loss: 1.88500599e-05
Iter: 478 loss: 1.85935423e-05
Iter: 479 loss: 1.85655808e-05
Iter: 480 loss: 1.86216366e-05
Iter: 481 loss: 1.85539066e-05
Iter: 482 loss: 1.85288318e-05
Iter: 483 loss: 1.85181689e-05
Iter: 484 loss: 1.85049412e-05
Iter: 485 loss: 1.84783239e-05
Iter: 486 loss: 1.88482281e-05
Iter: 487 loss: 1.8478162e-05
Iter: 488 loss: 1.84583732e-05
Iter: 489 loss: 1.8431756e-05
Iter: 490 loss: 1.8430379e-05
Iter: 491 loss: 1.8399478e-05
Iter: 492 loss: 1.83994234e-05
Iter: 493 loss: 1.83830562e-05
Iter: 494 loss: 1.8353061e-05
Iter: 495 loss: 1.90450119e-05
Iter: 496 loss: 1.83530465e-05
Iter: 497 loss: 1.83153788e-05
Iter: 498 loss: 1.84436958e-05
Iter: 499 loss: 1.83053817e-05
Iter: 500 loss: 1.82802796e-05
Iter: 501 loss: 1.86008328e-05
Iter: 502 loss: 1.82801123e-05
Iter: 503 loss: 1.8257113e-05
Iter: 504 loss: 1.82738768e-05
Iter: 505 loss: 1.82426338e-05
Iter: 506 loss: 1.82116455e-05
Iter: 507 loss: 1.8267885e-05
Iter: 508 loss: 1.81982505e-05
Iter: 509 loss: 1.81724499e-05
Iter: 510 loss: 1.84480541e-05
Iter: 511 loss: 1.81717805e-05
Iter: 512 loss: 1.81527557e-05
Iter: 513 loss: 1.81446158e-05
Iter: 514 loss: 1.81348e-05
Iter: 515 loss: 1.81079849e-05
Iter: 516 loss: 1.81514915e-05
Iter: 517 loss: 1.80957268e-05
Iter: 518 loss: 1.8069295e-05
Iter: 519 loss: 1.8069155e-05
Iter: 520 loss: 1.80575244e-05
Iter: 521 loss: 1.80292445e-05
Iter: 522 loss: 1.82968215e-05
Iter: 523 loss: 1.80250809e-05
Iter: 524 loss: 1.79868784e-05
Iter: 525 loss: 1.83122811e-05
Iter: 526 loss: 1.79846429e-05
Iter: 527 loss: 1.79585913e-05
Iter: 528 loss: 1.80482439e-05
Iter: 529 loss: 1.7951741e-05
Iter: 530 loss: 1.79298549e-05
Iter: 531 loss: 1.79984436e-05
Iter: 532 loss: 1.79239141e-05
Iter: 533 loss: 1.78971841e-05
Iter: 534 loss: 1.78948412e-05
Iter: 535 loss: 1.7875449e-05
Iter: 536 loss: 1.78439223e-05
Iter: 537 loss: 1.79197359e-05
Iter: 538 loss: 1.78325135e-05
Iter: 539 loss: 1.78021364e-05
Iter: 540 loss: 1.78588125e-05
Iter: 541 loss: 1.77895927e-05
Iter: 542 loss: 1.77591901e-05
Iter: 543 loss: 1.80579e-05
Iter: 544 loss: 1.77581551e-05
Iter: 545 loss: 1.773236e-05
Iter: 546 loss: 1.77724396e-05
Iter: 547 loss: 1.77201928e-05
Iter: 548 loss: 1.76982576e-05
Iter: 549 loss: 1.7763803e-05
Iter: 550 loss: 1.76914327e-05
Iter: 551 loss: 1.76631074e-05
Iter: 552 loss: 1.77152906e-05
Iter: 553 loss: 1.76510985e-05
Iter: 554 loss: 1.76240537e-05
Iter: 555 loss: 1.76238937e-05
Iter: 556 loss: 1.76023132e-05
Iter: 557 loss: 1.75895038e-05
Iter: 558 loss: 1.7583714e-05
Iter: 559 loss: 1.75708665e-05
Iter: 560 loss: 1.75490113e-05
Iter: 561 loss: 1.75491223e-05
Iter: 562 loss: 1.75239857e-05
Iter: 563 loss: 1.75283094e-05
Iter: 564 loss: 1.750509e-05
Iter: 565 loss: 1.74687884e-05
Iter: 566 loss: 1.78478695e-05
Iter: 567 loss: 1.74677643e-05
Iter: 568 loss: 1.74472934e-05
Iter: 569 loss: 1.74987308e-05
Iter: 570 loss: 1.74399065e-05
Iter: 571 loss: 1.74173874e-05
Iter: 572 loss: 1.74448833e-05
Iter: 573 loss: 1.74057095e-05
Iter: 574 loss: 1.73764547e-05
Iter: 575 loss: 1.74220968e-05
Iter: 576 loss: 1.73627304e-05
Iter: 577 loss: 1.73359076e-05
Iter: 578 loss: 1.73678891e-05
Iter: 579 loss: 1.73219487e-05
Iter: 580 loss: 1.72910313e-05
Iter: 581 loss: 1.74156448e-05
Iter: 582 loss: 1.72840009e-05
Iter: 583 loss: 1.72550681e-05
Iter: 584 loss: 1.75109271e-05
Iter: 585 loss: 1.72536893e-05
Iter: 586 loss: 1.72344371e-05
Iter: 587 loss: 1.72219043e-05
Iter: 588 loss: 1.72144137e-05
Iter: 589 loss: 1.71916126e-05
Iter: 590 loss: 1.75429195e-05
Iter: 591 loss: 1.71916108e-05
Iter: 592 loss: 1.71758747e-05
Iter: 593 loss: 1.71598949e-05
Iter: 594 loss: 1.7156899e-05
Iter: 595 loss: 1.71319844e-05
Iter: 596 loss: 1.74285688e-05
Iter: 597 loss: 1.71315569e-05
Iter: 598 loss: 1.7110191e-05
Iter: 599 loss: 1.71158845e-05
Iter: 600 loss: 1.70947951e-05
Iter: 601 loss: 1.70765088e-05
Iter: 602 loss: 1.70661624e-05
Iter: 603 loss: 1.70582061e-05
Iter: 604 loss: 1.70323e-05
Iter: 605 loss: 1.73082881e-05
Iter: 606 loss: 1.70316052e-05
Iter: 607 loss: 1.70068106e-05
Iter: 608 loss: 1.70294334e-05
Iter: 609 loss: 1.69927207e-05
Iter: 610 loss: 1.69707582e-05
Iter: 611 loss: 1.7045626e-05
Iter: 612 loss: 1.69649429e-05
Iter: 613 loss: 1.69417508e-05
Iter: 614 loss: 1.69823616e-05
Iter: 615 loss: 1.69310606e-05
Iter: 616 loss: 1.69039395e-05
Iter: 617 loss: 1.69301929e-05
Iter: 618 loss: 1.68884762e-05
Iter: 619 loss: 1.68602346e-05
Iter: 620 loss: 1.69738269e-05
Iter: 621 loss: 1.68541374e-05
Iter: 622 loss: 1.68320694e-05
Iter: 623 loss: 1.70883322e-05
Iter: 624 loss: 1.68317747e-05
Iter: 625 loss: 1.68144397e-05
Iter: 626 loss: 1.67944218e-05
Iter: 627 loss: 1.67922153e-05
Iter: 628 loss: 1.67671715e-05
Iter: 629 loss: 1.70070762e-05
Iter: 630 loss: 1.67662693e-05
Iter: 631 loss: 1.67471844e-05
Iter: 632 loss: 1.68218667e-05
Iter: 633 loss: 1.67427697e-05
Iter: 634 loss: 1.67266298e-05
Iter: 635 loss: 1.67767539e-05
Iter: 636 loss: 1.67220805e-05
Iter: 637 loss: 1.67010967e-05
Iter: 638 loss: 1.66819191e-05
Iter: 639 loss: 1.6676584e-05
Iter: 640 loss: 1.66519458e-05
Iter: 641 loss: 1.66450682e-05
Iter: 642 loss: 1.66301252e-05
Iter: 643 loss: 1.66061163e-05
Iter: 644 loss: 1.66058944e-05
Iter: 645 loss: 1.65831607e-05
Iter: 646 loss: 1.6617174e-05
Iter: 647 loss: 1.65720885e-05
Iter: 648 loss: 1.65522069e-05
Iter: 649 loss: 1.65676902e-05
Iter: 650 loss: 1.65401307e-05
Iter: 651 loss: 1.65147685e-05
Iter: 652 loss: 1.66120808e-05
Iter: 653 loss: 1.6508684e-05
Iter: 654 loss: 1.64854428e-05
Iter: 655 loss: 1.65655292e-05
Iter: 656 loss: 1.64792782e-05
Iter: 657 loss: 1.64557259e-05
Iter: 658 loss: 1.64684261e-05
Iter: 659 loss: 1.64398443e-05
Iter: 660 loss: 1.6424121e-05
Iter: 661 loss: 1.64232679e-05
Iter: 662 loss: 1.64104495e-05
Iter: 663 loss: 1.63841451e-05
Iter: 664 loss: 1.68449333e-05
Iter: 665 loss: 1.63837067e-05
Iter: 666 loss: 1.63615459e-05
Iter: 667 loss: 1.63615696e-05
Iter: 668 loss: 1.63409277e-05
Iter: 669 loss: 1.63630339e-05
Iter: 670 loss: 1.63295499e-05
Iter: 671 loss: 1.63124278e-05
Iter: 672 loss: 1.64534e-05
Iter: 673 loss: 1.631138e-05
Iter: 674 loss: 1.62977776e-05
Iter: 675 loss: 1.62717806e-05
Iter: 676 loss: 1.68293045e-05
Iter: 677 loss: 1.62713968e-05
Iter: 678 loss: 1.6245911e-05
Iter: 679 loss: 1.6376016e-05
Iter: 680 loss: 1.62416472e-05
Iter: 681 loss: 1.62195174e-05
Iter: 682 loss: 1.63192672e-05
Iter: 683 loss: 1.62156066e-05
Iter: 684 loss: 1.61946718e-05
Iter: 685 loss: 1.63395489e-05
Iter: 686 loss: 1.61926146e-05
Iter: 687 loss: 1.61785083e-05
Iter: 688 loss: 1.61514363e-05
Iter: 689 loss: 1.67360467e-05
Iter: 690 loss: 1.61513162e-05
Iter: 691 loss: 1.61213666e-05
Iter: 692 loss: 1.63546e-05
Iter: 693 loss: 1.61192984e-05
Iter: 694 loss: 1.6097536e-05
Iter: 695 loss: 1.62362048e-05
Iter: 696 loss: 1.60953568e-05
Iter: 697 loss: 1.60750496e-05
Iter: 698 loss: 1.60895597e-05
Iter: 699 loss: 1.60627897e-05
Iter: 700 loss: 1.60396321e-05
Iter: 701 loss: 1.62049364e-05
Iter: 702 loss: 1.60374366e-05
Iter: 703 loss: 1.60196723e-05
Iter: 704 loss: 1.60461223e-05
Iter: 705 loss: 1.60111049e-05
Iter: 706 loss: 1.59945084e-05
Iter: 707 loss: 1.60717682e-05
Iter: 708 loss: 1.59912979e-05
Iter: 709 loss: 1.59714546e-05
Iter: 710 loss: 1.60010677e-05
Iter: 711 loss: 1.59620722e-05
Iter: 712 loss: 1.59448446e-05
Iter: 713 loss: 1.59561896e-05
Iter: 714 loss: 1.59338033e-05
Iter: 715 loss: 1.59116589e-05
Iter: 716 loss: 1.60357122e-05
Iter: 717 loss: 1.59083957e-05
Iter: 718 loss: 1.58919611e-05
Iter: 719 loss: 1.5867623e-05
Iter: 720 loss: 1.58669609e-05
Iter: 721 loss: 1.58398325e-05
Iter: 722 loss: 1.60254131e-05
Iter: 723 loss: 1.5837184e-05
Iter: 724 loss: 1.58139064e-05
Iter: 725 loss: 1.60425971e-05
Iter: 726 loss: 1.58133098e-05
Iter: 727 loss: 1.57966842e-05
Iter: 728 loss: 1.57870036e-05
Iter: 729 loss: 1.57801351e-05
Iter: 730 loss: 1.57579598e-05
Iter: 731 loss: 1.57981249e-05
Iter: 732 loss: 1.57484319e-05
Iter: 733 loss: 1.57221475e-05
Iter: 734 loss: 1.58071853e-05
Iter: 735 loss: 1.57151262e-05
Iter: 736 loss: 1.56958849e-05
Iter: 737 loss: 1.59866122e-05
Iter: 738 loss: 1.56958758e-05
Iter: 739 loss: 1.56816423e-05
Iter: 740 loss: 1.56654842e-05
Iter: 741 loss: 1.56635269e-05
Iter: 742 loss: 1.5639449e-05
Iter: 743 loss: 1.58938656e-05
Iter: 744 loss: 1.56390288e-05
Iter: 745 loss: 1.56258557e-05
Iter: 746 loss: 1.5663978e-05
Iter: 747 loss: 1.56217338e-05
Iter: 748 loss: 1.56048791e-05
Iter: 749 loss: 1.56174683e-05
Iter: 750 loss: 1.55945636e-05
Iter: 751 loss: 1.55782363e-05
Iter: 752 loss: 1.55753733e-05
Iter: 753 loss: 1.55646831e-05
Iter: 754 loss: 1.55446287e-05
Iter: 755 loss: 1.57762679e-05
Iter: 756 loss: 1.55445141e-05
Iter: 757 loss: 1.5529502e-05
Iter: 758 loss: 1.55164107e-05
Iter: 759 loss: 1.55128982e-05
Iter: 760 loss: 1.54856971e-05
Iter: 761 loss: 1.55079197e-05
Iter: 762 loss: 1.54700465e-05
Iter: 763 loss: 1.54552727e-05
Iter: 764 loss: 1.54530899e-05
Iter: 765 loss: 1.54395875e-05
Iter: 766 loss: 1.5437925e-05
Iter: 767 loss: 1.54281915e-05
Iter: 768 loss: 1.54078443e-05
Iter: 769 loss: 1.54054e-05
Iter: 770 loss: 1.53907095e-05
Iter: 771 loss: 1.53674955e-05
Iter: 772 loss: 1.54556146e-05
Iter: 773 loss: 1.53615838e-05
Iter: 774 loss: 1.53434539e-05
Iter: 775 loss: 1.55940179e-05
Iter: 776 loss: 1.53432902e-05
Iter: 777 loss: 1.53277033e-05
Iter: 778 loss: 1.53327455e-05
Iter: 779 loss: 1.53163201e-05
Iter: 780 loss: 1.52994908e-05
Iter: 781 loss: 1.53946075e-05
Iter: 782 loss: 1.52974098e-05
Iter: 783 loss: 1.52789853e-05
Iter: 784 loss: 1.53013134e-05
Iter: 785 loss: 1.52693028e-05
Iter: 786 loss: 1.52522462e-05
Iter: 787 loss: 1.53303918e-05
Iter: 788 loss: 1.52490347e-05
Iter: 789 loss: 1.52339426e-05
Iter: 790 loss: 1.52322682e-05
Iter: 791 loss: 1.52216417e-05
Iter: 792 loss: 1.5203469e-05
Iter: 793 loss: 1.52515013e-05
Iter: 794 loss: 1.5197631e-05
Iter: 795 loss: 1.51773575e-05
Iter: 796 loss: 1.52665507e-05
Iter: 797 loss: 1.51732347e-05
Iter: 798 loss: 1.51543873e-05
Iter: 799 loss: 1.51708955e-05
Iter: 800 loss: 1.51436816e-05
Iter: 801 loss: 1.51245313e-05
Iter: 802 loss: 1.51615086e-05
Iter: 803 loss: 1.51166632e-05
Iter: 804 loss: 1.50936885e-05
Iter: 805 loss: 1.52837711e-05
Iter: 806 loss: 1.50921496e-05
Iter: 807 loss: 1.50774322e-05
Iter: 808 loss: 1.50757023e-05
Iter: 809 loss: 1.50647675e-05
Iter: 810 loss: 1.5046011e-05
Iter: 811 loss: 1.50551368e-05
Iter: 812 loss: 1.50335627e-05
Iter: 813 loss: 1.50127553e-05
Iter: 814 loss: 1.52476259e-05
Iter: 815 loss: 1.5012115e-05
Iter: 816 loss: 1.49965172e-05
Iter: 817 loss: 1.50990691e-05
Iter: 818 loss: 1.49948919e-05
Iter: 819 loss: 1.49821972e-05
Iter: 820 loss: 1.49671478e-05
Iter: 821 loss: 1.49657953e-05
Iter: 822 loss: 1.49413027e-05
Iter: 823 loss: 1.51980312e-05
Iter: 824 loss: 1.49408097e-05
Iter: 825 loss: 1.49308307e-05
Iter: 826 loss: 1.4923331e-05
Iter: 827 loss: 1.49200296e-05
Iter: 828 loss: 1.49030011e-05
Iter: 829 loss: 1.49630177e-05
Iter: 830 loss: 1.48985127e-05
Iter: 831 loss: 1.48782465e-05
Iter: 832 loss: 1.48765957e-05
Iter: 833 loss: 1.48617619e-05
Iter: 834 loss: 1.48409254e-05
Iter: 835 loss: 1.49885054e-05
Iter: 836 loss: 1.48393083e-05
Iter: 837 loss: 1.48215713e-05
Iter: 838 loss: 1.48888994e-05
Iter: 839 loss: 1.48175668e-05
Iter: 840 loss: 1.48011495e-05
Iter: 841 loss: 1.4797859e-05
Iter: 842 loss: 1.47869505e-05
Iter: 843 loss: 1.477156e-05
Iter: 844 loss: 1.47714927e-05
Iter: 845 loss: 1.47568207e-05
Iter: 846 loss: 1.47444671e-05
Iter: 847 loss: 1.47401179e-05
Iter: 848 loss: 1.47218188e-05
Iter: 849 loss: 1.47527453e-05
Iter: 850 loss: 1.47133851e-05
Iter: 851 loss: 1.46924049e-05
Iter: 852 loss: 1.47979808e-05
Iter: 853 loss: 1.46887833e-05
Iter: 854 loss: 1.46739258e-05
Iter: 855 loss: 1.48823601e-05
Iter: 856 loss: 1.4673964e-05
Iter: 857 loss: 1.46619859e-05
Iter: 858 loss: 1.46434977e-05
Iter: 859 loss: 1.4643294e-05
Iter: 860 loss: 1.46284037e-05
Iter: 861 loss: 1.46276197e-05
Iter: 862 loss: 1.46188622e-05
Iter: 863 loss: 1.45949753e-05
Iter: 864 loss: 1.4776514e-05
Iter: 865 loss: 1.45904232e-05
Iter: 866 loss: 1.45657868e-05
Iter: 867 loss: 1.48058161e-05
Iter: 868 loss: 1.45646436e-05
Iter: 869 loss: 1.45460381e-05
Iter: 870 loss: 1.46847206e-05
Iter: 871 loss: 1.45440481e-05
Iter: 872 loss: 1.45311133e-05
Iter: 873 loss: 1.45203576e-05
Iter: 874 loss: 1.45166459e-05
Iter: 875 loss: 1.4493412e-05
Iter: 876 loss: 1.46372113e-05
Iter: 877 loss: 1.4490799e-05
Iter: 878 loss: 1.44727383e-05
Iter: 879 loss: 1.45290369e-05
Iter: 880 loss: 1.44674168e-05
Iter: 881 loss: 1.44504229e-05
Iter: 882 loss: 1.44825372e-05
Iter: 883 loss: 1.44432588e-05
Iter: 884 loss: 1.44253308e-05
Iter: 885 loss: 1.45328568e-05
Iter: 886 loss: 1.44228507e-05
Iter: 887 loss: 1.44077703e-05
Iter: 888 loss: 1.43917086e-05
Iter: 889 loss: 1.43891666e-05
Iter: 890 loss: 1.43678599e-05
Iter: 891 loss: 1.44844344e-05
Iter: 892 loss: 1.43642128e-05
Iter: 893 loss: 1.43496018e-05
Iter: 894 loss: 1.43493708e-05
Iter: 895 loss: 1.43397292e-05
Iter: 896 loss: 1.43207926e-05
Iter: 897 loss: 1.47046867e-05
Iter: 898 loss: 1.43204416e-05
Iter: 899 loss: 1.42997633e-05
Iter: 900 loss: 1.45897129e-05
Iter: 901 loss: 1.42996687e-05
Iter: 902 loss: 1.42875524e-05
Iter: 903 loss: 1.42778827e-05
Iter: 904 loss: 1.42742674e-05
Iter: 905 loss: 1.42561557e-05
Iter: 906 loss: 1.42678382e-05
Iter: 907 loss: 1.42449853e-05
Iter: 908 loss: 1.42254939e-05
Iter: 909 loss: 1.44064e-05
Iter: 910 loss: 1.42249783e-05
Iter: 911 loss: 1.420638e-05
Iter: 912 loss: 1.42357203e-05
Iter: 913 loss: 1.4197808e-05
Iter: 914 loss: 1.4180785e-05
Iter: 915 loss: 1.42132103e-05
Iter: 916 loss: 1.41735663e-05
Iter: 917 loss: 1.41578312e-05
Iter: 918 loss: 1.42812478e-05
Iter: 919 loss: 1.41567989e-05
Iter: 920 loss: 1.41405717e-05
Iter: 921 loss: 1.41303726e-05
Iter: 922 loss: 1.41239661e-05
Iter: 923 loss: 1.41075525e-05
Iter: 924 loss: 1.43544121e-05
Iter: 925 loss: 1.41074415e-05
Iter: 926 loss: 1.40952861e-05
Iter: 927 loss: 1.40819348e-05
Iter: 928 loss: 1.4080003e-05
Iter: 929 loss: 1.40568955e-05
Iter: 930 loss: 1.41451437e-05
Iter: 931 loss: 1.40515958e-05
Iter: 932 loss: 1.40376051e-05
Iter: 933 loss: 1.40372485e-05
Iter: 934 loss: 1.40284337e-05
Iter: 935 loss: 1.40144239e-05
Iter: 936 loss: 1.40143911e-05
Iter: 937 loss: 1.39987014e-05
Iter: 938 loss: 1.41091969e-05
Iter: 939 loss: 1.39972362e-05
Iter: 940 loss: 1.39807362e-05
Iter: 941 loss: 1.39870972e-05
Iter: 942 loss: 1.39692902e-05
Iter: 943 loss: 1.39517142e-05
Iter: 944 loss: 1.39544372e-05
Iter: 945 loss: 1.39382573e-05
Iter: 946 loss: 1.39160747e-05
Iter: 947 loss: 1.3966629e-05
Iter: 948 loss: 1.39075319e-05
Iter: 949 loss: 1.38905798e-05
Iter: 950 loss: 1.41279861e-05
Iter: 951 loss: 1.38905389e-05
Iter: 952 loss: 1.3875575e-05
Iter: 953 loss: 1.38976902e-05
Iter: 954 loss: 1.38681853e-05
Iter: 955 loss: 1.38545474e-05
Iter: 956 loss: 1.38716514e-05
Iter: 957 loss: 1.38474716e-05
Iter: 958 loss: 1.38316118e-05
Iter: 959 loss: 1.39675367e-05
Iter: 960 loss: 1.38305504e-05
Iter: 961 loss: 1.38179948e-05
Iter: 962 loss: 1.38058622e-05
Iter: 963 loss: 1.38033238e-05
Iter: 964 loss: 1.3785695e-05
Iter: 965 loss: 1.39498552e-05
Iter: 966 loss: 1.37850257e-05
Iter: 967 loss: 1.37708066e-05
Iter: 968 loss: 1.37986044e-05
Iter: 969 loss: 1.37651941e-05
Iter: 970 loss: 1.37492934e-05
Iter: 971 loss: 1.38416144e-05
Iter: 972 loss: 1.37475508e-05
Iter: 973 loss: 1.37353436e-05
Iter: 974 loss: 1.37503239e-05
Iter: 975 loss: 1.37286479e-05
Iter: 976 loss: 1.37167017e-05
Iter: 977 loss: 1.37101915e-05
Iter: 978 loss: 1.37045581e-05
Iter: 979 loss: 1.36836534e-05
Iter: 980 loss: 1.38608584e-05
Iter: 981 loss: 1.36824046e-05
Iter: 982 loss: 1.36687249e-05
Iter: 983 loss: 1.36628496e-05
Iter: 984 loss: 1.36557628e-05
Iter: 985 loss: 1.36391918e-05
Iter: 986 loss: 1.36436192e-05
Iter: 987 loss: 1.36275394e-05
Iter: 988 loss: 1.36056497e-05
Iter: 989 loss: 1.36971112e-05
Iter: 990 loss: 1.36009758e-05
Iter: 991 loss: 1.35855262e-05
Iter: 992 loss: 1.35852351e-05
Iter: 993 loss: 1.35739911e-05
Iter: 994 loss: 1.35636437e-05
Iter: 995 loss: 1.35604223e-05
Iter: 996 loss: 1.35431137e-05
Iter: 997 loss: 1.36646586e-05
Iter: 998 loss: 1.35415485e-05
Iter: 999 loss: 1.35253158e-05
Iter: 1000 loss: 1.35645978e-05
Iter: 1001 loss: 1.35195633e-05
Iter: 1002 loss: 1.35059481e-05
Iter: 1003 loss: 1.35080236e-05
Iter: 1004 loss: 1.34956354e-05
Iter: 1005 loss: 1.34813135e-05
Iter: 1006 loss: 1.34813636e-05
Iter: 1007 loss: 1.34697239e-05
Iter: 1008 loss: 1.34679849e-05
Iter: 1009 loss: 1.34595284e-05
Iter: 1010 loss: 1.3443816e-05
Iter: 1011 loss: 1.34927268e-05
Iter: 1012 loss: 1.34394459e-05
Iter: 1013 loss: 1.34256643e-05
Iter: 1014 loss: 1.34667453e-05
Iter: 1015 loss: 1.34217062e-05
Iter: 1016 loss: 1.34099973e-05
Iter: 1017 loss: 1.34470974e-05
Iter: 1018 loss: 1.34064339e-05
Iter: 1019 loss: 1.33912417e-05
Iter: 1020 loss: 1.34004595e-05
Iter: 1021 loss: 1.33816802e-05
Iter: 1022 loss: 1.33681715e-05
Iter: 1023 loss: 1.33728099e-05
Iter: 1024 loss: 1.33587755e-05
Iter: 1025 loss: 1.33391904e-05
Iter: 1026 loss: 1.33838666e-05
Iter: 1027 loss: 1.33318845e-05
Iter: 1028 loss: 1.33135945e-05
Iter: 1029 loss: 1.34610509e-05
Iter: 1030 loss: 1.33125195e-05
Iter: 1031 loss: 1.32960049e-05
Iter: 1032 loss: 1.33562626e-05
Iter: 1033 loss: 1.32920668e-05
Iter: 1034 loss: 1.32799578e-05
Iter: 1035 loss: 1.32773712e-05
Iter: 1036 loss: 1.32697933e-05
Iter: 1037 loss: 1.32510122e-05
Iter: 1038 loss: 1.34108659e-05
Iter: 1039 loss: 1.32498899e-05
Iter: 1040 loss: 1.32398827e-05
Iter: 1041 loss: 1.32366758e-05
Iter: 1042 loss: 1.32308778e-05
Iter: 1043 loss: 1.32169134e-05
Iter: 1044 loss: 1.34113625e-05
Iter: 1045 loss: 1.32168952e-05
Iter: 1046 loss: 1.32075947e-05
Iter: 1047 loss: 1.31941515e-05
Iter: 1048 loss: 1.31935594e-05
Iter: 1049 loss: 1.31782381e-05
Iter: 1050 loss: 1.32784426e-05
Iter: 1051 loss: 1.31765919e-05
Iter: 1052 loss: 1.31637607e-05
Iter: 1053 loss: 1.32083169e-05
Iter: 1054 loss: 1.31605657e-05
Iter: 1055 loss: 1.3148011e-05
Iter: 1056 loss: 1.31643537e-05
Iter: 1057 loss: 1.3141751e-05
Iter: 1058 loss: 1.31268407e-05
Iter: 1059 loss: 1.31797342e-05
Iter: 1060 loss: 1.312317e-05
Iter: 1061 loss: 1.31103243e-05
Iter: 1062 loss: 1.31025299e-05
Iter: 1063 loss: 1.30971894e-05
Iter: 1064 loss: 1.30783465e-05
Iter: 1065 loss: 1.31161005e-05
Iter: 1066 loss: 1.30708786e-05
Iter: 1067 loss: 1.30535445e-05
Iter: 1068 loss: 1.32104633e-05
Iter: 1069 loss: 1.30528315e-05
Iter: 1070 loss: 1.30371482e-05
Iter: 1071 loss: 1.31039033e-05
Iter: 1072 loss: 1.30337457e-05
Iter: 1073 loss: 1.30211483e-05
Iter: 1074 loss: 1.30233548e-05
Iter: 1075 loss: 1.30116414e-05
Iter: 1076 loss: 1.29985492e-05
Iter: 1077 loss: 1.31492416e-05
Iter: 1078 loss: 1.29981399e-05
Iter: 1079 loss: 1.29865821e-05
Iter: 1080 loss: 1.29805612e-05
Iter: 1081 loss: 1.29755699e-05
Iter: 1082 loss: 1.29622485e-05
Iter: 1083 loss: 1.29623395e-05
Iter: 1084 loss: 1.29543596e-05
Iter: 1085 loss: 1.29449199e-05
Iter: 1086 loss: 1.29440068e-05
Iter: 1087 loss: 1.29297496e-05
Iter: 1088 loss: 1.29386372e-05
Iter: 1089 loss: 1.29207292e-05
Iter: 1090 loss: 1.29036216e-05
Iter: 1091 loss: 1.30737744e-05
Iter: 1092 loss: 1.29032815e-05
Iter: 1093 loss: 1.28900338e-05
Iter: 1094 loss: 1.29184391e-05
Iter: 1095 loss: 1.28850088e-05
Iter: 1096 loss: 1.28744578e-05
Iter: 1097 loss: 1.28899565e-05
Iter: 1098 loss: 1.28693146e-05
Iter: 1099 loss: 1.28540296e-05
Iter: 1100 loss: 1.2875953e-05
Iter: 1101 loss: 1.28465199e-05
Iter: 1102 loss: 1.28319862e-05
Iter: 1103 loss: 1.28264064e-05
Iter: 1104 loss: 1.28182728e-05
Iter: 1105 loss: 1.27980866e-05
Iter: 1106 loss: 1.29239434e-05
Iter: 1107 loss: 1.27958756e-05
Iter: 1108 loss: 1.27829089e-05
Iter: 1109 loss: 1.27829226e-05
Iter: 1110 loss: 1.27731146e-05
Iter: 1111 loss: 1.27572075e-05
Iter: 1112 loss: 1.27570183e-05
Iter: 1113 loss: 1.27457042e-05
Iter: 1114 loss: 1.27453159e-05
Iter: 1115 loss: 1.27354688e-05
Iter: 1116 loss: 1.27409739e-05
Iter: 1117 loss: 1.27292733e-05
Iter: 1118 loss: 1.27165149e-05
Iter: 1119 loss: 1.27630483e-05
Iter: 1120 loss: 1.27130807e-05
Iter: 1121 loss: 1.27010826e-05
Iter: 1122 loss: 1.27125777e-05
Iter: 1123 loss: 1.26940522e-05
Iter: 1124 loss: 1.26823143e-05
Iter: 1125 loss: 1.26848381e-05
Iter: 1126 loss: 1.26738832e-05
Iter: 1127 loss: 1.26616123e-05
Iter: 1128 loss: 1.26615887e-05
Iter: 1129 loss: 1.26510486e-05
Iter: 1130 loss: 1.26383284e-05
Iter: 1131 loss: 1.26372834e-05
Iter: 1132 loss: 1.26207779e-05
Iter: 1133 loss: 1.27130534e-05
Iter: 1134 loss: 1.26189952e-05
Iter: 1135 loss: 1.26052892e-05
Iter: 1136 loss: 1.26465766e-05
Iter: 1137 loss: 1.26014093e-05
Iter: 1138 loss: 1.25868937e-05
Iter: 1139 loss: 1.25873703e-05
Iter: 1140 loss: 1.25755869e-05
Iter: 1141 loss: 1.25587867e-05
Iter: 1142 loss: 1.26457289e-05
Iter: 1143 loss: 1.25562792e-05
Iter: 1144 loss: 1.25460356e-05
Iter: 1145 loss: 1.26823734e-05
Iter: 1146 loss: 1.25458791e-05
Iter: 1147 loss: 1.25357956e-05
Iter: 1148 loss: 1.25167535e-05
Iter: 1149 loss: 1.29417576e-05
Iter: 1150 loss: 1.25166016e-05
Iter: 1151 loss: 1.25086481e-05
Iter: 1152 loss: 1.25064435e-05
Iter: 1153 loss: 1.24974522e-05
Iter: 1154 loss: 1.24916969e-05
Iter: 1155 loss: 1.24881044e-05
Iter: 1156 loss: 1.24758662e-05
Iter: 1157 loss: 1.25336628e-05
Iter: 1158 loss: 1.24738854e-05
Iter: 1159 loss: 1.2461207e-05
Iter: 1160 loss: 1.24607905e-05
Iter: 1161 loss: 1.24512844e-05
Iter: 1162 loss: 1.24360595e-05
Iter: 1163 loss: 1.24839007e-05
Iter: 1164 loss: 1.24318885e-05
Iter: 1165 loss: 1.2420026e-05
Iter: 1166 loss: 1.2520497e-05
Iter: 1167 loss: 1.24192202e-05
Iter: 1168 loss: 1.24072812e-05
Iter: 1169 loss: 1.24041635e-05
Iter: 1170 loss: 1.2396793e-05
Iter: 1171 loss: 1.23815244e-05
Iter: 1172 loss: 1.2401988e-05
Iter: 1173 loss: 1.23740883e-05
Iter: 1174 loss: 1.23614182e-05
Iter: 1175 loss: 1.24830976e-05
Iter: 1176 loss: 1.23608097e-05
Iter: 1177 loss: 1.23490991e-05
Iter: 1178 loss: 1.23522168e-05
Iter: 1179 loss: 1.23407435e-05
Iter: 1180 loss: 1.23255668e-05
Iter: 1181 loss: 1.23451664e-05
Iter: 1182 loss: 1.23178233e-05
Iter: 1183 loss: 1.23081145e-05
Iter: 1184 loss: 1.23074497e-05
Iter: 1185 loss: 1.22992742e-05
Iter: 1186 loss: 1.22878237e-05
Iter: 1187 loss: 1.22870806e-05
Iter: 1188 loss: 1.22768397e-05
Iter: 1189 loss: 1.2276796e-05
Iter: 1190 loss: 1.22678484e-05
Iter: 1191 loss: 1.22629226e-05
Iter: 1192 loss: 1.22590418e-05
Iter: 1193 loss: 1.22477977e-05
Iter: 1194 loss: 1.22704387e-05
Iter: 1195 loss: 1.22432984e-05
Iter: 1196 loss: 1.22285655e-05
Iter: 1197 loss: 1.22697056e-05
Iter: 1198 loss: 1.22237516e-05
Iter: 1199 loss: 1.22123383e-05
Iter: 1200 loss: 1.22157771e-05
Iter: 1201 loss: 1.22043393e-05
Iter: 1202 loss: 1.21906505e-05
Iter: 1203 loss: 1.23434056e-05
Iter: 1204 loss: 1.21904195e-05
Iter: 1205 loss: 1.21801277e-05
Iter: 1206 loss: 1.21922421e-05
Iter: 1207 loss: 1.21748371e-05
Iter: 1208 loss: 1.21640624e-05
Iter: 1209 loss: 1.2153143e-05
Iter: 1210 loss: 1.21509083e-05
Iter: 1211 loss: 1.21345292e-05
Iter: 1212 loss: 1.22766542e-05
Iter: 1213 loss: 1.21337453e-05
Iter: 1214 loss: 1.21224248e-05
Iter: 1215 loss: 1.21967551e-05
Iter: 1216 loss: 1.21210805e-05
Iter: 1217 loss: 1.21118119e-05
Iter: 1218 loss: 1.21052872e-05
Iter: 1219 loss: 1.21018329e-05
Iter: 1220 loss: 1.2087743e-05
Iter: 1221 loss: 1.22441206e-05
Iter: 1222 loss: 1.20872237e-05
Iter: 1223 loss: 1.20759e-05
Iter: 1224 loss: 1.20935874e-05
Iter: 1225 loss: 1.20704744e-05
Iter: 1226 loss: 1.20620825e-05
Iter: 1227 loss: 1.21437251e-05
Iter: 1228 loss: 1.20618352e-05
Iter: 1229 loss: 1.20537179e-05
Iter: 1230 loss: 1.2038252e-05
Iter: 1231 loss: 1.23785676e-05
Iter: 1232 loss: 1.2038201e-05
Iter: 1233 loss: 1.2022896e-05
Iter: 1234 loss: 1.20993182e-05
Iter: 1235 loss: 1.20202021e-05
Iter: 1236 loss: 1.2008e-05
Iter: 1237 loss: 1.21028752e-05
Iter: 1238 loss: 1.20070708e-05
Iter: 1239 loss: 1.1997101e-05
Iter: 1240 loss: 1.19887445e-05
Iter: 1241 loss: 1.19858469e-05
Iter: 1242 loss: 1.19729057e-05
Iter: 1243 loss: 1.21229596e-05
Iter: 1244 loss: 1.19727338e-05
Iter: 1245 loss: 1.19622619e-05
Iter: 1246 loss: 1.19797942e-05
Iter: 1247 loss: 1.19571341e-05
Iter: 1248 loss: 1.19464512e-05
Iter: 1249 loss: 1.19369988e-05
Iter: 1250 loss: 1.19343877e-05
Iter: 1251 loss: 1.1918668e-05
Iter: 1252 loss: 1.19951101e-05
Iter: 1253 loss: 1.19159395e-05
Iter: 1254 loss: 1.19028609e-05
Iter: 1255 loss: 1.19892375e-05
Iter: 1256 loss: 1.19015604e-05
Iter: 1257 loss: 1.1889193e-05
Iter: 1258 loss: 1.19128e-05
Iter: 1259 loss: 1.18840953e-05
Iter: 1260 loss: 1.18710323e-05
Iter: 1261 loss: 1.19312908e-05
Iter: 1262 loss: 1.18685421e-05
Iter: 1263 loss: 1.18571834e-05
Iter: 1264 loss: 1.19158558e-05
Iter: 1265 loss: 1.18555e-05
Iter: 1266 loss: 1.18479338e-05
Iter: 1267 loss: 1.18586377e-05
Iter: 1268 loss: 1.18440967e-05
Iter: 1269 loss: 1.18321477e-05
Iter: 1270 loss: 1.18266253e-05
Iter: 1271 loss: 1.18207545e-05
Iter: 1272 loss: 1.18088819e-05
Iter: 1273 loss: 1.18129556e-05
Iter: 1274 loss: 1.18006374e-05
Iter: 1275 loss: 1.17874279e-05
Iter: 1276 loss: 1.17876125e-05
Iter: 1277 loss: 1.17773152e-05
Iter: 1278 loss: 1.17711852e-05
Iter: 1279 loss: 1.17667932e-05
Iter: 1280 loss: 1.17557865e-05
Iter: 1281 loss: 1.18913385e-05
Iter: 1282 loss: 1.17556592e-05
Iter: 1283 loss: 1.17457776e-05
Iter: 1284 loss: 1.17379204e-05
Iter: 1285 loss: 1.17346899e-05
Iter: 1286 loss: 1.17198833e-05
Iter: 1287 loss: 1.17674572e-05
Iter: 1288 loss: 1.17155278e-05
Iter: 1289 loss: 1.1702743e-05
Iter: 1290 loss: 1.17045938e-05
Iter: 1291 loss: 1.16928122e-05
Iter: 1292 loss: 1.16785459e-05
Iter: 1293 loss: 1.18550506e-05
Iter: 1294 loss: 1.16783185e-05
Iter: 1295 loss: 1.16657029e-05
Iter: 1296 loss: 1.17072414e-05
Iter: 1297 loss: 1.16621441e-05
Iter: 1298 loss: 1.16522451e-05
Iter: 1299 loss: 1.17114087e-05
Iter: 1300 loss: 1.1651051e-05
Iter: 1301 loss: 1.16425563e-05
Iter: 1302 loss: 1.16452247e-05
Iter: 1303 loss: 1.16363644e-05
Iter: 1304 loss: 1.16264364e-05
Iter: 1305 loss: 1.16760111e-05
Iter: 1306 loss: 1.16248193e-05
Iter: 1307 loss: 1.16148767e-05
Iter: 1308 loss: 1.16121919e-05
Iter: 1309 loss: 1.16061201e-05
Iter: 1310 loss: 1.15937437e-05
Iter: 1311 loss: 1.16125857e-05
Iter: 1312 loss: 1.15877647e-05
Iter: 1313 loss: 1.15775501e-05
Iter: 1314 loss: 1.17317077e-05
Iter: 1315 loss: 1.15776484e-05
Iter: 1316 loss: 1.15687399e-05
Iter: 1317 loss: 1.15643561e-05
Iter: 1318 loss: 1.15600651e-05
Iter: 1319 loss: 1.15487956e-05
Iter: 1320 loss: 1.16145184e-05
Iter: 1321 loss: 1.15472349e-05
Iter: 1322 loss: 1.1535325e-05
Iter: 1323 loss: 1.15520634e-05
Iter: 1324 loss: 1.15294961e-05
Iter: 1325 loss: 1.15189487e-05
Iter: 1326 loss: 1.15193934e-05
Iter: 1327 loss: 1.15106286e-05
Iter: 1328 loss: 1.14958766e-05
Iter: 1329 loss: 1.155054e-05
Iter: 1330 loss: 1.14923287e-05
Iter: 1331 loss: 1.14831764e-05
Iter: 1332 loss: 1.15947523e-05
Iter: 1333 loss: 1.14828763e-05
Iter: 1334 loss: 1.14735949e-05
Iter: 1335 loss: 1.14857385e-05
Iter: 1336 loss: 1.14688755e-05
Iter: 1337 loss: 1.14594923e-05
Iter: 1338 loss: 1.15020575e-05
Iter: 1339 loss: 1.14580052e-05
Iter: 1340 loss: 1.14490631e-05
Iter: 1341 loss: 1.14565837e-05
Iter: 1342 loss: 1.1443859e-05
Iter: 1343 loss: 1.14341401e-05
Iter: 1344 loss: 1.1459605e-05
Iter: 1345 loss: 1.14308432e-05
Iter: 1346 loss: 1.1420816e-05
Iter: 1347 loss: 1.14464819e-05
Iter: 1348 loss: 1.14174672e-05
Iter: 1349 loss: 1.14068489e-05
Iter: 1350 loss: 1.13921178e-05
Iter: 1351 loss: 1.13914657e-05
Iter: 1352 loss: 1.137654e-05
Iter: 1353 loss: 1.13762489e-05
Iter: 1354 loss: 1.13661199e-05
Iter: 1355 loss: 1.13965079e-05
Iter: 1356 loss: 1.13628839e-05
Iter: 1357 loss: 1.13547776e-05
Iter: 1358 loss: 1.1353839e-05
Iter: 1359 loss: 1.13477936e-05
Iter: 1360 loss: 1.13338319e-05
Iter: 1361 loss: 1.14059603e-05
Iter: 1362 loss: 1.13316091e-05
Iter: 1363 loss: 1.13219239e-05
Iter: 1364 loss: 1.13138667e-05
Iter: 1365 loss: 1.13111091e-05
Iter: 1366 loss: 1.12975613e-05
Iter: 1367 loss: 1.13825135e-05
Iter: 1368 loss: 1.12959369e-05
Iter: 1369 loss: 1.12865227e-05
Iter: 1370 loss: 1.14051472e-05
Iter: 1371 loss: 1.12865901e-05
Iter: 1372 loss: 1.12780081e-05
Iter: 1373 loss: 1.12813905e-05
Iter: 1374 loss: 1.12721709e-05
Iter: 1375 loss: 1.12634516e-05
Iter: 1376 loss: 1.12917851e-05
Iter: 1377 loss: 1.12608759e-05
Iter: 1378 loss: 1.1250273e-05
Iter: 1379 loss: 1.12641683e-05
Iter: 1380 loss: 1.12449961e-05
Iter: 1381 loss: 1.12359867e-05
Iter: 1382 loss: 1.12485595e-05
Iter: 1383 loss: 1.12316975e-05
Iter: 1384 loss: 1.12189191e-05
Iter: 1385 loss: 1.12519938e-05
Iter: 1386 loss: 1.12148382e-05
Iter: 1387 loss: 1.12044872e-05
Iter: 1388 loss: 1.12120342e-05
Iter: 1389 loss: 1.11981963e-05
Iter: 1390 loss: 1.11867312e-05
Iter: 1391 loss: 1.13188962e-05
Iter: 1392 loss: 1.11868212e-05
Iter: 1393 loss: 1.1176915e-05
Iter: 1394 loss: 1.11715462e-05
Iter: 1395 loss: 1.11672089e-05
Iter: 1396 loss: 1.11575391e-05
Iter: 1397 loss: 1.12290836e-05
Iter: 1398 loss: 1.11565669e-05
Iter: 1399 loss: 1.11457448e-05
Iter: 1400 loss: 1.11434128e-05
Iter: 1401 loss: 1.11364279e-05
Iter: 1402 loss: 1.11233585e-05
Iter: 1403 loss: 1.11663894e-05
Iter: 1404 loss: 1.11196132e-05
Iter: 1405 loss: 1.11084501e-05
Iter: 1406 loss: 1.11540176e-05
Iter: 1407 loss: 1.1106129e-05
Iter: 1408 loss: 1.10958381e-05
Iter: 1409 loss: 1.12064063e-05
Iter: 1410 loss: 1.1095517e-05
Iter: 1411 loss: 1.10895699e-05
Iter: 1412 loss: 1.10809824e-05
Iter: 1413 loss: 1.10808796e-05
Iter: 1414 loss: 1.10698547e-05
Iter: 1415 loss: 1.11775844e-05
Iter: 1416 loss: 1.10694473e-05
Iter: 1417 loss: 1.10614128e-05
Iter: 1418 loss: 1.10608089e-05
Iter: 1419 loss: 1.10546125e-05
Iter: 1420 loss: 1.10450283e-05
Iter: 1421 loss: 1.10691799e-05
Iter: 1422 loss: 1.10415531e-05
Iter: 1423 loss: 1.1029877e-05
Iter: 1424 loss: 1.10675846e-05
Iter: 1425 loss: 1.10265228e-05
Iter: 1426 loss: 1.10161873e-05
Iter: 1427 loss: 1.10369274e-05
Iter: 1428 loss: 1.10121564e-05
Iter: 1429 loss: 1.10021547e-05
Iter: 1430 loss: 1.10697947e-05
Iter: 1431 loss: 1.10012943e-05
Iter: 1432 loss: 1.09908788e-05
Iter: 1433 loss: 1.09811717e-05
Iter: 1434 loss: 1.0978687e-05
Iter: 1435 loss: 1.09659613e-05
Iter: 1436 loss: 1.10394494e-05
Iter: 1437 loss: 1.09644398e-05
Iter: 1438 loss: 1.09510365e-05
Iter: 1439 loss: 1.09796229e-05
Iter: 1440 loss: 1.09457987e-05
Iter: 1441 loss: 1.09353205e-05
Iter: 1442 loss: 1.09483835e-05
Iter: 1443 loss: 1.093012e-05
Iter: 1444 loss: 1.09214834e-05
Iter: 1445 loss: 1.09215753e-05
Iter: 1446 loss: 1.09139e-05
Iter: 1447 loss: 1.09149041e-05
Iter: 1448 loss: 1.09078373e-05
Iter: 1449 loss: 1.08999648e-05
Iter: 1450 loss: 1.0903871e-05
Iter: 1451 loss: 1.08946606e-05
Iter: 1452 loss: 1.08832437e-05
Iter: 1453 loss: 1.09620632e-05
Iter: 1454 loss: 1.08822178e-05
Iter: 1455 loss: 1.08743225e-05
Iter: 1456 loss: 1.08713448e-05
Iter: 1457 loss: 1.08668592e-05
Iter: 1458 loss: 1.08554877e-05
Iter: 1459 loss: 1.08808126e-05
Iter: 1460 loss: 1.08510767e-05
Iter: 1461 loss: 1.08384074e-05
Iter: 1462 loss: 1.09137436e-05
Iter: 1463 loss: 1.08366694e-05
Iter: 1464 loss: 1.08261092e-05
Iter: 1465 loss: 1.08456552e-05
Iter: 1466 loss: 1.08216673e-05
Iter: 1467 loss: 1.08120203e-05
Iter: 1468 loss: 1.08821041e-05
Iter: 1469 loss: 1.08111108e-05
Iter: 1470 loss: 1.08029435e-05
Iter: 1471 loss: 1.0795623e-05
Iter: 1472 loss: 1.07933647e-05
Iter: 1473 loss: 1.07832602e-05
Iter: 1474 loss: 1.08521117e-05
Iter: 1475 loss: 1.0782147e-05
Iter: 1476 loss: 1.07704791e-05
Iter: 1477 loss: 1.07786491e-05
Iter: 1478 loss: 1.07631513e-05
Iter: 1479 loss: 1.07531923e-05
Iter: 1480 loss: 1.08096156e-05
Iter: 1481 loss: 1.07516498e-05
Iter: 1482 loss: 1.074186e-05
Iter: 1483 loss: 1.07978476e-05
Iter: 1484 loss: 1.07405212e-05
Iter: 1485 loss: 1.07328524e-05
Iter: 1486 loss: 1.07240985e-05
Iter: 1487 loss: 1.07230371e-05
Iter: 1488 loss: 1.07114774e-05
Iter: 1489 loss: 1.07888154e-05
Iter: 1490 loss: 1.07107035e-05
Iter: 1491 loss: 1.07012893e-05
Iter: 1492 loss: 1.07497026e-05
Iter: 1493 loss: 1.06998777e-05
Iter: 1494 loss: 1.06919424e-05
Iter: 1495 loss: 1.06775151e-05
Iter: 1496 loss: 1.10158289e-05
Iter: 1497 loss: 1.06775396e-05
Iter: 1498 loss: 1.06688085e-05
Iter: 1499 loss: 1.06687676e-05
Iter: 1500 loss: 1.06603302e-05
Iter: 1501 loss: 1.06673742e-05
Iter: 1502 loss: 1.06552507e-05
Iter: 1503 loss: 1.06442994e-05
Iter: 1504 loss: 1.0667778e-05
Iter: 1505 loss: 1.06401167e-05
Iter: 1506 loss: 1.06279731e-05
Iter: 1507 loss: 1.06758289e-05
Iter: 1508 loss: 1.06251555e-05
Iter: 1509 loss: 1.06160014e-05
Iter: 1510 loss: 1.06273292e-05
Iter: 1511 loss: 1.06112739e-05
Iter: 1512 loss: 1.06019579e-05
Iter: 1513 loss: 1.06298521e-05
Iter: 1514 loss: 1.05989784e-05
Iter: 1515 loss: 1.05869549e-05
Iter: 1516 loss: 1.06161897e-05
Iter: 1517 loss: 1.05824156e-05
Iter: 1518 loss: 1.05760664e-05
Iter: 1519 loss: 1.06750504e-05
Iter: 1520 loss: 1.05760673e-05
Iter: 1521 loss: 1.05699273e-05
Iter: 1522 loss: 1.05619456e-05
Iter: 1523 loss: 1.05616436e-05
Iter: 1524 loss: 1.05522595e-05
Iter: 1525 loss: 1.05627514e-05
Iter: 1526 loss: 1.05473737e-05
Iter: 1527 loss: 1.0536327e-05
Iter: 1528 loss: 1.06310135e-05
Iter: 1529 loss: 1.05357012e-05
Iter: 1530 loss: 1.05266754e-05
Iter: 1531 loss: 1.05378731e-05
Iter: 1532 loss: 1.05219515e-05
Iter: 1533 loss: 1.05126855e-05
Iter: 1534 loss: 1.05076497e-05
Iter: 1535 loss: 1.05033132e-05
Iter: 1536 loss: 1.04923893e-05
Iter: 1537 loss: 1.06174284e-05
Iter: 1538 loss: 1.04921564e-05
Iter: 1539 loss: 1.04819264e-05
Iter: 1540 loss: 1.05133349e-05
Iter: 1541 loss: 1.04792152e-05
Iter: 1542 loss: 1.04710698e-05
Iter: 1543 loss: 1.04875226e-05
Iter: 1544 loss: 1.04680294e-05
Iter: 1545 loss: 1.04596747e-05
Iter: 1546 loss: 1.04873843e-05
Iter: 1547 loss: 1.045729e-05
Iter: 1548 loss: 1.04482533e-05
Iter: 1549 loss: 1.04429291e-05
Iter: 1550 loss: 1.04390892e-05
Iter: 1551 loss: 1.04312521e-05
Iter: 1552 loss: 1.04311266e-05
Iter: 1553 loss: 1.04243918e-05
Iter: 1554 loss: 1.04307283e-05
Iter: 1555 loss: 1.04207302e-05
Iter: 1556 loss: 1.0412341e-05
Iter: 1557 loss: 1.04507935e-05
Iter: 1558 loss: 1.04107203e-05
Iter: 1559 loss: 1.04037581e-05
Iter: 1560 loss: 1.03978218e-05
Iter: 1561 loss: 1.039565e-05
Iter: 1562 loss: 1.03852581e-05
Iter: 1563 loss: 1.04066985e-05
Iter: 1564 loss: 1.03807715e-05
Iter: 1565 loss: 1.03687726e-05
Iter: 1566 loss: 1.04691517e-05
Iter: 1567 loss: 1.03681123e-05
Iter: 1568 loss: 1.03595858e-05
Iter: 1569 loss: 1.03616649e-05
Iter: 1570 loss: 1.0353242e-05
Iter: 1571 loss: 1.03436041e-05
Iter: 1572 loss: 1.03533057e-05
Iter: 1573 loss: 1.03382636e-05
Iter: 1574 loss: 1.03270704e-05
Iter: 1575 loss: 1.04105475e-05
Iter: 1576 loss: 1.03262601e-05
Iter: 1577 loss: 1.03152652e-05
Iter: 1578 loss: 1.03428965e-05
Iter: 1579 loss: 1.03115754e-05
Iter: 1580 loss: 1.03044677e-05
Iter: 1581 loss: 1.03136854e-05
Iter: 1582 loss: 1.03010207e-05
Iter: 1583 loss: 1.02908343e-05
Iter: 1584 loss: 1.03123348e-05
Iter: 1585 loss: 1.02866297e-05
Iter: 1586 loss: 1.027703e-05
Iter: 1587 loss: 1.02979611e-05
Iter: 1588 loss: 1.02734466e-05
Iter: 1589 loss: 1.02658432e-05
Iter: 1590 loss: 1.03687662e-05
Iter: 1591 loss: 1.02657878e-05
Iter: 1592 loss: 1.02589856e-05
Iter: 1593 loss: 1.02539252e-05
Iter: 1594 loss: 1.02519107e-05
Iter: 1595 loss: 1.02417252e-05
Iter: 1596 loss: 1.03009625e-05
Iter: 1597 loss: 1.02402137e-05
Iter: 1598 loss: 1.02331587e-05
Iter: 1599 loss: 1.02337017e-05
Iter: 1600 loss: 1.02276827e-05
Iter: 1601 loss: 1.02180393e-05
Iter: 1602 loss: 1.02426648e-05
Iter: 1603 loss: 1.02146359e-05
Iter: 1604 loss: 1.02046433e-05
Iter: 1605 loss: 1.02893209e-05
Iter: 1606 loss: 1.02040249e-05
Iter: 1607 loss: 1.01968517e-05
Iter: 1608 loss: 1.01860524e-05
Iter: 1609 loss: 1.01859232e-05
Iter: 1610 loss: 1.01720725e-05
Iter: 1611 loss: 1.02212216e-05
Iter: 1612 loss: 1.01684745e-05
Iter: 1613 loss: 1.01591759e-05
Iter: 1614 loss: 1.0159205e-05
Iter: 1615 loss: 1.0151698e-05
Iter: 1616 loss: 1.0157748e-05
Iter: 1617 loss: 1.01472015e-05
Iter: 1618 loss: 1.01394508e-05
Iter: 1619 loss: 1.01379392e-05
Iter: 1620 loss: 1.01329206e-05
Iter: 1621 loss: 1.01222877e-05
Iter: 1622 loss: 1.02304311e-05
Iter: 1623 loss: 1.01220085e-05
Iter: 1624 loss: 1.01137593e-05
Iter: 1625 loss: 1.01218911e-05
Iter: 1626 loss: 1.01095775e-05
Iter: 1627 loss: 1.01004871e-05
Iter: 1628 loss: 1.01844689e-05
Iter: 1629 loss: 1.01004161e-05
Iter: 1630 loss: 1.00932311e-05
Iter: 1631 loss: 1.00862908e-05
Iter: 1632 loss: 1.00848229e-05
Iter: 1633 loss: 1.00759153e-05
Iter: 1634 loss: 1.01403684e-05
Iter: 1635 loss: 1.00749421e-05
Iter: 1636 loss: 1.00662228e-05
Iter: 1637 loss: 1.00666548e-05
Iter: 1638 loss: 1.00594007e-05
Iter: 1639 loss: 1.00508969e-05
Iter: 1640 loss: 1.01048681e-05
Iter: 1641 loss: 1.00501047e-05
Iter: 1642 loss: 1.00405796e-05
Iter: 1643 loss: 1.00536417e-05
Iter: 1644 loss: 1.00358466e-05
Iter: 1645 loss: 1.00270136e-05
Iter: 1646 loss: 1.00312582e-05
Iter: 1647 loss: 1.00206908e-05
Iter: 1648 loss: 1.00102434e-05
Iter: 1649 loss: 1.00476227e-05
Iter: 1650 loss: 1.00075504e-05
Iter: 1651 loss: 9.99726e-06
Iter: 1652 loss: 1.00865991e-05
Iter: 1653 loss: 9.99683289e-06
Iter: 1654 loss: 9.98904852e-06
Iter: 1655 loss: 9.9876188e-06
Iter: 1656 loss: 9.9824174e-06
Iter: 1657 loss: 9.97219649e-06
Iter: 1658 loss: 9.98924e-06
Iter: 1659 loss: 9.96775452e-06
Iter: 1660 loss: 9.96027302e-06
Iter: 1661 loss: 9.96021208e-06
Iter: 1662 loss: 9.95484788e-06
Iter: 1663 loss: 9.95572555e-06
Iter: 1664 loss: 9.9507e-06
Iter: 1665 loss: 9.94102083e-06
Iter: 1666 loss: 9.95629762e-06
Iter: 1667 loss: 9.93640606e-06
Iter: 1668 loss: 9.92763216e-06
Iter: 1669 loss: 9.93336562e-06
Iter: 1670 loss: 9.92198511e-06
Iter: 1671 loss: 9.9139088e-06
Iter: 1672 loss: 9.98639098e-06
Iter: 1673 loss: 9.91340676e-06
Iter: 1674 loss: 9.90563331e-06
Iter: 1675 loss: 9.89994078e-06
Iter: 1676 loss: 9.89729688e-06
Iter: 1677 loss: 9.88764623e-06
Iter: 1678 loss: 1.00056532e-05
Iter: 1679 loss: 9.88759348e-06
Iter: 1680 loss: 9.88041211e-06
Iter: 1681 loss: 9.88968259e-06
Iter: 1682 loss: 9.87668409e-06
Iter: 1683 loss: 9.86813575e-06
Iter: 1684 loss: 9.85957649e-06
Iter: 1685 loss: 9.85784391e-06
Iter: 1686 loss: 9.84488815e-06
Iter: 1687 loss: 9.96594827e-06
Iter: 1688 loss: 9.84447706e-06
Iter: 1689 loss: 9.83491918e-06
Iter: 1690 loss: 9.91065917e-06
Iter: 1691 loss: 9.83421705e-06
Iter: 1692 loss: 9.82823894e-06
Iter: 1693 loss: 9.82060192e-06
Iter: 1694 loss: 9.8201981e-06
Iter: 1695 loss: 9.80996538e-06
Iter: 1696 loss: 9.87551e-06
Iter: 1697 loss: 9.80923414e-06
Iter: 1698 loss: 9.80112e-06
Iter: 1699 loss: 9.87768726e-06
Iter: 1700 loss: 9.8007e-06
Iter: 1701 loss: 9.79462584e-06
Iter: 1702 loss: 9.79279775e-06
Iter: 1703 loss: 9.78959906e-06
Iter: 1704 loss: 9.7802349e-06
Iter: 1705 loss: 9.81536868e-06
Iter: 1706 loss: 9.77789568e-06
Iter: 1707 loss: 9.77058789e-06
Iter: 1708 loss: 9.76262891e-06
Iter: 1709 loss: 9.76141382e-06
Iter: 1710 loss: 9.75118655e-06
Iter: 1711 loss: 9.90329954e-06
Iter: 1712 loss: 9.7511e-06
Iter: 1713 loss: 9.74320756e-06
Iter: 1714 loss: 9.7463726e-06
Iter: 1715 loss: 9.73778333e-06
Iter: 1716 loss: 9.72864109e-06
Iter: 1717 loss: 9.78440221e-06
Iter: 1718 loss: 9.72754242e-06
Iter: 1719 loss: 9.71951e-06
Iter: 1720 loss: 9.73102124e-06
Iter: 1721 loss: 9.71584632e-06
Iter: 1722 loss: 9.70671317e-06
Iter: 1723 loss: 9.70470319e-06
Iter: 1724 loss: 9.699e-06
Iter: 1725 loss: 9.6908816e-06
Iter: 1726 loss: 9.69088615e-06
Iter: 1727 loss: 9.68325821e-06
Iter: 1728 loss: 9.68679069e-06
Iter: 1729 loss: 9.67827054e-06
Iter: 1730 loss: 9.66948e-06
Iter: 1731 loss: 9.67582855e-06
Iter: 1732 loss: 9.66395783e-06
Iter: 1733 loss: 9.65591516e-06
Iter: 1734 loss: 9.74669547e-06
Iter: 1735 loss: 9.65568e-06
Iter: 1736 loss: 9.64777792e-06
Iter: 1737 loss: 9.66515199e-06
Iter: 1738 loss: 9.64476203e-06
Iter: 1739 loss: 9.63780803e-06
Iter: 1740 loss: 9.63321872e-06
Iter: 1741 loss: 9.63035563e-06
Iter: 1742 loss: 9.61984733e-06
Iter: 1743 loss: 9.72088492e-06
Iter: 1744 loss: 9.61954629e-06
Iter: 1745 loss: 9.612756e-06
Iter: 1746 loss: 9.60037232e-06
Iter: 1747 loss: 9.88252214e-06
Iter: 1748 loss: 9.6002168e-06
Iter: 1749 loss: 9.59246063e-06
Iter: 1750 loss: 9.59158388e-06
Iter: 1751 loss: 9.58506826e-06
Iter: 1752 loss: 9.58229157e-06
Iter: 1753 loss: 9.57904558e-06
Iter: 1754 loss: 9.57079192e-06
Iter: 1755 loss: 9.631176e-06
Iter: 1756 loss: 9.57004431e-06
Iter: 1757 loss: 9.56276745e-06
Iter: 1758 loss: 9.56103668e-06
Iter: 1759 loss: 9.55645191e-06
Iter: 1760 loss: 9.54651841e-06
Iter: 1761 loss: 9.58098462e-06
Iter: 1762 loss: 9.54417555e-06
Iter: 1763 loss: 9.53501512e-06
Iter: 1764 loss: 9.60779653e-06
Iter: 1765 loss: 9.53452127e-06
Iter: 1766 loss: 9.52758819e-06
Iter: 1767 loss: 9.5272926e-06
Iter: 1768 loss: 9.52231312e-06
Iter: 1769 loss: 9.51303809e-06
Iter: 1770 loss: 9.52098708e-06
Iter: 1771 loss: 9.50755748e-06
Iter: 1772 loss: 9.49699e-06
Iter: 1773 loss: 9.49701098e-06
Iter: 1774 loss: 9.49258356e-06
Iter: 1775 loss: 9.48546403e-06
Iter: 1776 loss: 9.4853458e-06
Iter: 1777 loss: 9.47473e-06
Iter: 1778 loss: 9.50597496e-06
Iter: 1779 loss: 9.4713505e-06
Iter: 1780 loss: 9.45983902e-06
Iter: 1781 loss: 9.50723552e-06
Iter: 1782 loss: 9.45746069e-06
Iter: 1783 loss: 9.45073498e-06
Iter: 1784 loss: 9.45280499e-06
Iter: 1785 loss: 9.44594103e-06
Iter: 1786 loss: 9.43572559e-06
Iter: 1787 loss: 9.50519097e-06
Iter: 1788 loss: 9.4346251e-06
Iter: 1789 loss: 9.42708e-06
Iter: 1790 loss: 9.43554915e-06
Iter: 1791 loss: 9.42286533e-06
Iter: 1792 loss: 9.41511644e-06
Iter: 1793 loss: 9.44266139e-06
Iter: 1794 loss: 9.41310554e-06
Iter: 1795 loss: 9.4042789e-06
Iter: 1796 loss: 9.41245889e-06
Iter: 1797 loss: 9.39915572e-06
Iter: 1798 loss: 9.38992889e-06
Iter: 1799 loss: 9.42872248e-06
Iter: 1800 loss: 9.38809535e-06
Iter: 1801 loss: 9.37847381e-06
Iter: 1802 loss: 9.42451516e-06
Iter: 1803 loss: 9.37693e-06
Iter: 1804 loss: 9.3704748e-06
Iter: 1805 loss: 9.36849665e-06
Iter: 1806 loss: 9.36463948e-06
Iter: 1807 loss: 9.35829e-06
Iter: 1808 loss: 9.35838762e-06
Iter: 1809 loss: 9.35240587e-06
Iter: 1810 loss: 9.35181743e-06
Iter: 1811 loss: 9.34760101e-06
Iter: 1812 loss: 9.34049422e-06
Iter: 1813 loss: 9.33411e-06
Iter: 1814 loss: 9.33249794e-06
Iter: 1815 loss: 9.32382864e-06
Iter: 1816 loss: 9.32379e-06
Iter: 1817 loss: 9.3168519e-06
Iter: 1818 loss: 9.32066723e-06
Iter: 1819 loss: 9.3123781e-06
Iter: 1820 loss: 9.30371516e-06
Iter: 1821 loss: 9.31055456e-06
Iter: 1822 loss: 9.2984892e-06
Iter: 1823 loss: 9.28799182e-06
Iter: 1824 loss: 9.39733218e-06
Iter: 1825 loss: 9.28760528e-06
Iter: 1826 loss: 9.28073587e-06
Iter: 1827 loss: 9.27506699e-06
Iter: 1828 loss: 9.2732007e-06
Iter: 1829 loss: 9.26473331e-06
Iter: 1830 loss: 9.361087e-06
Iter: 1831 loss: 9.26467237e-06
Iter: 1832 loss: 9.2585542e-06
Iter: 1833 loss: 9.26614121e-06
Iter: 1834 loss: 9.25500899e-06
Iter: 1835 loss: 9.24803135e-06
Iter: 1836 loss: 9.26691519e-06
Iter: 1837 loss: 9.24542e-06
Iter: 1838 loss: 9.23583139e-06
Iter: 1839 loss: 9.24925916e-06
Iter: 1840 loss: 9.23100743e-06
Iter: 1841 loss: 9.22305389e-06
Iter: 1842 loss: 9.25074073e-06
Iter: 1843 loss: 9.22067738e-06
Iter: 1844 loss: 9.21368519e-06
Iter: 1845 loss: 9.28034478e-06
Iter: 1846 loss: 9.21330138e-06
Iter: 1847 loss: 9.20734601e-06
Iter: 1848 loss: 9.19816375e-06
Iter: 1849 loss: 9.19814738e-06
Iter: 1850 loss: 9.18739352e-06
Iter: 1851 loss: 9.20720777e-06
Iter: 1852 loss: 9.18255773e-06
Iter: 1853 loss: 9.17482066e-06
Iter: 1854 loss: 9.28422e-06
Iter: 1855 loss: 9.17476063e-06
Iter: 1856 loss: 9.16716726e-06
Iter: 1857 loss: 9.16649424e-06
Iter: 1858 loss: 9.16087447e-06
Iter: 1859 loss: 9.15319197e-06
Iter: 1860 loss: 9.19787726e-06
Iter: 1861 loss: 9.15191e-06
Iter: 1862 loss: 9.14473185e-06
Iter: 1863 loss: 9.1752463e-06
Iter: 1864 loss: 9.14325392e-06
Iter: 1865 loss: 9.13624808e-06
Iter: 1866 loss: 9.12802625e-06
Iter: 1867 loss: 9.12711e-06
Iter: 1868 loss: 9.11882398e-06
Iter: 1869 loss: 9.23381e-06
Iter: 1870 loss: 9.11890493e-06
Iter: 1871 loss: 9.11149618e-06
Iter: 1872 loss: 9.11769712e-06
Iter: 1873 loss: 9.1071106e-06
Iter: 1874 loss: 9.09895243e-06
Iter: 1875 loss: 9.13949225e-06
Iter: 1876 loss: 9.09755181e-06
Iter: 1877 loss: 9.08948732e-06
Iter: 1878 loss: 9.09799564e-06
Iter: 1879 loss: 9.08496e-06
Iter: 1880 loss: 9.07832418e-06
Iter: 1881 loss: 9.14616794e-06
Iter: 1882 loss: 9.07809954e-06
Iter: 1883 loss: 9.07212871e-06
Iter: 1884 loss: 9.07722278e-06
Iter: 1885 loss: 9.06865353e-06
Iter: 1886 loss: 9.06169589e-06
Iter: 1887 loss: 9.05510751e-06
Iter: 1888 loss: 9.05366323e-06
Iter: 1889 loss: 9.04380249e-06
Iter: 1890 loss: 9.07730464e-06
Iter: 1891 loss: 9.04136141e-06
Iter: 1892 loss: 9.03167e-06
Iter: 1893 loss: 9.11942789e-06
Iter: 1894 loss: 9.03102591e-06
Iter: 1895 loss: 9.02427e-06
Iter: 1896 loss: 9.03673e-06
Iter: 1897 loss: 9.02148895e-06
Iter: 1898 loss: 9.01508702e-06
Iter: 1899 loss: 9.02772081e-06
Iter: 1900 loss: 9.01251224e-06
Iter: 1901 loss: 9.00392115e-06
Iter: 1902 loss: 9.02708052e-06
Iter: 1903 loss: 9.00106716e-06
Iter: 1904 loss: 8.99314909e-06
Iter: 1905 loss: 8.99028237e-06
Iter: 1906 loss: 8.98588496e-06
Iter: 1907 loss: 8.97717473e-06
Iter: 1908 loss: 9.08265702e-06
Iter: 1909 loss: 8.97728387e-06
Iter: 1910 loss: 8.96950405e-06
Iter: 1911 loss: 8.97990503e-06
Iter: 1912 loss: 8.96556503e-06
Iter: 1913 loss: 8.95914127e-06
Iter: 1914 loss: 8.99434235e-06
Iter: 1915 loss: 8.95823632e-06
Iter: 1916 loss: 8.9515579e-06
Iter: 1917 loss: 8.95750236e-06
Iter: 1918 loss: 8.9477744e-06
Iter: 1919 loss: 8.93997276e-06
Iter: 1920 loss: 8.98687e-06
Iter: 1921 loss: 8.93876677e-06
Iter: 1922 loss: 8.93196375e-06
Iter: 1923 loss: 8.93007e-06
Iter: 1924 loss: 8.92578919e-06
Iter: 1925 loss: 8.91867421e-06
Iter: 1926 loss: 8.92923254e-06
Iter: 1927 loss: 8.91498803e-06
Iter: 1928 loss: 8.90547562e-06
Iter: 1929 loss: 8.92036405e-06
Iter: 1930 loss: 8.90092542e-06
Iter: 1931 loss: 8.89381954e-06
Iter: 1932 loss: 8.89377134e-06
Iter: 1933 loss: 8.8888055e-06
Iter: 1934 loss: 8.88059731e-06
Iter: 1935 loss: 8.88065188e-06
Iter: 1936 loss: 8.87290116e-06
Iter: 1937 loss: 8.9955256e-06
Iter: 1938 loss: 8.87300939e-06
Iter: 1939 loss: 8.86648195e-06
Iter: 1940 loss: 8.86250382e-06
Iter: 1941 loss: 8.85975e-06
Iter: 1942 loss: 8.85211375e-06
Iter: 1943 loss: 8.8775414e-06
Iter: 1944 loss: 8.84980909e-06
Iter: 1945 loss: 8.84096153e-06
Iter: 1946 loss: 8.89372313e-06
Iter: 1947 loss: 8.83974917e-06
Iter: 1948 loss: 8.83259145e-06
Iter: 1949 loss: 8.8380466e-06
Iter: 1950 loss: 8.82834e-06
Iter: 1951 loss: 8.82071072e-06
Iter: 1952 loss: 8.88348677e-06
Iter: 1953 loss: 8.82013319e-06
Iter: 1954 loss: 8.8143679e-06
Iter: 1955 loss: 8.82727e-06
Iter: 1956 loss: 8.81199048e-06
Iter: 1957 loss: 8.80650259e-06
Iter: 1958 loss: 8.81984e-06
Iter: 1959 loss: 8.80436892e-06
Iter: 1960 loss: 8.79863092e-06
Iter: 1961 loss: 8.79465733e-06
Iter: 1962 loss: 8.79237086e-06
Iter: 1963 loss: 8.78440187e-06
Iter: 1964 loss: 8.80801235e-06
Iter: 1965 loss: 8.78210449e-06
Iter: 1966 loss: 8.77297134e-06
Iter: 1967 loss: 8.80458e-06
Iter: 1968 loss: 8.77082948e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.6/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2
+ date
Sun Nov  8 09:50:22 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi1.6/300_100_100_100_1 --function f2 --psi 0 --alpha 2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeaf273048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeaf236d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeaf236268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeaf236ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeaf2362f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabf04b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabe71ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabe71048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabe96488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabed4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabe35510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabe356a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabe35378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabdc46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabde4510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabde4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabde46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabd01510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabd01ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabd01048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabc6bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabd85950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabcaa400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabcbd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabcbd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabcbd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabdc41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabc2af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabb83ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabb457b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabb45730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabb45378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabc22598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabc22730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabc22ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faeabae6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.011251545
test_loss: 0.013661898
train_loss: 0.010039722
test_loss: 0.012671517
train_loss: 0.009615131
test_loss: 0.011943462
train_loss: 0.009370013
test_loss: 0.012509012
train_loss: 0.009604917
test_loss: 0.011729694
train_loss: 0.009720666
test_loss: 0.012274137
train_loss: 0.009538417
test_loss: 0.011626579
train_loss: 0.008877076
test_loss: 0.011821684
train_loss: 0.009500515
test_loss: 0.011802196
train_loss: 0.008486817
test_loss: 0.011250986
train_loss: 0.009035098
test_loss: 0.011227749
train_loss: 0.00882323
test_loss: 0.011329413
train_loss: 0.008870665
test_loss: 0.011577557
train_loss: 0.008718971
test_loss: 0.011064299
train_loss: 0.008152076
test_loss: 0.011195437
train_loss: 0.008389033
test_loss: 0.011144178
train_loss: 0.008610711
test_loss: 0.010857319
train_loss: 0.008034623
test_loss: 0.010916094
train_loss: 0.008037667
test_loss: 0.010821957
train_loss: 0.008420397
test_loss: 0.010850273
train_loss: 0.0085175
test_loss: 0.011196098
train_loss: 0.008394318
test_loss: 0.011193437
train_loss: 0.008469863
test_loss: 0.010918501
train_loss: 0.008299878
test_loss: 0.011053589
train_loss: 0.007865568
test_loss: 0.0107298745
train_loss: 0.008879814
test_loss: 0.011160793
train_loss: 0.0078495145
test_loss: 0.010957607
train_loss: 0.007995622
test_loss: 0.010934951
train_loss: 0.007968507
test_loss: 0.010905459
train_loss: 0.007852784
test_loss: 0.010831249
train_loss: 0.007594456
test_loss: 0.01041134
train_loss: 0.008159064
test_loss: 0.010814635
train_loss: 0.007815705
test_loss: 0.01085657
train_loss: 0.0076588443
test_loss: 0.010556021
train_loss: 0.007891395
test_loss: 0.010581639
train_loss: 0.007839215
test_loss: 0.010613296
train_loss: 0.0081413705
test_loss: 0.010801331
train_loss: 0.008006664
test_loss: 0.010611119
train_loss: 0.007799725
test_loss: 0.010531245
train_loss: 0.0077442904
test_loss: 0.01046463
train_loss: 0.007871882
test_loss: 0.01045295
train_loss: 0.007880496
test_loss: 0.010585177
train_loss: 0.007633798
test_loss: 0.010575726
train_loss: 0.007500763
test_loss: 0.010307422
train_loss: 0.00783027
test_loss: 0.010546439
train_loss: 0.007811794
test_loss: 0.010278119
train_loss: 0.00753871
test_loss: 0.010535288
train_loss: 0.0076974565
test_loss: 0.010584415
train_loss: 0.0076724133
test_loss: 0.010444491
train_loss: 0.007212045
test_loss: 0.010304988
train_loss: 0.007755954
test_loss: 0.010342499
train_loss: 0.007667228
test_loss: 0.010742002
train_loss: 0.0072131427
test_loss: 0.01010957
train_loss: 0.0073287766
test_loss: 0.010081222
train_loss: 0.008124069
test_loss: 0.010646848
train_loss: 0.0068523698
test_loss: 0.0100440495
train_loss: 0.007625352
test_loss: 0.010375069
train_loss: 0.007389726
test_loss: 0.010208128
train_loss: 0.0075034928
test_loss: 0.010300615
train_loss: 0.007534285
test_loss: 0.010178605
train_loss: 0.007366435
test_loss: 0.010079095
train_loss: 0.007508302
test_loss: 0.010155462
train_loss: 0.0075369454
test_loss: 0.010120652
train_loss: 0.0072823022
test_loss: 0.010332961
train_loss: 0.00753696
test_loss: 0.010275867
train_loss: 0.0071731945
test_loss: 0.010267411
train_loss: 0.007205997
test_loss: 0.010122487
train_loss: 0.0071343537
test_loss: 0.009988399
train_loss: 0.0075983964
test_loss: 0.0102944225
train_loss: 0.006817063
test_loss: 0.010204029
train_loss: 0.007611273
test_loss: 0.010130022
train_loss: 0.0074288957
test_loss: 0.010157285
train_loss: 0.007109183
test_loss: 0.010131764
train_loss: 0.0068525686
test_loss: 0.009979582
train_loss: 0.0070026554
test_loss: 0.009722336
train_loss: 0.0073518245
test_loss: 0.010175329
train_loss: 0.007597886
test_loss: 0.009924488
train_loss: 0.0074888305
test_loss: 0.009888771
train_loss: 0.00714028
test_loss: 0.009957647
train_loss: 0.00711877
test_loss: 0.009942595
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 2 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991e43598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991e35950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991e10730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991e106a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991e107b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991dbf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991d94510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991e10488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7991d3b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979a05620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979a022f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979a05bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979a24b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79799e3e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979a24bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979a24ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979a02378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79798fb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979900a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79799007b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979881840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979881488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79798368c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979864048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979850400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79798506a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79797fc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979864598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79797d1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7979864488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f797974f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f797974f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79797066a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79796b47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79796b4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f79796b4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 9.42323313e-05
Iter: 2 loss: 7.85179e-05
Iter: 3 loss: 0.000142356439
Iter: 4 loss: 7.5629694e-05
Iter: 5 loss: 6.64919935e-05
Iter: 6 loss: 0.00010925137
Iter: 7 loss: 6.47808e-05
Iter: 8 loss: 5.82890898e-05
Iter: 9 loss: 7.75614171e-05
Iter: 10 loss: 5.62852838e-05
Iter: 11 loss: 5.17847402e-05
Iter: 12 loss: 9.08319344e-05
Iter: 13 loss: 5.15541833e-05
Iter: 14 loss: 4.89001613e-05
Iter: 15 loss: 4.90484235e-05
Iter: 16 loss: 4.68224389e-05
Iter: 17 loss: 4.41065786e-05
Iter: 18 loss: 6.18602862e-05
Iter: 19 loss: 4.38062452e-05
Iter: 20 loss: 4.18280906e-05
Iter: 21 loss: 4.4617489e-05
Iter: 22 loss: 4.08513297e-05
Iter: 23 loss: 3.93691444e-05
Iter: 24 loss: 5.3011303e-05
Iter: 25 loss: 3.9306542e-05
Iter: 26 loss: 3.79543126e-05
Iter: 27 loss: 3.92445e-05
Iter: 28 loss: 3.71822462e-05
Iter: 29 loss: 3.60484482e-05
Iter: 30 loss: 3.84048762e-05
Iter: 31 loss: 3.55950287e-05
Iter: 32 loss: 3.4459641e-05
Iter: 33 loss: 4.08476e-05
Iter: 34 loss: 3.4300454e-05
Iter: 35 loss: 3.33433418e-05
Iter: 36 loss: 3.37856982e-05
Iter: 37 loss: 3.26972659e-05
Iter: 38 loss: 3.1804866e-05
Iter: 39 loss: 3.42181556e-05
Iter: 40 loss: 3.15100697e-05
Iter: 41 loss: 3.09409515e-05
Iter: 42 loss: 3.09407369e-05
Iter: 43 loss: 3.05128742e-05
Iter: 44 loss: 3.25642213e-05
Iter: 45 loss: 3.0436986e-05
Iter: 46 loss: 3.01208838e-05
Iter: 47 loss: 3.09208517e-05
Iter: 48 loss: 3.0010975e-05
Iter: 49 loss: 2.96655417e-05
Iter: 50 loss: 2.98971445e-05
Iter: 51 loss: 2.94483289e-05
Iter: 52 loss: 2.90976459e-05
Iter: 53 loss: 2.98185696e-05
Iter: 54 loss: 2.89571217e-05
Iter: 55 loss: 2.8605793e-05
Iter: 56 loss: 3.04281093e-05
Iter: 57 loss: 2.85495662e-05
Iter: 58 loss: 2.82489109e-05
Iter: 59 loss: 2.87583098e-05
Iter: 60 loss: 2.81140201e-05
Iter: 61 loss: 2.78128355e-05
Iter: 62 loss: 2.96164217e-05
Iter: 63 loss: 2.77751224e-05
Iter: 64 loss: 2.75479288e-05
Iter: 65 loss: 2.79633859e-05
Iter: 66 loss: 2.74496633e-05
Iter: 67 loss: 2.72120851e-05
Iter: 68 loss: 2.71384e-05
Iter: 69 loss: 2.69983848e-05
Iter: 70 loss: 2.67215437e-05
Iter: 71 loss: 3.00111969e-05
Iter: 72 loss: 2.6718144e-05
Iter: 73 loss: 2.65341878e-05
Iter: 74 loss: 2.70105629e-05
Iter: 75 loss: 2.64716491e-05
Iter: 76 loss: 2.62939284e-05
Iter: 77 loss: 2.64136215e-05
Iter: 78 loss: 2.61822388e-05
Iter: 79 loss: 2.60222369e-05
Iter: 80 loss: 2.6020829e-05
Iter: 81 loss: 2.58852633e-05
Iter: 82 loss: 2.59091757e-05
Iter: 83 loss: 2.57831234e-05
Iter: 84 loss: 2.56534986e-05
Iter: 85 loss: 2.57681022e-05
Iter: 86 loss: 2.55774376e-05
Iter: 87 loss: 2.54055576e-05
Iter: 88 loss: 2.63161655e-05
Iter: 89 loss: 2.53790113e-05
Iter: 90 loss: 2.5225072e-05
Iter: 91 loss: 2.5377838e-05
Iter: 92 loss: 2.51384408e-05
Iter: 93 loss: 2.49942768e-05
Iter: 94 loss: 2.52919199e-05
Iter: 95 loss: 2.49366476e-05
Iter: 96 loss: 2.48015313e-05
Iter: 97 loss: 2.60663055e-05
Iter: 98 loss: 2.47957796e-05
Iter: 99 loss: 2.4692712e-05
Iter: 100 loss: 2.48045726e-05
Iter: 101 loss: 2.46364871e-05
Iter: 102 loss: 2.45280535e-05
Iter: 103 loss: 2.47951048e-05
Iter: 104 loss: 2.44895618e-05
Iter: 105 loss: 2.43639588e-05
Iter: 106 loss: 2.4568315e-05
Iter: 107 loss: 2.43066424e-05
Iter: 108 loss: 2.41903872e-05
Iter: 109 loss: 2.4464367e-05
Iter: 110 loss: 2.41477883e-05
Iter: 111 loss: 2.40122863e-05
Iter: 112 loss: 2.4264853e-05
Iter: 113 loss: 2.39543042e-05
Iter: 114 loss: 2.38363682e-05
Iter: 115 loss: 2.52798891e-05
Iter: 116 loss: 2.38352877e-05
Iter: 117 loss: 2.37660824e-05
Iter: 118 loss: 2.40716545e-05
Iter: 119 loss: 2.37524018e-05
Iter: 120 loss: 2.36714332e-05
Iter: 121 loss: 2.36798423e-05
Iter: 122 loss: 2.36087835e-05
Iter: 123 loss: 2.35222906e-05
Iter: 124 loss: 2.3529079e-05
Iter: 125 loss: 2.34549407e-05
Iter: 126 loss: 2.33524279e-05
Iter: 127 loss: 2.37629356e-05
Iter: 128 loss: 2.33296814e-05
Iter: 129 loss: 2.32374859e-05
Iter: 130 loss: 2.38223402e-05
Iter: 131 loss: 2.32273396e-05
Iter: 132 loss: 2.31388767e-05
Iter: 133 loss: 2.33043575e-05
Iter: 134 loss: 2.31010963e-05
Iter: 135 loss: 2.30259502e-05
Iter: 136 loss: 2.31507274e-05
Iter: 137 loss: 2.29920643e-05
Iter: 138 loss: 2.29061734e-05
Iter: 139 loss: 2.3199671e-05
Iter: 140 loss: 2.28834633e-05
Iter: 141 loss: 2.2795437e-05
Iter: 142 loss: 2.3040453e-05
Iter: 143 loss: 2.27674518e-05
Iter: 144 loss: 2.26874072e-05
Iter: 145 loss: 2.30772748e-05
Iter: 146 loss: 2.26735392e-05
Iter: 147 loss: 2.26045013e-05
Iter: 148 loss: 2.26954871e-05
Iter: 149 loss: 2.25695476e-05
Iter: 150 loss: 2.24943633e-05
Iter: 151 loss: 2.25690492e-05
Iter: 152 loss: 2.2451899e-05
Iter: 153 loss: 2.23966472e-05
Iter: 154 loss: 2.23965326e-05
Iter: 155 loss: 2.2343831e-05
Iter: 156 loss: 2.23425159e-05
Iter: 157 loss: 2.23009156e-05
Iter: 158 loss: 2.22273593e-05
Iter: 159 loss: 2.24212654e-05
Iter: 160 loss: 2.2202461e-05
Iter: 161 loss: 2.21360679e-05
Iter: 162 loss: 2.21934642e-05
Iter: 163 loss: 2.20966904e-05
Iter: 164 loss: 2.20231304e-05
Iter: 165 loss: 2.20929433e-05
Iter: 166 loss: 2.19810754e-05
Iter: 167 loss: 2.18863206e-05
Iter: 168 loss: 2.21098417e-05
Iter: 169 loss: 2.18516288e-05
Iter: 170 loss: 2.17733632e-05
Iter: 171 loss: 2.23608313e-05
Iter: 172 loss: 2.1767235e-05
Iter: 173 loss: 2.17042125e-05
Iter: 174 loss: 2.19532285e-05
Iter: 175 loss: 2.16900153e-05
Iter: 176 loss: 2.16257249e-05
Iter: 177 loss: 2.17275592e-05
Iter: 178 loss: 2.15960208e-05
Iter: 179 loss: 2.1530188e-05
Iter: 180 loss: 2.19171816e-05
Iter: 181 loss: 2.1521817e-05
Iter: 182 loss: 2.14715583e-05
Iter: 183 loss: 2.15162e-05
Iter: 184 loss: 2.14417414e-05
Iter: 185 loss: 2.13845051e-05
Iter: 186 loss: 2.15811724e-05
Iter: 187 loss: 2.13689982e-05
Iter: 188 loss: 2.13134153e-05
Iter: 189 loss: 2.17001361e-05
Iter: 190 loss: 2.13077656e-05
Iter: 191 loss: 2.12658233e-05
Iter: 192 loss: 2.13320254e-05
Iter: 193 loss: 2.12459818e-05
Iter: 194 loss: 2.11930546e-05
Iter: 195 loss: 2.13124295e-05
Iter: 196 loss: 2.11728038e-05
Iter: 197 loss: 2.11265105e-05
Iter: 198 loss: 2.11676906e-05
Iter: 199 loss: 2.11000552e-05
Iter: 200 loss: 2.10476392e-05
Iter: 201 loss: 2.12584891e-05
Iter: 202 loss: 2.10361268e-05
Iter: 203 loss: 2.09789505e-05
Iter: 204 loss: 2.09551399e-05
Iter: 205 loss: 2.09252958e-05
Iter: 206 loss: 2.08550373e-05
Iter: 207 loss: 2.11707265e-05
Iter: 208 loss: 2.08409692e-05
Iter: 209 loss: 2.078334e-05
Iter: 210 loss: 2.08911042e-05
Iter: 211 loss: 2.07587309e-05
Iter: 212 loss: 2.06997283e-05
Iter: 213 loss: 2.10774342e-05
Iter: 214 loss: 2.0692838e-05
Iter: 215 loss: 2.06434524e-05
Iter: 216 loss: 2.07659687e-05
Iter: 217 loss: 2.06263958e-05
Iter: 218 loss: 2.05728593e-05
Iter: 219 loss: 2.06731966e-05
Iter: 220 loss: 2.0550342e-05
Iter: 221 loss: 2.05053802e-05
Iter: 222 loss: 2.09426798e-05
Iter: 223 loss: 2.05039614e-05
Iter: 224 loss: 2.04651187e-05
Iter: 225 loss: 2.05512661e-05
Iter: 226 loss: 2.04501048e-05
Iter: 227 loss: 2.04088137e-05
Iter: 228 loss: 2.0505011e-05
Iter: 229 loss: 2.03932941e-05
Iter: 230 loss: 2.03441814e-05
Iter: 231 loss: 2.03802701e-05
Iter: 232 loss: 2.03141972e-05
Iter: 233 loss: 2.02677456e-05
Iter: 234 loss: 2.03901618e-05
Iter: 235 loss: 2.02523588e-05
Iter: 236 loss: 2.02076899e-05
Iter: 237 loss: 2.0426729e-05
Iter: 238 loss: 2.02000301e-05
Iter: 239 loss: 2.01608455e-05
Iter: 240 loss: 2.01628536e-05
Iter: 241 loss: 2.01305083e-05
Iter: 242 loss: 2.00884242e-05
Iter: 243 loss: 2.06305449e-05
Iter: 244 loss: 2.00882714e-05
Iter: 245 loss: 2.00575851e-05
Iter: 246 loss: 2.00824325e-05
Iter: 247 loss: 2.00391351e-05
Iter: 248 loss: 2.00024406e-05
Iter: 249 loss: 1.99868464e-05
Iter: 250 loss: 1.99677561e-05
Iter: 251 loss: 1.99153183e-05
Iter: 252 loss: 2.01479597e-05
Iter: 253 loss: 1.99048081e-05
Iter: 254 loss: 1.98572689e-05
Iter: 255 loss: 2.00561808e-05
Iter: 256 loss: 1.98473972e-05
Iter: 257 loss: 1.98004018e-05
Iter: 258 loss: 1.99058268e-05
Iter: 259 loss: 1.97827212e-05
Iter: 260 loss: 1.97442023e-05
Iter: 261 loss: 2.00820523e-05
Iter: 262 loss: 1.97421941e-05
Iter: 263 loss: 1.97080117e-05
Iter: 264 loss: 1.98284124e-05
Iter: 265 loss: 1.96992733e-05
Iter: 266 loss: 1.96714936e-05
Iter: 267 loss: 1.96437431e-05
Iter: 268 loss: 1.96380679e-05
Iter: 269 loss: 1.9595127e-05
Iter: 270 loss: 1.9843792e-05
Iter: 271 loss: 1.95892353e-05
Iter: 272 loss: 1.95506473e-05
Iter: 273 loss: 1.96457659e-05
Iter: 274 loss: 1.95368448e-05
Iter: 275 loss: 1.95010853e-05
Iter: 276 loss: 1.95781067e-05
Iter: 277 loss: 1.94876175e-05
Iter: 278 loss: 1.94465574e-05
Iter: 279 loss: 1.96084566e-05
Iter: 280 loss: 1.94376589e-05
Iter: 281 loss: 1.94019703e-05
Iter: 282 loss: 1.94249642e-05
Iter: 283 loss: 1.93788601e-05
Iter: 284 loss: 1.93378437e-05
Iter: 285 loss: 1.93907581e-05
Iter: 286 loss: 1.93171436e-05
Iter: 287 loss: 1.92767257e-05
Iter: 288 loss: 1.98723246e-05
Iter: 289 loss: 1.92765456e-05
Iter: 290 loss: 1.92470416e-05
Iter: 291 loss: 1.92354364e-05
Iter: 292 loss: 1.92194566e-05
Iter: 293 loss: 1.918009e-05
Iter: 294 loss: 1.93274427e-05
Iter: 295 loss: 1.91706858e-05
Iter: 296 loss: 1.91359504e-05
Iter: 297 loss: 1.92340522e-05
Iter: 298 loss: 1.91246872e-05
Iter: 299 loss: 1.90872088e-05
Iter: 300 loss: 1.92526713e-05
Iter: 301 loss: 1.90795727e-05
Iter: 302 loss: 1.90451774e-05
Iter: 303 loss: 1.92504067e-05
Iter: 304 loss: 1.90407263e-05
Iter: 305 loss: 1.90178544e-05
Iter: 306 loss: 1.89981292e-05
Iter: 307 loss: 1.89917773e-05
Iter: 308 loss: 1.89561433e-05
Iter: 309 loss: 1.90182654e-05
Iter: 310 loss: 1.8940611e-05
Iter: 311 loss: 1.88998802e-05
Iter: 312 loss: 1.91400504e-05
Iter: 313 loss: 1.88946e-05
Iter: 314 loss: 1.88621962e-05
Iter: 315 loss: 1.89068342e-05
Iter: 316 loss: 1.8845778e-05
Iter: 317 loss: 1.88098547e-05
Iter: 318 loss: 1.89277125e-05
Iter: 319 loss: 1.88004742e-05
Iter: 320 loss: 1.87640599e-05
Iter: 321 loss: 1.89400962e-05
Iter: 322 loss: 1.87574478e-05
Iter: 323 loss: 1.8728344e-05
Iter: 324 loss: 1.87136939e-05
Iter: 325 loss: 1.8700086e-05
Iter: 326 loss: 1.86572197e-05
Iter: 327 loss: 1.87562473e-05
Iter: 328 loss: 1.8641691e-05
Iter: 329 loss: 1.86004072e-05
Iter: 330 loss: 1.89726907e-05
Iter: 331 loss: 1.85992321e-05
Iter: 332 loss: 1.85691297e-05
Iter: 333 loss: 1.8691444e-05
Iter: 334 loss: 1.85626013e-05
Iter: 335 loss: 1.85361405e-05
Iter: 336 loss: 1.8574985e-05
Iter: 337 loss: 1.85232348e-05
Iter: 338 loss: 1.84934615e-05
Iter: 339 loss: 1.86703473e-05
Iter: 340 loss: 1.84898563e-05
Iter: 341 loss: 1.84672972e-05
Iter: 342 loss: 1.85515055e-05
Iter: 343 loss: 1.84616474e-05
Iter: 344 loss: 1.84400651e-05
Iter: 345 loss: 1.84193304e-05
Iter: 346 loss: 1.84143773e-05
Iter: 347 loss: 1.83768843e-05
Iter: 348 loss: 1.84213131e-05
Iter: 349 loss: 1.83569355e-05
Iter: 350 loss: 1.83172087e-05
Iter: 351 loss: 1.85704794e-05
Iter: 352 loss: 1.83124339e-05
Iter: 353 loss: 1.82792355e-05
Iter: 354 loss: 1.83780885e-05
Iter: 355 loss: 1.8269182e-05
Iter: 356 loss: 1.82351614e-05
Iter: 357 loss: 1.82531276e-05
Iter: 358 loss: 1.82126532e-05
Iter: 359 loss: 1.81735195e-05
Iter: 360 loss: 1.83928987e-05
Iter: 361 loss: 1.81682517e-05
Iter: 362 loss: 1.81331652e-05
Iter: 363 loss: 1.83162701e-05
Iter: 364 loss: 1.81279593e-05
Iter: 365 loss: 1.8102277e-05
Iter: 366 loss: 1.80805782e-05
Iter: 367 loss: 1.80733314e-05
Iter: 368 loss: 1.80333518e-05
Iter: 369 loss: 1.82118092e-05
Iter: 370 loss: 1.80253865e-05
Iter: 371 loss: 1.79907929e-05
Iter: 372 loss: 1.82078966e-05
Iter: 373 loss: 1.79866274e-05
Iter: 374 loss: 1.79590534e-05
Iter: 375 loss: 1.81218711e-05
Iter: 376 loss: 1.795547e-05
Iter: 377 loss: 1.79302733e-05
Iter: 378 loss: 1.79639101e-05
Iter: 379 loss: 1.79173367e-05
Iter: 380 loss: 1.78887822e-05
Iter: 381 loss: 1.79091949e-05
Iter: 382 loss: 1.78712762e-05
Iter: 383 loss: 1.78390528e-05
Iter: 384 loss: 1.80370298e-05
Iter: 385 loss: 1.78350947e-05
Iter: 386 loss: 1.78075716e-05
Iter: 387 loss: 1.78123628e-05
Iter: 388 loss: 1.77870388e-05
Iter: 389 loss: 1.77531183e-05
Iter: 390 loss: 1.78103983e-05
Iter: 391 loss: 1.77377169e-05
Iter: 392 loss: 1.77049624e-05
Iter: 393 loss: 1.79335693e-05
Iter: 394 loss: 1.77018101e-05
Iter: 395 loss: 1.76719404e-05
Iter: 396 loss: 1.76856338e-05
Iter: 397 loss: 1.76521426e-05
Iter: 398 loss: 1.76158555e-05
Iter: 399 loss: 1.76977137e-05
Iter: 400 loss: 1.76021986e-05
Iter: 401 loss: 1.75686855e-05
Iter: 402 loss: 1.7750921e-05
Iter: 403 loss: 1.75637724e-05
Iter: 404 loss: 1.7533237e-05
Iter: 405 loss: 1.76898575e-05
Iter: 406 loss: 1.75283094e-05
Iter: 407 loss: 1.75033601e-05
Iter: 408 loss: 1.74846209e-05
Iter: 409 loss: 1.7476119e-05
Iter: 410 loss: 1.74435663e-05
Iter: 411 loss: 1.77603888e-05
Iter: 412 loss: 1.74424858e-05
Iter: 413 loss: 1.74186753e-05
Iter: 414 loss: 1.76079429e-05
Iter: 415 loss: 1.74171691e-05
Iter: 416 loss: 1.73983663e-05
Iter: 417 loss: 1.74008419e-05
Iter: 418 loss: 1.73837761e-05
Iter: 419 loss: 1.73562439e-05
Iter: 420 loss: 1.73684621e-05
Iter: 421 loss: 1.73377739e-05
Iter: 422 loss: 1.73072931e-05
Iter: 423 loss: 1.73830467e-05
Iter: 424 loss: 1.72968503e-05
Iter: 425 loss: 1.7266133e-05
Iter: 426 loss: 1.7381919e-05
Iter: 427 loss: 1.7258837e-05
Iter: 428 loss: 1.72294349e-05
Iter: 429 loss: 1.74015495e-05
Iter: 430 loss: 1.72253349e-05
Iter: 431 loss: 1.72027085e-05
Iter: 432 loss: 1.72132532e-05
Iter: 433 loss: 1.71873944e-05
Iter: 434 loss: 1.71543579e-05
Iter: 435 loss: 1.72542095e-05
Iter: 436 loss: 1.71443589e-05
Iter: 437 loss: 1.71144547e-05
Iter: 438 loss: 1.7180686e-05
Iter: 439 loss: 1.71032661e-05
Iter: 440 loss: 1.70749772e-05
Iter: 441 loss: 1.70741914e-05
Iter: 442 loss: 1.7052e-05
Iter: 443 loss: 1.7020142e-05
Iter: 444 loss: 1.73929257e-05
Iter: 445 loss: 1.70195781e-05
Iter: 446 loss: 1.69948198e-05
Iter: 447 loss: 1.71052106e-05
Iter: 448 loss: 1.6990085e-05
Iter: 449 loss: 1.69702762e-05
Iter: 450 loss: 1.69888681e-05
Iter: 451 loss: 1.69591221e-05
Iter: 452 loss: 1.69326795e-05
Iter: 453 loss: 1.70918684e-05
Iter: 454 loss: 1.69290652e-05
Iter: 455 loss: 1.69048362e-05
Iter: 456 loss: 1.69050036e-05
Iter: 457 loss: 1.6885293e-05
Iter: 458 loss: 1.68548086e-05
Iter: 459 loss: 1.69383202e-05
Iter: 460 loss: 1.68447659e-05
Iter: 461 loss: 1.68146908e-05
Iter: 462 loss: 1.68336e-05
Iter: 463 loss: 1.67954058e-05
Iter: 464 loss: 1.67623984e-05
Iter: 465 loss: 1.68876104e-05
Iter: 466 loss: 1.6754675e-05
Iter: 467 loss: 1.67260114e-05
Iter: 468 loss: 1.68524602e-05
Iter: 469 loss: 1.67203052e-05
Iter: 470 loss: 1.66917762e-05
Iter: 471 loss: 1.67734033e-05
Iter: 472 loss: 1.6683176e-05
Iter: 473 loss: 1.66575e-05
Iter: 474 loss: 1.67295602e-05
Iter: 475 loss: 1.66491864e-05
Iter: 476 loss: 1.66248574e-05
Iter: 477 loss: 1.67647668e-05
Iter: 478 loss: 1.66212121e-05
Iter: 479 loss: 1.65999918e-05
Iter: 480 loss: 1.657959e-05
Iter: 481 loss: 1.65746296e-05
Iter: 482 loss: 1.65449746e-05
Iter: 483 loss: 1.6687105e-05
Iter: 484 loss: 1.65397687e-05
Iter: 485 loss: 1.65140482e-05
Iter: 486 loss: 1.6634267e-05
Iter: 487 loss: 1.65095353e-05
Iter: 488 loss: 1.64822868e-05
Iter: 489 loss: 1.65997481e-05
Iter: 490 loss: 1.64766334e-05
Iter: 491 loss: 1.64533431e-05
Iter: 492 loss: 1.6514e-05
Iter: 493 loss: 1.6445345e-05
Iter: 494 loss: 1.64206213e-05
Iter: 495 loss: 1.64558205e-05
Iter: 496 loss: 1.64086414e-05
Iter: 497 loss: 1.63856894e-05
Iter: 498 loss: 1.64345383e-05
Iter: 499 loss: 1.6377151e-05
Iter: 500 loss: 1.63479635e-05
Iter: 501 loss: 1.63667901e-05
Iter: 502 loss: 1.63295e-05
Iter: 503 loss: 1.63019431e-05
Iter: 504 loss: 1.64089251e-05
Iter: 505 loss: 1.6295633e-05
Iter: 506 loss: 1.62700417e-05
Iter: 507 loss: 1.6314365e-05
Iter: 508 loss: 1.62587094e-05
Iter: 509 loss: 1.62291108e-05
Iter: 510 loss: 1.63644763e-05
Iter: 511 loss: 1.62233682e-05
Iter: 512 loss: 1.61971802e-05
Iter: 513 loss: 1.62683718e-05
Iter: 514 loss: 1.61887911e-05
Iter: 515 loss: 1.61652133e-05
Iter: 516 loss: 1.61883854e-05
Iter: 517 loss: 1.61523694e-05
Iter: 518 loss: 1.61207645e-05
Iter: 519 loss: 1.63565965e-05
Iter: 520 loss: 1.61185471e-05
Iter: 521 loss: 1.60977124e-05
Iter: 522 loss: 1.61042408e-05
Iter: 523 loss: 1.60830841e-05
Iter: 524 loss: 1.60581258e-05
Iter: 525 loss: 1.61020598e-05
Iter: 526 loss: 1.60470154e-05
Iter: 527 loss: 1.60200416e-05
Iter: 528 loss: 1.63383702e-05
Iter: 529 loss: 1.60196068e-05
Iter: 530 loss: 1.60001309e-05
Iter: 531 loss: 1.60113814e-05
Iter: 532 loss: 1.59873434e-05
Iter: 533 loss: 1.59645715e-05
Iter: 534 loss: 1.60207346e-05
Iter: 535 loss: 1.59561987e-05
Iter: 536 loss: 1.59335323e-05
Iter: 537 loss: 1.59725332e-05
Iter: 538 loss: 1.59235678e-05
Iter: 539 loss: 1.5900896e-05
Iter: 540 loss: 1.60194941e-05
Iter: 541 loss: 1.58973053e-05
Iter: 542 loss: 1.58783532e-05
Iter: 543 loss: 1.58777966e-05
Iter: 544 loss: 1.58626408e-05
Iter: 545 loss: 1.58364492e-05
Iter: 546 loss: 1.58943949e-05
Iter: 547 loss: 1.5826321e-05
Iter: 548 loss: 1.57994309e-05
Iter: 549 loss: 1.59052161e-05
Iter: 550 loss: 1.57930263e-05
Iter: 551 loss: 1.57643244e-05
Iter: 552 loss: 1.58439343e-05
Iter: 553 loss: 1.57550548e-05
Iter: 554 loss: 1.5728303e-05
Iter: 555 loss: 1.57628965e-05
Iter: 556 loss: 1.5714344e-05
Iter: 557 loss: 1.5688609e-05
Iter: 558 loss: 1.5794807e-05
Iter: 559 loss: 1.56830974e-05
Iter: 560 loss: 1.56604983e-05
Iter: 561 loss: 1.5848258e-05
Iter: 562 loss: 1.56590813e-05
Iter: 563 loss: 1.56386486e-05
Iter: 564 loss: 1.5638323e-05
Iter: 565 loss: 1.56225833e-05
Iter: 566 loss: 1.56013812e-05
Iter: 567 loss: 1.58708335e-05
Iter: 568 loss: 1.56009955e-05
Iter: 569 loss: 1.55841335e-05
Iter: 570 loss: 1.5588339e-05
Iter: 571 loss: 1.55716225e-05
Iter: 572 loss: 1.55521138e-05
Iter: 573 loss: 1.55837843e-05
Iter: 574 loss: 1.55433299e-05
Iter: 575 loss: 1.55211892e-05
Iter: 576 loss: 1.55825619e-05
Iter: 577 loss: 1.55139205e-05
Iter: 578 loss: 1.54931531e-05
Iter: 579 loss: 1.55315e-05
Iter: 580 loss: 1.54836598e-05
Iter: 581 loss: 1.54592071e-05
Iter: 582 loss: 1.55869675e-05
Iter: 583 loss: 1.54554127e-05
Iter: 584 loss: 1.5437563e-05
Iter: 585 loss: 1.54355876e-05
Iter: 586 loss: 1.54227509e-05
Iter: 587 loss: 1.53956917e-05
Iter: 588 loss: 1.54509398e-05
Iter: 589 loss: 1.53849742e-05
Iter: 590 loss: 1.53558394e-05
Iter: 591 loss: 1.55103717e-05
Iter: 592 loss: 1.53514684e-05
Iter: 593 loss: 1.53268156e-05
Iter: 594 loss: 1.53862566e-05
Iter: 595 loss: 1.53180699e-05
Iter: 596 loss: 1.5295238e-05
Iter: 597 loss: 1.530605e-05
Iter: 598 loss: 1.52794746e-05
Iter: 599 loss: 1.52512876e-05
Iter: 600 loss: 1.53919027e-05
Iter: 601 loss: 1.52465327e-05
Iter: 602 loss: 1.52252815e-05
Iter: 603 loss: 1.55500493e-05
Iter: 604 loss: 1.52250705e-05
Iter: 605 loss: 1.52119428e-05
Iter: 606 loss: 1.5213569e-05
Iter: 607 loss: 1.52021412e-05
Iter: 608 loss: 1.51826316e-05
Iter: 609 loss: 1.52260955e-05
Iter: 610 loss: 1.51754466e-05
Iter: 611 loss: 1.51551421e-05
Iter: 612 loss: 1.5192627e-05
Iter: 613 loss: 1.51466138e-05
Iter: 614 loss: 1.51275517e-05
Iter: 615 loss: 1.51958666e-05
Iter: 616 loss: 1.51228351e-05
Iter: 617 loss: 1.51027243e-05
Iter: 618 loss: 1.50961669e-05
Iter: 619 loss: 1.50845144e-05
Iter: 620 loss: 1.50612759e-05
Iter: 621 loss: 1.53127476e-05
Iter: 622 loss: 1.50606356e-05
Iter: 623 loss: 1.50424012e-05
Iter: 624 loss: 1.50760261e-05
Iter: 625 loss: 1.50345631e-05
Iter: 626 loss: 1.5014467e-05
Iter: 627 loss: 1.50177548e-05
Iter: 628 loss: 1.4999051e-05
Iter: 629 loss: 1.49769985e-05
Iter: 630 loss: 1.51131826e-05
Iter: 631 loss: 1.49741772e-05
Iter: 632 loss: 1.49536718e-05
Iter: 633 loss: 1.50021497e-05
Iter: 634 loss: 1.49464531e-05
Iter: 635 loss: 1.49252855e-05
Iter: 636 loss: 1.49499483e-05
Iter: 637 loss: 1.49138395e-05
Iter: 638 loss: 1.4891938e-05
Iter: 639 loss: 1.49583766e-05
Iter: 640 loss: 1.48855e-05
Iter: 641 loss: 1.48677955e-05
Iter: 642 loss: 1.48677736e-05
Iter: 643 loss: 1.48551135e-05
Iter: 644 loss: 1.48402096e-05
Iter: 645 loss: 1.48385152e-05
Iter: 646 loss: 1.48173358e-05
Iter: 647 loss: 1.48402196e-05
Iter: 648 loss: 1.48056488e-05
Iter: 649 loss: 1.47782657e-05
Iter: 650 loss: 1.49076177e-05
Iter: 651 loss: 1.47732244e-05
Iter: 652 loss: 1.47523833e-05
Iter: 653 loss: 1.47936171e-05
Iter: 654 loss: 1.47438532e-05
Iter: 655 loss: 1.47247392e-05
Iter: 656 loss: 1.48894042e-05
Iter: 657 loss: 1.47236706e-05
Iter: 658 loss: 1.47076771e-05
Iter: 659 loss: 1.46966277e-05
Iter: 660 loss: 1.46907569e-05
Iter: 661 loss: 1.46651473e-05
Iter: 662 loss: 1.47485571e-05
Iter: 663 loss: 1.46579405e-05
Iter: 664 loss: 1.46385846e-05
Iter: 665 loss: 1.48099589e-05
Iter: 666 loss: 1.46379953e-05
Iter: 667 loss: 1.46215443e-05
Iter: 668 loss: 1.4629064e-05
Iter: 669 loss: 1.46101402e-05
Iter: 670 loss: 1.45899958e-05
Iter: 671 loss: 1.46736393e-05
Iter: 672 loss: 1.45856884e-05
Iter: 673 loss: 1.45667454e-05
Iter: 674 loss: 1.46082593e-05
Iter: 675 loss: 1.45599615e-05
Iter: 676 loss: 1.45412105e-05
Iter: 677 loss: 1.45669319e-05
Iter: 678 loss: 1.45319327e-05
Iter: 679 loss: 1.4515017e-05
Iter: 680 loss: 1.47884157e-05
Iter: 681 loss: 1.4515057e-05
Iter: 682 loss: 1.45016675e-05
Iter: 683 loss: 1.44837441e-05
Iter: 684 loss: 1.44829137e-05
Iter: 685 loss: 1.44608721e-05
Iter: 686 loss: 1.44803944e-05
Iter: 687 loss: 1.44481e-05
Iter: 688 loss: 1.44226851e-05
Iter: 689 loss: 1.46102639e-05
Iter: 690 loss: 1.44203887e-05
Iter: 691 loss: 1.44004434e-05
Iter: 692 loss: 1.44339865e-05
Iter: 693 loss: 1.4391173e-05
Iter: 694 loss: 1.43711331e-05
Iter: 695 loss: 1.44185133e-05
Iter: 696 loss: 1.43639709e-05
Iter: 697 loss: 1.43421557e-05
Iter: 698 loss: 1.4440714e-05
Iter: 699 loss: 1.43377674e-05
Iter: 700 loss: 1.43170537e-05
Iter: 701 loss: 1.43871302e-05
Iter: 702 loss: 1.43116313e-05
Iter: 703 loss: 1.42951076e-05
Iter: 704 loss: 1.42866329e-05
Iter: 705 loss: 1.42789686e-05
Iter: 706 loss: 1.42496601e-05
Iter: 707 loss: 1.44185933e-05
Iter: 708 loss: 1.42458239e-05
Iter: 709 loss: 1.42256822e-05
Iter: 710 loss: 1.42837362e-05
Iter: 711 loss: 1.4219273e-05
Iter: 712 loss: 1.42016706e-05
Iter: 713 loss: 1.42867866e-05
Iter: 714 loss: 1.41985984e-05
Iter: 715 loss: 1.41788796e-05
Iter: 716 loss: 1.42376875e-05
Iter: 717 loss: 1.41727451e-05
Iter: 718 loss: 1.41576311e-05
Iter: 719 loss: 1.41545743e-05
Iter: 720 loss: 1.41445407e-05
Iter: 721 loss: 1.41275013e-05
Iter: 722 loss: 1.42922299e-05
Iter: 723 loss: 1.41267137e-05
Iter: 724 loss: 1.41114378e-05
Iter: 725 loss: 1.41085166e-05
Iter: 726 loss: 1.40982756e-05
Iter: 727 loss: 1.40782668e-05
Iter: 728 loss: 1.41259479e-05
Iter: 729 loss: 1.40709135e-05
Iter: 730 loss: 1.40501324e-05
Iter: 731 loss: 1.41304863e-05
Iter: 732 loss: 1.40452903e-05
Iter: 733 loss: 1.40255952e-05
Iter: 734 loss: 1.40343527e-05
Iter: 735 loss: 1.40120092e-05
Iter: 736 loss: 1.39879421e-05
Iter: 737 loss: 1.4076717e-05
Iter: 738 loss: 1.39819276e-05
Iter: 739 loss: 1.39619333e-05
Iter: 740 loss: 1.41268883e-05
Iter: 741 loss: 1.39608401e-05
Iter: 742 loss: 1.39437825e-05
Iter: 743 loss: 1.39540361e-05
Iter: 744 loss: 1.39325857e-05
Iter: 745 loss: 1.39137792e-05
Iter: 746 loss: 1.39859503e-05
Iter: 747 loss: 1.39092863e-05
Iter: 748 loss: 1.38908244e-05
Iter: 749 loss: 1.39404838e-05
Iter: 750 loss: 1.38846844e-05
Iter: 751 loss: 1.38655214e-05
Iter: 752 loss: 1.39319145e-05
Iter: 753 loss: 1.38606802e-05
Iter: 754 loss: 1.38425621e-05
Iter: 755 loss: 1.39714275e-05
Iter: 756 loss: 1.38409087e-05
Iter: 757 loss: 1.38294854e-05
Iter: 758 loss: 1.38128989e-05
Iter: 759 loss: 1.38123214e-05
Iter: 760 loss: 1.37887273e-05
Iter: 761 loss: 1.38201922e-05
Iter: 762 loss: 1.37766983e-05
Iter: 763 loss: 1.37573352e-05
Iter: 764 loss: 1.40156326e-05
Iter: 765 loss: 1.3757267e-05
Iter: 766 loss: 1.37422358e-05
Iter: 767 loss: 1.3769517e-05
Iter: 768 loss: 1.37352527e-05
Iter: 769 loss: 1.37184807e-05
Iter: 770 loss: 1.37597199e-05
Iter: 771 loss: 1.37122688e-05
Iter: 772 loss: 1.36931058e-05
Iter: 773 loss: 1.37193783e-05
Iter: 774 loss: 1.36835706e-05
Iter: 775 loss: 1.36646522e-05
Iter: 776 loss: 1.37016377e-05
Iter: 777 loss: 1.36569106e-05
Iter: 778 loss: 1.36374329e-05
Iter: 779 loss: 1.36865456e-05
Iter: 780 loss: 1.36305398e-05
Iter: 781 loss: 1.36117069e-05
Iter: 782 loss: 1.37669776e-05
Iter: 783 loss: 1.36105555e-05
Iter: 784 loss: 1.35959863e-05
Iter: 785 loss: 1.35997052e-05
Iter: 786 loss: 1.35852188e-05
Iter: 787 loss: 1.35681876e-05
Iter: 788 loss: 1.36945919e-05
Iter: 789 loss: 1.35665814e-05
Iter: 790 loss: 1.35516011e-05
Iter: 791 loss: 1.35837408e-05
Iter: 792 loss: 1.35455066e-05
Iter: 793 loss: 1.35295659e-05
Iter: 794 loss: 1.36055687e-05
Iter: 795 loss: 1.35265891e-05
Iter: 796 loss: 1.35120645e-05
Iter: 797 loss: 1.3501e-05
Iter: 798 loss: 1.3496463e-05
Iter: 799 loss: 1.34734664e-05
Iter: 800 loss: 1.3507326e-05
Iter: 801 loss: 1.34627508e-05
Iter: 802 loss: 1.34434558e-05
Iter: 803 loss: 1.35315549e-05
Iter: 804 loss: 1.34397251e-05
Iter: 805 loss: 1.3419839e-05
Iter: 806 loss: 1.34750353e-05
Iter: 807 loss: 1.34137808e-05
Iter: 808 loss: 1.33914846e-05
Iter: 809 loss: 1.34225193e-05
Iter: 810 loss: 1.33803951e-05
Iter: 811 loss: 1.33633794e-05
Iter: 812 loss: 1.3547311e-05
Iter: 813 loss: 1.33629055e-05
Iter: 814 loss: 1.33489821e-05
Iter: 815 loss: 1.33706017e-05
Iter: 816 loss: 1.33422773e-05
Iter: 817 loss: 1.33249405e-05
Iter: 818 loss: 1.33173535e-05
Iter: 819 loss: 1.33084341e-05
Iter: 820 loss: 1.32870537e-05
Iter: 821 loss: 1.34575121e-05
Iter: 822 loss: 1.32859532e-05
Iter: 823 loss: 1.32687583e-05
Iter: 824 loss: 1.33242729e-05
Iter: 825 loss: 1.32638534e-05
Iter: 826 loss: 1.32494806e-05
Iter: 827 loss: 1.33141184e-05
Iter: 828 loss: 1.32464902e-05
Iter: 829 loss: 1.32317628e-05
Iter: 830 loss: 1.32830764e-05
Iter: 831 loss: 1.32277473e-05
Iter: 832 loss: 1.32144833e-05
Iter: 833 loss: 1.32165042e-05
Iter: 834 loss: 1.32043788e-05
Iter: 835 loss: 1.31871911e-05
Iter: 836 loss: 1.32751984e-05
Iter: 837 loss: 1.31845609e-05
Iter: 838 loss: 1.31698289e-05
Iter: 839 loss: 1.31664838e-05
Iter: 840 loss: 1.31573379e-05
Iter: 841 loss: 1.31366778e-05
Iter: 842 loss: 1.31622137e-05
Iter: 843 loss: 1.31258312e-05
Iter: 844 loss: 1.31042225e-05
Iter: 845 loss: 1.32480382e-05
Iter: 846 loss: 1.3101986e-05
Iter: 847 loss: 1.30844455e-05
Iter: 848 loss: 1.31439911e-05
Iter: 849 loss: 1.30797571e-05
Iter: 850 loss: 1.30625685e-05
Iter: 851 loss: 1.30699691e-05
Iter: 852 loss: 1.30504359e-05
Iter: 853 loss: 1.30296121e-05
Iter: 854 loss: 1.30985391e-05
Iter: 855 loss: 1.30236967e-05
Iter: 856 loss: 1.3004963e-05
Iter: 857 loss: 1.3142e-05
Iter: 858 loss: 1.30036024e-05
Iter: 859 loss: 1.29863438e-05
Iter: 860 loss: 1.30170974e-05
Iter: 861 loss: 1.2978966e-05
Iter: 862 loss: 1.29628952e-05
Iter: 863 loss: 1.30784756e-05
Iter: 864 loss: 1.29612217e-05
Iter: 865 loss: 1.29467671e-05
Iter: 866 loss: 1.29555438e-05
Iter: 867 loss: 1.29370965e-05
Iter: 868 loss: 1.29198143e-05
Iter: 869 loss: 1.29900927e-05
Iter: 870 loss: 1.29158989e-05
Iter: 871 loss: 1.29009059e-05
Iter: 872 loss: 1.29216187e-05
Iter: 873 loss: 1.2893539e-05
Iter: 874 loss: 1.28786378e-05
Iter: 875 loss: 1.28819456e-05
Iter: 876 loss: 1.28677648e-05
Iter: 877 loss: 1.28479051e-05
Iter: 878 loss: 1.29966056e-05
Iter: 879 loss: 1.28460579e-05
Iter: 880 loss: 1.28287629e-05
Iter: 881 loss: 1.28581542e-05
Iter: 882 loss: 1.28206175e-05
Iter: 883 loss: 1.28057554e-05
Iter: 884 loss: 1.2831968e-05
Iter: 885 loss: 1.27992662e-05
Iter: 886 loss: 1.27822514e-05
Iter: 887 loss: 1.28149768e-05
Iter: 888 loss: 1.27753774e-05
Iter: 889 loss: 1.27535777e-05
Iter: 890 loss: 1.28076481e-05
Iter: 891 loss: 1.27459789e-05
Iter: 892 loss: 1.27279745e-05
Iter: 893 loss: 1.27619214e-05
Iter: 894 loss: 1.27200074e-05
Iter: 895 loss: 1.27023623e-05
Iter: 896 loss: 1.27725e-05
Iter: 897 loss: 1.26979094e-05
Iter: 898 loss: 1.2679604e-05
Iter: 899 loss: 1.27913918e-05
Iter: 900 loss: 1.26771793e-05
Iter: 901 loss: 1.26619125e-05
Iter: 902 loss: 1.27270459e-05
Iter: 903 loss: 1.26584036e-05
Iter: 904 loss: 1.26451023e-05
Iter: 905 loss: 1.26578398e-05
Iter: 906 loss: 1.26375107e-05
Iter: 907 loss: 1.26223576e-05
Iter: 908 loss: 1.26273826e-05
Iter: 909 loss: 1.26116611e-05
Iter: 910 loss: 1.25963625e-05
Iter: 911 loss: 1.27217263e-05
Iter: 912 loss: 1.25952211e-05
Iter: 913 loss: 1.25815359e-05
Iter: 914 loss: 1.26166069e-05
Iter: 915 loss: 1.25770312e-05
Iter: 916 loss: 1.25641891e-05
Iter: 917 loss: 1.25592223e-05
Iter: 918 loss: 1.25521974e-05
Iter: 919 loss: 1.25338956e-05
Iter: 920 loss: 1.26676014e-05
Iter: 921 loss: 1.25323659e-05
Iter: 922 loss: 1.251701e-05
Iter: 923 loss: 1.2568642e-05
Iter: 924 loss: 1.2512719e-05
Iter: 925 loss: 1.24988928e-05
Iter: 926 loss: 1.25094521e-05
Iter: 927 loss: 1.24904982e-05
Iter: 928 loss: 1.24739945e-05
Iter: 929 loss: 1.25398255e-05
Iter: 930 loss: 1.2470653e-05
Iter: 931 loss: 1.24538383e-05
Iter: 932 loss: 1.24535691e-05
Iter: 933 loss: 1.24405087e-05
Iter: 934 loss: 1.24214639e-05
Iter: 935 loss: 1.25314109e-05
Iter: 936 loss: 1.24191029e-05
Iter: 937 loss: 1.24076532e-05
Iter: 938 loss: 1.2407625e-05
Iter: 939 loss: 1.23972295e-05
Iter: 940 loss: 1.23867267e-05
Iter: 941 loss: 1.23848949e-05
Iter: 942 loss: 1.2368012e-05
Iter: 943 loss: 1.24354156e-05
Iter: 944 loss: 1.2364274e-05
Iter: 945 loss: 1.23499585e-05
Iter: 946 loss: 1.23643385e-05
Iter: 947 loss: 1.23415311e-05
Iter: 948 loss: 1.232457e-05
Iter: 949 loss: 1.23503642e-05
Iter: 950 loss: 1.23164873e-05
Iter: 951 loss: 1.22984256e-05
Iter: 952 loss: 1.23538775e-05
Iter: 953 loss: 1.22928959e-05
Iter: 954 loss: 1.2274555e-05
Iter: 955 loss: 1.24096086e-05
Iter: 956 loss: 1.22730835e-05
Iter: 957 loss: 1.22588317e-05
Iter: 958 loss: 1.22681167e-05
Iter: 959 loss: 1.22494112e-05
Iter: 960 loss: 1.22341962e-05
Iter: 961 loss: 1.22896308e-05
Iter: 962 loss: 1.22302172e-05
Iter: 963 loss: 1.22154779e-05
Iter: 964 loss: 1.22487672e-05
Iter: 965 loss: 1.22096626e-05
Iter: 966 loss: 1.21923385e-05
Iter: 967 loss: 1.22014862e-05
Iter: 968 loss: 1.21810008e-05
Iter: 969 loss: 1.21651356e-05
Iter: 970 loss: 1.23644786e-05
Iter: 971 loss: 1.21649318e-05
Iter: 972 loss: 1.21520743e-05
Iter: 973 loss: 1.22079664e-05
Iter: 974 loss: 1.21493749e-05
Iter: 975 loss: 1.2139275e-05
Iter: 976 loss: 1.21516296e-05
Iter: 977 loss: 1.21340472e-05
Iter: 978 loss: 1.21203338e-05
Iter: 979 loss: 1.21433341e-05
Iter: 980 loss: 1.21136109e-05
Iter: 981 loss: 1.21008907e-05
Iter: 982 loss: 1.21198736e-05
Iter: 983 loss: 1.20943905e-05
Iter: 984 loss: 1.2079212e-05
Iter: 985 loss: 1.21241555e-05
Iter: 986 loss: 1.20743407e-05
Iter: 987 loss: 1.20587574e-05
Iter: 988 loss: 1.20789846e-05
Iter: 989 loss: 1.20507129e-05
Iter: 990 loss: 1.20332243e-05
Iter: 991 loss: 1.20416771e-05
Iter: 992 loss: 1.20213354e-05
Iter: 993 loss: 1.20033983e-05
Iter: 994 loss: 1.21681114e-05
Iter: 995 loss: 1.20027134e-05
Iter: 996 loss: 1.19876931e-05
Iter: 997 loss: 1.20350023e-05
Iter: 998 loss: 1.19834913e-05
Iter: 999 loss: 1.19679044e-05
Iter: 1000 loss: 1.19998122e-05
Iter: 1001 loss: 1.19618908e-05
Iter: 1002 loss: 1.19473007e-05
Iter: 1003 loss: 1.19956294e-05
Iter: 1004 loss: 1.19431852e-05
Iter: 1005 loss: 1.19277856e-05
Iter: 1006 loss: 1.19443812e-05
Iter: 1007 loss: 1.19191081e-05
Iter: 1008 loss: 1.19033939e-05
Iter: 1009 loss: 1.19779315e-05
Iter: 1010 loss: 1.19006017e-05
Iter: 1011 loss: 1.18871531e-05
Iter: 1012 loss: 1.20289187e-05
Iter: 1013 loss: 1.18867265e-05
Iter: 1014 loss: 1.18779462e-05
Iter: 1015 loss: 1.18631851e-05
Iter: 1016 loss: 1.18631451e-05
Iter: 1017 loss: 1.18466214e-05
Iter: 1018 loss: 1.19430288e-05
Iter: 1019 loss: 1.18446033e-05
Iter: 1020 loss: 1.18290154e-05
Iter: 1021 loss: 1.18614116e-05
Iter: 1022 loss: 1.18229e-05
Iter: 1023 loss: 1.18091702e-05
Iter: 1024 loss: 1.18626967e-05
Iter: 1025 loss: 1.18058451e-05
Iter: 1026 loss: 1.17940217e-05
Iter: 1027 loss: 1.18558055e-05
Iter: 1028 loss: 1.17919917e-05
Iter: 1029 loss: 1.17795098e-05
Iter: 1030 loss: 1.17681593e-05
Iter: 1031 loss: 1.17651871e-05
Iter: 1032 loss: 1.17471063e-05
Iter: 1033 loss: 1.18189491e-05
Iter: 1034 loss: 1.17430309e-05
Iter: 1035 loss: 1.17265336e-05
Iter: 1036 loss: 1.17634845e-05
Iter: 1037 loss: 1.17204463e-05
Iter: 1038 loss: 1.17035261e-05
Iter: 1039 loss: 1.18252538e-05
Iter: 1040 loss: 1.17021536e-05
Iter: 1041 loss: 1.16909305e-05
Iter: 1042 loss: 1.17093095e-05
Iter: 1043 loss: 1.16856845e-05
Iter: 1044 loss: 1.16719621e-05
Iter: 1045 loss: 1.17233994e-05
Iter: 1046 loss: 1.16684878e-05
Iter: 1047 loss: 1.16540123e-05
Iter: 1048 loss: 1.16768297e-05
Iter: 1049 loss: 1.16475821e-05
Iter: 1050 loss: 1.16328547e-05
Iter: 1051 loss: 1.17728869e-05
Iter: 1052 loss: 1.16324209e-05
Iter: 1053 loss: 1.16236279e-05
Iter: 1054 loss: 1.16154679e-05
Iter: 1055 loss: 1.16131532e-05
Iter: 1056 loss: 1.15994244e-05
Iter: 1057 loss: 1.16158371e-05
Iter: 1058 loss: 1.15920984e-05
Iter: 1059 loss: 1.15761304e-05
Iter: 1060 loss: 1.16814226e-05
Iter: 1061 loss: 1.1574476e-05
Iter: 1062 loss: 1.15607781e-05
Iter: 1063 loss: 1.15798703e-05
Iter: 1064 loss: 1.15541279e-05
Iter: 1065 loss: 1.15403473e-05
Iter: 1066 loss: 1.15582452e-05
Iter: 1067 loss: 1.15332932e-05
Iter: 1068 loss: 1.15183866e-05
Iter: 1069 loss: 1.1596605e-05
Iter: 1070 loss: 1.15161201e-05
Iter: 1071 loss: 1.15008388e-05
Iter: 1072 loss: 1.15590083e-05
Iter: 1073 loss: 1.14970971e-05
Iter: 1074 loss: 1.14827171e-05
Iter: 1075 loss: 1.14963041e-05
Iter: 1076 loss: 1.14742434e-05
Iter: 1077 loss: 1.14610839e-05
Iter: 1078 loss: 1.15293733e-05
Iter: 1079 loss: 1.14590475e-05
Iter: 1080 loss: 1.14465711e-05
Iter: 1081 loss: 1.14578133e-05
Iter: 1082 loss: 1.14390186e-05
Iter: 1083 loss: 1.14260602e-05
Iter: 1084 loss: 1.15371749e-05
Iter: 1085 loss: 1.14253e-05
Iter: 1086 loss: 1.14134236e-05
Iter: 1087 loss: 1.14439972e-05
Iter: 1088 loss: 1.14092e-05
Iter: 1089 loss: 1.13991946e-05
Iter: 1090 loss: 1.14050163e-05
Iter: 1091 loss: 1.13924179e-05
Iter: 1092 loss: 1.13789438e-05
Iter: 1093 loss: 1.14327486e-05
Iter: 1094 loss: 1.13757287e-05
Iter: 1095 loss: 1.13641081e-05
Iter: 1096 loss: 1.13665428e-05
Iter: 1097 loss: 1.13556844e-05
Iter: 1098 loss: 1.1342061e-05
Iter: 1099 loss: 1.13909246e-05
Iter: 1100 loss: 1.13388487e-05
Iter: 1101 loss: 1.13241767e-05
Iter: 1102 loss: 1.1370028e-05
Iter: 1103 loss: 1.13200058e-05
Iter: 1104 loss: 1.13064007e-05
Iter: 1105 loss: 1.13157803e-05
Iter: 1106 loss: 1.12976722e-05
Iter: 1107 loss: 1.12810321e-05
Iter: 1108 loss: 1.13173592e-05
Iter: 1109 loss: 1.12743601e-05
Iter: 1110 loss: 1.12570624e-05
Iter: 1111 loss: 1.13250526e-05
Iter: 1112 loss: 1.12531188e-05
Iter: 1113 loss: 1.12397247e-05
Iter: 1114 loss: 1.13559836e-05
Iter: 1115 loss: 1.12388561e-05
Iter: 1116 loss: 1.12288108e-05
Iter: 1117 loss: 1.1244324e-05
Iter: 1118 loss: 1.12239386e-05
Iter: 1119 loss: 1.12117305e-05
Iter: 1120 loss: 1.12630441e-05
Iter: 1121 loss: 1.12091675e-05
Iter: 1122 loss: 1.11984064e-05
Iter: 1123 loss: 1.12320595e-05
Iter: 1124 loss: 1.11954505e-05
Iter: 1125 loss: 1.11852087e-05
Iter: 1126 loss: 1.12285234e-05
Iter: 1127 loss: 1.11832414e-05
Iter: 1128 loss: 1.11744985e-05
Iter: 1129 loss: 1.11619793e-05
Iter: 1130 loss: 1.11615855e-05
Iter: 1131 loss: 1.11465279e-05
Iter: 1132 loss: 1.12509406e-05
Iter: 1133 loss: 1.11451673e-05
Iter: 1134 loss: 1.11334921e-05
Iter: 1135 loss: 1.11980571e-05
Iter: 1136 loss: 1.1131724e-05
Iter: 1137 loss: 1.11216104e-05
Iter: 1138 loss: 1.11122717e-05
Iter: 1139 loss: 1.11099544e-05
Iter: 1140 loss: 1.10940564e-05
Iter: 1141 loss: 1.12111848e-05
Iter: 1142 loss: 1.10925612e-05
Iter: 1143 loss: 1.10806459e-05
Iter: 1144 loss: 1.11172867e-05
Iter: 1145 loss: 1.10772316e-05
Iter: 1146 loss: 1.10665142e-05
Iter: 1147 loss: 1.10631363e-05
Iter: 1148 loss: 1.10569163e-05
Iter: 1149 loss: 1.10420415e-05
Iter: 1150 loss: 1.11202125e-05
Iter: 1151 loss: 1.10399105e-05
Iter: 1152 loss: 1.1027204e-05
Iter: 1153 loss: 1.10687661e-05
Iter: 1154 loss: 1.10240817e-05
Iter: 1155 loss: 1.10110232e-05
Iter: 1156 loss: 1.10606943e-05
Iter: 1157 loss: 1.10081191e-05
Iter: 1158 loss: 1.09966559e-05
Iter: 1159 loss: 1.10717574e-05
Iter: 1160 loss: 1.09953689e-05
Iter: 1161 loss: 1.09847197e-05
Iter: 1162 loss: 1.09927805e-05
Iter: 1163 loss: 1.09780867e-05
Iter: 1164 loss: 1.09681732e-05
Iter: 1165 loss: 1.09785942e-05
Iter: 1166 loss: 1.09627154e-05
Iter: 1167 loss: 1.09497851e-05
Iter: 1168 loss: 1.10130713e-05
Iter: 1169 loss: 1.09473049e-05
Iter: 1170 loss: 1.09367666e-05
Iter: 1171 loss: 1.09455141e-05
Iter: 1172 loss: 1.09305129e-05
Iter: 1173 loss: 1.09185848e-05
Iter: 1174 loss: 1.09417851e-05
Iter: 1175 loss: 1.09135526e-05
Iter: 1176 loss: 1.08987069e-05
Iter: 1177 loss: 1.09619432e-05
Iter: 1178 loss: 1.08954446e-05
Iter: 1179 loss: 1.08833501e-05
Iter: 1180 loss: 1.0898686e-05
Iter: 1181 loss: 1.087686e-05
Iter: 1182 loss: 1.08629984e-05
Iter: 1183 loss: 1.09307093e-05
Iter: 1184 loss: 1.08607128e-05
Iter: 1185 loss: 1.08482345e-05
Iter: 1186 loss: 1.08562908e-05
Iter: 1187 loss: 1.08404638e-05
Iter: 1188 loss: 1.0826001e-05
Iter: 1189 loss: 1.08443119e-05
Iter: 1190 loss: 1.08184277e-05
Iter: 1191 loss: 1.08025488e-05
Iter: 1192 loss: 1.08754111e-05
Iter: 1193 loss: 1.07994583e-05
Iter: 1194 loss: 1.07889045e-05
Iter: 1195 loss: 1.09174171e-05
Iter: 1196 loss: 1.0788709e-05
Iter: 1197 loss: 1.07799451e-05
Iter: 1198 loss: 1.07993601e-05
Iter: 1199 loss: 1.07763626e-05
Iter: 1200 loss: 1.07661399e-05
Iter: 1201 loss: 1.07724118e-05
Iter: 1202 loss: 1.07594724e-05
Iter: 1203 loss: 1.07486467e-05
Iter: 1204 loss: 1.07524838e-05
Iter: 1205 loss: 1.07412079e-05
Iter: 1206 loss: 1.07267533e-05
Iter: 1207 loss: 1.07677361e-05
Iter: 1208 loss: 1.07224896e-05
Iter: 1209 loss: 1.07095047e-05
Iter: 1210 loss: 1.08080449e-05
Iter: 1211 loss: 1.07085525e-05
Iter: 1212 loss: 1.06969947e-05
Iter: 1213 loss: 1.07023807e-05
Iter: 1214 loss: 1.06887819e-05
Iter: 1215 loss: 1.06764846e-05
Iter: 1216 loss: 1.07322876e-05
Iter: 1217 loss: 1.06739863e-05
Iter: 1218 loss: 1.06618772e-05
Iter: 1219 loss: 1.06955358e-05
Iter: 1220 loss: 1.06580137e-05
Iter: 1221 loss: 1.06464313e-05
Iter: 1222 loss: 1.06552206e-05
Iter: 1223 loss: 1.0639762e-05
Iter: 1224 loss: 1.06272291e-05
Iter: 1225 loss: 1.06773368e-05
Iter: 1226 loss: 1.06244879e-05
Iter: 1227 loss: 1.06108637e-05
Iter: 1228 loss: 1.0669638e-05
Iter: 1229 loss: 1.06082571e-05
Iter: 1230 loss: 1.05964555e-05
Iter: 1231 loss: 1.06155694e-05
Iter: 1232 loss: 1.05911422e-05
Iter: 1233 loss: 1.05820254e-05
Iter: 1234 loss: 1.06699335e-05
Iter: 1235 loss: 1.05817508e-05
Iter: 1236 loss: 1.05729741e-05
Iter: 1237 loss: 1.05766667e-05
Iter: 1238 loss: 1.05671133e-05
Iter: 1239 loss: 1.05563558e-05
Iter: 1240 loss: 1.05769286e-05
Iter: 1241 loss: 1.05516783e-05
Iter: 1242 loss: 1.05411145e-05
Iter: 1243 loss: 1.05532326e-05
Iter: 1244 loss: 1.05352337e-05
Iter: 1245 loss: 1.0522388e-05
Iter: 1246 loss: 1.05286308e-05
Iter: 1247 loss: 1.05136933e-05
Iter: 1248 loss: 1.04978772e-05
Iter: 1249 loss: 1.05732615e-05
Iter: 1250 loss: 1.04949359e-05
Iter: 1251 loss: 1.04825667e-05
Iter: 1252 loss: 1.05880954e-05
Iter: 1253 loss: 1.04817873e-05
Iter: 1254 loss: 1.04720793e-05
Iter: 1255 loss: 1.0471932e-05
Iter: 1256 loss: 1.04641704e-05
Iter: 1257 loss: 1.04511091e-05
Iter: 1258 loss: 1.05221516e-05
Iter: 1259 loss: 1.04491355e-05
Iter: 1260 loss: 1.04389e-05
Iter: 1261 loss: 1.04867622e-05
Iter: 1262 loss: 1.04369392e-05
Iter: 1263 loss: 1.04281617e-05
Iter: 1264 loss: 1.04214796e-05
Iter: 1265 loss: 1.04186038e-05
Iter: 1266 loss: 1.04051178e-05
Iter: 1267 loss: 1.0484051e-05
Iter: 1268 loss: 1.0403287e-05
Iter: 1269 loss: 1.03919829e-05
Iter: 1270 loss: 1.05055633e-05
Iter: 1271 loss: 1.03916245e-05
Iter: 1272 loss: 1.03832026e-05
Iter: 1273 loss: 1.03788516e-05
Iter: 1274 loss: 1.03749298e-05
Iter: 1275 loss: 1.03630027e-05
Iter: 1276 loss: 1.04008923e-05
Iter: 1277 loss: 1.03595157e-05
Iter: 1278 loss: 1.0348911e-05
Iter: 1279 loss: 1.03568527e-05
Iter: 1280 loss: 1.03427146e-05
Iter: 1281 loss: 1.03289694e-05
Iter: 1282 loss: 1.03572102e-05
Iter: 1283 loss: 1.03234606e-05
Iter: 1284 loss: 1.03133643e-05
Iter: 1285 loss: 1.04632209e-05
Iter: 1286 loss: 1.03133734e-05
Iter: 1287 loss: 1.0304695e-05
Iter: 1288 loss: 1.03018974e-05
Iter: 1289 loss: 1.02966933e-05
Iter: 1290 loss: 1.02844151e-05
Iter: 1291 loss: 1.03260745e-05
Iter: 1292 loss: 1.02814238e-05
Iter: 1293 loss: 1.02695367e-05
Iter: 1294 loss: 1.03103612e-05
Iter: 1295 loss: 1.02663553e-05
Iter: 1296 loss: 1.02551458e-05
Iter: 1297 loss: 1.02630165e-05
Iter: 1298 loss: 1.02481108e-05
Iter: 1299 loss: 1.02365602e-05
Iter: 1300 loss: 1.02864051e-05
Iter: 1301 loss: 1.02337281e-05
Iter: 1302 loss: 1.02215818e-05
Iter: 1303 loss: 1.02842141e-05
Iter: 1304 loss: 1.02195481e-05
Iter: 1305 loss: 1.02100312e-05
Iter: 1306 loss: 1.02272588e-05
Iter: 1307 loss: 1.02060021e-05
Iter: 1308 loss: 1.0194919e-05
Iter: 1309 loss: 1.02622635e-05
Iter: 1310 loss: 1.01938258e-05
Iter: 1311 loss: 1.01848545e-05
Iter: 1312 loss: 1.01794794e-05
Iter: 1313 loss: 1.01758487e-05
Iter: 1314 loss: 1.01640971e-05
Iter: 1315 loss: 1.02110025e-05
Iter: 1316 loss: 1.0161144e-05
Iter: 1317 loss: 1.01505311e-05
Iter: 1318 loss: 1.01672058e-05
Iter: 1319 loss: 1.01454825e-05
Iter: 1320 loss: 1.01328051e-05
Iter: 1321 loss: 1.01459118e-05
Iter: 1322 loss: 1.0125601e-05
Iter: 1323 loss: 1.01127371e-05
Iter: 1324 loss: 1.01531059e-05
Iter: 1325 loss: 1.01086462e-05
Iter: 1326 loss: 1.00954385e-05
Iter: 1327 loss: 1.017658e-05
Iter: 1328 loss: 1.00937486e-05
Iter: 1329 loss: 1.00829793e-05
Iter: 1330 loss: 1.01132737e-05
Iter: 1331 loss: 1.00793259e-05
Iter: 1332 loss: 1.00695743e-05
Iter: 1333 loss: 1.00791785e-05
Iter: 1334 loss: 1.00640882e-05
Iter: 1335 loss: 1.0052132e-05
Iter: 1336 loss: 1.01328442e-05
Iter: 1337 loss: 1.00509014e-05
Iter: 1338 loss: 1.00401776e-05
Iter: 1339 loss: 1.0054926e-05
Iter: 1340 loss: 1.00347443e-05
Iter: 1341 loss: 1.00256129e-05
Iter: 1342 loss: 1.00974903e-05
Iter: 1343 loss: 1.00250973e-05
Iter: 1344 loss: 1.0016257e-05
Iter: 1345 loss: 1.00262769e-05
Iter: 1346 loss: 1.00112957e-05
Iter: 1347 loss: 1.00021189e-05
Iter: 1348 loss: 1.00060042e-05
Iter: 1349 loss: 9.99546864e-06
Iter: 1350 loss: 9.98364703e-06
Iter: 1351 loss: 1.00539837e-05
Iter: 1352 loss: 9.9820827e-06
Iter: 1353 loss: 9.9734425e-06
Iter: 1354 loss: 9.98851829e-06
Iter: 1355 loss: 9.96971e-06
Iter: 1356 loss: 9.95929076e-06
Iter: 1357 loss: 9.97300413e-06
Iter: 1358 loss: 9.95396113e-06
Iter: 1359 loss: 9.94154379e-06
Iter: 1360 loss: 9.96350172e-06
Iter: 1361 loss: 9.93612321e-06
Iter: 1362 loss: 9.9233539e-06
Iter: 1363 loss: 9.93785216e-06
Iter: 1364 loss: 9.91648358e-06
Iter: 1365 loss: 9.90351145e-06
Iter: 1366 loss: 9.97905408e-06
Iter: 1367 loss: 9.90186891e-06
Iter: 1368 loss: 9.89080127e-06
Iter: 1369 loss: 9.95021128e-06
Iter: 1370 loss: 9.88937245e-06
Iter: 1371 loss: 9.88004649e-06
Iter: 1372 loss: 9.87824751e-06
Iter: 1373 loss: 9.87160547e-06
Iter: 1374 loss: 9.8587152e-06
Iter: 1375 loss: 9.91689e-06
Iter: 1376 loss: 9.85613588e-06
Iter: 1377 loss: 9.84605e-06
Iter: 1378 loss: 9.96697e-06
Iter: 1379 loss: 9.8458795e-06
Iter: 1380 loss: 9.83791051e-06
Iter: 1381 loss: 9.8405053e-06
Iter: 1382 loss: 9.83241171e-06
Iter: 1383 loss: 9.82318e-06
Iter: 1384 loss: 9.87977e-06
Iter: 1385 loss: 9.82201e-06
Iter: 1386 loss: 9.81480935e-06
Iter: 1387 loss: 9.81075937e-06
Iter: 1388 loss: 9.80778896e-06
Iter: 1389 loss: 9.79653123e-06
Iter: 1390 loss: 9.83693735e-06
Iter: 1391 loss: 9.7934726e-06
Iter: 1392 loss: 9.78279513e-06
Iter: 1393 loss: 9.81389167e-06
Iter: 1394 loss: 9.77965101e-06
Iter: 1395 loss: 9.76914e-06
Iter: 1396 loss: 9.79893412e-06
Iter: 1397 loss: 9.76596584e-06
Iter: 1398 loss: 9.75485091e-06
Iter: 1399 loss: 9.79210472e-06
Iter: 1400 loss: 9.75176317e-06
Iter: 1401 loss: 9.74213526e-06
Iter: 1402 loss: 9.74203795e-06
Iter: 1403 loss: 9.73405804e-06
Iter: 1404 loss: 9.72141333e-06
Iter: 1405 loss: 9.75043349e-06
Iter: 1406 loss: 9.71649752e-06
Iter: 1407 loss: 9.70587644e-06
Iter: 1408 loss: 9.81364519e-06
Iter: 1409 loss: 9.70549354e-06
Iter: 1410 loss: 9.69628491e-06
Iter: 1411 loss: 9.69966641e-06
Iter: 1412 loss: 9.68981385e-06
Iter: 1413 loss: 9.6771837e-06
Iter: 1414 loss: 9.69746361e-06
Iter: 1415 loss: 9.67131564e-06
Iter: 1416 loss: 9.66182324e-06
Iter: 1417 loss: 9.66183e-06
Iter: 1418 loss: 9.65350227e-06
Iter: 1419 loss: 9.65729305e-06
Iter: 1420 loss: 9.64775245e-06
Iter: 1421 loss: 9.63939692e-06
Iter: 1422 loss: 9.65964409e-06
Iter: 1423 loss: 9.63664e-06
Iter: 1424 loss: 9.62723425e-06
Iter: 1425 loss: 9.64414903e-06
Iter: 1426 loss: 9.62308513e-06
Iter: 1427 loss: 9.61334081e-06
Iter: 1428 loss: 9.63632192e-06
Iter: 1429 loss: 9.60973739e-06
Iter: 1430 loss: 9.59995396e-06
Iter: 1431 loss: 9.62882677e-06
Iter: 1432 loss: 9.59702538e-06
Iter: 1433 loss: 9.58635155e-06
Iter: 1434 loss: 9.5907817e-06
Iter: 1435 loss: 9.57932389e-06
Iter: 1436 loss: 9.56651456e-06
Iter: 1437 loss: 9.64634455e-06
Iter: 1438 loss: 9.56517943e-06
Iter: 1439 loss: 9.55439646e-06
Iter: 1440 loss: 9.60150282e-06
Iter: 1441 loss: 9.55206542e-06
Iter: 1442 loss: 9.54394727e-06
Iter: 1443 loss: 9.5411724e-06
Iter: 1444 loss: 9.53631388e-06
Iter: 1445 loss: 9.52496885e-06
Iter: 1446 loss: 9.56254189e-06
Iter: 1447 loss: 9.52181927e-06
Iter: 1448 loss: 9.50974209e-06
Iter: 1449 loss: 9.56363783e-06
Iter: 1450 loss: 9.5072719e-06
Iter: 1451 loss: 9.49727746e-06
Iter: 1452 loss: 9.51379297e-06
Iter: 1453 loss: 9.49262e-06
Iter: 1454 loss: 9.48387424e-06
Iter: 1455 loss: 9.56494569e-06
Iter: 1456 loss: 9.48362049e-06
Iter: 1457 loss: 9.47425906e-06
Iter: 1458 loss: 9.48161232e-06
Iter: 1459 loss: 9.46872206e-06
Iter: 1460 loss: 9.45971351e-06
Iter: 1461 loss: 9.46443834e-06
Iter: 1462 loss: 9.45374268e-06
Iter: 1463 loss: 9.44393832e-06
Iter: 1464 loss: 9.5017067e-06
Iter: 1465 loss: 9.44279782e-06
Iter: 1466 loss: 9.43430496e-06
Iter: 1467 loss: 9.44956901e-06
Iter: 1468 loss: 9.43073428e-06
Iter: 1469 loss: 9.41998587e-06
Iter: 1470 loss: 9.42988845e-06
Iter: 1471 loss: 9.41374583e-06
Iter: 1472 loss: 9.40014252e-06
Iter: 1473 loss: 9.46303e-06
Iter: 1474 loss: 9.39778147e-06
Iter: 1475 loss: 9.38876838e-06
Iter: 1476 loss: 9.39370148e-06
Iter: 1477 loss: 9.38280391e-06
Iter: 1478 loss: 9.37143614e-06
Iter: 1479 loss: 9.41274175e-06
Iter: 1480 loss: 9.36845572e-06
Iter: 1481 loss: 9.35764365e-06
Iter: 1482 loss: 9.44502881e-06
Iter: 1483 loss: 9.35694243e-06
Iter: 1484 loss: 9.34921445e-06
Iter: 1485 loss: 9.34723357e-06
Iter: 1486 loss: 9.34229138e-06
Iter: 1487 loss: 9.3316512e-06
Iter: 1488 loss: 9.37779532e-06
Iter: 1489 loss: 9.32939292e-06
Iter: 1490 loss: 9.31983777e-06
Iter: 1491 loss: 9.35752087e-06
Iter: 1492 loss: 9.31760587e-06
Iter: 1493 loss: 9.30984424e-06
Iter: 1494 loss: 9.3333274e-06
Iter: 1495 loss: 9.30727401e-06
Iter: 1496 loss: 9.29686212e-06
Iter: 1497 loss: 9.31756131e-06
Iter: 1498 loss: 9.29249654e-06
Iter: 1499 loss: 9.28363261e-06
Iter: 1500 loss: 9.28265e-06
Iter: 1501 loss: 9.27668952e-06
Iter: 1502 loss: 9.26568646e-06
Iter: 1503 loss: 9.30683746e-06
Iter: 1504 loss: 9.26298e-06
Iter: 1505 loss: 9.25268796e-06
Iter: 1506 loss: 9.29025e-06
Iter: 1507 loss: 9.24992128e-06
Iter: 1508 loss: 9.23984408e-06
Iter: 1509 loss: 9.2578e-06
Iter: 1510 loss: 9.23536754e-06
Iter: 1511 loss: 9.22632626e-06
Iter: 1512 loss: 9.29672206e-06
Iter: 1513 loss: 9.22523577e-06
Iter: 1514 loss: 9.21729315e-06
Iter: 1515 loss: 9.2155924e-06
Iter: 1516 loss: 9.21029641e-06
Iter: 1517 loss: 9.19891e-06
Iter: 1518 loss: 9.22781e-06
Iter: 1519 loss: 9.19535159e-06
Iter: 1520 loss: 9.18571277e-06
Iter: 1521 loss: 9.21443097e-06
Iter: 1522 loss: 9.18260048e-06
Iter: 1523 loss: 9.17215129e-06
Iter: 1524 loss: 9.2294058e-06
Iter: 1525 loss: 9.17079342e-06
Iter: 1526 loss: 9.16160843e-06
Iter: 1527 loss: 9.17658326e-06
Iter: 1528 loss: 9.15760938e-06
Iter: 1529 loss: 9.14898192e-06
Iter: 1530 loss: 9.22220352e-06
Iter: 1531 loss: 9.14860357e-06
Iter: 1532 loss: 9.1413558e-06
Iter: 1533 loss: 9.14398333e-06
Iter: 1534 loss: 9.13638905e-06
Iter: 1535 loss: 9.12687392e-06
Iter: 1536 loss: 9.17396e-06
Iter: 1537 loss: 9.12535688e-06
Iter: 1538 loss: 9.11740881e-06
Iter: 1539 loss: 9.11321786e-06
Iter: 1540 loss: 9.10937524e-06
Iter: 1541 loss: 9.09895425e-06
Iter: 1542 loss: 9.12899304e-06
Iter: 1543 loss: 9.09594564e-06
Iter: 1544 loss: 9.08563e-06
Iter: 1545 loss: 9.12323e-06
Iter: 1546 loss: 9.08324091e-06
Iter: 1547 loss: 9.0733738e-06
Iter: 1548 loss: 9.09864139e-06
Iter: 1549 loss: 9.06989e-06
Iter: 1550 loss: 9.06078094e-06
Iter: 1551 loss: 9.07786489e-06
Iter: 1552 loss: 9.0569547e-06
Iter: 1553 loss: 9.04653916e-06
Iter: 1554 loss: 9.11129882e-06
Iter: 1555 loss: 9.0456e-06
Iter: 1556 loss: 9.03626369e-06
Iter: 1557 loss: 9.04085118e-06
Iter: 1558 loss: 9.02995816e-06
Iter: 1559 loss: 9.0197409e-06
Iter: 1560 loss: 9.03596811e-06
Iter: 1561 loss: 9.01499152e-06
Iter: 1562 loss: 9.0041267e-06
Iter: 1563 loss: 9.06454534e-06
Iter: 1564 loss: 9.00282612e-06
Iter: 1565 loss: 8.99302722e-06
Iter: 1566 loss: 9.03113232e-06
Iter: 1567 loss: 8.99074257e-06
Iter: 1568 loss: 8.98255348e-06
Iter: 1569 loss: 9.03179e-06
Iter: 1570 loss: 8.98144663e-06
Iter: 1571 loss: 8.97389327e-06
Iter: 1572 loss: 8.98138296e-06
Iter: 1573 loss: 8.96944402e-06
Iter: 1574 loss: 8.96258098e-06
Iter: 1575 loss: 8.96267557e-06
Iter: 1576 loss: 8.95721e-06
Iter: 1577 loss: 8.94800542e-06
Iter: 1578 loss: 9.02815555e-06
Iter: 1579 loss: 8.94717505e-06
Iter: 1580 loss: 8.93962351e-06
Iter: 1581 loss: 8.94045843e-06
Iter: 1582 loss: 8.93357901e-06
Iter: 1583 loss: 8.92358821e-06
Iter: 1584 loss: 8.94973e-06
Iter: 1585 loss: 8.9202731e-06
Iter: 1586 loss: 8.9101959e-06
Iter: 1587 loss: 8.94157e-06
Iter: 1588 loss: 8.907351e-06
Iter: 1589 loss: 8.89772127e-06
Iter: 1590 loss: 8.9146688e-06
Iter: 1591 loss: 8.89338753e-06
Iter: 1592 loss: 8.8847537e-06
Iter: 1593 loss: 8.90896627e-06
Iter: 1594 loss: 8.88204e-06
Iter: 1595 loss: 8.87213901e-06
Iter: 1596 loss: 8.91924356e-06
Iter: 1597 loss: 8.87041278e-06
Iter: 1598 loss: 8.86085127e-06
Iter: 1599 loss: 8.87275655e-06
Iter: 1600 loss: 8.85593363e-06
Iter: 1601 loss: 8.84743713e-06
Iter: 1602 loss: 8.86650105e-06
Iter: 1603 loss: 8.84413294e-06
Iter: 1604 loss: 8.8347806e-06
Iter: 1605 loss: 8.9054729e-06
Iter: 1606 loss: 8.83393841e-06
Iter: 1607 loss: 8.82586573e-06
Iter: 1608 loss: 8.84209931e-06
Iter: 1609 loss: 8.82241511e-06
Iter: 1610 loss: 8.81475898e-06
Iter: 1611 loss: 8.83757275e-06
Iter: 1612 loss: 8.81234882e-06
Iter: 1613 loss: 8.80544485e-06
Iter: 1614 loss: 8.79814434e-06
Iter: 1615 loss: 8.79692107e-06
Iter: 1616 loss: 8.78547144e-06
Iter: 1617 loss: 8.84223937e-06
Iter: 1618 loss: 8.78333503e-06
Iter: 1619 loss: 8.77348612e-06
Iter: 1620 loss: 8.80525386e-06
Iter: 1621 loss: 8.77061302e-06
Iter: 1622 loss: 8.76047761e-06
Iter: 1623 loss: 8.79390609e-06
Iter: 1624 loss: 8.75782553e-06
Iter: 1625 loss: 8.74864236e-06
Iter: 1626 loss: 8.75776459e-06
Iter: 1627 loss: 8.74339821e-06
Iter: 1628 loss: 8.73440695e-06
Iter: 1629 loss: 8.81974665e-06
Iter: 1630 loss: 8.73413865e-06
Iter: 1631 loss: 8.72598866e-06
Iter: 1632 loss: 8.73741647e-06
Iter: 1633 loss: 8.72202509e-06
Iter: 1634 loss: 8.71344128e-06
Iter: 1635 loss: 8.72376859e-06
Iter: 1636 loss: 8.70920576e-06
Iter: 1637 loss: 8.7014223e-06
Iter: 1638 loss: 8.77366438e-06
Iter: 1639 loss: 8.70091208e-06
Iter: 1640 loss: 8.69410451e-06
Iter: 1641 loss: 8.70326585e-06
Iter: 1642 loss: 8.69061114e-06
Iter: 1643 loss: 8.68323514e-06
Iter: 1644 loss: 8.72551391e-06
Iter: 1645 loss: 8.68226653e-06
Iter: 1646 loss: 8.67560811e-06
Iter: 1647 loss: 8.67762446e-06
Iter: 1648 loss: 8.67088056e-06
Iter: 1649 loss: 8.66339542e-06
Iter: 1650 loss: 8.68619099e-06
Iter: 1651 loss: 8.66134087e-06
Iter: 1652 loss: 8.65236e-06
Iter: 1653 loss: 8.65758739e-06
Iter: 1654 loss: 8.64681897e-06
Iter: 1655 loss: 8.63681453e-06
Iter: 1656 loss: 8.65440416e-06
Iter: 1657 loss: 8.63292098e-06
Iter: 1658 loss: 8.62269371e-06
Iter: 1659 loss: 8.6603759e-06
Iter: 1660 loss: 8.62021534e-06
Iter: 1661 loss: 8.61082299e-06
Iter: 1662 loss: 8.64677713e-06
Iter: 1663 loss: 8.60855926e-06
Iter: 1664 loss: 8.5990323e-06
Iter: 1665 loss: 8.60597629e-06
Iter: 1666 loss: 8.59318152e-06
Iter: 1667 loss: 8.58297426e-06
Iter: 1668 loss: 8.616983e-06
Iter: 1669 loss: 8.57984924e-06
Iter: 1670 loss: 8.57112627e-06
Iter: 1671 loss: 8.6203645e-06
Iter: 1672 loss: 8.57003215e-06
Iter: 1673 loss: 8.5624315e-06
Iter: 1674 loss: 8.6147038e-06
Iter: 1675 loss: 8.56192491e-06
Iter: 1676 loss: 8.55530652e-06
Iter: 1677 loss: 8.55889448e-06
Iter: 1678 loss: 8.5509846e-06
Iter: 1679 loss: 8.54178597e-06
Iter: 1680 loss: 8.58099702e-06
Iter: 1681 loss: 8.53976e-06
Iter: 1682 loss: 8.53373695e-06
Iter: 1683 loss: 8.54530481e-06
Iter: 1684 loss: 8.53143592e-06
Iter: 1685 loss: 8.5247475e-06
Iter: 1686 loss: 8.53941674e-06
Iter: 1687 loss: 8.52241828e-06
Iter: 1688 loss: 8.51446748e-06
Iter: 1689 loss: 8.50985634e-06
Iter: 1690 loss: 8.50637116e-06
Iter: 1691 loss: 8.49692515e-06
Iter: 1692 loss: 8.60037653e-06
Iter: 1693 loss: 8.49650132e-06
Iter: 1694 loss: 8.48923628e-06
Iter: 1695 loss: 8.50758715e-06
Iter: 1696 loss: 8.48665059e-06
Iter: 1697 loss: 8.47913361e-06
Iter: 1698 loss: 8.4782987e-06
Iter: 1699 loss: 8.47294177e-06
Iter: 1700 loss: 8.4637777e-06
Iter: 1701 loss: 8.5221227e-06
Iter: 1702 loss: 8.46264265e-06
Iter: 1703 loss: 8.45433351e-06
Iter: 1704 loss: 8.46179046e-06
Iter: 1705 loss: 8.44936403e-06
Iter: 1706 loss: 8.43998896e-06
Iter: 1707 loss: 8.46690637e-06
Iter: 1708 loss: 8.43703765e-06
Iter: 1709 loss: 8.42802e-06
Iter: 1710 loss: 8.44416445e-06
Iter: 1711 loss: 8.4240819e-06
Iter: 1712 loss: 8.41618839e-06
Iter: 1713 loss: 8.41644487e-06
Iter: 1714 loss: 8.40937901e-06
Iter: 1715 loss: 8.40753819e-06
Iter: 1716 loss: 8.40308167e-06
Iter: 1717 loss: 8.39498443e-06
Iter: 1718 loss: 8.43694852e-06
Iter: 1719 loss: 8.39363111e-06
Iter: 1720 loss: 8.3865616e-06
Iter: 1721 loss: 8.38943652e-06
Iter: 1722 loss: 8.38211781e-06
Iter: 1723 loss: 8.37309926e-06
Iter: 1724 loss: 8.39879431e-06
Iter: 1725 loss: 8.37047e-06
Iter: 1726 loss: 8.36165418e-06
Iter: 1727 loss: 8.41064775e-06
Iter: 1728 loss: 8.36034815e-06
Iter: 1729 loss: 8.35392711e-06
Iter: 1730 loss: 8.35725587e-06
Iter: 1731 loss: 8.34930142e-06
Iter: 1732 loss: 8.34190359e-06
Iter: 1733 loss: 8.37105563e-06
Iter: 1734 loss: 8.34002913e-06
Iter: 1735 loss: 8.33143167e-06
Iter: 1736 loss: 8.3523646e-06
Iter: 1737 loss: 8.3283976e-06
Iter: 1738 loss: 8.3203613e-06
Iter: 1739 loss: 8.33931e-06
Iter: 1740 loss: 8.31746911e-06
Iter: 1741 loss: 8.30886074e-06
Iter: 1742 loss: 8.32530077e-06
Iter: 1743 loss: 8.3051882e-06
Iter: 1744 loss: 8.29608689e-06
Iter: 1745 loss: 8.31303259e-06
Iter: 1746 loss: 8.29191686e-06
Iter: 1747 loss: 8.2831757e-06
Iter: 1748 loss: 8.30653153e-06
Iter: 1749 loss: 8.28005886e-06
Iter: 1750 loss: 8.2740371e-06
Iter: 1751 loss: 8.2739989e-06
Iter: 1752 loss: 8.26906307e-06
Iter: 1753 loss: 8.26221822e-06
Iter: 1754 loss: 8.26209452e-06
Iter: 1755 loss: 8.25400184e-06
Iter: 1756 loss: 8.27542135e-06
Iter: 1757 loss: 8.25149255e-06
Iter: 1758 loss: 8.24307426e-06
Iter: 1759 loss: 8.27702752e-06
Iter: 1760 loss: 8.24100516e-06
Iter: 1761 loss: 8.23338e-06
Iter: 1762 loss: 8.24185372e-06
Iter: 1763 loss: 8.22923812e-06
Iter: 1764 loss: 8.22110542e-06
Iter: 1765 loss: 8.23959726e-06
Iter: 1766 loss: 8.21802223e-06
Iter: 1767 loss: 8.21003232e-06
Iter: 1768 loss: 8.27767e-06
Iter: 1769 loss: 8.20958485e-06
Iter: 1770 loss: 8.20280457e-06
Iter: 1771 loss: 8.20841797e-06
Iter: 1772 loss: 8.1986409e-06
Iter: 1773 loss: 8.19126399e-06
Iter: 1774 loss: 8.21669892e-06
Iter: 1775 loss: 8.18919e-06
Iter: 1776 loss: 8.18123135e-06
Iter: 1777 loss: 8.19504658e-06
Iter: 1778 loss: 8.17796717e-06
Iter: 1779 loss: 8.17012733e-06
Iter: 1780 loss: 8.20213427e-06
Iter: 1781 loss: 8.16819647e-06
Iter: 1782 loss: 8.16108604e-06
Iter: 1783 loss: 8.19223715e-06
Iter: 1784 loss: 8.15959083e-06
Iter: 1785 loss: 8.1533135e-06
Iter: 1786 loss: 8.15749354e-06
Iter: 1787 loss: 8.14953728e-06
Iter: 1788 loss: 8.14222585e-06
Iter: 1789 loss: 8.22212587e-06
Iter: 1790 loss: 8.14222221e-06
Iter: 1791 loss: 8.13677798e-06
Iter: 1792 loss: 8.13172846e-06
Iter: 1793 loss: 8.13059341e-06
Iter: 1794 loss: 8.12252074e-06
Iter: 1795 loss: 8.12347207e-06
Iter: 1796 loss: 8.11643167e-06
Iter: 1797 loss: 8.10751953e-06
Iter: 1798 loss: 8.21092908e-06
Iter: 1799 loss: 8.1073922e-06
Iter: 1800 loss: 8.1005328e-06
Iter: 1801 loss: 8.11161954e-06
Iter: 1802 loss: 8.09753601e-06
Iter: 1803 loss: 8.08959703e-06
Iter: 1804 loss: 8.09484663e-06
Iter: 1805 loss: 8.08464e-06
Iter: 1806 loss: 8.07603828e-06
Iter: 1807 loss: 8.11301925e-06
Iter: 1808 loss: 8.07435208e-06
Iter: 1809 loss: 8.0658765e-06
Iter: 1810 loss: 8.09763515e-06
Iter: 1811 loss: 8.06376e-06
Iter: 1812 loss: 8.05573654e-06
Iter: 1813 loss: 8.07135348e-06
Iter: 1814 loss: 8.05224408e-06
Iter: 1815 loss: 8.04396404e-06
Iter: 1816 loss: 8.08998811e-06
Iter: 1817 loss: 8.04289448e-06
Iter: 1818 loss: 8.03554576e-06
Iter: 1819 loss: 8.05062e-06
Iter: 1820 loss: 8.03286275e-06
Iter: 1821 loss: 8.02681916e-06
Iter: 1822 loss: 8.06959e-06
Iter: 1823 loss: 8.02635805e-06
Iter: 1824 loss: 8.02053364e-06
Iter: 1825 loss: 8.02358136e-06
Iter: 1826 loss: 8.01640545e-06
Iter: 1827 loss: 8.00935413e-06
Iter: 1828 loss: 8.01189162e-06
Iter: 1829 loss: 8.00443922e-06
Iter: 1830 loss: 7.99693316e-06
Iter: 1831 loss: 8.08225741e-06
Iter: 1832 loss: 7.9968695e-06
Iter: 1833 loss: 7.99115514e-06
Iter: 1834 loss: 7.98513247e-06
Iter: 1835 loss: 7.98396741e-06
Iter: 1836 loss: 7.9747133e-06
Iter: 1837 loss: 8.00701764e-06
Iter: 1838 loss: 7.97226312e-06
Iter: 1839 loss: 7.96414952e-06
Iter: 1840 loss: 8.00778889e-06
Iter: 1841 loss: 7.9628835e-06
Iter: 1842 loss: 7.95544474e-06
Iter: 1843 loss: 7.9660731e-06
Iter: 1844 loss: 7.95165579e-06
Iter: 1845 loss: 7.94366133e-06
Iter: 1846 loss: 7.95036e-06
Iter: 1847 loss: 7.93885556e-06
Iter: 1848 loss: 7.92981882e-06
Iter: 1849 loss: 7.99063309e-06
Iter: 1850 loss: 7.92877108e-06
Iter: 1851 loss: 7.92104765e-06
Iter: 1852 loss: 7.93861091e-06
Iter: 1853 loss: 7.91815182e-06
Iter: 1854 loss: 7.91052844e-06
Iter: 1855 loss: 7.93360505e-06
Iter: 1856 loss: 7.90843114e-06
Iter: 1857 loss: 7.9010133e-06
Iter: 1858 loss: 7.97540724e-06
Iter: 1859 loss: 7.90089325e-06
Iter: 1860 loss: 7.89595924e-06
Iter: 1861 loss: 7.8911462e-06
Iter: 1862 loss: 7.89016303e-06
Iter: 1863 loss: 7.88256e-06
Iter: 1864 loss: 7.91381535e-06
Iter: 1865 loss: 7.88091893e-06
Iter: 1866 loss: 7.87336e-06
Iter: 1867 loss: 7.90202103e-06
Iter: 1868 loss: 7.87164754e-06
Iter: 1869 loss: 7.86582859e-06
Iter: 1870 loss: 7.86363307e-06
Iter: 1871 loss: 7.86054807e-06
Iter: 1872 loss: 7.85268639e-06
Iter: 1873 loss: 7.92047922e-06
Iter: 1874 loss: 7.8521789e-06
Iter: 1875 loss: 7.84504846e-06
Iter: 1876 loss: 7.85063185e-06
Iter: 1877 loss: 7.84060103e-06
Iter: 1878 loss: 7.83250925e-06
Iter: 1879 loss: 7.85700468e-06
Iter: 1880 loss: 7.82993629e-06
Iter: 1881 loss: 7.8222256e-06
Iter: 1882 loss: 7.85100201e-06
Iter: 1883 loss: 7.82022835e-06
Iter: 1884 loss: 7.8122539e-06
Iter: 1885 loss: 7.81251492e-06
Iter: 1886 loss: 7.80584287e-06
Iter: 1887 loss: 7.7973591e-06
Iter: 1888 loss: 7.85157863e-06
Iter: 1889 loss: 7.79646871e-06
Iter: 1890 loss: 7.78952e-06
Iter: 1891 loss: 7.8114972e-06
Iter: 1892 loss: 7.78744197e-06
Iter: 1893 loss: 7.78015601e-06
Iter: 1894 loss: 7.80346181e-06
Iter: 1895 loss: 7.77797504e-06
Iter: 1896 loss: 7.77039168e-06
Iter: 1897 loss: 7.81990639e-06
Iter: 1898 loss: 7.76956404e-06
Iter: 1899 loss: 7.76467641e-06
Iter: 1900 loss: 7.76185334e-06
Iter: 1901 loss: 7.75984518e-06
Iter: 1902 loss: 7.75286389e-06
Iter: 1903 loss: 7.75390799e-06
Iter: 1904 loss: 7.74712862e-06
Iter: 1905 loss: 7.73817101e-06
Iter: 1906 loss: 7.80398568e-06
Iter: 1907 loss: 7.73751435e-06
Iter: 1908 loss: 7.72956355e-06
Iter: 1909 loss: 7.76532124e-06
Iter: 1910 loss: 7.72804106e-06
Iter: 1911 loss: 7.72179646e-06
Iter: 1912 loss: 7.72793e-06
Iter: 1913 loss: 7.71805e-06
Iter: 1914 loss: 7.71081613e-06
Iter: 1915 loss: 7.73646207e-06
Iter: 1916 loss: 7.70897623e-06
Iter: 1917 loss: 7.70120278e-06
Iter: 1918 loss: 7.71879149e-06
Iter: 1919 loss: 7.69810595e-06
Iter: 1920 loss: 7.69164853e-06
Iter: 1921 loss: 7.71050873e-06
Iter: 1922 loss: 7.68931568e-06
Iter: 1923 loss: 7.68247355e-06
Iter: 1924 loss: 7.71925534e-06
Iter: 1925 loss: 7.68163773e-06
Iter: 1926 loss: 7.67570054e-06
Iter: 1927 loss: 7.67551683e-06
Iter: 1928 loss: 7.67080928e-06
Iter: 1929 loss: 7.66313497e-06
Iter: 1930 loss: 7.70867155e-06
Iter: 1931 loss: 7.66218727e-06
Iter: 1932 loss: 7.65615732e-06
Iter: 1933 loss: 7.69402413e-06
Iter: 1934 loss: 7.65565346e-06
Iter: 1935 loss: 7.65033747e-06
Iter: 1936 loss: 7.65600817e-06
Iter: 1937 loss: 7.64750621e-06
Iter: 1938 loss: 7.64117158e-06
Iter: 1939 loss: 7.64114e-06
Iter: 1940 loss: 7.63627213e-06
Iter: 1941 loss: 7.62814807e-06
Iter: 1942 loss: 7.63780554e-06
Iter: 1943 loss: 7.62373429e-06
Iter: 1944 loss: 7.61483625e-06
Iter: 1945 loss: 7.64797e-06
Iter: 1946 loss: 7.61285128e-06
Iter: 1947 loss: 7.60472267e-06
Iter: 1948 loss: 7.65148161e-06
Iter: 1949 loss: 7.60364037e-06
Iter: 1950 loss: 7.59613067e-06
Iter: 1951 loss: 7.61620322e-06
Iter: 1952 loss: 7.59361501e-06
Iter: 1953 loss: 7.58687202e-06
Iter: 1954 loss: 7.59600653e-06
Iter: 1955 loss: 7.5836424e-06
Iter: 1956 loss: 7.57577436e-06
Iter: 1957 loss: 7.62069067e-06
Iter: 1958 loss: 7.57473208e-06
Iter: 1959 loss: 7.56843701e-06
Iter: 1960 loss: 7.56947202e-06
Iter: 1961 loss: 7.56371719e-06
Iter: 1962 loss: 7.55533119e-06
Iter: 1963 loss: 7.58712576e-06
Iter: 1964 loss: 7.55334258e-06
Iter: 1965 loss: 7.54567054e-06
Iter: 1966 loss: 7.59733211e-06
Iter: 1967 loss: 7.54502253e-06
Iter: 1968 loss: 7.53932727e-06
Iter: 1969 loss: 7.55602741e-06
Iter: 1970 loss: 7.53759196e-06
Iter: 1971 loss: 7.53161e-06
Iter: 1972 loss: 7.54753455e-06
Iter: 1973 loss: 7.529703e-06
Iter: 1974 loss: 7.52356618e-06
Iter: 1975 loss: 7.53202039e-06
Iter: 1976 loss: 7.52049e-06
Iter: 1977 loss: 7.51366724e-06
Iter: 1978 loss: 7.53187351e-06
Iter: 1979 loss: 7.51143398e-06
Iter: 1980 loss: 7.50555228e-06
Iter: 1981 loss: 7.50471554e-06
Iter: 1982 loss: 7.50060053e-06
Iter: 1983 loss: 7.49181663e-06
Iter: 1984 loss: 7.50728668e-06
Iter: 1985 loss: 7.48785169e-06
Iter: 1986 loss: 7.47804143e-06
Iter: 1987 loss: 7.5243388e-06
Iter: 1988 loss: 7.47633112e-06
Iter: 1989 loss: 7.46911155e-06
Iter: 1990 loss: 7.53299355e-06
Iter: 1991 loss: 7.46879414e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.4
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.4
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.4 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.4
+ date
Sun Nov  8 10:31:05 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2/300_100_100_100_1 --function f2 --psi 0 --alpha 2.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.4/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f983389a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ce6e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ce40e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ce40840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ce40400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ce0eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cd571e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ce317b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cd54268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cd1ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cd116a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cc1d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cc1dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cc972f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cc43400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cc5f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cc5fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb950d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb85510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb1f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb1f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb737b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb4bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb73c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cb73620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982cbef510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f98338e8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ca5a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ca5ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ca596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982ca1aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982c93a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982c93a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982c9bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982c9d4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f982c9d4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.010618907
test_loss: 0.013366117
train_loss: 0.009480537
test_loss: 0.011599051
train_loss: 0.00896531
test_loss: 0.011337017
train_loss: 0.008713733
test_loss: 0.011437643
train_loss: 0.008552763
test_loss: 0.01109182
train_loss: 0.008311751
test_loss: 0.010972943
train_loss: 0.008321653
test_loss: 0.011312763
train_loss: 0.008589602
test_loss: 0.01116414
train_loss: 0.008080769
test_loss: 0.010708699
train_loss: 0.008161336
test_loss: 0.010821845
train_loss: 0.008298374
test_loss: 0.010751095
train_loss: 0.008426844
test_loss: 0.010720193
train_loss: 0.008690409
test_loss: 0.011248822
train_loss: 0.008165339
test_loss: 0.010720268
train_loss: 0.008216207
test_loss: 0.0106531875
train_loss: 0.008255709
test_loss: 0.010769223
train_loss: 0.008177766
test_loss: 0.01060689
train_loss: 0.007513767
test_loss: 0.010646289
train_loss: 0.007552147
test_loss: 0.010996865
train_loss: 0.007731167
test_loss: 0.010853656
train_loss: 0.007764626
test_loss: 0.010402413
train_loss: 0.0080074975
test_loss: 0.010686867
train_loss: 0.00809907
test_loss: 0.0108264135
train_loss: 0.0078611635
test_loss: 0.01062642
train_loss: 0.008114804
test_loss: 0.010799365
train_loss: 0.007780249
test_loss: 0.0104427
train_loss: 0.007944036
test_loss: 0.010506736
train_loss: 0.0075967414
test_loss: 0.010312776
train_loss: 0.007964731
test_loss: 0.010496945
train_loss: 0.0077784457
test_loss: 0.010696638
train_loss: 0.007735285
test_loss: 0.011051103
train_loss: 0.007662384
test_loss: 0.010358755
train_loss: 0.0077368915
test_loss: 0.010400136
train_loss: 0.0072328146
test_loss: 0.010169536
train_loss: 0.0070961053
test_loss: 0.010020686
train_loss: 0.0073126378
test_loss: 0.010011571
train_loss: 0.0075164647
test_loss: 0.010427892
train_loss: 0.0076002623
test_loss: 0.010483693
train_loss: 0.0072952923
test_loss: 0.010213377
train_loss: 0.0072149653
test_loss: 0.0102901105
train_loss: 0.007286301
test_loss: 0.010267783
train_loss: 0.0074328687
test_loss: 0.010325492
train_loss: 0.0073706256
test_loss: 0.010097868
train_loss: 0.0075990087
test_loss: 0.0103382785
train_loss: 0.007861301
test_loss: 0.010186019
train_loss: 0.007151272
test_loss: 0.010112927
train_loss: 0.007393058
test_loss: 0.010143963
train_loss: 0.0072334795
test_loss: 0.010082658
train_loss: 0.0072930735
test_loss: 0.010035471
train_loss: 0.0074463626
test_loss: 0.010202903
train_loss: 0.007343928
test_loss: 0.010170322
train_loss: 0.0074171107
test_loss: 0.010109463
train_loss: 0.0072693164
test_loss: 0.010287871
train_loss: 0.0072463695
test_loss: 0.009969582
train_loss: 0.007661001
test_loss: 0.010371179
train_loss: 0.0071162316
test_loss: 0.009871381
train_loss: 0.007216671
test_loss: 0.0099734
train_loss: 0.0075934734
test_loss: 0.0101265665
train_loss: 0.0069232685
test_loss: 0.009864262
train_loss: 0.007101032
test_loss: 0.009805236
train_loss: 0.007614486
test_loss: 0.009999959
train_loss: 0.0074059507
test_loss: 0.010190313
train_loss: 0.0070583653
test_loss: 0.009780391
train_loss: 0.006953366
test_loss: 0.009818105
train_loss: 0.006936903
test_loss: 0.009799956
train_loss: 0.007525773
test_loss: 0.010010556
train_loss: 0.0072567537
test_loss: 0.009980173
train_loss: 0.0070941253
test_loss: 0.0097472975
train_loss: 0.0068878997
test_loss: 0.009954867
train_loss: 0.007157744
test_loss: 0.010030297
train_loss: 0.007357505
test_loss: 0.010015443
train_loss: 0.006963082
test_loss: 0.009949167
train_loss: 0.0072140377
test_loss: 0.0102298735
train_loss: 0.007045439
test_loss: 0.009767327
train_loss: 0.006745313
test_loss: 0.009567051
train_loss: 0.0068939202
test_loss: 0.009679545
train_loss: 0.0071359864
test_loss: 0.009914627
train_loss: 0.0065319655
test_loss: 0.009753726
train_loss: 0.006928041
test_loss: 0.009821149
train_loss: 0.0068170186
test_loss: 0.009645163
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.4/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.4/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 2.4 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.4/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330e9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330e9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330e9048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330adf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd433069598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330240d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330401e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330248c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd432fd21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd432ff6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd432fa0c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3e2b16048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3e2b167b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3e2ac02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd433004158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd4330e9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3e2a9d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3e2a45400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3e2a456a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3e2a45730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc1738c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc1906a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc13c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc13cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc0eb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc103488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc103620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc103f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc0c1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc08dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3bc103ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd364212730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd364218510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3641d5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3641d5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3641d5510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.0032165e-05
Iter: 2 loss: 6.90265369e-05
Iter: 3 loss: 9.60939433e-05
Iter: 4 loss: 6.52946183e-05
Iter: 5 loss: 5.64692455e-05
Iter: 6 loss: 8.2855433e-05
Iter: 7 loss: 5.38310087e-05
Iter: 8 loss: 4.90642924e-05
Iter: 9 loss: 6.14986566e-05
Iter: 10 loss: 4.74656335e-05
Iter: 11 loss: 4.42204473e-05
Iter: 12 loss: 8.03312287e-05
Iter: 13 loss: 4.41560733e-05
Iter: 14 loss: 4.23386882e-05
Iter: 15 loss: 4.93958541e-05
Iter: 16 loss: 4.19126955e-05
Iter: 17 loss: 4.01310135e-05
Iter: 18 loss: 4.1090283e-05
Iter: 19 loss: 3.89605666e-05
Iter: 20 loss: 3.70514244e-05
Iter: 21 loss: 4.36310365e-05
Iter: 22 loss: 3.65457272e-05
Iter: 23 loss: 3.51481285e-05
Iter: 24 loss: 4.36755e-05
Iter: 25 loss: 3.4979159e-05
Iter: 26 loss: 3.40254774e-05
Iter: 27 loss: 3.33850767e-05
Iter: 28 loss: 3.30313778e-05
Iter: 29 loss: 3.17265913e-05
Iter: 30 loss: 4.14730384e-05
Iter: 31 loss: 3.1621752e-05
Iter: 32 loss: 3.07118389e-05
Iter: 33 loss: 3.44101572e-05
Iter: 34 loss: 3.05119374e-05
Iter: 35 loss: 2.9851748e-05
Iter: 36 loss: 3.11574768e-05
Iter: 37 loss: 2.95793561e-05
Iter: 38 loss: 2.89726941e-05
Iter: 39 loss: 3.07955524e-05
Iter: 40 loss: 2.87892653e-05
Iter: 41 loss: 2.83350619e-05
Iter: 42 loss: 3.25706096e-05
Iter: 43 loss: 2.83159079e-05
Iter: 44 loss: 2.78850657e-05
Iter: 45 loss: 2.85907918e-05
Iter: 46 loss: 2.76877963e-05
Iter: 47 loss: 2.73295918e-05
Iter: 48 loss: 2.8912722e-05
Iter: 49 loss: 2.72587204e-05
Iter: 50 loss: 2.69397206e-05
Iter: 51 loss: 2.92282493e-05
Iter: 52 loss: 2.69118282e-05
Iter: 53 loss: 2.67068626e-05
Iter: 54 loss: 2.67701489e-05
Iter: 55 loss: 2.65600884e-05
Iter: 56 loss: 2.62564718e-05
Iter: 57 loss: 2.68868425e-05
Iter: 58 loss: 2.61364148e-05
Iter: 59 loss: 2.58942819e-05
Iter: 60 loss: 2.65721919e-05
Iter: 61 loss: 2.58170949e-05
Iter: 62 loss: 2.55504783e-05
Iter: 63 loss: 2.61353707e-05
Iter: 64 loss: 2.54485112e-05
Iter: 65 loss: 2.52099017e-05
Iter: 66 loss: 2.5796011e-05
Iter: 67 loss: 2.51252095e-05
Iter: 68 loss: 2.48966517e-05
Iter: 69 loss: 2.51731e-05
Iter: 70 loss: 2.47764328e-05
Iter: 71 loss: 2.45454594e-05
Iter: 72 loss: 2.67289906e-05
Iter: 73 loss: 2.45363699e-05
Iter: 74 loss: 2.4363173e-05
Iter: 75 loss: 2.42892966e-05
Iter: 76 loss: 2.4199755e-05
Iter: 77 loss: 2.39726742e-05
Iter: 78 loss: 2.47507178e-05
Iter: 79 loss: 2.39117871e-05
Iter: 80 loss: 2.3705792e-05
Iter: 81 loss: 2.49640398e-05
Iter: 82 loss: 2.36807791e-05
Iter: 83 loss: 2.35360494e-05
Iter: 84 loss: 2.50486264e-05
Iter: 85 loss: 2.35321804e-05
Iter: 86 loss: 2.3420278e-05
Iter: 87 loss: 2.33961036e-05
Iter: 88 loss: 2.33235951e-05
Iter: 89 loss: 2.32126567e-05
Iter: 90 loss: 2.3212453e-05
Iter: 91 loss: 2.31255563e-05
Iter: 92 loss: 2.29925172e-05
Iter: 93 loss: 2.29904272e-05
Iter: 94 loss: 2.28595709e-05
Iter: 95 loss: 2.39653946e-05
Iter: 96 loss: 2.28520112e-05
Iter: 97 loss: 2.27393357e-05
Iter: 98 loss: 2.28884674e-05
Iter: 99 loss: 2.26824923e-05
Iter: 100 loss: 2.25687108e-05
Iter: 101 loss: 2.27163237e-05
Iter: 102 loss: 2.2510887e-05
Iter: 103 loss: 2.23770985e-05
Iter: 104 loss: 2.30069381e-05
Iter: 105 loss: 2.2352755e-05
Iter: 106 loss: 2.22390736e-05
Iter: 107 loss: 2.24097985e-05
Iter: 108 loss: 2.21847367e-05
Iter: 109 loss: 2.20750662e-05
Iter: 110 loss: 2.22467024e-05
Iter: 111 loss: 2.20233978e-05
Iter: 112 loss: 2.19067115e-05
Iter: 113 loss: 2.28190074e-05
Iter: 114 loss: 2.18980167e-05
Iter: 115 loss: 2.18095884e-05
Iter: 116 loss: 2.18360947e-05
Iter: 117 loss: 2.17464403e-05
Iter: 118 loss: 2.1643722e-05
Iter: 119 loss: 2.20645197e-05
Iter: 120 loss: 2.16209173e-05
Iter: 121 loss: 2.1532418e-05
Iter: 122 loss: 2.2490658e-05
Iter: 123 loss: 2.15304608e-05
Iter: 124 loss: 2.14635511e-05
Iter: 125 loss: 2.15465479e-05
Iter: 126 loss: 2.14287938e-05
Iter: 127 loss: 2.13609619e-05
Iter: 128 loss: 2.17387533e-05
Iter: 129 loss: 2.1350912e-05
Iter: 130 loss: 2.12819032e-05
Iter: 131 loss: 2.12200448e-05
Iter: 132 loss: 2.12017712e-05
Iter: 133 loss: 2.11236911e-05
Iter: 134 loss: 2.13441563e-05
Iter: 135 loss: 2.10986909e-05
Iter: 136 loss: 2.10090984e-05
Iter: 137 loss: 2.15208129e-05
Iter: 138 loss: 2.09973732e-05
Iter: 139 loss: 2.09248192e-05
Iter: 140 loss: 2.09524042e-05
Iter: 141 loss: 2.08746824e-05
Iter: 142 loss: 2.0802152e-05
Iter: 143 loss: 2.10448743e-05
Iter: 144 loss: 2.07822086e-05
Iter: 145 loss: 2.07089251e-05
Iter: 146 loss: 2.10256949e-05
Iter: 147 loss: 2.06935911e-05
Iter: 148 loss: 2.06232344e-05
Iter: 149 loss: 2.06609e-05
Iter: 150 loss: 2.05765773e-05
Iter: 151 loss: 2.05009437e-05
Iter: 152 loss: 2.07965131e-05
Iter: 153 loss: 2.04833814e-05
Iter: 154 loss: 2.04102216e-05
Iter: 155 loss: 2.05616598e-05
Iter: 156 loss: 2.0381387e-05
Iter: 157 loss: 2.03006784e-05
Iter: 158 loss: 2.08197089e-05
Iter: 159 loss: 2.02921401e-05
Iter: 160 loss: 2.02500742e-05
Iter: 161 loss: 2.06691566e-05
Iter: 162 loss: 2.02486845e-05
Iter: 163 loss: 2.02072e-05
Iter: 164 loss: 2.01622279e-05
Iter: 165 loss: 2.01553976e-05
Iter: 166 loss: 2.00964732e-05
Iter: 167 loss: 2.06757686e-05
Iter: 168 loss: 2.00946779e-05
Iter: 169 loss: 2.00491286e-05
Iter: 170 loss: 2.00406357e-05
Iter: 171 loss: 2.00096874e-05
Iter: 172 loss: 1.99513106e-05
Iter: 173 loss: 2.00301838e-05
Iter: 174 loss: 1.99217502e-05
Iter: 175 loss: 1.98557882e-05
Iter: 176 loss: 2.0080799e-05
Iter: 177 loss: 1.98378e-05
Iter: 178 loss: 1.97704976e-05
Iter: 179 loss: 2.01899293e-05
Iter: 180 loss: 1.97626323e-05
Iter: 181 loss: 1.97184363e-05
Iter: 182 loss: 1.96924557e-05
Iter: 183 loss: 1.96738147e-05
Iter: 184 loss: 1.96062811e-05
Iter: 185 loss: 1.97513109e-05
Iter: 186 loss: 1.95798366e-05
Iter: 187 loss: 1.95197135e-05
Iter: 188 loss: 2.01387065e-05
Iter: 189 loss: 1.95177308e-05
Iter: 190 loss: 1.94667336e-05
Iter: 191 loss: 1.94939093e-05
Iter: 192 loss: 1.94329114e-05
Iter: 193 loss: 1.93824853e-05
Iter: 194 loss: 1.95152279e-05
Iter: 195 loss: 1.93652377e-05
Iter: 196 loss: 1.93158485e-05
Iter: 197 loss: 1.97957634e-05
Iter: 198 loss: 1.93137093e-05
Iter: 199 loss: 1.92682674e-05
Iter: 200 loss: 1.93570777e-05
Iter: 201 loss: 1.92498483e-05
Iter: 202 loss: 1.9213503e-05
Iter: 203 loss: 1.93686865e-05
Iter: 204 loss: 1.92060415e-05
Iter: 205 loss: 1.91722411e-05
Iter: 206 loss: 1.91802392e-05
Iter: 207 loss: 1.91476247e-05
Iter: 208 loss: 1.90994124e-05
Iter: 209 loss: 1.92598709e-05
Iter: 210 loss: 1.90861356e-05
Iter: 211 loss: 1.90433311e-05
Iter: 212 loss: 1.90643495e-05
Iter: 213 loss: 1.90145729e-05
Iter: 214 loss: 1.89671882e-05
Iter: 215 loss: 1.90880764e-05
Iter: 216 loss: 1.89508501e-05
Iter: 217 loss: 1.88972099e-05
Iter: 218 loss: 1.92578482e-05
Iter: 219 loss: 1.88917256e-05
Iter: 220 loss: 1.88561153e-05
Iter: 221 loss: 1.89424245e-05
Iter: 222 loss: 1.88438426e-05
Iter: 223 loss: 1.88072045e-05
Iter: 224 loss: 1.87423939e-05
Iter: 225 loss: 2.03494201e-05
Iter: 226 loss: 1.87424066e-05
Iter: 227 loss: 1.8685645e-05
Iter: 228 loss: 1.86855541e-05
Iter: 229 loss: 1.86450579e-05
Iter: 230 loss: 1.87817477e-05
Iter: 231 loss: 1.86340403e-05
Iter: 232 loss: 1.85905446e-05
Iter: 233 loss: 1.87066016e-05
Iter: 234 loss: 1.85766585e-05
Iter: 235 loss: 1.85396129e-05
Iter: 236 loss: 1.88705126e-05
Iter: 237 loss: 1.85383888e-05
Iter: 238 loss: 1.85053323e-05
Iter: 239 loss: 1.85335721e-05
Iter: 240 loss: 1.84860455e-05
Iter: 241 loss: 1.84540313e-05
Iter: 242 loss: 1.84559067e-05
Iter: 243 loss: 1.84289147e-05
Iter: 244 loss: 1.83766697e-05
Iter: 245 loss: 1.86733268e-05
Iter: 246 loss: 1.83695211e-05
Iter: 247 loss: 1.83358534e-05
Iter: 248 loss: 1.83335451e-05
Iter: 249 loss: 1.83081138e-05
Iter: 250 loss: 1.82650692e-05
Iter: 251 loss: 1.84866931e-05
Iter: 252 loss: 1.82581953e-05
Iter: 253 loss: 1.82160147e-05
Iter: 254 loss: 1.82527601e-05
Iter: 255 loss: 1.81915093e-05
Iter: 256 loss: 1.8149376e-05
Iter: 257 loss: 1.84479159e-05
Iter: 258 loss: 1.81456453e-05
Iter: 259 loss: 1.81091909e-05
Iter: 260 loss: 1.81856667e-05
Iter: 261 loss: 1.80946899e-05
Iter: 262 loss: 1.80583102e-05
Iter: 263 loss: 1.80927436e-05
Iter: 264 loss: 1.80373172e-05
Iter: 265 loss: 1.79948656e-05
Iter: 266 loss: 1.80087554e-05
Iter: 267 loss: 1.79648941e-05
Iter: 268 loss: 1.79147537e-05
Iter: 269 loss: 1.82513486e-05
Iter: 270 loss: 1.7909806e-05
Iter: 271 loss: 1.78782848e-05
Iter: 272 loss: 1.82943641e-05
Iter: 273 loss: 1.78783448e-05
Iter: 274 loss: 1.78483133e-05
Iter: 275 loss: 1.78701048e-05
Iter: 276 loss: 1.78291721e-05
Iter: 277 loss: 1.7797387e-05
Iter: 278 loss: 1.78953e-05
Iter: 279 loss: 1.77879228e-05
Iter: 280 loss: 1.77555576e-05
Iter: 281 loss: 1.77849288e-05
Iter: 282 loss: 1.77372494e-05
Iter: 283 loss: 1.77092679e-05
Iter: 284 loss: 1.79478102e-05
Iter: 285 loss: 1.77075017e-05
Iter: 286 loss: 1.76799876e-05
Iter: 287 loss: 1.76468257e-05
Iter: 288 loss: 1.76436297e-05
Iter: 289 loss: 1.76030717e-05
Iter: 290 loss: 1.77491547e-05
Iter: 291 loss: 1.75927562e-05
Iter: 292 loss: 1.75533787e-05
Iter: 293 loss: 1.7696997e-05
Iter: 294 loss: 1.75434088e-05
Iter: 295 loss: 1.75016139e-05
Iter: 296 loss: 1.76603135e-05
Iter: 297 loss: 1.74915876e-05
Iter: 298 loss: 1.74585166e-05
Iter: 299 loss: 1.7549326e-05
Iter: 300 loss: 1.74473244e-05
Iter: 301 loss: 1.74152192e-05
Iter: 302 loss: 1.747639e-05
Iter: 303 loss: 1.74014422e-05
Iter: 304 loss: 1.73643093e-05
Iter: 305 loss: 1.74206543e-05
Iter: 306 loss: 1.73462304e-05
Iter: 307 loss: 1.73096705e-05
Iter: 308 loss: 1.74005636e-05
Iter: 309 loss: 1.72970667e-05
Iter: 310 loss: 1.72713335e-05
Iter: 311 loss: 1.72715245e-05
Iter: 312 loss: 1.72437831e-05
Iter: 313 loss: 1.72162763e-05
Iter: 314 loss: 1.7210521e-05
Iter: 315 loss: 1.71750671e-05
Iter: 316 loss: 1.72809505e-05
Iter: 317 loss: 1.71638621e-05
Iter: 318 loss: 1.71314241e-05
Iter: 319 loss: 1.73080916e-05
Iter: 320 loss: 1.71263364e-05
Iter: 321 loss: 1.70926069e-05
Iter: 322 loss: 1.7108594e-05
Iter: 323 loss: 1.70697e-05
Iter: 324 loss: 1.70377716e-05
Iter: 325 loss: 1.7222912e-05
Iter: 326 loss: 1.70332096e-05
Iter: 327 loss: 1.70024068e-05
Iter: 328 loss: 1.70270214e-05
Iter: 329 loss: 1.69835075e-05
Iter: 330 loss: 1.69519153e-05
Iter: 331 loss: 1.69575178e-05
Iter: 332 loss: 1.69282139e-05
Iter: 333 loss: 1.68922725e-05
Iter: 334 loss: 1.73695335e-05
Iter: 335 loss: 1.68923016e-05
Iter: 336 loss: 1.68629704e-05
Iter: 337 loss: 1.69066916e-05
Iter: 338 loss: 1.68487077e-05
Iter: 339 loss: 1.68186525e-05
Iter: 340 loss: 1.68243751e-05
Iter: 341 loss: 1.67963917e-05
Iter: 342 loss: 1.67564267e-05
Iter: 343 loss: 1.69632294e-05
Iter: 344 loss: 1.67502149e-05
Iter: 345 loss: 1.6715876e-05
Iter: 346 loss: 1.68326296e-05
Iter: 347 loss: 1.67064445e-05
Iter: 348 loss: 1.668205e-05
Iter: 349 loss: 1.70053863e-05
Iter: 350 loss: 1.66822847e-05
Iter: 351 loss: 1.66610316e-05
Iter: 352 loss: 1.66496829e-05
Iter: 353 loss: 1.66403042e-05
Iter: 354 loss: 1.6609225e-05
Iter: 355 loss: 1.66127611e-05
Iter: 356 loss: 1.65854908e-05
Iter: 357 loss: 1.65531201e-05
Iter: 358 loss: 1.67586331e-05
Iter: 359 loss: 1.65493057e-05
Iter: 360 loss: 1.65148867e-05
Iter: 361 loss: 1.66256141e-05
Iter: 362 loss: 1.65051861e-05
Iter: 363 loss: 1.64765188e-05
Iter: 364 loss: 1.64953635e-05
Iter: 365 loss: 1.64586272e-05
Iter: 366 loss: 1.64288867e-05
Iter: 367 loss: 1.65379388e-05
Iter: 368 loss: 1.64212943e-05
Iter: 369 loss: 1.63890909e-05
Iter: 370 loss: 1.64792546e-05
Iter: 371 loss: 1.63786899e-05
Iter: 372 loss: 1.63477252e-05
Iter: 373 loss: 1.63778677e-05
Iter: 374 loss: 1.63301811e-05
Iter: 375 loss: 1.63059667e-05
Iter: 376 loss: 1.66290447e-05
Iter: 377 loss: 1.63058357e-05
Iter: 378 loss: 1.62833858e-05
Iter: 379 loss: 1.62681536e-05
Iter: 380 loss: 1.6259999e-05
Iter: 381 loss: 1.6226717e-05
Iter: 382 loss: 1.63170989e-05
Iter: 383 loss: 1.62161796e-05
Iter: 384 loss: 1.61863645e-05
Iter: 385 loss: 1.63338118e-05
Iter: 386 loss: 1.61816643e-05
Iter: 387 loss: 1.61568205e-05
Iter: 388 loss: 1.64606608e-05
Iter: 389 loss: 1.61565749e-05
Iter: 390 loss: 1.61416247e-05
Iter: 391 loss: 1.61141143e-05
Iter: 392 loss: 1.67152612e-05
Iter: 393 loss: 1.61142088e-05
Iter: 394 loss: 1.60818345e-05
Iter: 395 loss: 1.62943397e-05
Iter: 396 loss: 1.60782674e-05
Iter: 397 loss: 1.60532109e-05
Iter: 398 loss: 1.60709715e-05
Iter: 399 loss: 1.60376876e-05
Iter: 400 loss: 1.60097698e-05
Iter: 401 loss: 1.62368924e-05
Iter: 402 loss: 1.60080053e-05
Iter: 403 loss: 1.59831307e-05
Iter: 404 loss: 1.60234886e-05
Iter: 405 loss: 1.59717274e-05
Iter: 406 loss: 1.59462652e-05
Iter: 407 loss: 1.59416304e-05
Iter: 408 loss: 1.59244537e-05
Iter: 409 loss: 1.58930343e-05
Iter: 410 loss: 1.60156451e-05
Iter: 411 loss: 1.58859348e-05
Iter: 412 loss: 1.58567564e-05
Iter: 413 loss: 1.60308555e-05
Iter: 414 loss: 1.58530183e-05
Iter: 415 loss: 1.58228486e-05
Iter: 416 loss: 1.58232378e-05
Iter: 417 loss: 1.57992908e-05
Iter: 418 loss: 1.57743307e-05
Iter: 419 loss: 1.60981326e-05
Iter: 420 loss: 1.57742525e-05
Iter: 421 loss: 1.57518334e-05
Iter: 422 loss: 1.57411705e-05
Iter: 423 loss: 1.57301947e-05
Iter: 424 loss: 1.56987244e-05
Iter: 425 loss: 1.58261537e-05
Iter: 426 loss: 1.56919305e-05
Iter: 427 loss: 1.56737187e-05
Iter: 428 loss: 1.56736787e-05
Iter: 429 loss: 1.5657617e-05
Iter: 430 loss: 1.56256392e-05
Iter: 431 loss: 1.62808756e-05
Iter: 432 loss: 1.56255701e-05
Iter: 433 loss: 1.55904654e-05
Iter: 434 loss: 1.5673244e-05
Iter: 435 loss: 1.55777161e-05
Iter: 436 loss: 1.55493944e-05
Iter: 437 loss: 1.56954502e-05
Iter: 438 loss: 1.55449197e-05
Iter: 439 loss: 1.55181697e-05
Iter: 440 loss: 1.56063106e-05
Iter: 441 loss: 1.55111757e-05
Iter: 442 loss: 1.54820227e-05
Iter: 443 loss: 1.55730395e-05
Iter: 444 loss: 1.54737409e-05
Iter: 445 loss: 1.54526133e-05
Iter: 446 loss: 1.55803755e-05
Iter: 447 loss: 1.5450325e-05
Iter: 448 loss: 1.54322224e-05
Iter: 449 loss: 1.539808e-05
Iter: 450 loss: 1.61446551e-05
Iter: 451 loss: 1.53977599e-05
Iter: 452 loss: 1.53589244e-05
Iter: 453 loss: 1.55764428e-05
Iter: 454 loss: 1.53531437e-05
Iter: 455 loss: 1.5324822e-05
Iter: 456 loss: 1.55214457e-05
Iter: 457 loss: 1.53219262e-05
Iter: 458 loss: 1.52932334e-05
Iter: 459 loss: 1.53459514e-05
Iter: 460 loss: 1.52810226e-05
Iter: 461 loss: 1.52561061e-05
Iter: 462 loss: 1.53377841e-05
Iter: 463 loss: 1.5249354e-05
Iter: 464 loss: 1.5225226e-05
Iter: 465 loss: 1.53185156e-05
Iter: 466 loss: 1.52194689e-05
Iter: 467 loss: 1.51976128e-05
Iter: 468 loss: 1.52656921e-05
Iter: 469 loss: 1.51907307e-05
Iter: 470 loss: 1.51685763e-05
Iter: 471 loss: 1.53027067e-05
Iter: 472 loss: 1.51656095e-05
Iter: 473 loss: 1.51487711e-05
Iter: 474 loss: 1.51365402e-05
Iter: 475 loss: 1.51306303e-05
Iter: 476 loss: 1.51058912e-05
Iter: 477 loss: 1.50751657e-05
Iter: 478 loss: 1.50727255e-05
Iter: 479 loss: 1.50427877e-05
Iter: 480 loss: 1.50422529e-05
Iter: 481 loss: 1.50213937e-05
Iter: 482 loss: 1.51047698e-05
Iter: 483 loss: 1.50169617e-05
Iter: 484 loss: 1.49930083e-05
Iter: 485 loss: 1.50068336e-05
Iter: 486 loss: 1.49772923e-05
Iter: 487 loss: 1.4953328e-05
Iter: 488 loss: 1.50286041e-05
Iter: 489 loss: 1.4946284e-05
Iter: 490 loss: 1.491899e-05
Iter: 491 loss: 1.49576044e-05
Iter: 492 loss: 1.49055504e-05
Iter: 493 loss: 1.48819436e-05
Iter: 494 loss: 1.48973249e-05
Iter: 495 loss: 1.48666259e-05
Iter: 496 loss: 1.48345498e-05
Iter: 497 loss: 1.5017984e-05
Iter: 498 loss: 1.48297759e-05
Iter: 499 loss: 1.48014715e-05
Iter: 500 loss: 1.4955659e-05
Iter: 501 loss: 1.47972623e-05
Iter: 502 loss: 1.47768751e-05
Iter: 503 loss: 1.47964884e-05
Iter: 504 loss: 1.47654036e-05
Iter: 505 loss: 1.47420542e-05
Iter: 506 loss: 1.49222287e-05
Iter: 507 loss: 1.47403734e-05
Iter: 508 loss: 1.47185074e-05
Iter: 509 loss: 1.47491701e-05
Iter: 510 loss: 1.47075498e-05
Iter: 511 loss: 1.46857346e-05
Iter: 512 loss: 1.47499823e-05
Iter: 513 loss: 1.46789016e-05
Iter: 514 loss: 1.46597722e-05
Iter: 515 loss: 1.466086e-05
Iter: 516 loss: 1.46447364e-05
Iter: 517 loss: 1.46153143e-05
Iter: 518 loss: 1.46193461e-05
Iter: 519 loss: 1.45932845e-05
Iter: 520 loss: 1.45640633e-05
Iter: 521 loss: 1.48299969e-05
Iter: 522 loss: 1.45628546e-05
Iter: 523 loss: 1.45419281e-05
Iter: 524 loss: 1.47581832e-05
Iter: 525 loss: 1.45414342e-05
Iter: 526 loss: 1.45253889e-05
Iter: 527 loss: 1.44995829e-05
Iter: 528 loss: 1.44992628e-05
Iter: 529 loss: 1.44683354e-05
Iter: 530 loss: 1.46354487e-05
Iter: 531 loss: 1.44635706e-05
Iter: 532 loss: 1.44412734e-05
Iter: 533 loss: 1.45570084e-05
Iter: 534 loss: 1.4437599e-05
Iter: 535 loss: 1.44144778e-05
Iter: 536 loss: 1.43945826e-05
Iter: 537 loss: 1.43881962e-05
Iter: 538 loss: 1.43623693e-05
Iter: 539 loss: 1.46805705e-05
Iter: 540 loss: 1.43620828e-05
Iter: 541 loss: 1.43399575e-05
Iter: 542 loss: 1.44182832e-05
Iter: 543 loss: 1.43341022e-05
Iter: 544 loss: 1.43168309e-05
Iter: 545 loss: 1.43802117e-05
Iter: 546 loss: 1.43122679e-05
Iter: 547 loss: 1.42938779e-05
Iter: 548 loss: 1.43648022e-05
Iter: 549 loss: 1.42894742e-05
Iter: 550 loss: 1.42709168e-05
Iter: 551 loss: 1.42516619e-05
Iter: 552 loss: 1.42481131e-05
Iter: 553 loss: 1.42223753e-05
Iter: 554 loss: 1.44004825e-05
Iter: 555 loss: 1.42201261e-05
Iter: 556 loss: 1.41979372e-05
Iter: 557 loss: 1.42184081e-05
Iter: 558 loss: 1.41859082e-05
Iter: 559 loss: 1.41611044e-05
Iter: 560 loss: 1.41863784e-05
Iter: 561 loss: 1.41474029e-05
Iter: 562 loss: 1.41205146e-05
Iter: 563 loss: 1.42172385e-05
Iter: 564 loss: 1.41137671e-05
Iter: 565 loss: 1.40903394e-05
Iter: 566 loss: 1.43300895e-05
Iter: 567 loss: 1.40898501e-05
Iter: 568 loss: 1.4069642e-05
Iter: 569 loss: 1.4077611e-05
Iter: 570 loss: 1.40555258e-05
Iter: 571 loss: 1.40329585e-05
Iter: 572 loss: 1.40322591e-05
Iter: 573 loss: 1.40146094e-05
Iter: 574 loss: 1.39891836e-05
Iter: 575 loss: 1.41941855e-05
Iter: 576 loss: 1.39879794e-05
Iter: 577 loss: 1.39666454e-05
Iter: 578 loss: 1.40390284e-05
Iter: 579 loss: 1.39608537e-05
Iter: 580 loss: 1.39413851e-05
Iter: 581 loss: 1.3945566e-05
Iter: 582 loss: 1.39271942e-05
Iter: 583 loss: 1.39038375e-05
Iter: 584 loss: 1.418789e-05
Iter: 585 loss: 1.39034082e-05
Iter: 586 loss: 1.38857786e-05
Iter: 587 loss: 1.3922273e-05
Iter: 588 loss: 1.38790756e-05
Iter: 589 loss: 1.38613905e-05
Iter: 590 loss: 1.39563017e-05
Iter: 591 loss: 1.38585874e-05
Iter: 592 loss: 1.38438827e-05
Iter: 593 loss: 1.38259702e-05
Iter: 594 loss: 1.38243795e-05
Iter: 595 loss: 1.37985671e-05
Iter: 596 loss: 1.38817077e-05
Iter: 597 loss: 1.3791223e-05
Iter: 598 loss: 1.37691677e-05
Iter: 599 loss: 1.39074118e-05
Iter: 600 loss: 1.37664456e-05
Iter: 601 loss: 1.37482721e-05
Iter: 602 loss: 1.37485977e-05
Iter: 603 loss: 1.37335192e-05
Iter: 604 loss: 1.37080806e-05
Iter: 605 loss: 1.3763306e-05
Iter: 606 loss: 1.36984563e-05
Iter: 607 loss: 1.36757899e-05
Iter: 608 loss: 1.38029063e-05
Iter: 609 loss: 1.36727185e-05
Iter: 610 loss: 1.36504386e-05
Iter: 611 loss: 1.37794977e-05
Iter: 612 loss: 1.36476137e-05
Iter: 613 loss: 1.36306189e-05
Iter: 614 loss: 1.36194994e-05
Iter: 615 loss: 1.3612761e-05
Iter: 616 loss: 1.35873e-05
Iter: 617 loss: 1.35928913e-05
Iter: 618 loss: 1.35685214e-05
Iter: 619 loss: 1.35410073e-05
Iter: 620 loss: 1.35410737e-05
Iter: 621 loss: 1.35231458e-05
Iter: 622 loss: 1.35387763e-05
Iter: 623 loss: 1.35122027e-05
Iter: 624 loss: 1.34884021e-05
Iter: 625 loss: 1.35741138e-05
Iter: 626 loss: 1.34820903e-05
Iter: 627 loss: 1.34616585e-05
Iter: 628 loss: 1.36191593e-05
Iter: 629 loss: 1.34605389e-05
Iter: 630 loss: 1.34437387e-05
Iter: 631 loss: 1.34727306e-05
Iter: 632 loss: 1.34364263e-05
Iter: 633 loss: 1.34186375e-05
Iter: 634 loss: 1.34761194e-05
Iter: 635 loss: 1.3413458e-05
Iter: 636 loss: 1.33979538e-05
Iter: 637 loss: 1.33727026e-05
Iter: 638 loss: 1.33725671e-05
Iter: 639 loss: 1.33486992e-05
Iter: 640 loss: 1.36897106e-05
Iter: 641 loss: 1.3348521e-05
Iter: 642 loss: 1.33281901e-05
Iter: 643 loss: 1.33260401e-05
Iter: 644 loss: 1.33111689e-05
Iter: 645 loss: 1.32854775e-05
Iter: 646 loss: 1.34419824e-05
Iter: 647 loss: 1.32819787e-05
Iter: 648 loss: 1.32652904e-05
Iter: 649 loss: 1.32436526e-05
Iter: 650 loss: 1.32421046e-05
Iter: 651 loss: 1.32288615e-05
Iter: 652 loss: 1.32239129e-05
Iter: 653 loss: 1.32107571e-05
Iter: 654 loss: 1.32079904e-05
Iter: 655 loss: 1.31986317e-05
Iter: 656 loss: 1.31817033e-05
Iter: 657 loss: 1.31700272e-05
Iter: 658 loss: 1.31637244e-05
Iter: 659 loss: 1.31314519e-05
Iter: 660 loss: 1.33082976e-05
Iter: 661 loss: 1.31269308e-05
Iter: 662 loss: 1.31075794e-05
Iter: 663 loss: 1.32897494e-05
Iter: 664 loss: 1.31064571e-05
Iter: 665 loss: 1.30938806e-05
Iter: 666 loss: 1.31085962e-05
Iter: 667 loss: 1.3087285e-05
Iter: 668 loss: 1.3068704e-05
Iter: 669 loss: 1.31300849e-05
Iter: 670 loss: 1.30634453e-05
Iter: 671 loss: 1.30457111e-05
Iter: 672 loss: 1.31080942e-05
Iter: 673 loss: 1.30406461e-05
Iter: 674 loss: 1.30255157e-05
Iter: 675 loss: 1.3059218e-05
Iter: 676 loss: 1.30198e-05
Iter: 677 loss: 1.30051394e-05
Iter: 678 loss: 1.29894906e-05
Iter: 679 loss: 1.29868267e-05
Iter: 680 loss: 1.29633818e-05
Iter: 681 loss: 1.31124252e-05
Iter: 682 loss: 1.2960727e-05
Iter: 683 loss: 1.29418668e-05
Iter: 684 loss: 1.3030326e-05
Iter: 685 loss: 1.29382961e-05
Iter: 686 loss: 1.29222171e-05
Iter: 687 loss: 1.29249293e-05
Iter: 688 loss: 1.29103355e-05
Iter: 689 loss: 1.288778e-05
Iter: 690 loss: 1.29222854e-05
Iter: 691 loss: 1.2877078e-05
Iter: 692 loss: 1.28592474e-05
Iter: 693 loss: 1.28593256e-05
Iter: 694 loss: 1.28429265e-05
Iter: 695 loss: 1.28335723e-05
Iter: 696 loss: 1.2826863e-05
Iter: 697 loss: 1.28062602e-05
Iter: 698 loss: 1.28203992e-05
Iter: 699 loss: 1.27934172e-05
Iter: 700 loss: 1.2770066e-05
Iter: 701 loss: 1.29399414e-05
Iter: 702 loss: 1.27683143e-05
Iter: 703 loss: 1.27520307e-05
Iter: 704 loss: 1.28671891e-05
Iter: 705 loss: 1.27506064e-05
Iter: 706 loss: 1.27363382e-05
Iter: 707 loss: 1.27633011e-05
Iter: 708 loss: 1.27302292e-05
Iter: 709 loss: 1.27139556e-05
Iter: 710 loss: 1.27928924e-05
Iter: 711 loss: 1.2710906e-05
Iter: 712 loss: 1.26990808e-05
Iter: 713 loss: 1.27013645e-05
Iter: 714 loss: 1.26902951e-05
Iter: 715 loss: 1.26716341e-05
Iter: 716 loss: 1.27077838e-05
Iter: 717 loss: 1.26642972e-05
Iter: 718 loss: 1.26470195e-05
Iter: 719 loss: 1.26610903e-05
Iter: 720 loss: 1.26368286e-05
Iter: 721 loss: 1.2616304e-05
Iter: 722 loss: 1.26980885e-05
Iter: 723 loss: 1.26120649e-05
Iter: 724 loss: 1.25946481e-05
Iter: 725 loss: 1.26716277e-05
Iter: 726 loss: 1.25912429e-05
Iter: 727 loss: 1.25732358e-05
Iter: 728 loss: 1.25742617e-05
Iter: 729 loss: 1.25588176e-05
Iter: 730 loss: 1.25372599e-05
Iter: 731 loss: 1.2623771e-05
Iter: 732 loss: 1.25325969e-05
Iter: 733 loss: 1.25135684e-05
Iter: 734 loss: 1.26304913e-05
Iter: 735 loss: 1.25113929e-05
Iter: 736 loss: 1.24900562e-05
Iter: 737 loss: 1.25036859e-05
Iter: 738 loss: 1.24766184e-05
Iter: 739 loss: 1.24591807e-05
Iter: 740 loss: 1.24619037e-05
Iter: 741 loss: 1.24460457e-05
Iter: 742 loss: 1.2426146e-05
Iter: 743 loss: 1.25880515e-05
Iter: 744 loss: 1.24251364e-05
Iter: 745 loss: 1.24084763e-05
Iter: 746 loss: 1.2536073e-05
Iter: 747 loss: 1.24075059e-05
Iter: 748 loss: 1.23940945e-05
Iter: 749 loss: 1.24119688e-05
Iter: 750 loss: 1.23871023e-05
Iter: 751 loss: 1.23717718e-05
Iter: 752 loss: 1.24096514e-05
Iter: 753 loss: 1.23663349e-05
Iter: 754 loss: 1.23508362e-05
Iter: 755 loss: 1.23562713e-05
Iter: 756 loss: 1.23400496e-05
Iter: 757 loss: 1.23210784e-05
Iter: 758 loss: 1.24014878e-05
Iter: 759 loss: 1.23173995e-05
Iter: 760 loss: 1.22980346e-05
Iter: 761 loss: 1.23014306e-05
Iter: 762 loss: 1.22833e-05
Iter: 763 loss: 1.22640813e-05
Iter: 764 loss: 1.23847985e-05
Iter: 765 loss: 1.22617839e-05
Iter: 766 loss: 1.22441261e-05
Iter: 767 loss: 1.22642887e-05
Iter: 768 loss: 1.22349957e-05
Iter: 769 loss: 1.22122765e-05
Iter: 770 loss: 1.23179325e-05
Iter: 771 loss: 1.22080091e-05
Iter: 772 loss: 1.21930861e-05
Iter: 773 loss: 1.22069778e-05
Iter: 774 loss: 1.21845551e-05
Iter: 775 loss: 1.21686007e-05
Iter: 776 loss: 1.23647069e-05
Iter: 777 loss: 1.21681787e-05
Iter: 778 loss: 1.21549283e-05
Iter: 779 loss: 1.21405219e-05
Iter: 780 loss: 1.21385583e-05
Iter: 781 loss: 1.21203311e-05
Iter: 782 loss: 1.21788034e-05
Iter: 783 loss: 1.21151761e-05
Iter: 784 loss: 1.20965724e-05
Iter: 785 loss: 1.21889043e-05
Iter: 786 loss: 1.20932636e-05
Iter: 787 loss: 1.20713903e-05
Iter: 788 loss: 1.21498033e-05
Iter: 789 loss: 1.20657151e-05
Iter: 790 loss: 1.20527229e-05
Iter: 791 loss: 1.20807508e-05
Iter: 792 loss: 1.20476361e-05
Iter: 793 loss: 1.20338682e-05
Iter: 794 loss: 1.20675631e-05
Iter: 795 loss: 1.20286932e-05
Iter: 796 loss: 1.20142749e-05
Iter: 797 loss: 1.20077311e-05
Iter: 798 loss: 1.20006189e-05
Iter: 799 loss: 1.19816323e-05
Iter: 800 loss: 1.21552366e-05
Iter: 801 loss: 1.19803972e-05
Iter: 802 loss: 1.19664119e-05
Iter: 803 loss: 1.19667202e-05
Iter: 804 loss: 1.19552751e-05
Iter: 805 loss: 1.19355018e-05
Iter: 806 loss: 1.20085024e-05
Iter: 807 loss: 1.19305341e-05
Iter: 808 loss: 1.19124907e-05
Iter: 809 loss: 1.19514116e-05
Iter: 810 loss: 1.19056458e-05
Iter: 811 loss: 1.18863245e-05
Iter: 812 loss: 1.2003371e-05
Iter: 813 loss: 1.18838561e-05
Iter: 814 loss: 1.18706294e-05
Iter: 815 loss: 1.1884018e-05
Iter: 816 loss: 1.18635126e-05
Iter: 817 loss: 1.18458229e-05
Iter: 818 loss: 1.19521274e-05
Iter: 819 loss: 1.18433063e-05
Iter: 820 loss: 1.18299395e-05
Iter: 821 loss: 1.18144817e-05
Iter: 822 loss: 1.18125135e-05
Iter: 823 loss: 1.17941681e-05
Iter: 824 loss: 1.19141332e-05
Iter: 825 loss: 1.17921591e-05
Iter: 826 loss: 1.17775653e-05
Iter: 827 loss: 1.19789138e-05
Iter: 828 loss: 1.17775053e-05
Iter: 829 loss: 1.17678346e-05
Iter: 830 loss: 1.17517156e-05
Iter: 831 loss: 1.17518739e-05
Iter: 832 loss: 1.17352911e-05
Iter: 833 loss: 1.18849093e-05
Iter: 834 loss: 1.17345317e-05
Iter: 835 loss: 1.1720892e-05
Iter: 836 loss: 1.17382679e-05
Iter: 837 loss: 1.17139007e-05
Iter: 838 loss: 1.16978399e-05
Iter: 839 loss: 1.16989777e-05
Iter: 840 loss: 1.16852043e-05
Iter: 841 loss: 1.16656447e-05
Iter: 842 loss: 1.17947193e-05
Iter: 843 loss: 1.16636566e-05
Iter: 844 loss: 1.16457677e-05
Iter: 845 loss: 1.1674646e-05
Iter: 846 loss: 1.16376168e-05
Iter: 847 loss: 1.16205201e-05
Iter: 848 loss: 1.16581286e-05
Iter: 849 loss: 1.16140982e-05
Iter: 850 loss: 1.15967596e-05
Iter: 851 loss: 1.16772317e-05
Iter: 852 loss: 1.15934417e-05
Iter: 853 loss: 1.15774974e-05
Iter: 854 loss: 1.16273395e-05
Iter: 855 loss: 1.15729526e-05
Iter: 856 loss: 1.15566836e-05
Iter: 857 loss: 1.16008741e-05
Iter: 858 loss: 1.1551273e-05
Iter: 859 loss: 1.15365783e-05
Iter: 860 loss: 1.16196934e-05
Iter: 861 loss: 1.15346229e-05
Iter: 862 loss: 1.15226358e-05
Iter: 863 loss: 1.15005105e-05
Iter: 864 loss: 1.19988908e-05
Iter: 865 loss: 1.15003331e-05
Iter: 866 loss: 1.14879313e-05
Iter: 867 loss: 1.1485783e-05
Iter: 868 loss: 1.14733357e-05
Iter: 869 loss: 1.1501189e-05
Iter: 870 loss: 1.14686391e-05
Iter: 871 loss: 1.14579507e-05
Iter: 872 loss: 1.14452923e-05
Iter: 873 loss: 1.14441445e-05
Iter: 874 loss: 1.14264012e-05
Iter: 875 loss: 1.15379289e-05
Iter: 876 loss: 1.14245395e-05
Iter: 877 loss: 1.14058494e-05
Iter: 878 loss: 1.14473087e-05
Iter: 879 loss: 1.13987189e-05
Iter: 880 loss: 1.13852939e-05
Iter: 881 loss: 1.13876031e-05
Iter: 882 loss: 1.13752649e-05
Iter: 883 loss: 1.13579745e-05
Iter: 884 loss: 1.14752929e-05
Iter: 885 loss: 1.13558826e-05
Iter: 886 loss: 1.13416208e-05
Iter: 887 loss: 1.13643437e-05
Iter: 888 loss: 1.13349543e-05
Iter: 889 loss: 1.1316195e-05
Iter: 890 loss: 1.13447568e-05
Iter: 891 loss: 1.13072856e-05
Iter: 892 loss: 1.12923262e-05
Iter: 893 loss: 1.13710676e-05
Iter: 894 loss: 1.12900671e-05
Iter: 895 loss: 1.12746548e-05
Iter: 896 loss: 1.13179167e-05
Iter: 897 loss: 1.12694097e-05
Iter: 898 loss: 1.12537e-05
Iter: 899 loss: 1.12980379e-05
Iter: 900 loss: 1.12486759e-05
Iter: 901 loss: 1.12343396e-05
Iter: 902 loss: 1.12838479e-05
Iter: 903 loss: 1.12303314e-05
Iter: 904 loss: 1.12160851e-05
Iter: 905 loss: 1.12102425e-05
Iter: 906 loss: 1.12026555e-05
Iter: 907 loss: 1.1191245e-05
Iter: 908 loss: 1.11906174e-05
Iter: 909 loss: 1.11792579e-05
Iter: 910 loss: 1.1169951e-05
Iter: 911 loss: 1.11665195e-05
Iter: 912 loss: 1.11516292e-05
Iter: 913 loss: 1.11513e-05
Iter: 914 loss: 1.11395966e-05
Iter: 915 loss: 1.11211275e-05
Iter: 916 loss: 1.13073493e-05
Iter: 917 loss: 1.11206809e-05
Iter: 918 loss: 1.11061172e-05
Iter: 919 loss: 1.11479558e-05
Iter: 920 loss: 1.11017871e-05
Iter: 921 loss: 1.10892288e-05
Iter: 922 loss: 1.1080263e-05
Iter: 923 loss: 1.10761257e-05
Iter: 924 loss: 1.10564897e-05
Iter: 925 loss: 1.11491463e-05
Iter: 926 loss: 1.10527035e-05
Iter: 927 loss: 1.10350393e-05
Iter: 928 loss: 1.11054796e-05
Iter: 929 loss: 1.10306601e-05
Iter: 930 loss: 1.10140354e-05
Iter: 931 loss: 1.10596047e-05
Iter: 932 loss: 1.10086239e-05
Iter: 933 loss: 1.09934681e-05
Iter: 934 loss: 1.1008503e-05
Iter: 935 loss: 1.09850398e-05
Iter: 936 loss: 1.09674384e-05
Iter: 937 loss: 1.11432128e-05
Iter: 938 loss: 1.09666089e-05
Iter: 939 loss: 1.09542125e-05
Iter: 940 loss: 1.0966789e-05
Iter: 941 loss: 1.09474713e-05
Iter: 942 loss: 1.09335924e-05
Iter: 943 loss: 1.09736748e-05
Iter: 944 loss: 1.09289385e-05
Iter: 945 loss: 1.0914533e-05
Iter: 946 loss: 1.09375742e-05
Iter: 947 loss: 1.09076536e-05
Iter: 948 loss: 1.08951508e-05
Iter: 949 loss: 1.10729507e-05
Iter: 950 loss: 1.08951172e-05
Iter: 951 loss: 1.08845688e-05
Iter: 952 loss: 1.0873061e-05
Iter: 953 loss: 1.08712375e-05
Iter: 954 loss: 1.08552404e-05
Iter: 955 loss: 1.08628283e-05
Iter: 956 loss: 1.08444929e-05
Iter: 957 loss: 1.08300483e-05
Iter: 958 loss: 1.10086276e-05
Iter: 959 loss: 1.08297181e-05
Iter: 960 loss: 1.08174481e-05
Iter: 961 loss: 1.08481472e-05
Iter: 962 loss: 1.08132481e-05
Iter: 963 loss: 1.08011327e-05
Iter: 964 loss: 1.07858486e-05
Iter: 965 loss: 1.07848255e-05
Iter: 966 loss: 1.07676769e-05
Iter: 967 loss: 1.09378825e-05
Iter: 968 loss: 1.07670458e-05
Iter: 969 loss: 1.07514697e-05
Iter: 970 loss: 1.07726919e-05
Iter: 971 loss: 1.07439646e-05
Iter: 972 loss: 1.07259093e-05
Iter: 973 loss: 1.0815842e-05
Iter: 974 loss: 1.07230208e-05
Iter: 975 loss: 1.07099822e-05
Iter: 976 loss: 1.07301703e-05
Iter: 977 loss: 1.07040451e-05
Iter: 978 loss: 1.06896487e-05
Iter: 979 loss: 1.07806354e-05
Iter: 980 loss: 1.06881271e-05
Iter: 981 loss: 1.06744219e-05
Iter: 982 loss: 1.06937587e-05
Iter: 983 loss: 1.06678217e-05
Iter: 984 loss: 1.06566995e-05
Iter: 985 loss: 1.06872612e-05
Iter: 986 loss: 1.06529524e-05
Iter: 987 loss: 1.06386815e-05
Iter: 988 loss: 1.06541565e-05
Iter: 989 loss: 1.06308271e-05
Iter: 990 loss: 1.06207026e-05
Iter: 991 loss: 1.06204243e-05
Iter: 992 loss: 1.06116513e-05
Iter: 993 loss: 1.06059524e-05
Iter: 994 loss: 1.06024017e-05
Iter: 995 loss: 1.05924555e-05
Iter: 996 loss: 1.05967902e-05
Iter: 997 loss: 1.05856379e-05
Iter: 998 loss: 1.05704185e-05
Iter: 999 loss: 1.06235902e-05
Iter: 1000 loss: 1.05661275e-05
Iter: 1001 loss: 1.05513109e-05
Iter: 1002 loss: 1.06384623e-05
Iter: 1003 loss: 1.05492454e-05
Iter: 1004 loss: 1.05394356e-05
Iter: 1005 loss: 1.0521635e-05
Iter: 1006 loss: 1.09567454e-05
Iter: 1007 loss: 1.05214876e-05
Iter: 1008 loss: 1.05029576e-05
Iter: 1009 loss: 1.06674852e-05
Iter: 1010 loss: 1.0502039e-05
Iter: 1011 loss: 1.04871815e-05
Iter: 1012 loss: 1.05705121e-05
Iter: 1013 loss: 1.04851961e-05
Iter: 1014 loss: 1.04724068e-05
Iter: 1015 loss: 1.04835763e-05
Iter: 1016 loss: 1.0464697e-05
Iter: 1017 loss: 1.04491464e-05
Iter: 1018 loss: 1.05071567e-05
Iter: 1019 loss: 1.04456039e-05
Iter: 1020 loss: 1.0432419e-05
Iter: 1021 loss: 1.05325635e-05
Iter: 1022 loss: 1.04313858e-05
Iter: 1023 loss: 1.04205783e-05
Iter: 1024 loss: 1.04170267e-05
Iter: 1025 loss: 1.04107239e-05
Iter: 1026 loss: 1.03984203e-05
Iter: 1027 loss: 1.04847468e-05
Iter: 1028 loss: 1.03973189e-05
Iter: 1029 loss: 1.03868151e-05
Iter: 1030 loss: 1.04106766e-05
Iter: 1031 loss: 1.03830107e-05
Iter: 1032 loss: 1.03709444e-05
Iter: 1033 loss: 1.04374776e-05
Iter: 1034 loss: 1.03691564e-05
Iter: 1035 loss: 1.03601196e-05
Iter: 1036 loss: 1.03598531e-05
Iter: 1037 loss: 1.03525672e-05
Iter: 1038 loss: 1.0340581e-05
Iter: 1039 loss: 1.03306629e-05
Iter: 1040 loss: 1.03272605e-05
Iter: 1041 loss: 1.03148295e-05
Iter: 1042 loss: 1.03145958e-05
Iter: 1043 loss: 1.03034836e-05
Iter: 1044 loss: 1.03130524e-05
Iter: 1045 loss: 1.02970844e-05
Iter: 1046 loss: 1.02837621e-05
Iter: 1047 loss: 1.02790509e-05
Iter: 1048 loss: 1.02720924e-05
Iter: 1049 loss: 1.02548747e-05
Iter: 1050 loss: 1.0350388e-05
Iter: 1051 loss: 1.02526938e-05
Iter: 1052 loss: 1.02390813e-05
Iter: 1053 loss: 1.02965078e-05
Iter: 1054 loss: 1.02361228e-05
Iter: 1055 loss: 1.02211688e-05
Iter: 1056 loss: 1.02461754e-05
Iter: 1057 loss: 1.02144813e-05
Iter: 1058 loss: 1.02000486e-05
Iter: 1059 loss: 1.026671e-05
Iter: 1060 loss: 1.0197642e-05
Iter: 1061 loss: 1.01881305e-05
Iter: 1062 loss: 1.02676649e-05
Iter: 1063 loss: 1.01875066e-05
Iter: 1064 loss: 1.01785135e-05
Iter: 1065 loss: 1.01664054e-05
Iter: 1066 loss: 1.01656569e-05
Iter: 1067 loss: 1.01499991e-05
Iter: 1068 loss: 1.02378035e-05
Iter: 1069 loss: 1.01474252e-05
Iter: 1070 loss: 1.01353144e-05
Iter: 1071 loss: 1.01813566e-05
Iter: 1072 loss: 1.01324576e-05
Iter: 1073 loss: 1.0121933e-05
Iter: 1074 loss: 1.01421347e-05
Iter: 1075 loss: 1.01178248e-05
Iter: 1076 loss: 1.01048499e-05
Iter: 1077 loss: 1.02000067e-05
Iter: 1078 loss: 1.01039732e-05
Iter: 1079 loss: 1.00936868e-05
Iter: 1080 loss: 1.00867792e-05
Iter: 1081 loss: 1.00830712e-05
Iter: 1082 loss: 1.00709667e-05
Iter: 1083 loss: 1.01015012e-05
Iter: 1084 loss: 1.00667812e-05
Iter: 1085 loss: 1.00530933e-05
Iter: 1086 loss: 1.01325768e-05
Iter: 1087 loss: 1.00512134e-05
Iter: 1088 loss: 1.0041118e-05
Iter: 1089 loss: 1.0027341e-05
Iter: 1090 loss: 1.00268835e-05
Iter: 1091 loss: 1.00096404e-05
Iter: 1092 loss: 1.0128997e-05
Iter: 1093 loss: 1.00081907e-05
Iter: 1094 loss: 9.99538406e-06
Iter: 1095 loss: 1.00129455e-05
Iter: 1096 loss: 9.98878932e-06
Iter: 1097 loss: 9.9747931e-06
Iter: 1098 loss: 1.01086371e-05
Iter: 1099 loss: 9.97421466e-06
Iter: 1100 loss: 9.96429844e-06
Iter: 1101 loss: 9.9638537e-06
Iter: 1102 loss: 9.95605e-06
Iter: 1103 loss: 9.94390757e-06
Iter: 1104 loss: 1.00511115e-05
Iter: 1105 loss: 9.94314723e-06
Iter: 1106 loss: 9.9324634e-06
Iter: 1107 loss: 9.94990114e-06
Iter: 1108 loss: 9.92769128e-06
Iter: 1109 loss: 9.91568595e-06
Iter: 1110 loss: 9.92391415e-06
Iter: 1111 loss: 9.90794615e-06
Iter: 1112 loss: 9.89594355e-06
Iter: 1113 loss: 9.95985101e-06
Iter: 1114 loss: 9.89394903e-06
Iter: 1115 loss: 9.88193551e-06
Iter: 1116 loss: 9.89106229e-06
Iter: 1117 loss: 9.87451767e-06
Iter: 1118 loss: 9.86222767e-06
Iter: 1119 loss: 9.9271856e-06
Iter: 1120 loss: 9.86047507e-06
Iter: 1121 loss: 9.8478431e-06
Iter: 1122 loss: 9.92854e-06
Iter: 1123 loss: 9.84620601e-06
Iter: 1124 loss: 9.83761493e-06
Iter: 1125 loss: 9.82897291e-06
Iter: 1126 loss: 9.82724123e-06
Iter: 1127 loss: 9.81358244e-06
Iter: 1128 loss: 9.94068432e-06
Iter: 1129 loss: 9.81287667e-06
Iter: 1130 loss: 9.80362347e-06
Iter: 1131 loss: 9.78841581e-06
Iter: 1132 loss: 9.78837852e-06
Iter: 1133 loss: 9.77196578e-06
Iter: 1134 loss: 9.89118871e-06
Iter: 1135 loss: 9.77034688e-06
Iter: 1136 loss: 9.75857256e-06
Iter: 1137 loss: 9.77178661e-06
Iter: 1138 loss: 9.75232797e-06
Iter: 1139 loss: 9.73848e-06
Iter: 1140 loss: 9.84103281e-06
Iter: 1141 loss: 9.73735769e-06
Iter: 1142 loss: 9.72612179e-06
Iter: 1143 loss: 9.75400781e-06
Iter: 1144 loss: 9.72219732e-06
Iter: 1145 loss: 9.71104055e-06
Iter: 1146 loss: 9.71837471e-06
Iter: 1147 loss: 9.70417204e-06
Iter: 1148 loss: 9.6932672e-06
Iter: 1149 loss: 9.81497215e-06
Iter: 1150 loss: 9.69310349e-06
Iter: 1151 loss: 9.68337372e-06
Iter: 1152 loss: 9.69270877e-06
Iter: 1153 loss: 9.6779695e-06
Iter: 1154 loss: 9.66603147e-06
Iter: 1155 loss: 9.68425411e-06
Iter: 1156 loss: 9.66031257e-06
Iter: 1157 loss: 9.64697e-06
Iter: 1158 loss: 9.69420944e-06
Iter: 1159 loss: 9.64371247e-06
Iter: 1160 loss: 9.63310413e-06
Iter: 1161 loss: 9.71256668e-06
Iter: 1162 loss: 9.63244293e-06
Iter: 1163 loss: 9.6230433e-06
Iter: 1164 loss: 9.64566334e-06
Iter: 1165 loss: 9.61982732e-06
Iter: 1166 loss: 9.61108344e-06
Iter: 1167 loss: 9.59827139e-06
Iter: 1168 loss: 9.59796307e-06
Iter: 1169 loss: 9.58776127e-06
Iter: 1170 loss: 9.58778674e-06
Iter: 1171 loss: 9.57798329e-06
Iter: 1172 loss: 9.57980319e-06
Iter: 1173 loss: 9.57068278e-06
Iter: 1174 loss: 9.55794258e-06
Iter: 1175 loss: 9.55259384e-06
Iter: 1176 loss: 9.54617462e-06
Iter: 1177 loss: 9.53052e-06
Iter: 1178 loss: 9.65447e-06
Iter: 1179 loss: 9.5296e-06
Iter: 1180 loss: 9.51721904e-06
Iter: 1181 loss: 9.55617e-06
Iter: 1182 loss: 9.51344555e-06
Iter: 1183 loss: 9.50042522e-06
Iter: 1184 loss: 9.54887e-06
Iter: 1185 loss: 9.49737478e-06
Iter: 1186 loss: 9.48699744e-06
Iter: 1187 loss: 9.49988862e-06
Iter: 1188 loss: 9.4815241e-06
Iter: 1189 loss: 9.4688321e-06
Iter: 1190 loss: 9.50571302e-06
Iter: 1191 loss: 9.46490491e-06
Iter: 1192 loss: 9.45262582e-06
Iter: 1193 loss: 9.55757e-06
Iter: 1194 loss: 9.45211741e-06
Iter: 1195 loss: 9.44388557e-06
Iter: 1196 loss: 9.44484873e-06
Iter: 1197 loss: 9.43747818e-06
Iter: 1198 loss: 9.42508177e-06
Iter: 1199 loss: 9.46565524e-06
Iter: 1200 loss: 9.42208317e-06
Iter: 1201 loss: 9.4117695e-06
Iter: 1202 loss: 9.45703505e-06
Iter: 1203 loss: 9.40986592e-06
Iter: 1204 loss: 9.39969232e-06
Iter: 1205 loss: 9.44906697e-06
Iter: 1206 loss: 9.39804613e-06
Iter: 1207 loss: 9.38967e-06
Iter: 1208 loss: 9.38124685e-06
Iter: 1209 loss: 9.3797089e-06
Iter: 1210 loss: 9.36748165e-06
Iter: 1211 loss: 9.41428607e-06
Iter: 1212 loss: 9.36461583e-06
Iter: 1213 loss: 9.35318167e-06
Iter: 1214 loss: 9.43705e-06
Iter: 1215 loss: 9.35206481e-06
Iter: 1216 loss: 9.34398122e-06
Iter: 1217 loss: 9.33281626e-06
Iter: 1218 loss: 9.3323124e-06
Iter: 1219 loss: 9.31859722e-06
Iter: 1220 loss: 9.39176607e-06
Iter: 1221 loss: 9.31628711e-06
Iter: 1222 loss: 9.30435908e-06
Iter: 1223 loss: 9.31656814e-06
Iter: 1224 loss: 9.29731232e-06
Iter: 1225 loss: 9.28645932e-06
Iter: 1226 loss: 9.4574616e-06
Iter: 1227 loss: 9.28631925e-06
Iter: 1228 loss: 9.2771952e-06
Iter: 1229 loss: 9.26447046e-06
Iter: 1230 loss: 9.26377925e-06
Iter: 1231 loss: 9.24974483e-06
Iter: 1232 loss: 9.38987068e-06
Iter: 1233 loss: 9.24918822e-06
Iter: 1234 loss: 9.23958e-06
Iter: 1235 loss: 9.2594255e-06
Iter: 1236 loss: 9.23563e-06
Iter: 1237 loss: 9.22433173e-06
Iter: 1238 loss: 9.30177157e-06
Iter: 1239 loss: 9.22365052e-06
Iter: 1240 loss: 9.214e-06
Iter: 1241 loss: 9.24060896e-06
Iter: 1242 loss: 9.21080755e-06
Iter: 1243 loss: 9.20189e-06
Iter: 1244 loss: 9.21284e-06
Iter: 1245 loss: 9.19737249e-06
Iter: 1246 loss: 9.18996193e-06
Iter: 1247 loss: 9.22518575e-06
Iter: 1248 loss: 9.18866135e-06
Iter: 1249 loss: 9.17935e-06
Iter: 1250 loss: 9.17065063e-06
Iter: 1251 loss: 9.16860336e-06
Iter: 1252 loss: 9.15715e-06
Iter: 1253 loss: 9.19024569e-06
Iter: 1254 loss: 9.15367582e-06
Iter: 1255 loss: 9.14202246e-06
Iter: 1256 loss: 9.20377e-06
Iter: 1257 loss: 9.14033262e-06
Iter: 1258 loss: 9.12829455e-06
Iter: 1259 loss: 9.15309829e-06
Iter: 1260 loss: 9.1235288e-06
Iter: 1261 loss: 9.11463576e-06
Iter: 1262 loss: 9.12055657e-06
Iter: 1263 loss: 9.10904328e-06
Iter: 1264 loss: 9.09652681e-06
Iter: 1265 loss: 9.10573181e-06
Iter: 1266 loss: 9.08878e-06
Iter: 1267 loss: 9.07500907e-06
Iter: 1268 loss: 9.19545892e-06
Iter: 1269 loss: 9.07468e-06
Iter: 1270 loss: 9.06447349e-06
Iter: 1271 loss: 9.10826566e-06
Iter: 1272 loss: 9.06234345e-06
Iter: 1273 loss: 9.05317393e-06
Iter: 1274 loss: 9.05377874e-06
Iter: 1275 loss: 9.04641274e-06
Iter: 1276 loss: 9.03591899e-06
Iter: 1277 loss: 9.16493809e-06
Iter: 1278 loss: 9.03583805e-06
Iter: 1279 loss: 9.02700322e-06
Iter: 1280 loss: 9.05512934e-06
Iter: 1281 loss: 9.02472129e-06
Iter: 1282 loss: 9.01828571e-06
Iter: 1283 loss: 9.01486055e-06
Iter: 1284 loss: 9.01174371e-06
Iter: 1285 loss: 9.0014e-06
Iter: 1286 loss: 9.04124136e-06
Iter: 1287 loss: 8.9988589e-06
Iter: 1288 loss: 8.98961571e-06
Iter: 1289 loss: 8.99227416e-06
Iter: 1290 loss: 8.98302824e-06
Iter: 1291 loss: 8.97292648e-06
Iter: 1292 loss: 8.97293103e-06
Iter: 1293 loss: 8.96634447e-06
Iter: 1294 loss: 8.95736503e-06
Iter: 1295 loss: 8.95692119e-06
Iter: 1296 loss: 8.94362529e-06
Iter: 1297 loss: 8.97118298e-06
Iter: 1298 loss: 8.93832384e-06
Iter: 1299 loss: 8.92865501e-06
Iter: 1300 loss: 9.03284308e-06
Iter: 1301 loss: 8.92854769e-06
Iter: 1302 loss: 8.91920172e-06
Iter: 1303 loss: 8.93091874e-06
Iter: 1304 loss: 8.91444142e-06
Iter: 1305 loss: 8.90459614e-06
Iter: 1306 loss: 8.9047262e-06
Iter: 1307 loss: 8.89665e-06
Iter: 1308 loss: 8.88545492e-06
Iter: 1309 loss: 8.93785364e-06
Iter: 1310 loss: 8.88331488e-06
Iter: 1311 loss: 8.87208535e-06
Iter: 1312 loss: 8.91850868e-06
Iter: 1313 loss: 8.8696579e-06
Iter: 1314 loss: 8.86035e-06
Iter: 1315 loss: 8.9291625e-06
Iter: 1316 loss: 8.85961708e-06
Iter: 1317 loss: 8.85168083e-06
Iter: 1318 loss: 8.87340866e-06
Iter: 1319 loss: 8.84907604e-06
Iter: 1320 loss: 8.84158726e-06
Iter: 1321 loss: 8.84077872e-06
Iter: 1322 loss: 8.83523808e-06
Iter: 1323 loss: 8.82479162e-06
Iter: 1324 loss: 8.8173656e-06
Iter: 1325 loss: 8.81370397e-06
Iter: 1326 loss: 8.80246535e-06
Iter: 1327 loss: 8.80223433e-06
Iter: 1328 loss: 8.7943572e-06
Iter: 1329 loss: 8.78422361e-06
Iter: 1330 loss: 8.78364153e-06
Iter: 1331 loss: 8.7727858e-06
Iter: 1332 loss: 8.88673e-06
Iter: 1333 loss: 8.77262755e-06
Iter: 1334 loss: 8.76211288e-06
Iter: 1335 loss: 8.79365416e-06
Iter: 1336 loss: 8.75881051e-06
Iter: 1337 loss: 8.74933176e-06
Iter: 1338 loss: 8.75068e-06
Iter: 1339 loss: 8.74177204e-06
Iter: 1340 loss: 8.73086265e-06
Iter: 1341 loss: 8.75457499e-06
Iter: 1342 loss: 8.7269309e-06
Iter: 1343 loss: 8.71670818e-06
Iter: 1344 loss: 8.81541564e-06
Iter: 1345 loss: 8.71614247e-06
Iter: 1346 loss: 8.70714757e-06
Iter: 1347 loss: 8.71243628e-06
Iter: 1348 loss: 8.701365e-06
Iter: 1349 loss: 8.69208e-06
Iter: 1350 loss: 8.7043145e-06
Iter: 1351 loss: 8.68757e-06
Iter: 1352 loss: 8.67835843e-06
Iter: 1353 loss: 8.80798143e-06
Iter: 1354 loss: 8.67824383e-06
Iter: 1355 loss: 8.67054223e-06
Iter: 1356 loss: 8.67542e-06
Iter: 1357 loss: 8.66550909e-06
Iter: 1358 loss: 8.65757829e-06
Iter: 1359 loss: 8.68331881e-06
Iter: 1360 loss: 8.65537186e-06
Iter: 1361 loss: 8.64804133e-06
Iter: 1362 loss: 8.64751382e-06
Iter: 1363 loss: 8.64201502e-06
Iter: 1364 loss: 8.63021887e-06
Iter: 1365 loss: 8.64674257e-06
Iter: 1366 loss: 8.62420347e-06
Iter: 1367 loss: 8.61385342e-06
Iter: 1368 loss: 8.67642848e-06
Iter: 1369 loss: 8.61262379e-06
Iter: 1370 loss: 8.6022319e-06
Iter: 1371 loss: 8.61905937e-06
Iter: 1372 loss: 8.59757711e-06
Iter: 1373 loss: 8.58631756e-06
Iter: 1374 loss: 8.58841668e-06
Iter: 1375 loss: 8.57816849e-06
Iter: 1376 loss: 8.56458519e-06
Iter: 1377 loss: 8.61591252e-06
Iter: 1378 loss: 8.56151655e-06
Iter: 1379 loss: 8.55061626e-06
Iter: 1380 loss: 8.66565279e-06
Iter: 1381 loss: 8.5504289e-06
Iter: 1382 loss: 8.54200334e-06
Iter: 1383 loss: 8.57759369e-06
Iter: 1384 loss: 8.54015798e-06
Iter: 1385 loss: 8.53358779e-06
Iter: 1386 loss: 8.52759331e-06
Iter: 1387 loss: 8.52619723e-06
Iter: 1388 loss: 8.51635923e-06
Iter: 1389 loss: 8.66296341e-06
Iter: 1390 loss: 8.51622372e-06
Iter: 1391 loss: 8.51012283e-06
Iter: 1392 loss: 8.51604273e-06
Iter: 1393 loss: 8.50654578e-06
Iter: 1394 loss: 8.49840762e-06
Iter: 1395 loss: 8.53135134e-06
Iter: 1396 loss: 8.4965759e-06
Iter: 1397 loss: 8.48878699e-06
Iter: 1398 loss: 8.48536729e-06
Iter: 1399 loss: 8.48133095e-06
Iter: 1400 loss: 8.47101e-06
Iter: 1401 loss: 8.5014708e-06
Iter: 1402 loss: 8.46771218e-06
Iter: 1403 loss: 8.45803515e-06
Iter: 1404 loss: 8.50867673e-06
Iter: 1405 loss: 8.45656905e-06
Iter: 1406 loss: 8.44880196e-06
Iter: 1407 loss: 8.44507304e-06
Iter: 1408 loss: 8.44148508e-06
Iter: 1409 loss: 8.43046564e-06
Iter: 1410 loss: 8.49247499e-06
Iter: 1411 loss: 8.42884674e-06
Iter: 1412 loss: 8.4190915e-06
Iter: 1413 loss: 8.45652903e-06
Iter: 1414 loss: 8.41717065e-06
Iter: 1415 loss: 8.40873781e-06
Iter: 1416 loss: 8.41489418e-06
Iter: 1417 loss: 8.40336907e-06
Iter: 1418 loss: 8.39264067e-06
Iter: 1419 loss: 8.401581e-06
Iter: 1420 loss: 8.38641154e-06
Iter: 1421 loss: 8.37448169e-06
Iter: 1422 loss: 8.46878083e-06
Iter: 1423 loss: 8.37365769e-06
Iter: 1424 loss: 8.3653249e-06
Iter: 1425 loss: 8.43947873e-06
Iter: 1426 loss: 8.36490835e-06
Iter: 1427 loss: 8.3582454e-06
Iter: 1428 loss: 8.35207811e-06
Iter: 1429 loss: 8.35035917e-06
Iter: 1430 loss: 8.3411087e-06
Iter: 1431 loss: 8.4211224e-06
Iter: 1432 loss: 8.34077764e-06
Iter: 1433 loss: 8.33167451e-06
Iter: 1434 loss: 8.34960065e-06
Iter: 1435 loss: 8.32813748e-06
Iter: 1436 loss: 8.32186652e-06
Iter: 1437 loss: 8.36823438e-06
Iter: 1438 loss: 8.3213381e-06
Iter: 1439 loss: 8.31465877e-06
Iter: 1440 loss: 8.31290708e-06
Iter: 1441 loss: 8.308627e-06
Iter: 1442 loss: 8.29916462e-06
Iter: 1443 loss: 8.31162924e-06
Iter: 1444 loss: 8.29443707e-06
Iter: 1445 loss: 8.28598604e-06
Iter: 1446 loss: 8.3351315e-06
Iter: 1447 loss: 8.28493194e-06
Iter: 1448 loss: 8.27693111e-06
Iter: 1449 loss: 8.27958502e-06
Iter: 1450 loss: 8.27127224e-06
Iter: 1451 loss: 8.26149517e-06
Iter: 1452 loss: 8.27002441e-06
Iter: 1453 loss: 8.25591633e-06
Iter: 1454 loss: 8.2440547e-06
Iter: 1455 loss: 8.3281293e-06
Iter: 1456 loss: 8.24316794e-06
Iter: 1457 loss: 8.23326627e-06
Iter: 1458 loss: 8.2513061e-06
Iter: 1459 loss: 8.22896254e-06
Iter: 1460 loss: 8.21985668e-06
Iter: 1461 loss: 8.228767e-06
Iter: 1462 loss: 8.21474441e-06
Iter: 1463 loss: 8.20439709e-06
Iter: 1464 loss: 8.23859e-06
Iter: 1465 loss: 8.20182595e-06
Iter: 1466 loss: 8.19201341e-06
Iter: 1467 loss: 8.23540631e-06
Iter: 1468 loss: 8.1901253e-06
Iter: 1469 loss: 8.18034459e-06
Iter: 1470 loss: 8.24879226e-06
Iter: 1471 loss: 8.17959153e-06
Iter: 1472 loss: 8.17346245e-06
Iter: 1473 loss: 8.1916578e-06
Iter: 1474 loss: 8.17160435e-06
Iter: 1475 loss: 8.16413558e-06
Iter: 1476 loss: 8.17613545e-06
Iter: 1477 loss: 8.16052398e-06
Iter: 1478 loss: 8.153007e-06
Iter: 1479 loss: 8.15017302e-06
Iter: 1480 loss: 8.14635678e-06
Iter: 1481 loss: 8.13509632e-06
Iter: 1482 loss: 8.18152876e-06
Iter: 1483 loss: 8.13307361e-06
Iter: 1484 loss: 8.12427879e-06
Iter: 1485 loss: 8.19280831e-06
Iter: 1486 loss: 8.12354756e-06
Iter: 1487 loss: 8.11721475e-06
Iter: 1488 loss: 8.1151793e-06
Iter: 1489 loss: 8.11137579e-06
Iter: 1490 loss: 8.10002621e-06
Iter: 1491 loss: 8.14286068e-06
Iter: 1492 loss: 8.09718949e-06
Iter: 1493 loss: 8.08919867e-06
Iter: 1494 loss: 8.09490666e-06
Iter: 1495 loss: 8.08418554e-06
Iter: 1496 loss: 8.07473e-06
Iter: 1497 loss: 8.09627818e-06
Iter: 1498 loss: 8.07088e-06
Iter: 1499 loss: 8.06034586e-06
Iter: 1500 loss: 8.12408507e-06
Iter: 1501 loss: 8.05929449e-06
Iter: 1502 loss: 8.05124273e-06
Iter: 1503 loss: 8.04804313e-06
Iter: 1504 loss: 8.04382e-06
Iter: 1505 loss: 8.03223884e-06
Iter: 1506 loss: 8.07778633e-06
Iter: 1507 loss: 8.02963223e-06
Iter: 1508 loss: 8.0195714e-06
Iter: 1509 loss: 8.05125637e-06
Iter: 1510 loss: 8.01668648e-06
Iter: 1511 loss: 8.00918315e-06
Iter: 1512 loss: 8.00906309e-06
Iter: 1513 loss: 8.00459566e-06
Iter: 1514 loss: 7.99634927e-06
Iter: 1515 loss: 8.16758075e-06
Iter: 1516 loss: 7.99635654e-06
Iter: 1517 loss: 7.9867e-06
Iter: 1518 loss: 8.08544155e-06
Iter: 1519 loss: 7.98643214e-06
Iter: 1520 loss: 7.98018755e-06
Iter: 1521 loss: 7.97388111e-06
Iter: 1522 loss: 7.97271787e-06
Iter: 1523 loss: 7.96188124e-06
Iter: 1524 loss: 8.01669376e-06
Iter: 1525 loss: 7.9598185e-06
Iter: 1526 loss: 7.95122833e-06
Iter: 1527 loss: 7.97827488e-06
Iter: 1528 loss: 7.94862e-06
Iter: 1529 loss: 7.93892104e-06
Iter: 1530 loss: 7.95421056e-06
Iter: 1531 loss: 7.93433355e-06
Iter: 1532 loss: 7.92610354e-06
Iter: 1533 loss: 7.94712e-06
Iter: 1534 loss: 7.92362425e-06
Iter: 1535 loss: 7.91564344e-06
Iter: 1536 loss: 7.98449128e-06
Iter: 1537 loss: 7.91534239e-06
Iter: 1538 loss: 7.90861395e-06
Iter: 1539 loss: 7.90563354e-06
Iter: 1540 loss: 7.90224658e-06
Iter: 1541 loss: 7.89133e-06
Iter: 1542 loss: 7.93688559e-06
Iter: 1543 loss: 7.88879333e-06
Iter: 1544 loss: 7.88048601e-06
Iter: 1545 loss: 7.8883e-06
Iter: 1546 loss: 7.87545468e-06
Iter: 1547 loss: 7.86526653e-06
Iter: 1548 loss: 7.87873614e-06
Iter: 1549 loss: 7.86009605e-06
Iter: 1550 loss: 7.8509529e-06
Iter: 1551 loss: 7.9041547e-06
Iter: 1552 loss: 7.84993608e-06
Iter: 1553 loss: 7.84063286e-06
Iter: 1554 loss: 7.90581362e-06
Iter: 1555 loss: 7.83943142e-06
Iter: 1556 loss: 7.8326957e-06
Iter: 1557 loss: 7.83872565e-06
Iter: 1558 loss: 7.82878124e-06
Iter: 1559 loss: 7.8215844e-06
Iter: 1560 loss: 7.85531e-06
Iter: 1561 loss: 7.82049119e-06
Iter: 1562 loss: 7.81378549e-06
Iter: 1563 loss: 7.80537084e-06
Iter: 1564 loss: 7.80469236e-06
Iter: 1565 loss: 7.79415e-06
Iter: 1566 loss: 7.86935925e-06
Iter: 1567 loss: 7.79333641e-06
Iter: 1568 loss: 7.7853e-06
Iter: 1569 loss: 7.81511699e-06
Iter: 1570 loss: 7.78316644e-06
Iter: 1571 loss: 7.7747909e-06
Iter: 1572 loss: 7.78041431e-06
Iter: 1573 loss: 7.76951674e-06
Iter: 1574 loss: 7.76089746e-06
Iter: 1575 loss: 7.79529182e-06
Iter: 1576 loss: 7.75892659e-06
Iter: 1577 loss: 7.75146145e-06
Iter: 1578 loss: 7.81289054e-06
Iter: 1579 loss: 7.751054e-06
Iter: 1580 loss: 7.74449e-06
Iter: 1581 loss: 7.74305954e-06
Iter: 1582 loss: 7.73882402e-06
Iter: 1583 loss: 7.72936437e-06
Iter: 1584 loss: 7.76655361e-06
Iter: 1585 loss: 7.72722524e-06
Iter: 1586 loss: 7.71979e-06
Iter: 1587 loss: 7.7366567e-06
Iter: 1588 loss: 7.71694e-06
Iter: 1589 loss: 7.70826318e-06
Iter: 1590 loss: 7.70220504e-06
Iter: 1591 loss: 7.69910275e-06
Iter: 1592 loss: 7.69226699e-06
Iter: 1593 loss: 7.6919705e-06
Iter: 1594 loss: 7.68474092e-06
Iter: 1595 loss: 7.69704366e-06
Iter: 1596 loss: 7.68163591e-06
Iter: 1597 loss: 7.6762044e-06
Iter: 1598 loss: 7.67239e-06
Iter: 1599 loss: 7.67043366e-06
Iter: 1600 loss: 7.66298672e-06
Iter: 1601 loss: 7.72177918e-06
Iter: 1602 loss: 7.66244e-06
Iter: 1603 loss: 7.65540062e-06
Iter: 1604 loss: 7.66710309e-06
Iter: 1605 loss: 7.6522756e-06
Iter: 1606 loss: 7.64426841e-06
Iter: 1607 loss: 7.6514807e-06
Iter: 1608 loss: 7.63995558e-06
Iter: 1609 loss: 7.63152639e-06
Iter: 1610 loss: 7.66499397e-06
Iter: 1611 loss: 7.62943091e-06
Iter: 1612 loss: 7.62093305e-06
Iter: 1613 loss: 7.65502591e-06
Iter: 1614 loss: 7.61901356e-06
Iter: 1615 loss: 7.61281444e-06
Iter: 1616 loss: 7.61185265e-06
Iter: 1617 loss: 7.6078295e-06
Iter: 1618 loss: 7.59749219e-06
Iter: 1619 loss: 7.6168576e-06
Iter: 1620 loss: 7.59312388e-06
Iter: 1621 loss: 7.58307124e-06
Iter: 1622 loss: 7.6729757e-06
Iter: 1623 loss: 7.58234546e-06
Iter: 1624 loss: 7.5757639e-06
Iter: 1625 loss: 7.58047099e-06
Iter: 1626 loss: 7.57183216e-06
Iter: 1627 loss: 7.56419058e-06
Iter: 1628 loss: 7.60334751e-06
Iter: 1629 loss: 7.56296322e-06
Iter: 1630 loss: 7.55539077e-06
Iter: 1631 loss: 7.61000501e-06
Iter: 1632 loss: 7.55488463e-06
Iter: 1633 loss: 7.5505568e-06
Iter: 1634 loss: 7.54734219e-06
Iter: 1635 loss: 7.54602297e-06
Iter: 1636 loss: 7.53893619e-06
Iter: 1637 loss: 7.58857323e-06
Iter: 1638 loss: 7.53819404e-06
Iter: 1639 loss: 7.53275481e-06
Iter: 1640 loss: 7.5271505e-06
Iter: 1641 loss: 7.52603592e-06
Iter: 1642 loss: 7.51657808e-06
Iter: 1643 loss: 7.53825179e-06
Iter: 1644 loss: 7.5131943e-06
Iter: 1645 loss: 7.50487834e-06
Iter: 1646 loss: 7.57969519e-06
Iter: 1647 loss: 7.50436084e-06
Iter: 1648 loss: 7.49699257e-06
Iter: 1649 loss: 7.50517711e-06
Iter: 1650 loss: 7.49296305e-06
Iter: 1651 loss: 7.48568e-06
Iter: 1652 loss: 7.50035088e-06
Iter: 1653 loss: 7.48284674e-06
Iter: 1654 loss: 7.47465901e-06
Iter: 1655 loss: 7.51045263e-06
Iter: 1656 loss: 7.47344529e-06
Iter: 1657 loss: 7.46553451e-06
Iter: 1658 loss: 7.47014656e-06
Iter: 1659 loss: 7.4605241e-06
Iter: 1660 loss: 7.45225088e-06
Iter: 1661 loss: 7.46723026e-06
Iter: 1662 loss: 7.44879844e-06
Iter: 1663 loss: 7.43941291e-06
Iter: 1664 loss: 7.4844811e-06
Iter: 1665 loss: 7.43782857e-06
Iter: 1666 loss: 7.42934208e-06
Iter: 1667 loss: 7.45457874e-06
Iter: 1668 loss: 7.4269019e-06
Iter: 1669 loss: 7.41968142e-06
Iter: 1670 loss: 7.46848809e-06
Iter: 1671 loss: 7.41903e-06
Iter: 1672 loss: 7.41201e-06
Iter: 1673 loss: 7.43508417e-06
Iter: 1674 loss: 7.41013355e-06
Iter: 1675 loss: 7.40495943e-06
Iter: 1676 loss: 7.39502639e-06
Iter: 1677 loss: 7.59629211e-06
Iter: 1678 loss: 7.39494772e-06
Iter: 1679 loss: 7.38634571e-06
Iter: 1680 loss: 7.47133527e-06
Iter: 1681 loss: 7.38612198e-06
Iter: 1682 loss: 7.37928895e-06
Iter: 1683 loss: 7.44094405e-06
Iter: 1684 loss: 7.37897926e-06
Iter: 1685 loss: 7.37418668e-06
Iter: 1686 loss: 7.36766e-06
Iter: 1687 loss: 7.36744914e-06
Iter: 1688 loss: 7.35740741e-06
Iter: 1689 loss: 7.40269206e-06
Iter: 1690 loss: 7.35544927e-06
Iter: 1691 loss: 7.34784635e-06
Iter: 1692 loss: 7.40508221e-06
Iter: 1693 loss: 7.34738614e-06
Iter: 1694 loss: 7.34219793e-06
Iter: 1695 loss: 7.34171499e-06
Iter: 1696 loss: 7.33794332e-06
Iter: 1697 loss: 7.33033949e-06
Iter: 1698 loss: 7.35844e-06
Iter: 1699 loss: 7.32862827e-06
Iter: 1700 loss: 7.32128774e-06
Iter: 1701 loss: 7.34379137e-06
Iter: 1702 loss: 7.31886666e-06
Iter: 1703 loss: 7.31242653e-06
Iter: 1704 loss: 7.31016098e-06
Iter: 1705 loss: 7.30640841e-06
Iter: 1706 loss: 7.29795102e-06
Iter: 1707 loss: 7.35465119e-06
Iter: 1708 loss: 7.29718613e-06
Iter: 1709 loss: 7.28973737e-06
Iter: 1710 loss: 7.32998342e-06
Iter: 1711 loss: 7.28855912e-06
Iter: 1712 loss: 7.28274e-06
Iter: 1713 loss: 7.32851868e-06
Iter: 1714 loss: 7.28242912e-06
Iter: 1715 loss: 7.27766792e-06
Iter: 1716 loss: 7.2716839e-06
Iter: 1717 loss: 7.27107317e-06
Iter: 1718 loss: 7.2632306e-06
Iter: 1719 loss: 7.27704673e-06
Iter: 1720 loss: 7.25958807e-06
Iter: 1721 loss: 7.25085329e-06
Iter: 1722 loss: 7.25177779e-06
Iter: 1723 loss: 7.24388065e-06
Iter: 1724 loss: 7.2373623e-06
Iter: 1725 loss: 7.23737139e-06
Iter: 1726 loss: 7.23059384e-06
Iter: 1727 loss: 7.24025494e-06
Iter: 1728 loss: 7.22732148e-06
Iter: 1729 loss: 7.21990955e-06
Iter: 1730 loss: 7.230763e-06
Iter: 1731 loss: 7.21634888e-06
Iter: 1732 loss: 7.20950902e-06
Iter: 1733 loss: 7.24813526e-06
Iter: 1734 loss: 7.20867047e-06
Iter: 1735 loss: 7.2022267e-06
Iter: 1736 loss: 7.20911157e-06
Iter: 1737 loss: 7.1987597e-06
Iter: 1738 loss: 7.19159925e-06
Iter: 1739 loss: 7.20858588e-06
Iter: 1740 loss: 7.18901538e-06
Iter: 1741 loss: 7.18210367e-06
Iter: 1742 loss: 7.22572531e-06
Iter: 1743 loss: 7.18114279e-06
Iter: 1744 loss: 7.1757504e-06
Iter: 1745 loss: 7.1730974e-06
Iter: 1746 loss: 7.17055855e-06
Iter: 1747 loss: 7.16180512e-06
Iter: 1748 loss: 7.20327716e-06
Iter: 1749 loss: 7.16024169e-06
Iter: 1750 loss: 7.1535228e-06
Iter: 1751 loss: 7.24141182e-06
Iter: 1752 loss: 7.15336591e-06
Iter: 1753 loss: 7.14918269e-06
Iter: 1754 loss: 7.14346334e-06
Iter: 1755 loss: 7.14299949e-06
Iter: 1756 loss: 7.13482359e-06
Iter: 1757 loss: 7.16738805e-06
Iter: 1758 loss: 7.13278087e-06
Iter: 1759 loss: 7.12515975e-06
Iter: 1760 loss: 7.1236891e-06
Iter: 1761 loss: 7.11871371e-06
Iter: 1762 loss: 7.10931818e-06
Iter: 1763 loss: 7.1322338e-06
Iter: 1764 loss: 7.10589393e-06
Iter: 1765 loss: 7.09846245e-06
Iter: 1766 loss: 7.19979107e-06
Iter: 1767 loss: 7.09843835e-06
Iter: 1768 loss: 7.09190681e-06
Iter: 1769 loss: 7.10926952e-06
Iter: 1770 loss: 7.08964171e-06
Iter: 1771 loss: 7.08358402e-06
Iter: 1772 loss: 7.08373227e-06
Iter: 1773 loss: 7.07890285e-06
Iter: 1774 loss: 7.07085428e-06
Iter: 1775 loss: 7.12123347e-06
Iter: 1776 loss: 7.06981837e-06
Iter: 1777 loss: 7.06315723e-06
Iter: 1778 loss: 7.07604522e-06
Iter: 1779 loss: 7.0602191e-06
Iter: 1780 loss: 7.05311595e-06
Iter: 1781 loss: 7.05918728e-06
Iter: 1782 loss: 7.04894819e-06
Iter: 1783 loss: 7.04017975e-06
Iter: 1784 loss: 7.1052259e-06
Iter: 1785 loss: 7.03947444e-06
Iter: 1786 loss: 7.03394471e-06
Iter: 1787 loss: 7.03264868e-06
Iter: 1788 loss: 7.02904799e-06
Iter: 1789 loss: 7.02130183e-06
Iter: 1790 loss: 7.04786e-06
Iter: 1791 loss: 7.01929093e-06
Iter: 1792 loss: 7.01254203e-06
Iter: 1793 loss: 7.07655363e-06
Iter: 1794 loss: 7.01213685e-06
Iter: 1795 loss: 7.00649025e-06
Iter: 1796 loss: 7.02390571e-06
Iter: 1797 loss: 7.00461169e-06
Iter: 1798 loss: 6.9998041e-06
Iter: 1799 loss: 7.00351757e-06
Iter: 1800 loss: 6.99671637e-06
Iter: 1801 loss: 6.99047e-06
Iter: 1802 loss: 6.98891e-06
Iter: 1803 loss: 6.9848611e-06
Iter: 1804 loss: 6.97642872e-06
Iter: 1805 loss: 6.99997145e-06
Iter: 1806 loss: 6.97358655e-06
Iter: 1807 loss: 6.96760708e-06
Iter: 1808 loss: 7.06115407e-06
Iter: 1809 loss: 6.96765801e-06
Iter: 1810 loss: 6.96167444e-06
Iter: 1811 loss: 6.95918334e-06
Iter: 1812 loss: 6.95607423e-06
Iter: 1813 loss: 6.94871733e-06
Iter: 1814 loss: 6.96737425e-06
Iter: 1815 loss: 6.94625e-06
Iter: 1816 loss: 6.93900256e-06
Iter: 1817 loss: 6.99162547e-06
Iter: 1818 loss: 6.93849734e-06
Iter: 1819 loss: 6.93337051e-06
Iter: 1820 loss: 6.93681432e-06
Iter: 1821 loss: 6.93010497e-06
Iter: 1822 loss: 6.92333924e-06
Iter: 1823 loss: 6.93791162e-06
Iter: 1824 loss: 6.92082176e-06
Iter: 1825 loss: 6.91383e-06
Iter: 1826 loss: 6.95935751e-06
Iter: 1827 loss: 6.91299e-06
Iter: 1828 loss: 6.90853449e-06
Iter: 1829 loss: 6.90178149e-06
Iter: 1830 loss: 6.90173965e-06
Iter: 1831 loss: 6.89304261e-06
Iter: 1832 loss: 6.98588428e-06
Iter: 1833 loss: 6.89261606e-06
Iter: 1834 loss: 6.88714817e-06
Iter: 1835 loss: 6.95226254e-06
Iter: 1836 loss: 6.88708769e-06
Iter: 1837 loss: 6.88357431e-06
Iter: 1838 loss: 6.87931606e-06
Iter: 1839 loss: 6.87888314e-06
Iter: 1840 loss: 6.87209786e-06
Iter: 1841 loss: 6.8912741e-06
Iter: 1842 loss: 6.86996646e-06
Iter: 1843 loss: 6.86377734e-06
Iter: 1844 loss: 6.86671865e-06
Iter: 1845 loss: 6.85944906e-06
Iter: 1846 loss: 6.85246096e-06
Iter: 1847 loss: 6.88791442e-06
Iter: 1848 loss: 6.85140458e-06
Iter: 1849 loss: 6.8443087e-06
Iter: 1850 loss: 6.88473392e-06
Iter: 1851 loss: 6.84336055e-06
Iter: 1852 loss: 6.83832241e-06
Iter: 1853 loss: 6.83771714e-06
Iter: 1854 loss: 6.83397411e-06
Iter: 1855 loss: 6.82741302e-06
Iter: 1856 loss: 6.84900624e-06
Iter: 1857 loss: 6.82561677e-06
Iter: 1858 loss: 6.81796337e-06
Iter: 1859 loss: 6.84496626e-06
Iter: 1860 loss: 6.81578695e-06
Iter: 1861 loss: 6.81005e-06
Iter: 1862 loss: 6.82257723e-06
Iter: 1863 loss: 6.80793437e-06
Iter: 1864 loss: 6.80185076e-06
Iter: 1865 loss: 6.81716756e-06
Iter: 1866 loss: 6.79961568e-06
Iter: 1867 loss: 6.79269397e-06
Iter: 1868 loss: 6.80905032e-06
Iter: 1869 loss: 6.78991091e-06
Iter: 1870 loss: 6.78388233e-06
Iter: 1871 loss: 6.79050618e-06
Iter: 1872 loss: 6.78034939e-06
Iter: 1873 loss: 6.77519756e-06
Iter: 1874 loss: 6.77491971e-06
Iter: 1875 loss: 6.77142907e-06
Iter: 1876 loss: 6.76582931e-06
Iter: 1877 loss: 6.7658566e-06
Iter: 1878 loss: 6.7589408e-06
Iter: 1879 loss: 6.78549077e-06
Iter: 1880 loss: 6.75746742e-06
Iter: 1881 loss: 6.75111596e-06
Iter: 1882 loss: 6.76043237e-06
Iter: 1883 loss: 6.74808598e-06
Iter: 1884 loss: 6.74093e-06
Iter: 1885 loss: 6.76170521e-06
Iter: 1886 loss: 6.73862542e-06
Iter: 1887 loss: 6.73295972e-06
Iter: 1888 loss: 6.77072603e-06
Iter: 1889 loss: 6.73256091e-06
Iter: 1890 loss: 6.72583428e-06
Iter: 1891 loss: 6.72593933e-06
Iter: 1892 loss: 6.72071246e-06
Iter: 1893 loss: 6.71432281e-06
Iter: 1894 loss: 6.72634178e-06
Iter: 1895 loss: 6.7119e-06
Iter: 1896 loss: 6.70525469e-06
Iter: 1897 loss: 6.75019965e-06
Iter: 1898 loss: 6.70454938e-06
Iter: 1899 loss: 6.69817427e-06
Iter: 1900 loss: 6.69855945e-06
Iter: 1901 loss: 6.69277961e-06
Iter: 1902 loss: 6.68612302e-06
Iter: 1903 loss: 6.71984253e-06
Iter: 1904 loss: 6.68493931e-06
Iter: 1905 loss: 6.67834775e-06
Iter: 1906 loss: 6.69900282e-06
Iter: 1907 loss: 6.67664426e-06
Iter: 1908 loss: 6.67058703e-06
Iter: 1909 loss: 6.67416043e-06
Iter: 1910 loss: 6.66673895e-06
Iter: 1911 loss: 6.66080177e-06
Iter: 1912 loss: 6.66101869e-06
Iter: 1913 loss: 6.65612606e-06
Iter: 1914 loss: 6.65744938e-06
Iter: 1915 loss: 6.65290509e-06
Iter: 1916 loss: 6.6476955e-06
Iter: 1917 loss: 6.64467734e-06
Iter: 1918 loss: 6.64244635e-06
Iter: 1919 loss: 6.63620222e-06
Iter: 1920 loss: 6.70136296e-06
Iter: 1921 loss: 6.63596938e-06
Iter: 1922 loss: 6.63056744e-06
Iter: 1923 loss: 6.63119226e-06
Iter: 1924 loss: 6.62655748e-06
Iter: 1925 loss: 6.61927788e-06
Iter: 1926 loss: 6.65569314e-06
Iter: 1927 loss: 6.6179332e-06
Iter: 1928 loss: 6.61213198e-06
Iter: 1929 loss: 6.65358948e-06
Iter: 1930 loss: 6.61157947e-06
Iter: 1931 loss: 6.60663318e-06
Iter: 1932 loss: 6.6004468e-06
Iter: 1933 loss: 6.600078e-06
Iter: 1934 loss: 6.59268608e-06
Iter: 1935 loss: 6.6396351e-06
Iter: 1936 loss: 6.59186799e-06
Iter: 1937 loss: 6.58566842e-06
Iter: 1938 loss: 6.62694856e-06
Iter: 1939 loss: 6.58509816e-06
Iter: 1940 loss: 6.58067211e-06
Iter: 1941 loss: 6.57951887e-06
Iter: 1942 loss: 6.57661303e-06
Iter: 1943 loss: 6.5705e-06
Iter: 1944 loss: 6.59688612e-06
Iter: 1945 loss: 6.56922793e-06
Iter: 1946 loss: 6.56249085e-06
Iter: 1947 loss: 6.57898454e-06
Iter: 1948 loss: 6.56010161e-06
Iter: 1949 loss: 6.55474651e-06
Iter: 1950 loss: 6.59661691e-06
Iter: 1951 loss: 6.55424901e-06
Iter: 1952 loss: 6.54929499e-06
Iter: 1953 loss: 6.56052634e-06
Iter: 1954 loss: 6.54725818e-06
Iter: 1955 loss: 6.54275436e-06
Iter: 1956 loss: 6.53469806e-06
Iter: 1957 loss: 6.53470488e-06
Iter: 1958 loss: 6.5268473e-06
Iter: 1959 loss: 6.58946919e-06
Iter: 1960 loss: 6.52648578e-06
Iter: 1961 loss: 6.52004383e-06
Iter: 1962 loss: 6.55738222e-06
Iter: 1963 loss: 6.51938763e-06
Iter: 1964 loss: 6.51472328e-06
Iter: 1965 loss: 6.51670689e-06
Iter: 1966 loss: 6.51148275e-06
Iter: 1967 loss: 6.50416314e-06
Iter: 1968 loss: 6.54435462e-06
Iter: 1969 loss: 6.50318543e-06
Iter: 1970 loss: 6.49825051e-06
Iter: 1971 loss: 6.509385e-06
Iter: 1972 loss: 6.49630056e-06
Iter: 1973 loss: 6.4912042e-06
Iter: 1974 loss: 6.48796959e-06
Iter: 1975 loss: 6.48589321e-06
Iter: 1976 loss: 6.47956813e-06
Iter: 1977 loss: 6.56124939e-06
Iter: 1978 loss: 6.47948764e-06
Iter: 1979 loss: 6.47380148e-06
Iter: 1980 loss: 6.47487e-06
Iter: 1981 loss: 6.46949593e-06
Iter: 1982 loss: 6.46338322e-06
Iter: 1983 loss: 6.47884917e-06
Iter: 1984 loss: 6.46131139e-06
Iter: 1985 loss: 6.45514729e-06
Iter: 1986 loss: 6.4967885e-06
Iter: 1987 loss: 6.45450928e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.4/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.8
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.8
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.8 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.8
+ date
Sun Nov  8 11:12:03 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.4/300_100_100_100_1 --function f2 --psi 0 --alpha 2.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.8/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9baaf9fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9baaf9f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9baaf9f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9baaf9f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9baaf9f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba759e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba74ca158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba74cad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba74ca488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7484598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7491d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba73da400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba73da7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7438d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba750f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba750f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba750b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba736b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba736b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7327378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7327e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba72b78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba72b76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba72b7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba73f87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7404950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba722dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba722dd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba71f3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba71e2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba71f3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba70fc620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba70fc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7267a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7129620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9ba7267950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.00896652
test_loss: 0.011316539
train_loss: 0.008511617
test_loss: 0.0107160425
train_loss: 0.008520221
test_loss: 0.010611051
train_loss: 0.008663822
test_loss: 0.010693715
train_loss: 0.009731955
test_loss: 0.011966121
train_loss: 0.0079451045
test_loss: 0.010278168
train_loss: 0.008025383
test_loss: 0.010377778
train_loss: 0.0077128215
test_loss: 0.010151167
train_loss: 0.007807565
test_loss: 0.010216448
train_loss: 0.0076462193
test_loss: 0.010133596
train_loss: 0.0077685686
test_loss: 0.010121417
train_loss: 0.007427158
test_loss: 0.010004181
train_loss: 0.007980146
test_loss: 0.010716139
train_loss: 0.0073372694
test_loss: 0.010386662
train_loss: 0.0076807253
test_loss: 0.0101479115
train_loss: 0.0075342734
test_loss: 0.009886619
train_loss: 0.0074259695
test_loss: 0.009987917
train_loss: 0.007640695
test_loss: 0.010177279
train_loss: 0.0074751764
test_loss: 0.009736926
train_loss: 0.007164197
test_loss: 0.009872802
train_loss: 0.0069050076
test_loss: 0.009840931
train_loss: 0.007555153
test_loss: 0.010009668
train_loss: 0.0067820204
test_loss: 0.009836472
train_loss: 0.007603628
test_loss: 0.009903613
train_loss: 0.0075461087
test_loss: 0.009789235
train_loss: 0.007801764
test_loss: 0.009929905
train_loss: 0.007223068
test_loss: 0.010000438
train_loss: 0.007050089
test_loss: 0.009822496
train_loss: 0.008060503
test_loss: 0.01000245
train_loss: 0.0072058532
test_loss: 0.009973227
train_loss: 0.0070158457
test_loss: 0.009777714
train_loss: 0.0074138287
test_loss: 0.010230238
train_loss: 0.0066698478
test_loss: 0.009781707
train_loss: 0.007239897
test_loss: 0.009894343
train_loss: 0.0073296586
test_loss: 0.010255061
train_loss: 0.006721439
test_loss: 0.009704622
train_loss: 0.0068981745
test_loss: 0.00954676
train_loss: 0.007199699
test_loss: 0.00982957
train_loss: 0.006799759
test_loss: 0.009521115
train_loss: 0.007106391
test_loss: 0.009584751
train_loss: 0.007296721
test_loss: 0.009709827
train_loss: 0.0067931763
test_loss: 0.009406298
train_loss: 0.006888492
test_loss: 0.009586575
train_loss: 0.0068800603
test_loss: 0.00963258
train_loss: 0.00669746
test_loss: 0.009638409
train_loss: 0.006678992
test_loss: 0.009556876
train_loss: 0.007067841
test_loss: 0.009389996
train_loss: 0.006866147
test_loss: 0.009570969
train_loss: 0.0065474138
test_loss: 0.009593982
train_loss: 0.0067704744
test_loss: 0.009566918
train_loss: 0.007114716
test_loss: 0.009657969
train_loss: 0.007121915
test_loss: 0.009813356
train_loss: 0.0068615605
test_loss: 0.009596013
train_loss: 0.0068838866
test_loss: 0.0094776405
train_loss: 0.006927802
test_loss: 0.009453677
train_loss: 0.006966546
test_loss: 0.009436678
train_loss: 0.0066852607
test_loss: 0.00946921
train_loss: 0.006697392
test_loss: 0.009314858
train_loss: 0.006536396
test_loss: 0.009486921
train_loss: 0.0066776252
test_loss: 0.009640008
train_loss: 0.0063548596
test_loss: 0.009251697
train_loss: 0.0064913607
test_loss: 0.009549595
train_loss: 0.0065203467
test_loss: 0.009541921
train_loss: 0.0068988963
test_loss: 0.009471927
train_loss: 0.0066297646
test_loss: 0.009512619
train_loss: 0.007028983
test_loss: 0.009351405
train_loss: 0.006524224
test_loss: 0.009453211
train_loss: 0.0067428225
test_loss: 0.009396831
train_loss: 0.006478663
test_loss: 0.00931461
train_loss: 0.006401127
test_loss: 0.00929418
train_loss: 0.0069077015
test_loss: 0.009820049
train_loss: 0.0064189453
test_loss: 0.0093221115
train_loss: 0.0066439644
test_loss: 0.009357665
train_loss: 0.0065359543
test_loss: 0.009219039
train_loss: 0.006685366
test_loss: 0.009603643
train_loss: 0.0064119743
test_loss: 0.009353996
train_loss: 0.006628311
test_loss: 0.00942254
train_loss: 0.0066485023
test_loss: 0.00955041
train_loss: 0.0068037985
test_loss: 0.009552593
train_loss: 0.0067716646
test_loss: 0.009420546
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.8/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.8/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 2.8 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi2.8/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc6d6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc6e17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc6e1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc6e1b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc661598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc67db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc631158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc631950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc5d8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc5f39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc58ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc572840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc572e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc661840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd319378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2dc53cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd319510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd2e80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd2e8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd2e8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd2d27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd28a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd230b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd230730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd1d6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd1d62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd200ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd28a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd1c6b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd18fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd1d6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd0eb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd0f1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd0b5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd0b5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2cd0b5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 7.8930927e-05
Iter: 2 loss: 6.5917091e-05
Iter: 3 loss: 0.000126888888
Iter: 4 loss: 6.36300683e-05
Iter: 5 loss: 5.79931148e-05
Iter: 6 loss: 5.44876966e-05
Iter: 7 loss: 5.21966904e-05
Iter: 8 loss: 4.671036e-05
Iter: 9 loss: 0.000114127193
Iter: 10 loss: 4.66556739e-05
Iter: 11 loss: 4.30189575e-05
Iter: 12 loss: 6.38457132e-05
Iter: 13 loss: 4.25195394e-05
Iter: 14 loss: 4.02603182e-05
Iter: 15 loss: 4.6863086e-05
Iter: 16 loss: 3.95630705e-05
Iter: 17 loss: 3.77949036e-05
Iter: 18 loss: 4.23442907e-05
Iter: 19 loss: 3.71890055e-05
Iter: 20 loss: 3.57089521e-05
Iter: 21 loss: 3.88402768e-05
Iter: 22 loss: 3.51227354e-05
Iter: 23 loss: 3.35154109e-05
Iter: 24 loss: 4.06181607e-05
Iter: 25 loss: 3.32012642e-05
Iter: 26 loss: 3.21301668e-05
Iter: 27 loss: 3.30432413e-05
Iter: 28 loss: 3.14956415e-05
Iter: 29 loss: 3.03621673e-05
Iter: 30 loss: 3.43903812e-05
Iter: 31 loss: 3.00711836e-05
Iter: 32 loss: 2.90716343e-05
Iter: 33 loss: 3.30015246e-05
Iter: 34 loss: 2.88426127e-05
Iter: 35 loss: 2.80834702e-05
Iter: 36 loss: 3.02839089e-05
Iter: 37 loss: 2.78470325e-05
Iter: 38 loss: 2.71935132e-05
Iter: 39 loss: 2.75768089e-05
Iter: 40 loss: 2.67698379e-05
Iter: 41 loss: 2.63935617e-05
Iter: 42 loss: 2.63701768e-05
Iter: 43 loss: 2.60500765e-05
Iter: 44 loss: 2.65889939e-05
Iter: 45 loss: 2.59050212e-05
Iter: 46 loss: 2.55859941e-05
Iter: 47 loss: 2.77043491e-05
Iter: 48 loss: 2.55529867e-05
Iter: 49 loss: 2.52621649e-05
Iter: 50 loss: 2.58235232e-05
Iter: 51 loss: 2.51411566e-05
Iter: 52 loss: 2.48996621e-05
Iter: 53 loss: 2.52754617e-05
Iter: 54 loss: 2.47864355e-05
Iter: 55 loss: 2.45009087e-05
Iter: 56 loss: 2.53552753e-05
Iter: 57 loss: 2.4414574e-05
Iter: 58 loss: 2.41900325e-05
Iter: 59 loss: 2.51210331e-05
Iter: 60 loss: 2.41416747e-05
Iter: 61 loss: 2.39418277e-05
Iter: 62 loss: 2.43432987e-05
Iter: 63 loss: 2.38608627e-05
Iter: 64 loss: 2.36421929e-05
Iter: 65 loss: 2.37637305e-05
Iter: 66 loss: 2.34995932e-05
Iter: 67 loss: 2.32665261e-05
Iter: 68 loss: 2.39609108e-05
Iter: 69 loss: 2.31952254e-05
Iter: 70 loss: 2.29708712e-05
Iter: 71 loss: 2.3952236e-05
Iter: 72 loss: 2.29254874e-05
Iter: 73 loss: 2.27229448e-05
Iter: 74 loss: 2.32220973e-05
Iter: 75 loss: 2.26508018e-05
Iter: 76 loss: 2.24617688e-05
Iter: 77 loss: 2.26322481e-05
Iter: 78 loss: 2.235178e-05
Iter: 79 loss: 2.21732153e-05
Iter: 80 loss: 2.27015171e-05
Iter: 81 loss: 2.21183982e-05
Iter: 82 loss: 2.19115336e-05
Iter: 83 loss: 2.26951524e-05
Iter: 84 loss: 2.18618043e-05
Iter: 85 loss: 2.17381039e-05
Iter: 86 loss: 2.17374509e-05
Iter: 87 loss: 2.16436274e-05
Iter: 88 loss: 2.18117784e-05
Iter: 89 loss: 2.16028675e-05
Iter: 90 loss: 2.14917563e-05
Iter: 91 loss: 2.175398e-05
Iter: 92 loss: 2.14514512e-05
Iter: 93 loss: 2.13475e-05
Iter: 94 loss: 2.13130352e-05
Iter: 95 loss: 2.1253225e-05
Iter: 96 loss: 2.11417137e-05
Iter: 97 loss: 2.23326242e-05
Iter: 98 loss: 2.11390179e-05
Iter: 99 loss: 2.10530816e-05
Iter: 100 loss: 2.11057722e-05
Iter: 101 loss: 2.09976643e-05
Iter: 102 loss: 2.08912861e-05
Iter: 103 loss: 2.14329884e-05
Iter: 104 loss: 2.08738929e-05
Iter: 105 loss: 2.0787882e-05
Iter: 106 loss: 2.1022468e-05
Iter: 107 loss: 2.07596677e-05
Iter: 108 loss: 2.06696313e-05
Iter: 109 loss: 2.05727411e-05
Iter: 110 loss: 2.05573833e-05
Iter: 111 loss: 2.04299358e-05
Iter: 112 loss: 2.1341948e-05
Iter: 113 loss: 2.04190783e-05
Iter: 114 loss: 2.03197815e-05
Iter: 115 loss: 2.07555331e-05
Iter: 116 loss: 2.02995507e-05
Iter: 117 loss: 2.02084921e-05
Iter: 118 loss: 2.03089676e-05
Iter: 119 loss: 2.01591447e-05
Iter: 120 loss: 2.00606701e-05
Iter: 121 loss: 2.01741077e-05
Iter: 122 loss: 2.00076665e-05
Iter: 123 loss: 1.99115821e-05
Iter: 124 loss: 2.0634714e-05
Iter: 125 loss: 1.99037495e-05
Iter: 126 loss: 1.98352718e-05
Iter: 127 loss: 1.983521e-05
Iter: 128 loss: 1.97910849e-05
Iter: 129 loss: 1.97198315e-05
Iter: 130 loss: 1.97195841e-05
Iter: 131 loss: 1.96409383e-05
Iter: 132 loss: 1.97617192e-05
Iter: 133 loss: 1.96033907e-05
Iter: 134 loss: 1.95212815e-05
Iter: 135 loss: 2.0459107e-05
Iter: 136 loss: 1.95199373e-05
Iter: 137 loss: 1.94682361e-05
Iter: 138 loss: 1.94787845e-05
Iter: 139 loss: 1.94295935e-05
Iter: 140 loss: 1.93568776e-05
Iter: 141 loss: 1.98351991e-05
Iter: 142 loss: 1.93491087e-05
Iter: 143 loss: 1.92956359e-05
Iter: 144 loss: 1.93318065e-05
Iter: 145 loss: 1.92619482e-05
Iter: 146 loss: 1.92024927e-05
Iter: 147 loss: 1.94398617e-05
Iter: 148 loss: 1.91889376e-05
Iter: 149 loss: 1.9134779e-05
Iter: 150 loss: 1.92883599e-05
Iter: 151 loss: 1.91177169e-05
Iter: 152 loss: 1.90545325e-05
Iter: 153 loss: 1.90566243e-05
Iter: 154 loss: 1.90044084e-05
Iter: 155 loss: 1.894261e-05
Iter: 156 loss: 1.91702784e-05
Iter: 157 loss: 1.89276197e-05
Iter: 158 loss: 1.88617887e-05
Iter: 159 loss: 1.91331874e-05
Iter: 160 loss: 1.88475387e-05
Iter: 161 loss: 1.87892329e-05
Iter: 162 loss: 1.88025224e-05
Iter: 163 loss: 1.87460737e-05
Iter: 164 loss: 1.8698e-05
Iter: 165 loss: 1.86982361e-05
Iter: 166 loss: 1.86523466e-05
Iter: 167 loss: 1.87937039e-05
Iter: 168 loss: 1.86389389e-05
Iter: 169 loss: 1.8601866e-05
Iter: 170 loss: 1.85270528e-05
Iter: 171 loss: 1.99243514e-05
Iter: 172 loss: 1.8526227e-05
Iter: 173 loss: 1.84507771e-05
Iter: 174 loss: 1.88239701e-05
Iter: 175 loss: 1.84378623e-05
Iter: 176 loss: 1.83757766e-05
Iter: 177 loss: 1.87656151e-05
Iter: 178 loss: 1.83688899e-05
Iter: 179 loss: 1.83148513e-05
Iter: 180 loss: 1.85641948e-05
Iter: 181 loss: 1.83048323e-05
Iter: 182 loss: 1.82612584e-05
Iter: 183 loss: 1.83712182e-05
Iter: 184 loss: 1.82458534e-05
Iter: 185 loss: 1.82018812e-05
Iter: 186 loss: 1.83808861e-05
Iter: 187 loss: 1.8192115e-05
Iter: 188 loss: 1.81554951e-05
Iter: 189 loss: 1.81687756e-05
Iter: 190 loss: 1.81294527e-05
Iter: 191 loss: 1.80791649e-05
Iter: 192 loss: 1.81483701e-05
Iter: 193 loss: 1.80542957e-05
Iter: 194 loss: 1.80088864e-05
Iter: 195 loss: 1.85757272e-05
Iter: 196 loss: 1.80083698e-05
Iter: 197 loss: 1.79742819e-05
Iter: 198 loss: 1.79459403e-05
Iter: 199 loss: 1.79361741e-05
Iter: 200 loss: 1.78819519e-05
Iter: 201 loss: 1.80737261e-05
Iter: 202 loss: 1.78681603e-05
Iter: 203 loss: 1.78192731e-05
Iter: 204 loss: 1.82213662e-05
Iter: 205 loss: 1.78158498e-05
Iter: 206 loss: 1.77836137e-05
Iter: 207 loss: 1.80328643e-05
Iter: 208 loss: 1.77809816e-05
Iter: 209 loss: 1.77507063e-05
Iter: 210 loss: 1.7704624e-05
Iter: 211 loss: 1.77040201e-05
Iter: 212 loss: 1.76550748e-05
Iter: 213 loss: 1.77182374e-05
Iter: 214 loss: 1.76293943e-05
Iter: 215 loss: 1.75735295e-05
Iter: 216 loss: 1.77261682e-05
Iter: 217 loss: 1.75548557e-05
Iter: 218 loss: 1.75082059e-05
Iter: 219 loss: 1.79254857e-05
Iter: 220 loss: 1.75060577e-05
Iter: 221 loss: 1.74708111e-05
Iter: 222 loss: 1.7708031e-05
Iter: 223 loss: 1.74670604e-05
Iter: 224 loss: 1.74360484e-05
Iter: 225 loss: 1.74030447e-05
Iter: 226 loss: 1.73974167e-05
Iter: 227 loss: 1.73514491e-05
Iter: 228 loss: 1.75232635e-05
Iter: 229 loss: 1.7340546e-05
Iter: 230 loss: 1.7294853e-05
Iter: 231 loss: 1.75561399e-05
Iter: 232 loss: 1.72887958e-05
Iter: 233 loss: 1.72516375e-05
Iter: 234 loss: 1.72836299e-05
Iter: 235 loss: 1.72293676e-05
Iter: 236 loss: 1.71919382e-05
Iter: 237 loss: 1.73076896e-05
Iter: 238 loss: 1.71812499e-05
Iter: 239 loss: 1.71311804e-05
Iter: 240 loss: 1.72230702e-05
Iter: 241 loss: 1.71093943e-05
Iter: 242 loss: 1.7079612e-05
Iter: 243 loss: 1.70793101e-05
Iter: 244 loss: 1.70557105e-05
Iter: 245 loss: 1.7045928e-05
Iter: 246 loss: 1.70331805e-05
Iter: 247 loss: 1.69991763e-05
Iter: 248 loss: 1.69655705e-05
Iter: 249 loss: 1.69581872e-05
Iter: 250 loss: 1.69108189e-05
Iter: 251 loss: 1.71756656e-05
Iter: 252 loss: 1.69041014e-05
Iter: 253 loss: 1.68683291e-05
Iter: 254 loss: 1.71030151e-05
Iter: 255 loss: 1.68645456e-05
Iter: 256 loss: 1.68278548e-05
Iter: 257 loss: 1.68301813e-05
Iter: 258 loss: 1.67998114e-05
Iter: 259 loss: 1.67699473e-05
Iter: 260 loss: 1.67697599e-05
Iter: 261 loss: 1.67465769e-05
Iter: 262 loss: 1.67362923e-05
Iter: 263 loss: 1.6724518e-05
Iter: 264 loss: 1.66896207e-05
Iter: 265 loss: 1.66955706e-05
Iter: 266 loss: 1.66631198e-05
Iter: 267 loss: 1.66130521e-05
Iter: 268 loss: 1.67605594e-05
Iter: 269 loss: 1.65972142e-05
Iter: 270 loss: 1.6568998e-05
Iter: 271 loss: 1.65681031e-05
Iter: 272 loss: 1.65459096e-05
Iter: 273 loss: 1.65147176e-05
Iter: 274 loss: 1.65131896e-05
Iter: 275 loss: 1.64792364e-05
Iter: 276 loss: 1.64792509e-05
Iter: 277 loss: 1.6453816e-05
Iter: 278 loss: 1.65031634e-05
Iter: 279 loss: 1.64438206e-05
Iter: 280 loss: 1.64214271e-05
Iter: 281 loss: 1.63857367e-05
Iter: 282 loss: 1.63854e-05
Iter: 283 loss: 1.63526929e-05
Iter: 284 loss: 1.63526856e-05
Iter: 285 loss: 1.63277982e-05
Iter: 286 loss: 1.62816432e-05
Iter: 287 loss: 1.7320519e-05
Iter: 288 loss: 1.62814649e-05
Iter: 289 loss: 1.62344058e-05
Iter: 290 loss: 1.64845533e-05
Iter: 291 loss: 1.62265296e-05
Iter: 292 loss: 1.61970493e-05
Iter: 293 loss: 1.61969292e-05
Iter: 294 loss: 1.61703883e-05
Iter: 295 loss: 1.61829812e-05
Iter: 296 loss: 1.61523512e-05
Iter: 297 loss: 1.61242642e-05
Iter: 298 loss: 1.61068401e-05
Iter: 299 loss: 1.60955e-05
Iter: 300 loss: 1.60577856e-05
Iter: 301 loss: 1.64748017e-05
Iter: 302 loss: 1.60569743e-05
Iter: 303 loss: 1.6029946e-05
Iter: 304 loss: 1.6095406e-05
Iter: 305 loss: 1.6020098e-05
Iter: 306 loss: 1.598985e-05
Iter: 307 loss: 1.60522104e-05
Iter: 308 loss: 1.59779647e-05
Iter: 309 loss: 1.5948619e-05
Iter: 310 loss: 1.6246202e-05
Iter: 311 loss: 1.59472602e-05
Iter: 312 loss: 1.59272277e-05
Iter: 313 loss: 1.59714145e-05
Iter: 314 loss: 1.59194533e-05
Iter: 315 loss: 1.58973489e-05
Iter: 316 loss: 1.58842704e-05
Iter: 317 loss: 1.58750336e-05
Iter: 318 loss: 1.58411131e-05
Iter: 319 loss: 1.58947205e-05
Iter: 320 loss: 1.58250532e-05
Iter: 321 loss: 1.57925497e-05
Iter: 322 loss: 1.58974071e-05
Iter: 323 loss: 1.5783462e-05
Iter: 324 loss: 1.57470386e-05
Iter: 325 loss: 1.58464427e-05
Iter: 326 loss: 1.57352606e-05
Iter: 327 loss: 1.56998212e-05
Iter: 328 loss: 1.58758794e-05
Iter: 329 loss: 1.56938859e-05
Iter: 330 loss: 1.56706592e-05
Iter: 331 loss: 1.56939313e-05
Iter: 332 loss: 1.56574242e-05
Iter: 333 loss: 1.56288661e-05
Iter: 334 loss: 1.59036172e-05
Iter: 335 loss: 1.56279511e-05
Iter: 336 loss: 1.56070655e-05
Iter: 337 loss: 1.55880734e-05
Iter: 338 loss: 1.5583304e-05
Iter: 339 loss: 1.55527341e-05
Iter: 340 loss: 1.55563e-05
Iter: 341 loss: 1.55293201e-05
Iter: 342 loss: 1.55007874e-05
Iter: 343 loss: 1.55007838e-05
Iter: 344 loss: 1.54743084e-05
Iter: 345 loss: 1.55802627e-05
Iter: 346 loss: 1.54685204e-05
Iter: 347 loss: 1.54438912e-05
Iter: 348 loss: 1.54945737e-05
Iter: 349 loss: 1.54340451e-05
Iter: 350 loss: 1.54079389e-05
Iter: 351 loss: 1.54419122e-05
Iter: 352 loss: 1.53946512e-05
Iter: 353 loss: 1.53696128e-05
Iter: 354 loss: 1.53622932e-05
Iter: 355 loss: 1.53472629e-05
Iter: 356 loss: 1.53129313e-05
Iter: 357 loss: 1.55018643e-05
Iter: 358 loss: 1.53081673e-05
Iter: 359 loss: 1.52750126e-05
Iter: 360 loss: 1.53428191e-05
Iter: 361 loss: 1.52615539e-05
Iter: 362 loss: 1.52330504e-05
Iter: 363 loss: 1.53825022e-05
Iter: 364 loss: 1.52284938e-05
Iter: 365 loss: 1.52041357e-05
Iter: 366 loss: 1.52199318e-05
Iter: 367 loss: 1.51887962e-05
Iter: 368 loss: 1.51530712e-05
Iter: 369 loss: 1.53646106e-05
Iter: 370 loss: 1.51486856e-05
Iter: 371 loss: 1.51259119e-05
Iter: 372 loss: 1.52016964e-05
Iter: 373 loss: 1.51199729e-05
Iter: 374 loss: 1.50946453e-05
Iter: 375 loss: 1.5100145e-05
Iter: 376 loss: 1.50765209e-05
Iter: 377 loss: 1.50447813e-05
Iter: 378 loss: 1.51062395e-05
Iter: 379 loss: 1.50322294e-05
Iter: 380 loss: 1.50040514e-05
Iter: 381 loss: 1.51381755e-05
Iter: 382 loss: 1.49986445e-05
Iter: 383 loss: 1.49745329e-05
Iter: 384 loss: 1.5285681e-05
Iter: 385 loss: 1.497432e-05
Iter: 386 loss: 1.49581501e-05
Iter: 387 loss: 1.49235193e-05
Iter: 388 loss: 1.54627742e-05
Iter: 389 loss: 1.49220232e-05
Iter: 390 loss: 1.48977115e-05
Iter: 391 loss: 1.48977233e-05
Iter: 392 loss: 1.48756117e-05
Iter: 393 loss: 1.4853581e-05
Iter: 394 loss: 1.48491199e-05
Iter: 395 loss: 1.48231611e-05
Iter: 396 loss: 1.50132355e-05
Iter: 397 loss: 1.482057e-05
Iter: 398 loss: 1.47980227e-05
Iter: 399 loss: 1.47680457e-05
Iter: 400 loss: 1.47665178e-05
Iter: 401 loss: 1.47340415e-05
Iter: 402 loss: 1.47343981e-05
Iter: 403 loss: 1.47082592e-05
Iter: 404 loss: 1.47924848e-05
Iter: 405 loss: 1.47011906e-05
Iter: 406 loss: 1.46777165e-05
Iter: 407 loss: 1.47570699e-05
Iter: 408 loss: 1.46710572e-05
Iter: 409 loss: 1.46479606e-05
Iter: 410 loss: 1.46767889e-05
Iter: 411 loss: 1.46359434e-05
Iter: 412 loss: 1.46096663e-05
Iter: 413 loss: 1.46476787e-05
Iter: 414 loss: 1.45968133e-05
Iter: 415 loss: 1.45728845e-05
Iter: 416 loss: 1.46484381e-05
Iter: 417 loss: 1.45660179e-05
Iter: 418 loss: 1.45412605e-05
Iter: 419 loss: 1.48046174e-05
Iter: 420 loss: 1.45404956e-05
Iter: 421 loss: 1.45210979e-05
Iter: 422 loss: 1.45047543e-05
Iter: 423 loss: 1.44996957e-05
Iter: 424 loss: 1.44753931e-05
Iter: 425 loss: 1.46441735e-05
Iter: 426 loss: 1.44731821e-05
Iter: 427 loss: 1.44565147e-05
Iter: 428 loss: 1.44322403e-05
Iter: 429 loss: 1.44318938e-05
Iter: 430 loss: 1.43994203e-05
Iter: 431 loss: 1.47722758e-05
Iter: 432 loss: 1.43987436e-05
Iter: 433 loss: 1.43747093e-05
Iter: 434 loss: 1.43947027e-05
Iter: 435 loss: 1.43604211e-05
Iter: 436 loss: 1.43366133e-05
Iter: 437 loss: 1.43403922e-05
Iter: 438 loss: 1.43186289e-05
Iter: 439 loss: 1.42835397e-05
Iter: 440 loss: 1.44148e-05
Iter: 441 loss: 1.42753233e-05
Iter: 442 loss: 1.42565195e-05
Iter: 443 loss: 1.42552071e-05
Iter: 444 loss: 1.42423032e-05
Iter: 445 loss: 1.42238669e-05
Iter: 446 loss: 1.42232129e-05
Iter: 447 loss: 1.41970177e-05
Iter: 448 loss: 1.42682584e-05
Iter: 449 loss: 1.41882119e-05
Iter: 450 loss: 1.4158597e-05
Iter: 451 loss: 1.4277306e-05
Iter: 452 loss: 1.41520859e-05
Iter: 453 loss: 1.41323681e-05
Iter: 454 loss: 1.43113166e-05
Iter: 455 loss: 1.41311839e-05
Iter: 456 loss: 1.41134951e-05
Iter: 457 loss: 1.41458568e-05
Iter: 458 loss: 1.4105849e-05
Iter: 459 loss: 1.40889279e-05
Iter: 460 loss: 1.40632592e-05
Iter: 461 loss: 1.40627117e-05
Iter: 462 loss: 1.40305547e-05
Iter: 463 loss: 1.418191e-05
Iter: 464 loss: 1.40245602e-05
Iter: 465 loss: 1.40016145e-05
Iter: 466 loss: 1.4162194e-05
Iter: 467 loss: 1.39992635e-05
Iter: 468 loss: 1.39764752e-05
Iter: 469 loss: 1.40068387e-05
Iter: 470 loss: 1.39650365e-05
Iter: 471 loss: 1.39437598e-05
Iter: 472 loss: 1.39778494e-05
Iter: 473 loss: 1.39339918e-05
Iter: 474 loss: 1.3906084e-05
Iter: 475 loss: 1.39974682e-05
Iter: 476 loss: 1.38980831e-05
Iter: 477 loss: 1.38751693e-05
Iter: 478 loss: 1.3889965e-05
Iter: 479 loss: 1.38607975e-05
Iter: 480 loss: 1.38363448e-05
Iter: 481 loss: 1.41298433e-05
Iter: 482 loss: 1.38358873e-05
Iter: 483 loss: 1.38145751e-05
Iter: 484 loss: 1.38329233e-05
Iter: 485 loss: 1.38015021e-05
Iter: 486 loss: 1.37822908e-05
Iter: 487 loss: 1.37843908e-05
Iter: 488 loss: 1.37672077e-05
Iter: 489 loss: 1.37519492e-05
Iter: 490 loss: 1.37510915e-05
Iter: 491 loss: 1.37346542e-05
Iter: 492 loss: 1.37262305e-05
Iter: 493 loss: 1.37182715e-05
Iter: 494 loss: 1.36977596e-05
Iter: 495 loss: 1.37601392e-05
Iter: 496 loss: 1.36914778e-05
Iter: 497 loss: 1.36709641e-05
Iter: 498 loss: 1.36999533e-05
Iter: 499 loss: 1.36608805e-05
Iter: 500 loss: 1.36371427e-05
Iter: 501 loss: 1.36578446e-05
Iter: 502 loss: 1.36234639e-05
Iter: 503 loss: 1.35978171e-05
Iter: 504 loss: 1.36502667e-05
Iter: 505 loss: 1.35870687e-05
Iter: 506 loss: 1.35613054e-05
Iter: 507 loss: 1.38484102e-05
Iter: 508 loss: 1.35606779e-05
Iter: 509 loss: 1.35410082e-05
Iter: 510 loss: 1.35413047e-05
Iter: 511 loss: 1.35252e-05
Iter: 512 loss: 1.35017317e-05
Iter: 513 loss: 1.35852988e-05
Iter: 514 loss: 1.34956354e-05
Iter: 515 loss: 1.34748925e-05
Iter: 516 loss: 1.35257296e-05
Iter: 517 loss: 1.34673301e-05
Iter: 518 loss: 1.34422398e-05
Iter: 519 loss: 1.36067956e-05
Iter: 520 loss: 1.34395214e-05
Iter: 521 loss: 1.34232941e-05
Iter: 522 loss: 1.34087022e-05
Iter: 523 loss: 1.34046813e-05
Iter: 524 loss: 1.33828471e-05
Iter: 525 loss: 1.36586386e-05
Iter: 526 loss: 1.33828489e-05
Iter: 527 loss: 1.33658714e-05
Iter: 528 loss: 1.34372831e-05
Iter: 529 loss: 1.33623525e-05
Iter: 530 loss: 1.33450994e-05
Iter: 531 loss: 1.33357144e-05
Iter: 532 loss: 1.33279927e-05
Iter: 533 loss: 1.33053563e-05
Iter: 534 loss: 1.33582e-05
Iter: 535 loss: 1.32966397e-05
Iter: 536 loss: 1.32771893e-05
Iter: 537 loss: 1.32807027e-05
Iter: 538 loss: 1.3262872e-05
Iter: 539 loss: 1.32343448e-05
Iter: 540 loss: 1.34565043e-05
Iter: 541 loss: 1.32323294e-05
Iter: 542 loss: 1.32115283e-05
Iter: 543 loss: 1.32761652e-05
Iter: 544 loss: 1.3205804e-05
Iter: 545 loss: 1.31866273e-05
Iter: 546 loss: 1.31759e-05
Iter: 547 loss: 1.31674487e-05
Iter: 548 loss: 1.31436809e-05
Iter: 549 loss: 1.35022419e-05
Iter: 550 loss: 1.31433426e-05
Iter: 551 loss: 1.31247725e-05
Iter: 552 loss: 1.31259494e-05
Iter: 553 loss: 1.31106135e-05
Iter: 554 loss: 1.3086059e-05
Iter: 555 loss: 1.3169255e-05
Iter: 556 loss: 1.30794879e-05
Iter: 557 loss: 1.30610115e-05
Iter: 558 loss: 1.32585319e-05
Iter: 559 loss: 1.3060584e-05
Iter: 560 loss: 1.30449744e-05
Iter: 561 loss: 1.30308417e-05
Iter: 562 loss: 1.30272074e-05
Iter: 563 loss: 1.30087137e-05
Iter: 564 loss: 1.32641162e-05
Iter: 565 loss: 1.30087938e-05
Iter: 566 loss: 1.299014e-05
Iter: 567 loss: 1.29977e-05
Iter: 568 loss: 1.29776272e-05
Iter: 569 loss: 1.29623277e-05
Iter: 570 loss: 1.29349892e-05
Iter: 571 loss: 1.29350756e-05
Iter: 572 loss: 1.29035579e-05
Iter: 573 loss: 1.30917397e-05
Iter: 574 loss: 1.28995744e-05
Iter: 575 loss: 1.28737775e-05
Iter: 576 loss: 1.30672752e-05
Iter: 577 loss: 1.28716456e-05
Iter: 578 loss: 1.28504362e-05
Iter: 579 loss: 1.28829124e-05
Iter: 580 loss: 1.28404681e-05
Iter: 581 loss: 1.28188458e-05
Iter: 582 loss: 1.28736301e-05
Iter: 583 loss: 1.28110196e-05
Iter: 584 loss: 1.27907788e-05
Iter: 585 loss: 1.29187e-05
Iter: 586 loss: 1.27888907e-05
Iter: 587 loss: 1.27703443e-05
Iter: 588 loss: 1.27697422e-05
Iter: 589 loss: 1.27555386e-05
Iter: 590 loss: 1.27325411e-05
Iter: 591 loss: 1.29007922e-05
Iter: 592 loss: 1.27306339e-05
Iter: 593 loss: 1.27098128e-05
Iter: 594 loss: 1.27350813e-05
Iter: 595 loss: 1.26989125e-05
Iter: 596 loss: 1.26808636e-05
Iter: 597 loss: 1.28431802e-05
Iter: 598 loss: 1.26797013e-05
Iter: 599 loss: 1.26634786e-05
Iter: 600 loss: 1.26602972e-05
Iter: 601 loss: 1.26491486e-05
Iter: 602 loss: 1.26321756e-05
Iter: 603 loss: 1.26320938e-05
Iter: 604 loss: 1.26223586e-05
Iter: 605 loss: 1.26032846e-05
Iter: 606 loss: 1.29796617e-05
Iter: 607 loss: 1.26030773e-05
Iter: 608 loss: 1.25766937e-05
Iter: 609 loss: 1.26317209e-05
Iter: 610 loss: 1.25664e-05
Iter: 611 loss: 1.2544222e-05
Iter: 612 loss: 1.25415499e-05
Iter: 613 loss: 1.25255938e-05
Iter: 614 loss: 1.24995731e-05
Iter: 615 loss: 1.27969452e-05
Iter: 616 loss: 1.24990493e-05
Iter: 617 loss: 1.24799535e-05
Iter: 618 loss: 1.2585464e-05
Iter: 619 loss: 1.24772214e-05
Iter: 620 loss: 1.2458373e-05
Iter: 621 loss: 1.2466001e-05
Iter: 622 loss: 1.24456983e-05
Iter: 623 loss: 1.24215821e-05
Iter: 624 loss: 1.25084844e-05
Iter: 625 loss: 1.24157486e-05
Iter: 626 loss: 1.23991122e-05
Iter: 627 loss: 1.25616898e-05
Iter: 628 loss: 1.23983573e-05
Iter: 629 loss: 1.23848085e-05
Iter: 630 loss: 1.23768e-05
Iter: 631 loss: 1.23709988e-05
Iter: 632 loss: 1.23520331e-05
Iter: 633 loss: 1.25653769e-05
Iter: 634 loss: 1.23516611e-05
Iter: 635 loss: 1.23387181e-05
Iter: 636 loss: 1.23592972e-05
Iter: 637 loss: 1.233279e-05
Iter: 638 loss: 1.23175723e-05
Iter: 639 loss: 1.23802138e-05
Iter: 640 loss: 1.23140562e-05
Iter: 641 loss: 1.23003974e-05
Iter: 642 loss: 1.22978763e-05
Iter: 643 loss: 1.22891333e-05
Iter: 644 loss: 1.22703468e-05
Iter: 645 loss: 1.23211103e-05
Iter: 646 loss: 1.2264416e-05
Iter: 647 loss: 1.22449419e-05
Iter: 648 loss: 1.22559122e-05
Iter: 649 loss: 1.22326464e-05
Iter: 650 loss: 1.22081237e-05
Iter: 651 loss: 1.22495385e-05
Iter: 652 loss: 1.21973371e-05
Iter: 653 loss: 1.21714584e-05
Iter: 654 loss: 1.2262979e-05
Iter: 655 loss: 1.21649737e-05
Iter: 656 loss: 1.21429694e-05
Iter: 657 loss: 1.21741714e-05
Iter: 658 loss: 1.21323583e-05
Iter: 659 loss: 1.21085259e-05
Iter: 660 loss: 1.22860765e-05
Iter: 661 loss: 1.21066678e-05
Iter: 662 loss: 1.20859968e-05
Iter: 663 loss: 1.22017263e-05
Iter: 664 loss: 1.20831201e-05
Iter: 665 loss: 1.20703135e-05
Iter: 666 loss: 1.20808963e-05
Iter: 667 loss: 1.20628174e-05
Iter: 668 loss: 1.20443865e-05
Iter: 669 loss: 1.21341136e-05
Iter: 670 loss: 1.20412624e-05
Iter: 671 loss: 1.20248442e-05
Iter: 672 loss: 1.20549576e-05
Iter: 673 loss: 1.20179429e-05
Iter: 674 loss: 1.20031345e-05
Iter: 675 loss: 1.21482881e-05
Iter: 676 loss: 1.20029217e-05
Iter: 677 loss: 1.19944625e-05
Iter: 678 loss: 1.19796969e-05
Iter: 679 loss: 1.19796878e-05
Iter: 680 loss: 1.1957326e-05
Iter: 681 loss: 1.20535951e-05
Iter: 682 loss: 1.19527576e-05
Iter: 683 loss: 1.19370434e-05
Iter: 684 loss: 1.19332963e-05
Iter: 685 loss: 1.19232736e-05
Iter: 686 loss: 1.18982443e-05
Iter: 687 loss: 1.19318165e-05
Iter: 688 loss: 1.18858352e-05
Iter: 689 loss: 1.18639209e-05
Iter: 690 loss: 1.2027067e-05
Iter: 691 loss: 1.18620483e-05
Iter: 692 loss: 1.18425414e-05
Iter: 693 loss: 1.19138258e-05
Iter: 694 loss: 1.18375247e-05
Iter: 695 loss: 1.18201369e-05
Iter: 696 loss: 1.18133812e-05
Iter: 697 loss: 1.18043044e-05
Iter: 698 loss: 1.17818345e-05
Iter: 699 loss: 1.20041859e-05
Iter: 700 loss: 1.1780955e-05
Iter: 701 loss: 1.17663276e-05
Iter: 702 loss: 1.18706221e-05
Iter: 703 loss: 1.17653981e-05
Iter: 704 loss: 1.17522814e-05
Iter: 705 loss: 1.17568889e-05
Iter: 706 loss: 1.17428e-05
Iter: 707 loss: 1.17255895e-05
Iter: 708 loss: 1.18412e-05
Iter: 709 loss: 1.17242762e-05
Iter: 710 loss: 1.17081636e-05
Iter: 711 loss: 1.17134077e-05
Iter: 712 loss: 1.16969222e-05
Iter: 713 loss: 1.16810452e-05
Iter: 714 loss: 1.18046091e-05
Iter: 715 loss: 1.16799047e-05
Iter: 716 loss: 1.16673673e-05
Iter: 717 loss: 1.16556475e-05
Iter: 718 loss: 1.16527717e-05
Iter: 719 loss: 1.16351966e-05
Iter: 720 loss: 1.16799838e-05
Iter: 721 loss: 1.16291994e-05
Iter: 722 loss: 1.16087249e-05
Iter: 723 loss: 1.17197242e-05
Iter: 724 loss: 1.16058764e-05
Iter: 725 loss: 1.15914117e-05
Iter: 726 loss: 1.15955536e-05
Iter: 727 loss: 1.15808834e-05
Iter: 728 loss: 1.15605417e-05
Iter: 729 loss: 1.15850562e-05
Iter: 730 loss: 1.15498442e-05
Iter: 731 loss: 1.15273497e-05
Iter: 732 loss: 1.15604544e-05
Iter: 733 loss: 1.15165722e-05
Iter: 734 loss: 1.14956247e-05
Iter: 735 loss: 1.17063792e-05
Iter: 736 loss: 1.14949144e-05
Iter: 737 loss: 1.14772702e-05
Iter: 738 loss: 1.15447374e-05
Iter: 739 loss: 1.14733029e-05
Iter: 740 loss: 1.14581198e-05
Iter: 741 loss: 1.15542844e-05
Iter: 742 loss: 1.14565537e-05
Iter: 743 loss: 1.14447221e-05
Iter: 744 loss: 1.14788654e-05
Iter: 745 loss: 1.14412596e-05
Iter: 746 loss: 1.14283157e-05
Iter: 747 loss: 1.14466238e-05
Iter: 748 loss: 1.14221202e-05
Iter: 749 loss: 1.140719e-05
Iter: 750 loss: 1.14377681e-05
Iter: 751 loss: 1.14013465e-05
Iter: 752 loss: 1.13856795e-05
Iter: 753 loss: 1.14033046e-05
Iter: 754 loss: 1.13775932e-05
Iter: 755 loss: 1.13622045e-05
Iter: 756 loss: 1.14578379e-05
Iter: 757 loss: 1.13605447e-05
Iter: 758 loss: 1.13475444e-05
Iter: 759 loss: 1.13355873e-05
Iter: 760 loss: 1.13324804e-05
Iter: 761 loss: 1.1310738e-05
Iter: 762 loss: 1.13804363e-05
Iter: 763 loss: 1.13045289e-05
Iter: 764 loss: 1.12871185e-05
Iter: 765 loss: 1.14247741e-05
Iter: 766 loss: 1.12856e-05
Iter: 767 loss: 1.1269708e-05
Iter: 768 loss: 1.12822545e-05
Iter: 769 loss: 1.1259961e-05
Iter: 770 loss: 1.12411826e-05
Iter: 771 loss: 1.12553598e-05
Iter: 772 loss: 1.12297594e-05
Iter: 773 loss: 1.12090602e-05
Iter: 774 loss: 1.12937332e-05
Iter: 775 loss: 1.120462e-05
Iter: 776 loss: 1.11895097e-05
Iter: 777 loss: 1.1317391e-05
Iter: 778 loss: 1.11886093e-05
Iter: 779 loss: 1.11713262e-05
Iter: 780 loss: 1.12046737e-05
Iter: 781 loss: 1.11640511e-05
Iter: 782 loss: 1.11534027e-05
Iter: 783 loss: 1.1227321e-05
Iter: 784 loss: 1.11524751e-05
Iter: 785 loss: 1.11406562e-05
Iter: 786 loss: 1.11182771e-05
Iter: 787 loss: 1.15979728e-05
Iter: 788 loss: 1.11183472e-05
Iter: 789 loss: 1.11015524e-05
Iter: 790 loss: 1.11015052e-05
Iter: 791 loss: 1.10898236e-05
Iter: 792 loss: 1.10955334e-05
Iter: 793 loss: 1.10824349e-05
Iter: 794 loss: 1.10652618e-05
Iter: 795 loss: 1.10655919e-05
Iter: 796 loss: 1.10517794e-05
Iter: 797 loss: 1.10323545e-05
Iter: 798 loss: 1.12069129e-05
Iter: 799 loss: 1.10315013e-05
Iter: 800 loss: 1.10175552e-05
Iter: 801 loss: 1.10361125e-05
Iter: 802 loss: 1.10103265e-05
Iter: 803 loss: 1.09938983e-05
Iter: 804 loss: 1.10094024e-05
Iter: 805 loss: 1.09840685e-05
Iter: 806 loss: 1.0965281e-05
Iter: 807 loss: 1.11154923e-05
Iter: 808 loss: 1.09638695e-05
Iter: 809 loss: 1.09502744e-05
Iter: 810 loss: 1.09701195e-05
Iter: 811 loss: 1.09436669e-05
Iter: 812 loss: 1.09268058e-05
Iter: 813 loss: 1.09314624e-05
Iter: 814 loss: 1.09145385e-05
Iter: 815 loss: 1.09042303e-05
Iter: 816 loss: 1.0902635e-05
Iter: 817 loss: 1.08914228e-05
Iter: 818 loss: 1.08817303e-05
Iter: 819 loss: 1.08787099e-05
Iter: 820 loss: 1.08656168e-05
Iter: 821 loss: 1.09394514e-05
Iter: 822 loss: 1.08638569e-05
Iter: 823 loss: 1.08492677e-05
Iter: 824 loss: 1.08621334e-05
Iter: 825 loss: 1.08412014e-05
Iter: 826 loss: 1.08270897e-05
Iter: 827 loss: 1.08335862e-05
Iter: 828 loss: 1.08176264e-05
Iter: 829 loss: 1.08044133e-05
Iter: 830 loss: 1.09545863e-05
Iter: 831 loss: 1.08040867e-05
Iter: 832 loss: 1.07912574e-05
Iter: 833 loss: 1.07817459e-05
Iter: 834 loss: 1.07775541e-05
Iter: 835 loss: 1.07597943e-05
Iter: 836 loss: 1.0787976e-05
Iter: 837 loss: 1.0751528e-05
Iter: 838 loss: 1.07341075e-05
Iter: 839 loss: 1.08431677e-05
Iter: 840 loss: 1.07318783e-05
Iter: 841 loss: 1.07145925e-05
Iter: 842 loss: 1.07610504e-05
Iter: 843 loss: 1.07082724e-05
Iter: 844 loss: 1.06938287e-05
Iter: 845 loss: 1.07086225e-05
Iter: 846 loss: 1.06852622e-05
Iter: 847 loss: 1.06705374e-05
Iter: 848 loss: 1.08140775e-05
Iter: 849 loss: 1.06697198e-05
Iter: 850 loss: 1.06593325e-05
Iter: 851 loss: 1.06987791e-05
Iter: 852 loss: 1.06566013e-05
Iter: 853 loss: 1.06440757e-05
Iter: 854 loss: 1.06683565e-05
Iter: 855 loss: 1.06384323e-05
Iter: 856 loss: 1.06245234e-05
Iter: 857 loss: 1.06255711e-05
Iter: 858 loss: 1.06137413e-05
Iter: 859 loss: 1.06010139e-05
Iter: 860 loss: 1.07310461e-05
Iter: 861 loss: 1.06006137e-05
Iter: 862 loss: 1.05898616e-05
Iter: 863 loss: 1.0599374e-05
Iter: 864 loss: 1.05837598e-05
Iter: 865 loss: 1.05714398e-05
Iter: 866 loss: 1.05600648e-05
Iter: 867 loss: 1.05568161e-05
Iter: 868 loss: 1.05399358e-05
Iter: 869 loss: 1.07182914e-05
Iter: 870 loss: 1.05395284e-05
Iter: 871 loss: 1.05252075e-05
Iter: 872 loss: 1.05677664e-05
Iter: 873 loss: 1.05206764e-05
Iter: 874 loss: 1.05076424e-05
Iter: 875 loss: 1.05114614e-05
Iter: 876 loss: 1.0497979e-05
Iter: 877 loss: 1.04808205e-05
Iter: 878 loss: 1.04979008e-05
Iter: 879 loss: 1.04709043e-05
Iter: 880 loss: 1.04523378e-05
Iter: 881 loss: 1.05585787e-05
Iter: 882 loss: 1.04499386e-05
Iter: 883 loss: 1.04345545e-05
Iter: 884 loss: 1.05370655e-05
Iter: 885 loss: 1.04327737e-05
Iter: 886 loss: 1.04189839e-05
Iter: 887 loss: 1.04333794e-05
Iter: 888 loss: 1.04114524e-05
Iter: 889 loss: 1.03997872e-05
Iter: 890 loss: 1.03995808e-05
Iter: 891 loss: 1.03928378e-05
Iter: 892 loss: 1.03770544e-05
Iter: 893 loss: 1.05535346e-05
Iter: 894 loss: 1.0375582e-05
Iter: 895 loss: 1.03587154e-05
Iter: 896 loss: 1.05597201e-05
Iter: 897 loss: 1.03585598e-05
Iter: 898 loss: 1.03458742e-05
Iter: 899 loss: 1.03685798e-05
Iter: 900 loss: 1.03402181e-05
Iter: 901 loss: 1.03256589e-05
Iter: 902 loss: 1.033642e-05
Iter: 903 loss: 1.03166913e-05
Iter: 904 loss: 1.02991989e-05
Iter: 905 loss: 1.0362136e-05
Iter: 906 loss: 1.0295098e-05
Iter: 907 loss: 1.02803824e-05
Iter: 908 loss: 1.02897975e-05
Iter: 909 loss: 1.02712529e-05
Iter: 910 loss: 1.02572703e-05
Iter: 911 loss: 1.04282763e-05
Iter: 912 loss: 1.02571139e-05
Iter: 913 loss: 1.02455388e-05
Iter: 914 loss: 1.02504819e-05
Iter: 915 loss: 1.0237537e-05
Iter: 916 loss: 1.02242448e-05
Iter: 917 loss: 1.02328522e-05
Iter: 918 loss: 1.02160529e-05
Iter: 919 loss: 1.01965679e-05
Iter: 920 loss: 1.02447175e-05
Iter: 921 loss: 1.01897758e-05
Iter: 922 loss: 1.01772293e-05
Iter: 923 loss: 1.02804706e-05
Iter: 924 loss: 1.01766909e-05
Iter: 925 loss: 1.01622418e-05
Iter: 926 loss: 1.02079202e-05
Iter: 927 loss: 1.01583755e-05
Iter: 928 loss: 1.01475362e-05
Iter: 929 loss: 1.01697669e-05
Iter: 930 loss: 1.01430851e-05
Iter: 931 loss: 1.01303085e-05
Iter: 932 loss: 1.012967e-05
Iter: 933 loss: 1.01201258e-05
Iter: 934 loss: 1.0106447e-05
Iter: 935 loss: 1.02032454e-05
Iter: 936 loss: 1.01050828e-05
Iter: 937 loss: 1.00936013e-05
Iter: 938 loss: 1.01406695e-05
Iter: 939 loss: 1.00908874e-05
Iter: 940 loss: 1.00810175e-05
Iter: 941 loss: 1.00664256e-05
Iter: 942 loss: 1.00660063e-05
Iter: 943 loss: 1.00482393e-05
Iter: 944 loss: 1.01330315e-05
Iter: 945 loss: 1.00451143e-05
Iter: 946 loss: 1.00300285e-05
Iter: 947 loss: 1.01452297e-05
Iter: 948 loss: 1.00288635e-05
Iter: 949 loss: 1.00167144e-05
Iter: 950 loss: 1.00257139e-05
Iter: 951 loss: 1.00093439e-05
Iter: 952 loss: 9.99525764e-06
Iter: 953 loss: 1.00580619e-05
Iter: 954 loss: 9.99239819e-06
Iter: 955 loss: 9.97788447e-06
Iter: 956 loss: 9.98584619e-06
Iter: 957 loss: 9.96874496e-06
Iter: 958 loss: 9.95282608e-06
Iter: 959 loss: 9.99151234e-06
Iter: 960 loss: 9.94705533e-06
Iter: 961 loss: 9.93977756e-06
Iter: 962 loss: 9.93875074e-06
Iter: 963 loss: 9.93058347e-06
Iter: 964 loss: 9.91650541e-06
Iter: 965 loss: 9.91652087e-06
Iter: 966 loss: 9.90418721e-06
Iter: 967 loss: 9.95775736e-06
Iter: 968 loss: 9.90185254e-06
Iter: 969 loss: 9.89002638e-06
Iter: 970 loss: 9.94032871e-06
Iter: 971 loss: 9.8872315e-06
Iter: 972 loss: 9.87617659e-06
Iter: 973 loss: 9.88980719e-06
Iter: 974 loss: 9.87045314e-06
Iter: 975 loss: 9.85704e-06
Iter: 976 loss: 9.91338675e-06
Iter: 977 loss: 9.85430233e-06
Iter: 978 loss: 9.84293e-06
Iter: 979 loss: 9.844136e-06
Iter: 980 loss: 9.8339433e-06
Iter: 981 loss: 9.81982521e-06
Iter: 982 loss: 9.83766768e-06
Iter: 983 loss: 9.81230733e-06
Iter: 984 loss: 9.79576544e-06
Iter: 985 loss: 9.87234853e-06
Iter: 986 loss: 9.79275501e-06
Iter: 987 loss: 9.77746367e-06
Iter: 988 loss: 9.86972918e-06
Iter: 989 loss: 9.77571108e-06
Iter: 990 loss: 9.76307274e-06
Iter: 991 loss: 9.76363208e-06
Iter: 992 loss: 9.75296643e-06
Iter: 993 loss: 9.739093e-06
Iter: 994 loss: 9.80615368e-06
Iter: 995 loss: 9.73651731e-06
Iter: 996 loss: 9.72465e-06
Iter: 997 loss: 9.79156357e-06
Iter: 998 loss: 9.72304406e-06
Iter: 999 loss: 9.71067493e-06
Iter: 1000 loss: 9.76230513e-06
Iter: 1001 loss: 9.70841211e-06
Iter: 1002 loss: 9.69821485e-06
Iter: 1003 loss: 9.70542715e-06
Iter: 1004 loss: 9.69196117e-06
Iter: 1005 loss: 9.68231325e-06
Iter: 1006 loss: 9.68433051e-06
Iter: 1007 loss: 9.67515643e-06
Iter: 1008 loss: 9.66292464e-06
Iter: 1009 loss: 9.7344755e-06
Iter: 1010 loss: 9.6615e-06
Iter: 1011 loss: 9.6485137e-06
Iter: 1012 loss: 9.68531276e-06
Iter: 1013 loss: 9.64451e-06
Iter: 1014 loss: 9.63403545e-06
Iter: 1015 loss: 9.63014463e-06
Iter: 1016 loss: 9.62455215e-06
Iter: 1017 loss: 9.60914349e-06
Iter: 1018 loss: 9.72727e-06
Iter: 1019 loss: 9.60790476e-06
Iter: 1020 loss: 9.5957912e-06
Iter: 1021 loss: 9.5944215e-06
Iter: 1022 loss: 9.58571127e-06
Iter: 1023 loss: 9.5719306e-06
Iter: 1024 loss: 9.59658155e-06
Iter: 1025 loss: 9.56609802e-06
Iter: 1026 loss: 9.54993357e-06
Iter: 1027 loss: 9.67745109e-06
Iter: 1028 loss: 9.54882398e-06
Iter: 1029 loss: 9.53861854e-06
Iter: 1030 loss: 9.59215e-06
Iter: 1031 loss: 9.53702875e-06
Iter: 1032 loss: 9.52778919e-06
Iter: 1033 loss: 9.51661514e-06
Iter: 1034 loss: 9.51555739e-06
Iter: 1035 loss: 9.5060177e-06
Iter: 1036 loss: 9.5046671e-06
Iter: 1037 loss: 9.4975e-06
Iter: 1038 loss: 9.48792876e-06
Iter: 1039 loss: 9.4872812e-06
Iter: 1040 loss: 9.47580884e-06
Iter: 1041 loss: 9.49705463e-06
Iter: 1042 loss: 9.47101853e-06
Iter: 1043 loss: 9.45737793e-06
Iter: 1044 loss: 9.50766298e-06
Iter: 1045 loss: 9.45404645e-06
Iter: 1046 loss: 9.4409861e-06
Iter: 1047 loss: 9.50164576e-06
Iter: 1048 loss: 9.43850864e-06
Iter: 1049 loss: 9.42911174e-06
Iter: 1050 loss: 9.48021443e-06
Iter: 1051 loss: 9.42761471e-06
Iter: 1052 loss: 9.41948929e-06
Iter: 1053 loss: 9.40495283e-06
Iter: 1054 loss: 9.75656167e-06
Iter: 1055 loss: 9.40502741e-06
Iter: 1056 loss: 9.39006168e-06
Iter: 1057 loss: 9.52135633e-06
Iter: 1058 loss: 9.38916e-06
Iter: 1059 loss: 9.37647746e-06
Iter: 1060 loss: 9.4293855e-06
Iter: 1061 loss: 9.37383084e-06
Iter: 1062 loss: 9.36268862e-06
Iter: 1063 loss: 9.35844764e-06
Iter: 1064 loss: 9.35268326e-06
Iter: 1065 loss: 9.33795945e-06
Iter: 1066 loss: 9.41948747e-06
Iter: 1067 loss: 9.33591946e-06
Iter: 1068 loss: 9.32389594e-06
Iter: 1069 loss: 9.42256156e-06
Iter: 1070 loss: 9.32286093e-06
Iter: 1071 loss: 9.31417e-06
Iter: 1072 loss: 9.33168667e-06
Iter: 1073 loss: 9.31041814e-06
Iter: 1074 loss: 9.29857924e-06
Iter: 1075 loss: 9.32725925e-06
Iter: 1076 loss: 9.29402631e-06
Iter: 1077 loss: 9.28533882e-06
Iter: 1078 loss: 9.28323789e-06
Iter: 1079 loss: 9.27747e-06
Iter: 1080 loss: 9.26642588e-06
Iter: 1081 loss: 9.27670317e-06
Iter: 1082 loss: 9.25963468e-06
Iter: 1083 loss: 9.24846154e-06
Iter: 1084 loss: 9.41290091e-06
Iter: 1085 loss: 9.24845517e-06
Iter: 1086 loss: 9.23801e-06
Iter: 1087 loss: 9.24100641e-06
Iter: 1088 loss: 9.23053449e-06
Iter: 1089 loss: 9.22021e-06
Iter: 1090 loss: 9.25205677e-06
Iter: 1091 loss: 9.21722e-06
Iter: 1092 loss: 9.20499588e-06
Iter: 1093 loss: 9.20930415e-06
Iter: 1094 loss: 9.19632475e-06
Iter: 1095 loss: 9.18314527e-06
Iter: 1096 loss: 9.26828307e-06
Iter: 1097 loss: 9.18151454e-06
Iter: 1098 loss: 9.17105899e-06
Iter: 1099 loss: 9.18136448e-06
Iter: 1100 loss: 9.16510908e-06
Iter: 1101 loss: 9.15084638e-06
Iter: 1102 loss: 9.20999628e-06
Iter: 1103 loss: 9.14734574e-06
Iter: 1104 loss: 9.13596523e-06
Iter: 1105 loss: 9.15932e-06
Iter: 1106 loss: 9.13156e-06
Iter: 1107 loss: 9.1235579e-06
Iter: 1108 loss: 9.12328323e-06
Iter: 1109 loss: 9.11734605e-06
Iter: 1110 loss: 9.11767347e-06
Iter: 1111 loss: 9.11263851e-06
Iter: 1112 loss: 9.10442e-06
Iter: 1113 loss: 9.11271854e-06
Iter: 1114 loss: 9.09960545e-06
Iter: 1115 loss: 9.087129e-06
Iter: 1116 loss: 9.08389575e-06
Iter: 1117 loss: 9.07621779e-06
Iter: 1118 loss: 9.06299829e-06
Iter: 1119 loss: 9.08894708e-06
Iter: 1120 loss: 9.05758952e-06
Iter: 1121 loss: 9.04739136e-06
Iter: 1122 loss: 9.04726949e-06
Iter: 1123 loss: 9.0381e-06
Iter: 1124 loss: 9.04604349e-06
Iter: 1125 loss: 9.03265664e-06
Iter: 1126 loss: 9.02171541e-06
Iter: 1127 loss: 9.01667499e-06
Iter: 1128 loss: 9.0116373e-06
Iter: 1129 loss: 8.99841507e-06
Iter: 1130 loss: 9.05735214e-06
Iter: 1131 loss: 8.99591396e-06
Iter: 1132 loss: 8.98265534e-06
Iter: 1133 loss: 9.0331614e-06
Iter: 1134 loss: 8.97964674e-06
Iter: 1135 loss: 8.9671521e-06
Iter: 1136 loss: 9.01947897e-06
Iter: 1137 loss: 8.9643072e-06
Iter: 1138 loss: 8.95614448e-06
Iter: 1139 loss: 8.97756945e-06
Iter: 1140 loss: 8.95305129e-06
Iter: 1141 loss: 8.94354343e-06
Iter: 1142 loss: 8.99560837e-06
Iter: 1143 loss: 8.94193181e-06
Iter: 1144 loss: 8.93181823e-06
Iter: 1145 loss: 8.94133791e-06
Iter: 1146 loss: 8.92564458e-06
Iter: 1147 loss: 8.9162113e-06
Iter: 1148 loss: 8.94694404e-06
Iter: 1149 loss: 8.9135865e-06
Iter: 1150 loss: 8.90377851e-06
Iter: 1151 loss: 8.90222145e-06
Iter: 1152 loss: 8.89550483e-06
Iter: 1153 loss: 8.88390423e-06
Iter: 1154 loss: 8.95316e-06
Iter: 1155 loss: 8.88279828e-06
Iter: 1156 loss: 8.87133e-06
Iter: 1157 loss: 8.88056638e-06
Iter: 1158 loss: 8.86448e-06
Iter: 1159 loss: 8.85578811e-06
Iter: 1160 loss: 8.92246499e-06
Iter: 1161 loss: 8.85507689e-06
Iter: 1162 loss: 8.8453844e-06
Iter: 1163 loss: 8.86054386e-06
Iter: 1164 loss: 8.84122164e-06
Iter: 1165 loss: 8.83178745e-06
Iter: 1166 loss: 8.82265522e-06
Iter: 1167 loss: 8.82057702e-06
Iter: 1168 loss: 8.80622065e-06
Iter: 1169 loss: 8.86540147e-06
Iter: 1170 loss: 8.80346215e-06
Iter: 1171 loss: 8.78936e-06
Iter: 1172 loss: 8.81111373e-06
Iter: 1173 loss: 8.78306855e-06
Iter: 1174 loss: 8.77390448e-06
Iter: 1175 loss: 8.77358616e-06
Iter: 1176 loss: 8.7657827e-06
Iter: 1177 loss: 8.77422644e-06
Iter: 1178 loss: 8.76136801e-06
Iter: 1179 loss: 8.75132537e-06
Iter: 1180 loss: 8.80466e-06
Iter: 1181 loss: 8.74999841e-06
Iter: 1182 loss: 8.74284524e-06
Iter: 1183 loss: 8.73951e-06
Iter: 1184 loss: 8.73609315e-06
Iter: 1185 loss: 8.72695091e-06
Iter: 1186 loss: 8.74910438e-06
Iter: 1187 loss: 8.7235785e-06
Iter: 1188 loss: 8.71124848e-06
Iter: 1189 loss: 8.737401e-06
Iter: 1190 loss: 8.70635085e-06
Iter: 1191 loss: 8.69590895e-06
Iter: 1192 loss: 8.70540316e-06
Iter: 1193 loss: 8.68969255e-06
Iter: 1194 loss: 8.67760536e-06
Iter: 1195 loss: 8.77202183e-06
Iter: 1196 loss: 8.67664585e-06
Iter: 1197 loss: 8.66701157e-06
Iter: 1198 loss: 8.70459371e-06
Iter: 1199 loss: 8.66479513e-06
Iter: 1200 loss: 8.65615584e-06
Iter: 1201 loss: 8.66280152e-06
Iter: 1202 loss: 8.6506534e-06
Iter: 1203 loss: 8.64105368e-06
Iter: 1204 loss: 8.67419476e-06
Iter: 1205 loss: 8.63858e-06
Iter: 1206 loss: 8.6285545e-06
Iter: 1207 loss: 8.62138404e-06
Iter: 1208 loss: 8.61837e-06
Iter: 1209 loss: 8.60427372e-06
Iter: 1210 loss: 8.69527594e-06
Iter: 1211 loss: 8.60295404e-06
Iter: 1212 loss: 8.59335705e-06
Iter: 1213 loss: 8.67296058e-06
Iter: 1214 loss: 8.59309876e-06
Iter: 1215 loss: 8.58356179e-06
Iter: 1216 loss: 8.61913e-06
Iter: 1217 loss: 8.58102794e-06
Iter: 1218 loss: 8.574405e-06
Iter: 1219 loss: 8.5680349e-06
Iter: 1220 loss: 8.56658335e-06
Iter: 1221 loss: 8.55591497e-06
Iter: 1222 loss: 8.64202e-06
Iter: 1223 loss: 8.55520284e-06
Iter: 1224 loss: 8.54681457e-06
Iter: 1225 loss: 8.53727852e-06
Iter: 1226 loss: 8.53618258e-06
Iter: 1227 loss: 8.52491667e-06
Iter: 1228 loss: 8.64381946e-06
Iter: 1229 loss: 8.52469111e-06
Iter: 1230 loss: 8.51493132e-06
Iter: 1231 loss: 8.53526217e-06
Iter: 1232 loss: 8.51118784e-06
Iter: 1233 loss: 8.50115248e-06
Iter: 1234 loss: 8.5156e-06
Iter: 1235 loss: 8.49613934e-06
Iter: 1236 loss: 8.486968e-06
Iter: 1237 loss: 8.60008095e-06
Iter: 1238 loss: 8.48678883e-06
Iter: 1239 loss: 8.48021591e-06
Iter: 1240 loss: 8.46848e-06
Iter: 1241 loss: 8.46851071e-06
Iter: 1242 loss: 8.45555223e-06
Iter: 1243 loss: 8.52450648e-06
Iter: 1244 loss: 8.45324757e-06
Iter: 1245 loss: 8.44297e-06
Iter: 1246 loss: 8.47025149e-06
Iter: 1247 loss: 8.43952694e-06
Iter: 1248 loss: 8.4291969e-06
Iter: 1249 loss: 8.48624495e-06
Iter: 1250 loss: 8.42788722e-06
Iter: 1251 loss: 8.418996e-06
Iter: 1252 loss: 8.48394666e-06
Iter: 1253 loss: 8.41841e-06
Iter: 1254 loss: 8.41090787e-06
Iter: 1255 loss: 8.41873316e-06
Iter: 1256 loss: 8.40679604e-06
Iter: 1257 loss: 8.39939e-06
Iter: 1258 loss: 8.38853794e-06
Iter: 1259 loss: 8.3884e-06
Iter: 1260 loss: 8.37763e-06
Iter: 1261 loss: 8.50804827e-06
Iter: 1262 loss: 8.37765219e-06
Iter: 1263 loss: 8.36860909e-06
Iter: 1264 loss: 8.39642507e-06
Iter: 1265 loss: 8.36605614e-06
Iter: 1266 loss: 8.35695937e-06
Iter: 1267 loss: 8.35334504e-06
Iter: 1268 loss: 8.34832281e-06
Iter: 1269 loss: 8.33770173e-06
Iter: 1270 loss: 8.43627367e-06
Iter: 1271 loss: 8.33719696e-06
Iter: 1272 loss: 8.3280429e-06
Iter: 1273 loss: 8.36480285e-06
Iter: 1274 loss: 8.32596561e-06
Iter: 1275 loss: 8.31889702e-06
Iter: 1276 loss: 8.32437672e-06
Iter: 1277 loss: 8.31440775e-06
Iter: 1278 loss: 8.30494719e-06
Iter: 1279 loss: 8.33917602e-06
Iter: 1280 loss: 8.30267891e-06
Iter: 1281 loss: 8.29317378e-06
Iter: 1282 loss: 8.29049259e-06
Iter: 1283 loss: 8.28486191e-06
Iter: 1284 loss: 8.27457643e-06
Iter: 1285 loss: 8.29576e-06
Iter: 1286 loss: 8.2706365e-06
Iter: 1287 loss: 8.26247742e-06
Iter: 1288 loss: 8.26226824e-06
Iter: 1289 loss: 8.25409279e-06
Iter: 1290 loss: 8.24814197e-06
Iter: 1291 loss: 8.24544077e-06
Iter: 1292 loss: 8.23610389e-06
Iter: 1293 loss: 8.24557719e-06
Iter: 1294 loss: 8.23082e-06
Iter: 1295 loss: 8.2201168e-06
Iter: 1296 loss: 8.26425e-06
Iter: 1297 loss: 8.21807225e-06
Iter: 1298 loss: 8.20882724e-06
Iter: 1299 loss: 8.25615462e-06
Iter: 1300 loss: 8.20743298e-06
Iter: 1301 loss: 8.19889192e-06
Iter: 1302 loss: 8.20444438e-06
Iter: 1303 loss: 8.19341585e-06
Iter: 1304 loss: 8.18457193e-06
Iter: 1305 loss: 8.25453e-06
Iter: 1306 loss: 8.18388e-06
Iter: 1307 loss: 8.17680211e-06
Iter: 1308 loss: 8.18281e-06
Iter: 1309 loss: 8.17253385e-06
Iter: 1310 loss: 8.16341526e-06
Iter: 1311 loss: 8.2076e-06
Iter: 1312 loss: 8.16178e-06
Iter: 1313 loss: 8.15290878e-06
Iter: 1314 loss: 8.15237672e-06
Iter: 1315 loss: 8.14565647e-06
Iter: 1316 loss: 8.13525367e-06
Iter: 1317 loss: 8.17390446e-06
Iter: 1318 loss: 8.13286715e-06
Iter: 1319 loss: 8.12441704e-06
Iter: 1320 loss: 8.16202191e-06
Iter: 1321 loss: 8.12272083e-06
Iter: 1322 loss: 8.1135222e-06
Iter: 1323 loss: 8.12379e-06
Iter: 1324 loss: 8.10816164e-06
Iter: 1325 loss: 8.10203164e-06
Iter: 1326 loss: 8.10188794e-06
Iter: 1327 loss: 8.09592166e-06
Iter: 1328 loss: 8.08633376e-06
Iter: 1329 loss: 8.08619552e-06
Iter: 1330 loss: 8.07697415e-06
Iter: 1331 loss: 8.06906246e-06
Iter: 1332 loss: 8.06638e-06
Iter: 1333 loss: 8.05414311e-06
Iter: 1334 loss: 8.21669892e-06
Iter: 1335 loss: 8.05393393e-06
Iter: 1336 loss: 8.04507e-06
Iter: 1337 loss: 8.06507705e-06
Iter: 1338 loss: 8.04172487e-06
Iter: 1339 loss: 8.03105831e-06
Iter: 1340 loss: 8.09006e-06
Iter: 1341 loss: 8.02947761e-06
Iter: 1342 loss: 8.02202248e-06
Iter: 1343 loss: 8.02719842e-06
Iter: 1344 loss: 8.01753777e-06
Iter: 1345 loss: 8.00884118e-06
Iter: 1346 loss: 8.08676396e-06
Iter: 1347 loss: 8.00831549e-06
Iter: 1348 loss: 8.00166345e-06
Iter: 1349 loss: 7.99854388e-06
Iter: 1350 loss: 7.99525878e-06
Iter: 1351 loss: 7.98503879e-06
Iter: 1352 loss: 7.99990084e-06
Iter: 1353 loss: 7.98015481e-06
Iter: 1354 loss: 7.97002212e-06
Iter: 1355 loss: 8.03762669e-06
Iter: 1356 loss: 7.96886161e-06
Iter: 1357 loss: 7.95969208e-06
Iter: 1358 loss: 7.98408564e-06
Iter: 1359 loss: 7.95661526e-06
Iter: 1360 loss: 7.94983e-06
Iter: 1361 loss: 8.04089e-06
Iter: 1362 loss: 7.94979405e-06
Iter: 1363 loss: 7.94403059e-06
Iter: 1364 loss: 7.93647268e-06
Iter: 1365 loss: 7.93630534e-06
Iter: 1366 loss: 7.92612718e-06
Iter: 1367 loss: 7.94188418e-06
Iter: 1368 loss: 7.92151423e-06
Iter: 1369 loss: 7.91045204e-06
Iter: 1370 loss: 7.9663414e-06
Iter: 1371 loss: 7.90852e-06
Iter: 1372 loss: 7.89959631e-06
Iter: 1373 loss: 7.9038773e-06
Iter: 1374 loss: 7.89342e-06
Iter: 1375 loss: 7.8834255e-06
Iter: 1376 loss: 7.90342e-06
Iter: 1377 loss: 7.87921726e-06
Iter: 1378 loss: 7.86934652e-06
Iter: 1379 loss: 7.99232294e-06
Iter: 1380 loss: 7.86925284e-06
Iter: 1381 loss: 7.86121564e-06
Iter: 1382 loss: 7.87402587e-06
Iter: 1383 loss: 7.85746397e-06
Iter: 1384 loss: 7.84974145e-06
Iter: 1385 loss: 7.86268083e-06
Iter: 1386 loss: 7.84620079e-06
Iter: 1387 loss: 7.83648e-06
Iter: 1388 loss: 7.8750254e-06
Iter: 1389 loss: 7.83430278e-06
Iter: 1390 loss: 7.82566894e-06
Iter: 1391 loss: 7.81964081e-06
Iter: 1392 loss: 7.81648941e-06
Iter: 1393 loss: 7.80628e-06
Iter: 1394 loss: 7.892344e-06
Iter: 1395 loss: 7.80565097e-06
Iter: 1396 loss: 7.79837501e-06
Iter: 1397 loss: 7.89482237e-06
Iter: 1398 loss: 7.798355e-06
Iter: 1399 loss: 7.79266702e-06
Iter: 1400 loss: 7.7847335e-06
Iter: 1401 loss: 7.78439608e-06
Iter: 1402 loss: 7.77510922e-06
Iter: 1403 loss: 7.81670497e-06
Iter: 1404 loss: 7.77360583e-06
Iter: 1405 loss: 7.76469096e-06
Iter: 1406 loss: 7.7862187e-06
Iter: 1407 loss: 7.76171782e-06
Iter: 1408 loss: 7.7536406e-06
Iter: 1409 loss: 7.75525405e-06
Iter: 1410 loss: 7.74772889e-06
Iter: 1411 loss: 7.73618e-06
Iter: 1412 loss: 7.75121953e-06
Iter: 1413 loss: 7.73076317e-06
Iter: 1414 loss: 7.72133e-06
Iter: 1415 loss: 7.8198882e-06
Iter: 1416 loss: 7.72105523e-06
Iter: 1417 loss: 7.71182931e-06
Iter: 1418 loss: 7.74433283e-06
Iter: 1419 loss: 7.70938095e-06
Iter: 1420 loss: 7.70152838e-06
Iter: 1421 loss: 7.70676e-06
Iter: 1422 loss: 7.69671715e-06
Iter: 1423 loss: 7.68931659e-06
Iter: 1424 loss: 7.76854267e-06
Iter: 1425 loss: 7.68912651e-06
Iter: 1426 loss: 7.68303653e-06
Iter: 1427 loss: 7.67202e-06
Iter: 1428 loss: 7.93519212e-06
Iter: 1429 loss: 7.67197344e-06
Iter: 1430 loss: 7.66340781e-06
Iter: 1431 loss: 7.66334233e-06
Iter: 1432 loss: 7.65826735e-06
Iter: 1433 loss: 7.68509381e-06
Iter: 1434 loss: 7.65714503e-06
Iter: 1435 loss: 7.651548e-06
Iter: 1436 loss: 7.65272307e-06
Iter: 1437 loss: 7.6474289e-06
Iter: 1438 loss: 7.6400911e-06
Iter: 1439 loss: 7.64108154e-06
Iter: 1440 loss: 7.63461867e-06
Iter: 1441 loss: 7.62603395e-06
Iter: 1442 loss: 7.64158813e-06
Iter: 1443 loss: 7.62233776e-06
Iter: 1444 loss: 7.61341562e-06
Iter: 1445 loss: 7.66284575e-06
Iter: 1446 loss: 7.61218e-06
Iter: 1447 loss: 7.60244e-06
Iter: 1448 loss: 7.61553e-06
Iter: 1449 loss: 7.59753402e-06
Iter: 1450 loss: 7.58914484e-06
Iter: 1451 loss: 7.60262719e-06
Iter: 1452 loss: 7.5851508e-06
Iter: 1453 loss: 7.5753178e-06
Iter: 1454 loss: 7.61622687e-06
Iter: 1455 loss: 7.57336056e-06
Iter: 1456 loss: 7.56588224e-06
Iter: 1457 loss: 7.6532333e-06
Iter: 1458 loss: 7.56581267e-06
Iter: 1459 loss: 7.55976453e-06
Iter: 1460 loss: 7.55436031e-06
Iter: 1461 loss: 7.55304427e-06
Iter: 1462 loss: 7.54509119e-06
Iter: 1463 loss: 7.57106636e-06
Iter: 1464 loss: 7.54296616e-06
Iter: 1465 loss: 7.53458289e-06
Iter: 1466 loss: 7.58734495e-06
Iter: 1467 loss: 7.53361701e-06
Iter: 1468 loss: 7.52669803e-06
Iter: 1469 loss: 7.54353869e-06
Iter: 1470 loss: 7.52415417e-06
Iter: 1471 loss: 7.51745756e-06
Iter: 1472 loss: 7.5685557e-06
Iter: 1473 loss: 7.51694961e-06
Iter: 1474 loss: 7.51256e-06
Iter: 1475 loss: 7.5017324e-06
Iter: 1476 loss: 7.62851505e-06
Iter: 1477 loss: 7.50065647e-06
Iter: 1478 loss: 7.48977345e-06
Iter: 1479 loss: 7.56501458e-06
Iter: 1480 loss: 7.48867797e-06
Iter: 1481 loss: 7.47971308e-06
Iter: 1482 loss: 7.48582534e-06
Iter: 1483 loss: 7.47410422e-06
Iter: 1484 loss: 7.46537e-06
Iter: 1485 loss: 7.60332932e-06
Iter: 1486 loss: 7.465218e-06
Iter: 1487 loss: 7.45808529e-06
Iter: 1488 loss: 7.45323814e-06
Iter: 1489 loss: 7.45032685e-06
Iter: 1490 loss: 7.44167073e-06
Iter: 1491 loss: 7.48352522e-06
Iter: 1492 loss: 7.44011277e-06
Iter: 1493 loss: 7.43157943e-06
Iter: 1494 loss: 7.48729599e-06
Iter: 1495 loss: 7.43063038e-06
Iter: 1496 loss: 7.42376233e-06
Iter: 1497 loss: 7.43845794e-06
Iter: 1498 loss: 7.42144039e-06
Iter: 1499 loss: 7.41387294e-06
Iter: 1500 loss: 7.42357497e-06
Iter: 1501 loss: 7.41001077e-06
Iter: 1502 loss: 7.40299402e-06
Iter: 1503 loss: 7.42216116e-06
Iter: 1504 loss: 7.40051291e-06
Iter: 1505 loss: 7.3933179e-06
Iter: 1506 loss: 7.42325301e-06
Iter: 1507 loss: 7.39151528e-06
Iter: 1508 loss: 7.38369135e-06
Iter: 1509 loss: 7.4245645e-06
Iter: 1510 loss: 7.38222434e-06
Iter: 1511 loss: 7.37749451e-06
Iter: 1512 loss: 7.37532082e-06
Iter: 1513 loss: 7.37285609e-06
Iter: 1514 loss: 7.36466882e-06
Iter: 1515 loss: 7.3983656e-06
Iter: 1516 loss: 7.36289485e-06
Iter: 1517 loss: 7.35660888e-06
Iter: 1518 loss: 7.35378944e-06
Iter: 1519 loss: 7.35036201e-06
Iter: 1520 loss: 7.33981551e-06
Iter: 1521 loss: 7.35592948e-06
Iter: 1522 loss: 7.33477964e-06
Iter: 1523 loss: 7.32410808e-06
Iter: 1524 loss: 7.34863215e-06
Iter: 1525 loss: 7.32005901e-06
Iter: 1526 loss: 7.30857073e-06
Iter: 1527 loss: 7.34140804e-06
Iter: 1528 loss: 7.30496367e-06
Iter: 1529 loss: 7.29950352e-06
Iter: 1530 loss: 7.29908697e-06
Iter: 1531 loss: 7.29344538e-06
Iter: 1532 loss: 7.28832492e-06
Iter: 1533 loss: 7.28689201e-06
Iter: 1534 loss: 7.27797169e-06
Iter: 1535 loss: 7.35053663e-06
Iter: 1536 loss: 7.27723545e-06
Iter: 1537 loss: 7.27119732e-06
Iter: 1538 loss: 7.27701354e-06
Iter: 1539 loss: 7.26739654e-06
Iter: 1540 loss: 7.26033068e-06
Iter: 1541 loss: 7.28046643e-06
Iter: 1542 loss: 7.25830341e-06
Iter: 1543 loss: 7.25037808e-06
Iter: 1544 loss: 7.30955799e-06
Iter: 1545 loss: 7.24996607e-06
Iter: 1546 loss: 7.24447727e-06
Iter: 1547 loss: 7.24485881e-06
Iter: 1548 loss: 7.24047231e-06
Iter: 1549 loss: 7.23295216e-06
Iter: 1550 loss: 7.24013307e-06
Iter: 1551 loss: 7.22858e-06
Iter: 1552 loss: 7.22017194e-06
Iter: 1553 loss: 7.227879e-06
Iter: 1554 loss: 7.21556262e-06
Iter: 1555 loss: 7.20628213e-06
Iter: 1556 loss: 7.25232485e-06
Iter: 1557 loss: 7.20469825e-06
Iter: 1558 loss: 7.19737454e-06
Iter: 1559 loss: 7.26464714e-06
Iter: 1560 loss: 7.19683976e-06
Iter: 1561 loss: 7.19153195e-06
Iter: 1562 loss: 7.18491538e-06
Iter: 1563 loss: 7.18448518e-06
Iter: 1564 loss: 7.17526564e-06
Iter: 1565 loss: 7.21428296e-06
Iter: 1566 loss: 7.17324883e-06
Iter: 1567 loss: 7.16486602e-06
Iter: 1568 loss: 7.17907642e-06
Iter: 1569 loss: 7.16144768e-06
Iter: 1570 loss: 7.15321858e-06
Iter: 1571 loss: 7.20858e-06
Iter: 1572 loss: 7.15245596e-06
Iter: 1573 loss: 7.14497583e-06
Iter: 1574 loss: 7.1956465e-06
Iter: 1575 loss: 7.14416592e-06
Iter: 1576 loss: 7.1396571e-06
Iter: 1577 loss: 7.1322529e-06
Iter: 1578 loss: 7.13221561e-06
Iter: 1579 loss: 7.1259351e-06
Iter: 1580 loss: 7.12548263e-06
Iter: 1581 loss: 7.12060228e-06
Iter: 1582 loss: 7.11629264e-06
Iter: 1583 loss: 7.11539406e-06
Iter: 1584 loss: 7.10911763e-06
Iter: 1585 loss: 7.11989378e-06
Iter: 1586 loss: 7.10621589e-06
Iter: 1587 loss: 7.09835513e-06
Iter: 1588 loss: 7.11620851e-06
Iter: 1589 loss: 7.0956803e-06
Iter: 1590 loss: 7.08746393e-06
Iter: 1591 loss: 7.09383e-06
Iter: 1592 loss: 7.08269272e-06
Iter: 1593 loss: 7.07464278e-06
Iter: 1594 loss: 7.15305305e-06
Iter: 1595 loss: 7.07436766e-06
Iter: 1596 loss: 7.06750234e-06
Iter: 1597 loss: 7.07152594e-06
Iter: 1598 loss: 7.06300943e-06
Iter: 1599 loss: 7.0543183e-06
Iter: 1600 loss: 7.07868503e-06
Iter: 1601 loss: 7.05170351e-06
Iter: 1602 loss: 7.04462127e-06
Iter: 1603 loss: 7.07721392e-06
Iter: 1604 loss: 7.04345e-06
Iter: 1605 loss: 7.03641535e-06
Iter: 1606 loss: 7.05175898e-06
Iter: 1607 loss: 7.03350452e-06
Iter: 1608 loss: 7.02608304e-06
Iter: 1609 loss: 7.02468787e-06
Iter: 1610 loss: 7.01981162e-06
Iter: 1611 loss: 7.01190902e-06
Iter: 1612 loss: 7.12304336e-06
Iter: 1613 loss: 7.01172485e-06
Iter: 1614 loss: 7.00602686e-06
Iter: 1615 loss: 7.03914247e-06
Iter: 1616 loss: 7.00547389e-06
Iter: 1617 loss: 7.00119563e-06
Iter: 1618 loss: 7.00211149e-06
Iter: 1619 loss: 6.99800876e-06
Iter: 1620 loss: 6.99085422e-06
Iter: 1621 loss: 7.0160072e-06
Iter: 1622 loss: 6.98895246e-06
Iter: 1623 loss: 6.98394615e-06
Iter: 1624 loss: 6.97455516e-06
Iter: 1625 loss: 7.19269565e-06
Iter: 1626 loss: 6.97454607e-06
Iter: 1627 loss: 6.96556253e-06
Iter: 1628 loss: 7.01439058e-06
Iter: 1629 loss: 6.96428e-06
Iter: 1630 loss: 6.95515791e-06
Iter: 1631 loss: 6.96797451e-06
Iter: 1632 loss: 6.95052722e-06
Iter: 1633 loss: 6.94181108e-06
Iter: 1634 loss: 7.04650938e-06
Iter: 1635 loss: 6.94158643e-06
Iter: 1636 loss: 6.93604397e-06
Iter: 1637 loss: 6.93536276e-06
Iter: 1638 loss: 6.93126231e-06
Iter: 1639 loss: 6.92224e-06
Iter: 1640 loss: 6.93732591e-06
Iter: 1641 loss: 6.91827927e-06
Iter: 1642 loss: 6.91192463e-06
Iter: 1643 loss: 6.91183732e-06
Iter: 1644 loss: 6.90684192e-06
Iter: 1645 loss: 6.9035259e-06
Iter: 1646 loss: 6.90180696e-06
Iter: 1647 loss: 6.89391618e-06
Iter: 1648 loss: 6.91943751e-06
Iter: 1649 loss: 6.89176341e-06
Iter: 1650 loss: 6.88337423e-06
Iter: 1651 loss: 6.94867822e-06
Iter: 1652 loss: 6.88273622e-06
Iter: 1653 loss: 6.87793909e-06
Iter: 1654 loss: 6.893516e-06
Iter: 1655 loss: 6.87662441e-06
Iter: 1656 loss: 6.87099191e-06
Iter: 1657 loss: 6.87808506e-06
Iter: 1658 loss: 6.86829253e-06
Iter: 1659 loss: 6.86303338e-06
Iter: 1660 loss: 6.87617057e-06
Iter: 1661 loss: 6.86107796e-06
Iter: 1662 loss: 6.855229e-06
Iter: 1663 loss: 6.86509929e-06
Iter: 1664 loss: 6.85243458e-06
Iter: 1665 loss: 6.84628958e-06
Iter: 1666 loss: 6.85322539e-06
Iter: 1667 loss: 6.84301403e-06
Iter: 1668 loss: 6.8358413e-06
Iter: 1669 loss: 6.833307e-06
Iter: 1670 loss: 6.8294562e-06
Iter: 1671 loss: 6.81995107e-06
Iter: 1672 loss: 6.86324711e-06
Iter: 1673 loss: 6.81812344e-06
Iter: 1674 loss: 6.80971243e-06
Iter: 1675 loss: 6.84009956e-06
Iter: 1676 loss: 6.80756511e-06
Iter: 1677 loss: 6.79920686e-06
Iter: 1678 loss: 6.8417562e-06
Iter: 1679 loss: 6.7977262e-06
Iter: 1680 loss: 6.79095501e-06
Iter: 1681 loss: 6.80935773e-06
Iter: 1682 loss: 6.78867445e-06
Iter: 1683 loss: 6.7815763e-06
Iter: 1684 loss: 6.78572087e-06
Iter: 1685 loss: 6.77709249e-06
Iter: 1686 loss: 6.76992977e-06
Iter: 1687 loss: 6.8510335e-06
Iter: 1688 loss: 6.76996706e-06
Iter: 1689 loss: 6.76394302e-06
Iter: 1690 loss: 6.78231117e-06
Iter: 1691 loss: 6.7618671e-06
Iter: 1692 loss: 6.75652063e-06
Iter: 1693 loss: 6.78686411e-06
Iter: 1694 loss: 6.75583169e-06
Iter: 1695 loss: 6.75164711e-06
Iter: 1696 loss: 6.74620105e-06
Iter: 1697 loss: 6.74573675e-06
Iter: 1698 loss: 6.73898376e-06
Iter: 1699 loss: 6.79936738e-06
Iter: 1700 loss: 6.73840805e-06
Iter: 1701 loss: 6.73326622e-06
Iter: 1702 loss: 6.74464127e-06
Iter: 1703 loss: 6.73106842e-06
Iter: 1704 loss: 6.72497526e-06
Iter: 1705 loss: 6.7208648e-06
Iter: 1706 loss: 6.71878115e-06
Iter: 1707 loss: 6.71310045e-06
Iter: 1708 loss: 6.71301132e-06
Iter: 1709 loss: 6.70839927e-06
Iter: 1710 loss: 6.70074223e-06
Iter: 1711 loss: 6.7009064e-06
Iter: 1712 loss: 6.69245856e-06
Iter: 1713 loss: 6.72363421e-06
Iter: 1714 loss: 6.69028577e-06
Iter: 1715 loss: 6.68213579e-06
Iter: 1716 loss: 6.69408792e-06
Iter: 1717 loss: 6.67813356e-06
Iter: 1718 loss: 6.66869755e-06
Iter: 1719 loss: 6.69345809e-06
Iter: 1720 loss: 6.66595406e-06
Iter: 1721 loss: 6.65770722e-06
Iter: 1722 loss: 6.71758744e-06
Iter: 1723 loss: 6.65719745e-06
Iter: 1724 loss: 6.65034077e-06
Iter: 1725 loss: 6.67778386e-06
Iter: 1726 loss: 6.64881918e-06
Iter: 1727 loss: 6.64207619e-06
Iter: 1728 loss: 6.68468465e-06
Iter: 1729 loss: 6.64122808e-06
Iter: 1730 loss: 6.63546143e-06
Iter: 1731 loss: 6.64172967e-06
Iter: 1732 loss: 6.63217543e-06
Iter: 1733 loss: 6.62736466e-06
Iter: 1734 loss: 6.62656748e-06
Iter: 1735 loss: 6.62338152e-06
Iter: 1736 loss: 6.61680315e-06
Iter: 1737 loss: 6.68087705e-06
Iter: 1738 loss: 6.6165353e-06
Iter: 1739 loss: 6.61102285e-06
Iter: 1740 loss: 6.61455852e-06
Iter: 1741 loss: 6.60750266e-06
Iter: 1742 loss: 6.60117803e-06
Iter: 1743 loss: 6.61907279e-06
Iter: 1744 loss: 6.59925763e-06
Iter: 1745 loss: 6.59287707e-06
Iter: 1746 loss: 6.60579963e-06
Iter: 1747 loss: 6.5901404e-06
Iter: 1748 loss: 6.58289446e-06
Iter: 1749 loss: 6.58764657e-06
Iter: 1750 loss: 6.57811597e-06
Iter: 1751 loss: 6.57011697e-06
Iter: 1752 loss: 6.57876899e-06
Iter: 1753 loss: 6.56549128e-06
Iter: 1754 loss: 6.55673921e-06
Iter: 1755 loss: 6.60708156e-06
Iter: 1756 loss: 6.55539088e-06
Iter: 1757 loss: 6.54928863e-06
Iter: 1758 loss: 6.60319301e-06
Iter: 1759 loss: 6.54906034e-06
Iter: 1760 loss: 6.54311816e-06
Iter: 1761 loss: 6.54622363e-06
Iter: 1762 loss: 6.5392851e-06
Iter: 1763 loss: 6.53274856e-06
Iter: 1764 loss: 6.54157429e-06
Iter: 1765 loss: 6.52934295e-06
Iter: 1766 loss: 6.52396557e-06
Iter: 1767 loss: 6.52382187e-06
Iter: 1768 loss: 6.51969913e-06
Iter: 1769 loss: 6.51483833e-06
Iter: 1770 loss: 6.51442951e-06
Iter: 1771 loss: 6.50780521e-06
Iter: 1772 loss: 6.51109804e-06
Iter: 1773 loss: 6.5033546e-06
Iter: 1774 loss: 6.4964197e-06
Iter: 1775 loss: 6.57604778e-06
Iter: 1776 loss: 6.49622598e-06
Iter: 1777 loss: 6.4910455e-06
Iter: 1778 loss: 6.50471975e-06
Iter: 1779 loss: 6.48925061e-06
Iter: 1780 loss: 6.4832725e-06
Iter: 1781 loss: 6.49332287e-06
Iter: 1782 loss: 6.48075684e-06
Iter: 1783 loss: 6.47427532e-06
Iter: 1784 loss: 6.47836532e-06
Iter: 1785 loss: 6.47018e-06
Iter: 1786 loss: 6.46302442e-06
Iter: 1787 loss: 6.48553805e-06
Iter: 1788 loss: 6.46100034e-06
Iter: 1789 loss: 6.45507589e-06
Iter: 1790 loss: 6.48081823e-06
Iter: 1791 loss: 6.45360615e-06
Iter: 1792 loss: 6.44764123e-06
Iter: 1793 loss: 6.46859871e-06
Iter: 1794 loss: 6.44587544e-06
Iter: 1795 loss: 6.44039756e-06
Iter: 1796 loss: 6.43286876e-06
Iter: 1797 loss: 6.43231715e-06
Iter: 1798 loss: 6.42349323e-06
Iter: 1799 loss: 6.49211506e-06
Iter: 1800 loss: 6.4226665e-06
Iter: 1801 loss: 6.41882298e-06
Iter: 1802 loss: 6.41844508e-06
Iter: 1803 loss: 6.41411316e-06
Iter: 1804 loss: 6.40660255e-06
Iter: 1805 loss: 6.40668077e-06
Iter: 1806 loss: 6.39927384e-06
Iter: 1807 loss: 6.44661577e-06
Iter: 1808 loss: 6.39851442e-06
Iter: 1809 loss: 6.39322e-06
Iter: 1810 loss: 6.41708175e-06
Iter: 1811 loss: 6.39216614e-06
Iter: 1812 loss: 6.38771689e-06
Iter: 1813 loss: 6.38328402e-06
Iter: 1814 loss: 6.38229358e-06
Iter: 1815 loss: 6.37677067e-06
Iter: 1816 loss: 6.44658439e-06
Iter: 1817 loss: 6.3766056e-06
Iter: 1818 loss: 6.37118228e-06
Iter: 1819 loss: 6.37641733e-06
Iter: 1820 loss: 6.36798814e-06
Iter: 1821 loss: 6.36202e-06
Iter: 1822 loss: 6.36719778e-06
Iter: 1823 loss: 6.35821743e-06
Iter: 1824 loss: 6.35178822e-06
Iter: 1825 loss: 6.37481935e-06
Iter: 1826 loss: 6.35003198e-06
Iter: 1827 loss: 6.34347498e-06
Iter: 1828 loss: 6.35998595e-06
Iter: 1829 loss: 6.34119715e-06
Iter: 1830 loss: 6.33448508e-06
Iter: 1831 loss: 6.34473326e-06
Iter: 1832 loss: 6.3312e-06
Iter: 1833 loss: 6.32399633e-06
Iter: 1834 loss: 6.34042635e-06
Iter: 1835 loss: 6.32127967e-06
Iter: 1836 loss: 6.3161051e-06
Iter: 1837 loss: 6.38383881e-06
Iter: 1838 loss: 6.31603962e-06
Iter: 1839 loss: 6.31083094e-06
Iter: 1840 loss: 6.31752209e-06
Iter: 1841 loss: 6.30838622e-06
Iter: 1842 loss: 6.30240856e-06
Iter: 1843 loss: 6.33481659e-06
Iter: 1844 loss: 6.30145951e-06
Iter: 1845 loss: 6.29723581e-06
Iter: 1846 loss: 6.29213355e-06
Iter: 1847 loss: 6.29189e-06
Iter: 1848 loss: 6.28499311e-06
Iter: 1849 loss: 6.29229908e-06
Iter: 1850 loss: 6.28106091e-06
Iter: 1851 loss: 6.2736367e-06
Iter: 1852 loss: 6.33330274e-06
Iter: 1853 loss: 6.27290547e-06
Iter: 1854 loss: 6.2677309e-06
Iter: 1855 loss: 6.31267267e-06
Iter: 1856 loss: 6.26736619e-06
Iter: 1857 loss: 6.2624058e-06
Iter: 1858 loss: 6.2585e-06
Iter: 1859 loss: 6.25702e-06
Iter: 1860 loss: 6.25143366e-06
Iter: 1861 loss: 6.30983141e-06
Iter: 1862 loss: 6.25121811e-06
Iter: 1863 loss: 6.24626955e-06
Iter: 1864 loss: 6.24658514e-06
Iter: 1865 loss: 6.24219092e-06
Iter: 1866 loss: 6.23655069e-06
Iter: 1867 loss: 6.25040502e-06
Iter: 1868 loss: 6.23444066e-06
Iter: 1869 loss: 6.22784955e-06
Iter: 1870 loss: 6.2248364e-06
Iter: 1871 loss: 6.22144853e-06
Iter: 1872 loss: 6.21424e-06
Iter: 1873 loss: 6.27062036e-06
Iter: 1874 loss: 6.21355866e-06
Iter: 1875 loss: 6.20641e-06
Iter: 1876 loss: 6.23893948e-06
Iter: 1877 loss: 6.20517494e-06
Iter: 1878 loss: 6.2000654e-06
Iter: 1879 loss: 6.23517735e-06
Iter: 1880 loss: 6.19969251e-06
Iter: 1881 loss: 6.19461434e-06
Iter: 1882 loss: 6.21002528e-06
Iter: 1883 loss: 6.19320826e-06
Iter: 1884 loss: 6.189347e-06
Iter: 1885 loss: 6.1877281e-06
Iter: 1886 loss: 6.18575405e-06
Iter: 1887 loss: 6.18049125e-06
Iter: 1888 loss: 6.19459252e-06
Iter: 1889 loss: 6.17876503e-06
Iter: 1890 loss: 6.1720234e-06
Iter: 1891 loss: 6.18818285e-06
Iter: 1892 loss: 6.16962643e-06
Iter: 1893 loss: 6.16376201e-06
Iter: 1894 loss: 6.16872512e-06
Iter: 1895 loss: 6.16044963e-06
Iter: 1896 loss: 6.1540577e-06
Iter: 1897 loss: 6.18418653e-06
Iter: 1898 loss: 6.15298e-06
Iter: 1899 loss: 6.14750707e-06
Iter: 1900 loss: 6.19683124e-06
Iter: 1901 loss: 6.14732426e-06
Iter: 1902 loss: 6.14258624e-06
Iter: 1903 loss: 6.14098553e-06
Iter: 1904 loss: 6.13837392e-06
Iter: 1905 loss: 6.13343764e-06
Iter: 1906 loss: 6.14289593e-06
Iter: 1907 loss: 6.1312694e-06
Iter: 1908 loss: 6.12455233e-06
Iter: 1909 loss: 6.13072598e-06
Iter: 1910 loss: 6.12078748e-06
Iter: 1911 loss: 6.11374526e-06
Iter: 1912 loss: 6.21032905e-06
Iter: 1913 loss: 6.11370342e-06
Iter: 1914 loss: 6.10940879e-06
Iter: 1915 loss: 6.10621373e-06
Iter: 1916 loss: 6.10488041e-06
Iter: 1917 loss: 6.09875315e-06
Iter: 1918 loss: 6.13081784e-06
Iter: 1919 loss: 6.09801646e-06
Iter: 1920 loss: 6.09150084e-06
Iter: 1921 loss: 6.14149076e-06
Iter: 1922 loss: 6.09096242e-06
Iter: 1923 loss: 6.08790197e-06
Iter: 1924 loss: 6.0827947e-06
Iter: 1925 loss: 6.08275332e-06
Iter: 1926 loss: 6.07562561e-06
Iter: 1927 loss: 6.08838673e-06
Iter: 1928 loss: 6.07267702e-06
Iter: 1929 loss: 6.06528283e-06
Iter: 1930 loss: 6.12533e-06
Iter: 1931 loss: 6.06453523e-06
Iter: 1932 loss: 6.05960895e-06
Iter: 1933 loss: 6.06787808e-06
Iter: 1934 loss: 6.05736204e-06
Iter: 1935 loss: 6.05187734e-06
Iter: 1936 loss: 6.06626918e-06
Iter: 1937 loss: 6.04992056e-06
Iter: 1938 loss: 6.04401248e-06
Iter: 1939 loss: 6.06613776e-06
Iter: 1940 loss: 6.04265324e-06
Iter: 1941 loss: 6.03723902e-06
Iter: 1942 loss: 6.05436708e-06
Iter: 1943 loss: 6.03563967e-06
Iter: 1944 loss: 6.03087847e-06
Iter: 1945 loss: 6.05909e-06
Iter: 1946 loss: 6.0303646e-06
Iter: 1947 loss: 6.02601267e-06
Iter: 1948 loss: 6.02241425e-06
Iter: 1949 loss: 6.02135242e-06
Iter: 1950 loss: 6.01493321e-06
Iter: 1951 loss: 6.02747468e-06
Iter: 1952 loss: 6.01240208e-06
Iter: 1953 loss: 6.00557723e-06
Iter: 1954 loss: 6.01903139e-06
Iter: 1955 loss: 6.00287603e-06
Iter: 1956 loss: 5.99889154e-06
Iter: 1957 loss: 5.99848772e-06
Iter: 1958 loss: 5.99466739e-06
Iter: 1959 loss: 5.99522718e-06
Iter: 1960 loss: 5.99170153e-06
Iter: 1961 loss: 5.98767338e-06
Iter: 1962 loss: 5.99576e-06
Iter: 1963 loss: 5.98588758e-06
Iter: 1964 loss: 5.98031511e-06
Iter: 1965 loss: 5.98572478e-06
Iter: 1966 loss: 5.97727603e-06
Iter: 1967 loss: 5.97207872e-06
Iter: 1968 loss: 5.97451617e-06
Iter: 1969 loss: 5.96871087e-06
Iter: 1970 loss: 5.96230166e-06
Iter: 1971 loss: 5.98765291e-06
Iter: 1972 loss: 5.96084e-06
Iter: 1973 loss: 5.95461279e-06
Iter: 1974 loss: 5.97030157e-06
Iter: 1975 loss: 5.95243682e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.8/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi3
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi3
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi3 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi3
+ date
Sun Nov  8 11:52:09 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi3/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi2.8/300_100_100_100_1 --function f2 --psi 0 --alpha 3 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi3/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b169ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b169510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077afc78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077afc7a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077afc7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077afeca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077af737b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0759accd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077af77488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0759a5f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0759a538c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0759a536a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0759a4ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b007510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b00f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b00f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b00f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f073410e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f073410e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b00f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0734042d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0734066840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0734066620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07599d17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f077b128d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07599d1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07207dbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07207db950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07207ad488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07206d8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07206d87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f07206d8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0720751158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0720772ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f072077a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0720681598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.007363064
test_loss: 0.009680675
train_loss: 0.00706197
test_loss: 0.0095467
train_loss: 0.007790008
test_loss: 0.009810481
train_loss: 0.006796211
test_loss: 0.009406491
train_loss: 0.0070986566
test_loss: 0.009542948
train_loss: 0.0072596585
test_loss: 0.0094843805
train_loss: 0.007074305
test_loss: 0.00968303
train_loss: 0.008291642
test_loss: 0.009578235
train_loss: 0.008613493
test_loss: 0.011744113
train_loss: 0.0067462437
test_loss: 0.009645898
train_loss: 0.0069731665
test_loss: 0.009786213
train_loss: 0.006726994
test_loss: 0.009421838
train_loss: 0.006547486
test_loss: 0.009670007
train_loss: 0.00666187
test_loss: 0.009406467
train_loss: 0.0064856606
test_loss: 0.009310244
train_loss: 0.006671309
test_loss: 0.009220112
train_loss: 0.007228599
test_loss: 0.009942772
train_loss: 0.006950997
test_loss: 0.009439643
train_loss: 0.007598105
test_loss: 0.010269127
train_loss: 0.00683639
test_loss: 0.00977319
train_loss: 0.006797743
test_loss: 0.009213693
train_loss: 0.0067135203
test_loss: 0.009257106
train_loss: 0.0068178065
test_loss: 0.00949641
train_loss: 0.0065033007
test_loss: 0.009258645
train_loss: 0.006433313
test_loss: 0.009139969
train_loss: 0.0064757504
test_loss: 0.009195324
train_loss: 0.007006334
test_loss: 0.009340389
train_loss: 0.0070080347
test_loss: 0.00957798
train_loss: 0.006287926
test_loss: 0.009448751
train_loss: 0.006709786
test_loss: 0.009307601
train_loss: 0.0061606835
test_loss: 0.009041042
train_loss: 0.0065033794
test_loss: 0.009254175
train_loss: 0.0067106904
test_loss: 0.009367385
train_loss: 0.0063954107
test_loss: 0.0091975955
train_loss: 0.0062165996
test_loss: 0.0091102915
train_loss: 0.006367849
test_loss: 0.009432028
train_loss: 0.0067341663
test_loss: 0.009492571
train_loss: 0.0064229816
test_loss: 0.00916557
train_loss: 0.0065938868
test_loss: 0.009122676
train_loss: 0.0063882433
test_loss: 0.009258279
train_loss: 0.0064399745
test_loss: 0.009313196
train_loss: 0.0066794106
test_loss: 0.009308579
train_loss: 0.006276274
test_loss: 0.009109642
train_loss: 0.006491998
test_loss: 0.0091645485
train_loss: 0.006370998
test_loss: 0.009361547
train_loss: 0.006746618
test_loss: 0.009276306
train_loss: 0.0062901145
test_loss: 0.009264696
train_loss: 0.0064041098
test_loss: 0.009009161
train_loss: 0.0064459513
test_loss: 0.009230767
train_loss: 0.006167043
test_loss: 0.009194104
train_loss: 0.0062902737
test_loss: 0.008990022
train_loss: 0.006575724
test_loss: 0.0096460385
train_loss: 0.0061007794
test_loss: 0.009017119
train_loss: 0.0067354953
test_loss: 0.0090336995
train_loss: 0.0066306004
test_loss: 0.009167678
train_loss: 0.00636772
test_loss: 0.0091627
train_loss: 0.0063792774
test_loss: 0.009283962
train_loss: 0.006195307
test_loss: 0.008989573
train_loss: 0.0064555546
test_loss: 0.009137517
train_loss: 0.0064134635
test_loss: 0.009126392
train_loss: 0.006120153
test_loss: 0.009042396
train_loss: 0.0063892524
test_loss: 0.009089045
train_loss: 0.0060798973
test_loss: 0.009017225
train_loss: 0.006114806
test_loss: 0.008988846
train_loss: 0.0064055235
test_loss: 0.009035744
train_loss: 0.0066159535
test_loss: 0.009093081
train_loss: 0.006179076
test_loss: 0.009188797
train_loss: 0.0061891275
test_loss: 0.009073268
train_loss: 0.0059655067
test_loss: 0.009180119
train_loss: 0.0063251154
test_loss: 0.009023664
train_loss: 0.0062679653
test_loss: 0.008880332
train_loss: 0.00608254
test_loss: 0.009142308
train_loss: 0.0061417855
test_loss: 0.009084588
train_loss: 0.0059997467
test_loss: 0.00910882
train_loss: 0.0061840005
test_loss: 0.009208383
train_loss: 0.006012028
test_loss: 0.00897686
train_loss: 0.0059891557
test_loss: 0.009136253
train_loss: 0.006205862
test_loss: 0.008918749
train_loss: 0.006035851
test_loss: 0.009288073
train_loss: 0.0061106253
test_loss: 0.009031106
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi3/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi3/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 0 --alpha 3 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi0_phi3/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98ee9e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98eeb4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98ee74950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98ee74620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98ee41950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98ee20d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff986026d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff98605ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff986062268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985ff6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff986026378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9860046a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985ff6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985fa1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985fa1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985fa1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985f21488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985eac730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985edeae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985ede2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985e2f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985e53048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985def510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985e53a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985deff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff985e1a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff93394c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff933905268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9339056a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff93387b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff93389d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff93389db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff933845488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff90c105378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff90c101730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff90c101840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 6.27879635e-05
Iter: 2 loss: 5.56998057e-05
Iter: 3 loss: 7.3617739e-05
Iter: 4 loss: 5.31342339e-05
Iter: 5 loss: 4.87907419e-05
Iter: 6 loss: 5.31864207e-05
Iter: 7 loss: 4.63700235e-05
Iter: 8 loss: 4.14722381e-05
Iter: 9 loss: 8.04002048e-05
Iter: 10 loss: 4.11371511e-05
Iter: 11 loss: 3.79991397e-05
Iter: 12 loss: 4.15975228e-05
Iter: 13 loss: 3.63169929e-05
Iter: 14 loss: 3.41094346e-05
Iter: 15 loss: 5.64064285e-05
Iter: 16 loss: 3.40422121e-05
Iter: 17 loss: 3.2776119e-05
Iter: 18 loss: 3.39839535e-05
Iter: 19 loss: 3.20503495e-05
Iter: 20 loss: 3.06916299e-05
Iter: 21 loss: 3.40828628e-05
Iter: 22 loss: 3.02152766e-05
Iter: 23 loss: 2.90024e-05
Iter: 24 loss: 3.46981105e-05
Iter: 25 loss: 2.87799467e-05
Iter: 26 loss: 2.78791704e-05
Iter: 27 loss: 2.89278687e-05
Iter: 28 loss: 2.73985897e-05
Iter: 29 loss: 2.65657127e-05
Iter: 30 loss: 3.52174175e-05
Iter: 31 loss: 2.65425242e-05
Iter: 32 loss: 2.59887565e-05
Iter: 33 loss: 2.54429815e-05
Iter: 34 loss: 2.53264552e-05
Iter: 35 loss: 2.44466773e-05
Iter: 36 loss: 3.07799746e-05
Iter: 37 loss: 2.43690083e-05
Iter: 38 loss: 2.3963672e-05
Iter: 39 loss: 2.81518969e-05
Iter: 40 loss: 2.39523833e-05
Iter: 41 loss: 2.36009473e-05
Iter: 42 loss: 2.44021394e-05
Iter: 43 loss: 2.3468685e-05
Iter: 44 loss: 2.30992282e-05
Iter: 45 loss: 2.479457e-05
Iter: 46 loss: 2.30287078e-05
Iter: 47 loss: 2.27256241e-05
Iter: 48 loss: 2.3169694e-05
Iter: 49 loss: 2.25799486e-05
Iter: 50 loss: 2.23302886e-05
Iter: 51 loss: 2.33145656e-05
Iter: 52 loss: 2.22730632e-05
Iter: 53 loss: 2.19957728e-05
Iter: 54 loss: 2.21779846e-05
Iter: 55 loss: 2.18209407e-05
Iter: 56 loss: 2.154912e-05
Iter: 57 loss: 2.23730531e-05
Iter: 58 loss: 2.14675983e-05
Iter: 59 loss: 2.12228988e-05
Iter: 60 loss: 2.25754629e-05
Iter: 61 loss: 2.11878214e-05
Iter: 62 loss: 2.09939662e-05
Iter: 63 loss: 2.1070864e-05
Iter: 64 loss: 2.08595447e-05
Iter: 65 loss: 2.0639829e-05
Iter: 66 loss: 2.22783547e-05
Iter: 67 loss: 2.06224395e-05
Iter: 68 loss: 2.04338e-05
Iter: 69 loss: 2.05618853e-05
Iter: 70 loss: 2.03156851e-05
Iter: 71 loss: 2.01411749e-05
Iter: 72 loss: 2.04460484e-05
Iter: 73 loss: 2.006469e-05
Iter: 74 loss: 1.98757371e-05
Iter: 75 loss: 2.16555582e-05
Iter: 76 loss: 1.98681864e-05
Iter: 77 loss: 1.97145237e-05
Iter: 78 loss: 2.03393e-05
Iter: 79 loss: 1.96804031e-05
Iter: 80 loss: 1.95693501e-05
Iter: 81 loss: 2.01636612e-05
Iter: 82 loss: 1.9552308e-05
Iter: 83 loss: 1.94669447e-05
Iter: 84 loss: 1.94229324e-05
Iter: 85 loss: 1.93834148e-05
Iter: 86 loss: 1.92474417e-05
Iter: 87 loss: 1.9819312e-05
Iter: 88 loss: 1.92186599e-05
Iter: 89 loss: 1.90955743e-05
Iter: 90 loss: 1.94016284e-05
Iter: 91 loss: 1.90520987e-05
Iter: 92 loss: 1.89496586e-05
Iter: 93 loss: 1.9056095e-05
Iter: 94 loss: 1.8893e-05
Iter: 95 loss: 1.87700789e-05
Iter: 96 loss: 1.93393553e-05
Iter: 97 loss: 1.87474961e-05
Iter: 98 loss: 1.86283542e-05
Iter: 99 loss: 1.87327496e-05
Iter: 100 loss: 1.8558665e-05
Iter: 101 loss: 1.84477067e-05
Iter: 102 loss: 1.9206218e-05
Iter: 103 loss: 1.84370128e-05
Iter: 104 loss: 1.83439788e-05
Iter: 105 loss: 1.84903529e-05
Iter: 106 loss: 1.83005177e-05
Iter: 107 loss: 1.81965333e-05
Iter: 108 loss: 1.83028606e-05
Iter: 109 loss: 1.8138322e-05
Iter: 110 loss: 1.80636198e-05
Iter: 111 loss: 1.80634761e-05
Iter: 112 loss: 1.79930903e-05
Iter: 113 loss: 1.80917923e-05
Iter: 114 loss: 1.79581584e-05
Iter: 115 loss: 1.7883689e-05
Iter: 116 loss: 1.81035884e-05
Iter: 117 loss: 1.78611153e-05
Iter: 118 loss: 1.77918282e-05
Iter: 119 loss: 1.79206854e-05
Iter: 120 loss: 1.77620441e-05
Iter: 121 loss: 1.7697017e-05
Iter: 122 loss: 1.78661721e-05
Iter: 123 loss: 1.76745398e-05
Iter: 124 loss: 1.76038066e-05
Iter: 125 loss: 1.78371665e-05
Iter: 126 loss: 1.75842597e-05
Iter: 127 loss: 1.75279183e-05
Iter: 128 loss: 1.75161331e-05
Iter: 129 loss: 1.74792e-05
Iter: 130 loss: 1.74032521e-05
Iter: 131 loss: 1.79980416e-05
Iter: 132 loss: 1.73978278e-05
Iter: 133 loss: 1.73351e-05
Iter: 134 loss: 1.73990484e-05
Iter: 135 loss: 1.73000026e-05
Iter: 136 loss: 1.72316395e-05
Iter: 137 loss: 1.74800243e-05
Iter: 138 loss: 1.72144755e-05
Iter: 139 loss: 1.71494903e-05
Iter: 140 loss: 1.73025473e-05
Iter: 141 loss: 1.71259526e-05
Iter: 142 loss: 1.70608437e-05
Iter: 143 loss: 1.72819382e-05
Iter: 144 loss: 1.7043134e-05
Iter: 145 loss: 1.69942159e-05
Iter: 146 loss: 1.72673044e-05
Iter: 147 loss: 1.69875184e-05
Iter: 148 loss: 1.69292216e-05
Iter: 149 loss: 1.70493477e-05
Iter: 150 loss: 1.69060186e-05
Iter: 151 loss: 1.68620281e-05
Iter: 152 loss: 1.69799841e-05
Iter: 153 loss: 1.68478655e-05
Iter: 154 loss: 1.68003407e-05
Iter: 155 loss: 1.68730367e-05
Iter: 156 loss: 1.67779945e-05
Iter: 157 loss: 1.67254748e-05
Iter: 158 loss: 1.68316838e-05
Iter: 159 loss: 1.67043709e-05
Iter: 160 loss: 1.66535974e-05
Iter: 161 loss: 1.68961706e-05
Iter: 162 loss: 1.66445207e-05
Iter: 163 loss: 1.6598231e-05
Iter: 164 loss: 1.65986748e-05
Iter: 165 loss: 1.65611418e-05
Iter: 166 loss: 1.65062884e-05
Iter: 167 loss: 1.6688402e-05
Iter: 168 loss: 1.64905596e-05
Iter: 169 loss: 1.64387548e-05
Iter: 170 loss: 1.68164424e-05
Iter: 171 loss: 1.6434471e-05
Iter: 172 loss: 1.63972363e-05
Iter: 173 loss: 1.63801178e-05
Iter: 174 loss: 1.63616751e-05
Iter: 175 loss: 1.63072218e-05
Iter: 176 loss: 1.66260706e-05
Iter: 177 loss: 1.63001932e-05
Iter: 178 loss: 1.6251106e-05
Iter: 179 loss: 1.63614295e-05
Iter: 180 loss: 1.62323322e-05
Iter: 181 loss: 1.61955068e-05
Iter: 182 loss: 1.65923157e-05
Iter: 183 loss: 1.619455e-05
Iter: 184 loss: 1.6158443e-05
Iter: 185 loss: 1.61766839e-05
Iter: 186 loss: 1.61338703e-05
Iter: 187 loss: 1.60982836e-05
Iter: 188 loss: 1.61851422e-05
Iter: 189 loss: 1.60854634e-05
Iter: 190 loss: 1.60473719e-05
Iter: 191 loss: 1.61701391e-05
Iter: 192 loss: 1.60366089e-05
Iter: 193 loss: 1.59984484e-05
Iter: 194 loss: 1.60279851e-05
Iter: 195 loss: 1.59751198e-05
Iter: 196 loss: 1.59327319e-05
Iter: 197 loss: 1.61346688e-05
Iter: 198 loss: 1.59253213e-05
Iter: 199 loss: 1.58865951e-05
Iter: 200 loss: 1.59435403e-05
Iter: 201 loss: 1.58678267e-05
Iter: 202 loss: 1.58267649e-05
Iter: 203 loss: 1.58191e-05
Iter: 204 loss: 1.57912582e-05
Iter: 205 loss: 1.57412742e-05
Iter: 206 loss: 1.64422836e-05
Iter: 207 loss: 1.57414215e-05
Iter: 208 loss: 1.57063459e-05
Iter: 209 loss: 1.56929636e-05
Iter: 210 loss: 1.56741553e-05
Iter: 211 loss: 1.56240767e-05
Iter: 212 loss: 1.57955346e-05
Iter: 213 loss: 1.56100923e-05
Iter: 214 loss: 1.55714279e-05
Iter: 215 loss: 1.59769115e-05
Iter: 216 loss: 1.55701346e-05
Iter: 217 loss: 1.55447669e-05
Iter: 218 loss: 1.56636888e-05
Iter: 219 loss: 1.55399775e-05
Iter: 220 loss: 1.5509333e-05
Iter: 221 loss: 1.54936079e-05
Iter: 222 loss: 1.54796253e-05
Iter: 223 loss: 1.54449535e-05
Iter: 224 loss: 1.55773778e-05
Iter: 225 loss: 1.54364079e-05
Iter: 226 loss: 1.54028403e-05
Iter: 227 loss: 1.55358939e-05
Iter: 228 loss: 1.53951241e-05
Iter: 229 loss: 1.53627516e-05
Iter: 230 loss: 1.53633118e-05
Iter: 231 loss: 1.53364945e-05
Iter: 232 loss: 1.53019173e-05
Iter: 233 loss: 1.56144633e-05
Iter: 234 loss: 1.53003439e-05
Iter: 235 loss: 1.52725806e-05
Iter: 236 loss: 1.52732628e-05
Iter: 237 loss: 1.52505299e-05
Iter: 238 loss: 1.52133671e-05
Iter: 239 loss: 1.52895154e-05
Iter: 240 loss: 1.5198566e-05
Iter: 241 loss: 1.51633794e-05
Iter: 242 loss: 1.54321642e-05
Iter: 243 loss: 1.51607328e-05
Iter: 244 loss: 1.51321419e-05
Iter: 245 loss: 1.51533923e-05
Iter: 246 loss: 1.51143167e-05
Iter: 247 loss: 1.50766191e-05
Iter: 248 loss: 1.51201384e-05
Iter: 249 loss: 1.50565884e-05
Iter: 250 loss: 1.50286905e-05
Iter: 251 loss: 1.50286123e-05
Iter: 252 loss: 1.50056767e-05
Iter: 253 loss: 1.50578271e-05
Iter: 254 loss: 1.49970128e-05
Iter: 255 loss: 1.49705156e-05
Iter: 256 loss: 1.49801472e-05
Iter: 257 loss: 1.49523257e-05
Iter: 258 loss: 1.49212228e-05
Iter: 259 loss: 1.49855005e-05
Iter: 260 loss: 1.49090611e-05
Iter: 261 loss: 1.48797408e-05
Iter: 262 loss: 1.50770084e-05
Iter: 263 loss: 1.48766339e-05
Iter: 264 loss: 1.48514719e-05
Iter: 265 loss: 1.48579729e-05
Iter: 266 loss: 1.48331746e-05
Iter: 267 loss: 1.48023073e-05
Iter: 268 loss: 1.48530307e-05
Iter: 269 loss: 1.47882456e-05
Iter: 270 loss: 1.4751482e-05
Iter: 271 loss: 1.49811412e-05
Iter: 272 loss: 1.47470564e-05
Iter: 273 loss: 1.47245164e-05
Iter: 274 loss: 1.4699207e-05
Iter: 275 loss: 1.46959583e-05
Iter: 276 loss: 1.46606626e-05
Iter: 277 loss: 1.51124304e-05
Iter: 278 loss: 1.46609527e-05
Iter: 279 loss: 1.46339135e-05
Iter: 280 loss: 1.46460134e-05
Iter: 281 loss: 1.46156481e-05
Iter: 282 loss: 1.45868398e-05
Iter: 283 loss: 1.46975508e-05
Iter: 284 loss: 1.45801087e-05
Iter: 285 loss: 1.45554222e-05
Iter: 286 loss: 1.47561068e-05
Iter: 287 loss: 1.45539834e-05
Iter: 288 loss: 1.45296644e-05
Iter: 289 loss: 1.45626191e-05
Iter: 290 loss: 1.45172016e-05
Iter: 291 loss: 1.44930527e-05
Iter: 292 loss: 1.45228214e-05
Iter: 293 loss: 1.44805526e-05
Iter: 294 loss: 1.44551068e-05
Iter: 295 loss: 1.45525901e-05
Iter: 296 loss: 1.44490186e-05
Iter: 297 loss: 1.44262995e-05
Iter: 298 loss: 1.44901987e-05
Iter: 299 loss: 1.44188871e-05
Iter: 300 loss: 1.43916513e-05
Iter: 301 loss: 1.44043579e-05
Iter: 302 loss: 1.43731941e-05
Iter: 303 loss: 1.4344123e-05
Iter: 304 loss: 1.44205578e-05
Iter: 305 loss: 1.43348043e-05
Iter: 306 loss: 1.43043108e-05
Iter: 307 loss: 1.4458421e-05
Iter: 308 loss: 1.42991421e-05
Iter: 309 loss: 1.42736135e-05
Iter: 310 loss: 1.42771005e-05
Iter: 311 loss: 1.42543122e-05
Iter: 312 loss: 1.42275958e-05
Iter: 313 loss: 1.43885554e-05
Iter: 314 loss: 1.42241333e-05
Iter: 315 loss: 1.41967384e-05
Iter: 316 loss: 1.42470226e-05
Iter: 317 loss: 1.41845558e-05
Iter: 318 loss: 1.41600294e-05
Iter: 319 loss: 1.42344306e-05
Iter: 320 loss: 1.41528171e-05
Iter: 321 loss: 1.41319169e-05
Iter: 322 loss: 1.43464458e-05
Iter: 323 loss: 1.41311739e-05
Iter: 324 loss: 1.41104283e-05
Iter: 325 loss: 1.41051369e-05
Iter: 326 loss: 1.40920774e-05
Iter: 327 loss: 1.40672491e-05
Iter: 328 loss: 1.41115679e-05
Iter: 329 loss: 1.40564271e-05
Iter: 330 loss: 1.40274124e-05
Iter: 331 loss: 1.41276059e-05
Iter: 332 loss: 1.40192678e-05
Iter: 333 loss: 1.39931326e-05
Iter: 334 loss: 1.40882867e-05
Iter: 335 loss: 1.39863705e-05
Iter: 336 loss: 1.39630665e-05
Iter: 337 loss: 1.40201337e-05
Iter: 338 loss: 1.39545627e-05
Iter: 339 loss: 1.3931116e-05
Iter: 340 loss: 1.39352614e-05
Iter: 341 loss: 1.3913701e-05
Iter: 342 loss: 1.38857449e-05
Iter: 343 loss: 1.41161099e-05
Iter: 344 loss: 1.38841369e-05
Iter: 345 loss: 1.38622127e-05
Iter: 346 loss: 1.38852738e-05
Iter: 347 loss: 1.38497271e-05
Iter: 348 loss: 1.3824515e-05
Iter: 349 loss: 1.38578889e-05
Iter: 350 loss: 1.38114265e-05
Iter: 351 loss: 1.37850711e-05
Iter: 352 loss: 1.39623189e-05
Iter: 353 loss: 1.37826364e-05
Iter: 354 loss: 1.37572461e-05
Iter: 355 loss: 1.3782821e-05
Iter: 356 loss: 1.37429261e-05
Iter: 357 loss: 1.37272609e-05
Iter: 358 loss: 1.37269381e-05
Iter: 359 loss: 1.37106317e-05
Iter: 360 loss: 1.36802146e-05
Iter: 361 loss: 1.43192246e-05
Iter: 362 loss: 1.36799081e-05
Iter: 363 loss: 1.3650485e-05
Iter: 364 loss: 1.38183887e-05
Iter: 365 loss: 1.36462768e-05
Iter: 366 loss: 1.3624e-05
Iter: 367 loss: 1.3766974e-05
Iter: 368 loss: 1.36214576e-05
Iter: 369 loss: 1.36026028e-05
Iter: 370 loss: 1.36170383e-05
Iter: 371 loss: 1.35913078e-05
Iter: 372 loss: 1.35647515e-05
Iter: 373 loss: 1.36065464e-05
Iter: 374 loss: 1.35522969e-05
Iter: 375 loss: 1.35289965e-05
Iter: 376 loss: 1.36501567e-05
Iter: 377 loss: 1.35253349e-05
Iter: 378 loss: 1.3507215e-05
Iter: 379 loss: 1.35123801e-05
Iter: 380 loss: 1.34940547e-05
Iter: 381 loss: 1.34614411e-05
Iter: 382 loss: 1.35468517e-05
Iter: 383 loss: 1.34501915e-05
Iter: 384 loss: 1.34289385e-05
Iter: 385 loss: 1.34687489e-05
Iter: 386 loss: 1.34198672e-05
Iter: 387 loss: 1.3392284e-05
Iter: 388 loss: 1.34711199e-05
Iter: 389 loss: 1.33833491e-05
Iter: 390 loss: 1.33562153e-05
Iter: 391 loss: 1.3492695e-05
Iter: 392 loss: 1.33518024e-05
Iter: 393 loss: 1.33343901e-05
Iter: 394 loss: 1.3528771e-05
Iter: 395 loss: 1.3333929e-05
Iter: 396 loss: 1.33197509e-05
Iter: 397 loss: 1.33044314e-05
Iter: 398 loss: 1.33022259e-05
Iter: 399 loss: 1.32785681e-05
Iter: 400 loss: 1.32910754e-05
Iter: 401 loss: 1.32628847e-05
Iter: 402 loss: 1.32400828e-05
Iter: 403 loss: 1.32402147e-05
Iter: 404 loss: 1.32227524e-05
Iter: 405 loss: 1.32200485e-05
Iter: 406 loss: 1.32085243e-05
Iter: 407 loss: 1.3186148e-05
Iter: 408 loss: 1.32764162e-05
Iter: 409 loss: 1.3181043e-05
Iter: 410 loss: 1.31595043e-05
Iter: 411 loss: 1.31818706e-05
Iter: 412 loss: 1.3147006e-05
Iter: 413 loss: 1.31204324e-05
Iter: 414 loss: 1.31669567e-05
Iter: 415 loss: 1.31083589e-05
Iter: 416 loss: 1.30855751e-05
Iter: 417 loss: 1.33581361e-05
Iter: 418 loss: 1.3085205e-05
Iter: 419 loss: 1.30695489e-05
Iter: 420 loss: 1.30413446e-05
Iter: 421 loss: 1.37319848e-05
Iter: 422 loss: 1.30409771e-05
Iter: 423 loss: 1.30140534e-05
Iter: 424 loss: 1.30140397e-05
Iter: 425 loss: 1.29956543e-05
Iter: 426 loss: 1.30682693e-05
Iter: 427 loss: 1.29913706e-05
Iter: 428 loss: 1.29731015e-05
Iter: 429 loss: 1.30473954e-05
Iter: 430 loss: 1.29696164e-05
Iter: 431 loss: 1.29525e-05
Iter: 432 loss: 1.29396276e-05
Iter: 433 loss: 1.29338905e-05
Iter: 434 loss: 1.29145265e-05
Iter: 435 loss: 1.29730561e-05
Iter: 436 loss: 1.29086793e-05
Iter: 437 loss: 1.28860811e-05
Iter: 438 loss: 1.29749851e-05
Iter: 439 loss: 1.28804795e-05
Iter: 440 loss: 1.28571946e-05
Iter: 441 loss: 1.29108348e-05
Iter: 442 loss: 1.28483225e-05
Iter: 443 loss: 1.28312286e-05
Iter: 444 loss: 1.28577403e-05
Iter: 445 loss: 1.2823084e-05
Iter: 446 loss: 1.27998728e-05
Iter: 447 loss: 1.28472639e-05
Iter: 448 loss: 1.2790555e-05
Iter: 449 loss: 1.27659459e-05
Iter: 450 loss: 1.28070078e-05
Iter: 451 loss: 1.27543481e-05
Iter: 452 loss: 1.2731407e-05
Iter: 453 loss: 1.29100326e-05
Iter: 454 loss: 1.27294616e-05
Iter: 455 loss: 1.27115527e-05
Iter: 456 loss: 1.27221156e-05
Iter: 457 loss: 1.26999621e-05
Iter: 458 loss: 1.26779987e-05
Iter: 459 loss: 1.27468811e-05
Iter: 460 loss: 1.26716295e-05
Iter: 461 loss: 1.26524828e-05
Iter: 462 loss: 1.28750771e-05
Iter: 463 loss: 1.26521645e-05
Iter: 464 loss: 1.26376017e-05
Iter: 465 loss: 1.26465384e-05
Iter: 466 loss: 1.2628564e-05
Iter: 467 loss: 1.26095165e-05
Iter: 468 loss: 1.26329105e-05
Iter: 469 loss: 1.25996721e-05
Iter: 470 loss: 1.25797123e-05
Iter: 471 loss: 1.25785009e-05
Iter: 472 loss: 1.2563567e-05
Iter: 473 loss: 1.25415318e-05
Iter: 474 loss: 1.28518705e-05
Iter: 475 loss: 1.25414244e-05
Iter: 476 loss: 1.25240467e-05
Iter: 477 loss: 1.25514471e-05
Iter: 478 loss: 1.25159531e-05
Iter: 479 loss: 1.24993521e-05
Iter: 480 loss: 1.24838298e-05
Iter: 481 loss: 1.24803473e-05
Iter: 482 loss: 1.24494354e-05
Iter: 483 loss: 1.2693723e-05
Iter: 484 loss: 1.24473809e-05
Iter: 485 loss: 1.24287108e-05
Iter: 486 loss: 1.24666585e-05
Iter: 487 loss: 1.24211156e-05
Iter: 488 loss: 1.23995214e-05
Iter: 489 loss: 1.24438793e-05
Iter: 490 loss: 1.2390602e-05
Iter: 491 loss: 1.23708051e-05
Iter: 492 loss: 1.24710168e-05
Iter: 493 loss: 1.23672708e-05
Iter: 494 loss: 1.23486607e-05
Iter: 495 loss: 1.23685741e-05
Iter: 496 loss: 1.23382888e-05
Iter: 497 loss: 1.23225564e-05
Iter: 498 loss: 1.23227273e-05
Iter: 499 loss: 1.23109912e-05
Iter: 500 loss: 1.22922302e-05
Iter: 501 loss: 1.22920164e-05
Iter: 502 loss: 1.22700512e-05
Iter: 503 loss: 1.24162088e-05
Iter: 504 loss: 1.22677684e-05
Iter: 505 loss: 1.2251513e-05
Iter: 506 loss: 1.22483298e-05
Iter: 507 loss: 1.22374104e-05
Iter: 508 loss: 1.22194615e-05
Iter: 509 loss: 1.24185763e-05
Iter: 510 loss: 1.22191304e-05
Iter: 511 loss: 1.22012489e-05
Iter: 512 loss: 1.21949315e-05
Iter: 513 loss: 1.21849853e-05
Iter: 514 loss: 1.21610137e-05
Iter: 515 loss: 1.22010661e-05
Iter: 516 loss: 1.21501507e-05
Iter: 517 loss: 1.21290086e-05
Iter: 518 loss: 1.22948441e-05
Iter: 519 loss: 1.21271187e-05
Iter: 520 loss: 1.210967e-05
Iter: 521 loss: 1.21328512e-05
Iter: 522 loss: 1.21006478e-05
Iter: 523 loss: 1.20782797e-05
Iter: 524 loss: 1.21044486e-05
Iter: 525 loss: 1.20661871e-05
Iter: 526 loss: 1.20446257e-05
Iter: 527 loss: 1.2230128e-05
Iter: 528 loss: 1.20435298e-05
Iter: 529 loss: 1.2028524e-05
Iter: 530 loss: 1.20686782e-05
Iter: 531 loss: 1.20234527e-05
Iter: 532 loss: 1.20072364e-05
Iter: 533 loss: 1.20992809e-05
Iter: 534 loss: 1.20049699e-05
Iter: 535 loss: 1.19896613e-05
Iter: 536 loss: 1.19767919e-05
Iter: 537 loss: 1.19724036e-05
Iter: 538 loss: 1.19543747e-05
Iter: 539 loss: 1.2072197e-05
Iter: 540 loss: 1.19526521e-05
Iter: 541 loss: 1.19367478e-05
Iter: 542 loss: 1.19413417e-05
Iter: 543 loss: 1.19249471e-05
Iter: 544 loss: 1.19032256e-05
Iter: 545 loss: 1.19959586e-05
Iter: 546 loss: 1.18986763e-05
Iter: 547 loss: 1.18803955e-05
Iter: 548 loss: 1.20076566e-05
Iter: 549 loss: 1.18787038e-05
Iter: 550 loss: 1.18664066e-05
Iter: 551 loss: 1.18492544e-05
Iter: 552 loss: 1.18483622e-05
Iter: 553 loss: 1.18238395e-05
Iter: 554 loss: 1.19082488e-05
Iter: 555 loss: 1.18173939e-05
Iter: 556 loss: 1.17971813e-05
Iter: 557 loss: 1.20228151e-05
Iter: 558 loss: 1.17967738e-05
Iter: 559 loss: 1.17832806e-05
Iter: 560 loss: 1.17706386e-05
Iter: 561 loss: 1.17673972e-05
Iter: 562 loss: 1.17447453e-05
Iter: 563 loss: 1.19110919e-05
Iter: 564 loss: 1.17430309e-05
Iter: 565 loss: 1.17264444e-05
Iter: 566 loss: 1.18213211e-05
Iter: 567 loss: 1.17242889e-05
Iter: 568 loss: 1.17103036e-05
Iter: 569 loss: 1.17741401e-05
Iter: 570 loss: 1.17076479e-05
Iter: 571 loss: 1.16956126e-05
Iter: 572 loss: 1.16805641e-05
Iter: 573 loss: 1.16790961e-05
Iter: 574 loss: 1.16568262e-05
Iter: 575 loss: 1.17317995e-05
Iter: 576 loss: 1.16509518e-05
Iter: 577 loss: 1.16337069e-05
Iter: 578 loss: 1.17703494e-05
Iter: 579 loss: 1.16320462e-05
Iter: 580 loss: 1.16196552e-05
Iter: 581 loss: 1.16285737e-05
Iter: 582 loss: 1.16118754e-05
Iter: 583 loss: 1.15932426e-05
Iter: 584 loss: 1.166e-05
Iter: 585 loss: 1.15884177e-05
Iter: 586 loss: 1.15715684e-05
Iter: 587 loss: 1.15726862e-05
Iter: 588 loss: 1.15585954e-05
Iter: 589 loss: 1.15396306e-05
Iter: 590 loss: 1.15830262e-05
Iter: 591 loss: 1.15325147e-05
Iter: 592 loss: 1.15106395e-05
Iter: 593 loss: 1.16438814e-05
Iter: 594 loss: 1.1507942e-05
Iter: 595 loss: 1.14927716e-05
Iter: 596 loss: 1.15397761e-05
Iter: 597 loss: 1.14884024e-05
Iter: 598 loss: 1.1472358e-05
Iter: 599 loss: 1.14734357e-05
Iter: 600 loss: 1.1459706e-05
Iter: 601 loss: 1.14439208e-05
Iter: 602 loss: 1.14434461e-05
Iter: 603 loss: 1.14329059e-05
Iter: 604 loss: 1.14333416e-05
Iter: 605 loss: 1.14245149e-05
Iter: 606 loss: 1.14068225e-05
Iter: 607 loss: 1.1409802e-05
Iter: 608 loss: 1.13934466e-05
Iter: 609 loss: 1.13763808e-05
Iter: 610 loss: 1.14170325e-05
Iter: 611 loss: 1.13700098e-05
Iter: 612 loss: 1.13494725e-05
Iter: 613 loss: 1.14435625e-05
Iter: 614 loss: 1.13454707e-05
Iter: 615 loss: 1.13298574e-05
Iter: 616 loss: 1.13875303e-05
Iter: 617 loss: 1.13259221e-05
Iter: 618 loss: 1.13122514e-05
Iter: 619 loss: 1.13699534e-05
Iter: 620 loss: 1.13092083e-05
Iter: 621 loss: 1.12964681e-05
Iter: 622 loss: 1.12807647e-05
Iter: 623 loss: 1.12793368e-05
Iter: 624 loss: 1.12565158e-05
Iter: 625 loss: 1.13312244e-05
Iter: 626 loss: 1.12502657e-05
Iter: 627 loss: 1.12309208e-05
Iter: 628 loss: 1.14591212e-05
Iter: 629 loss: 1.12309772e-05
Iter: 630 loss: 1.12177513e-05
Iter: 631 loss: 1.12181115e-05
Iter: 632 loss: 1.1207766e-05
Iter: 633 loss: 1.11904437e-05
Iter: 634 loss: 1.12863308e-05
Iter: 635 loss: 1.11877534e-05
Iter: 636 loss: 1.11721247e-05
Iter: 637 loss: 1.12718662e-05
Iter: 638 loss: 1.11702575e-05
Iter: 639 loss: 1.11587169e-05
Iter: 640 loss: 1.1159651e-05
Iter: 641 loss: 1.11491099e-05
Iter: 642 loss: 1.11335248e-05
Iter: 643 loss: 1.11678264e-05
Iter: 644 loss: 1.11276422e-05
Iter: 645 loss: 1.1110742e-05
Iter: 646 loss: 1.11176396e-05
Iter: 647 loss: 1.10991114e-05
Iter: 648 loss: 1.10817327e-05
Iter: 649 loss: 1.12815069e-05
Iter: 650 loss: 1.10815818e-05
Iter: 651 loss: 1.10676247e-05
Iter: 652 loss: 1.10797555e-05
Iter: 653 loss: 1.10595138e-05
Iter: 654 loss: 1.10433157e-05
Iter: 655 loss: 1.10992269e-05
Iter: 656 loss: 1.10389756e-05
Iter: 657 loss: 1.10215633e-05
Iter: 658 loss: 1.10211622e-05
Iter: 659 loss: 1.10072106e-05
Iter: 660 loss: 1.09876e-05
Iter: 661 loss: 1.10324418e-05
Iter: 662 loss: 1.09801567e-05
Iter: 663 loss: 1.09633875e-05
Iter: 664 loss: 1.11525924e-05
Iter: 665 loss: 1.0963131e-05
Iter: 666 loss: 1.09479115e-05
Iter: 667 loss: 1.09435114e-05
Iter: 668 loss: 1.09344201e-05
Iter: 669 loss: 1.09169123e-05
Iter: 670 loss: 1.11157424e-05
Iter: 671 loss: 1.09166358e-05
Iter: 672 loss: 1.09032644e-05
Iter: 673 loss: 1.09700077e-05
Iter: 674 loss: 1.09008442e-05
Iter: 675 loss: 1.08919312e-05
Iter: 676 loss: 1.08834574e-05
Iter: 677 loss: 1.08810964e-05
Iter: 678 loss: 1.08630538e-05
Iter: 679 loss: 1.09055509e-05
Iter: 680 loss: 1.08561981e-05
Iter: 681 loss: 1.08389049e-05
Iter: 682 loss: 1.08773074e-05
Iter: 683 loss: 1.08325094e-05
Iter: 684 loss: 1.08151435e-05
Iter: 685 loss: 1.09069206e-05
Iter: 686 loss: 1.08123504e-05
Iter: 687 loss: 1.07965516e-05
Iter: 688 loss: 1.08377981e-05
Iter: 689 loss: 1.07910564e-05
Iter: 690 loss: 1.07777987e-05
Iter: 691 loss: 1.08091272e-05
Iter: 692 loss: 1.07726792e-05
Iter: 693 loss: 1.07567557e-05
Iter: 694 loss: 1.07682736e-05
Iter: 695 loss: 1.07470159e-05
Iter: 696 loss: 1.07298838e-05
Iter: 697 loss: 1.07793239e-05
Iter: 698 loss: 1.07245551e-05
Iter: 699 loss: 1.07077494e-05
Iter: 700 loss: 1.0752161e-05
Iter: 701 loss: 1.07018323e-05
Iter: 702 loss: 1.06842144e-05
Iter: 703 loss: 1.080119e-05
Iter: 704 loss: 1.06824646e-05
Iter: 705 loss: 1.06692933e-05
Iter: 706 loss: 1.07060141e-05
Iter: 707 loss: 1.06650632e-05
Iter: 708 loss: 1.06499228e-05
Iter: 709 loss: 1.07197084e-05
Iter: 710 loss: 1.06473763e-05
Iter: 711 loss: 1.06378266e-05
Iter: 712 loss: 1.06220641e-05
Iter: 713 loss: 1.06219322e-05
Iter: 714 loss: 1.06029838e-05
Iter: 715 loss: 1.07945361e-05
Iter: 716 loss: 1.06024963e-05
Iter: 717 loss: 1.0588964e-05
Iter: 718 loss: 1.05897925e-05
Iter: 719 loss: 1.05789477e-05
Iter: 720 loss: 1.05646232e-05
Iter: 721 loss: 1.07348715e-05
Iter: 722 loss: 1.05644503e-05
Iter: 723 loss: 1.05519e-05
Iter: 724 loss: 1.05449981e-05
Iter: 725 loss: 1.05398267e-05
Iter: 726 loss: 1.05214567e-05
Iter: 727 loss: 1.06204097e-05
Iter: 728 loss: 1.05188146e-05
Iter: 729 loss: 1.05061e-05
Iter: 730 loss: 1.0529594e-05
Iter: 731 loss: 1.05008e-05
Iter: 732 loss: 1.04854735e-05
Iter: 733 loss: 1.04944465e-05
Iter: 734 loss: 1.04753144e-05
Iter: 735 loss: 1.04570063e-05
Iter: 736 loss: 1.05334402e-05
Iter: 737 loss: 1.04530682e-05
Iter: 738 loss: 1.0435605e-05
Iter: 739 loss: 1.05536456e-05
Iter: 740 loss: 1.04337596e-05
Iter: 741 loss: 1.04218361e-05
Iter: 742 loss: 1.04807532e-05
Iter: 743 loss: 1.04197479e-05
Iter: 744 loss: 1.04079672e-05
Iter: 745 loss: 1.0421606e-05
Iter: 746 loss: 1.04015926e-05
Iter: 747 loss: 1.03898683e-05
Iter: 748 loss: 1.03757684e-05
Iter: 749 loss: 1.03742259e-05
Iter: 750 loss: 1.03590182e-05
Iter: 751 loss: 1.03590737e-05
Iter: 752 loss: 1.0347655e-05
Iter: 753 loss: 1.03447583e-05
Iter: 754 loss: 1.03378688e-05
Iter: 755 loss: 1.03210878e-05
Iter: 756 loss: 1.04194387e-05
Iter: 757 loss: 1.03188759e-05
Iter: 758 loss: 1.0303911e-05
Iter: 759 loss: 1.03398907e-05
Iter: 760 loss: 1.02985323e-05
Iter: 761 loss: 1.02861304e-05
Iter: 762 loss: 1.02970671e-05
Iter: 763 loss: 1.02792455e-05
Iter: 764 loss: 1.02613049e-05
Iter: 765 loss: 1.02964541e-05
Iter: 766 loss: 1.02540889e-05
Iter: 767 loss: 1.02366939e-05
Iter: 768 loss: 1.02944086e-05
Iter: 769 loss: 1.02317435e-05
Iter: 770 loss: 1.02174845e-05
Iter: 771 loss: 1.0251908e-05
Iter: 772 loss: 1.02122076e-05
Iter: 773 loss: 1.01944524e-05
Iter: 774 loss: 1.02995045e-05
Iter: 775 loss: 1.01922305e-05
Iter: 776 loss: 1.01798614e-05
Iter: 777 loss: 1.02487611e-05
Iter: 778 loss: 1.01778296e-05
Iter: 779 loss: 1.01679889e-05
Iter: 780 loss: 1.0172218e-05
Iter: 781 loss: 1.01607775e-05
Iter: 782 loss: 1.01484438e-05
Iter: 783 loss: 1.01431951e-05
Iter: 784 loss: 1.01367459e-05
Iter: 785 loss: 1.01201686e-05
Iter: 786 loss: 1.0247084e-05
Iter: 787 loss: 1.01193809e-05
Iter: 788 loss: 1.0104668e-05
Iter: 789 loss: 1.01367832e-05
Iter: 790 loss: 1.009889e-05
Iter: 791 loss: 1.00840971e-05
Iter: 792 loss: 1.01330024e-05
Iter: 793 loss: 1.00802263e-05
Iter: 794 loss: 1.00663819e-05
Iter: 795 loss: 1.01274054e-05
Iter: 796 loss: 1.00635734e-05
Iter: 797 loss: 1.00523102e-05
Iter: 798 loss: 1.0040726e-05
Iter: 799 loss: 1.00385105e-05
Iter: 800 loss: 1.00201514e-05
Iter: 801 loss: 1.01650867e-05
Iter: 802 loss: 1.00189645e-05
Iter: 803 loss: 1.00062352e-05
Iter: 804 loss: 1.00468387e-05
Iter: 805 loss: 1.00022626e-05
Iter: 806 loss: 9.99004e-06
Iter: 807 loss: 9.99615e-06
Iter: 808 loss: 9.98154428e-06
Iter: 809 loss: 9.96463859e-06
Iter: 810 loss: 1.0132243e-05
Iter: 811 loss: 9.96398376e-06
Iter: 812 loss: 9.95185292e-06
Iter: 813 loss: 9.97152802e-06
Iter: 814 loss: 9.94633774e-06
Iter: 815 loss: 9.93379945e-06
Iter: 816 loss: 9.95420305e-06
Iter: 817 loss: 9.92805144e-06
Iter: 818 loss: 9.91366e-06
Iter: 819 loss: 9.90668923e-06
Iter: 820 loss: 9.89997e-06
Iter: 821 loss: 9.88460306e-06
Iter: 822 loss: 1.00472662e-05
Iter: 823 loss: 9.884463e-06
Iter: 824 loss: 9.87136809e-06
Iter: 825 loss: 9.90039189e-06
Iter: 826 loss: 9.86641408e-06
Iter: 827 loss: 9.85218321e-06
Iter: 828 loss: 9.8862638e-06
Iter: 829 loss: 9.84705e-06
Iter: 830 loss: 9.83376e-06
Iter: 831 loss: 9.89332329e-06
Iter: 832 loss: 9.83126665e-06
Iter: 833 loss: 9.81924495e-06
Iter: 834 loss: 9.81611083e-06
Iter: 835 loss: 9.80877485e-06
Iter: 836 loss: 9.79231299e-06
Iter: 837 loss: 9.83916198e-06
Iter: 838 loss: 9.78686694e-06
Iter: 839 loss: 9.76952e-06
Iter: 840 loss: 9.85532643e-06
Iter: 841 loss: 9.76658885e-06
Iter: 842 loss: 9.7541033e-06
Iter: 843 loss: 9.80621644e-06
Iter: 844 loss: 9.75135845e-06
Iter: 845 loss: 9.7387574e-06
Iter: 846 loss: 9.80627283e-06
Iter: 847 loss: 9.73707211e-06
Iter: 848 loss: 9.72489306e-06
Iter: 849 loss: 9.72396538e-06
Iter: 850 loss: 9.71523878e-06
Iter: 851 loss: 9.70207293e-06
Iter: 852 loss: 9.76496449e-06
Iter: 853 loss: 9.69954544e-06
Iter: 854 loss: 9.68721451e-06
Iter: 855 loss: 9.69072062e-06
Iter: 856 loss: 9.67822598e-06
Iter: 857 loss: 9.66403331e-06
Iter: 858 loss: 9.67745473e-06
Iter: 859 loss: 9.65578238e-06
Iter: 860 loss: 9.63873936e-06
Iter: 861 loss: 9.84355938e-06
Iter: 862 loss: 9.63832099e-06
Iter: 863 loss: 9.62814192e-06
Iter: 864 loss: 9.64110768e-06
Iter: 865 loss: 9.62316517e-06
Iter: 866 loss: 9.6116255e-06
Iter: 867 loss: 9.64411902e-06
Iter: 868 loss: 9.6079e-06
Iter: 869 loss: 9.59464433e-06
Iter: 870 loss: 9.59346198e-06
Iter: 871 loss: 9.58366218e-06
Iter: 872 loss: 9.5678879e-06
Iter: 873 loss: 9.64326136e-06
Iter: 874 loss: 9.56484291e-06
Iter: 875 loss: 9.55234191e-06
Iter: 876 loss: 9.60292255e-06
Iter: 877 loss: 9.54956704e-06
Iter: 878 loss: 9.53669951e-06
Iter: 879 loss: 9.58283454e-06
Iter: 880 loss: 9.53309245e-06
Iter: 881 loss: 9.52071241e-06
Iter: 882 loss: 9.59907175e-06
Iter: 883 loss: 9.51935272e-06
Iter: 884 loss: 9.51033508e-06
Iter: 885 loss: 9.51177481e-06
Iter: 886 loss: 9.50363574e-06
Iter: 887 loss: 9.49241621e-06
Iter: 888 loss: 9.50533831e-06
Iter: 889 loss: 9.48595789e-06
Iter: 890 loss: 9.46963337e-06
Iter: 891 loss: 9.50704634e-06
Iter: 892 loss: 9.46378532e-06
Iter: 893 loss: 9.45166903e-06
Iter: 894 loss: 9.47604622e-06
Iter: 895 loss: 9.44655585e-06
Iter: 896 loss: 9.43259784e-06
Iter: 897 loss: 9.51758e-06
Iter: 898 loss: 9.43091709e-06
Iter: 899 loss: 9.41800408e-06
Iter: 900 loss: 9.43797477e-06
Iter: 901 loss: 9.41180497e-06
Iter: 902 loss: 9.40133577e-06
Iter: 903 loss: 9.43576742e-06
Iter: 904 loss: 9.3982917e-06
Iter: 905 loss: 9.3867211e-06
Iter: 906 loss: 9.40693644e-06
Iter: 907 loss: 9.38164794e-06
Iter: 908 loss: 9.36986726e-06
Iter: 909 loss: 9.37640925e-06
Iter: 910 loss: 9.36204924e-06
Iter: 911 loss: 9.34812397e-06
Iter: 912 loss: 9.42296447e-06
Iter: 913 loss: 9.34606942e-06
Iter: 914 loss: 9.33284082e-06
Iter: 915 loss: 9.42719817e-06
Iter: 916 loss: 9.33170668e-06
Iter: 917 loss: 9.32264902e-06
Iter: 918 loss: 9.35892785e-06
Iter: 919 loss: 9.32043804e-06
Iter: 920 loss: 9.31245813e-06
Iter: 921 loss: 9.30143869e-06
Iter: 922 loss: 9.30081933e-06
Iter: 923 loss: 9.28547252e-06
Iter: 924 loss: 9.36702e-06
Iter: 925 loss: 9.2832779e-06
Iter: 926 loss: 9.27036672e-06
Iter: 927 loss: 9.30639362e-06
Iter: 928 loss: 9.26654e-06
Iter: 929 loss: 9.25538552e-06
Iter: 930 loss: 9.27845304e-06
Iter: 931 loss: 9.25093264e-06
Iter: 932 loss: 9.23940752e-06
Iter: 933 loss: 9.3003182e-06
Iter: 934 loss: 9.23741391e-06
Iter: 935 loss: 9.22648906e-06
Iter: 936 loss: 9.25419408e-06
Iter: 937 loss: 9.22254821e-06
Iter: 938 loss: 9.21276933e-06
Iter: 939 loss: 9.20639468e-06
Iter: 940 loss: 9.20287403e-06
Iter: 941 loss: 9.18752357e-06
Iter: 942 loss: 9.33467345e-06
Iter: 943 loss: 9.18707156e-06
Iter: 944 loss: 9.17629586e-06
Iter: 945 loss: 9.16354657e-06
Iter: 946 loss: 9.16237877e-06
Iter: 947 loss: 9.15095734e-06
Iter: 948 loss: 9.15086457e-06
Iter: 949 loss: 9.13992335e-06
Iter: 950 loss: 9.16088175e-06
Iter: 951 loss: 9.13534495e-06
Iter: 952 loss: 9.12376254e-06
Iter: 953 loss: 9.15096643e-06
Iter: 954 loss: 9.11980533e-06
Iter: 955 loss: 9.10966e-06
Iter: 956 loss: 9.12121595e-06
Iter: 957 loss: 9.10434392e-06
Iter: 958 loss: 9.09161099e-06
Iter: 959 loss: 9.10079143e-06
Iter: 960 loss: 9.0833546e-06
Iter: 961 loss: 9.06921832e-06
Iter: 962 loss: 9.18493788e-06
Iter: 963 loss: 9.06827245e-06
Iter: 964 loss: 9.0593694e-06
Iter: 965 loss: 9.07089452e-06
Iter: 966 loss: 9.05481647e-06
Iter: 967 loss: 9.04333501e-06
Iter: 968 loss: 9.09063056e-06
Iter: 969 loss: 9.04089575e-06
Iter: 970 loss: 9.02892407e-06
Iter: 971 loss: 9.04231638e-06
Iter: 972 loss: 9.02254942e-06
Iter: 973 loss: 9.01062776e-06
Iter: 974 loss: 9.02676675e-06
Iter: 975 loss: 9.0045869e-06
Iter: 976 loss: 8.99246788e-06
Iter: 977 loss: 9.08209e-06
Iter: 978 loss: 8.99170391e-06
Iter: 979 loss: 8.98137387e-06
Iter: 980 loss: 8.98082e-06
Iter: 981 loss: 8.97307655e-06
Iter: 982 loss: 8.96117126e-06
Iter: 983 loss: 9.0486119e-06
Iter: 984 loss: 8.96027177e-06
Iter: 985 loss: 8.9481855e-06
Iter: 986 loss: 9.00102e-06
Iter: 987 loss: 8.94573441e-06
Iter: 988 loss: 8.93753349e-06
Iter: 989 loss: 8.93883225e-06
Iter: 990 loss: 8.93153265e-06
Iter: 991 loss: 8.91952914e-06
Iter: 992 loss: 8.94717232e-06
Iter: 993 loss: 8.91521722e-06
Iter: 994 loss: 8.90325464e-06
Iter: 995 loss: 8.92560638e-06
Iter: 996 loss: 8.89819512e-06
Iter: 997 loss: 8.88865816e-06
Iter: 998 loss: 8.95284211e-06
Iter: 999 loss: 8.88762497e-06
Iter: 1000 loss: 8.87867827e-06
Iter: 1001 loss: 8.87885e-06
Iter: 1002 loss: 8.87125952e-06
Iter: 1003 loss: 8.85915506e-06
Iter: 1004 loss: 8.95055837e-06
Iter: 1005 loss: 8.85812733e-06
Iter: 1006 loss: 8.84880683e-06
Iter: 1007 loss: 8.87101487e-06
Iter: 1008 loss: 8.84551446e-06
Iter: 1009 loss: 8.83726352e-06
Iter: 1010 loss: 8.8308152e-06
Iter: 1011 loss: 8.82810218e-06
Iter: 1012 loss: 8.81460073e-06
Iter: 1013 loss: 8.92749085e-06
Iter: 1014 loss: 8.81378764e-06
Iter: 1015 loss: 8.80322659e-06
Iter: 1016 loss: 8.81901906e-06
Iter: 1017 loss: 8.7983135e-06
Iter: 1018 loss: 8.78807805e-06
Iter: 1019 loss: 8.86232283e-06
Iter: 1020 loss: 8.78705e-06
Iter: 1021 loss: 8.77683124e-06
Iter: 1022 loss: 8.80234802e-06
Iter: 1023 loss: 8.77320872e-06
Iter: 1024 loss: 8.76516606e-06
Iter: 1025 loss: 8.76035665e-06
Iter: 1026 loss: 8.75697e-06
Iter: 1027 loss: 8.74492071e-06
Iter: 1028 loss: 8.81981123e-06
Iter: 1029 loss: 8.74349098e-06
Iter: 1030 loss: 8.73222234e-06
Iter: 1031 loss: 8.73471163e-06
Iter: 1032 loss: 8.72403143e-06
Iter: 1033 loss: 8.71127668e-06
Iter: 1034 loss: 8.77607908e-06
Iter: 1035 loss: 8.70924123e-06
Iter: 1036 loss: 8.69912947e-06
Iter: 1037 loss: 8.75605292e-06
Iter: 1038 loss: 8.69782343e-06
Iter: 1039 loss: 8.68840652e-06
Iter: 1040 loss: 8.69636824e-06
Iter: 1041 loss: 8.68329153e-06
Iter: 1042 loss: 8.67049675e-06
Iter: 1043 loss: 8.70801523e-06
Iter: 1044 loss: 8.66672326e-06
Iter: 1045 loss: 8.65684433e-06
Iter: 1046 loss: 8.66212304e-06
Iter: 1047 loss: 8.65058246e-06
Iter: 1048 loss: 8.63830792e-06
Iter: 1049 loss: 8.69154337e-06
Iter: 1050 loss: 8.63596688e-06
Iter: 1051 loss: 8.62469278e-06
Iter: 1052 loss: 8.68204e-06
Iter: 1053 loss: 8.62312118e-06
Iter: 1054 loss: 8.61499393e-06
Iter: 1055 loss: 8.65808e-06
Iter: 1056 loss: 8.61376e-06
Iter: 1057 loss: 8.60459295e-06
Iter: 1058 loss: 8.60695309e-06
Iter: 1059 loss: 8.59781449e-06
Iter: 1060 loss: 8.58794192e-06
Iter: 1061 loss: 8.59081774e-06
Iter: 1062 loss: 8.58071144e-06
Iter: 1063 loss: 8.57060695e-06
Iter: 1064 loss: 8.66964e-06
Iter: 1065 loss: 8.57029499e-06
Iter: 1066 loss: 8.56145562e-06
Iter: 1067 loss: 8.56085535e-06
Iter: 1068 loss: 8.55427788e-06
Iter: 1069 loss: 8.54323e-06
Iter: 1070 loss: 8.58450403e-06
Iter: 1071 loss: 8.54045538e-06
Iter: 1072 loss: 8.5286174e-06
Iter: 1073 loss: 8.56682891e-06
Iter: 1074 loss: 8.52519406e-06
Iter: 1075 loss: 8.51453478e-06
Iter: 1076 loss: 8.5679967e-06
Iter: 1077 loss: 8.51258119e-06
Iter: 1078 loss: 8.50463312e-06
Iter: 1079 loss: 8.51121e-06
Iter: 1080 loss: 8.49987373e-06
Iter: 1081 loss: 8.48770105e-06
Iter: 1082 loss: 8.49543176e-06
Iter: 1083 loss: 8.48021e-06
Iter: 1084 loss: 8.46952389e-06
Iter: 1085 loss: 8.52288213e-06
Iter: 1086 loss: 8.46779767e-06
Iter: 1087 loss: 8.45706927e-06
Iter: 1088 loss: 8.51025288e-06
Iter: 1089 loss: 8.45549857e-06
Iter: 1090 loss: 8.4467265e-06
Iter: 1091 loss: 8.49173739e-06
Iter: 1092 loss: 8.44537954e-06
Iter: 1093 loss: 8.43686212e-06
Iter: 1094 loss: 8.43932e-06
Iter: 1095 loss: 8.43074668e-06
Iter: 1096 loss: 8.42164263e-06
Iter: 1097 loss: 8.42092595e-06
Iter: 1098 loss: 8.41408564e-06
Iter: 1099 loss: 8.40266148e-06
Iter: 1100 loss: 8.49133448e-06
Iter: 1101 loss: 8.4017347e-06
Iter: 1102 loss: 8.39144e-06
Iter: 1103 loss: 8.4090716e-06
Iter: 1104 loss: 8.38685355e-06
Iter: 1105 loss: 8.37709e-06
Iter: 1106 loss: 8.39147287e-06
Iter: 1107 loss: 8.37247717e-06
Iter: 1108 loss: 8.36110212e-06
Iter: 1109 loss: 8.44565056e-06
Iter: 1110 loss: 8.36027903e-06
Iter: 1111 loss: 8.3515024e-06
Iter: 1112 loss: 8.36489562e-06
Iter: 1113 loss: 8.34742e-06
Iter: 1114 loss: 8.33906233e-06
Iter: 1115 loss: 8.36135e-06
Iter: 1116 loss: 8.3362429e-06
Iter: 1117 loss: 8.3263e-06
Iter: 1118 loss: 8.32442311e-06
Iter: 1119 loss: 8.31765828e-06
Iter: 1120 loss: 8.30498e-06
Iter: 1121 loss: 8.37533571e-06
Iter: 1122 loss: 8.30326189e-06
Iter: 1123 loss: 8.29380224e-06
Iter: 1124 loss: 8.38601409e-06
Iter: 1125 loss: 8.29332566e-06
Iter: 1126 loss: 8.28612247e-06
Iter: 1127 loss: 8.30506451e-06
Iter: 1128 loss: 8.28378143e-06
Iter: 1129 loss: 8.27620715e-06
Iter: 1130 loss: 8.27396343e-06
Iter: 1131 loss: 8.26949054e-06
Iter: 1132 loss: 8.25876577e-06
Iter: 1133 loss: 8.28854e-06
Iter: 1134 loss: 8.25579173e-06
Iter: 1135 loss: 8.24718336e-06
Iter: 1136 loss: 8.25955431e-06
Iter: 1137 loss: 8.2430679e-06
Iter: 1138 loss: 8.23078e-06
Iter: 1139 loss: 8.28183784e-06
Iter: 1140 loss: 8.22823858e-06
Iter: 1141 loss: 8.21936e-06
Iter: 1142 loss: 8.23043047e-06
Iter: 1143 loss: 8.21456e-06
Iter: 1144 loss: 8.20665082e-06
Iter: 1145 loss: 8.30331101e-06
Iter: 1146 loss: 8.206237e-06
Iter: 1147 loss: 8.19911111e-06
Iter: 1148 loss: 8.19287561e-06
Iter: 1149 loss: 8.19109118e-06
Iter: 1150 loss: 8.18075569e-06
Iter: 1151 loss: 8.23208666e-06
Iter: 1152 loss: 8.17909586e-06
Iter: 1153 loss: 8.16834563e-06
Iter: 1154 loss: 8.17814089e-06
Iter: 1155 loss: 8.16238935e-06
Iter: 1156 loss: 8.15326e-06
Iter: 1157 loss: 8.21604317e-06
Iter: 1158 loss: 8.1524413e-06
Iter: 1159 loss: 8.14419218e-06
Iter: 1160 loss: 8.18243461e-06
Iter: 1161 loss: 8.14234954e-06
Iter: 1162 loss: 8.13423594e-06
Iter: 1163 loss: 8.1412536e-06
Iter: 1164 loss: 8.1291746e-06
Iter: 1165 loss: 8.12033068e-06
Iter: 1166 loss: 8.13914721e-06
Iter: 1167 loss: 8.11655173e-06
Iter: 1168 loss: 8.10737583e-06
Iter: 1169 loss: 8.1177941e-06
Iter: 1170 loss: 8.10246092e-06
Iter: 1171 loss: 8.09253106e-06
Iter: 1172 loss: 8.11634254e-06
Iter: 1173 loss: 8.08898676e-06
Iter: 1174 loss: 8.07703418e-06
Iter: 1175 loss: 8.13147835e-06
Iter: 1176 loss: 8.07441e-06
Iter: 1177 loss: 8.06618664e-06
Iter: 1178 loss: 8.08929872e-06
Iter: 1179 loss: 8.06350909e-06
Iter: 1180 loss: 8.05591299e-06
Iter: 1181 loss: 8.0919217e-06
Iter: 1182 loss: 8.05448872e-06
Iter: 1183 loss: 8.04517913e-06
Iter: 1184 loss: 8.03689363e-06
Iter: 1185 loss: 8.03447256e-06
Iter: 1186 loss: 8.02488466e-06
Iter: 1187 loss: 8.0949967e-06
Iter: 1188 loss: 8.02398336e-06
Iter: 1189 loss: 8.01528768e-06
Iter: 1190 loss: 8.03211242e-06
Iter: 1191 loss: 8.01165515e-06
Iter: 1192 loss: 8.00264206e-06
Iter: 1193 loss: 8.03260627e-06
Iter: 1194 loss: 8.0003183e-06
Iter: 1195 loss: 7.99043846e-06
Iter: 1196 loss: 8.05182117e-06
Iter: 1197 loss: 7.98928613e-06
Iter: 1198 loss: 7.98337351e-06
Iter: 1199 loss: 7.98639394e-06
Iter: 1200 loss: 7.97943903e-06
Iter: 1201 loss: 7.97083158e-06
Iter: 1202 loss: 7.97242e-06
Iter: 1203 loss: 7.96445329e-06
Iter: 1204 loss: 7.95301276e-06
Iter: 1205 loss: 7.99277404e-06
Iter: 1206 loss: 7.94993684e-06
Iter: 1207 loss: 7.94074549e-06
Iter: 1208 loss: 7.96195854e-06
Iter: 1209 loss: 7.93721847e-06
Iter: 1210 loss: 7.92594255e-06
Iter: 1211 loss: 7.97617213e-06
Iter: 1212 loss: 7.92379433e-06
Iter: 1213 loss: 7.91538e-06
Iter: 1214 loss: 7.93172148e-06
Iter: 1215 loss: 7.9115307e-06
Iter: 1216 loss: 7.90345e-06
Iter: 1217 loss: 7.96755194e-06
Iter: 1218 loss: 7.90300874e-06
Iter: 1219 loss: 7.89598835e-06
Iter: 1220 loss: 7.89186561e-06
Iter: 1221 loss: 7.88902253e-06
Iter: 1222 loss: 7.87914723e-06
Iter: 1223 loss: 7.8912708e-06
Iter: 1224 loss: 7.87369754e-06
Iter: 1225 loss: 7.86156852e-06
Iter: 1226 loss: 7.94809239e-06
Iter: 1227 loss: 7.86042256e-06
Iter: 1228 loss: 7.85286556e-06
Iter: 1229 loss: 7.9119709e-06
Iter: 1230 loss: 7.85235e-06
Iter: 1231 loss: 7.84631811e-06
Iter: 1232 loss: 7.8652165e-06
Iter: 1233 loss: 7.84470376e-06
Iter: 1234 loss: 7.83865289e-06
Iter: 1235 loss: 7.82838652e-06
Iter: 1236 loss: 7.82876668e-06
Iter: 1237 loss: 7.81754534e-06
Iter: 1238 loss: 7.93022718e-06
Iter: 1239 loss: 7.81721246e-06
Iter: 1240 loss: 7.81006929e-06
Iter: 1241 loss: 7.82135066e-06
Iter: 1242 loss: 7.80688606e-06
Iter: 1243 loss: 7.79844231e-06
Iter: 1244 loss: 7.79728725e-06
Iter: 1245 loss: 7.79149377e-06
Iter: 1246 loss: 7.78063895e-06
Iter: 1247 loss: 7.92788614e-06
Iter: 1248 loss: 7.78087451e-06
Iter: 1249 loss: 7.77443347e-06
Iter: 1250 loss: 7.77625064e-06
Iter: 1251 loss: 7.77019704e-06
Iter: 1252 loss: 7.76144225e-06
Iter: 1253 loss: 7.80834216e-06
Iter: 1254 loss: 7.76004617e-06
Iter: 1255 loss: 7.75291574e-06
Iter: 1256 loss: 7.754943e-06
Iter: 1257 loss: 7.74747423e-06
Iter: 1258 loss: 7.7387449e-06
Iter: 1259 loss: 7.74846649e-06
Iter: 1260 loss: 7.73406737e-06
Iter: 1261 loss: 7.72350904e-06
Iter: 1262 loss: 7.79673e-06
Iter: 1263 loss: 7.72255771e-06
Iter: 1264 loss: 7.71422856e-06
Iter: 1265 loss: 7.77188e-06
Iter: 1266 loss: 7.71356281e-06
Iter: 1267 loss: 7.70721817e-06
Iter: 1268 loss: 7.71675e-06
Iter: 1269 loss: 7.70405768e-06
Iter: 1270 loss: 7.69713733e-06
Iter: 1271 loss: 7.69194776e-06
Iter: 1272 loss: 7.68962309e-06
Iter: 1273 loss: 7.68023074e-06
Iter: 1274 loss: 7.7456807e-06
Iter: 1275 loss: 7.67951678e-06
Iter: 1276 loss: 7.67129222e-06
Iter: 1277 loss: 7.68285736e-06
Iter: 1278 loss: 7.66737594e-06
Iter: 1279 loss: 7.65889763e-06
Iter: 1280 loss: 7.68052087e-06
Iter: 1281 loss: 7.65594086e-06
Iter: 1282 loss: 7.64733431e-06
Iter: 1283 loss: 7.68685732e-06
Iter: 1284 loss: 7.64532342e-06
Iter: 1285 loss: 7.63670141e-06
Iter: 1286 loss: 7.65341611e-06
Iter: 1287 loss: 7.63286062e-06
Iter: 1288 loss: 7.62518903e-06
Iter: 1289 loss: 7.66486846e-06
Iter: 1290 loss: 7.62377204e-06
Iter: 1291 loss: 7.61598039e-06
Iter: 1292 loss: 7.62182663e-06
Iter: 1293 loss: 7.61115e-06
Iter: 1294 loss: 7.60242074e-06
Iter: 1295 loss: 7.59810337e-06
Iter: 1296 loss: 7.5938392e-06
Iter: 1297 loss: 7.58936039e-06
Iter: 1298 loss: 7.58768965e-06
Iter: 1299 loss: 7.58252463e-06
Iter: 1300 loss: 7.585405e-06
Iter: 1301 loss: 7.57897487e-06
Iter: 1302 loss: 7.5715443e-06
Iter: 1303 loss: 7.57770931e-06
Iter: 1304 loss: 7.5671137e-06
Iter: 1305 loss: 7.55863311e-06
Iter: 1306 loss: 7.56775e-06
Iter: 1307 loss: 7.55414885e-06
Iter: 1308 loss: 7.54428856e-06
Iter: 1309 loss: 7.5738626e-06
Iter: 1310 loss: 7.54142502e-06
Iter: 1311 loss: 7.53303311e-06
Iter: 1312 loss: 7.57832959e-06
Iter: 1313 loss: 7.53165159e-06
Iter: 1314 loss: 7.52403594e-06
Iter: 1315 loss: 7.52733149e-06
Iter: 1316 loss: 7.51890593e-06
Iter: 1317 loss: 7.50946765e-06
Iter: 1318 loss: 7.56648296e-06
Iter: 1319 loss: 7.50801246e-06
Iter: 1320 loss: 7.49966557e-06
Iter: 1321 loss: 7.51843163e-06
Iter: 1322 loss: 7.49603896e-06
Iter: 1323 loss: 7.48857e-06
Iter: 1324 loss: 7.52175265e-06
Iter: 1325 loss: 7.48711682e-06
Iter: 1326 loss: 7.48028151e-06
Iter: 1327 loss: 7.49258e-06
Iter: 1328 loss: 7.47732247e-06
Iter: 1329 loss: 7.46990236e-06
Iter: 1330 loss: 7.46453225e-06
Iter: 1331 loss: 7.46203568e-06
Iter: 1332 loss: 7.4552031e-06
Iter: 1333 loss: 7.45461739e-06
Iter: 1334 loss: 7.44829322e-06
Iter: 1335 loss: 7.45000489e-06
Iter: 1336 loss: 7.44368435e-06
Iter: 1337 loss: 7.43616738e-06
Iter: 1338 loss: 7.4427935e-06
Iter: 1339 loss: 7.43200872e-06
Iter: 1340 loss: 7.42205611e-06
Iter: 1341 loss: 7.4486934e-06
Iter: 1342 loss: 7.41867552e-06
Iter: 1343 loss: 7.41065651e-06
Iter: 1344 loss: 7.42174416e-06
Iter: 1345 loss: 7.40665473e-06
Iter: 1346 loss: 7.39755615e-06
Iter: 1347 loss: 7.44563795e-06
Iter: 1348 loss: 7.39596726e-06
Iter: 1349 loss: 7.38755034e-06
Iter: 1350 loss: 7.40046335e-06
Iter: 1351 loss: 7.38355948e-06
Iter: 1352 loss: 7.37642085e-06
Iter: 1353 loss: 7.42672182e-06
Iter: 1354 loss: 7.37580876e-06
Iter: 1355 loss: 7.36822722e-06
Iter: 1356 loss: 7.3681349e-06
Iter: 1357 loss: 7.36214406e-06
Iter: 1358 loss: 7.35244657e-06
Iter: 1359 loss: 7.40388214e-06
Iter: 1360 loss: 7.35071126e-06
Iter: 1361 loss: 7.34331206e-06
Iter: 1362 loss: 7.36197944e-06
Iter: 1363 loss: 7.34058767e-06
Iter: 1364 loss: 7.33285742e-06
Iter: 1365 loss: 7.33874049e-06
Iter: 1366 loss: 7.32821309e-06
Iter: 1367 loss: 7.32245371e-06
Iter: 1368 loss: 7.32226545e-06
Iter: 1369 loss: 7.31686941e-06
Iter: 1370 loss: 7.31187311e-06
Iter: 1371 loss: 7.31070759e-06
Iter: 1372 loss: 7.30263127e-06
Iter: 1373 loss: 7.31062073e-06
Iter: 1374 loss: 7.29802923e-06
Iter: 1375 loss: 7.28791201e-06
Iter: 1376 loss: 7.34320065e-06
Iter: 1377 loss: 7.28667601e-06
Iter: 1378 loss: 7.27845054e-06
Iter: 1379 loss: 7.28029e-06
Iter: 1380 loss: 7.2723451e-06
Iter: 1381 loss: 7.26365124e-06
Iter: 1382 loss: 7.32061972e-06
Iter: 1383 loss: 7.26253438e-06
Iter: 1384 loss: 7.25354084e-06
Iter: 1385 loss: 7.2646e-06
Iter: 1386 loss: 7.24857773e-06
Iter: 1387 loss: 7.24098936e-06
Iter: 1388 loss: 7.3031506e-06
Iter: 1389 loss: 7.24041911e-06
Iter: 1390 loss: 7.23402582e-06
Iter: 1391 loss: 7.24644133e-06
Iter: 1392 loss: 7.23154062e-06
Iter: 1393 loss: 7.22449e-06
Iter: 1394 loss: 7.22604364e-06
Iter: 1395 loss: 7.21941115e-06
Iter: 1396 loss: 7.20975822e-06
Iter: 1397 loss: 7.26559574e-06
Iter: 1398 loss: 7.20816797e-06
Iter: 1399 loss: 7.20156e-06
Iter: 1400 loss: 7.20993739e-06
Iter: 1401 loss: 7.1982663e-06
Iter: 1402 loss: 7.19023865e-06
Iter: 1403 loss: 7.26267763e-06
Iter: 1404 loss: 7.18984438e-06
Iter: 1405 loss: 7.1839213e-06
Iter: 1406 loss: 7.18164029e-06
Iter: 1407 loss: 7.17842249e-06
Iter: 1408 loss: 7.17080093e-06
Iter: 1409 loss: 7.17853163e-06
Iter: 1410 loss: 7.16660725e-06
Iter: 1411 loss: 7.15827082e-06
Iter: 1412 loss: 7.22386767e-06
Iter: 1413 loss: 7.15797842e-06
Iter: 1414 loss: 7.15100668e-06
Iter: 1415 loss: 7.14680118e-06
Iter: 1416 loss: 7.14402358e-06
Iter: 1417 loss: 7.13491863e-06
Iter: 1418 loss: 7.18876709e-06
Iter: 1419 loss: 7.13381269e-06
Iter: 1420 loss: 7.12436849e-06
Iter: 1421 loss: 7.15542546e-06
Iter: 1422 loss: 7.12213568e-06
Iter: 1423 loss: 7.11499615e-06
Iter: 1424 loss: 7.1441691e-06
Iter: 1425 loss: 7.11367829e-06
Iter: 1426 loss: 7.1065233e-06
Iter: 1427 loss: 7.11770736e-06
Iter: 1428 loss: 7.10312543e-06
Iter: 1429 loss: 7.09586857e-06
Iter: 1430 loss: 7.10909808e-06
Iter: 1431 loss: 7.09241795e-06
Iter: 1432 loss: 7.08473908e-06
Iter: 1433 loss: 7.11672055e-06
Iter: 1434 loss: 7.0831411e-06
Iter: 1435 loss: 7.07585377e-06
Iter: 1436 loss: 7.09762753e-06
Iter: 1437 loss: 7.07377603e-06
Iter: 1438 loss: 7.06669971e-06
Iter: 1439 loss: 7.11287612e-06
Iter: 1440 loss: 7.0657693e-06
Iter: 1441 loss: 7.06038873e-06
Iter: 1442 loss: 7.05279035e-06
Iter: 1443 loss: 7.05239563e-06
Iter: 1444 loss: 7.04314698e-06
Iter: 1445 loss: 7.07895879e-06
Iter: 1446 loss: 7.04098602e-06
Iter: 1447 loss: 7.03263458e-06
Iter: 1448 loss: 7.07502295e-06
Iter: 1449 loss: 7.03144269e-06
Iter: 1450 loss: 7.02333091e-06
Iter: 1451 loss: 7.03005253e-06
Iter: 1452 loss: 7.01875888e-06
Iter: 1453 loss: 7.01065073e-06
Iter: 1454 loss: 7.03397063e-06
Iter: 1455 loss: 7.00797818e-06
Iter: 1456 loss: 6.99980228e-06
Iter: 1457 loss: 7.05658567e-06
Iter: 1458 loss: 6.99923294e-06
Iter: 1459 loss: 6.99296e-06
Iter: 1460 loss: 7.00480359e-06
Iter: 1461 loss: 6.99026077e-06
Iter: 1462 loss: 6.98373424e-06
Iter: 1463 loss: 6.99939937e-06
Iter: 1464 loss: 6.98108579e-06
Iter: 1465 loss: 6.97307496e-06
Iter: 1466 loss: 6.98062513e-06
Iter: 1467 loss: 6.96853249e-06
Iter: 1468 loss: 6.96232564e-06
Iter: 1469 loss: 7.01101635e-06
Iter: 1470 loss: 6.96192774e-06
Iter: 1471 loss: 6.95602102e-06
Iter: 1472 loss: 6.96916231e-06
Iter: 1473 loss: 6.95362633e-06
Iter: 1474 loss: 6.9464877e-06
Iter: 1475 loss: 6.96543611e-06
Iter: 1476 loss: 6.9439061e-06
Iter: 1477 loss: 6.93744e-06
Iter: 1478 loss: 6.93511947e-06
Iter: 1479 loss: 6.93132097e-06
Iter: 1480 loss: 6.92372214e-06
Iter: 1481 loss: 6.94616e-06
Iter: 1482 loss: 6.92169851e-06
Iter: 1483 loss: 6.91297691e-06
Iter: 1484 loss: 6.94662e-06
Iter: 1485 loss: 6.9110697e-06
Iter: 1486 loss: 6.9032435e-06
Iter: 1487 loss: 6.92758158e-06
Iter: 1488 loss: 6.9008488e-06
Iter: 1489 loss: 6.89358376e-06
Iter: 1490 loss: 6.89673334e-06
Iter: 1491 loss: 6.88866658e-06
Iter: 1492 loss: 6.8807617e-06
Iter: 1493 loss: 6.98258145e-06
Iter: 1494 loss: 6.88068667e-06
Iter: 1495 loss: 6.87502688e-06
Iter: 1496 loss: 6.87860665e-06
Iter: 1497 loss: 6.87127613e-06
Iter: 1498 loss: 6.864856e-06
Iter: 1499 loss: 6.89268927e-06
Iter: 1500 loss: 6.86336261e-06
Iter: 1501 loss: 6.85698569e-06
Iter: 1502 loss: 6.86239719e-06
Iter: 1503 loss: 6.85334953e-06
Iter: 1504 loss: 6.84717634e-06
Iter: 1505 loss: 6.88324462e-06
Iter: 1506 loss: 6.84607494e-06
Iter: 1507 loss: 6.83963935e-06
Iter: 1508 loss: 6.86170279e-06
Iter: 1509 loss: 6.83795e-06
Iter: 1510 loss: 6.83208464e-06
Iter: 1511 loss: 6.8417271e-06
Iter: 1512 loss: 6.82942e-06
Iter: 1513 loss: 6.82416157e-06
Iter: 1514 loss: 6.82905102e-06
Iter: 1515 loss: 6.82118298e-06
Iter: 1516 loss: 6.81354732e-06
Iter: 1517 loss: 6.80842095e-06
Iter: 1518 loss: 6.80554831e-06
Iter: 1519 loss: 6.79734967e-06
Iter: 1520 loss: 6.79754885e-06
Iter: 1521 loss: 6.79109689e-06
Iter: 1522 loss: 6.80214498e-06
Iter: 1523 loss: 6.78833476e-06
Iter: 1524 loss: 6.78207289e-06
Iter: 1525 loss: 6.78891593e-06
Iter: 1526 loss: 6.77880598e-06
Iter: 1527 loss: 6.77143817e-06
Iter: 1528 loss: 6.82454265e-06
Iter: 1529 loss: 6.77061917e-06
Iter: 1530 loss: 6.76408e-06
Iter: 1531 loss: 6.7710771e-06
Iter: 1532 loss: 6.76057152e-06
Iter: 1533 loss: 6.75385e-06
Iter: 1534 loss: 6.771882e-06
Iter: 1535 loss: 6.75173123e-06
Iter: 1536 loss: 6.74331204e-06
Iter: 1537 loss: 6.75824822e-06
Iter: 1538 loss: 6.73985141e-06
Iter: 1539 loss: 6.73329669e-06
Iter: 1540 loss: 6.79113236e-06
Iter: 1541 loss: 6.73293107e-06
Iter: 1542 loss: 6.72722308e-06
Iter: 1543 loss: 6.74300418e-06
Iter: 1544 loss: 6.72542319e-06
Iter: 1545 loss: 6.72054739e-06
Iter: 1546 loss: 6.71893e-06
Iter: 1547 loss: 6.71612906e-06
Iter: 1548 loss: 6.70867576e-06
Iter: 1549 loss: 6.72652777e-06
Iter: 1550 loss: 6.70573354e-06
Iter: 1551 loss: 6.69840756e-06
Iter: 1552 loss: 6.71887028e-06
Iter: 1553 loss: 6.69591554e-06
Iter: 1554 loss: 6.6892153e-06
Iter: 1555 loss: 6.69986139e-06
Iter: 1556 loss: 6.68626217e-06
Iter: 1557 loss: 6.678305e-06
Iter: 1558 loss: 6.72923261e-06
Iter: 1559 loss: 6.67708218e-06
Iter: 1560 loss: 6.67114773e-06
Iter: 1561 loss: 6.67130917e-06
Iter: 1562 loss: 6.66629603e-06
Iter: 1563 loss: 6.65926746e-06
Iter: 1564 loss: 6.74366765e-06
Iter: 1565 loss: 6.65915741e-06
Iter: 1566 loss: 6.65340485e-06
Iter: 1567 loss: 6.651685e-06
Iter: 1568 loss: 6.64806657e-06
Iter: 1569 loss: 6.64047684e-06
Iter: 1570 loss: 6.67505537e-06
Iter: 1571 loss: 6.63911487e-06
Iter: 1572 loss: 6.63279388e-06
Iter: 1573 loss: 6.6660582e-06
Iter: 1574 loss: 6.63177434e-06
Iter: 1575 loss: 6.62706861e-06
Iter: 1576 loss: 6.64807521e-06
Iter: 1577 loss: 6.6261e-06
Iter: 1578 loss: 6.62068396e-06
Iter: 1579 loss: 6.6227808e-06
Iter: 1580 loss: 6.61723334e-06
Iter: 1581 loss: 6.61078866e-06
Iter: 1582 loss: 6.6128232e-06
Iter: 1583 loss: 6.60631804e-06
Iter: 1584 loss: 6.59995294e-06
Iter: 1585 loss: 6.64359777e-06
Iter: 1586 loss: 6.59923808e-06
Iter: 1587 loss: 6.59315447e-06
Iter: 1588 loss: 6.59252328e-06
Iter: 1589 loss: 6.5882723e-06
Iter: 1590 loss: 6.57999954e-06
Iter: 1591 loss: 6.62092134e-06
Iter: 1592 loss: 6.57860073e-06
Iter: 1593 loss: 6.57239343e-06
Iter: 1594 loss: 6.60990554e-06
Iter: 1595 loss: 6.57166811e-06
Iter: 1596 loss: 6.56559405e-06
Iter: 1597 loss: 6.56201564e-06
Iter: 1598 loss: 6.55940767e-06
Iter: 1599 loss: 6.55215899e-06
Iter: 1600 loss: 6.65627431e-06
Iter: 1601 loss: 6.55209442e-06
Iter: 1602 loss: 6.54710948e-06
Iter: 1603 loss: 6.55429403e-06
Iter: 1604 loss: 6.54472933e-06
Iter: 1605 loss: 6.53898633e-06
Iter: 1606 loss: 6.53445204e-06
Iter: 1607 loss: 6.53278721e-06
Iter: 1608 loss: 6.52552353e-06
Iter: 1609 loss: 6.52554354e-06
Iter: 1610 loss: 6.52176277e-06
Iter: 1611 loss: 6.53350571e-06
Iter: 1612 loss: 6.52060817e-06
Iter: 1613 loss: 6.51621394e-06
Iter: 1614 loss: 6.51314349e-06
Iter: 1615 loss: 6.51129358e-06
Iter: 1616 loss: 6.50495576e-06
Iter: 1617 loss: 6.5087961e-06
Iter: 1618 loss: 6.50038874e-06
Iter: 1619 loss: 6.49321373e-06
Iter: 1620 loss: 6.5489603e-06
Iter: 1621 loss: 6.49279218e-06
Iter: 1622 loss: 6.48683181e-06
Iter: 1623 loss: 6.49299454e-06
Iter: 1624 loss: 6.48359583e-06
Iter: 1625 loss: 6.47671732e-06
Iter: 1626 loss: 6.49459434e-06
Iter: 1627 loss: 6.47442448e-06
Iter: 1628 loss: 6.4673286e-06
Iter: 1629 loss: 6.50076254e-06
Iter: 1630 loss: 6.46586432e-06
Iter: 1631 loss: 6.46008766e-06
Iter: 1632 loss: 6.47983779e-06
Iter: 1633 loss: 6.45842647e-06
Iter: 1634 loss: 6.45295631e-06
Iter: 1635 loss: 6.47057186e-06
Iter: 1636 loss: 6.45149203e-06
Iter: 1637 loss: 6.44565e-06
Iter: 1638 loss: 6.45701857e-06
Iter: 1639 loss: 6.44339934e-06
Iter: 1640 loss: 6.43784779e-06
Iter: 1641 loss: 6.43714975e-06
Iter: 1642 loss: 6.43328895e-06
Iter: 1643 loss: 6.42632403e-06
Iter: 1644 loss: 6.42640043e-06
Iter: 1645 loss: 6.42219584e-06
Iter: 1646 loss: 6.42637087e-06
Iter: 1647 loss: 6.41979886e-06
Iter: 1648 loss: 6.41427414e-06
Iter: 1649 loss: 6.41721908e-06
Iter: 1650 loss: 6.41068436e-06
Iter: 1651 loss: 6.40478902e-06
Iter: 1652 loss: 6.41192082e-06
Iter: 1653 loss: 6.40155258e-06
Iter: 1654 loss: 6.39460586e-06
Iter: 1655 loss: 6.40918688e-06
Iter: 1656 loss: 6.39190375e-06
Iter: 1657 loss: 6.38422762e-06
Iter: 1658 loss: 6.42852137e-06
Iter: 1659 loss: 6.38318897e-06
Iter: 1660 loss: 6.37713583e-06
Iter: 1661 loss: 6.38632e-06
Iter: 1662 loss: 6.3742209e-06
Iter: 1663 loss: 6.36863706e-06
Iter: 1664 loss: 6.40498456e-06
Iter: 1665 loss: 6.36788809e-06
Iter: 1666 loss: 6.36247296e-06
Iter: 1667 loss: 6.3672278e-06
Iter: 1668 loss: 6.35920105e-06
Iter: 1669 loss: 6.35242668e-06
Iter: 1670 loss: 6.38310303e-06
Iter: 1671 loss: 6.35116885e-06
Iter: 1672 loss: 6.34541266e-06
Iter: 1673 loss: 6.36077766e-06
Iter: 1674 loss: 6.34346134e-06
Iter: 1675 loss: 6.33796571e-06
Iter: 1676 loss: 6.34196385e-06
Iter: 1677 loss: 6.33436457e-06
Iter: 1678 loss: 6.32882393e-06
Iter: 1679 loss: 6.41675751e-06
Iter: 1680 loss: 6.32885167e-06
Iter: 1681 loss: 6.32507181e-06
Iter: 1682 loss: 6.32112278e-06
Iter: 1683 loss: 6.32031379e-06
Iter: 1684 loss: 6.31344301e-06
Iter: 1685 loss: 6.33629725e-06
Iter: 1686 loss: 6.31151397e-06
Iter: 1687 loss: 6.30543309e-06
Iter: 1688 loss: 6.31709281e-06
Iter: 1689 loss: 6.30274235e-06
Iter: 1690 loss: 6.29696751e-06
Iter: 1691 loss: 6.29635542e-06
Iter: 1692 loss: 6.29206488e-06
Iter: 1693 loss: 6.28457929e-06
Iter: 1694 loss: 6.3602e-06
Iter: 1695 loss: 6.28436419e-06
Iter: 1696 loss: 6.27817462e-06
Iter: 1697 loss: 6.28598036e-06
Iter: 1698 loss: 6.27469672e-06
Iter: 1699 loss: 6.26849896e-06
Iter: 1700 loss: 6.2989543e-06
Iter: 1701 loss: 6.26733208e-06
Iter: 1702 loss: 6.26147539e-06
Iter: 1703 loss: 6.28514772e-06
Iter: 1704 loss: 6.26043584e-06
Iter: 1705 loss: 6.25496887e-06
Iter: 1706 loss: 6.25786606e-06
Iter: 1707 loss: 6.25131179e-06
Iter: 1708 loss: 6.24432505e-06
Iter: 1709 loss: 6.28361704e-06
Iter: 1710 loss: 6.24353925e-06
Iter: 1711 loss: 6.23894539e-06
Iter: 1712 loss: 6.24893255e-06
Iter: 1713 loss: 6.23706455e-06
Iter: 1714 loss: 6.23169e-06
Iter: 1715 loss: 6.26412475e-06
Iter: 1716 loss: 6.23088454e-06
Iter: 1717 loss: 6.22675498e-06
Iter: 1718 loss: 6.22409243e-06
Iter: 1719 loss: 6.22258722e-06
Iter: 1720 loss: 6.21625713e-06
Iter: 1721 loss: 6.23365077e-06
Iter: 1722 loss: 6.21437266e-06
Iter: 1723 loss: 6.2067711e-06
Iter: 1724 loss: 6.2181789e-06
Iter: 1725 loss: 6.20336868e-06
Iter: 1726 loss: 6.19708362e-06
Iter: 1727 loss: 6.21185563e-06
Iter: 1728 loss: 6.19486764e-06
Iter: 1729 loss: 6.18795366e-06
Iter: 1730 loss: 6.19989078e-06
Iter: 1731 loss: 6.18511285e-06
Iter: 1732 loss: 6.17804562e-06
Iter: 1733 loss: 6.24263157e-06
Iter: 1734 loss: 6.17777187e-06
Iter: 1735 loss: 6.17279329e-06
Iter: 1736 loss: 6.1780861e-06
Iter: 1737 loss: 6.17013029e-06
Iter: 1738 loss: 6.16426496e-06
Iter: 1739 loss: 6.19080311e-06
Iter: 1740 loss: 6.16303441e-06
Iter: 1741 loss: 6.1572573e-06
Iter: 1742 loss: 6.16761281e-06
Iter: 1743 loss: 6.15472e-06
Iter: 1744 loss: 6.14954206e-06
Iter: 1745 loss: 6.17197475e-06
Iter: 1746 loss: 6.14844248e-06
Iter: 1747 loss: 6.1432188e-06
Iter: 1748 loss: 6.15408771e-06
Iter: 1749 loss: 6.14142e-06
Iter: 1750 loss: 6.13547309e-06
Iter: 1751 loss: 6.16316629e-06
Iter: 1752 loss: 6.13429484e-06
Iter: 1753 loss: 6.12991153e-06
Iter: 1754 loss: 6.12776967e-06
Iter: 1755 loss: 6.1255746e-06
Iter: 1756 loss: 6.11991891e-06
Iter: 1757 loss: 6.13920292e-06
Iter: 1758 loss: 6.11821042e-06
Iter: 1759 loss: 6.11162204e-06
Iter: 1760 loss: 6.12700933e-06
Iter: 1761 loss: 6.10909319e-06
Iter: 1762 loss: 6.10330335e-06
Iter: 1763 loss: 6.10654479e-06
Iter: 1764 loss: 6.09964127e-06
Iter: 1765 loss: 6.09186691e-06
Iter: 1766 loss: 6.12244139e-06
Iter: 1767 loss: 6.08992377e-06
Iter: 1768 loss: 6.08394384e-06
Iter: 1769 loss: 6.12253416e-06
Iter: 1770 loss: 6.08322853e-06
Iter: 1771 loss: 6.07712172e-06
Iter: 1772 loss: 6.08292066e-06
Iter: 1773 loss: 6.07379388e-06
Iter: 1774 loss: 6.06770891e-06
Iter: 1775 loss: 6.1086e-06
Iter: 1776 loss: 6.06720505e-06
Iter: 1777 loss: 6.06144e-06
Iter: 1778 loss: 6.06584626e-06
Iter: 1779 loss: 6.05791865e-06
Iter: 1780 loss: 6.05320838e-06
Iter: 1781 loss: 6.08614073e-06
Iter: 1782 loss: 6.05287914e-06
Iter: 1783 loss: 6.04787056e-06
Iter: 1784 loss: 6.05624882e-06
Iter: 1785 loss: 6.04574598e-06
Iter: 1786 loss: 6.04055367e-06
Iter: 1787 loss: 6.05934156e-06
Iter: 1788 loss: 6.03927811e-06
Iter: 1789 loss: 6.03513672e-06
Iter: 1790 loss: 6.03153285e-06
Iter: 1791 loss: 6.03040689e-06
Iter: 1792 loss: 6.02415639e-06
Iter: 1793 loss: 6.06114872e-06
Iter: 1794 loss: 6.02356704e-06
Iter: 1795 loss: 6.01765169e-06
Iter: 1796 loss: 6.02840919e-06
Iter: 1797 loss: 6.01531883e-06
Iter: 1798 loss: 6.00889098e-06
Iter: 1799 loss: 6.01537431e-06
Iter: 1800 loss: 6.00551675e-06
Iter: 1801 loss: 5.99878376e-06
Iter: 1802 loss: 6.01634292e-06
Iter: 1803 loss: 5.99636769e-06
Iter: 1804 loss: 5.98974748e-06
Iter: 1805 loss: 6.03516401e-06
Iter: 1806 loss: 5.98895349e-06
Iter: 1807 loss: 5.98286215e-06
Iter: 1808 loss: 5.99647137e-06
Iter: 1809 loss: 5.98055294e-06
Iter: 1810 loss: 5.97519738e-06
Iter: 1811 loss: 6.00017847e-06
Iter: 1812 loss: 5.97415146e-06
Iter: 1813 loss: 5.96901691e-06
Iter: 1814 loss: 5.97931103e-06
Iter: 1815 loss: 5.96704695e-06
Iter: 1816 loss: 5.96241489e-06
Iter: 1817 loss: 5.97793314e-06
Iter: 1818 loss: 5.96116e-06
Iter: 1819 loss: 5.95551319e-06
Iter: 1820 loss: 5.96950122e-06
Iter: 1821 loss: 5.95341407e-06
Iter: 1822 loss: 5.94853464e-06
Iter: 1823 loss: 5.95642e-06
Iter: 1824 loss: 5.9463755e-06
Iter: 1825 loss: 5.94124776e-06
Iter: 1826 loss: 5.94888206e-06
Iter: 1827 loss: 5.93891855e-06
Iter: 1828 loss: 5.93280038e-06
Iter: 1829 loss: 5.93543109e-06
Iter: 1830 loss: 5.92858532e-06
Iter: 1831 loss: 5.92233391e-06
Iter: 1832 loss: 5.98811039e-06
Iter: 1833 loss: 5.92229344e-06
Iter: 1834 loss: 5.9171839e-06
Iter: 1835 loss: 5.91724256e-06
Iter: 1836 loss: 5.91312528e-06
Iter: 1837 loss: 5.90692935e-06
Iter: 1838 loss: 5.91630305e-06
Iter: 1839 loss: 5.90383434e-06
Iter: 1840 loss: 5.89773072e-06
Iter: 1841 loss: 5.9605859e-06
Iter: 1842 loss: 5.89744104e-06
Iter: 1843 loss: 5.89152478e-06
Iter: 1844 loss: 5.89958063e-06
Iter: 1845 loss: 5.88873945e-06
Iter: 1846 loss: 5.88374951e-06
Iter: 1847 loss: 5.91555408e-06
Iter: 1848 loss: 5.88337252e-06
Iter: 1849 loss: 5.87904242e-06
Iter: 1850 loss: 5.88323428e-06
Iter: 1851 loss: 5.87654176e-06
Iter: 1852 loss: 5.87111435e-06
Iter: 1853 loss: 5.88910552e-06
Iter: 1854 loss: 5.86955593e-06
Iter: 1855 loss: 5.86338047e-06
Iter: 1856 loss: 5.88147577e-06
Iter: 1857 loss: 5.8613773e-06
Iter: 1858 loss: 5.85690759e-06
Iter: 1859 loss: 5.85933867e-06
Iter: 1860 loss: 5.85387625e-06
Iter: 1861 loss: 5.84829786e-06
Iter: 1862 loss: 5.86396163e-06
Iter: 1863 loss: 5.84664303e-06
Iter: 1864 loss: 5.84053305e-06
Iter: 1865 loss: 5.84779946e-06
Iter: 1866 loss: 5.83719975e-06
Iter: 1867 loss: 5.83151e-06
Iter: 1868 loss: 5.85754333e-06
Iter: 1869 loss: 5.83045312e-06
Iter: 1870 loss: 5.82442499e-06
Iter: 1871 loss: 5.83522888e-06
Iter: 1872 loss: 5.82173743e-06
Iter: 1873 loss: 5.81570384e-06
Iter: 1874 loss: 5.82890834e-06
Iter: 1875 loss: 5.81333279e-06
Iter: 1876 loss: 5.8075e-06
Iter: 1877 loss: 5.82547545e-06
Iter: 1878 loss: 5.8057276e-06
Iter: 1879 loss: 5.79955258e-06
Iter: 1880 loss: 5.84237068e-06
Iter: 1881 loss: 5.79888456e-06
Iter: 1882 loss: 5.79448943e-06
Iter: 1883 loss: 5.79656398e-06
Iter: 1884 loss: 5.79115112e-06
Iter: 1885 loss: 5.78632216e-06
Iter: 1886 loss: 5.83429619e-06
Iter: 1887 loss: 5.78605614e-06
Iter: 1888 loss: 5.78247273e-06
Iter: 1889 loss: 5.78606705e-06
Iter: 1890 loss: 5.78043409e-06
Iter: 1891 loss: 5.77474566e-06
Iter: 1892 loss: 5.78329582e-06
Iter: 1893 loss: 5.77215178e-06
Iter: 1894 loss: 5.76702587e-06
Iter: 1895 loss: 5.77177343e-06
Iter: 1896 loss: 5.76417779e-06
Iter: 1897 loss: 5.75867398e-06
Iter: 1898 loss: 5.77247283e-06
Iter: 1899 loss: 5.75699778e-06
Iter: 1900 loss: 5.75058812e-06
Iter: 1901 loss: 5.76862e-06
Iter: 1902 loss: 5.74872502e-06
Iter: 1903 loss: 5.74272372e-06
Iter: 1904 loss: 5.74888e-06
Iter: 1905 loss: 5.73942452e-06
Iter: 1906 loss: 5.73330135e-06
Iter: 1907 loss: 5.77773426e-06
Iter: 1908 loss: 5.73284433e-06
Iter: 1909 loss: 5.72771387e-06
Iter: 1910 loss: 5.73061743e-06
Iter: 1911 loss: 5.72439421e-06
Iter: 1912 loss: 5.71777309e-06
Iter: 1913 loss: 5.73949092e-06
Iter: 1914 loss: 5.71578948e-06
Iter: 1915 loss: 5.71111286e-06
Iter: 1916 loss: 5.76995626e-06
Iter: 1917 loss: 5.7109155e-06
Iter: 1918 loss: 5.70676821e-06
Iter: 1919 loss: 5.70272914e-06
Iter: 1920 loss: 5.7018774e-06
Iter: 1921 loss: 5.69704571e-06
Iter: 1922 loss: 5.7698262e-06
Iter: 1923 loss: 5.69687472e-06
Iter: 1924 loss: 5.6925237e-06
Iter: 1925 loss: 5.69377789e-06
Iter: 1926 loss: 5.68950236e-06
Iter: 1927 loss: 5.68405903e-06
Iter: 1928 loss: 5.70901921e-06
Iter: 1929 loss: 5.68294945e-06
Iter: 1930 loss: 5.67864845e-06
Iter: 1931 loss: 5.67758343e-06
Iter: 1932 loss: 5.67483858e-06
Iter: 1933 loss: 5.66871449e-06
Iter: 1934 loss: 5.675377e-06
Iter: 1935 loss: 5.66532344e-06
Iter: 1936 loss: 5.65969185e-06
Iter: 1937 loss: 5.73026682e-06
Iter: 1938 loss: 5.65959908e-06
Iter: 1939 loss: 5.65528308e-06
Iter: 1940 loss: 5.65361279e-06
Iter: 1941 loss: 5.65127584e-06
Iter: 1942 loss: 5.64394668e-06
Iter: 1943 loss: 5.65829123e-06
Iter: 1944 loss: 5.64090624e-06
Iter: 1945 loss: 5.63466756e-06
Iter: 1946 loss: 5.69465237e-06
Iter: 1947 loss: 5.63449521e-06
Iter: 1948 loss: 5.62992636e-06
Iter: 1949 loss: 5.63139429e-06
Iter: 1950 loss: 5.62635933e-06
Iter: 1951 loss: 5.62044352e-06
Iter: 1952 loss: 5.66915242e-06
Iter: 1953 loss: 5.61978959e-06
Iter: 1954 loss: 5.61467232e-06
Iter: 1955 loss: 5.61912975e-06
Iter: 1956 loss: 5.61163597e-06
Iter: 1957 loss: 5.6069116e-06
Iter: 1958 loss: 5.65183063e-06
Iter: 1959 loss: 5.60678245e-06
Iter: 1960 loss: 5.60314083e-06
Iter: 1961 loss: 5.60920034e-06
Iter: 1962 loss: 5.60127955e-06
Iter: 1963 loss: 5.5971168e-06
Iter: 1964 loss: 5.59492037e-06
Iter: 1965 loss: 5.59303498e-06
Iter: 1966 loss: 5.58620286e-06
Iter: 1967 loss: 5.62790729e-06
Iter: 1968 loss: 5.5854025e-06
Iter: 1969 loss: 5.58157853e-06
Iter: 1970 loss: 5.57746671e-06
Iter: 1971 loss: 5.57664316e-06
Iter: 1972 loss: 5.56949635e-06
Iter: 1973 loss: 5.60381795e-06
Iter: 1974 loss: 5.56818622e-06
Iter: 1975 loss: 5.56189843e-06
Iter: 1976 loss: 5.60808394e-06
Iter: 1977 loss: 5.56140822e-06
Iter: 1978 loss: 5.55760153e-06
Iter: 1979 loss: 5.55545921e-06
Iter: 1980 loss: 5.55391034e-06
Iter: 1981 loss: 5.54719918e-06
Iter: 1982 loss: 5.56994837e-06
Iter: 1983 loss: 5.54519238e-06
Iter: 1984 loss: 5.53872223e-06
Iter: 1985 loss: 5.57290468e-06
Iter: 1986 loss: 5.5377709e-06
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi0_phi3/300_100_100_100_1
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output120/f2_psi1_phi0
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output121/f2_psi1_phi0
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output120/f2_psi1_phi0 /home/mrdouglas/Manifold/experiments.final/output121/f2_psi1_phi0
+ date
Sun Nov  8 12:32:49 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output120/f2_psi1_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --load_model experiments.yidi/biholo/f0_psi0.5/300_100_100_100_1 --function f2 --psi 1 --alpha 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output120/f2_psi1_phi0/ --save_name 300_100_100_100_1 --optimizer adam --n_pairs 20000 --batch_size 5000 --max_epochs 400 --loss_func weighted_MAPE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdecbe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdecbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdce8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffde18f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdd4a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701d4c8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdd58a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdd58840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdc88ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdbac730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdbde268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdcadd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdc2f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdc2fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdb27f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdc2fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdac8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdaddc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdb77bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdb77ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffda322f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd656ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd6534950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd6546f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd6547510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdc21f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffdc21950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd64b1048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd64972f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd647c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fd6497ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb03d1ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb03d19d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fb03d1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffda8d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6ffda658c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
train_loss: 0.0017627226
test_loss: 0.001731871
train_loss: 0.0018746128
test_loss: 0.0018748816
train_loss: 0.0017830019
test_loss: 0.0019405216
train_loss: 0.001687341
test_loss: 0.0020070064
train_loss: 0.0017368714
test_loss: 0.0019355101
train_loss: 0.0018643112
test_loss: 0.0018940091
train_loss: 0.001743909
test_loss: 0.0018685193
train_loss: 0.0018400254
test_loss: 0.0017502292
train_loss: 0.0018537773
test_loss: 0.0018276648
train_loss: 0.00185027
test_loss: 0.0018574293
train_loss: 0.001760981
test_loss: 0.0017535298
train_loss: 0.0018995698
test_loss: 0.0022883546
train_loss: 0.0017816327
test_loss: 0.0018716689
train_loss: 0.0017481815
test_loss: 0.0017537342
train_loss: 0.0017354791
test_loss: 0.0017103786
train_loss: 0.0017991357
test_loss: 0.0018004299
train_loss: 0.0016785702
test_loss: 0.0016527091
train_loss: 0.0017979883
test_loss: 0.0017856596
train_loss: 0.0017665984
test_loss: 0.0018909989
train_loss: 0.0017124652
test_loss: 0.0018397468
train_loss: 0.0018337319
test_loss: 0.0017458663
train_loss: 0.0018643178
test_loss: 0.0017027487
train_loss: 0.0017865617
test_loss: 0.001736674
train_loss: 0.0016743352
test_loss: 0.0018148423
train_loss: 0.0018741337
test_loss: 0.0018454781
train_loss: 0.0020375894
test_loss: 0.0017917516
train_loss: 0.0016052083
test_loss: 0.0018069312
train_loss: 0.0017865616
test_loss: 0.0016597279
train_loss: 0.0017008662
test_loss: 0.0017044549
train_loss: 0.0017553514
test_loss: 0.0018978743
train_loss: 0.001954615
test_loss: 0.0017594284
train_loss: 0.0017127322
test_loss: 0.0016829625
train_loss: 0.0016210718
test_loss: 0.0017610933
train_loss: 0.0018898377
test_loss: 0.001750259
train_loss: 0.0016903426
test_loss: 0.0018119352
train_loss: 0.0019366811
test_loss: 0.0018617299
train_loss: 0.0015563703
test_loss: 0.0016870926
train_loss: 0.001893253
test_loss: 0.0018338194
train_loss: 0.0017002183
test_loss: 0.001867999
train_loss: 0.0019501878
test_loss: 0.0017483633
train_loss: 0.0017444994
test_loss: 0.0017192678
train_loss: 0.0016955694
test_loss: 0.0018458694
train_loss: 0.0017398447
test_loss: 0.0017198684
train_loss: 0.0015878002
test_loss: 0.0016931642
train_loss: 0.0018225963
test_loss: 0.001881297
train_loss: 0.0017396945
test_loss: 0.0017394987
train_loss: 0.0016476141
test_loss: 0.0017653775
train_loss: 0.0017690904
test_loss: 0.0016838859
train_loss: 0.0019090748
test_loss: 0.0019569625
train_loss: 0.0015442003
test_loss: 0.001683316
train_loss: 0.0018065542
test_loss: 0.0016856877
train_loss: 0.0016261765
test_loss: 0.0017798448
train_loss: 0.0016642201
test_loss: 0.0021416247
train_loss: 0.0017417767
test_loss: 0.0020520973
train_loss: 0.0019047585
test_loss: 0.0018241492
train_loss: 0.001733222
test_loss: 0.0020265682
train_loss: 0.0015459959
test_loss: 0.0016215686
train_loss: 0.0016896965
test_loss: 0.0017098875
train_loss: 0.0016602001
test_loss: 0.0017894163
train_loss: 0.0016326979
test_loss: 0.0017512955
train_loss: 0.0016474396
test_loss: 0.001605966
train_loss: 0.0016738784
test_loss: 0.0016740746
train_loss: 0.0017704035
test_loss: 0.0017178212
train_loss: 0.0016705889
test_loss: 0.0016485315
train_loss: 0.0018109663
test_loss: 0.0019485175
train_loss: 0.0015970208
test_loss: 0.0017079028
train_loss: 0.001737094
test_loss: 0.0017210364
train_loss: 0.0016231822
test_loss: 0.0017385831
train_loss: 0.0016640364
test_loss: 0.0017146203
train_loss: 0.0018494541
test_loss: 0.0018863956
train_loss: 0.001843473
test_loss: 0.0018529722
train_loss: 0.0015194366
test_loss: 0.0016052467
train_loss: 0.0016495358
test_loss: 0.0016874435
train_loss: 0.001672132
test_loss: 0.0018020747
train_loss: 0.0016850648
test_loss: 0.0020160081
train_loss: 0.0016415594
test_loss: 0.00173556
train_loss: 0.0016581565
test_loss: 0.0016041094
train_loss: 0.0017235152
test_loss: 0.0016293324
train_loss: 0.0017239276
test_loss: 0.0018693287
train_loss: 0.0016990667
test_loss: 0.0017263594
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output121/f2_psi1_phi0/300_100_100_100_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 4000 --load_model /home/mrdouglas/Manifold/experiments.final/output120/f2_psi1_phi0/300_100_100_100_1 --optimizer lbfgs --function f2 --psi 1 --alpha 0 --layers 300_100_100_100_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output121/f2_psi1_phi0/ --save_name 300_100_100_100_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 300_100_100_100_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f635987ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63598897b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f635987ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63597df048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63597da2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63597da8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63597daf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6359711ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6359777e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63596e9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6359695488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6359777730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63596c7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63596870d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63596c7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6359664ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6359664598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63596646a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63595c1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63595c16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f635957b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f635953e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63594ea620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63594abae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63594ab8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63594ab950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f63594b4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c7726a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c7987b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c798f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c7aa158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c6fdb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c768ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c6cf9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c692a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f631c69d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.39836822e-06
Iter: 2 loss: 6.07707079e-06
Iter: 3 loss: 3.69075701e-06
Iter: 4 loss: 3.37211236e-06
Iter: 5 loss: 4.04894763e-06
Iter: 6 loss: 3.24689586e-06
Iter: 7 loss: 3.13048326e-06
Iter: 8 loss: 2.95766176e-06
Iter: 9 loss: 2.95367113e-06
Iter: 10 loss: 2.99283056e-06
Iter: 11 loss: 2.86875638e-06
Iter: 12 loss: 2.83147892e-06
Iter: 13 loss: 2.81797611e-06
Iter: 14 loss: 2.79712822e-06
Iter: 15 loss: 2.76536593e-06
Iter: 16 loss: 3.02014e-06
Iter: 17 loss: 2.76325227e-06
Iter: 18 loss: 2.72581974e-06
Iter: 19 loss: 2.71696626e-06
Iter: 20 loss: 2.69295333e-06
Iter: 21 loss: 2.65548078e-06
Iter: 22 loss: 2.60942829e-06
Iter: 23 loss: 2.60524189e-06
Iter: 24 loss: 2.55300074e-06
Iter: 25 loss: 2.55076702e-06
Iter: 26 loss: 2.51034635e-06
Iter: 27 loss: 2.43916702e-06
Iter: 28 loss: 2.43916452e-06
Iter: 29 loss: 2.3674329e-06
Iter: 30 loss: 2.25074609e-06
Iter: 31 loss: 2.25002123e-06
Iter: 32 loss: 2.17742058e-06
Iter: 33 loss: 2.17034312e-06
Iter: 34 loss: 2.13100657e-06
Iter: 35 loss: 2.1306505e-06
Iter: 36 loss: 2.10116286e-06
Iter: 37 loss: 2.04208482e-06
Iter: 38 loss: 3.15606098e-06
Iter: 39 loss: 2.04124376e-06
Iter: 40 loss: 2.00811087e-06
Iter: 41 loss: 2.40443615e-06
Iter: 42 loss: 2.00769682e-06
Iter: 43 loss: 1.98347743e-06
Iter: 44 loss: 2.28067529e-06
Iter: 45 loss: 1.98320549e-06
Iter: 46 loss: 1.96616156e-06
Iter: 47 loss: 1.92923289e-06
Iter: 48 loss: 2.50269204e-06
Iter: 49 loss: 1.92790867e-06
Iter: 50 loss: 1.92960874e-06
Iter: 51 loss: 1.91198978e-06
Iter: 52 loss: 1.90246692e-06
Iter: 53 loss: 1.87988189e-06
Iter: 54 loss: 2.14054853e-06
Iter: 55 loss: 1.8778112e-06
Iter: 56 loss: 1.84537703e-06
Iter: 57 loss: 1.85434169e-06
Iter: 58 loss: 1.82194219e-06
Iter: 59 loss: 1.80129678e-06
Iter: 60 loss: 1.7951503e-06
Iter: 61 loss: 1.7843555e-06
Iter: 62 loss: 1.75086075e-06
Iter: 63 loss: 1.81767621e-06
Iter: 64 loss: 1.72984903e-06
Iter: 65 loss: 1.66857126e-06
Iter: 66 loss: 1.96753717e-06
Iter: 67 loss: 1.65786571e-06
Iter: 68 loss: 1.6313071e-06
Iter: 69 loss: 1.63081359e-06
Iter: 70 loss: 1.59827744e-06
Iter: 71 loss: 1.56374517e-06
Iter: 72 loss: 1.55800785e-06
Iter: 73 loss: 1.51370023e-06
Iter: 74 loss: 1.59902584e-06
Iter: 75 loss: 1.49519474e-06
Iter: 76 loss: 1.48323033e-06
Iter: 77 loss: 1.47971309e-06
Iter: 78 loss: 1.46334673e-06
Iter: 79 loss: 1.4438906e-06
Iter: 80 loss: 1.44179512e-06
Iter: 81 loss: 1.4294842e-06
Iter: 82 loss: 1.42947442e-06
Iter: 83 loss: 1.41850228e-06
Iter: 84 loss: 1.44200521e-06
Iter: 85 loss: 1.41418332e-06
Iter: 86 loss: 1.40603515e-06
Iter: 87 loss: 1.39290773e-06
Iter: 88 loss: 1.39276062e-06
Iter: 89 loss: 1.38547455e-06
Iter: 90 loss: 1.38415066e-06
Iter: 91 loss: 1.37550569e-06
Iter: 92 loss: 1.36640244e-06
Iter: 93 loss: 1.36480026e-06
Iter: 94 loss: 1.34969173e-06
Iter: 95 loss: 1.32515527e-06
Iter: 96 loss: 1.32498712e-06
Iter: 97 loss: 1.29667308e-06
Iter: 98 loss: 1.41798932e-06
Iter: 99 loss: 1.29083469e-06
Iter: 100 loss: 1.26865677e-06
Iter: 101 loss: 1.2680191e-06
Iter: 102 loss: 1.25597194e-06
Iter: 103 loss: 1.24591179e-06
Iter: 104 loss: 1.24254007e-06
Iter: 105 loss: 1.23038467e-06
Iter: 106 loss: 1.23862355e-06
Iter: 107 loss: 1.22278198e-06
Iter: 108 loss: 1.2085959e-06
Iter: 109 loss: 1.20841764e-06
Iter: 110 loss: 1.20293885e-06
Iter: 111 loss: 1.19692436e-06
Iter: 112 loss: 1.19605681e-06
Iter: 113 loss: 1.18860794e-06
Iter: 114 loss: 1.18858338e-06
Iter: 115 loss: 1.18263904e-06
Iter: 116 loss: 1.16858564e-06
Iter: 117 loss: 1.32636615e-06
Iter: 118 loss: 1.16725801e-06
Iter: 119 loss: 1.15823468e-06
Iter: 120 loss: 1.28892339e-06
Iter: 121 loss: 1.15821035e-06
Iter: 122 loss: 1.14971817e-06
Iter: 123 loss: 1.19954632e-06
Iter: 124 loss: 1.14863917e-06
Iter: 125 loss: 1.1423615e-06
Iter: 126 loss: 1.13360716e-06
Iter: 127 loss: 1.13325962e-06
Iter: 128 loss: 1.12576743e-06
Iter: 129 loss: 1.12816451e-06
Iter: 130 loss: 1.12041744e-06
Iter: 131 loss: 1.11479994e-06
Iter: 132 loss: 1.11385066e-06
Iter: 133 loss: 1.10782821e-06
Iter: 134 loss: 1.10300425e-06
Iter: 135 loss: 1.10115695e-06
Iter: 136 loss: 1.09236953e-06
Iter: 137 loss: 1.07702817e-06
Iter: 138 loss: 1.0770076e-06
Iter: 139 loss: 1.08140978e-06
Iter: 140 loss: 1.06941297e-06
Iter: 141 loss: 1.06407765e-06
Iter: 142 loss: 1.05364757e-06
Iter: 143 loss: 1.27085912e-06
Iter: 144 loss: 1.05360027e-06
Iter: 145 loss: 1.04741582e-06
Iter: 146 loss: 1.04717299e-06
Iter: 147 loss: 1.04086655e-06
Iter: 148 loss: 1.04036985e-06
Iter: 149 loss: 1.03560023e-06
Iter: 150 loss: 1.03139928e-06
Iter: 151 loss: 1.02773913e-06
Iter: 152 loss: 1.02660636e-06
Iter: 153 loss: 1.02524496e-06
Iter: 154 loss: 1.02347337e-06
Iter: 155 loss: 1.02118315e-06
Iter: 156 loss: 1.01839601e-06
Iter: 157 loss: 1.01812475e-06
Iter: 158 loss: 1.01424894e-06
Iter: 159 loss: 1.00880345e-06
Iter: 160 loss: 1.00858711e-06
Iter: 161 loss: 1.00234638e-06
Iter: 162 loss: 1.06446237e-06
Iter: 163 loss: 1.00214254e-06
Iter: 164 loss: 9.98902237e-07
Iter: 165 loss: 9.98833912e-07
Iter: 166 loss: 9.95584287e-07
Iter: 167 loss: 9.86544364e-07
Iter: 168 loss: 1.03932655e-06
Iter: 169 loss: 9.84012217e-07
Iter: 170 loss: 9.76937827e-07
Iter: 171 loss: 1.01738146e-06
Iter: 172 loss: 9.75944772e-07
Iter: 173 loss: 9.6974054e-07
Iter: 174 loss: 1.02627382e-06
Iter: 175 loss: 9.69481221e-07
Iter: 176 loss: 9.6205e-07
Iter: 177 loss: 9.70975634e-07
Iter: 178 loss: 9.58148462e-07
Iter: 179 loss: 9.5480641e-07
Iter: 180 loss: 9.66557536e-07
Iter: 181 loss: 9.53883e-07
Iter: 182 loss: 9.47997876e-07
Iter: 183 loss: 9.37195864e-07
Iter: 184 loss: 1.19092158e-06
Iter: 185 loss: 9.37215589e-07
Iter: 186 loss: 9.31578256e-07
Iter: 187 loss: 9.53644e-07
Iter: 188 loss: 9.30321676e-07
Iter: 189 loss: 9.27419478e-07
Iter: 190 loss: 9.2722513e-07
Iter: 191 loss: 9.24223514e-07
Iter: 192 loss: 9.18763362e-07
Iter: 193 loss: 1.04409742e-06
Iter: 194 loss: 9.18730962e-07
Iter: 195 loss: 9.15756e-07
Iter: 196 loss: 9.21098831e-07
Iter: 197 loss: 9.14420866e-07
Iter: 198 loss: 9.11100301e-07
Iter: 199 loss: 9.28059421e-07
Iter: 200 loss: 9.10512767e-07
Iter: 201 loss: 9.08966854e-07
Iter: 202 loss: 9.08958214e-07
Iter: 203 loss: 9.07086928e-07
Iter: 204 loss: 9.03707075e-07
Iter: 205 loss: 9.85909082e-07
Iter: 206 loss: 9.03708553e-07
Iter: 207 loss: 9.00222517e-07
Iter: 208 loss: 9.05718707e-07
Iter: 209 loss: 8.98551605e-07
Iter: 210 loss: 8.96451638e-07
Iter: 211 loss: 8.96399968e-07
Iter: 212 loss: 8.93763513e-07
Iter: 213 loss: 8.878e-07
Iter: 214 loss: 9.70527253e-07
Iter: 215 loss: 8.87464921e-07
Iter: 216 loss: 8.84883093e-07
Iter: 217 loss: 8.84641054e-07
Iter: 218 loss: 8.81657343e-07
Iter: 219 loss: 8.8098e-07
Iter: 220 loss: 8.79110189e-07
Iter: 221 loss: 8.75441174e-07
Iter: 222 loss: 8.69457097e-07
Iter: 223 loss: 8.69420546e-07
Iter: 224 loss: 8.71057296e-07
Iter: 225 loss: 8.67027097e-07
Iter: 226 loss: 8.64952085e-07
Iter: 227 loss: 8.59511943e-07
Iter: 228 loss: 9.03332307e-07
Iter: 229 loss: 8.58477279e-07
Iter: 230 loss: 8.54201062e-07
Iter: 231 loss: 8.82305756e-07
Iter: 232 loss: 8.53749611e-07
Iter: 233 loss: 8.50879815e-07
Iter: 234 loss: 8.55093788e-07
Iter: 235 loss: 8.49489425e-07
Iter: 236 loss: 8.48664172e-07
Iter: 237 loss: 8.48223181e-07
Iter: 238 loss: 8.47059368e-07
Iter: 239 loss: 8.47593924e-07
Iter: 240 loss: 8.46221326e-07
Iter: 241 loss: 8.44772e-07
Iter: 242 loss: 8.44949398e-07
Iter: 243 loss: 8.43659905e-07
Iter: 244 loss: 8.42007125e-07
Iter: 245 loss: 8.42025031e-07
Iter: 246 loss: 8.41281405e-07
Iter: 247 loss: 8.3926335e-07
Iter: 248 loss: 8.51720358e-07
Iter: 249 loss: 8.38690653e-07
Iter: 250 loss: 8.35699836e-07
Iter: 251 loss: 8.75820717e-07
Iter: 252 loss: 8.35711717e-07
Iter: 253 loss: 8.33438776e-07
Iter: 254 loss: 8.297406e-07
Iter: 255 loss: 8.29744693e-07
Iter: 256 loss: 8.26882683e-07
Iter: 257 loss: 8.25861321e-07
Iter: 258 loss: 8.24260724e-07
Iter: 259 loss: 8.21600622e-07
Iter: 260 loss: 8.21052765e-07
Iter: 261 loss: 8.19978482e-07
Iter: 262 loss: 8.18014598e-07
Iter: 263 loss: 8.18029e-07
Iter: 264 loss: 8.15975852e-07
Iter: 265 loss: 8.15201361e-07
Iter: 266 loss: 8.14102918e-07
Iter: 267 loss: 8.12711448e-07
Iter: 268 loss: 8.12705366e-07
Iter: 269 loss: 8.11318216e-07
Iter: 270 loss: 8.14134751e-07
Iter: 271 loss: 8.10777465e-07
Iter: 272 loss: 8.09613539e-07
Iter: 273 loss: 8.13735483e-07
Iter: 274 loss: 8.09294647e-07
Iter: 275 loss: 8.0844211e-07
Iter: 276 loss: 8.21173785e-07
Iter: 277 loss: 8.08451091e-07
Iter: 278 loss: 8.07734068e-07
Iter: 279 loss: 8.05942477e-07
Iter: 280 loss: 8.21355854e-07
Iter: 281 loss: 8.05643253e-07
Iter: 282 loss: 8.0447461e-07
Iter: 283 loss: 8.04367176e-07
Iter: 284 loss: 8.03097919e-07
Iter: 285 loss: 8.03319836e-07
Iter: 286 loss: 8.02154204e-07
Iter: 287 loss: 8.00822249e-07
Iter: 288 loss: 7.97567566e-07
Iter: 289 loss: 8.3168112e-07
Iter: 290 loss: 7.9718734e-07
Iter: 291 loss: 7.96450706e-07
Iter: 292 loss: 7.95441906e-07
Iter: 293 loss: 7.93378376e-07
Iter: 294 loss: 7.9036613e-07
Iter: 295 loss: 7.90310878e-07
Iter: 296 loss: 7.86999863e-07
Iter: 297 loss: 7.911475e-07
Iter: 298 loss: 7.85286e-07
Iter: 299 loss: 7.83415658e-07
Iter: 300 loss: 7.97296195e-07
Iter: 301 loss: 7.83263772e-07
Iter: 302 loss: 7.81605422e-07
Iter: 303 loss: 7.94809296e-07
Iter: 304 loss: 7.81451206e-07
Iter: 305 loss: 7.80187179e-07
Iter: 306 loss: 7.80256e-07
Iter: 307 loss: 7.79228799e-07
Iter: 308 loss: 7.78389392e-07
Iter: 309 loss: 7.89207263e-07
Iter: 310 loss: 7.78419121e-07
Iter: 311 loss: 7.77513549e-07
Iter: 312 loss: 7.77523837e-07
Iter: 313 loss: 7.76800334e-07
Iter: 314 loss: 7.75859462e-07
Iter: 315 loss: 7.75943249e-07
Iter: 316 loss: 7.75103e-07
Iter: 317 loss: 7.7407924e-07
Iter: 318 loss: 7.74077648e-07
Iter: 319 loss: 7.73199872e-07
Iter: 320 loss: 7.70585586e-07
Iter: 321 loss: 7.77726655e-07
Iter: 322 loss: 7.69157509e-07
Iter: 323 loss: 7.66268897e-07
Iter: 324 loss: 7.89308672e-07
Iter: 325 loss: 7.66053631e-07
Iter: 326 loss: 7.64213837e-07
Iter: 327 loss: 7.64176832e-07
Iter: 328 loss: 7.62956e-07
Iter: 329 loss: 7.60775833e-07
Iter: 330 loss: 8.11900918e-07
Iter: 331 loss: 7.6074906e-07
Iter: 332 loss: 7.58906253e-07
Iter: 333 loss: 7.61927254e-07
Iter: 334 loss: 7.58052636e-07
Iter: 335 loss: 7.57356815e-07
Iter: 336 loss: 7.56987845e-07
Iter: 337 loss: 7.56271106e-07
Iter: 338 loss: 7.55631334e-07
Iter: 339 loss: 7.55401175e-07
Iter: 340 loss: 7.5417455e-07
Iter: 341 loss: 7.53589063e-07
Iter: 342 loss: 7.52971459e-07
Iter: 343 loss: 7.52167466e-07
Iter: 344 loss: 7.51842833e-07
Iter: 345 loss: 7.51282585e-07
Iter: 346 loss: 7.50447214e-07
Iter: 347 loss: 7.50429763e-07
Iter: 348 loss: 7.49604169e-07
Iter: 349 loss: 7.57313842e-07
Iter: 350 loss: 7.49582e-07
Iter: 351 loss: 7.48648745e-07
Iter: 352 loss: 7.49093488e-07
Iter: 353 loss: 7.48038588e-07
Iter: 354 loss: 7.47508466e-07
Iter: 355 loss: 7.46931846e-07
Iter: 356 loss: 7.4686568e-07
Iter: 357 loss: 7.45970169e-07
Iter: 358 loss: 7.50687377e-07
Iter: 359 loss: 7.45826924e-07
Iter: 360 loss: 7.44774241e-07
Iter: 361 loss: 7.508811e-07
Iter: 362 loss: 7.44667489e-07
Iter: 363 loss: 7.44189492e-07
Iter: 364 loss: 7.42774944e-07
Iter: 365 loss: 7.46052478e-07
Iter: 366 loss: 7.41906547e-07
Iter: 367 loss: 7.39549705e-07
Iter: 368 loss: 7.60412092e-07
Iter: 369 loss: 7.39444886e-07
Iter: 370 loss: 7.38291362e-07
Iter: 371 loss: 7.38153517e-07
Iter: 372 loss: 7.37258631e-07
Iter: 373 loss: 7.35139e-07
Iter: 374 loss: 7.59063141e-07
Iter: 375 loss: 7.34900482e-07
Iter: 376 loss: 7.34113712e-07
Iter: 377 loss: 7.33944944e-07
Iter: 378 loss: 7.32910735e-07
Iter: 379 loss: 7.34086655e-07
Iter: 380 loss: 7.32280228e-07
Iter: 381 loss: 7.31657678e-07
Iter: 382 loss: 7.34597336e-07
Iter: 383 loss: 7.31546208e-07
Iter: 384 loss: 7.30990223e-07
Iter: 385 loss: 7.34037428e-07
Iter: 386 loss: 7.30897398e-07
Iter: 387 loss: 7.30474824e-07
Iter: 388 loss: 7.29543217e-07
Iter: 389 loss: 7.43219516e-07
Iter: 390 loss: 7.2949706e-07
Iter: 391 loss: 7.28486782e-07
Iter: 392 loss: 7.34823516e-07
Iter: 393 loss: 7.28353484e-07
Iter: 394 loss: 7.28098485e-07
Iter: 395 loss: 7.27958e-07
Iter: 396 loss: 7.27597921e-07
Iter: 397 loss: 7.26531312e-07
Iter: 398 loss: 7.30078796e-07
Iter: 399 loss: 7.26021312e-07
Iter: 400 loss: 7.24927418e-07
Iter: 401 loss: 7.30570264e-07
Iter: 402 loss: 7.24741085e-07
Iter: 403 loss: 7.2398052e-07
Iter: 404 loss: 7.36364541e-07
Iter: 405 loss: 7.23958465e-07
Iter: 406 loss: 7.23004177e-07
Iter: 407 loss: 7.22692789e-07
Iter: 408 loss: 7.22126515e-07
Iter: 409 loss: 7.21260449e-07
Iter: 410 loss: 7.2009334e-07
Iter: 411 loss: 7.19981529e-07
Iter: 412 loss: 7.18571812e-07
Iter: 413 loss: 7.18536739e-07
Iter: 414 loss: 7.17634236e-07
Iter: 415 loss: 7.16885324e-07
Iter: 416 loss: 7.16666932e-07
Iter: 417 loss: 7.15748456e-07
Iter: 418 loss: 7.15713213e-07
Iter: 419 loss: 7.15153362e-07
Iter: 420 loss: 7.14285591e-07
Iter: 421 loss: 7.1422869e-07
Iter: 422 loss: 7.1341924e-07
Iter: 423 loss: 7.15810302e-07
Iter: 424 loss: 7.13174131e-07
Iter: 425 loss: 7.12628264e-07
Iter: 426 loss: 7.1945135e-07
Iter: 427 loss: 7.12620817e-07
Iter: 428 loss: 7.12033227e-07
Iter: 429 loss: 7.13205281e-07
Iter: 430 loss: 7.11768394e-07
Iter: 431 loss: 7.11434893e-07
Iter: 432 loss: 7.10771815e-07
Iter: 433 loss: 7.22858942e-07
Iter: 434 loss: 7.10762492e-07
Iter: 435 loss: 7.09723167e-07
Iter: 436 loss: 7.10630843e-07
Iter: 437 loss: 7.09152573e-07
Iter: 438 loss: 7.08942e-07
Iter: 439 loss: 7.08482446e-07
Iter: 440 loss: 7.08040147e-07
Iter: 441 loss: 7.06695062e-07
Iter: 442 loss: 7.13631437e-07
Iter: 443 loss: 7.06271692e-07
Iter: 444 loss: 7.05592129e-07
Iter: 445 loss: 7.05431489e-07
Iter: 446 loss: 7.04624e-07
Iter: 447 loss: 7.05609182e-07
Iter: 448 loss: 7.04152e-07
Iter: 449 loss: 7.03476758e-07
Iter: 450 loss: 7.04448894e-07
Iter: 451 loss: 7.03094088e-07
Iter: 452 loss: 7.01932265e-07
Iter: 453 loss: 7.05107936e-07
Iter: 454 loss: 7.01581257e-07
Iter: 455 loss: 7.00979058e-07
Iter: 456 loss: 7.00483952e-07
Iter: 457 loss: 7.003365e-07
Iter: 458 loss: 6.99305474e-07
Iter: 459 loss: 6.99176212e-07
Iter: 460 loss: 6.98473855e-07
Iter: 461 loss: 6.98656891e-07
Iter: 462 loss: 6.97969597e-07
Iter: 463 loss: 6.97548671e-07
Iter: 464 loss: 6.97172425e-07
Iter: 465 loss: 6.97078178e-07
Iter: 466 loss: 6.9661354e-07
Iter: 467 loss: 6.96172378e-07
Iter: 468 loss: 6.96036466e-07
Iter: 469 loss: 6.95334052e-07
Iter: 470 loss: 6.97404403e-07
Iter: 471 loss: 6.95081269e-07
Iter: 472 loss: 6.94415576e-07
Iter: 473 loss: 6.94404775e-07
Iter: 474 loss: 6.94052e-07
Iter: 475 loss: 6.93219363e-07
Iter: 476 loss: 7.04398929e-07
Iter: 477 loss: 6.93186394e-07
Iter: 478 loss: 6.9246164e-07
Iter: 479 loss: 6.92441631e-07
Iter: 480 loss: 6.91589094e-07
Iter: 481 loss: 6.90550621e-07
Iter: 482 loss: 6.90472916e-07
Iter: 483 loss: 6.89827914e-07
Iter: 484 loss: 6.89829506e-07
Iter: 485 loss: 6.89106116e-07
Iter: 486 loss: 6.87926217e-07
Iter: 487 loss: 6.87926104e-07
Iter: 488 loss: 6.87152692e-07
Iter: 489 loss: 6.90252136e-07
Iter: 490 loss: 6.86967951e-07
Iter: 491 loss: 6.86475119e-07
Iter: 492 loss: 6.87071633e-07
Iter: 493 loss: 6.86187377e-07
Iter: 494 loss: 6.85868372e-07
Iter: 495 loss: 6.85813063e-07
Iter: 496 loss: 6.85556074e-07
Iter: 497 loss: 6.86530257e-07
Iter: 498 loss: 6.85517762e-07
Iter: 499 loss: 6.85276518e-07
Iter: 500 loss: 6.84715815e-07
Iter: 501 loss: 6.85871214e-07
Iter: 502 loss: 6.84316319e-07
Iter: 503 loss: 6.83344524e-07
Iter: 504 loss: 6.89323599e-07
Iter: 505 loss: 6.83201677e-07
Iter: 506 loss: 6.82735447e-07
Iter: 507 loss: 6.8267326e-07
Iter: 508 loss: 6.82158657e-07
Iter: 509 loss: 6.81124391e-07
Iter: 510 loss: 7.01716829e-07
Iter: 511 loss: 6.81096253e-07
Iter: 512 loss: 6.80277935e-07
Iter: 513 loss: 6.81052143e-07
Iter: 514 loss: 6.7978e-07
Iter: 515 loss: 6.79535276e-07
Iter: 516 loss: 6.79229402e-07
Iter: 517 loss: 6.78867423e-07
Iter: 518 loss: 6.78157107e-07
Iter: 519 loss: 6.92646154e-07
Iter: 520 loss: 6.78161882e-07
Iter: 521 loss: 6.77732544e-07
Iter: 522 loss: 6.77756134e-07
Iter: 523 loss: 6.77331627e-07
Iter: 524 loss: 6.77177354e-07
Iter: 525 loss: 6.76930767e-07
Iter: 526 loss: 6.76605168e-07
Iter: 527 loss: 6.76163268e-07
Iter: 528 loss: 6.76101763e-07
Iter: 529 loss: 6.76017748e-07
Iter: 530 loss: 6.75844e-07
Iter: 531 loss: 6.75610409e-07
Iter: 532 loss: 6.75710623e-07
Iter: 533 loss: 6.75423166e-07
Iter: 534 loss: 6.75213073e-07
Iter: 535 loss: 6.74764181e-07
Iter: 536 loss: 6.84896236e-07
Iter: 537 loss: 6.74761395e-07
Iter: 538 loss: 6.74215926e-07
Iter: 539 loss: 6.77624826e-07
Iter: 540 loss: 6.74126682e-07
Iter: 541 loss: 6.73713828e-07
Iter: 542 loss: 6.76691798e-07
Iter: 543 loss: 6.73702061e-07
Iter: 544 loss: 6.73116688e-07
Iter: 545 loss: 6.72768692e-07
Iter: 546 loss: 6.72555416e-07
Iter: 547 loss: 6.71916837e-07
Iter: 548 loss: 6.72122667e-07
Iter: 549 loss: 6.71421219e-07
Iter: 550 loss: 6.70745294e-07
Iter: 551 loss: 6.76884838e-07
Iter: 552 loss: 6.70705219e-07
Iter: 553 loss: 6.69867632e-07
Iter: 554 loss: 6.70408212e-07
Iter: 555 loss: 6.69334611e-07
Iter: 556 loss: 6.690139e-07
Iter: 557 loss: 6.69600922e-07
Iter: 558 loss: 6.68890607e-07
Iter: 559 loss: 6.68418863e-07
Iter: 560 loss: 6.71082944e-07
Iter: 561 loss: 6.68336952e-07
Iter: 562 loss: 6.6807479e-07
Iter: 563 loss: 6.67783183e-07
Iter: 564 loss: 6.67707923e-07
Iter: 565 loss: 6.67681e-07
Iter: 566 loss: 6.67568088e-07
Iter: 567 loss: 6.67415748e-07
Iter: 568 loss: 6.66969527e-07
Iter: 569 loss: 6.67497488e-07
Iter: 570 loss: 6.66657115e-07
Iter: 571 loss: 6.65954133e-07
Iter: 572 loss: 6.71563498e-07
Iter: 573 loss: 6.65933726e-07
Iter: 574 loss: 6.65322034e-07
Iter: 575 loss: 6.65963796e-07
Iter: 576 loss: 6.64986374e-07
Iter: 577 loss: 6.64592903e-07
Iter: 578 loss: 6.64590061e-07
Iter: 579 loss: 6.6413611e-07
Iter: 580 loss: 6.65137e-07
Iter: 581 loss: 6.63936873e-07
Iter: 582 loss: 6.63608603e-07
Iter: 583 loss: 6.63526521e-07
Iter: 584 loss: 6.63321828e-07
Iter: 585 loss: 6.63224796e-07
Iter: 586 loss: 6.63106789e-07
Iter: 587 loss: 6.62853552e-07
Iter: 588 loss: 6.62207867e-07
Iter: 589 loss: 6.66082144e-07
Iter: 590 loss: 6.62029265e-07
Iter: 591 loss: 6.61769491e-07
Iter: 592 loss: 6.61643639e-07
Iter: 593 loss: 6.61329295e-07
Iter: 594 loss: 6.61260572e-07
Iter: 595 loss: 6.61011654e-07
Iter: 596 loss: 6.60647515e-07
Iter: 597 loss: 6.596905e-07
Iter: 598 loss: 6.69208418e-07
Iter: 599 loss: 6.59584543e-07
Iter: 600 loss: 6.60136948e-07
Iter: 601 loss: 6.59109162e-07
Iter: 602 loss: 6.58937267e-07
Iter: 603 loss: 6.58700174e-07
Iter: 604 loss: 6.58710576e-07
Iter: 605 loss: 6.58330464e-07
Iter: 606 loss: 6.5824014e-07
Iter: 607 loss: 6.5799918e-07
Iter: 608 loss: 6.5762481e-07
Iter: 609 loss: 6.61310764e-07
Iter: 610 loss: 6.57622422e-07
Iter: 611 loss: 6.57339399e-07
Iter: 612 loss: 6.58925273e-07
Iter: 613 loss: 6.57282158e-07
Iter: 614 loss: 6.56909492e-07
Iter: 615 loss: 6.562e-07
Iter: 616 loss: 6.56225325e-07
Iter: 617 loss: 6.55564577e-07
Iter: 618 loss: 6.56094926e-07
Iter: 619 loss: 6.55142969e-07
Iter: 620 loss: 6.54417249e-07
Iter: 621 loss: 6.54402356e-07
Iter: 622 loss: 6.54097335e-07
Iter: 623 loss: 6.53483426e-07
Iter: 624 loss: 6.63224796e-07
Iter: 625 loss: 6.53471375e-07
Iter: 626 loss: 6.52917151e-07
Iter: 627 loss: 6.58043632e-07
Iter: 628 loss: 6.52876111e-07
Iter: 629 loss: 6.5235588e-07
Iter: 630 loss: 6.55077088e-07
Iter: 631 loss: 6.52242306e-07
Iter: 632 loss: 6.52038125e-07
Iter: 633 loss: 6.51832181e-07
Iter: 634 loss: 6.51757489e-07
Iter: 635 loss: 6.51397045e-07
Iter: 636 loss: 6.51477876e-07
Iter: 637 loss: 6.51100095e-07
Iter: 638 loss: 6.50827246e-07
Iter: 639 loss: 6.50817e-07
Iter: 640 loss: 6.50531547e-07
Iter: 641 loss: 6.5199481e-07
Iter: 642 loss: 6.50484481e-07
Iter: 643 loss: 6.50285756e-07
Iter: 644 loss: 6.49906951e-07
Iter: 645 loss: 6.55867439e-07
Iter: 646 loss: 6.49890069e-07
Iter: 647 loss: 6.497512e-07
Iter: 648 loss: 6.49656158e-07
Iter: 649 loss: 6.49464937e-07
Iter: 650 loss: 6.49237052e-07
Iter: 651 loss: 6.49181231e-07
Iter: 652 loss: 6.48958689e-07
Iter: 653 loss: 6.4907664e-07
Iter: 654 loss: 6.48779519e-07
Iter: 655 loss: 6.48476771e-07
Iter: 656 loss: 6.4847012e-07
Iter: 657 loss: 6.48245418e-07
Iter: 658 loss: 6.47803631e-07
Iter: 659 loss: 6.55202541e-07
Iter: 660 loss: 6.47794081e-07
Iter: 661 loss: 6.47580691e-07
Iter: 662 loss: 6.47517879e-07
Iter: 663 loss: 6.47350362e-07
Iter: 664 loss: 6.46821718e-07
Iter: 665 loss: 6.50113634e-07
Iter: 666 loss: 6.46710077e-07
Iter: 667 loss: 6.46118735e-07
Iter: 668 loss: 6.46863327e-07
Iter: 669 loss: 6.45856e-07
Iter: 670 loss: 6.45481862e-07
Iter: 671 loss: 6.45284786e-07
Iter: 672 loss: 6.4509436e-07
Iter: 673 loss: 6.44911381e-07
Iter: 674 loss: 6.44856186e-07
Iter: 675 loss: 6.44592376e-07
Iter: 676 loss: 6.4481236e-07
Iter: 677 loss: 6.44443048e-07
Iter: 678 loss: 6.44183217e-07
Iter: 679 loss: 6.44064926e-07
Iter: 680 loss: 6.43931855e-07
Iter: 681 loss: 6.43786393e-07
Iter: 682 loss: 6.4371568e-07
Iter: 683 loss: 6.43550493e-07
Iter: 684 loss: 6.43190219e-07
Iter: 685 loss: 6.47051479e-07
Iter: 686 loss: 6.43119847e-07
Iter: 687 loss: 6.4261161e-07
Iter: 688 loss: 6.44830948e-07
Iter: 689 loss: 6.4251617e-07
Iter: 690 loss: 6.42130885e-07
Iter: 691 loss: 6.42135e-07
Iter: 692 loss: 6.41989971e-07
Iter: 693 loss: 6.4168e-07
Iter: 694 loss: 6.45377213e-07
Iter: 695 loss: 6.4164476e-07
Iter: 696 loss: 6.41239524e-07
Iter: 697 loss: 6.45295302e-07
Iter: 698 loss: 6.41221732e-07
Iter: 699 loss: 6.40987309e-07
Iter: 700 loss: 6.40709459e-07
Iter: 701 loss: 6.40674784e-07
Iter: 702 loss: 6.40306666e-07
Iter: 703 loss: 6.40240387e-07
Iter: 704 loss: 6.40016083e-07
Iter: 705 loss: 6.39604309e-07
Iter: 706 loss: 6.44799059e-07
Iter: 707 loss: 6.39606128e-07
Iter: 708 loss: 6.39335838e-07
Iter: 709 loss: 6.40313374e-07
Iter: 710 loss: 6.39269786e-07
Iter: 711 loss: 6.39040877e-07
Iter: 712 loss: 6.38978349e-07
Iter: 713 loss: 6.38827601e-07
Iter: 714 loss: 6.38562824e-07
Iter: 715 loss: 6.41085933e-07
Iter: 716 loss: 6.38530707e-07
Iter: 717 loss: 6.38300776e-07
Iter: 718 loss: 6.39296729e-07
Iter: 719 loss: 6.38270194e-07
Iter: 720 loss: 6.3810586e-07
Iter: 721 loss: 6.37908272e-07
Iter: 722 loss: 6.37911228e-07
Iter: 723 loss: 6.37743369e-07
Iter: 724 loss: 6.37723645e-07
Iter: 725 loss: 6.3759e-07
Iter: 726 loss: 6.37345352e-07
Iter: 727 loss: 6.37342339e-07
Iter: 728 loss: 6.3708535e-07
Iter: 729 loss: 6.38374672e-07
Iter: 730 loss: 6.37023447e-07
Iter: 731 loss: 6.3668864e-07
Iter: 732 loss: 6.36452853e-07
Iter: 733 loss: 6.36309608e-07
Iter: 734 loss: 6.35954734e-07
Iter: 735 loss: 6.36160792e-07
Iter: 736 loss: 6.3577113e-07
Iter: 737 loss: 6.35243623e-07
Iter: 738 loss: 6.39181053e-07
Iter: 739 loss: 6.35228844e-07
Iter: 740 loss: 6.34771197e-07
Iter: 741 loss: 6.37307721e-07
Iter: 742 loss: 6.3473351e-07
Iter: 743 loss: 6.34519552e-07
Iter: 744 loss: 6.34779269e-07
Iter: 745 loss: 6.3438074e-07
Iter: 746 loss: 6.34185596e-07
Iter: 747 loss: 6.34746755e-07
Iter: 748 loss: 6.34087826e-07
Iter: 749 loss: 6.33845161e-07
Iter: 750 loss: 6.35732704e-07
Iter: 751 loss: 6.33829814e-07
Iter: 752 loss: 6.33690433e-07
Iter: 753 loss: 6.33541674e-07
Iter: 754 loss: 6.33501372e-07
Iter: 755 loss: 6.3328622e-07
Iter: 756 loss: 6.3480951e-07
Iter: 757 loss: 6.33272293e-07
Iter: 758 loss: 6.33004674e-07
Iter: 759 loss: 6.32999559e-07
Iter: 760 loss: 6.32806461e-07
Iter: 761 loss: 6.3252503e-07
Iter: 762 loss: 6.3305788e-07
Iter: 763 loss: 6.32435672e-07
Iter: 764 loss: 6.32140654e-07
Iter: 765 loss: 6.34078333e-07
Iter: 766 loss: 6.32123601e-07
Iter: 767 loss: 6.31906744e-07
Iter: 768 loss: 6.31329499e-07
Iter: 769 loss: 6.36932668e-07
Iter: 770 loss: 6.31240937e-07
Iter: 771 loss: 6.31047442e-07
Iter: 772 loss: 6.30983266e-07
Iter: 773 loss: 6.30798922e-07
Iter: 774 loss: 6.31763385e-07
Iter: 775 loss: 6.30768511e-07
Iter: 776 loss: 6.30591444e-07
Iter: 777 loss: 6.304723e-07
Iter: 778 loss: 6.30431259e-07
Iter: 779 loss: 6.30200589e-07
Iter: 780 loss: 6.30791874e-07
Iter: 781 loss: 6.30134423e-07
Iter: 782 loss: 6.29877377e-07
Iter: 783 loss: 6.32160095e-07
Iter: 784 loss: 6.29887325e-07
Iter: 785 loss: 6.29653186e-07
Iter: 786 loss: 6.29384317e-07
Iter: 787 loss: 6.29387387e-07
Iter: 788 loss: 6.29121303e-07
Iter: 789 loss: 6.30493332e-07
Iter: 790 loss: 6.29097144e-07
Iter: 791 loss: 6.28906491e-07
Iter: 792 loss: 6.28883697e-07
Iter: 793 loss: 6.28751593e-07
Iter: 794 loss: 6.28546275e-07
Iter: 795 loss: 6.32960109e-07
Iter: 796 loss: 6.28521548e-07
Iter: 797 loss: 6.28484713e-07
Iter: 798 loss: 6.28424232e-07
Iter: 799 loss: 6.28327371e-07
Iter: 800 loss: 6.28176167e-07
Iter: 801 loss: 6.30537613e-07
Iter: 802 loss: 6.28185148e-07
Iter: 803 loss: 6.27949134e-07
Iter: 804 loss: 6.2808806e-07
Iter: 805 loss: 6.27818054e-07
Iter: 806 loss: 6.27687768e-07
Iter: 807 loss: 6.27679867e-07
Iter: 808 loss: 6.27552367e-07
Iter: 809 loss: 6.27265877e-07
Iter: 810 loss: 6.32038677e-07
Iter: 811 loss: 6.27280144e-07
Iter: 812 loss: 6.26949145e-07
Iter: 813 loss: 6.2749524e-07
Iter: 814 loss: 6.26805559e-07
Iter: 815 loss: 6.26600468e-07
Iter: 816 loss: 6.29878286e-07
Iter: 817 loss: 6.26600524e-07
Iter: 818 loss: 6.26422661e-07
Iter: 819 loss: 6.26389351e-07
Iter: 820 loss: 6.26215183e-07
Iter: 821 loss: 6.25984285e-07
Iter: 822 loss: 6.25766518e-07
Iter: 823 loss: 6.25671419e-07
Iter: 824 loss: 6.2570723e-07
Iter: 825 loss: 6.2553238e-07
Iter: 826 loss: 6.2541244e-07
Iter: 827 loss: 6.25140046e-07
Iter: 828 loss: 6.29313888e-07
Iter: 829 loss: 6.25131406e-07
Iter: 830 loss: 6.24925747e-07
Iter: 831 loss: 6.27350687e-07
Iter: 832 loss: 6.24917448e-07
Iter: 833 loss: 6.24716222e-07
Iter: 834 loss: 6.25125949e-07
Iter: 835 loss: 6.24609356e-07
Iter: 836 loss: 6.24472932e-07
Iter: 837 loss: 6.24145684e-07
Iter: 838 loss: 6.28424687e-07
Iter: 839 loss: 6.24121867e-07
Iter: 840 loss: 6.23901e-07
Iter: 841 loss: 6.23885171e-07
Iter: 842 loss: 6.23732944e-07
Iter: 843 loss: 6.26049939e-07
Iter: 844 loss: 6.23709298e-07
Iter: 845 loss: 6.23647452e-07
Iter: 846 loss: 6.23386541e-07
Iter: 847 loss: 6.24470204e-07
Iter: 848 loss: 6.23275639e-07
Iter: 849 loss: 6.22946345e-07
Iter: 850 loss: 6.24831614e-07
Iter: 851 loss: 6.2289e-07
Iter: 852 loss: 6.22652806e-07
Iter: 853 loss: 6.26377869e-07
Iter: 854 loss: 6.22657751e-07
Iter: 855 loss: 6.22448283e-07
Iter: 856 loss: 6.22003824e-07
Iter: 857 loss: 6.29384658e-07
Iter: 858 loss: 6.22040545e-07
Iter: 859 loss: 6.21695449e-07
Iter: 860 loss: 6.26563462e-07
Iter: 861 loss: 6.21710285e-07
Iter: 862 loss: 6.21434594e-07
Iter: 863 loss: 6.23658821e-07
Iter: 864 loss: 6.21435447e-07
Iter: 865 loss: 6.21263666e-07
Iter: 866 loss: 6.20921355e-07
Iter: 867 loss: 6.25789085e-07
Iter: 868 loss: 6.2091874e-07
Iter: 869 loss: 6.20874744e-07
Iter: 870 loss: 6.20750598e-07
Iter: 871 loss: 6.2065169e-07
Iter: 872 loss: 6.2048656e-07
Iter: 873 loss: 6.23949347e-07
Iter: 874 loss: 6.20488436e-07
Iter: 875 loss: 6.20305173e-07
Iter: 876 loss: 6.20490312e-07
Iter: 877 loss: 6.20182163e-07
Iter: 878 loss: 6.20085132e-07
Iter: 879 loss: 6.2008337e-07
Iter: 880 loss: 6.19941147e-07
Iter: 881 loss: 6.19937964e-07
Iter: 882 loss: 6.19833656e-07
Iter: 883 loss: 6.19632544e-07
Iter: 884 loss: 6.19804041e-07
Iter: 885 loss: 6.19489583e-07
Iter: 886 loss: 6.19320076e-07
Iter: 887 loss: 6.20738433e-07
Iter: 888 loss: 6.1929876e-07
Iter: 889 loss: 6.19086165e-07
Iter: 890 loss: 6.18837134e-07
Iter: 891 loss: 6.18819058e-07
Iter: 892 loss: 6.18381137e-07
Iter: 893 loss: 6.18398303e-07
Iter: 894 loss: 6.18012166e-07
Iter: 895 loss: 6.18085494e-07
Iter: 896 loss: 6.17804687e-07
Iter: 897 loss: 6.17698902e-07
Iter: 898 loss: 6.17462206e-07
Iter: 899 loss: 6.17479145e-07
Iter: 900 loss: 6.17330613e-07
Iter: 901 loss: 6.19246123e-07
Iter: 902 loss: 6.1730168e-07
Iter: 903 loss: 6.17120293e-07
Iter: 904 loss: 6.17214255e-07
Iter: 905 loss: 6.17017122e-07
Iter: 906 loss: 6.16902071e-07
Iter: 907 loss: 6.16823684e-07
Iter: 908 loss: 6.16741886e-07
Iter: 909 loss: 6.16593638e-07
Iter: 910 loss: 6.17090564e-07
Iter: 911 loss: 6.16505417e-07
Iter: 912 loss: 6.16381953e-07
Iter: 913 loss: 6.16343925e-07
Iter: 914 loss: 6.16291231e-07
Iter: 915 loss: 6.1615458e-07
Iter: 916 loss: 6.18486411e-07
Iter: 917 loss: 6.1614611e-07
Iter: 918 loss: 6.15968361e-07
Iter: 919 loss: 6.17074875e-07
Iter: 920 loss: 6.15888666e-07
Iter: 921 loss: 6.1567988e-07
Iter: 922 loss: 6.16344437e-07
Iter: 923 loss: 6.15649583e-07
Iter: 924 loss: 6.15478427e-07
Iter: 925 loss: 6.15401575e-07
Iter: 926 loss: 6.15285387e-07
Iter: 927 loss: 6.15131114e-07
Iter: 928 loss: 6.1817417e-07
Iter: 929 loss: 6.15125771e-07
Iter: 930 loss: 6.14934379e-07
Iter: 931 loss: 6.1483928e-07
Iter: 932 loss: 6.14731903e-07
Iter: 933 loss: 6.14565749e-07
Iter: 934 loss: 6.15202111e-07
Iter: 935 loss: 6.1448e-07
Iter: 936 loss: 6.14241117e-07
Iter: 937 loss: 6.14888165e-07
Iter: 938 loss: 6.14163525e-07
Iter: 939 loss: 6.13952921e-07
Iter: 940 loss: 6.13826e-07
Iter: 941 loss: 6.13774205e-07
Iter: 942 loss: 6.13539555e-07
Iter: 943 loss: 6.14254304e-07
Iter: 944 loss: 6.13476629e-07
Iter: 945 loss: 6.13336908e-07
Iter: 946 loss: 6.13351403e-07
Iter: 947 loss: 6.13238e-07
Iter: 948 loss: 6.13238342e-07
Iter: 949 loss: 6.13137615e-07
Iter: 950 loss: 6.13055533e-07
Iter: 951 loss: 6.13138923e-07
Iter: 952 loss: 6.13011082e-07
Iter: 953 loss: 6.12863687e-07
Iter: 954 loss: 6.13390171e-07
Iter: 955 loss: 6.12817473e-07
Iter: 956 loss: 6.12687472e-07
Iter: 957 loss: 6.12762051e-07
Iter: 958 loss: 6.12601752e-07
Iter: 959 loss: 6.12454301e-07
Iter: 960 loss: 6.13285636e-07
Iter: 961 loss: 6.12438953e-07
Iter: 962 loss: 6.12237e-07
Iter: 963 loss: 6.12266376e-07
Iter: 964 loss: 6.1210784e-07
Iter: 965 loss: 6.11876317e-07
Iter: 966 loss: 6.11906728e-07
Iter: 967 loss: 6.11731707e-07
Iter: 968 loss: 6.11519397e-07
Iter: 969 loss: 6.11502401e-07
Iter: 970 loss: 6.11418272e-07
Iter: 971 loss: 6.11161227e-07
Iter: 972 loss: 6.14471219e-07
Iter: 973 loss: 6.11155826e-07
Iter: 974 loss: 6.10911172e-07
Iter: 975 loss: 6.11877681e-07
Iter: 976 loss: 6.10862458e-07
Iter: 977 loss: 6.10730353e-07
Iter: 978 loss: 6.123758e-07
Iter: 979 loss: 6.10741893e-07
Iter: 980 loss: 6.10603365e-07
Iter: 981 loss: 6.10688517e-07
Iter: 982 loss: 6.105181e-07
Iter: 983 loss: 6.10363088e-07
Iter: 984 loss: 6.10598704e-07
Iter: 985 loss: 6.10291067e-07
Iter: 986 loss: 6.10169081e-07
Iter: 987 loss: 6.11335906e-07
Iter: 988 loss: 6.10152256e-07
Iter: 989 loss: 6.10002644e-07
Iter: 990 loss: 6.09860535e-07
Iter: 991 loss: 6.09830295e-07
Iter: 992 loss: 6.09627477e-07
Iter: 993 loss: 6.10936468e-07
Iter: 994 loss: 6.09598146e-07
Iter: 995 loss: 6.09420226e-07
Iter: 996 loss: 6.11028838e-07
Iter: 997 loss: 6.09409199e-07
Iter: 998 loss: 6.09317453e-07
Iter: 999 loss: 6.09170343e-07
Iter: 1000 loss: 6.09146127e-07
Iter: 1001 loss: 6.09007e-07
Iter: 1002 loss: 6.09019537e-07
Iter: 1003 loss: 6.08865207e-07
Iter: 1004 loss: 6.08736741e-07
Iter: 1005 loss: 6.08703317e-07
Iter: 1006 loss: 6.08540574e-07
Iter: 1007 loss: 6.08625669e-07
Iter: 1008 loss: 6.08397727e-07
Iter: 1009 loss: 6.08184791e-07
Iter: 1010 loss: 6.10375764e-07
Iter: 1011 loss: 6.08188202e-07
Iter: 1012 loss: 6.07990273e-07
Iter: 1013 loss: 6.09508447e-07
Iter: 1014 loss: 6.08003859e-07
Iter: 1015 loss: 6.07900688e-07
Iter: 1016 loss: 6.07818379e-07
Iter: 1017 loss: 6.07791833e-07
Iter: 1018 loss: 6.07657853e-07
Iter: 1019 loss: 6.08576954e-07
Iter: 1020 loss: 6.07650804e-07
Iter: 1021 loss: 6.075187e-07
Iter: 1022 loss: 6.07458333e-07
Iter: 1023 loss: 6.07380912e-07
Iter: 1024 loss: 6.07282402e-07
Iter: 1025 loss: 6.08155517e-07
Iter: 1026 loss: 6.07257e-07
Iter: 1027 loss: 6.07125116e-07
Iter: 1028 loss: 6.08193432e-07
Iter: 1029 loss: 6.07124434e-07
Iter: 1030 loss: 6.07063953e-07
Iter: 1031 loss: 6.06908e-07
Iter: 1032 loss: 6.09503275e-07
Iter: 1033 loss: 6.06911499e-07
Iter: 1034 loss: 6.06783317e-07
Iter: 1035 loss: 6.06774e-07
Iter: 1036 loss: 6.06620858e-07
Iter: 1037 loss: 6.065e-07
Iter: 1038 loss: 6.06479318e-07
Iter: 1039 loss: 6.06248e-07
Iter: 1040 loss: 6.0609807e-07
Iter: 1041 loss: 6.06024742e-07
Iter: 1042 loss: 6.05758544e-07
Iter: 1043 loss: 6.08418e-07
Iter: 1044 loss: 6.05729667e-07
Iter: 1045 loss: 6.05508149e-07
Iter: 1046 loss: 6.06687536e-07
Iter: 1047 loss: 6.05505932e-07
Iter: 1048 loss: 6.05311357e-07
Iter: 1049 loss: 6.05216201e-07
Iter: 1050 loss: 6.0510763e-07
Iter: 1051 loss: 6.04985303e-07
Iter: 1052 loss: 6.04975185e-07
Iter: 1053 loss: 6.0487605e-07
Iter: 1054 loss: 6.04734453e-07
Iter: 1055 loss: 6.04728029e-07
Iter: 1056 loss: 6.04519812e-07
Iter: 1057 loss: 6.04758668e-07
Iter: 1058 loss: 6.0443142e-07
Iter: 1059 loss: 6.04324839e-07
Iter: 1060 loss: 6.043133e-07
Iter: 1061 loss: 6.04205184e-07
Iter: 1062 loss: 6.04037382e-07
Iter: 1063 loss: 6.07163656e-07
Iter: 1064 loss: 6.04056595e-07
Iter: 1065 loss: 6.03847525e-07
Iter: 1066 loss: 6.04983711e-07
Iter: 1067 loss: 6.03806654e-07
Iter: 1068 loss: 6.03620776e-07
Iter: 1069 loss: 6.04078195e-07
Iter: 1070 loss: 6.0352977e-07
Iter: 1071 loss: 6.03397098e-07
Iter: 1072 loss: 6.03320359e-07
Iter: 1073 loss: 6.03274543e-07
Iter: 1074 loss: 6.03096964e-07
Iter: 1075 loss: 6.03847923e-07
Iter: 1076 loss: 6.03072181e-07
Iter: 1077 loss: 6.02922114e-07
Iter: 1078 loss: 6.04719389e-07
Iter: 1079 loss: 6.02921148e-07
Iter: 1080 loss: 6.02809e-07
Iter: 1081 loss: 6.02843897e-07
Iter: 1082 loss: 6.02762725e-07
Iter: 1083 loss: 6.02693262e-07
Iter: 1084 loss: 6.03336389e-07
Iter: 1085 loss: 6.02622322e-07
Iter: 1086 loss: 6.02544901e-07
Iter: 1087 loss: 6.02408875e-07
Iter: 1088 loss: 6.02412229e-07
Iter: 1089 loss: 6.02248235e-07
Iter: 1090 loss: 6.02500904e-07
Iter: 1091 loss: 6.02187811e-07
Iter: 1092 loss: 6.02075374e-07
Iter: 1093 loss: 6.02069235e-07
Iter: 1094 loss: 6.01941792e-07
Iter: 1095 loss: 6.01780698e-07
Iter: 1096 loss: 6.0177706e-07
Iter: 1097 loss: 6.01598856e-07
Iter: 1098 loss: 6.03120043e-07
Iter: 1099 loss: 6.01615284e-07
Iter: 1100 loss: 6.01482213e-07
Iter: 1101 loss: 6.01987381e-07
Iter: 1102 loss: 6.0146948e-07
Iter: 1103 loss: 6.01388308e-07
Iter: 1104 loss: 6.01215675e-07
Iter: 1105 loss: 6.01199133e-07
Iter: 1106 loss: 6.01074873e-07
Iter: 1107 loss: 6.02800469e-07
Iter: 1108 loss: 6.01069075e-07
Iter: 1109 loss: 6.00963403e-07
Iter: 1110 loss: 6.01826969e-07
Iter: 1111 loss: 6.00964768e-07
Iter: 1112 loss: 6.00854605e-07
Iter: 1113 loss: 6.00739e-07
Iter: 1114 loss: 6.00747626e-07
Iter: 1115 loss: 6.00592841e-07
Iter: 1116 loss: 6.02079297e-07
Iter: 1117 loss: 6.00556689e-07
Iter: 1118 loss: 6.00449482e-07
Iter: 1119 loss: 6.00398153e-07
Iter: 1120 loss: 6.00301178e-07
Iter: 1121 loss: 6.00124451e-07
Iter: 1122 loss: 5.99918508e-07
Iter: 1123 loss: 5.99880366e-07
Iter: 1124 loss: 5.99736268e-07
Iter: 1125 loss: 5.99708926e-07
Iter: 1126 loss: 5.9955471e-07
Iter: 1127 loss: 5.99594841e-07
Iter: 1128 loss: 5.99462453e-07
Iter: 1129 loss: 5.99316536e-07
Iter: 1130 loss: 5.99351e-07
Iter: 1131 loss: 5.99214786e-07
Iter: 1132 loss: 5.99018392e-07
Iter: 1133 loss: 6.01231875e-07
Iter: 1134 loss: 5.9900924e-07
Iter: 1135 loss: 5.98888391e-07
Iter: 1136 loss: 5.98762824e-07
Iter: 1137 loss: 5.98743895e-07
Iter: 1138 loss: 5.98564952e-07
Iter: 1139 loss: 5.99105647e-07
Iter: 1140 loss: 5.98533518e-07
Iter: 1141 loss: 5.98388681e-07
Iter: 1142 loss: 6.00067551e-07
Iter: 1143 loss: 5.9840022e-07
Iter: 1144 loss: 5.98280394e-07
Iter: 1145 loss: 5.98239581e-07
Iter: 1146 loss: 5.98190923e-07
Iter: 1147 loss: 5.98046086e-07
Iter: 1148 loss: 5.98860765e-07
Iter: 1149 loss: 5.98066265e-07
Iter: 1150 loss: 5.97899543e-07
Iter: 1151 loss: 5.97958092e-07
Iter: 1152 loss: 5.97825533e-07
Iter: 1153 loss: 5.97677058e-07
Iter: 1154 loss: 5.97686437e-07
Iter: 1155 loss: 5.9753e-07
Iter: 1156 loss: 5.97405631e-07
Iter: 1157 loss: 5.97417852e-07
Iter: 1158 loss: 5.97324572e-07
Iter: 1159 loss: 5.97365556e-07
Iter: 1160 loss: 5.97242888e-07
Iter: 1161 loss: 5.97131475e-07
Iter: 1162 loss: 5.96996301e-07
Iter: 1163 loss: 5.96992e-07
Iter: 1164 loss: 5.96832592e-07
Iter: 1165 loss: 5.96827e-07
Iter: 1166 loss: 5.9673954e-07
Iter: 1167 loss: 5.96557584e-07
Iter: 1168 loss: 6.00265082e-07
Iter: 1169 loss: 5.96535074e-07
Iter: 1170 loss: 5.96317761e-07
Iter: 1171 loss: 5.97150915e-07
Iter: 1172 loss: 5.96246537e-07
Iter: 1173 loss: 5.96139557e-07
Iter: 1174 loss: 5.96129041e-07
Iter: 1175 loss: 5.96007624e-07
Iter: 1176 loss: 5.95931056e-07
Iter: 1177 loss: 5.95866709e-07
Iter: 1178 loss: 5.95709139e-07
Iter: 1179 loss: 5.96129439e-07
Iter: 1180 loss: 5.95653319e-07
Iter: 1181 loss: 5.95447489e-07
Iter: 1182 loss: 5.96700033e-07
Iter: 1183 loss: 5.95440099e-07
Iter: 1184 loss: 5.95326242e-07
Iter: 1185 loss: 5.95230631e-07
Iter: 1186 loss: 5.95229892e-07
Iter: 1187 loss: 5.95026847e-07
Iter: 1188 loss: 5.95598181e-07
Iter: 1189 loss: 5.95006554e-07
Iter: 1190 loss: 5.9482079e-07
Iter: 1191 loss: 5.96523876e-07
Iter: 1192 loss: 5.94797939e-07
Iter: 1193 loss: 5.94722337e-07
Iter: 1194 loss: 5.94530206e-07
Iter: 1195 loss: 5.9789329e-07
Iter: 1196 loss: 5.9453987e-07
Iter: 1197 loss: 5.94355583e-07
Iter: 1198 loss: 5.96866698e-07
Iter: 1199 loss: 5.9433961e-07
Iter: 1200 loss: 5.94189146e-07
Iter: 1201 loss: 5.94078301e-07
Iter: 1202 loss: 5.9403e-07
Iter: 1203 loss: 5.93855702e-07
Iter: 1204 loss: 5.94012306e-07
Iter: 1205 loss: 5.93755146e-07
Iter: 1206 loss: 5.93534082e-07
Iter: 1207 loss: 5.95386723e-07
Iter: 1208 loss: 5.93554e-07
Iter: 1209 loss: 5.93367872e-07
Iter: 1210 loss: 5.9360093e-07
Iter: 1211 loss: 5.93275217e-07
Iter: 1212 loss: 5.93131858e-07
Iter: 1213 loss: 5.93685627e-07
Iter: 1214 loss: 5.93086e-07
Iter: 1215 loss: 5.92955189e-07
Iter: 1216 loss: 5.93973e-07
Iter: 1217 loss: 5.92962351e-07
Iter: 1218 loss: 5.92849517e-07
Iter: 1219 loss: 5.92688423e-07
Iter: 1220 loss: 5.96897678e-07
Iter: 1221 loss: 5.92677679e-07
Iter: 1222 loss: 5.92474294e-07
Iter: 1223 loss: 5.93666186e-07
Iter: 1224 loss: 5.92465767e-07
Iter: 1225 loss: 5.92366405e-07
Iter: 1226 loss: 5.92358674e-07
Iter: 1227 loss: 5.92288131e-07
Iter: 1228 loss: 5.92090657e-07
Iter: 1229 loss: 5.95161509e-07
Iter: 1230 loss: 5.9210987e-07
Iter: 1231 loss: 5.92022104e-07
Iter: 1232 loss: 5.92019887e-07
Iter: 1233 loss: 5.9197157e-07
Iter: 1234 loss: 5.91875732e-07
Iter: 1235 loss: 5.91883861e-07
Iter: 1236 loss: 5.91756418e-07
Iter: 1237 loss: 5.91620847e-07
Iter: 1238 loss: 5.91603794e-07
Iter: 1239 loss: 5.91460037e-07
Iter: 1240 loss: 5.91474304e-07
Iter: 1241 loss: 5.91335947e-07
Iter: 1242 loss: 5.91563548e-07
Iter: 1243 loss: 5.91271373e-07
Iter: 1244 loss: 5.91122e-07
Iter: 1245 loss: 5.90959075e-07
Iter: 1246 loss: 5.90947593e-07
Iter: 1247 loss: 5.90775e-07
Iter: 1248 loss: 5.9075694e-07
Iter: 1249 loss: 5.90660648e-07
Iter: 1250 loss: 5.90483637e-07
Iter: 1251 loss: 5.90467891e-07
Iter: 1252 loss: 5.90275874e-07
Iter: 1253 loss: 5.90544687e-07
Iter: 1254 loss: 5.90153604e-07
Iter: 1255 loss: 5.90244156e-07
Iter: 1256 loss: 5.90098e-07
Iter: 1257 loss: 5.90053787e-07
Iter: 1258 loss: 5.89904971e-07
Iter: 1259 loss: 5.91479477e-07
Iter: 1260 loss: 5.89911e-07
Iter: 1261 loss: 5.89778892e-07
Iter: 1262 loss: 5.90634045e-07
Iter: 1263 loss: 5.89776846e-07
Iter: 1264 loss: 5.89645367e-07
Iter: 1265 loss: 5.89804131e-07
Iter: 1266 loss: 5.89574142e-07
Iter: 1267 loss: 5.89464378e-07
Iter: 1268 loss: 5.8943e-07
Iter: 1269 loss: 5.89369108e-07
Iter: 1270 loss: 5.89183742e-07
Iter: 1271 loss: 5.89486206e-07
Iter: 1272 loss: 5.89097169e-07
Iter: 1273 loss: 5.88811304e-07
Iter: 1274 loss: 5.91435878e-07
Iter: 1275 loss: 5.88798571e-07
Iter: 1276 loss: 5.88717057e-07
Iter: 1277 loss: 5.88552552e-07
Iter: 1278 loss: 5.88551131e-07
Iter: 1279 loss: 5.88423404e-07
Iter: 1280 loss: 5.88406124e-07
Iter: 1281 loss: 5.88268051e-07
Iter: 1282 loss: 5.88272e-07
Iter: 1283 loss: 5.88172497e-07
Iter: 1284 loss: 5.88060061e-07
Iter: 1285 loss: 5.88103376e-07
Iter: 1286 loss: 5.87978093e-07
Iter: 1287 loss: 5.87909483e-07
Iter: 1288 loss: 5.8791e-07
Iter: 1289 loss: 5.87804891e-07
Iter: 1290 loss: 5.87752311e-07
Iter: 1291 loss: 5.87733098e-07
Iter: 1292 loss: 5.87654199e-07
Iter: 1293 loss: 5.88027206e-07
Iter: 1294 loss: 5.8761708e-07
Iter: 1295 loss: 5.87542047e-07
Iter: 1296 loss: 5.87714794e-07
Iter: 1297 loss: 5.87500438e-07
Iter: 1298 loss: 5.87399882e-07
Iter: 1299 loss: 5.87331044e-07
Iter: 1300 loss: 5.87327122e-07
Iter: 1301 loss: 5.87193881e-07
Iter: 1302 loss: 5.87763964e-07
Iter: 1303 loss: 5.87139198e-07
Iter: 1304 loss: 5.87034606e-07
Iter: 1305 loss: 5.87057116e-07
Iter: 1306 loss: 5.86969e-07
Iter: 1307 loss: 5.86824115e-07
Iter: 1308 loss: 5.89158788e-07
Iter: 1309 loss: 5.86798649e-07
Iter: 1310 loss: 5.86733222e-07
Iter: 1311 loss: 5.86714918e-07
Iter: 1312 loss: 5.86646934e-07
Iter: 1313 loss: 5.86560702e-07
Iter: 1314 loss: 5.86535123e-07
Iter: 1315 loss: 5.86396823e-07
Iter: 1316 loss: 5.86315537e-07
Iter: 1317 loss: 5.8626415e-07
Iter: 1318 loss: 5.86166493e-07
Iter: 1319 loss: 5.86159217e-07
Iter: 1320 loss: 5.86059e-07
Iter: 1321 loss: 5.8623084e-07
Iter: 1322 loss: 5.85977944e-07
Iter: 1323 loss: 5.85940597e-07
Iter: 1324 loss: 5.85870112e-07
Iter: 1325 loss: 5.85866758e-07
Iter: 1326 loss: 5.85774387e-07
Iter: 1327 loss: 5.85767395e-07
Iter: 1328 loss: 5.85716236e-07
Iter: 1329 loss: 5.85624e-07
Iter: 1330 loss: 5.87740544e-07
Iter: 1331 loss: 5.85611133e-07
Iter: 1332 loss: 5.85503358e-07
Iter: 1333 loss: 5.85696398e-07
Iter: 1334 loss: 5.8546533e-07
Iter: 1335 loss: 5.85401949e-07
Iter: 1336 loss: 5.85395298e-07
Iter: 1337 loss: 5.85335727e-07
Iter: 1338 loss: 5.85172472e-07
Iter: 1339 loss: 5.88495141e-07
Iter: 1340 loss: 5.85193447e-07
Iter: 1341 loss: 5.85026896e-07
Iter: 1342 loss: 5.86101294e-07
Iter: 1343 loss: 5.8503997e-07
Iter: 1344 loss: 5.84911959e-07
Iter: 1345 loss: 5.85377961e-07
Iter: 1346 loss: 5.84902864e-07
Iter: 1347 loss: 5.84829081e-07
Iter: 1348 loss: 5.84662303e-07
Iter: 1349 loss: 5.84665713e-07
Iter: 1350 loss: 5.84508143e-07
Iter: 1351 loss: 5.85496139e-07
Iter: 1352 loss: 5.84490181e-07
Iter: 1353 loss: 5.84425493e-07
Iter: 1354 loss: 5.84393774e-07
Iter: 1355 loss: 5.84374391e-07
Iter: 1356 loss: 5.84274517e-07
Iter: 1357 loss: 5.85202883e-07
Iter: 1358 loss: 5.84279633e-07
Iter: 1359 loss: 5.8416714e-07
Iter: 1360 loss: 5.84166742e-07
Iter: 1361 loss: 5.84102679e-07
Iter: 1362 loss: 5.84066e-07
Iter: 1363 loss: 5.84055329e-07
Iter: 1364 loss: 5.83971655e-07
Iter: 1365 loss: 5.83976657e-07
Iter: 1366 loss: 5.83915153e-07
Iter: 1367 loss: 5.83805274e-07
Iter: 1368 loss: 5.8448893e-07
Iter: 1369 loss: 5.83797316e-07
Iter: 1370 loss: 5.83689712e-07
Iter: 1371 loss: 5.84162422e-07
Iter: 1372 loss: 5.83646681e-07
Iter: 1373 loss: 5.83583187e-07
Iter: 1374 loss: 5.83530323e-07
Iter: 1375 loss: 5.83496785e-07
Iter: 1376 loss: 5.83396172e-07
Iter: 1377 loss: 5.84408895e-07
Iter: 1378 loss: 5.83364226e-07
Iter: 1379 loss: 5.83281178e-07
Iter: 1380 loss: 5.83207e-07
Iter: 1381 loss: 5.83190968e-07
Iter: 1382 loss: 5.83055566e-07
Iter: 1383 loss: 5.83096494e-07
Iter: 1384 loss: 5.82967289e-07
Iter: 1385 loss: 5.82904477e-07
Iter: 1386 loss: 5.82879e-07
Iter: 1387 loss: 5.82794428e-07
Iter: 1388 loss: 5.82630094e-07
Iter: 1389 loss: 5.82613893e-07
Iter: 1390 loss: 5.82550911e-07
Iter: 1391 loss: 5.83794304e-07
Iter: 1392 loss: 5.82530902e-07
Iter: 1393 loss: 5.82447683e-07
Iter: 1394 loss: 5.82408802e-07
Iter: 1395 loss: 5.82312509e-07
Iter: 1396 loss: 5.82207122e-07
Iter: 1397 loss: 5.82325811e-07
Iter: 1398 loss: 5.82170742e-07
Iter: 1399 loss: 5.82043413e-07
Iter: 1400 loss: 5.82406642e-07
Iter: 1401 loss: 5.8199646e-07
Iter: 1402 loss: 5.81889822e-07
Iter: 1403 loss: 5.81883e-07
Iter: 1404 loss: 5.81814277e-07
Iter: 1405 loss: 5.81754193e-07
Iter: 1406 loss: 5.81717e-07
Iter: 1407 loss: 5.81713721e-07
Iter: 1408 loss: 5.82740029e-07
Iter: 1409 loss: 5.81692916e-07
Iter: 1410 loss: 5.81603729e-07
Iter: 1411 loss: 5.81503514e-07
Iter: 1412 loss: 5.81476286e-07
Iter: 1413 loss: 5.81366635e-07
Iter: 1414 loss: 5.81331619e-07
Iter: 1415 loss: 5.81263066e-07
Iter: 1416 loss: 5.81124425e-07
Iter: 1417 loss: 5.82915732e-07
Iter: 1418 loss: 5.81128347e-07
Iter: 1419 loss: 5.81011e-07
Iter: 1420 loss: 5.81230893e-07
Iter: 1421 loss: 5.80958613e-07
Iter: 1422 loss: 5.80885853e-07
Iter: 1423 loss: 5.8114324e-07
Iter: 1424 loss: 5.80871585e-07
Iter: 1425 loss: 5.80810593e-07
Iter: 1426 loss: 5.80954406e-07
Iter: 1427 loss: 5.80790697e-07
Iter: 1428 loss: 5.80720211e-07
Iter: 1429 loss: 5.80604876e-07
Iter: 1430 loss: 5.80606184e-07
Iter: 1431 loss: 5.8052882e-07
Iter: 1432 loss: 5.81277845e-07
Iter: 1433 loss: 5.8052558e-07
Iter: 1434 loss: 5.80486471e-07
Iter: 1435 loss: 5.81127949e-07
Iter: 1436 loss: 5.80473397e-07
Iter: 1437 loss: 5.80417691e-07
Iter: 1438 loss: 5.80291726e-07
Iter: 1439 loss: 5.82198766e-07
Iter: 1440 loss: 5.80289452e-07
Iter: 1441 loss: 5.80178209e-07
Iter: 1442 loss: 5.80971118e-07
Iter: 1443 loss: 5.80172582e-07
Iter: 1444 loss: 5.80075039e-07
Iter: 1445 loss: 5.80598e-07
Iter: 1446 loss: 5.80045594e-07
Iter: 1447 loss: 5.79961124e-07
Iter: 1448 loss: 5.79877053e-07
Iter: 1449 loss: 5.82764642e-07
Iter: 1450 loss: 5.79863354e-07
Iter: 1451 loss: 5.79755579e-07
Iter: 1452 loss: 5.81237e-07
Iter: 1453 loss: 5.79750633e-07
Iter: 1454 loss: 5.79657865e-07
Iter: 1455 loss: 5.80298718e-07
Iter: 1456 loss: 5.79641323e-07
Iter: 1457 loss: 5.79571065e-07
Iter: 1458 loss: 5.79546963e-07
Iter: 1459 loss: 5.79502512e-07
Iter: 1460 loss: 5.79424466e-07
Iter: 1461 loss: 5.80171104e-07
Iter: 1462 loss: 5.79396215e-07
Iter: 1463 loss: 5.79343691e-07
Iter: 1464 loss: 5.79206755e-07
Iter: 1465 loss: 5.79192488e-07
Iter: 1466 loss: 5.79028722e-07
Iter: 1467 loss: 5.79024288e-07
Iter: 1468 loss: 5.78921117e-07
Iter: 1469 loss: 5.78780714e-07
Iter: 1470 loss: 5.78754793e-07
Iter: 1471 loss: 5.78597508e-07
Iter: 1472 loss: 5.78797199e-07
Iter: 1473 loss: 5.78543677e-07
Iter: 1474 loss: 5.7843522e-07
Iter: 1475 loss: 5.78411459e-07
Iter: 1476 loss: 5.78322897e-07
Iter: 1477 loss: 5.78289303e-07
Iter: 1478 loss: 5.78270942e-07
Iter: 1479 loss: 5.7820921e-07
Iter: 1480 loss: 5.78064601e-07
Iter: 1481 loss: 5.81090603e-07
Iter: 1482 loss: 5.78069432e-07
Iter: 1483 loss: 5.78011964e-07
Iter: 1484 loss: 5.78871777e-07
Iter: 1485 loss: 5.77993546e-07
Iter: 1486 loss: 5.7796143e-07
Iter: 1487 loss: 5.78573122e-07
Iter: 1488 loss: 5.77939147e-07
Iter: 1489 loss: 5.77903961e-07
Iter: 1490 loss: 5.77818867e-07
Iter: 1491 loss: 5.77834385e-07
Iter: 1492 loss: 5.77747358e-07
Iter: 1493 loss: 5.78727054e-07
Iter: 1494 loss: 5.77739513e-07
Iter: 1495 loss: 5.77699723e-07
Iter: 1496 loss: 5.776227e-07
Iter: 1497 loss: 5.77602577e-07
Iter: 1498 loss: 5.77520495e-07
Iter: 1499 loss: 5.7740624e-07
Iter: 1500 loss: 5.77402147e-07
Iter: 1501 loss: 5.77252763e-07
Iter: 1502 loss: 5.77948867e-07
Iter: 1503 loss: 5.77220817e-07
Iter: 1504 loss: 5.77095307e-07
Iter: 1505 loss: 5.77071944e-07
Iter: 1506 loss: 5.77014475e-07
Iter: 1507 loss: 5.76803757e-07
Iter: 1508 loss: 5.78914126e-07
Iter: 1509 loss: 5.76775e-07
Iter: 1510 loss: 5.76613616e-07
Iter: 1511 loss: 5.77248102e-07
Iter: 1512 loss: 5.76555522e-07
Iter: 1513 loss: 5.76455363e-07
Iter: 1514 loss: 5.76453e-07
Iter: 1515 loss: 5.76396133e-07
Iter: 1516 loss: 5.76341563e-07
Iter: 1517 loss: 5.76335538e-07
Iter: 1518 loss: 5.76292166e-07
Iter: 1519 loss: 5.76283924e-07
Iter: 1520 loss: 5.7625806e-07
Iter: 1521 loss: 5.76255445e-07
Iter: 1522 loss: 5.76213e-07
Iter: 1523 loss: 5.76194509e-07
Iter: 1524 loss: 5.76138291e-07
Iter: 1525 loss: 5.77066373e-07
Iter: 1526 loss: 5.76162506e-07
Iter: 1527 loss: 5.76086677e-07
Iter: 1528 loss: 5.76339801e-07
Iter: 1529 loss: 5.76074285e-07
Iter: 1530 loss: 5.75993909e-07
Iter: 1531 loss: 5.7595804e-07
Iter: 1532 loss: 5.75929789e-07
Iter: 1533 loss: 5.75816898e-07
Iter: 1534 loss: 5.75765796e-07
Iter: 1535 loss: 5.75720378e-07
Iter: 1536 loss: 5.75521597e-07
Iter: 1537 loss: 5.75825709e-07
Iter: 1538 loss: 5.75491299e-07
Iter: 1539 loss: 5.75408762e-07
Iter: 1540 loss: 5.75393074e-07
Iter: 1541 loss: 5.75318268e-07
Iter: 1542 loss: 5.75535125e-07
Iter: 1543 loss: 5.75301215e-07
Iter: 1544 loss: 5.75218223e-07
Iter: 1545 loss: 5.7509726e-07
Iter: 1546 loss: 5.78029244e-07
Iter: 1547 loss: 5.75100728e-07
Iter: 1548 loss: 5.75141371e-07
Iter: 1549 loss: 5.75076115e-07
Iter: 1550 loss: 5.75039621e-07
Iter: 1551 loss: 5.74968738e-07
Iter: 1552 loss: 5.75501872e-07
Iter: 1553 loss: 5.74931732e-07
Iter: 1554 loss: 5.74862099e-07
Iter: 1555 loss: 5.74874775e-07
Iter: 1556 loss: 5.74819069e-07
Iter: 1557 loss: 5.74828732e-07
Iter: 1558 loss: 5.74772457e-07
Iter: 1559 loss: 5.7470379e-07
Iter: 1560 loss: 5.74837827e-07
Iter: 1561 loss: 5.74681451e-07
Iter: 1562 loss: 5.74616251e-07
Iter: 1563 loss: 5.74786782e-07
Iter: 1564 loss: 5.74590786e-07
Iter: 1565 loss: 5.74538262e-07
Iter: 1566 loss: 5.74529508e-07
Iter: 1567 loss: 5.745095e-07
Iter: 1568 loss: 5.74442879e-07
Iter: 1569 loss: 5.74356136e-07
Iter: 1570 loss: 5.76544437e-07
Iter: 1571 loss: 5.74335729e-07
Iter: 1572 loss: 5.74253818e-07
Iter: 1573 loss: 5.74322655e-07
Iter: 1574 loss: 5.74206467e-07
Iter: 1575 loss: 5.74151557e-07
Iter: 1576 loss: 5.74663261e-07
Iter: 1577 loss: 5.74122907e-07
Iter: 1578 loss: 5.74026728e-07
Iter: 1579 loss: 5.74001319e-07
Iter: 1580 loss: 5.73938621e-07
Iter: 1581 loss: 5.73852503e-07
Iter: 1582 loss: 5.7485687e-07
Iter: 1583 loss: 5.73885814e-07
Iter: 1584 loss: 5.73805664e-07
Iter: 1585 loss: 5.74341e-07
Iter: 1586 loss: 5.73795774e-07
Iter: 1587 loss: 5.73751095e-07
Iter: 1588 loss: 5.73740749e-07
Iter: 1589 loss: 5.73713578e-07
Iter: 1590 loss: 5.73652187e-07
Iter: 1591 loss: 5.73672196e-07
Iter: 1592 loss: 5.73645252e-07
Iter: 1593 loss: 5.73592e-07
Iter: 1594 loss: 5.73866373e-07
Iter: 1595 loss: 5.73562488e-07
Iter: 1596 loss: 5.73476655e-07
Iter: 1597 loss: 5.73484556e-07
Iter: 1598 loss: 5.73413899e-07
Iter: 1599 loss: 5.7349348e-07
Iter: 1600 loss: 5.73422426e-07
Iter: 1601 loss: 5.73364389e-07
Iter: 1602 loss: 5.73412649e-07
Iter: 1603 loss: 5.73320563e-07
Iter: 1604 loss: 5.73225407e-07
Iter: 1605 loss: 5.73457e-07
Iter: 1606 loss: 5.73213924e-07
Iter: 1607 loss: 5.73142643e-07
Iter: 1608 loss: 5.73447096e-07
Iter: 1609 loss: 5.73133207e-07
Iter: 1610 loss: 5.73069485e-07
Iter: 1611 loss: 5.73059481e-07
Iter: 1612 loss: 5.73001159e-07
Iter: 1613 loss: 5.72929935e-07
Iter: 1614 loss: 5.73490752e-07
Iter: 1615 loss: 5.7294551e-07
Iter: 1616 loss: 5.7291021e-07
Iter: 1617 loss: 5.72929196e-07
Iter: 1618 loss: 5.7287707e-07
Iter: 1619 loss: 5.72849217e-07
Iter: 1620 loss: 5.72850865e-07
Iter: 1621 loss: 5.72782426e-07
Iter: 1622 loss: 5.73393208e-07
Iter: 1623 loss: 5.72792146e-07
Iter: 1624 loss: 5.72770773e-07
Iter: 1625 loss: 5.72671183e-07
Iter: 1626 loss: 5.73831926e-07
Iter: 1627 loss: 5.72669876e-07
Iter: 1628 loss: 5.72570855e-07
Iter: 1629 loss: 5.72969213e-07
Iter: 1630 loss: 5.72593081e-07
Iter: 1631 loss: 5.72461374e-07
Iter: 1632 loss: 5.72890258e-07
Iter: 1633 loss: 5.72459385e-07
Iter: 1634 loss: 5.72379463e-07
Iter: 1635 loss: 5.7242903e-07
Iter: 1636 loss: 5.72330578e-07
Iter: 1637 loss: 5.72277031e-07
Iter: 1638 loss: 5.72903161e-07
Iter: 1639 loss: 5.72269755e-07
Iter: 1640 loss: 5.72186877e-07
Iter: 1641 loss: 5.72206886e-07
Iter: 1642 loss: 5.72163231e-07
Iter: 1643 loss: 5.72103e-07
Iter: 1644 loss: 5.72284137e-07
Iter: 1645 loss: 5.72062277e-07
Iter: 1646 loss: 5.7201089e-07
Iter: 1647 loss: 5.72213366e-07
Iter: 1648 loss: 5.71982071e-07
Iter: 1649 loss: 5.71931082e-07
Iter: 1650 loss: 5.72241277e-07
Iter: 1651 loss: 5.71946202e-07
Iter: 1652 loss: 5.71883106e-07
Iter: 1653 loss: 5.71825694e-07
Iter: 1654 loss: 5.71796534e-07
Iter: 1655 loss: 5.71783687e-07
Iter: 1656 loss: 5.71745943e-07
Iter: 1657 loss: 5.71703595e-07
Iter: 1658 loss: 5.71616397e-07
Iter: 1659 loss: 5.73449597e-07
Iter: 1660 loss: 5.71628561e-07
Iter: 1661 loss: 5.71552505e-07
Iter: 1662 loss: 5.71811711e-07
Iter: 1663 loss: 5.71519479e-07
Iter: 1664 loss: 5.71445071e-07
Iter: 1665 loss: 5.71456781e-07
Iter: 1666 loss: 5.71376859e-07
Iter: 1667 loss: 5.71309101e-07
Iter: 1668 loss: 5.73058685e-07
Iter: 1669 loss: 5.71276132e-07
Iter: 1670 loss: 5.71220426e-07
Iter: 1671 loss: 5.72327622e-07
Iter: 1672 loss: 5.71204e-07
Iter: 1673 loss: 5.71130386e-07
Iter: 1674 loss: 5.7122918e-07
Iter: 1675 loss: 5.71082808e-07
Iter: 1676 loss: 5.70994871e-07
Iter: 1677 loss: 5.71075361e-07
Iter: 1678 loss: 5.70979296e-07
Iter: 1679 loss: 5.70889142e-07
Iter: 1680 loss: 5.70911197e-07
Iter: 1681 loss: 5.7083e-07
Iter: 1682 loss: 5.70749478e-07
Iter: 1683 loss: 5.71926421e-07
Iter: 1684 loss: 5.70748739e-07
Iter: 1685 loss: 5.70658472e-07
Iter: 1686 loss: 5.70918701e-07
Iter: 1687 loss: 5.7061186e-07
Iter: 1688 loss: 5.70547456e-07
Iter: 1689 loss: 5.70869133e-07
Iter: 1690 loss: 5.70549673e-07
Iter: 1691 loss: 5.70465261e-07
Iter: 1692 loss: 5.70438146e-07
Iter: 1693 loss: 5.70381872e-07
Iter: 1694 loss: 5.70295242e-07
Iter: 1695 loss: 5.70501129e-07
Iter: 1696 loss: 5.70255736e-07
Iter: 1697 loss: 5.70228622e-07
Iter: 1698 loss: 5.71010105e-07
Iter: 1699 loss: 5.70218617e-07
Iter: 1700 loss: 5.70137445e-07
Iter: 1701 loss: 5.69983513e-07
Iter: 1702 loss: 5.72481042e-07
Iter: 1703 loss: 5.70005341e-07
Iter: 1704 loss: 5.69882332e-07
Iter: 1705 loss: 5.6987227e-07
Iter: 1706 loss: 5.6981213e-07
Iter: 1707 loss: 5.69879603e-07
Iter: 1708 loss: 5.69760459e-07
Iter: 1709 loss: 5.69669623e-07
Iter: 1710 loss: 5.69616191e-07
Iter: 1711 loss: 5.6959027e-07
Iter: 1712 loss: 5.69452595e-07
Iter: 1713 loss: 5.69960378e-07
Iter: 1714 loss: 5.6944458e-07
Iter: 1715 loss: 5.69358292e-07
Iter: 1716 loss: 5.69993063e-07
Iter: 1717 loss: 5.6939183e-07
Iter: 1718 loss: 5.69320491e-07
Iter: 1719 loss: 5.69557528e-07
Iter: 1720 loss: 5.69284339e-07
Iter: 1721 loss: 5.69244492e-07
Iter: 1722 loss: 5.69392e-07
Iter: 1723 loss: 5.6922147e-07
Iter: 1724 loss: 5.69160761e-07
Iter: 1725 loss: 5.69374834e-07
Iter: 1726 loss: 5.69145413e-07
Iter: 1727 loss: 5.69115855e-07
Iter: 1728 loss: 5.69031954e-07
Iter: 1729 loss: 5.69025076e-07
Iter: 1730 loss: 5.68900873e-07
Iter: 1731 loss: 5.69592e-07
Iter: 1732 loss: 5.68909854e-07
Iter: 1733 loss: 5.68760129e-07
Iter: 1734 loss: 5.68943733e-07
Iter: 1735 loss: 5.68678956e-07
Iter: 1736 loss: 5.68591474e-07
Iter: 1737 loss: 5.68761948e-07
Iter: 1738 loss: 5.68585619e-07
Iter: 1739 loss: 5.68495693e-07
Iter: 1740 loss: 5.68717269e-07
Iter: 1741 loss: 5.68441919e-07
Iter: 1742 loss: 5.68331927e-07
Iter: 1743 loss: 5.68395706e-07
Iter: 1744 loss: 5.68245184e-07
Iter: 1745 loss: 5.68140194e-07
Iter: 1746 loss: 5.68531391e-07
Iter: 1747 loss: 5.68125188e-07
Iter: 1748 loss: 5.68068e-07
Iter: 1749 loss: 5.68096766e-07
Iter: 1750 loss: 5.6801e-07
Iter: 1751 loss: 5.67921575e-07
Iter: 1752 loss: 5.69194071e-07
Iter: 1753 loss: 5.67906625e-07
Iter: 1754 loss: 5.67861093e-07
Iter: 1755 loss: 5.6791157e-07
Iter: 1756 loss: 5.67827101e-07
Iter: 1757 loss: 5.67776851e-07
Iter: 1758 loss: 5.68153382e-07
Iter: 1759 loss: 5.67750646e-07
Iter: 1760 loss: 5.67708753e-07
Iter: 1761 loss: 5.67584891e-07
Iter: 1762 loss: 5.69581744e-07
Iter: 1763 loss: 5.67584891e-07
Iter: 1764 loss: 5.67478e-07
Iter: 1765 loss: 5.68487565e-07
Iter: 1766 loss: 5.6745921e-07
Iter: 1767 loss: 5.67364452e-07
Iter: 1768 loss: 5.68221708e-07
Iter: 1769 loss: 5.67340749e-07
Iter: 1770 loss: 5.67318921e-07
Iter: 1771 loss: 5.67200459e-07
Iter: 1772 loss: 5.688687e-07
Iter: 1773 loss: 5.67189602e-07
Iter: 1774 loss: 5.67059033e-07
Iter: 1775 loss: 5.67053235e-07
Iter: 1776 loss: 5.66984909e-07
Iter: 1777 loss: 5.66965127e-07
Iter: 1778 loss: 5.66928634e-07
Iter: 1779 loss: 5.66848087e-07
Iter: 1780 loss: 5.66909762e-07
Iter: 1781 loss: 5.66823132e-07
Iter: 1782 loss: 5.6670865e-07
Iter: 1783 loss: 5.66882477e-07
Iter: 1784 loss: 5.66652375e-07
Iter: 1785 loss: 5.66569383e-07
Iter: 1786 loss: 5.66559493e-07
Iter: 1787 loss: 5.66505776e-07
Iter: 1788 loss: 5.66486563e-07
Iter: 1789 loss: 5.66448648e-07
Iter: 1790 loss: 5.66387882e-07
Iter: 1791 loss: 5.66385552e-07
Iter: 1792 loss: 5.66331153e-07
Iter: 1793 loss: 5.66298525e-07
Iter: 1794 loss: 5.66287326e-07
Iter: 1795 loss: 5.66211952e-07
Iter: 1796 loss: 5.66138169e-07
Iter: 1797 loss: 5.66108838e-07
Iter: 1798 loss: 5.65976052e-07
Iter: 1799 loss: 5.66148628e-07
Iter: 1800 loss: 5.65926143e-07
Iter: 1801 loss: 5.65762548e-07
Iter: 1802 loss: 5.67622351e-07
Iter: 1803 loss: 5.65757091e-07
Iter: 1804 loss: 5.65754931e-07
Iter: 1805 loss: 5.65725486e-07
Iter: 1806 loss: 5.65690812e-07
Iter: 1807 loss: 5.65649088e-07
Iter: 1808 loss: 5.66563187e-07
Iter: 1809 loss: 5.65632547e-07
Iter: 1810 loss: 5.6556587e-07
Iter: 1811 loss: 5.6620695e-07
Iter: 1812 loss: 5.65577352e-07
Iter: 1813 loss: 5.65508401e-07
Iter: 1814 loss: 5.66001745e-07
Iter: 1815 loss: 5.65522498e-07
Iter: 1816 loss: 5.65527102e-07
Iter: 1817 loss: 5.65528126e-07
Iter: 1818 loss: 5.65520622e-07
Iter: 1819 loss: 5.6551761e-07
Iter: 1820 loss: 5.65517269e-07
Iter: 1821 loss: 5.65521873e-07
Iter: 1822 loss: 5.65525568e-07
Iter: 1823 loss: 5.65525909e-07
Iter: 1824 loss: 5.65517325e-07
Iter: 1825 loss: 5.65523578e-07
Iter: 1826 loss: 5.65520622e-07
Iter: 1827 loss: 5.65516928e-07
Iter: 1828 loss: 5.65527102e-07
Iter: 1829 loss: 5.65522612e-07
Iter: 1830 loss: 5.65523123e-07
Iter: 1831 loss: 5.6551994e-07
Iter: 1832 loss: 5.65520679e-07
Iter: 1833 loss: 5.65521191e-07
Iter: 1834 loss: 5.65521532e-07
Iter: 1835 loss: 5.65521873e-07
Iter: 1836 loss: 5.65523067e-07
Iter: 1837 loss: 5.65523123e-07
Iter: 1838 loss: 5.65523067e-07
Iter: 1839 loss: 5.65523123e-07
Iter: 1840 loss: 5.65523123e-07
Iter: 1841 loss: 5.65523067e-07
Iter: 1842 loss: 5.65523123e-07
Iter: 1843 loss: 5.65467246e-07
Iter: 1844 loss: 5.66246626e-07
Iter: 1845 loss: 5.65461619e-07
Iter: 1846 loss: 5.65449113e-07
Iter: 1847 loss: 5.6543422e-07
Iter: 1848 loss: 5.6539875e-07
Iter: 1849 loss: 5.65373e-07
Iter: 1850 loss: 5.65374307e-07
Iter: 1851 loss: 5.65322466e-07
Iter: 1852 loss: 5.65849632e-07
Iter: 1853 loss: 5.65339633e-07
Iter: 1854 loss: 5.6528495e-07
Iter: 1855 loss: 5.65181438e-07
Iter: 1856 loss: 5.65510959e-07
Iter: 1857 loss: 5.65121468e-07
Iter: 1858 loss: 5.6497322e-07
Iter: 1859 loss: 5.65331959e-07
Iter: 1860 loss: 5.64938659e-07
Iter: 1861 loss: 5.64814513e-07
Iter: 1862 loss: 5.64769039e-07
Iter: 1863 loss: 5.64713559e-07
Iter: 1864 loss: 5.6446197e-07
Iter: 1865 loss: 5.66126459e-07
Iter: 1866 loss: 5.64485674e-07
Iter: 1867 loss: 5.64368349e-07
Iter: 1868 loss: 5.64352e-07
Iter: 1869 loss: 5.64294169e-07
Iter: 1870 loss: 5.64205948e-07
Iter: 1871 loss: 5.642259e-07
Iter: 1872 loss: 5.6413154e-07
Iter: 1873 loss: 5.64107154e-07
Iter: 1874 loss: 5.64053607e-07
Iter: 1875 loss: 5.63949072e-07
Iter: 1876 loss: 5.63773142e-07
Iter: 1877 loss: 5.63757226e-07
Iter: 1878 loss: 5.63645358e-07
Iter: 1879 loss: 5.65601908e-07
Iter: 1880 loss: 5.63633819e-07
Iter: 1881 loss: 5.63613128e-07
Iter: 1882 loss: 5.63601816e-07
Iter: 1883 loss: 5.63567e-07
Iter: 1884 loss: 5.63521e-07
Iter: 1885 loss: 5.63506831e-07
Iter: 1886 loss: 5.63483468e-07
Iter: 1887 loss: 5.6405753e-07
Iter: 1888 loss: 5.63483e-07
Iter: 1889 loss: 5.63415711e-07
Iter: 1890 loss: 5.63368417e-07
Iter: 1891 loss: 5.63364836e-07
Iter: 1892 loss: 5.63334879e-07
Iter: 1893 loss: 5.63341132e-07
Iter: 1894 loss: 5.6328804e-07
Iter: 1895 loss: 5.63210449e-07
Iter: 1896 loss: 5.6322483e-07
Iter: 1897 loss: 5.63186404e-07
Iter: 1898 loss: 5.6312706e-07
Iter: 1899 loss: 5.64156664e-07
Iter: 1900 loss: 5.63124615e-07
Iter: 1901 loss: 5.63054698e-07
Iter: 1902 loss: 5.63811e-07
Iter: 1903 loss: 5.63064418e-07
Iter: 1904 loss: 5.62981768e-07
Iter: 1905 loss: 5.63007745e-07
Iter: 1906 loss: 5.62937316e-07
Iter: 1907 loss: 5.62865068e-07
Iter: 1908 loss: 5.62786738e-07
Iter: 1909 loss: 5.62763944e-07
Iter: 1910 loss: 5.62691298e-07
Iter: 1911 loss: 5.62944251e-07
Iter: 1912 loss: 5.62669527e-07
Iter: 1913 loss: 5.62606203e-07
Iter: 1914 loss: 5.63412186e-07
Iter: 1915 loss: 5.62592732e-07
Iter: 1916 loss: 5.62524122e-07
Iter: 1917 loss: 5.62558682e-07
Iter: 1918 loss: 5.62436298e-07
Iter: 1919 loss: 5.62425498e-07
Iter: 1920 loss: 5.63186461e-07
Iter: 1921 loss: 5.62427772e-07
Iter: 1922 loss: 5.62380478e-07
Iter: 1923 loss: 5.62401851e-07
Iter: 1924 loss: 5.62332e-07
Iter: 1925 loss: 5.62284e-07
Iter: 1926 loss: 5.62278046e-07
Iter: 1927 loss: 5.62239848e-07
Iter: 1928 loss: 5.62190962e-07
Iter: 1929 loss: 5.6296858e-07
Iter: 1930 loss: 5.621838e-07
Iter: 1931 loss: 5.62112348e-07
Iter: 1932 loss: 5.62124342e-07
Iter: 1933 loss: 5.62059256e-07
Iter: 1934 loss: 5.62015089e-07
Iter: 1935 loss: 5.62168566e-07
Iter: 1936 loss: 5.6197365e-07
Iter: 1937 loss: 5.61893785e-07
Iter: 1938 loss: 5.61910724e-07
Iter: 1939 loss: 5.61877755e-07
Iter: 1940 loss: 5.61782656e-07
Iter: 1941 loss: 5.62004971e-07
Iter: 1942 loss: 5.61735249e-07
Iter: 1943 loss: 5.61585921e-07
Iter: 1944 loss: 5.62284754e-07
Iter: 1945 loss: 5.61599506e-07
Iter: 1946 loss: 5.61490424e-07
Iter: 1947 loss: 5.61483489e-07
Iter: 1948 loss: 5.61414367e-07
Iter: 1949 loss: 5.61857121e-07
Iter: 1950 loss: 5.61395495e-07
Iter: 1951 loss: 5.61363777e-07
Iter: 1952 loss: 5.61302954e-07
Iter: 1953 loss: 5.6129727e-07
Iter: 1954 loss: 5.61249522e-07
Iter: 1955 loss: 5.61501793e-07
Iter: 1956 loss: 5.61215188e-07
Iter: 1957 loss: 5.61181139e-07
Iter: 1958 loss: 5.61164143e-07
Iter: 1959 loss: 5.61137313e-07
Iter: 1960 loss: 5.6113231e-07
Iter: 1961 loss: 5.61091e-07
Iter: 1962 loss: 5.610882e-07
Iter: 1963 loss: 5.61355364e-07
Iter: 1964 loss: 5.61109175e-07
Iter: 1965 loss: 5.61094339e-07
Iter: 1966 loss: 5.61096499e-07
Iter: 1967 loss: 5.61104684e-07
Iter: 1968 loss: 5.6110116e-07
Iter: 1969 loss: 5.61111563e-07
Iter: 1970 loss: 5.61108209e-07
Iter: 1971 loss: 5.61088768e-07
Iter: 1972 loss: 5.61083311e-07
Iter: 1973 loss: 5.61095362e-07
Iter: 1974 loss: 5.61091781e-07
Iter: 1975 loss: 5.61098659e-07
Iter: 1976 loss: 5.61083539e-07
Iter: 1977 loss: 5.61092349e-07
Iter: 1978 loss: 5.61085869e-07
Iter: 1979 loss: 5.61083652e-07
Iter: 1980 loss: 5.61091269e-07
Iter: 1981 loss: 5.61093145e-07
Iter: 1982 loss: 5.61093543e-07
Iter: 1983 loss: 5.6109e-07
Iter: 1984 loss: 5.61091554e-07
Iter: 1985 loss: 5.61091611e-07
Iter: 1986 loss: 5.61091724e-07
Iter: 1987 loss: 5.61091724e-07
Iter: 1988 loss: 5.61091554e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script120
+ '[' -r STOP.script120 ']'
+ exit 1
