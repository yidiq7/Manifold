+ RUN=3
+ export CUDA_VISIBLE_DEVICES=3
+ CUDA_VISIBLE_DEVICES=3
+ LAYERS=500_500_500_500_1
+ case $RUN in
+ PSI='2 3'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output61
++ pwd
+ OUT2=/home/mrdouglas/Manifold/experiments.final/output69
+ for fn in f2
+ case $fn in
+ OPT=--alpha
+ for psi in $PSI
+ for layers in $LAYERS
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0
+ date
Sat Nov  7 12:47:11 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0/500_500_500_500_1 --optimizer lbfgs --function f2 --psi 2 --alpha 0 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94703b4d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94703e3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9470459488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947039ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947035cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947035cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947032f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94702c7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947032f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947032f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947035ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947024ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947024e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947024ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94701f4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94701e3ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9470188510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9470188d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f947010c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94700b7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94700b7510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94700d1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94700d1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9470058ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f94700588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946fff8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946fff87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ffc2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ffc2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ff710d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ff71840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ff6dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ff010d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ff22d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946ff22bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f946fe838c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 5.56566602e-06
Iter: 2 loss: 4.61562922e-06
Iter: 3 loss: 4.46859758e-06
Iter: 4 loss: 4.10956909e-06
Iter: 5 loss: 3.8586586e-06
Iter: 6 loss: 3.730358e-06
Iter: 7 loss: 3.48926596e-06
Iter: 8 loss: 4.11287874e-06
Iter: 9 loss: 3.40697648e-06
Iter: 10 loss: 3.14498811e-06
Iter: 11 loss: 5.79871175e-06
Iter: 12 loss: 3.13699934e-06
Iter: 13 loss: 3.06997572e-06
Iter: 14 loss: 3.07066875e-06
Iter: 15 loss: 3.01644172e-06
Iter: 16 loss: 2.93549078e-06
Iter: 17 loss: 3.14610611e-06
Iter: 18 loss: 2.90791718e-06
Iter: 19 loss: 2.80454606e-06
Iter: 20 loss: 3.49091874e-06
Iter: 21 loss: 2.79393748e-06
Iter: 22 loss: 2.73880187e-06
Iter: 23 loss: 2.60043566e-06
Iter: 24 loss: 3.88329227e-06
Iter: 25 loss: 2.58041291e-06
Iter: 26 loss: 2.4743938e-06
Iter: 27 loss: 2.4588021e-06
Iter: 28 loss: 2.38237681e-06
Iter: 29 loss: 2.30874593e-06
Iter: 30 loss: 2.29189345e-06
Iter: 31 loss: 2.23328243e-06
Iter: 32 loss: 2.18828905e-06
Iter: 33 loss: 2.16960507e-06
Iter: 34 loss: 2.1263927e-06
Iter: 35 loss: 2.12463237e-06
Iter: 36 loss: 2.08959909e-06
Iter: 37 loss: 2.53273538e-06
Iter: 38 loss: 2.08931215e-06
Iter: 39 loss: 2.0660716e-06
Iter: 40 loss: 2.01187822e-06
Iter: 41 loss: 2.67007772e-06
Iter: 42 loss: 2.0075172e-06
Iter: 43 loss: 1.9877225e-06
Iter: 44 loss: 1.98198541e-06
Iter: 45 loss: 1.95131861e-06
Iter: 46 loss: 1.88601041e-06
Iter: 47 loss: 2.9354926e-06
Iter: 48 loss: 1.88401827e-06
Iter: 49 loss: 1.83113104e-06
Iter: 50 loss: 2.34328013e-06
Iter: 51 loss: 1.82916267e-06
Iter: 52 loss: 1.81282189e-06
Iter: 53 loss: 1.81199266e-06
Iter: 54 loss: 1.79646429e-06
Iter: 55 loss: 1.75612274e-06
Iter: 56 loss: 2.07134349e-06
Iter: 57 loss: 1.7483236e-06
Iter: 58 loss: 1.69280406e-06
Iter: 59 loss: 1.94118593e-06
Iter: 60 loss: 1.68193196e-06
Iter: 61 loss: 1.6298427e-06
Iter: 62 loss: 2.17085426e-06
Iter: 63 loss: 1.62842264e-06
Iter: 64 loss: 1.60511172e-06
Iter: 65 loss: 1.53914334e-06
Iter: 66 loss: 1.86412024e-06
Iter: 67 loss: 1.5168464e-06
Iter: 68 loss: 1.4687098e-06
Iter: 69 loss: 1.46867887e-06
Iter: 70 loss: 1.45034835e-06
Iter: 71 loss: 1.4493412e-06
Iter: 72 loss: 1.430623e-06
Iter: 73 loss: 1.45920512e-06
Iter: 74 loss: 1.42180738e-06
Iter: 75 loss: 1.41343446e-06
Iter: 76 loss: 1.40154566e-06
Iter: 77 loss: 1.40110637e-06
Iter: 78 loss: 1.37598227e-06
Iter: 79 loss: 1.47095727e-06
Iter: 80 loss: 1.36990741e-06
Iter: 81 loss: 1.35011464e-06
Iter: 82 loss: 1.3269314e-06
Iter: 83 loss: 1.32431683e-06
Iter: 84 loss: 1.29923387e-06
Iter: 85 loss: 1.60902687e-06
Iter: 86 loss: 1.29899888e-06
Iter: 87 loss: 1.27388466e-06
Iter: 88 loss: 1.33504932e-06
Iter: 89 loss: 1.26490295e-06
Iter: 90 loss: 1.25009456e-06
Iter: 91 loss: 1.26653617e-06
Iter: 92 loss: 1.24206645e-06
Iter: 93 loss: 1.2318618e-06
Iter: 94 loss: 1.23186032e-06
Iter: 95 loss: 1.22154415e-06
Iter: 96 loss: 1.20456366e-06
Iter: 97 loss: 1.20452125e-06
Iter: 98 loss: 1.19443837e-06
Iter: 99 loss: 1.18645448e-06
Iter: 100 loss: 1.18340517e-06
Iter: 101 loss: 1.16172669e-06
Iter: 102 loss: 1.23978327e-06
Iter: 103 loss: 1.15621845e-06
Iter: 104 loss: 1.15341095e-06
Iter: 105 loss: 1.14637919e-06
Iter: 106 loss: 1.14209251e-06
Iter: 107 loss: 1.12922191e-06
Iter: 108 loss: 1.16949059e-06
Iter: 109 loss: 1.12294731e-06
Iter: 110 loss: 1.12461589e-06
Iter: 111 loss: 1.11566806e-06
Iter: 112 loss: 1.11012946e-06
Iter: 113 loss: 1.09988741e-06
Iter: 114 loss: 1.33913079e-06
Iter: 115 loss: 1.09986854e-06
Iter: 116 loss: 1.08721088e-06
Iter: 117 loss: 1.07387768e-06
Iter: 118 loss: 1.07159121e-06
Iter: 119 loss: 1.08284235e-06
Iter: 120 loss: 1.06414802e-06
Iter: 121 loss: 1.05977e-06
Iter: 122 loss: 1.04866831e-06
Iter: 123 loss: 1.14006434e-06
Iter: 124 loss: 1.0466506e-06
Iter: 125 loss: 1.03129014e-06
Iter: 126 loss: 1.08517565e-06
Iter: 127 loss: 1.02733657e-06
Iter: 128 loss: 1.02745651e-06
Iter: 129 loss: 1.02441277e-06
Iter: 130 loss: 1.02168053e-06
Iter: 131 loss: 1.01603e-06
Iter: 132 loss: 1.11812278e-06
Iter: 133 loss: 1.01593082e-06
Iter: 134 loss: 1.01056753e-06
Iter: 135 loss: 1.00812406e-06
Iter: 136 loss: 1.00547413e-06
Iter: 137 loss: 9.95865094e-07
Iter: 138 loss: 1.02637659e-06
Iter: 139 loss: 9.93112849e-07
Iter: 140 loss: 9.78828439e-07
Iter: 141 loss: 1.03352363e-06
Iter: 142 loss: 9.75458875e-07
Iter: 143 loss: 9.69088e-07
Iter: 144 loss: 9.54865754e-07
Iter: 145 loss: 1.15025682e-06
Iter: 146 loss: 9.54107122e-07
Iter: 147 loss: 9.48205184e-07
Iter: 148 loss: 9.43845237e-07
Iter: 149 loss: 9.40161101e-07
Iter: 150 loss: 9.33513718e-07
Iter: 151 loss: 1.09691791e-06
Iter: 152 loss: 9.33522813e-07
Iter: 153 loss: 9.28034183e-07
Iter: 154 loss: 9.5840835e-07
Iter: 155 loss: 9.27241e-07
Iter: 156 loss: 9.23421283e-07
Iter: 157 loss: 9.23373364e-07
Iter: 158 loss: 9.21722062e-07
Iter: 159 loss: 9.16116164e-07
Iter: 160 loss: 9.14427687e-07
Iter: 161 loss: 9.09787957e-07
Iter: 162 loss: 8.97953782e-07
Iter: 163 loss: 1.04567334e-06
Iter: 164 loss: 8.97830319e-07
Iter: 165 loss: 8.94170853e-07
Iter: 166 loss: 8.93678589e-07
Iter: 167 loss: 8.90308797e-07
Iter: 168 loss: 8.81174174e-07
Iter: 169 loss: 9.43812495e-07
Iter: 170 loss: 8.79107461e-07
Iter: 171 loss: 8.70786948e-07
Iter: 172 loss: 9.49236096e-07
Iter: 173 loss: 8.70481585e-07
Iter: 174 loss: 8.67930908e-07
Iter: 175 loss: 8.678943e-07
Iter: 176 loss: 8.64720164e-07
Iter: 177 loss: 8.60235673e-07
Iter: 178 loss: 8.6005474e-07
Iter: 179 loss: 8.56587462e-07
Iter: 180 loss: 8.57331202e-07
Iter: 181 loss: 8.54058612e-07
Iter: 182 loss: 8.50436265e-07
Iter: 183 loss: 8.50275683e-07
Iter: 184 loss: 8.47991942e-07
Iter: 185 loss: 8.44288e-07
Iter: 186 loss: 8.44229362e-07
Iter: 187 loss: 8.4262e-07
Iter: 188 loss: 8.42567715e-07
Iter: 189 loss: 8.40388907e-07
Iter: 190 loss: 8.34791763e-07
Iter: 191 loss: 8.82059965e-07
Iter: 192 loss: 8.33865158e-07
Iter: 193 loss: 8.29229805e-07
Iter: 194 loss: 8.5356e-07
Iter: 195 loss: 8.28478733e-07
Iter: 196 loss: 8.24705808e-07
Iter: 197 loss: 8.43290195e-07
Iter: 198 loss: 8.24021527e-07
Iter: 199 loss: 8.18723038e-07
Iter: 200 loss: 8.25416862e-07
Iter: 201 loss: 8.16023e-07
Iter: 202 loss: 8.12066162e-07
Iter: 203 loss: 8.15934243e-07
Iter: 204 loss: 8.09818232e-07
Iter: 205 loss: 8.05548439e-07
Iter: 206 loss: 8.10787583e-07
Iter: 207 loss: 8.03332625e-07
Iter: 208 loss: 8.05665309e-07
Iter: 209 loss: 8.01982424e-07
Iter: 210 loss: 8.01397618e-07
Iter: 211 loss: 7.99424129e-07
Iter: 212 loss: 7.97308871e-07
Iter: 213 loss: 7.96552854e-07
Iter: 214 loss: 7.93234335e-07
Iter: 215 loss: 7.9314259e-07
Iter: 216 loss: 7.89912633e-07
Iter: 217 loss: 8.02671593e-07
Iter: 218 loss: 7.89184242e-07
Iter: 219 loss: 7.87265151e-07
Iter: 220 loss: 7.81787662e-07
Iter: 221 loss: 8.0764687e-07
Iter: 222 loss: 7.7984555e-07
Iter: 223 loss: 7.73885176e-07
Iter: 224 loss: 7.73414229e-07
Iter: 225 loss: 7.71559712e-07
Iter: 226 loss: 7.6814257e-07
Iter: 227 loss: 8.44482884e-07
Iter: 228 loss: 7.6812853e-07
Iter: 229 loss: 7.65278287e-07
Iter: 230 loss: 7.81633901e-07
Iter: 231 loss: 7.64880838e-07
Iter: 232 loss: 7.64250785e-07
Iter: 233 loss: 7.63802404e-07
Iter: 234 loss: 7.63156095e-07
Iter: 235 loss: 7.61251499e-07
Iter: 236 loss: 7.70075872e-07
Iter: 237 loss: 7.60566877e-07
Iter: 238 loss: 7.5803564e-07
Iter: 239 loss: 7.78529056e-07
Iter: 240 loss: 7.57863916e-07
Iter: 241 loss: 7.56599945e-07
Iter: 242 loss: 7.72610065e-07
Iter: 243 loss: 7.56596592e-07
Iter: 244 loss: 7.5489578e-07
Iter: 245 loss: 7.50826416e-07
Iter: 246 loss: 7.93889967e-07
Iter: 247 loss: 7.50339e-07
Iter: 248 loss: 7.47224306e-07
Iter: 249 loss: 7.65836944e-07
Iter: 250 loss: 7.46836292e-07
Iter: 251 loss: 7.45443117e-07
Iter: 252 loss: 7.45257125e-07
Iter: 253 loss: 7.43942337e-07
Iter: 254 loss: 7.40438452e-07
Iter: 255 loss: 7.65607524e-07
Iter: 256 loss: 7.39653728e-07
Iter: 257 loss: 7.38943925e-07
Iter: 258 loss: 7.38176709e-07
Iter: 259 loss: 7.36411607e-07
Iter: 260 loss: 7.32292563e-07
Iter: 261 loss: 7.80667165e-07
Iter: 262 loss: 7.31927457e-07
Iter: 263 loss: 7.28984901e-07
Iter: 264 loss: 7.45361945e-07
Iter: 265 loss: 7.28556643e-07
Iter: 266 loss: 7.26885332e-07
Iter: 267 loss: 7.45648094e-07
Iter: 268 loss: 7.26832354e-07
Iter: 269 loss: 7.24752908e-07
Iter: 270 loss: 7.23859841e-07
Iter: 271 loss: 7.22774416e-07
Iter: 272 loss: 7.21583206e-07
Iter: 273 loss: 7.2311218e-07
Iter: 274 loss: 7.210013e-07
Iter: 275 loss: 7.1923057e-07
Iter: 276 loss: 7.20291609e-07
Iter: 277 loss: 7.18060051e-07
Iter: 278 loss: 7.15137389e-07
Iter: 279 loss: 7.3809997e-07
Iter: 280 loss: 7.14960663e-07
Iter: 281 loss: 7.13413556e-07
Iter: 282 loss: 7.0935755e-07
Iter: 283 loss: 7.39772531e-07
Iter: 284 loss: 7.08540711e-07
Iter: 285 loss: 7.05968318e-07
Iter: 286 loss: 7.05591219e-07
Iter: 287 loss: 7.03231649e-07
Iter: 288 loss: 7.15392616e-07
Iter: 289 loss: 7.02840907e-07
Iter: 290 loss: 7.01934425e-07
Iter: 291 loss: 7.00258397e-07
Iter: 292 loss: 7.39642473e-07
Iter: 293 loss: 7.0026249e-07
Iter: 294 loss: 6.98917688e-07
Iter: 295 loss: 6.98742951e-07
Iter: 296 loss: 6.98368297e-07
Iter: 297 loss: 6.97432938e-07
Iter: 298 loss: 7.04199124e-07
Iter: 299 loss: 6.97199539e-07
Iter: 300 loss: 6.95675112e-07
Iter: 301 loss: 6.98174745e-07
Iter: 302 loss: 6.9495303e-07
Iter: 303 loss: 6.92813e-07
Iter: 304 loss: 7.07741492e-07
Iter: 305 loss: 6.92597609e-07
Iter: 306 loss: 6.91491664e-07
Iter: 307 loss: 6.88490559e-07
Iter: 308 loss: 7.07102e-07
Iter: 309 loss: 6.87705153e-07
Iter: 310 loss: 6.85066198e-07
Iter: 311 loss: 6.84921133e-07
Iter: 312 loss: 6.8363471e-07
Iter: 313 loss: 6.83579401e-07
Iter: 314 loss: 6.82815312e-07
Iter: 315 loss: 6.80914241e-07
Iter: 316 loss: 6.98770123e-07
Iter: 317 loss: 6.80633548e-07
Iter: 318 loss: 6.79191658e-07
Iter: 319 loss: 6.95176539e-07
Iter: 320 loss: 6.79137315e-07
Iter: 321 loss: 6.78525794e-07
Iter: 322 loss: 6.78428137e-07
Iter: 323 loss: 6.77941898e-07
Iter: 324 loss: 6.76260129e-07
Iter: 325 loss: 6.76289119e-07
Iter: 326 loss: 6.74546072e-07
Iter: 327 loss: 6.78048423e-07
Iter: 328 loss: 6.7369848e-07
Iter: 329 loss: 6.73182171e-07
Iter: 330 loss: 6.71738405e-07
Iter: 331 loss: 6.76936622e-07
Iter: 332 loss: 6.71104e-07
Iter: 333 loss: 6.68971211e-07
Iter: 334 loss: 6.7637643e-07
Iter: 335 loss: 6.68455243e-07
Iter: 336 loss: 6.67613222e-07
Iter: 337 loss: 6.6743263e-07
Iter: 338 loss: 6.66763754e-07
Iter: 339 loss: 6.64731374e-07
Iter: 340 loss: 6.70313852e-07
Iter: 341 loss: 6.63647484e-07
Iter: 342 loss: 6.61364e-07
Iter: 343 loss: 6.82613859e-07
Iter: 344 loss: 6.61263698e-07
Iter: 345 loss: 6.59676118e-07
Iter: 346 loss: 6.5967447e-07
Iter: 347 loss: 6.5821331e-07
Iter: 348 loss: 6.57119e-07
Iter: 349 loss: 6.56644943e-07
Iter: 350 loss: 6.55688609e-07
Iter: 351 loss: 6.58798854e-07
Iter: 352 loss: 6.55443841e-07
Iter: 353 loss: 6.54707492e-07
Iter: 354 loss: 6.64200684e-07
Iter: 355 loss: 6.54726136e-07
Iter: 356 loss: 6.53933853e-07
Iter: 357 loss: 6.53112238e-07
Iter: 358 loss: 6.52948529e-07
Iter: 359 loss: 6.52320523e-07
Iter: 360 loss: 6.54839482e-07
Iter: 361 loss: 6.52156928e-07
Iter: 362 loss: 6.51090488e-07
Iter: 363 loss: 6.50927348e-07
Iter: 364 loss: 6.50212087e-07
Iter: 365 loss: 6.48962782e-07
Iter: 366 loss: 6.47695174e-07
Iter: 367 loss: 6.4743017e-07
Iter: 368 loss: 6.46297508e-07
Iter: 369 loss: 6.46205365e-07
Iter: 370 loss: 6.44809461e-07
Iter: 371 loss: 6.4344465e-07
Iter: 372 loss: 6.43157534e-07
Iter: 373 loss: 6.42322277e-07
Iter: 374 loss: 6.43234614e-07
Iter: 375 loss: 6.41866734e-07
Iter: 376 loss: 6.41072518e-07
Iter: 377 loss: 6.52676e-07
Iter: 378 loss: 6.41056431e-07
Iter: 379 loss: 6.40420183e-07
Iter: 380 loss: 6.42549594e-07
Iter: 381 loss: 6.4023186e-07
Iter: 382 loss: 6.3987369e-07
Iter: 383 loss: 6.38989491e-07
Iter: 384 loss: 6.48565845e-07
Iter: 385 loss: 6.38890072e-07
Iter: 386 loss: 6.37515086e-07
Iter: 387 loss: 6.43625754e-07
Iter: 388 loss: 6.37251219e-07
Iter: 389 loss: 6.35738957e-07
Iter: 390 loss: 6.46565525e-07
Iter: 391 loss: 6.35578e-07
Iter: 392 loss: 6.34758578e-07
Iter: 393 loss: 6.32764568e-07
Iter: 394 loss: 6.52898734e-07
Iter: 395 loss: 6.32530771e-07
Iter: 396 loss: 6.31969442e-07
Iter: 397 loss: 6.31184037e-07
Iter: 398 loss: 6.30791419e-07
Iter: 399 loss: 6.29768238e-07
Iter: 400 loss: 6.39815653e-07
Iter: 401 loss: 6.2963619e-07
Iter: 402 loss: 6.28694465e-07
Iter: 403 loss: 6.38045321e-07
Iter: 404 loss: 6.28661041e-07
Iter: 405 loss: 6.2785864e-07
Iter: 406 loss: 6.35719289e-07
Iter: 407 loss: 6.27842553e-07
Iter: 408 loss: 6.27576298e-07
Iter: 409 loss: 6.26761675e-07
Iter: 410 loss: 6.29398414e-07
Iter: 411 loss: 6.26378096e-07
Iter: 412 loss: 6.25420171e-07
Iter: 413 loss: 6.2541028e-07
Iter: 414 loss: 6.24594804e-07
Iter: 415 loss: 6.29828605e-07
Iter: 416 loss: 6.24496579e-07
Iter: 417 loss: 6.2398982e-07
Iter: 418 loss: 6.22895527e-07
Iter: 419 loss: 6.39127734e-07
Iter: 420 loss: 6.22848574e-07
Iter: 421 loss: 6.21691e-07
Iter: 422 loss: 6.32635306e-07
Iter: 423 loss: 6.21642e-07
Iter: 424 loss: 6.21068239e-07
Iter: 425 loss: 6.21041181e-07
Iter: 426 loss: 6.20672722e-07
Iter: 427 loss: 6.19594e-07
Iter: 428 loss: 6.24179506e-07
Iter: 429 loss: 6.19146476e-07
Iter: 430 loss: 6.20012e-07
Iter: 431 loss: 6.18753347e-07
Iter: 432 loss: 6.18452191e-07
Iter: 433 loss: 6.17637227e-07
Iter: 434 loss: 6.23073845e-07
Iter: 435 loss: 6.17461581e-07
Iter: 436 loss: 6.16369562e-07
Iter: 437 loss: 6.15493718e-07
Iter: 438 loss: 6.15178351e-07
Iter: 439 loss: 6.14567853e-07
Iter: 440 loss: 6.14470594e-07
Iter: 441 loss: 6.13926602e-07
Iter: 442 loss: 6.16030491e-07
Iter: 443 loss: 6.1378023e-07
Iter: 444 loss: 6.13322413e-07
Iter: 445 loss: 6.12250801e-07
Iter: 446 loss: 6.23645633e-07
Iter: 447 loss: 6.12121312e-07
Iter: 448 loss: 6.12026724e-07
Iter: 449 loss: 6.1159966e-07
Iter: 450 loss: 6.11112739e-07
Iter: 451 loss: 6.10318182e-07
Iter: 452 loss: 6.10321081e-07
Iter: 453 loss: 6.09238782e-07
Iter: 454 loss: 6.09708763e-07
Iter: 455 loss: 6.08524431e-07
Iter: 456 loss: 6.07519439e-07
Iter: 457 loss: 6.18079184e-07
Iter: 458 loss: 6.07497327e-07
Iter: 459 loss: 6.06577828e-07
Iter: 460 loss: 6.11283e-07
Iter: 461 loss: 6.06467324e-07
Iter: 462 loss: 6.05877574e-07
Iter: 463 loss: 6.05383377e-07
Iter: 464 loss: 6.05221032e-07
Iter: 465 loss: 6.05319144e-07
Iter: 466 loss: 6.04954266e-07
Iter: 467 loss: 6.0481284e-07
Iter: 468 loss: 6.04308468e-07
Iter: 469 loss: 6.04209617e-07
Iter: 470 loss: 6.03773515e-07
Iter: 471 loss: 6.0304319e-07
Iter: 472 loss: 6.03048306e-07
Iter: 473 loss: 6.02426155e-07
Iter: 474 loss: 6.04412151e-07
Iter: 475 loss: 6.02275236e-07
Iter: 476 loss: 6.01565944e-07
Iter: 477 loss: 6.00531621e-07
Iter: 478 loss: 6.00497401e-07
Iter: 479 loss: 5.99389921e-07
Iter: 480 loss: 6.03619469e-07
Iter: 481 loss: 5.99107182e-07
Iter: 482 loss: 5.98797101e-07
Iter: 483 loss: 5.98627366e-07
Iter: 484 loss: 5.98253393e-07
Iter: 485 loss: 5.97377607e-07
Iter: 486 loss: 6.07662173e-07
Iter: 487 loss: 5.97297e-07
Iter: 488 loss: 5.9679445e-07
Iter: 489 loss: 6.033207e-07
Iter: 490 loss: 5.96788e-07
Iter: 491 loss: 5.96406835e-07
Iter: 492 loss: 5.97343728e-07
Iter: 493 loss: 5.96286384e-07
Iter: 494 loss: 5.9569561e-07
Iter: 495 loss: 5.95519964e-07
Iter: 496 loss: 5.95112624e-07
Iter: 497 loss: 5.94385654e-07
Iter: 498 loss: 5.9572011e-07
Iter: 499 loss: 5.94045446e-07
Iter: 500 loss: 5.93377308e-07
Iter: 501 loss: 5.9338538e-07
Iter: 502 loss: 5.92942456e-07
Iter: 503 loss: 5.91618118e-07
Iter: 504 loss: 5.95284405e-07
Iter: 505 loss: 5.90912407e-07
Iter: 506 loss: 5.90965101e-07
Iter: 507 loss: 5.90414686e-07
Iter: 508 loss: 5.89893432e-07
Iter: 509 loss: 5.90445e-07
Iter: 510 loss: 5.89572892e-07
Iter: 511 loss: 5.8905448e-07
Iter: 512 loss: 5.88712396e-07
Iter: 513 loss: 5.88518674e-07
Iter: 514 loss: 5.87961608e-07
Iter: 515 loss: 5.91392848e-07
Iter: 516 loss: 5.87920169e-07
Iter: 517 loss: 5.87227532e-07
Iter: 518 loss: 5.9011586e-07
Iter: 519 loss: 5.87098214e-07
Iter: 520 loss: 5.8669707e-07
Iter: 521 loss: 5.86453552e-07
Iter: 522 loss: 5.86285296e-07
Iter: 523 loss: 5.85897396e-07
Iter: 524 loss: 5.88185628e-07
Iter: 525 loss: 5.85851581e-07
Iter: 526 loss: 5.85480166e-07
Iter: 527 loss: 5.88212401e-07
Iter: 528 loss: 5.85456348e-07
Iter: 529 loss: 5.85147632e-07
Iter: 530 loss: 5.85113526e-07
Iter: 531 loss: 5.84879103e-07
Iter: 532 loss: 5.84610575e-07
Iter: 533 loss: 5.86391479e-07
Iter: 534 loss: 5.8459807e-07
Iter: 535 loss: 5.84189138e-07
Iter: 536 loss: 5.83327449e-07
Iter: 537 loss: 5.96703671e-07
Iter: 538 loss: 5.83294593e-07
Iter: 539 loss: 5.8236941e-07
Iter: 540 loss: 5.84066413e-07
Iter: 541 loss: 5.82005669e-07
Iter: 542 loss: 5.81641075e-07
Iter: 543 loss: 5.81532845e-07
Iter: 544 loss: 5.81088e-07
Iter: 545 loss: 5.80313554e-07
Iter: 546 loss: 5.99237069e-07
Iter: 547 loss: 5.80324354e-07
Iter: 548 loss: 5.80017058e-07
Iter: 549 loss: 5.83425503e-07
Iter: 550 loss: 5.80014671e-07
Iter: 551 loss: 5.79821e-07
Iter: 552 loss: 5.81989639e-07
Iter: 553 loss: 5.79824e-07
Iter: 554 loss: 5.79630068e-07
Iter: 555 loss: 5.79266384e-07
Iter: 556 loss: 5.85053613e-07
Iter: 557 loss: 5.79263769e-07
Iter: 558 loss: 5.78917138e-07
Iter: 559 loss: 5.80029109e-07
Iter: 560 loss: 5.78835227e-07
Iter: 561 loss: 5.78480922e-07
Iter: 562 loss: 5.81007e-07
Iter: 563 loss: 5.78444599e-07
Iter: 564 loss: 5.78028676e-07
Iter: 565 loss: 5.77535332e-07
Iter: 566 loss: 5.7745757e-07
Iter: 567 loss: 5.76928073e-07
Iter: 568 loss: 5.80936671e-07
Iter: 569 loss: 5.76892944e-07
Iter: 570 loss: 5.76580305e-07
Iter: 571 loss: 5.81402333e-07
Iter: 572 loss: 5.76585364e-07
Iter: 573 loss: 5.76374759e-07
Iter: 574 loss: 5.75885e-07
Iter: 575 loss: 5.80512165e-07
Iter: 576 loss: 5.75828039e-07
Iter: 577 loss: 5.75623289e-07
Iter: 578 loss: 5.75605668e-07
Iter: 579 loss: 5.75347258e-07
Iter: 580 loss: 5.751765e-07
Iter: 581 loss: 5.75082538e-07
Iter: 582 loss: 5.7472937e-07
Iter: 583 loss: 5.74743467e-07
Iter: 584 loss: 5.74448677e-07
Iter: 585 loss: 5.74370688e-07
Iter: 586 loss: 5.74302476e-07
Iter: 587 loss: 5.74122339e-07
Iter: 588 loss: 5.7376792e-07
Iter: 589 loss: 5.79955213e-07
Iter: 590 loss: 5.73762918e-07
Iter: 591 loss: 5.7343982e-07
Iter: 592 loss: 5.75008926e-07
Iter: 593 loss: 5.73375814e-07
Iter: 594 loss: 5.73184195e-07
Iter: 595 loss: 5.74880858e-07
Iter: 596 loss: 5.73143325e-07
Iter: 597 loss: 5.72876843e-07
Iter: 598 loss: 5.72881049e-07
Iter: 599 loss: 5.72683348e-07
Iter: 600 loss: 5.7238492e-07
Iter: 601 loss: 5.72930389e-07
Iter: 602 loss: 5.72263843e-07
Iter: 603 loss: 5.72018e-07
Iter: 604 loss: 5.75177864e-07
Iter: 605 loss: 5.71999635e-07
Iter: 606 loss: 5.7175032e-07
Iter: 607 loss: 5.71280964e-07
Iter: 608 loss: 5.82801e-07
Iter: 609 loss: 5.7129364e-07
Iter: 610 loss: 5.71063481e-07
Iter: 611 loss: 5.73139403e-07
Iter: 612 loss: 5.7105882e-07
Iter: 613 loss: 5.70892553e-07
Iter: 614 loss: 5.72544309e-07
Iter: 615 loss: 5.70905058e-07
Iter: 616 loss: 5.70773864e-07
Iter: 617 loss: 5.7051534e-07
Iter: 618 loss: 5.74413093e-07
Iter: 619 loss: 5.70474185e-07
Iter: 620 loss: 5.70284e-07
Iter: 621 loss: 5.72567558e-07
Iter: 622 loss: 5.70269265e-07
Iter: 623 loss: 5.70050361e-07
Iter: 624 loss: 5.70515e-07
Iter: 625 loss: 5.6994395e-07
Iter: 626 loss: 5.69757958e-07
Iter: 627 loss: 5.69488179e-07
Iter: 628 loss: 5.69470274e-07
Iter: 629 loss: 5.69171789e-07
Iter: 630 loss: 5.70850659e-07
Iter: 631 loss: 5.69132169e-07
Iter: 632 loss: 5.68823168e-07
Iter: 633 loss: 5.71583882e-07
Iter: 634 loss: 5.68777807e-07
Iter: 635 loss: 5.68648602e-07
Iter: 636 loss: 5.68684754e-07
Iter: 637 loss: 5.68572716e-07
Iter: 638 loss: 5.68400935e-07
Iter: 639 loss: 5.69331064e-07
Iter: 640 loss: 5.68369273e-07
Iter: 641 loss: 5.68156679e-07
Iter: 642 loss: 5.67891391e-07
Iter: 643 loss: 5.67847565e-07
Iter: 644 loss: 5.67567213e-07
Iter: 645 loss: 5.6810029e-07
Iter: 646 loss: 5.67467225e-07
Iter: 647 loss: 5.67258326e-07
Iter: 648 loss: 5.67263157e-07
Iter: 649 loss: 5.67045731e-07
Iter: 650 loss: 5.66733604e-07
Iter: 651 loss: 5.6673565e-07
Iter: 652 loss: 5.66527945e-07
Iter: 653 loss: 5.67011909e-07
Iter: 654 loss: 5.66442282e-07
Iter: 655 loss: 5.66177278e-07
Iter: 656 loss: 5.6815918e-07
Iter: 657 loss: 5.6614067e-07
Iter: 658 loss: 5.65965308e-07
Iter: 659 loss: 5.65709115e-07
Iter: 660 loss: 5.65674554e-07
Iter: 661 loss: 5.6535788e-07
Iter: 662 loss: 5.65283244e-07
Iter: 663 loss: 5.6508236e-07
Iter: 664 loss: 5.64749485e-07
Iter: 665 loss: 5.64720722e-07
Iter: 666 loss: 5.64576794e-07
Iter: 667 loss: 5.6431054e-07
Iter: 668 loss: 5.64315314e-07
Iter: 669 loss: 5.64042352e-07
Iter: 670 loss: 5.66399194e-07
Iter: 671 loss: 5.64020468e-07
Iter: 672 loss: 5.63806509e-07
Iter: 673 loss: 5.64714696e-07
Iter: 674 loss: 5.63751087e-07
Iter: 675 loss: 5.63636888e-07
Iter: 676 loss: 5.63448907e-07
Iter: 677 loss: 5.63442882e-07
Iter: 678 loss: 5.63180379e-07
Iter: 679 loss: 5.64510515e-07
Iter: 680 loss: 5.63112962e-07
Iter: 681 loss: 5.62695789e-07
Iter: 682 loss: 5.62649689e-07
Iter: 683 loss: 5.62348418e-07
Iter: 684 loss: 5.61945171e-07
Iter: 685 loss: 5.61223487e-07
Iter: 686 loss: 5.78058689e-07
Iter: 687 loss: 5.61222748e-07
Iter: 688 loss: 5.60674437e-07
Iter: 689 loss: 5.60563592e-07
Iter: 690 loss: 5.601417e-07
Iter: 691 loss: 5.59394209e-07
Iter: 692 loss: 5.59407795e-07
Iter: 693 loss: 5.58637623e-07
Iter: 694 loss: 5.58289344e-07
Iter: 695 loss: 5.5792259e-07
Iter: 696 loss: 5.58440149e-07
Iter: 697 loss: 5.57592728e-07
Iter: 698 loss: 5.5736939e-07
Iter: 699 loss: 5.56735074e-07
Iter: 700 loss: 5.60587694e-07
Iter: 701 loss: 5.56545331e-07
Iter: 702 loss: 5.55580471e-07
Iter: 703 loss: 5.5538078e-07
Iter: 704 loss: 5.547314e-07
Iter: 705 loss: 5.55715587e-07
Iter: 706 loss: 5.54325823e-07
Iter: 707 loss: 5.54037456e-07
Iter: 708 loss: 5.53231644e-07
Iter: 709 loss: 5.55344627e-07
Iter: 710 loss: 5.52762231e-07
Iter: 711 loss: 5.51885933e-07
Iter: 712 loss: 5.65027392e-07
Iter: 713 loss: 5.51888888e-07
Iter: 714 loss: 5.51016683e-07
Iter: 715 loss: 5.56860755e-07
Iter: 716 loss: 5.50908453e-07
Iter: 717 loss: 5.50223831e-07
Iter: 718 loss: 5.48890796e-07
Iter: 719 loss: 5.75582646e-07
Iter: 720 loss: 5.48857713e-07
Iter: 721 loss: 5.48501134e-07
Iter: 722 loss: 5.48268076e-07
Iter: 723 loss: 5.47652064e-07
Iter: 724 loss: 5.46941806e-07
Iter: 725 loss: 5.46884451e-07
Iter: 726 loss: 5.45954322e-07
Iter: 727 loss: 5.45565399e-07
Iter: 728 loss: 5.45082116e-07
Iter: 729 loss: 5.44992076e-07
Iter: 730 loss: 5.44781642e-07
Iter: 731 loss: 5.44407271e-07
Iter: 732 loss: 5.43840429e-07
Iter: 733 loss: 5.43837302e-07
Iter: 734 loss: 5.43162571e-07
Iter: 735 loss: 5.43387159e-07
Iter: 736 loss: 5.42688952e-07
Iter: 737 loss: 5.42301e-07
Iter: 738 loss: 5.42275643e-07
Iter: 739 loss: 5.41773545e-07
Iter: 740 loss: 5.41717213e-07
Iter: 741 loss: 5.4136467e-07
Iter: 742 loss: 5.40857e-07
Iter: 743 loss: 5.4033211e-07
Iter: 744 loss: 5.40245765e-07
Iter: 745 loss: 5.3956137e-07
Iter: 746 loss: 5.39564326e-07
Iter: 747 loss: 5.38841334e-07
Iter: 748 loss: 5.39659595e-07
Iter: 749 loss: 5.38473614e-07
Iter: 750 loss: 5.3812164e-07
Iter: 751 loss: 5.37849246e-07
Iter: 752 loss: 5.37717483e-07
Iter: 753 loss: 5.36991138e-07
Iter: 754 loss: 5.43989472e-07
Iter: 755 loss: 5.36942366e-07
Iter: 756 loss: 5.36568393e-07
Iter: 757 loss: 5.35990466e-07
Iter: 758 loss: 5.3599706e-07
Iter: 759 loss: 5.35327217e-07
Iter: 760 loss: 5.35480865e-07
Iter: 761 loss: 5.34848482e-07
Iter: 762 loss: 5.35044364e-07
Iter: 763 loss: 5.3454113e-07
Iter: 764 loss: 5.3431063e-07
Iter: 765 loss: 5.3391534e-07
Iter: 766 loss: 5.33913578e-07
Iter: 767 loss: 5.33404659e-07
Iter: 768 loss: 5.32943659e-07
Iter: 769 loss: 5.3280155e-07
Iter: 770 loss: 5.32180195e-07
Iter: 771 loss: 5.32293939e-07
Iter: 772 loss: 5.31734486e-07
Iter: 773 loss: 5.31589421e-07
Iter: 774 loss: 5.31213971e-07
Iter: 775 loss: 5.3091253e-07
Iter: 776 loss: 5.30263833e-07
Iter: 777 loss: 5.39904875e-07
Iter: 778 loss: 5.30238822e-07
Iter: 779 loss: 5.29449267e-07
Iter: 780 loss: 5.29798456e-07
Iter: 781 loss: 5.2891744e-07
Iter: 782 loss: 5.28451608e-07
Iter: 783 loss: 5.28384362e-07
Iter: 784 loss: 5.2787766e-07
Iter: 785 loss: 5.29159365e-07
Iter: 786 loss: 5.27715031e-07
Iter: 787 loss: 5.27252041e-07
Iter: 788 loss: 5.26475e-07
Iter: 789 loss: 5.26475787e-07
Iter: 790 loss: 5.26755855e-07
Iter: 791 loss: 5.26274675e-07
Iter: 792 loss: 5.26117219e-07
Iter: 793 loss: 5.25739665e-07
Iter: 794 loss: 5.30530883e-07
Iter: 795 loss: 5.25709765e-07
Iter: 796 loss: 5.25164864e-07
Iter: 797 loss: 5.24520374e-07
Iter: 798 loss: 5.24437041e-07
Iter: 799 loss: 5.24589609e-07
Iter: 800 loss: 5.24046129e-07
Iter: 801 loss: 5.23780386e-07
Iter: 802 loss: 5.22885898e-07
Iter: 803 loss: 5.27297288e-07
Iter: 804 loss: 5.22593155e-07
Iter: 805 loss: 5.2174488e-07
Iter: 806 loss: 5.26402e-07
Iter: 807 loss: 5.21623519e-07
Iter: 808 loss: 5.21194181e-07
Iter: 809 loss: 5.21179e-07
Iter: 810 loss: 5.20759613e-07
Iter: 811 loss: 5.20454e-07
Iter: 812 loss: 5.20314e-07
Iter: 813 loss: 5.2004151e-07
Iter: 814 loss: 5.20045432e-07
Iter: 815 loss: 5.19845912e-07
Iter: 816 loss: 5.19425782e-07
Iter: 817 loss: 5.21851575e-07
Iter: 818 loss: 5.19378432e-07
Iter: 819 loss: 5.18894296e-07
Iter: 820 loss: 5.20941512e-07
Iter: 821 loss: 5.18803745e-07
Iter: 822 loss: 5.18537604e-07
Iter: 823 loss: 5.18309548e-07
Iter: 824 loss: 5.18248e-07
Iter: 825 loss: 5.17925e-07
Iter: 826 loss: 5.17925855e-07
Iter: 827 loss: 5.17613955e-07
Iter: 828 loss: 5.17323656e-07
Iter: 829 loss: 5.17257718e-07
Iter: 830 loss: 5.16868568e-07
Iter: 831 loss: 5.16508294e-07
Iter: 832 loss: 5.16419391e-07
Iter: 833 loss: 5.16158138e-07
Iter: 834 loss: 5.16030411e-07
Iter: 835 loss: 5.15753072e-07
Iter: 836 loss: 5.15298211e-07
Iter: 837 loss: 5.15298325e-07
Iter: 838 loss: 5.1478645e-07
Iter: 839 loss: 5.13652196e-07
Iter: 840 loss: 5.2947837e-07
Iter: 841 loss: 5.13586087e-07
Iter: 842 loss: 5.13841485e-07
Iter: 843 loss: 5.13148507e-07
Iter: 844 loss: 5.12772431e-07
Iter: 845 loss: 5.15379043e-07
Iter: 846 loss: 5.1271229e-07
Iter: 847 loss: 5.12544e-07
Iter: 848 loss: 5.12023348e-07
Iter: 849 loss: 5.17834e-07
Iter: 850 loss: 5.11970541e-07
Iter: 851 loss: 5.11822805e-07
Iter: 852 loss: 5.11764085e-07
Iter: 853 loss: 5.11455767e-07
Iter: 854 loss: 5.10946109e-07
Iter: 855 loss: 5.1094878e-07
Iter: 856 loss: 5.10625114e-07
Iter: 857 loss: 5.12502538e-07
Iter: 858 loss: 5.10574296e-07
Iter: 859 loss: 5.10129e-07
Iter: 860 loss: 5.12116628e-07
Iter: 861 loss: 5.10079701e-07
Iter: 862 loss: 5.09600909e-07
Iter: 863 loss: 5.08723758e-07
Iter: 864 loss: 5.28052396e-07
Iter: 865 loss: 5.08724156e-07
Iter: 866 loss: 5.0824508e-07
Iter: 867 loss: 5.08231e-07
Iter: 868 loss: 5.07888103e-07
Iter: 869 loss: 5.10401094e-07
Iter: 870 loss: 5.07832397e-07
Iter: 871 loss: 5.07619859e-07
Iter: 872 loss: 5.07052619e-07
Iter: 873 loss: 5.13220755e-07
Iter: 874 loss: 5.06978154e-07
Iter: 875 loss: 5.06483332e-07
Iter: 876 loss: 5.07930508e-07
Iter: 877 loss: 5.06331673e-07
Iter: 878 loss: 5.06246806e-07
Iter: 879 loss: 5.06067693e-07
Iter: 880 loss: 5.05897106e-07
Iter: 881 loss: 5.05605385e-07
Iter: 882 loss: 5.05606579e-07
Iter: 883 loss: 5.05251819e-07
Iter: 884 loss: 5.04775926e-07
Iter: 885 loss: 5.04748357e-07
Iter: 886 loss: 5.04425941e-07
Iter: 887 loss: 5.04303216e-07
Iter: 888 loss: 5.04146215e-07
Iter: 889 loss: 5.03728359e-07
Iter: 890 loss: 5.06341678e-07
Iter: 891 loss: 5.03617116e-07
Iter: 892 loss: 5.03300043e-07
Iter: 893 loss: 5.03277704e-07
Iter: 894 loss: 5.02942157e-07
Iter: 895 loss: 5.0307392e-07
Iter: 896 loss: 5.02711032e-07
Iter: 897 loss: 5.02394414e-07
Iter: 898 loss: 5.01902491e-07
Iter: 899 loss: 5.01898967e-07
Iter: 900 loss: 5.01936825e-07
Iter: 901 loss: 5.0165022e-07
Iter: 902 loss: 5.01485601e-07
Iter: 903 loss: 5.01376462e-07
Iter: 904 loss: 5.01302054e-07
Iter: 905 loss: 5.01056093e-07
Iter: 906 loss: 5.00536771e-07
Iter: 907 loss: 5.09594429e-07
Iter: 908 loss: 5.00508463e-07
Iter: 909 loss: 5.00153078e-07
Iter: 910 loss: 5.04546961e-07
Iter: 911 loss: 5.00147792e-07
Iter: 912 loss: 4.99914279e-07
Iter: 913 loss: 4.9990706e-07
Iter: 914 loss: 4.99683551e-07
Iter: 915 loss: 4.99245857e-07
Iter: 916 loss: 5.08025323e-07
Iter: 917 loss: 4.99225678e-07
Iter: 918 loss: 4.98990119e-07
Iter: 919 loss: 4.98995462e-07
Iter: 920 loss: 4.98679924e-07
Iter: 921 loss: 4.98326358e-07
Iter: 922 loss: 4.9828725e-07
Iter: 923 loss: 4.98017812e-07
Iter: 924 loss: 4.98590907e-07
Iter: 925 loss: 4.97898327e-07
Iter: 926 loss: 4.97742349e-07
Iter: 927 loss: 5.00379713e-07
Iter: 928 loss: 4.97728195e-07
Iter: 929 loss: 4.974994e-07
Iter: 930 loss: 4.9727123e-07
Iter: 931 loss: 4.97230303e-07
Iter: 932 loss: 4.97046869e-07
Iter: 933 loss: 4.98145255e-07
Iter: 934 loss: 4.97027713e-07
Iter: 935 loss: 4.96850873e-07
Iter: 936 loss: 4.97522819e-07
Iter: 937 loss: 4.96798634e-07
Iter: 938 loss: 4.96594225e-07
Iter: 939 loss: 4.96285679e-07
Iter: 940 loss: 4.96279483e-07
Iter: 941 loss: 4.960566e-07
Iter: 942 loss: 4.97403e-07
Iter: 943 loss: 4.96001746e-07
Iter: 944 loss: 4.95803079e-07
Iter: 945 loss: 4.95837185e-07
Iter: 946 loss: 4.956662e-07
Iter: 947 loss: 4.95482368e-07
Iter: 948 loss: 4.95448035e-07
Iter: 949 loss: 4.95352197e-07
Iter: 950 loss: 4.95072186e-07
Iter: 951 loss: 4.96284e-07
Iter: 952 loss: 4.94954861e-07
Iter: 953 loss: 4.9460823e-07
Iter: 954 loss: 4.94596748e-07
Iter: 955 loss: 4.94420078e-07
Iter: 956 loss: 4.94193671e-07
Iter: 957 loss: 4.94160929e-07
Iter: 958 loss: 4.9393617e-07
Iter: 959 loss: 4.95278641e-07
Iter: 960 loss: 4.93901553e-07
Iter: 961 loss: 4.93662128e-07
Iter: 962 loss: 4.93915877e-07
Iter: 963 loss: 4.93512459e-07
Iter: 964 loss: 4.93352104e-07
Iter: 965 loss: 4.93580387e-07
Iter: 966 loss: 4.93273e-07
Iter: 967 loss: 4.93076527e-07
Iter: 968 loss: 4.95032282e-07
Iter: 969 loss: 4.93073401e-07
Iter: 970 loss: 4.92894912e-07
Iter: 971 loss: 4.94027518e-07
Iter: 972 loss: 4.92884055e-07
Iter: 973 loss: 4.92777247e-07
Iter: 974 loss: 4.92488425e-07
Iter: 975 loss: 4.9392338e-07
Iter: 976 loss: 4.9241828e-07
Iter: 977 loss: 4.92014465e-07
Iter: 978 loss: 4.94381652e-07
Iter: 979 loss: 4.9197638e-07
Iter: 980 loss: 4.91695346e-07
Iter: 981 loss: 4.92058575e-07
Iter: 982 loss: 4.91561423e-07
Iter: 983 loss: 4.9155193e-07
Iter: 984 loss: 4.91413743e-07
Iter: 985 loss: 4.9134735e-07
Iter: 986 loss: 4.91165565e-07
Iter: 987 loss: 4.92540494e-07
Iter: 988 loss: 4.91116452e-07
Iter: 989 loss: 4.91006119e-07
Iter: 990 loss: 4.9100106e-07
Iter: 991 loss: 4.90879074e-07
Iter: 992 loss: 4.9092489e-07
Iter: 993 loss: 4.90774255e-07
Iter: 994 loss: 4.90672846e-07
Iter: 995 loss: 4.90630327e-07
Iter: 996 loss: 4.90584853e-07
Iter: 997 loss: 4.90366858e-07
Iter: 998 loss: 4.91310857e-07
Iter: 999 loss: 4.90331e-07
Iter: 1000 loss: 4.90229809e-07
Iter: 1001 loss: 4.90599518e-07
Iter: 1002 loss: 4.90199284e-07
Iter: 1003 loss: 4.90126467e-07
Iter: 1004 loss: 4.89935246e-07
Iter: 1005 loss: 4.92680329e-07
Iter: 1006 loss: 4.89923195e-07
Iter: 1007 loss: 4.89684794e-07
Iter: 1008 loss: 4.89953834e-07
Iter: 1009 loss: 4.89559284e-07
Iter: 1010 loss: 4.89321565e-07
Iter: 1011 loss: 4.89741467e-07
Iter: 1012 loss: 4.89216632e-07
Iter: 1013 loss: 4.88835e-07
Iter: 1014 loss: 4.8947112e-07
Iter: 1015 loss: 4.88682304e-07
Iter: 1016 loss: 4.88259843e-07
Iter: 1017 loss: 4.88167302e-07
Iter: 1018 loss: 4.87918214e-07
Iter: 1019 loss: 4.87839e-07
Iter: 1020 loss: 4.87704597e-07
Iter: 1021 loss: 4.87583236e-07
Iter: 1022 loss: 4.89219e-07
Iter: 1023 loss: 4.87559475e-07
Iter: 1024 loss: 4.87513034e-07
Iter: 1025 loss: 4.87324087e-07
Iter: 1026 loss: 4.87943908e-07
Iter: 1027 loss: 4.87214493e-07
Iter: 1028 loss: 4.87261559e-07
Iter: 1029 loss: 4.871128e-07
Iter: 1030 loss: 4.87041063e-07
Iter: 1031 loss: 4.86791464e-07
Iter: 1032 loss: 4.87339946e-07
Iter: 1033 loss: 4.86605416e-07
Iter: 1034 loss: 4.86509862e-07
Iter: 1035 loss: 4.86405156e-07
Iter: 1036 loss: 4.86191311e-07
Iter: 1037 loss: 4.86386398e-07
Iter: 1038 loss: 4.86102522e-07
Iter: 1039 loss: 4.85901637e-07
Iter: 1040 loss: 4.85572059e-07
Iter: 1041 loss: 4.85584508e-07
Iter: 1042 loss: 4.85327689e-07
Iter: 1043 loss: 4.85277837e-07
Iter: 1044 loss: 4.85111855e-07
Iter: 1045 loss: 4.85042165e-07
Iter: 1046 loss: 4.84966108e-07
Iter: 1047 loss: 4.84745101e-07
Iter: 1048 loss: 4.84386192e-07
Iter: 1049 loss: 4.84385566e-07
Iter: 1050 loss: 4.83891e-07
Iter: 1051 loss: 4.86792828e-07
Iter: 1052 loss: 4.83822589e-07
Iter: 1053 loss: 4.83544056e-07
Iter: 1054 loss: 4.84683255e-07
Iter: 1055 loss: 4.83476185e-07
Iter: 1056 loss: 4.83120743e-07
Iter: 1057 loss: 4.85492933e-07
Iter: 1058 loss: 4.83090446e-07
Iter: 1059 loss: 4.82992846e-07
Iter: 1060 loss: 4.82880807e-07
Iter: 1061 loss: 4.8285068e-07
Iter: 1062 loss: 4.82666223e-07
Iter: 1063 loss: 4.85084172e-07
Iter: 1064 loss: 4.82668952e-07
Iter: 1065 loss: 4.82486e-07
Iter: 1066 loss: 4.82101711e-07
Iter: 1067 loss: 4.8630892e-07
Iter: 1068 loss: 4.82062319e-07
Iter: 1069 loss: 4.81915492e-07
Iter: 1070 loss: 4.81866323e-07
Iter: 1071 loss: 4.81645827e-07
Iter: 1072 loss: 4.81058e-07
Iter: 1073 loss: 4.87453121e-07
Iter: 1074 loss: 4.8101424e-07
Iter: 1075 loss: 4.80472465e-07
Iter: 1076 loss: 4.81133384e-07
Iter: 1077 loss: 4.80190693e-07
Iter: 1078 loss: 4.79913069e-07
Iter: 1079 loss: 4.79905452e-07
Iter: 1080 loss: 4.79723667e-07
Iter: 1081 loss: 4.81870188e-07
Iter: 1082 loss: 4.79721734e-07
Iter: 1083 loss: 4.79630046e-07
Iter: 1084 loss: 4.79572691e-07
Iter: 1085 loss: 4.79517553e-07
Iter: 1086 loss: 4.79374933e-07
Iter: 1087 loss: 4.79433481e-07
Iter: 1088 loss: 4.79311723e-07
Iter: 1089 loss: 4.79121582e-07
Iter: 1090 loss: 4.81131281e-07
Iter: 1091 loss: 4.79115215e-07
Iter: 1092 loss: 4.78910238e-07
Iter: 1093 loss: 4.78679e-07
Iter: 1094 loss: 4.78653817e-07
Iter: 1095 loss: 4.78440768e-07
Iter: 1096 loss: 4.79357e-07
Iter: 1097 loss: 4.78399841e-07
Iter: 1098 loss: 4.78014897e-07
Iter: 1099 loss: 4.77920594e-07
Iter: 1100 loss: 4.77686172e-07
Iter: 1101 loss: 4.77402693e-07
Iter: 1102 loss: 4.79345e-07
Iter: 1103 loss: 4.77387289e-07
Iter: 1104 loss: 4.77241542e-07
Iter: 1105 loss: 4.77242224e-07
Iter: 1106 loss: 4.7716361e-07
Iter: 1107 loss: 4.76980802e-07
Iter: 1108 loss: 4.77718231e-07
Iter: 1109 loss: 4.76895877e-07
Iter: 1110 loss: 4.76666798e-07
Iter: 1111 loss: 4.78199e-07
Iter: 1112 loss: 4.76622915e-07
Iter: 1113 loss: 4.76501612e-07
Iter: 1114 loss: 4.76496211e-07
Iter: 1115 loss: 4.76367518e-07
Iter: 1116 loss: 4.76225466e-07
Iter: 1117 loss: 4.76203553e-07
Iter: 1118 loss: 4.75999e-07
Iter: 1119 loss: 4.76590941e-07
Iter: 1120 loss: 4.75945626e-07
Iter: 1121 loss: 4.75769127e-07
Iter: 1122 loss: 4.76526736e-07
Iter: 1123 loss: 4.75741956e-07
Iter: 1124 loss: 4.7556253e-07
Iter: 1125 loss: 4.76134176e-07
Iter: 1126 loss: 4.75509097e-07
Iter: 1127 loss: 4.75381825e-07
Iter: 1128 loss: 4.7532248e-07
Iter: 1129 loss: 4.75246395e-07
Iter: 1130 loss: 4.75119577e-07
Iter: 1131 loss: 4.75127933e-07
Iter: 1132 loss: 4.74984347e-07
Iter: 1133 loss: 4.74596163e-07
Iter: 1134 loss: 4.75887873e-07
Iter: 1135 loss: 4.74411706e-07
Iter: 1136 loss: 4.7462666e-07
Iter: 1137 loss: 4.74256865e-07
Iter: 1138 loss: 4.74133145e-07
Iter: 1139 loss: 4.74011813e-07
Iter: 1140 loss: 4.74004565e-07
Iter: 1141 loss: 4.73822e-07
Iter: 1142 loss: 4.73730665e-07
Iter: 1143 loss: 4.73657337e-07
Iter: 1144 loss: 4.73644064e-07
Iter: 1145 loss: 4.73577188e-07
Iter: 1146 loss: 4.73521254e-07
Iter: 1147 loss: 4.73460943e-07
Iter: 1148 loss: 4.73449973e-07
Iter: 1149 loss: 4.73337593e-07
Iter: 1150 loss: 4.73504855e-07
Iter: 1151 loss: 4.73298087e-07
Iter: 1152 loss: 4.73166608e-07
Iter: 1153 loss: 4.73514575e-07
Iter: 1154 loss: 4.73119911e-07
Iter: 1155 loss: 4.72934e-07
Iter: 1156 loss: 4.73152284e-07
Iter: 1157 loss: 4.72830095e-07
Iter: 1158 loss: 4.72624464e-07
Iter: 1159 loss: 4.72447311e-07
Iter: 1160 loss: 4.72366651e-07
Iter: 1161 loss: 4.72174463e-07
Iter: 1162 loss: 4.72174435e-07
Iter: 1163 loss: 4.72017632e-07
Iter: 1164 loss: 4.71840167e-07
Iter: 1165 loss: 4.71820385e-07
Iter: 1166 loss: 4.71656023e-07
Iter: 1167 loss: 4.7239547e-07
Iter: 1168 loss: 4.71630671e-07
Iter: 1169 loss: 4.71429445e-07
Iter: 1170 loss: 4.7255611e-07
Iter: 1171 loss: 4.71401478e-07
Iter: 1172 loss: 4.71291116e-07
Iter: 1173 loss: 4.71041062e-07
Iter: 1174 loss: 4.74263743e-07
Iter: 1175 loss: 4.71024748e-07
Iter: 1176 loss: 4.70833328e-07
Iter: 1177 loss: 4.72132825e-07
Iter: 1178 loss: 4.70821504e-07
Iter: 1179 loss: 4.70601975e-07
Iter: 1180 loss: 4.71831981e-07
Iter: 1181 loss: 4.70569091e-07
Iter: 1182 loss: 4.70347942e-07
Iter: 1183 loss: 4.70048491e-07
Iter: 1184 loss: 4.70034138e-07
Iter: 1185 loss: 4.69788461e-07
Iter: 1186 loss: 4.72563e-07
Iter: 1187 loss: 4.69800398e-07
Iter: 1188 loss: 4.69605396e-07
Iter: 1189 loss: 4.71416058e-07
Iter: 1190 loss: 4.6961307e-07
Iter: 1191 loss: 4.6943191e-07
Iter: 1192 loss: 4.69118788e-07
Iter: 1193 loss: 4.76712103e-07
Iter: 1194 loss: 4.69112535e-07
Iter: 1195 loss: 4.68885275e-07
Iter: 1196 loss: 4.69290455e-07
Iter: 1197 loss: 4.68803194e-07
Iter: 1198 loss: 4.68493511e-07
Iter: 1199 loss: 4.72075016e-07
Iter: 1200 loss: 4.68486149e-07
Iter: 1201 loss: 4.68396706e-07
Iter: 1202 loss: 4.68271224e-07
Iter: 1203 loss: 4.68262783e-07
Iter: 1204 loss: 4.6814074e-07
Iter: 1205 loss: 4.68137216e-07
Iter: 1206 loss: 4.68021199e-07
Iter: 1207 loss: 4.67839357e-07
Iter: 1208 loss: 4.67845297e-07
Iter: 1209 loss: 4.67718934e-07
Iter: 1210 loss: 4.67701966e-07
Iter: 1211 loss: 4.67609567e-07
Iter: 1212 loss: 4.67425764e-07
Iter: 1213 loss: 4.68680923e-07
Iter: 1214 loss: 4.6743267e-07
Iter: 1215 loss: 4.67251709e-07
Iter: 1216 loss: 4.67121936e-07
Iter: 1217 loss: 4.67042526e-07
Iter: 1218 loss: 4.66856932e-07
Iter: 1219 loss: 4.67537063e-07
Iter: 1220 loss: 4.66802419e-07
Iter: 1221 loss: 4.66617223e-07
Iter: 1222 loss: 4.67624943e-07
Iter: 1223 loss: 4.66597669e-07
Iter: 1224 loss: 4.66382289e-07
Iter: 1225 loss: 4.67443442e-07
Iter: 1226 loss: 4.66346535e-07
Iter: 1227 loss: 4.66249077e-07
Iter: 1228 loss: 4.66060612e-07
Iter: 1229 loss: 4.66053052e-07
Iter: 1230 loss: 4.65968697e-07
Iter: 1231 loss: 4.65937092e-07
Iter: 1232 loss: 4.65843101e-07
Iter: 1233 loss: 4.65810558e-07
Iter: 1234 loss: 4.65758603e-07
Iter: 1235 loss: 4.65689794e-07
Iter: 1236 loss: 4.66082213e-07
Iter: 1237 loss: 4.65675555e-07
Iter: 1238 loss: 4.65553796e-07
Iter: 1239 loss: 4.65335859e-07
Iter: 1240 loss: 4.69834049e-07
Iter: 1241 loss: 4.65311132e-07
Iter: 1242 loss: 4.65105984e-07
Iter: 1243 loss: 4.6609e-07
Iter: 1244 loss: 4.65070229e-07
Iter: 1245 loss: 4.64873324e-07
Iter: 1246 loss: 4.66392123e-07
Iter: 1247 loss: 4.64870595e-07
Iter: 1248 loss: 4.64687247e-07
Iter: 1249 loss: 4.64751963e-07
Iter: 1250 loss: 4.64563755e-07
Iter: 1251 loss: 4.6443094e-07
Iter: 1252 loss: 4.64350762e-07
Iter: 1253 loss: 4.64263707e-07
Iter: 1254 loss: 4.6398236e-07
Iter: 1255 loss: 4.64861046e-07
Iter: 1256 loss: 4.63914944e-07
Iter: 1257 loss: 4.63773659e-07
Iter: 1258 loss: 4.6375402e-07
Iter: 1259 loss: 4.6366921e-07
Iter: 1260 loss: 4.63506979e-07
Iter: 1261 loss: 4.65567751e-07
Iter: 1262 loss: 4.63492256e-07
Iter: 1263 loss: 4.63276706e-07
Iter: 1264 loss: 4.64204788e-07
Iter: 1265 loss: 4.63239218e-07
Iter: 1266 loss: 4.62975493e-07
Iter: 1267 loss: 4.63951864e-07
Iter: 1268 loss: 4.62914954e-07
Iter: 1269 loss: 4.62793054e-07
Iter: 1270 loss: 4.62651542e-07
Iter: 1271 loss: 4.62638269e-07
Iter: 1272 loss: 4.62363289e-07
Iter: 1273 loss: 4.64745767e-07
Iter: 1274 loss: 4.62350386e-07
Iter: 1275 loss: 4.62229309e-07
Iter: 1276 loss: 4.62078162e-07
Iter: 1277 loss: 4.62070915e-07
Iter: 1278 loss: 4.61915789e-07
Iter: 1279 loss: 4.63526e-07
Iter: 1280 loss: 4.61923463e-07
Iter: 1281 loss: 4.61749494e-07
Iter: 1282 loss: 4.61959104e-07
Iter: 1283 loss: 4.61659454e-07
Iter: 1284 loss: 4.61542754e-07
Iter: 1285 loss: 4.6146485e-07
Iter: 1286 loss: 4.6141e-07
Iter: 1287 loss: 4.61157555e-07
Iter: 1288 loss: 4.61051911e-07
Iter: 1289 loss: 4.60918585e-07
Iter: 1290 loss: 4.60793927e-07
Iter: 1291 loss: 4.60712045e-07
Iter: 1292 loss: 4.60583465e-07
Iter: 1293 loss: 4.60564024e-07
Iter: 1294 loss: 4.60458068e-07
Iter: 1295 loss: 4.60318603e-07
Iter: 1296 loss: 4.60096885e-07
Iter: 1297 loss: 4.60099955e-07
Iter: 1298 loss: 4.60166547e-07
Iter: 1299 loss: 4.59979447e-07
Iter: 1300 loss: 4.59927e-07
Iter: 1301 loss: 4.59780154e-07
Iter: 1302 loss: 4.60519885e-07
Iter: 1303 loss: 4.59708303e-07
Iter: 1304 loss: 4.59553718e-07
Iter: 1305 loss: 4.61612103e-07
Iter: 1306 loss: 4.59539876e-07
Iter: 1307 loss: 4.59416299e-07
Iter: 1308 loss: 4.60781337e-07
Iter: 1309 loss: 4.59399e-07
Iter: 1310 loss: 4.59348314e-07
Iter: 1311 loss: 4.59120884e-07
Iter: 1312 loss: 4.59208252e-07
Iter: 1313 loss: 4.58899706e-07
Iter: 1314 loss: 4.59349394e-07
Iter: 1315 loss: 4.58802305e-07
Iter: 1316 loss: 4.58729517e-07
Iter: 1317 loss: 4.58834194e-07
Iter: 1318 loss: 4.58668808e-07
Iter: 1319 loss: 4.58552677e-07
Iter: 1320 loss: 4.58373393e-07
Iter: 1321 loss: 4.58370749e-07
Iter: 1322 loss: 4.58165744e-07
Iter: 1323 loss: 4.59936359e-07
Iter: 1324 loss: 4.58169779e-07
Iter: 1325 loss: 4.58036027e-07
Iter: 1326 loss: 4.58625834e-07
Iter: 1327 loss: 4.58001693e-07
Iter: 1328 loss: 4.57887154e-07
Iter: 1329 loss: 4.57758858e-07
Iter: 1330 loss: 4.57731261e-07
Iter: 1331 loss: 4.57600464e-07
Iter: 1332 loss: 4.58643e-07
Iter: 1333 loss: 4.57603e-07
Iter: 1334 loss: 4.57433e-07
Iter: 1335 loss: 4.58619354e-07
Iter: 1336 loss: 4.57433458e-07
Iter: 1337 loss: 4.57289474e-07
Iter: 1338 loss: 4.57052522e-07
Iter: 1339 loss: 4.57054853e-07
Iter: 1340 loss: 4.56886767e-07
Iter: 1341 loss: 4.57824399e-07
Iter: 1342 loss: 4.56851495e-07
Iter: 1343 loss: 4.56706488e-07
Iter: 1344 loss: 4.56719278e-07
Iter: 1345 loss: 4.56602947e-07
Iter: 1346 loss: 4.56518677e-07
Iter: 1347 loss: 4.5646712e-07
Iter: 1348 loss: 4.56415364e-07
Iter: 1349 loss: 4.56290365e-07
Iter: 1350 loss: 4.58381237e-07
Iter: 1351 loss: 4.56285107e-07
Iter: 1352 loss: 4.56157409e-07
Iter: 1353 loss: 4.5593282e-07
Iter: 1354 loss: 4.61655759e-07
Iter: 1355 loss: 4.55931314e-07
Iter: 1356 loss: 4.55785624e-07
Iter: 1357 loss: 4.55764763e-07
Iter: 1358 loss: 4.55547593e-07
Iter: 1359 loss: 4.56091328e-07
Iter: 1360 loss: 4.55494899e-07
Iter: 1361 loss: 4.55375016e-07
Iter: 1362 loss: 4.55235124e-07
Iter: 1363 loss: 4.55234243e-07
Iter: 1364 loss: 4.55198574e-07
Iter: 1365 loss: 4.55145369e-07
Iter: 1366 loss: 4.55065958e-07
Iter: 1367 loss: 4.54925612e-07
Iter: 1368 loss: 4.57844294e-07
Iter: 1369 loss: 4.54923168e-07
Iter: 1370 loss: 4.54786459e-07
Iter: 1371 loss: 4.55602418e-07
Iter: 1372 loss: 4.54765484e-07
Iter: 1373 loss: 4.54605328e-07
Iter: 1374 loss: 4.55424e-07
Iter: 1375 loss: 4.54580913e-07
Iter: 1376 loss: 4.54476464e-07
Iter: 1377 loss: 4.54233117e-07
Iter: 1378 loss: 4.56147262e-07
Iter: 1379 loss: 4.54191252e-07
Iter: 1380 loss: 4.53888561e-07
Iter: 1381 loss: 4.56940427e-07
Iter: 1382 loss: 4.53884809e-07
Iter: 1383 loss: 4.53671078e-07
Iter: 1384 loss: 4.54035415e-07
Iter: 1385 loss: 4.53573051e-07
Iter: 1386 loss: 4.5344126e-07
Iter: 1387 loss: 4.54685846e-07
Iter: 1388 loss: 4.53433955e-07
Iter: 1389 loss: 4.53349088e-07
Iter: 1390 loss: 4.54624711e-07
Iter: 1391 loss: 4.53350196e-07
Iter: 1392 loss: 4.53256e-07
Iter: 1393 loss: 4.53066036e-07
Iter: 1394 loss: 4.5505962e-07
Iter: 1395 loss: 4.5303895e-07
Iter: 1396 loss: 4.53006209e-07
Iter: 1397 loss: 4.52961928e-07
Iter: 1398 loss: 4.52902e-07
Iter: 1399 loss: 4.52780682e-07
Iter: 1400 loss: 4.52772724e-07
Iter: 1401 loss: 4.52675181e-07
Iter: 1402 loss: 4.5301465e-07
Iter: 1403 loss: 4.52659918e-07
Iter: 1404 loss: 4.52515252e-07
Iter: 1405 loss: 4.53246457e-07
Iter: 1406 loss: 4.52513e-07
Iter: 1407 loss: 4.52399519e-07
Iter: 1408 loss: 4.52293051e-07
Iter: 1409 loss: 4.55565839e-07
Iter: 1410 loss: 4.52306438e-07
Iter: 1411 loss: 4.52253857e-07
Iter: 1412 loss: 4.52232598e-07
Iter: 1413 loss: 4.52174618e-07
Iter: 1414 loss: 4.52086e-07
Iter: 1415 loss: 4.52067411e-07
Iter: 1416 loss: 4.51946619e-07
Iter: 1417 loss: 4.51805e-07
Iter: 1418 loss: 4.51790584e-07
Iter: 1419 loss: 4.51649413e-07
Iter: 1420 loss: 4.52183826e-07
Iter: 1421 loss: 4.51594047e-07
Iter: 1422 loss: 4.51515405e-07
Iter: 1423 loss: 4.51365139e-07
Iter: 1424 loss: 4.54411918e-07
Iter: 1425 loss: 4.51368436e-07
Iter: 1426 loss: 4.51320204e-07
Iter: 1427 loss: 4.51281949e-07
Iter: 1428 loss: 4.51206688e-07
Iter: 1429 loss: 4.51430424e-07
Iter: 1430 loss: 4.51180796e-07
Iter: 1431 loss: 4.51097e-07
Iter: 1432 loss: 4.51143137e-07
Iter: 1433 loss: 4.51043405e-07
Iter: 1434 loss: 4.5092105e-07
Iter: 1435 loss: 4.50954985e-07
Iter: 1436 loss: 4.50803128e-07
Iter: 1437 loss: 4.50748701e-07
Iter: 1438 loss: 4.5073341e-07
Iter: 1439 loss: 4.5064769e-07
Iter: 1440 loss: 4.5048256e-07
Iter: 1441 loss: 4.53978942e-07
Iter: 1442 loss: 4.50495577e-07
Iter: 1443 loss: 4.50338177e-07
Iter: 1444 loss: 4.50869607e-07
Iter: 1445 loss: 4.50291424e-07
Iter: 1446 loss: 4.50277355e-07
Iter: 1447 loss: 4.50243732e-07
Iter: 1448 loss: 4.50220597e-07
Iter: 1449 loss: 4.50119956e-07
Iter: 1450 loss: 4.50519082e-07
Iter: 1451 loss: 4.50079e-07
Iter: 1452 loss: 4.49959089e-07
Iter: 1453 loss: 4.50800115e-07
Iter: 1454 loss: 4.49947635e-07
Iter: 1455 loss: 4.4987911e-07
Iter: 1456 loss: 4.49888944e-07
Iter: 1457 loss: 4.49833493e-07
Iter: 1458 loss: 4.4975107e-07
Iter: 1459 loss: 4.51665301e-07
Iter: 1460 loss: 4.49755e-07
Iter: 1461 loss: 4.49624565e-07
Iter: 1462 loss: 4.50490234e-07
Iter: 1463 loss: 4.49614191e-07
Iter: 1464 loss: 4.49533246e-07
Iter: 1465 loss: 4.4994357e-07
Iter: 1466 loss: 4.49519405e-07
Iter: 1467 loss: 4.49417286e-07
Iter: 1468 loss: 4.49337222e-07
Iter: 1469 loss: 4.49308544e-07
Iter: 1470 loss: 4.4918761e-07
Iter: 1471 loss: 4.49409413e-07
Iter: 1472 loss: 4.49128862e-07
Iter: 1473 loss: 4.49001391e-07
Iter: 1474 loss: 4.50765469e-07
Iter: 1475 loss: 4.49006052e-07
Iter: 1476 loss: 4.48942785e-07
Iter: 1477 loss: 4.48731669e-07
Iter: 1478 loss: 4.49733875e-07
Iter: 1479 loss: 4.48674371e-07
Iter: 1480 loss: 4.48499861e-07
Iter: 1481 loss: 4.49003039e-07
Iter: 1482 loss: 4.48452226e-07
Iter: 1483 loss: 4.48371424e-07
Iter: 1484 loss: 4.48331747e-07
Iter: 1485 loss: 4.48258305e-07
Iter: 1486 loss: 4.48259698e-07
Iter: 1487 loss: 4.4817196e-07
Iter: 1488 loss: 4.48080812e-07
Iter: 1489 loss: 4.47872594e-07
Iter: 1490 loss: 4.50640016e-07
Iter: 1491 loss: 4.47848151e-07
Iter: 1492 loss: 4.4767026e-07
Iter: 1493 loss: 4.47650734e-07
Iter: 1494 loss: 4.47521586e-07
Iter: 1495 loss: 4.48886965e-07
Iter: 1496 loss: 4.47500724e-07
Iter: 1497 loss: 4.47366745e-07
Iter: 1498 loss: 4.47162137e-07
Iter: 1499 loss: 4.471637e-07
Iter: 1500 loss: 4.47069056e-07
Iter: 1501 loss: 4.47040861e-07
Iter: 1502 loss: 4.46983393e-07
Iter: 1503 loss: 4.46989105e-07
Iter: 1504 loss: 4.46935815e-07
Iter: 1505 loss: 4.46880847e-07
Iter: 1506 loss: 4.46906597e-07
Iter: 1507 loss: 4.46831365e-07
Iter: 1508 loss: 4.46701222e-07
Iter: 1509 loss: 4.46755109e-07
Iter: 1510 loss: 4.46618571e-07
Iter: 1511 loss: 4.46525434e-07
Iter: 1512 loss: 4.46336372e-07
Iter: 1513 loss: 4.49520684e-07
Iter: 1514 loss: 4.46342682e-07
Iter: 1515 loss: 4.46208162e-07
Iter: 1516 loss: 4.47894536e-07
Iter: 1517 loss: 4.46198555e-07
Iter: 1518 loss: 4.4608e-07
Iter: 1519 loss: 4.47313e-07
Iter: 1520 loss: 4.46087569e-07
Iter: 1521 loss: 4.46008244e-07
Iter: 1522 loss: 4.45862071e-07
Iter: 1523 loss: 4.45851754e-07
Iter: 1524 loss: 4.45699527e-07
Iter: 1525 loss: 4.46101808e-07
Iter: 1526 loss: 4.45648652e-07
Iter: 1527 loss: 4.45564126e-07
Iter: 1528 loss: 4.4712209e-07
Iter: 1529 loss: 4.45567252e-07
Iter: 1530 loss: 4.45418e-07
Iter: 1531 loss: 4.45255466e-07
Iter: 1532 loss: 4.45230484e-07
Iter: 1533 loss: 4.45139e-07
Iter: 1534 loss: 4.45134276e-07
Iter: 1535 loss: 4.4506794e-07
Iter: 1536 loss: 4.45099033e-07
Iter: 1537 loss: 4.45011437e-07
Iter: 1538 loss: 4.4492225e-07
Iter: 1539 loss: 4.44837497e-07
Iter: 1540 loss: 4.4480737e-07
Iter: 1541 loss: 4.44760019e-07
Iter: 1542 loss: 4.44729807e-07
Iter: 1543 loss: 4.44672082e-07
Iter: 1544 loss: 4.44589233e-07
Iter: 1545 loss: 4.46962503e-07
Iter: 1546 loss: 4.44594491e-07
Iter: 1547 loss: 4.44446471e-07
Iter: 1548 loss: 4.44312377e-07
Iter: 1549 loss: 4.44295324e-07
Iter: 1550 loss: 4.44226629e-07
Iter: 1551 loss: 4.4421185e-07
Iter: 1552 loss: 4.44095377e-07
Iter: 1553 loss: 4.43893725e-07
Iter: 1554 loss: 4.48269816e-07
Iter: 1555 loss: 4.43883209e-07
Iter: 1556 loss: 4.43719443e-07
Iter: 1557 loss: 4.44310103e-07
Iter: 1558 loss: 4.43648503e-07
Iter: 1559 loss: 4.43499175e-07
Iter: 1560 loss: 4.4335502e-07
Iter: 1561 loss: 4.43313411e-07
Iter: 1562 loss: 4.43166613e-07
Iter: 1563 loss: 4.43108206e-07
Iter: 1564 loss: 4.43058127e-07
Iter: 1565 loss: 4.43078619e-07
Iter: 1566 loss: 4.43005092e-07
Iter: 1567 loss: 4.42899506e-07
Iter: 1568 loss: 4.43329384e-07
Iter: 1569 loss: 4.42877649e-07
Iter: 1570 loss: 4.42808698e-07
Iter: 1571 loss: 4.42728322e-07
Iter: 1572 loss: 4.42716328e-07
Iter: 1573 loss: 4.42635752e-07
Iter: 1574 loss: 4.43673628e-07
Iter: 1575 loss: 4.42643369e-07
Iter: 1576 loss: 4.42571206e-07
Iter: 1577 loss: 4.42602698e-07
Iter: 1578 loss: 4.42531473e-07
Iter: 1579 loss: 4.42429865e-07
Iter: 1580 loss: 4.42231169e-07
Iter: 1581 loss: 4.42231851e-07
Iter: 1582 loss: 4.42053874e-07
Iter: 1583 loss: 4.42674434e-07
Iter: 1584 loss: 4.42015363e-07
Iter: 1585 loss: 4.41814336e-07
Iter: 1586 loss: 4.43692898e-07
Iter: 1587 loss: 4.41818713e-07
Iter: 1588 loss: 4.41589862e-07
Iter: 1589 loss: 4.41369366e-07
Iter: 1590 loss: 4.41336539e-07
Iter: 1591 loss: 4.4116274e-07
Iter: 1592 loss: 4.41019154e-07
Iter: 1593 loss: 4.40944632e-07
Iter: 1594 loss: 4.40814034e-07
Iter: 1595 loss: 4.40792405e-07
Iter: 1596 loss: 4.40645607e-07
Iter: 1597 loss: 4.41171835e-07
Iter: 1598 loss: 4.40614116e-07
Iter: 1599 loss: 4.40499662e-07
Iter: 1600 loss: 4.40398338e-07
Iter: 1601 loss: 4.4036517e-07
Iter: 1602 loss: 4.40229599e-07
Iter: 1603 loss: 4.40221072e-07
Iter: 1604 loss: 4.4017213e-07
Iter: 1605 loss: 4.40070579e-07
Iter: 1606 loss: 4.41965312e-07
Iter: 1607 loss: 4.40073222e-07
Iter: 1608 loss: 4.39929551e-07
Iter: 1609 loss: 4.40887703e-07
Iter: 1610 loss: 4.39925287e-07
Iter: 1611 loss: 4.39766154e-07
Iter: 1612 loss: 4.40104316e-07
Iter: 1613 loss: 4.39715308e-07
Iter: 1614 loss: 4.39642349e-07
Iter: 1615 loss: 4.39512604e-07
Iter: 1616 loss: 4.42641806e-07
Iter: 1617 loss: 4.3950098e-07
Iter: 1618 loss: 4.39320701e-07
Iter: 1619 loss: 4.39992249e-07
Iter: 1620 loss: 4.39277358e-07
Iter: 1621 loss: 4.39159521e-07
Iter: 1622 loss: 4.39146675e-07
Iter: 1623 loss: 4.39091821e-07
Iter: 1624 loss: 4.38961763e-07
Iter: 1625 loss: 4.41163166e-07
Iter: 1626 loss: 4.38945847e-07
Iter: 1627 loss: 4.38774236e-07
Iter: 1628 loss: 4.39132748e-07
Iter: 1629 loss: 4.38717677e-07
Iter: 1630 loss: 4.38683116e-07
Iter: 1631 loss: 4.38642303e-07
Iter: 1632 loss: 4.38568208e-07
Iter: 1633 loss: 4.38396285e-07
Iter: 1634 loss: 4.38956135e-07
Iter: 1635 loss: 4.38323639e-07
Iter: 1636 loss: 4.38315681e-07
Iter: 1637 loss: 4.38211089e-07
Iter: 1638 loss: 4.38135316e-07
Iter: 1639 loss: 4.38055679e-07
Iter: 1640 loss: 4.38009323e-07
Iter: 1641 loss: 4.37880203e-07
Iter: 1642 loss: 4.37651693e-07
Iter: 1643 loss: 4.37642598e-07
Iter: 1644 loss: 4.37886143e-07
Iter: 1645 loss: 4.37553894e-07
Iter: 1646 loss: 4.37477809e-07
Iter: 1647 loss: 4.37436427e-07
Iter: 1648 loss: 4.37417242e-07
Iter: 1649 loss: 4.37309211e-07
Iter: 1650 loss: 4.37091e-07
Iter: 1651 loss: 4.4183804e-07
Iter: 1652 loss: 4.37095053e-07
Iter: 1653 loss: 4.3698239e-07
Iter: 1654 loss: 4.36992764e-07
Iter: 1655 loss: 4.36863388e-07
Iter: 1656 loss: 4.37043099e-07
Iter: 1657 loss: 4.36801969e-07
Iter: 1658 loss: 4.3668058e-07
Iter: 1659 loss: 4.36731455e-07
Iter: 1660 loss: 4.36595968e-07
Iter: 1661 loss: 4.36487568e-07
Iter: 1662 loss: 4.36850257e-07
Iter: 1663 loss: 4.36463495e-07
Iter: 1664 loss: 4.36335057e-07
Iter: 1665 loss: 4.36747598e-07
Iter: 1666 loss: 4.36278356e-07
Iter: 1667 loss: 4.36147729e-07
Iter: 1668 loss: 4.36103278e-07
Iter: 1669 loss: 4.36027534e-07
Iter: 1670 loss: 4.35949516e-07
Iter: 1671 loss: 4.35953382e-07
Iter: 1672 loss: 4.35862376e-07
Iter: 1673 loss: 4.35631677e-07
Iter: 1674 loss: 4.36436352e-07
Iter: 1675 loss: 4.35517109e-07
Iter: 1676 loss: 4.35411948e-07
Iter: 1677 loss: 4.35386937e-07
Iter: 1678 loss: 4.35298034e-07
Iter: 1679 loss: 4.36296659e-07
Iter: 1680 loss: 4.35288797e-07
Iter: 1681 loss: 4.35218453e-07
Iter: 1682 loss: 4.35089134e-07
Iter: 1683 loss: 4.3727519e-07
Iter: 1684 loss: 4.35076572e-07
Iter: 1685 loss: 4.34972492e-07
Iter: 1686 loss: 4.35282402e-07
Iter: 1687 loss: 4.34908685e-07
Iter: 1688 loss: 4.34811341e-07
Iter: 1689 loss: 4.34818674e-07
Iter: 1690 loss: 4.34759556e-07
Iter: 1691 loss: 4.34697654e-07
Iter: 1692 loss: 4.34670255e-07
Iter: 1693 loss: 4.34615458e-07
Iter: 1694 loss: 4.34462038e-07
Iter: 1695 loss: 4.37608207e-07
Iter: 1696 loss: 4.34463686e-07
Iter: 1697 loss: 4.34366285e-07
Iter: 1698 loss: 4.34342496e-07
Iter: 1699 loss: 4.34261466e-07
Iter: 1700 loss: 4.34203031e-07
Iter: 1701 loss: 4.34178332e-07
Iter: 1702 loss: 4.34058563e-07
Iter: 1703 loss: 4.3456788e-07
Iter: 1704 loss: 4.34054897e-07
Iter: 1705 loss: 4.33913954e-07
Iter: 1706 loss: 4.33838977e-07
Iter: 1707 loss: 4.33779519e-07
Iter: 1708 loss: 4.33632408e-07
Iter: 1709 loss: 4.34251746e-07
Iter: 1710 loss: 4.33594039e-07
Iter: 1711 loss: 4.33529635e-07
Iter: 1712 loss: 4.33519943e-07
Iter: 1713 loss: 4.33434479e-07
Iter: 1714 loss: 4.33361322e-07
Iter: 1715 loss: 4.33332275e-07
Iter: 1716 loss: 4.33284839e-07
Iter: 1717 loss: 4.33203297e-07
Iter: 1718 loss: 4.33204463e-07
Iter: 1719 loss: 4.33142873e-07
Iter: 1720 loss: 4.33126047e-07
Iter: 1721 loss: 4.33075854e-07
Iter: 1722 loss: 4.33051724e-07
Iter: 1723 loss: 4.33028191e-07
Iter: 1724 loss: 4.32972115e-07
Iter: 1725 loss: 4.32874e-07
Iter: 1726 loss: 4.32886736e-07
Iter: 1727 loss: 4.32850555e-07
Iter: 1728 loss: 4.32822446e-07
Iter: 1729 loss: 4.32784731e-07
Iter: 1730 loss: 4.32736442e-07
Iter: 1731 loss: 4.32721663e-07
Iter: 1732 loss: 4.32623153e-07
Iter: 1733 loss: 4.32887106e-07
Iter: 1734 loss: 4.32589786e-07
Iter: 1735 loss: 4.3251e-07
Iter: 1736 loss: 4.32821935e-07
Iter: 1737 loss: 4.32482068e-07
Iter: 1738 loss: 4.3242153e-07
Iter: 1739 loss: 4.32421643e-07
Iter: 1740 loss: 4.3237452e-07
Iter: 1741 loss: 4.32277375e-07
Iter: 1742 loss: 4.32308866e-07
Iter: 1743 loss: 4.32228745e-07
Iter: 1744 loss: 4.32090928e-07
Iter: 1745 loss: 4.32536751e-07
Iter: 1746 loss: 4.32065349e-07
Iter: 1747 loss: 4.3198088e-07
Iter: 1748 loss: 4.31959762e-07
Iter: 1749 loss: 4.31913918e-07
Iter: 1750 loss: 4.3183087e-07
Iter: 1751 loss: 4.33062752e-07
Iter: 1752 loss: 4.31843262e-07
Iter: 1753 loss: 4.31752937e-07
Iter: 1754 loss: 4.32130946e-07
Iter: 1755 loss: 4.31745548e-07
Iter: 1756 loss: 4.31701835e-07
Iter: 1757 loss: 4.31585534e-07
Iter: 1758 loss: 4.32478544e-07
Iter: 1759 loss: 4.31558135e-07
Iter: 1760 loss: 4.3151536e-07
Iter: 1761 loss: 4.31506322e-07
Iter: 1762 loss: 4.31430095e-07
Iter: 1763 loss: 4.31523915e-07
Iter: 1764 loss: 4.31402185e-07
Iter: 1765 loss: 4.31319592e-07
Iter: 1766 loss: 4.31307029e-07
Iter: 1767 loss: 4.31263516e-07
Iter: 1768 loss: 4.31156195e-07
Iter: 1769 loss: 4.31601791e-07
Iter: 1770 loss: 4.31133429e-07
Iter: 1771 loss: 4.31066184e-07
Iter: 1772 loss: 4.31467527e-07
Iter: 1773 loss: 4.31065246e-07
Iter: 1774 loss: 4.30991378e-07
Iter: 1775 loss: 4.30963638e-07
Iter: 1776 loss: 4.30936211e-07
Iter: 1777 loss: 4.30859558e-07
Iter: 1778 loss: 4.31396188e-07
Iter: 1779 loss: 4.30853333e-07
Iter: 1780 loss: 4.30790806e-07
Iter: 1781 loss: 4.30699572e-07
Iter: 1782 loss: 4.30716455e-07
Iter: 1783 loss: 4.30568e-07
Iter: 1784 loss: 4.30993509e-07
Iter: 1785 loss: 4.30555758e-07
Iter: 1786 loss: 4.30542258e-07
Iter: 1787 loss: 4.30490957e-07
Iter: 1788 loss: 4.30472056e-07
Iter: 1789 loss: 4.30371074e-07
Iter: 1790 loss: 4.307106e-07
Iter: 1791 loss: 4.30329067e-07
Iter: 1792 loss: 4.30306955e-07
Iter: 1793 loss: 4.30271484e-07
Iter: 1794 loss: 4.30210378e-07
Iter: 1795 loss: 4.3036016e-07
Iter: 1796 loss: 4.30167319e-07
Iter: 1797 loss: 4.30109623e-07
Iter: 1798 loss: 4.30132388e-07
Iter: 1799 loss: 4.30083389e-07
Iter: 1800 loss: 4.30000426e-07
Iter: 1801 loss: 4.30351491e-07
Iter: 1802 loss: 4.29975699e-07
Iter: 1803 loss: 4.29900751e-07
Iter: 1804 loss: 4.30183263e-07
Iter: 1805 loss: 4.29900325e-07
Iter: 1806 loss: 4.29830152e-07
Iter: 1807 loss: 4.29716579e-07
Iter: 1808 loss: 4.29711292e-07
Iter: 1809 loss: 4.29579472e-07
Iter: 1810 loss: 4.30737686e-07
Iter: 1811 loss: 4.29572026e-07
Iter: 1812 loss: 4.29475108e-07
Iter: 1813 loss: 4.29523823e-07
Iter: 1814 loss: 4.29422641e-07
Iter: 1815 loss: 4.29320664e-07
Iter: 1816 loss: 4.2927303e-07
Iter: 1817 loss: 4.29231164e-07
Iter: 1818 loss: 4.29278458e-07
Iter: 1819 loss: 4.29184411e-07
Iter: 1820 loss: 4.29136179e-07
Iter: 1821 loss: 4.29059e-07
Iter: 1822 loss: 4.29788315e-07
Iter: 1823 loss: 4.29036561e-07
Iter: 1824 loss: 4.28919492e-07
Iter: 1825 loss: 4.29473147e-07
Iter: 1826 loss: 4.28898517e-07
Iter: 1827 loss: 4.28812314e-07
Iter: 1828 loss: 4.3015973e-07
Iter: 1829 loss: 4.28802622e-07
Iter: 1830 loss: 4.28755584e-07
Iter: 1831 loss: 4.28607393e-07
Iter: 1832 loss: 4.30832813e-07
Iter: 1833 loss: 4.28601425e-07
Iter: 1834 loss: 4.28456843e-07
Iter: 1835 loss: 4.30689312e-07
Iter: 1836 loss: 4.28453632e-07
Iter: 1837 loss: 4.28369503e-07
Iter: 1838 loss: 4.28586418e-07
Iter: 1839 loss: 4.28358788e-07
Iter: 1840 loss: 4.28291116e-07
Iter: 1841 loss: 4.28358589e-07
Iter: 1842 loss: 4.28282135e-07
Iter: 1843 loss: 4.2818408e-07
Iter: 1844 loss: 4.28292424e-07
Iter: 1845 loss: 4.28148752e-07
Iter: 1846 loss: 4.28086111e-07
Iter: 1847 loss: 4.28319538e-07
Iter: 1848 loss: 4.28068518e-07
Iter: 1849 loss: 4.27989619e-07
Iter: 1850 loss: 4.27834436e-07
Iter: 1851 loss: 4.3064091e-07
Iter: 1852 loss: 4.27839666e-07
Iter: 1853 loss: 4.2780519e-07
Iter: 1854 loss: 4.27756106e-07
Iter: 1855 loss: 4.27679083e-07
Iter: 1856 loss: 4.27618232e-07
Iter: 1857 loss: 4.27586116e-07
Iter: 1858 loss: 4.27452e-07
Iter: 1859 loss: 4.27205237e-07
Iter: 1860 loss: 4.27206089e-07
Iter: 1861 loss: 4.27393388e-07
Iter: 1862 loss: 4.27123837e-07
Iter: 1863 loss: 4.27055198e-07
Iter: 1864 loss: 4.26943927e-07
Iter: 1865 loss: 4.29383647e-07
Iter: 1866 loss: 4.26942648e-07
Iter: 1867 loss: 4.26808811e-07
Iter: 1868 loss: 4.28164981e-07
Iter: 1869 loss: 4.26803581e-07
Iter: 1870 loss: 4.26672329e-07
Iter: 1871 loss: 4.27319065e-07
Iter: 1872 loss: 4.26652889e-07
Iter: 1873 loss: 4.2656e-07
Iter: 1874 loss: 4.26730594e-07
Iter: 1875 loss: 4.26516976e-07
Iter: 1876 loss: 4.26410793e-07
Iter: 1877 loss: 4.26511235e-07
Iter: 1878 loss: 4.26355797e-07
Iter: 1879 loss: 4.26193651e-07
Iter: 1880 loss: 4.2604205e-07
Iter: 1881 loss: 4.26004846e-07
Iter: 1882 loss: 4.25764227e-07
Iter: 1883 loss: 4.26400106e-07
Iter: 1884 loss: 4.25676603e-07
Iter: 1885 loss: 4.25495699e-07
Iter: 1886 loss: 4.26010615e-07
Iter: 1887 loss: 4.25407478e-07
Iter: 1888 loss: 4.25322355e-07
Iter: 1889 loss: 4.25296605e-07
Iter: 1890 loss: 4.25249084e-07
Iter: 1891 loss: 4.25098165e-07
Iter: 1892 loss: 4.26116287e-07
Iter: 1893 loss: 4.25069175e-07
Iter: 1894 loss: 4.24891198e-07
Iter: 1895 loss: 4.2560572e-07
Iter: 1896 loss: 4.24834809e-07
Iter: 1897 loss: 4.24632105e-07
Iter: 1898 loss: 4.2650862e-07
Iter: 1899 loss: 4.24620907e-07
Iter: 1900 loss: 4.24524728e-07
Iter: 1901 loss: 4.24409336e-07
Iter: 1902 loss: 4.24372985e-07
Iter: 1903 loss: 4.24208537e-07
Iter: 1904 loss: 4.25936264e-07
Iter: 1905 loss: 4.24191626e-07
Iter: 1906 loss: 4.24111761e-07
Iter: 1907 loss: 4.24372246e-07
Iter: 1908 loss: 4.24070834e-07
Iter: 1909 loss: 4.23968913e-07
Iter: 1910 loss: 4.24282717e-07
Iter: 1911 loss: 4.23965588e-07
Iter: 1912 loss: 4.23888224e-07
Iter: 1913 loss: 4.23867192e-07
Iter: 1914 loss: 4.23815749e-07
Iter: 1915 loss: 4.2369436e-07
Iter: 1916 loss: 4.23850679e-07
Iter: 1917 loss: 4.23642689e-07
Iter: 1918 loss: 4.23505981e-07
Iter: 1919 loss: 4.23432823e-07
Iter: 1920 loss: 4.23393743e-07
Iter: 1921 loss: 4.2319715e-07
Iter: 1922 loss: 4.23209372e-07
Iter: 1923 loss: 4.22988535e-07
Iter: 1924 loss: 4.23028382e-07
Iter: 1925 loss: 4.22867e-07
Iter: 1926 loss: 4.22756131e-07
Iter: 1927 loss: 4.22643893e-07
Iter: 1928 loss: 4.22632127e-07
Iter: 1929 loss: 4.2256093e-07
Iter: 1930 loss: 4.2251736e-07
Iter: 1931 loss: 4.22430304e-07
Iter: 1932 loss: 4.22411233e-07
Iter: 1933 loss: 4.22380907e-07
Iter: 1934 loss: 4.2230846e-07
Iter: 1935 loss: 4.22815958e-07
Iter: 1936 loss: 4.22303856e-07
Iter: 1937 loss: 4.22232574e-07
Iter: 1938 loss: 4.22138754e-07
Iter: 1939 loss: 4.22128323e-07
Iter: 1940 loss: 4.21993263e-07
Iter: 1941 loss: 4.23245268e-07
Iter: 1942 loss: 4.22005144e-07
Iter: 1943 loss: 4.21923232e-07
Iter: 1944 loss: 4.21801872e-07
Iter: 1945 loss: 4.24512166e-07
Iter: 1946 loss: 4.21789224e-07
Iter: 1947 loss: 4.2164956e-07
Iter: 1948 loss: 4.22309e-07
Iter: 1949 loss: 4.21601783e-07
Iter: 1950 loss: 4.21521747e-07
Iter: 1951 loss: 4.21782659e-07
Iter: 1952 loss: 4.21484572e-07
Iter: 1953 loss: 4.21362984e-07
Iter: 1954 loss: 4.21462943e-07
Iter: 1955 loss: 4.21299518e-07
Iter: 1956 loss: 4.21206607e-07
Iter: 1957 loss: 4.21212889e-07
Iter: 1958 loss: 4.21151668e-07
Iter: 1959 loss: 4.21013681e-07
Iter: 1960 loss: 4.21843481e-07
Iter: 1961 loss: 4.20989096e-07
Iter: 1962 loss: 4.20857731e-07
Iter: 1963 loss: 4.20838546e-07
Iter: 1964 loss: 4.20709114e-07
Iter: 1965 loss: 4.20860317e-07
Iter: 1966 loss: 4.2065119e-07
Iter: 1967 loss: 4.20515e-07
Iter: 1968 loss: 4.2060185e-07
Iter: 1969 loss: 4.20436066e-07
Iter: 1970 loss: 4.20269885e-07
Iter: 1971 loss: 4.21677214e-07
Iter: 1972 loss: 4.20273977e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.4
+ date
Sat Nov  7 13:13:37 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.4/500_500_500_500_1 --optimizer lbfgs --function f2 --psi 2 --alpha 0.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71873598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd718736a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71776400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71779378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71779b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd717797b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd7170cbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd716b2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd716b2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd716a6c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71685950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd716a6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd7161a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71644950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd7160cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd7160c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd715a3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd7157cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71535620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd71535598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd716b9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68b2f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68b05620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68aad1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68ab4620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68a798c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68a9e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68a79620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68a9e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68a45a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68a45b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd689ff730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd689ba730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd689bae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68976a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fbd68972d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 1.38712312e-05
Iter: 2 loss: 1.10856618e-05
Iter: 3 loss: 4.1479776e-05
Iter: 4 loss: 1.10234705e-05
Iter: 5 loss: 9.86705345e-06
Iter: 6 loss: 1.45378435e-05
Iter: 7 loss: 9.60775e-06
Iter: 8 loss: 8.94160621e-06
Iter: 9 loss: 8.24411654e-06
Iter: 10 loss: 8.12265171e-06
Iter: 11 loss: 7.36290622e-06
Iter: 12 loss: 7.35343201e-06
Iter: 13 loss: 6.83330563e-06
Iter: 14 loss: 7.61894e-06
Iter: 15 loss: 6.58465069e-06
Iter: 16 loss: 6.27303461e-06
Iter: 17 loss: 6.53095185e-06
Iter: 18 loss: 6.08706e-06
Iter: 19 loss: 5.68492578e-06
Iter: 20 loss: 9.91506568e-06
Iter: 21 loss: 5.67451298e-06
Iter: 22 loss: 5.4581169e-06
Iter: 23 loss: 5.2236669e-06
Iter: 24 loss: 5.18718025e-06
Iter: 25 loss: 5.05849766e-06
Iter: 26 loss: 5.03323554e-06
Iter: 27 loss: 4.89637068e-06
Iter: 28 loss: 4.74066837e-06
Iter: 29 loss: 4.72094052e-06
Iter: 30 loss: 4.57256783e-06
Iter: 31 loss: 4.57981059e-06
Iter: 32 loss: 4.45606292e-06
Iter: 33 loss: 4.30822911e-06
Iter: 34 loss: 4.4959188e-06
Iter: 35 loss: 4.23221945e-06
Iter: 36 loss: 4.04432649e-06
Iter: 37 loss: 4.28345265e-06
Iter: 38 loss: 3.94761446e-06
Iter: 39 loss: 3.80953543e-06
Iter: 40 loss: 5.04781747e-06
Iter: 41 loss: 3.80294205e-06
Iter: 42 loss: 3.69759891e-06
Iter: 43 loss: 3.68091969e-06
Iter: 44 loss: 3.60805348e-06
Iter: 45 loss: 3.4736795e-06
Iter: 46 loss: 4.77166486e-06
Iter: 47 loss: 3.46869319e-06
Iter: 48 loss: 3.36489984e-06
Iter: 49 loss: 3.64382504e-06
Iter: 50 loss: 3.33035905e-06
Iter: 51 loss: 3.26007239e-06
Iter: 52 loss: 3.27766611e-06
Iter: 53 loss: 3.20897925e-06
Iter: 54 loss: 3.08525887e-06
Iter: 55 loss: 3.74258912e-06
Iter: 56 loss: 3.06639367e-06
Iter: 57 loss: 3.00492979e-06
Iter: 58 loss: 2.9697635e-06
Iter: 59 loss: 2.94353094e-06
Iter: 60 loss: 2.89085801e-06
Iter: 61 loss: 2.88653109e-06
Iter: 62 loss: 2.84605767e-06
Iter: 63 loss: 2.78928928e-06
Iter: 64 loss: 2.78709967e-06
Iter: 65 loss: 2.73778778e-06
Iter: 66 loss: 3.22257938e-06
Iter: 67 loss: 2.73612295e-06
Iter: 68 loss: 2.69166549e-06
Iter: 69 loss: 2.72053649e-06
Iter: 70 loss: 2.6635912e-06
Iter: 71 loss: 2.61104651e-06
Iter: 72 loss: 2.64858022e-06
Iter: 73 loss: 2.57850343e-06
Iter: 74 loss: 2.52548034e-06
Iter: 75 loss: 3.06976563e-06
Iter: 76 loss: 2.52394852e-06
Iter: 77 loss: 2.48598963e-06
Iter: 78 loss: 2.49764707e-06
Iter: 79 loss: 2.45884894e-06
Iter: 80 loss: 2.41208591e-06
Iter: 81 loss: 2.87931334e-06
Iter: 82 loss: 2.41055386e-06
Iter: 83 loss: 2.37894596e-06
Iter: 84 loss: 2.38849475e-06
Iter: 85 loss: 2.35632797e-06
Iter: 86 loss: 2.33364426e-06
Iter: 87 loss: 2.33366632e-06
Iter: 88 loss: 2.31199283e-06
Iter: 89 loss: 2.26714747e-06
Iter: 90 loss: 3.03759589e-06
Iter: 91 loss: 2.26614384e-06
Iter: 92 loss: 2.23189181e-06
Iter: 93 loss: 2.71468207e-06
Iter: 94 loss: 2.23178131e-06
Iter: 95 loss: 2.2017191e-06
Iter: 96 loss: 2.31394984e-06
Iter: 97 loss: 2.19441881e-06
Iter: 98 loss: 2.17500519e-06
Iter: 99 loss: 2.15956402e-06
Iter: 100 loss: 2.1536564e-06
Iter: 101 loss: 2.11913493e-06
Iter: 102 loss: 2.40078e-06
Iter: 103 loss: 2.11701445e-06
Iter: 104 loss: 2.09737254e-06
Iter: 105 loss: 2.11877114e-06
Iter: 106 loss: 2.08670554e-06
Iter: 107 loss: 2.06824416e-06
Iter: 108 loss: 2.13068824e-06
Iter: 109 loss: 2.06324535e-06
Iter: 110 loss: 2.0418579e-06
Iter: 111 loss: 2.08886968e-06
Iter: 112 loss: 2.03361515e-06
Iter: 113 loss: 2.01611579e-06
Iter: 114 loss: 2.12967e-06
Iter: 115 loss: 2.0141938e-06
Iter: 116 loss: 1.99666442e-06
Iter: 117 loss: 1.99775877e-06
Iter: 118 loss: 1.98290377e-06
Iter: 119 loss: 1.96006795e-06
Iter: 120 loss: 2.04059597e-06
Iter: 121 loss: 1.95422695e-06
Iter: 122 loss: 1.92859852e-06
Iter: 123 loss: 2.04595312e-06
Iter: 124 loss: 1.92376547e-06
Iter: 125 loss: 1.91236632e-06
Iter: 126 loss: 1.9047834e-06
Iter: 127 loss: 1.90043681e-06
Iter: 128 loss: 1.88304841e-06
Iter: 129 loss: 2.12350756e-06
Iter: 130 loss: 1.88299191e-06
Iter: 131 loss: 1.87150749e-06
Iter: 132 loss: 1.8562788e-06
Iter: 133 loss: 1.85529393e-06
Iter: 134 loss: 1.84190708e-06
Iter: 135 loss: 1.84183523e-06
Iter: 136 loss: 1.83053226e-06
Iter: 137 loss: 1.81500059e-06
Iter: 138 loss: 1.81435075e-06
Iter: 139 loss: 1.79367908e-06
Iter: 140 loss: 1.88015542e-06
Iter: 141 loss: 1.78931646e-06
Iter: 142 loss: 1.77438687e-06
Iter: 143 loss: 1.90944024e-06
Iter: 144 loss: 1.77374113e-06
Iter: 145 loss: 1.76312165e-06
Iter: 146 loss: 1.77180141e-06
Iter: 147 loss: 1.75667424e-06
Iter: 148 loss: 1.74356319e-06
Iter: 149 loss: 1.82663439e-06
Iter: 150 loss: 1.74204422e-06
Iter: 151 loss: 1.73438923e-06
Iter: 152 loss: 1.74371803e-06
Iter: 153 loss: 1.73030548e-06
Iter: 154 loss: 1.72074169e-06
Iter: 155 loss: 1.78299695e-06
Iter: 156 loss: 1.71967076e-06
Iter: 157 loss: 1.71122088e-06
Iter: 158 loss: 1.69379825e-06
Iter: 159 loss: 2.00256886e-06
Iter: 160 loss: 1.69347436e-06
Iter: 161 loss: 1.6884934e-06
Iter: 162 loss: 1.68492693e-06
Iter: 163 loss: 1.67740427e-06
Iter: 164 loss: 1.66634027e-06
Iter: 165 loss: 1.66601785e-06
Iter: 166 loss: 1.65365827e-06
Iter: 167 loss: 1.72606701e-06
Iter: 168 loss: 1.65197287e-06
Iter: 169 loss: 1.63957475e-06
Iter: 170 loss: 1.67924702e-06
Iter: 171 loss: 1.63603613e-06
Iter: 172 loss: 1.62905212e-06
Iter: 173 loss: 1.63919015e-06
Iter: 174 loss: 1.62568494e-06
Iter: 175 loss: 1.61784089e-06
Iter: 176 loss: 1.63960976e-06
Iter: 177 loss: 1.61529158e-06
Iter: 178 loss: 1.60553725e-06
Iter: 179 loss: 1.62049105e-06
Iter: 180 loss: 1.60088234e-06
Iter: 181 loss: 1.59252431e-06
Iter: 182 loss: 1.67289681e-06
Iter: 183 loss: 1.59218303e-06
Iter: 184 loss: 1.58582725e-06
Iter: 185 loss: 1.58253931e-06
Iter: 186 loss: 1.57966895e-06
Iter: 187 loss: 1.5717477e-06
Iter: 188 loss: 1.6798665e-06
Iter: 189 loss: 1.57174475e-06
Iter: 190 loss: 1.56563749e-06
Iter: 191 loss: 1.56103977e-06
Iter: 192 loss: 1.5590881e-06
Iter: 193 loss: 1.55312205e-06
Iter: 194 loss: 1.59119531e-06
Iter: 195 loss: 1.55242662e-06
Iter: 196 loss: 1.54553163e-06
Iter: 197 loss: 1.5605458e-06
Iter: 198 loss: 1.54277677e-06
Iter: 199 loss: 1.53790006e-06
Iter: 200 loss: 1.54259669e-06
Iter: 201 loss: 1.5350688e-06
Iter: 202 loss: 1.52808843e-06
Iter: 203 loss: 1.55625139e-06
Iter: 204 loss: 1.52658265e-06
Iter: 205 loss: 1.51991355e-06
Iter: 206 loss: 1.51269921e-06
Iter: 207 loss: 1.51154086e-06
Iter: 208 loss: 1.50287315e-06
Iter: 209 loss: 1.61369394e-06
Iter: 210 loss: 1.50276946e-06
Iter: 211 loss: 1.49736798e-06
Iter: 212 loss: 1.52212306e-06
Iter: 213 loss: 1.49634434e-06
Iter: 214 loss: 1.49202015e-06
Iter: 215 loss: 1.49951654e-06
Iter: 216 loss: 1.49014488e-06
Iter: 217 loss: 1.48452466e-06
Iter: 218 loss: 1.49444395e-06
Iter: 219 loss: 1.48204913e-06
Iter: 220 loss: 1.47864921e-06
Iter: 221 loss: 1.52282735e-06
Iter: 222 loss: 1.47865319e-06
Iter: 223 loss: 1.47551123e-06
Iter: 224 loss: 1.47227843e-06
Iter: 225 loss: 1.47162007e-06
Iter: 226 loss: 1.46605157e-06
Iter: 227 loss: 1.46613138e-06
Iter: 228 loss: 1.46164825e-06
Iter: 229 loss: 1.4549197e-06
Iter: 230 loss: 1.45492845e-06
Iter: 231 loss: 1.45109971e-06
Iter: 232 loss: 1.44402861e-06
Iter: 233 loss: 1.60572029e-06
Iter: 234 loss: 1.44402361e-06
Iter: 235 loss: 1.43722411e-06
Iter: 236 loss: 1.4371949e-06
Iter: 237 loss: 1.43327634e-06
Iter: 238 loss: 1.43329169e-06
Iter: 239 loss: 1.43014404e-06
Iter: 240 loss: 1.426165e-06
Iter: 241 loss: 1.43893851e-06
Iter: 242 loss: 1.42505507e-06
Iter: 243 loss: 1.42030251e-06
Iter: 244 loss: 1.43542616e-06
Iter: 245 loss: 1.41896544e-06
Iter: 246 loss: 1.41443707e-06
Iter: 247 loss: 1.42301724e-06
Iter: 248 loss: 1.41253508e-06
Iter: 249 loss: 1.40777e-06
Iter: 250 loss: 1.43131842e-06
Iter: 251 loss: 1.40698467e-06
Iter: 252 loss: 1.40310567e-06
Iter: 253 loss: 1.40603129e-06
Iter: 254 loss: 1.40075485e-06
Iter: 255 loss: 1.39448048e-06
Iter: 256 loss: 1.41669148e-06
Iter: 257 loss: 1.3928684e-06
Iter: 258 loss: 1.38944097e-06
Iter: 259 loss: 1.39083159e-06
Iter: 260 loss: 1.38705184e-06
Iter: 261 loss: 1.38400685e-06
Iter: 262 loss: 1.38397536e-06
Iter: 263 loss: 1.38123937e-06
Iter: 264 loss: 1.37622465e-06
Iter: 265 loss: 1.4898651e-06
Iter: 266 loss: 1.37617576e-06
Iter: 267 loss: 1.37297343e-06
Iter: 268 loss: 1.37278676e-06
Iter: 269 loss: 1.3700519e-06
Iter: 270 loss: 1.36651761e-06
Iter: 271 loss: 1.366221e-06
Iter: 272 loss: 1.36114681e-06
Iter: 273 loss: 1.37043617e-06
Iter: 274 loss: 1.35901087e-06
Iter: 275 loss: 1.35443247e-06
Iter: 276 loss: 1.41492501e-06
Iter: 277 loss: 1.35442883e-06
Iter: 278 loss: 1.35132814e-06
Iter: 279 loss: 1.35275911e-06
Iter: 280 loss: 1.34921618e-06
Iter: 281 loss: 1.34513414e-06
Iter: 282 loss: 1.36093354e-06
Iter: 283 loss: 1.3441495e-06
Iter: 284 loss: 1.34053494e-06
Iter: 285 loss: 1.34963079e-06
Iter: 286 loss: 1.33922799e-06
Iter: 287 loss: 1.33633841e-06
Iter: 288 loss: 1.36949484e-06
Iter: 289 loss: 1.33628896e-06
Iter: 290 loss: 1.33435901e-06
Iter: 291 loss: 1.33001492e-06
Iter: 292 loss: 1.38743201e-06
Iter: 293 loss: 1.32974355e-06
Iter: 294 loss: 1.32727291e-06
Iter: 295 loss: 1.32683056e-06
Iter: 296 loss: 1.32447622e-06
Iter: 297 loss: 1.32435787e-06
Iter: 298 loss: 1.32253899e-06
Iter: 299 loss: 1.32012292e-06
Iter: 300 loss: 1.32715832e-06
Iter: 301 loss: 1.31940487e-06
Iter: 302 loss: 1.3158209e-06
Iter: 303 loss: 1.31902073e-06
Iter: 304 loss: 1.31381512e-06
Iter: 305 loss: 1.31075353e-06
Iter: 306 loss: 1.31228137e-06
Iter: 307 loss: 1.3086883e-06
Iter: 308 loss: 1.30502588e-06
Iter: 309 loss: 1.33191838e-06
Iter: 310 loss: 1.30468175e-06
Iter: 311 loss: 1.30137437e-06
Iter: 312 loss: 1.30608407e-06
Iter: 313 loss: 1.29972216e-06
Iter: 314 loss: 1.29682826e-06
Iter: 315 loss: 1.3149e-06
Iter: 316 loss: 1.29653904e-06
Iter: 317 loss: 1.2943226e-06
Iter: 318 loss: 1.29709713e-06
Iter: 319 loss: 1.29312821e-06
Iter: 320 loss: 1.29068474e-06
Iter: 321 loss: 1.3092e-06
Iter: 322 loss: 1.29048885e-06
Iter: 323 loss: 1.28829151e-06
Iter: 324 loss: 1.28598424e-06
Iter: 325 loss: 1.28561351e-06
Iter: 326 loss: 1.28302213e-06
Iter: 327 loss: 1.30141439e-06
Iter: 328 loss: 1.28279862e-06
Iter: 329 loss: 1.2795058e-06
Iter: 330 loss: 1.27963449e-06
Iter: 331 loss: 1.27692158e-06
Iter: 332 loss: 1.27348562e-06
Iter: 333 loss: 1.28529223e-06
Iter: 334 loss: 1.27262183e-06
Iter: 335 loss: 1.26975806e-06
Iter: 336 loss: 1.29785803e-06
Iter: 337 loss: 1.2696446e-06
Iter: 338 loss: 1.26799137e-06
Iter: 339 loss: 1.26519069e-06
Iter: 340 loss: 1.26518876e-06
Iter: 341 loss: 1.26245072e-06
Iter: 342 loss: 1.29805926e-06
Iter: 343 loss: 1.26244595e-06
Iter: 344 loss: 1.26053544e-06
Iter: 345 loss: 1.26586951e-06
Iter: 346 loss: 1.25993506e-06
Iter: 347 loss: 1.25816848e-06
Iter: 348 loss: 1.26022076e-06
Iter: 349 loss: 1.25719794e-06
Iter: 350 loss: 1.25462986e-06
Iter: 351 loss: 1.25888778e-06
Iter: 352 loss: 1.25347583e-06
Iter: 353 loss: 1.25133715e-06
Iter: 354 loss: 1.27440285e-06
Iter: 355 loss: 1.25128497e-06
Iter: 356 loss: 1.24940675e-06
Iter: 357 loss: 1.24811584e-06
Iter: 358 loss: 1.24741405e-06
Iter: 359 loss: 1.24489145e-06
Iter: 360 loss: 1.25061979e-06
Iter: 361 loss: 1.24394546e-06
Iter: 362 loss: 1.24138285e-06
Iter: 363 loss: 1.27274893e-06
Iter: 364 loss: 1.24138899e-06
Iter: 365 loss: 1.24029953e-06
Iter: 366 loss: 1.23915083e-06
Iter: 367 loss: 1.23900168e-06
Iter: 368 loss: 1.23690154e-06
Iter: 369 loss: 1.25159988e-06
Iter: 370 loss: 1.23671521e-06
Iter: 371 loss: 1.23485643e-06
Iter: 372 loss: 1.2323826e-06
Iter: 373 loss: 1.23225618e-06
Iter: 374 loss: 1.23005e-06
Iter: 375 loss: 1.25845509e-06
Iter: 376 loss: 1.2300236e-06
Iter: 377 loss: 1.22811286e-06
Iter: 378 loss: 1.23044072e-06
Iter: 379 loss: 1.22706797e-06
Iter: 380 loss: 1.22472977e-06
Iter: 381 loss: 1.22814947e-06
Iter: 382 loss: 1.22356391e-06
Iter: 383 loss: 1.2213452e-06
Iter: 384 loss: 1.23931204e-06
Iter: 385 loss: 1.22113556e-06
Iter: 386 loss: 1.21988091e-06
Iter: 387 loss: 1.22603808e-06
Iter: 388 loss: 1.21967207e-06
Iter: 389 loss: 1.21816129e-06
Iter: 390 loss: 1.21742892e-06
Iter: 391 loss: 1.21672838e-06
Iter: 392 loss: 1.2146686e-06
Iter: 393 loss: 1.21722769e-06
Iter: 394 loss: 1.21365929e-06
Iter: 395 loss: 1.21182416e-06
Iter: 396 loss: 1.2118071e-06
Iter: 397 loss: 1.2106176e-06
Iter: 398 loss: 1.20793288e-06
Iter: 399 loss: 1.24745395e-06
Iter: 400 loss: 1.20783716e-06
Iter: 401 loss: 1.20596724e-06
Iter: 402 loss: 1.20583331e-06
Iter: 403 loss: 1.20437539e-06
Iter: 404 loss: 1.20306572e-06
Iter: 405 loss: 1.20272114e-06
Iter: 406 loss: 1.20080881e-06
Iter: 407 loss: 1.20821801e-06
Iter: 408 loss: 1.20038658e-06
Iter: 409 loss: 1.1985876e-06
Iter: 410 loss: 1.20759455e-06
Iter: 411 loss: 1.19826495e-06
Iter: 412 loss: 1.19691e-06
Iter: 413 loss: 1.19868264e-06
Iter: 414 loss: 1.19620563e-06
Iter: 415 loss: 1.19451693e-06
Iter: 416 loss: 1.19913921e-06
Iter: 417 loss: 1.19395247e-06
Iter: 418 loss: 1.19217043e-06
Iter: 419 loss: 1.19774722e-06
Iter: 420 loss: 1.19163133e-06
Iter: 421 loss: 1.18960963e-06
Iter: 422 loss: 1.19687138e-06
Iter: 423 loss: 1.1891384e-06
Iter: 424 loss: 1.18780667e-06
Iter: 425 loss: 1.1866739e-06
Iter: 426 loss: 1.18634057e-06
Iter: 427 loss: 1.18462958e-06
Iter: 428 loss: 1.18461344e-06
Iter: 429 loss: 1.18328398e-06
Iter: 430 loss: 1.18157163e-06
Iter: 431 loss: 1.18143771e-06
Iter: 432 loss: 1.18015828e-06
Iter: 433 loss: 1.18014304e-06
Iter: 434 loss: 1.17889135e-06
Iter: 435 loss: 1.17733168e-06
Iter: 436 loss: 1.17719549e-06
Iter: 437 loss: 1.17527009e-06
Iter: 438 loss: 1.18320827e-06
Iter: 439 loss: 1.17485183e-06
Iter: 440 loss: 1.17321702e-06
Iter: 441 loss: 1.18506887e-06
Iter: 442 loss: 1.1730491e-06
Iter: 443 loss: 1.17173715e-06
Iter: 444 loss: 1.17103457e-06
Iter: 445 loss: 1.17043987e-06
Iter: 446 loss: 1.16831814e-06
Iter: 447 loss: 1.17920263e-06
Iter: 448 loss: 1.1680014e-06
Iter: 449 loss: 1.16648482e-06
Iter: 450 loss: 1.17549871e-06
Iter: 451 loss: 1.16628803e-06
Iter: 452 loss: 1.16506976e-06
Iter: 453 loss: 1.16875299e-06
Iter: 454 loss: 1.1646905e-06
Iter: 455 loss: 1.16343767e-06
Iter: 456 loss: 1.16142451e-06
Iter: 457 loss: 1.16141348e-06
Iter: 458 loss: 1.16024626e-06
Iter: 459 loss: 1.16005094e-06
Iter: 460 loss: 1.15890339e-06
Iter: 461 loss: 1.15757393e-06
Iter: 462 loss: 1.15742864e-06
Iter: 463 loss: 1.15575881e-06
Iter: 464 loss: 1.16645469e-06
Iter: 465 loss: 1.15558373e-06
Iter: 466 loss: 1.1538483e-06
Iter: 467 loss: 1.1563568e-06
Iter: 468 loss: 1.15299372e-06
Iter: 469 loss: 1.15175669e-06
Iter: 470 loss: 1.15317721e-06
Iter: 471 loss: 1.15102671e-06
Iter: 472 loss: 1.14947204e-06
Iter: 473 loss: 1.15905573e-06
Iter: 474 loss: 1.14925547e-06
Iter: 475 loss: 1.14788259e-06
Iter: 476 loss: 1.14872887e-06
Iter: 477 loss: 1.1469898e-06
Iter: 478 loss: 1.14554518e-06
Iter: 479 loss: 1.15364639e-06
Iter: 480 loss: 1.14536329e-06
Iter: 481 loss: 1.14412057e-06
Iter: 482 loss: 1.14708928e-06
Iter: 483 loss: 1.14366651e-06
Iter: 484 loss: 1.14217778e-06
Iter: 485 loss: 1.14751856e-06
Iter: 486 loss: 1.14177794e-06
Iter: 487 loss: 1.14047839e-06
Iter: 488 loss: 1.14026216e-06
Iter: 489 loss: 1.1393297e-06
Iter: 490 loss: 1.13814372e-06
Iter: 491 loss: 1.15067132e-06
Iter: 492 loss: 1.13810279e-06
Iter: 493 loss: 1.13668307e-06
Iter: 494 loss: 1.13547435e-06
Iter: 495 loss: 1.13509429e-06
Iter: 496 loss: 1.1335253e-06
Iter: 497 loss: 1.14531053e-06
Iter: 498 loss: 1.13340866e-06
Iter: 499 loss: 1.13205977e-06
Iter: 500 loss: 1.13756073e-06
Iter: 501 loss: 1.13172359e-06
Iter: 502 loss: 1.13075885e-06
Iter: 503 loss: 1.12944804e-06
Iter: 504 loss: 1.12939631e-06
Iter: 505 loss: 1.1278803e-06
Iter: 506 loss: 1.14991735e-06
Iter: 507 loss: 1.12787063e-06
Iter: 508 loss: 1.1268462e-06
Iter: 509 loss: 1.12778639e-06
Iter: 510 loss: 1.12626878e-06
Iter: 511 loss: 1.12515454e-06
Iter: 512 loss: 1.12717726e-06
Iter: 513 loss: 1.12468592e-06
Iter: 514 loss: 1.12324517e-06
Iter: 515 loss: 1.1282616e-06
Iter: 516 loss: 1.12293253e-06
Iter: 517 loss: 1.1216747e-06
Iter: 518 loss: 1.12929524e-06
Iter: 519 loss: 1.12154373e-06
Iter: 520 loss: 1.12051771e-06
Iter: 521 loss: 1.11967688e-06
Iter: 522 loss: 1.11937163e-06
Iter: 523 loss: 1.11801114e-06
Iter: 524 loss: 1.12556415e-06
Iter: 525 loss: 1.11779786e-06
Iter: 526 loss: 1.11628674e-06
Iter: 527 loss: 1.12269936e-06
Iter: 528 loss: 1.11597228e-06
Iter: 529 loss: 1.11514055e-06
Iter: 530 loss: 1.11514146e-06
Iter: 531 loss: 1.11443808e-06
Iter: 532 loss: 1.11298868e-06
Iter: 533 loss: 1.11975714e-06
Iter: 534 loss: 1.11269833e-06
Iter: 535 loss: 1.11163467e-06
Iter: 536 loss: 1.11152679e-06
Iter: 537 loss: 1.11073825e-06
Iter: 538 loss: 1.10965766e-06
Iter: 539 loss: 1.12015437e-06
Iter: 540 loss: 1.10962435e-06
Iter: 541 loss: 1.10848509e-06
Iter: 542 loss: 1.1081454e-06
Iter: 543 loss: 1.10742144e-06
Iter: 544 loss: 1.10583903e-06
Iter: 545 loss: 1.11061968e-06
Iter: 546 loss: 1.10533301e-06
Iter: 547 loss: 1.10410201e-06
Iter: 548 loss: 1.11508893e-06
Iter: 549 loss: 1.1040313e-06
Iter: 550 loss: 1.10311066e-06
Iter: 551 loss: 1.10632141e-06
Iter: 552 loss: 1.10287817e-06
Iter: 553 loss: 1.1018958e-06
Iter: 554 loss: 1.10135466e-06
Iter: 555 loss: 1.10090502e-06
Iter: 556 loss: 1.09978498e-06
Iter: 557 loss: 1.1049699e-06
Iter: 558 loss: 1.09959888e-06
Iter: 559 loss: 1.09847304e-06
Iter: 560 loss: 1.10657743e-06
Iter: 561 loss: 1.09837401e-06
Iter: 562 loss: 1.09756718e-06
Iter: 563 loss: 1.09611381e-06
Iter: 564 loss: 1.13044553e-06
Iter: 565 loss: 1.09610323e-06
Iter: 566 loss: 1.0945912e-06
Iter: 567 loss: 1.09461007e-06
Iter: 568 loss: 1.09379812e-06
Iter: 569 loss: 1.09282132e-06
Iter: 570 loss: 1.09277858e-06
Iter: 571 loss: 1.09150562e-06
Iter: 572 loss: 1.10052406e-06
Iter: 573 loss: 1.09144094e-06
Iter: 574 loss: 1.09034863e-06
Iter: 575 loss: 1.09365794e-06
Iter: 576 loss: 1.09000416e-06
Iter: 577 loss: 1.08922552e-06
Iter: 578 loss: 1.09018833e-06
Iter: 579 loss: 1.08880727e-06
Iter: 580 loss: 1.08778386e-06
Iter: 581 loss: 1.09128337e-06
Iter: 582 loss: 1.08752101e-06
Iter: 583 loss: 1.08642166e-06
Iter: 584 loss: 1.0907338e-06
Iter: 585 loss: 1.08619224e-06
Iter: 586 loss: 1.08512131e-06
Iter: 587 loss: 1.08617519e-06
Iter: 588 loss: 1.08454287e-06
Iter: 589 loss: 1.08346012e-06
Iter: 590 loss: 1.08315874e-06
Iter: 591 loss: 1.08247707e-06
Iter: 592 loss: 1.08097606e-06
Iter: 593 loss: 1.1026134e-06
Iter: 594 loss: 1.08095833e-06
Iter: 595 loss: 1.07999176e-06
Iter: 596 loss: 1.07909239e-06
Iter: 597 loss: 1.07884568e-06
Iter: 598 loss: 1.07796473e-06
Iter: 599 loss: 1.0779263e-06
Iter: 600 loss: 1.07721939e-06
Iter: 601 loss: 1.0760748e-06
Iter: 602 loss: 1.07608253e-06
Iter: 603 loss: 1.07496044e-06
Iter: 604 loss: 1.08422012e-06
Iter: 605 loss: 1.07489666e-06
Iter: 606 loss: 1.07398591e-06
Iter: 607 loss: 1.0767767e-06
Iter: 608 loss: 1.07376297e-06
Iter: 609 loss: 1.07286769e-06
Iter: 610 loss: 1.07235792e-06
Iter: 611 loss: 1.07201754e-06
Iter: 612 loss: 1.07068513e-06
Iter: 613 loss: 1.08099539e-06
Iter: 614 loss: 1.07056269e-06
Iter: 615 loss: 1.06957668e-06
Iter: 616 loss: 1.07625078e-06
Iter: 617 loss: 1.06943571e-06
Iter: 618 loss: 1.06867583e-06
Iter: 619 loss: 1.06916616e-06
Iter: 620 loss: 1.0681639e-06
Iter: 621 loss: 1.06718949e-06
Iter: 622 loss: 1.06663856e-06
Iter: 623 loss: 1.06619279e-06
Iter: 624 loss: 1.06544553e-06
Iter: 625 loss: 1.06534014e-06
Iter: 626 loss: 1.06465427e-06
Iter: 627 loss: 1.06343236e-06
Iter: 628 loss: 1.09188306e-06
Iter: 629 loss: 1.06347034e-06
Iter: 630 loss: 1.06229197e-06
Iter: 631 loss: 1.07822439e-06
Iter: 632 loss: 1.06229402e-06
Iter: 633 loss: 1.06124435e-06
Iter: 634 loss: 1.06076936e-06
Iter: 635 loss: 1.06027449e-06
Iter: 636 loss: 1.05924153e-06
Iter: 637 loss: 1.06454672e-06
Iter: 638 loss: 1.05910237e-06
Iter: 639 loss: 1.05807396e-06
Iter: 640 loss: 1.06210689e-06
Iter: 641 loss: 1.05783238e-06
Iter: 642 loss: 1.05698064e-06
Iter: 643 loss: 1.05692322e-06
Iter: 644 loss: 1.0562228e-06
Iter: 645 loss: 1.05526601e-06
Iter: 646 loss: 1.06261609e-06
Iter: 647 loss: 1.05516904e-06
Iter: 648 loss: 1.05433605e-06
Iter: 649 loss: 1.05710137e-06
Iter: 650 loss: 1.05406571e-06
Iter: 651 loss: 1.0530805e-06
Iter: 652 loss: 1.05528829e-06
Iter: 653 loss: 1.05276831e-06
Iter: 654 loss: 1.05197637e-06
Iter: 655 loss: 1.05215474e-06
Iter: 656 loss: 1.05141226e-06
Iter: 657 loss: 1.05051686e-06
Iter: 658 loss: 1.05897448e-06
Iter: 659 loss: 1.05048127e-06
Iter: 660 loss: 1.04953233e-06
Iter: 661 loss: 1.04843264e-06
Iter: 662 loss: 1.04830406e-06
Iter: 663 loss: 1.04748642e-06
Iter: 664 loss: 1.04747153e-06
Iter: 665 loss: 1.04671039e-06
Iter: 666 loss: 1.04649189e-06
Iter: 667 loss: 1.04603964e-06
Iter: 668 loss: 1.04502192e-06
Iter: 669 loss: 1.04598621e-06
Iter: 670 loss: 1.04449987e-06
Iter: 671 loss: 1.04349624e-06
Iter: 672 loss: 1.05767799e-06
Iter: 673 loss: 1.04347873e-06
Iter: 674 loss: 1.04288347e-06
Iter: 675 loss: 1.04243429e-06
Iter: 676 loss: 1.04228229e-06
Iter: 677 loss: 1.04128333e-06
Iter: 678 loss: 1.04381979e-06
Iter: 679 loss: 1.04099229e-06
Iter: 680 loss: 1.03988668e-06
Iter: 681 loss: 1.04794833e-06
Iter: 682 loss: 1.03981563e-06
Iter: 683 loss: 1.03906564e-06
Iter: 684 loss: 1.04148967e-06
Iter: 685 loss: 1.03885372e-06
Iter: 686 loss: 1.03807486e-06
Iter: 687 loss: 1.03714274e-06
Iter: 688 loss: 1.03703906e-06
Iter: 689 loss: 1.03587115e-06
Iter: 690 loss: 1.0486948e-06
Iter: 691 loss: 1.03586706e-06
Iter: 692 loss: 1.03477191e-06
Iter: 693 loss: 1.03739058e-06
Iter: 694 loss: 1.03440425e-06
Iter: 695 loss: 1.03367029e-06
Iter: 696 loss: 1.03416812e-06
Iter: 697 loss: 1.03321202e-06
Iter: 698 loss: 1.03197067e-06
Iter: 699 loss: 1.03533694e-06
Iter: 700 loss: 1.03154048e-06
Iter: 701 loss: 1.03079083e-06
Iter: 702 loss: 1.03202285e-06
Iter: 703 loss: 1.03044488e-06
Iter: 704 loss: 1.0297606e-06
Iter: 705 loss: 1.03554e-06
Iter: 706 loss: 1.02968636e-06
Iter: 707 loss: 1.02907268e-06
Iter: 708 loss: 1.02820377e-06
Iter: 709 loss: 1.02814943e-06
Iter: 710 loss: 1.02710533e-06
Iter: 711 loss: 1.03224579e-06
Iter: 712 loss: 1.0269e-06
Iter: 713 loss: 1.02608351e-06
Iter: 714 loss: 1.03482307e-06
Iter: 715 loss: 1.02605395e-06
Iter: 716 loss: 1.02538888e-06
Iter: 717 loss: 1.02635784e-06
Iter: 718 loss: 1.0250784e-06
Iter: 719 loss: 1.02428e-06
Iter: 720 loss: 1.02448382e-06
Iter: 721 loss: 1.02370336e-06
Iter: 722 loss: 1.02299e-06
Iter: 723 loss: 1.02685e-06
Iter: 724 loss: 1.02288186e-06
Iter: 725 loss: 1.02197259e-06
Iter: 726 loss: 1.02415117e-06
Iter: 727 loss: 1.02163381e-06
Iter: 728 loss: 1.02086733e-06
Iter: 729 loss: 1.02094259e-06
Iter: 730 loss: 1.02029048e-06
Iter: 731 loss: 1.01926776e-06
Iter: 732 loss: 1.0321794e-06
Iter: 733 loss: 1.01928617e-06
Iter: 734 loss: 1.01877254e-06
Iter: 735 loss: 1.01776607e-06
Iter: 736 loss: 1.03946218e-06
Iter: 737 loss: 1.01776163e-06
Iter: 738 loss: 1.01688408e-06
Iter: 739 loss: 1.01688079e-06
Iter: 740 loss: 1.01632145e-06
Iter: 741 loss: 1.01701221e-06
Iter: 742 loss: 1.01602643e-06
Iter: 743 loss: 1.01547562e-06
Iter: 744 loss: 1.01510159e-06
Iter: 745 loss: 1.01492265e-06
Iter: 746 loss: 1.01408955e-06
Iter: 747 loss: 1.02489719e-06
Iter: 748 loss: 1.01409341e-06
Iter: 749 loss: 1.0134645e-06
Iter: 750 loss: 1.01550165e-06
Iter: 751 loss: 1.0132627e-06
Iter: 752 loss: 1.01261435e-06
Iter: 753 loss: 1.01242517e-06
Iter: 754 loss: 1.01207036e-06
Iter: 755 loss: 1.01106889e-06
Iter: 756 loss: 1.01157525e-06
Iter: 757 loss: 1.010402e-06
Iter: 758 loss: 1.00939121e-06
Iter: 759 loss: 1.00938109e-06
Iter: 760 loss: 1.00880948e-06
Iter: 761 loss: 1.00790987e-06
Iter: 762 loss: 1.00791317e-06
Iter: 763 loss: 1.00722195e-06
Iter: 764 loss: 1.0071609e-06
Iter: 765 loss: 1.00669763e-06
Iter: 766 loss: 1.00605018e-06
Iter: 767 loss: 1.00602722e-06
Iter: 768 loss: 1.00529371e-06
Iter: 769 loss: 1.00989405e-06
Iter: 770 loss: 1.0052396e-06
Iter: 771 loss: 1.0044082e-06
Iter: 772 loss: 1.00433408e-06
Iter: 773 loss: 1.00372563e-06
Iter: 774 loss: 1.00276702e-06
Iter: 775 loss: 1.00438763e-06
Iter: 776 loss: 1.00234547e-06
Iter: 777 loss: 1.00145644e-06
Iter: 778 loss: 1.00683644e-06
Iter: 779 loss: 1.0013581e-06
Iter: 780 loss: 1.00032071e-06
Iter: 781 loss: 1.0030576e-06
Iter: 782 loss: 9.99994427e-07
Iter: 783 loss: 9.99093572e-07
Iter: 784 loss: 1.00329453e-06
Iter: 785 loss: 9.98932e-07
Iter: 786 loss: 9.98405199e-07
Iter: 787 loss: 9.98314931e-07
Iter: 788 loss: 9.97952839e-07
Iter: 789 loss: 9.97247412e-07
Iter: 790 loss: 1.00464672e-06
Iter: 791 loss: 9.97205461e-07
Iter: 792 loss: 9.96553e-07
Iter: 793 loss: 9.95703545e-07
Iter: 794 loss: 9.95624532e-07
Iter: 795 loss: 9.95116579e-07
Iter: 796 loss: 9.95051778e-07
Iter: 797 loss: 9.94562697e-07
Iter: 798 loss: 9.93529625e-07
Iter: 799 loss: 1.01274452e-06
Iter: 800 loss: 9.93534513e-07
Iter: 801 loss: 9.92666e-07
Iter: 802 loss: 1.00165653e-06
Iter: 803 loss: 9.92613309e-07
Iter: 804 loss: 9.91947445e-07
Iter: 805 loss: 9.96282552e-07
Iter: 806 loss: 9.91877414e-07
Iter: 807 loss: 9.9147087e-07
Iter: 808 loss: 9.90859917e-07
Iter: 809 loss: 9.90852072e-07
Iter: 810 loss: 9.90050466e-07
Iter: 811 loss: 9.93832828e-07
Iter: 812 loss: 9.89935e-07
Iter: 813 loss: 9.89327e-07
Iter: 814 loss: 9.8933765e-07
Iter: 815 loss: 9.88934289e-07
Iter: 816 loss: 9.8890132e-07
Iter: 817 loss: 9.88650299e-07
Iter: 818 loss: 9.87946578e-07
Iter: 819 loss: 9.87966359e-07
Iter: 820 loss: 9.87436351e-07
Iter: 821 loss: 9.8694e-07
Iter: 822 loss: 9.86935788e-07
Iter: 823 loss: 9.8643477e-07
Iter: 824 loss: 9.86126679e-07
Iter: 825 loss: 9.85962288e-07
Iter: 826 loss: 9.85377937e-07
Iter: 827 loss: 9.88829242e-07
Iter: 828 loss: 9.8528426e-07
Iter: 829 loss: 9.84670692e-07
Iter: 830 loss: 9.8595433e-07
Iter: 831 loss: 9.84438e-07
Iter: 832 loss: 9.83970153e-07
Iter: 833 loss: 9.83626251e-07
Iter: 834 loss: 9.83458108e-07
Iter: 835 loss: 9.82762799e-07
Iter: 836 loss: 9.93214258e-07
Iter: 837 loss: 9.8275e-07
Iter: 838 loss: 9.82378083e-07
Iter: 839 loss: 9.82167e-07
Iter: 840 loss: 9.82030201e-07
Iter: 841 loss: 9.81421294e-07
Iter: 842 loss: 9.81009407e-07
Iter: 843 loss: 9.80794653e-07
Iter: 844 loss: 9.80063078e-07
Iter: 845 loss: 9.80065579e-07
Iter: 846 loss: 9.79506467e-07
Iter: 847 loss: 9.80642199e-07
Iter: 848 loss: 9.79298193e-07
Iter: 849 loss: 9.78779781e-07
Iter: 850 loss: 9.7922748e-07
Iter: 851 loss: 9.78498747e-07
Iter: 852 loss: 9.77871082e-07
Iter: 853 loss: 9.78562184e-07
Iter: 854 loss: 9.77519448e-07
Iter: 855 loss: 9.76761839e-07
Iter: 856 loss: 9.8445912e-07
Iter: 857 loss: 9.76730462e-07
Iter: 858 loss: 9.76440333e-07
Iter: 859 loss: 9.7639338e-07
Iter: 860 loss: 9.762216e-07
Iter: 861 loss: 9.75733656e-07
Iter: 862 loss: 9.77850277e-07
Iter: 863 loss: 9.75574e-07
Iter: 864 loss: 9.75127136e-07
Iter: 865 loss: 9.74403065e-07
Iter: 866 loss: 9.7440693e-07
Iter: 867 loss: 9.73898523e-07
Iter: 868 loss: 9.7389966e-07
Iter: 869 loss: 9.7339273e-07
Iter: 870 loss: 9.72736e-07
Iter: 871 loss: 9.72715156e-07
Iter: 872 loss: 9.71996542e-07
Iter: 873 loss: 9.74263912e-07
Iter: 874 loss: 9.71808504e-07
Iter: 875 loss: 9.71325903e-07
Iter: 876 loss: 9.74801424e-07
Iter: 877 loss: 9.71268605e-07
Iter: 878 loss: 9.70797373e-07
Iter: 879 loss: 9.72899443e-07
Iter: 880 loss: 9.70716769e-07
Iter: 881 loss: 9.70348879e-07
Iter: 882 loss: 9.71311351e-07
Iter: 883 loss: 9.70214842e-07
Iter: 884 loss: 9.69885718e-07
Iter: 885 loss: 9.69825692e-07
Iter: 886 loss: 9.69577741e-07
Iter: 887 loss: 9.69081384e-07
Iter: 888 loss: 9.74089517e-07
Iter: 889 loss: 9.6906183e-07
Iter: 890 loss: 9.68674385e-07
Iter: 891 loss: 9.68188e-07
Iter: 892 loss: 9.68131644e-07
Iter: 893 loss: 9.67887672e-07
Iter: 894 loss: 9.67842311e-07
Iter: 895 loss: 9.67586175e-07
Iter: 896 loss: 9.66995e-07
Iter: 897 loss: 9.76791853e-07
Iter: 898 loss: 9.6698227e-07
Iter: 899 loss: 9.66494099e-07
Iter: 900 loss: 9.70759e-07
Iter: 901 loss: 9.66499556e-07
Iter: 902 loss: 9.66082212e-07
Iter: 903 loss: 9.6835231e-07
Iter: 904 loss: 9.66046e-07
Iter: 905 loss: 9.65744789e-07
Iter: 906 loss: 9.65152594e-07
Iter: 907 loss: 9.75632815e-07
Iter: 908 loss: 9.6513827e-07
Iter: 909 loss: 9.64543119e-07
Iter: 910 loss: 9.69247139e-07
Iter: 911 loss: 9.64498781e-07
Iter: 912 loss: 9.64064157e-07
Iter: 913 loss: 9.70004521e-07
Iter: 914 loss: 9.64060746e-07
Iter: 915 loss: 9.63713319e-07
Iter: 916 loss: 9.63604e-07
Iter: 917 loss: 9.63330535e-07
Iter: 918 loss: 9.62842478e-07
Iter: 919 loss: 9.6529709e-07
Iter: 920 loss: 9.62721515e-07
Iter: 921 loss: 9.62450486e-07
Iter: 922 loss: 9.63840648e-07
Iter: 923 loss: 9.62374202e-07
Iter: 924 loss: 9.61988576e-07
Iter: 925 loss: 9.61911269e-07
Iter: 926 loss: 9.61648425e-07
Iter: 927 loss: 9.61200499e-07
Iter: 928 loss: 9.62433887e-07
Iter: 929 loss: 9.61033606e-07
Iter: 930 loss: 9.60567e-07
Iter: 931 loss: 9.64490141e-07
Iter: 932 loss: 9.60482566e-07
Iter: 933 loss: 9.60200168e-07
Iter: 934 loss: 9.59594104e-07
Iter: 935 loss: 9.69717576e-07
Iter: 936 loss: 9.59553631e-07
Iter: 937 loss: 9.59110821e-07
Iter: 938 loss: 9.59056138e-07
Iter: 939 loss: 9.58753e-07
Iter: 940 loss: 9.58542273e-07
Iter: 941 loss: 9.58425517e-07
Iter: 942 loss: 9.58012834e-07
Iter: 943 loss: 9.57715e-07
Iter: 944 loss: 9.57552061e-07
Iter: 945 loss: 9.57269776e-07
Iter: 946 loss: 9.57209409e-07
Iter: 947 loss: 9.56879603e-07
Iter: 948 loss: 9.57016482e-07
Iter: 949 loss: 9.56623467e-07
Iter: 950 loss: 9.56134272e-07
Iter: 951 loss: 9.56577082e-07
Iter: 952 loss: 9.55810719e-07
Iter: 953 loss: 9.55185556e-07
Iter: 954 loss: 9.56994541e-07
Iter: 955 loss: 9.54996153e-07
Iter: 956 loss: 9.54609e-07
Iter: 957 loss: 9.54609e-07
Iter: 958 loss: 9.54353e-07
Iter: 959 loss: 9.53823e-07
Iter: 960 loss: 9.63254934e-07
Iter: 961 loss: 9.53800168e-07
Iter: 962 loss: 9.5347724e-07
Iter: 963 loss: 9.53427957e-07
Iter: 964 loss: 9.53126801e-07
Iter: 965 loss: 9.52853838e-07
Iter: 966 loss: 9.52776475e-07
Iter: 967 loss: 9.52437631e-07
Iter: 968 loss: 9.53576091e-07
Iter: 969 loss: 9.52364758e-07
Iter: 970 loss: 9.51874256e-07
Iter: 971 loss: 9.52626e-07
Iter: 972 loss: 9.51661491e-07
Iter: 973 loss: 9.51254833e-07
Iter: 974 loss: 9.51196057e-07
Iter: 975 loss: 9.50916274e-07
Iter: 976 loss: 9.50391893e-07
Iter: 977 loss: 9.52154039e-07
Iter: 978 loss: 9.50285937e-07
Iter: 979 loss: 9.49868195e-07
Iter: 980 loss: 9.49871207e-07
Iter: 981 loss: 9.4959e-07
Iter: 982 loss: 9.49410833e-07
Iter: 983 loss: 9.49306809e-07
Iter: 984 loss: 9.48808861e-07
Iter: 985 loss: 9.50021331e-07
Iter: 986 loss: 9.4866806e-07
Iter: 987 loss: 9.48238835e-07
Iter: 988 loss: 9.50618698e-07
Iter: 989 loss: 9.48178126e-07
Iter: 990 loss: 9.47807393e-07
Iter: 991 loss: 9.48865e-07
Iter: 992 loss: 9.47694048e-07
Iter: 993 loss: 9.47478725e-07
Iter: 994 loss: 9.47516128e-07
Iter: 995 loss: 9.47244757e-07
Iter: 996 loss: 9.46778869e-07
Iter: 997 loss: 9.48385832e-07
Iter: 998 loss: 9.46625391e-07
Iter: 999 loss: 9.46287287e-07
Iter: 1000 loss: 9.46011482e-07
Iter: 1001 loss: 9.45911665e-07
Iter: 1002 loss: 9.45549573e-07
Iter: 1003 loss: 9.45571117e-07
Iter: 1004 loss: 9.45162185e-07
Iter: 1005 loss: 9.44413557e-07
Iter: 1006 loss: 9.59785666e-07
Iter: 1007 loss: 9.44439478e-07
Iter: 1008 loss: 9.43822897e-07
Iter: 1009 loss: 9.47101398e-07
Iter: 1010 loss: 9.43742066e-07
Iter: 1011 loss: 9.4337463e-07
Iter: 1012 loss: 9.4776783e-07
Iter: 1013 loss: 9.4332529e-07
Iter: 1014 loss: 9.42967517e-07
Iter: 1015 loss: 9.43176076e-07
Iter: 1016 loss: 9.42714451e-07
Iter: 1017 loss: 9.42355655e-07
Iter: 1018 loss: 9.43822215e-07
Iter: 1019 loss: 9.42315808e-07
Iter: 1020 loss: 9.41953601e-07
Iter: 1021 loss: 9.4229722e-07
Iter: 1022 loss: 9.41763574e-07
Iter: 1023 loss: 9.41323037e-07
Iter: 1024 loss: 9.43415159e-07
Iter: 1025 loss: 9.41262385e-07
Iter: 1026 loss: 9.40887446e-07
Iter: 1027 loss: 9.4073016e-07
Iter: 1028 loss: 9.40526434e-07
Iter: 1029 loss: 9.40192308e-07
Iter: 1030 loss: 9.4019174e-07
Iter: 1031 loss: 9.39840959e-07
Iter: 1032 loss: 9.3941253e-07
Iter: 1033 loss: 9.39395534e-07
Iter: 1034 loss: 9.3903418e-07
Iter: 1035 loss: 9.40644213e-07
Iter: 1036 loss: 9.38952212e-07
Iter: 1037 loss: 9.38607741e-07
Iter: 1038 loss: 9.40405357e-07
Iter: 1039 loss: 9.38538e-07
Iter: 1040 loss: 9.38178175e-07
Iter: 1041 loss: 9.37370942e-07
Iter: 1042 loss: 9.47303533e-07
Iter: 1043 loss: 9.37315633e-07
Iter: 1044 loss: 9.36590141e-07
Iter: 1045 loss: 9.44897295e-07
Iter: 1046 loss: 9.36575816e-07
Iter: 1047 loss: 9.3623845e-07
Iter: 1048 loss: 9.36217361e-07
Iter: 1049 loss: 9.3589324e-07
Iter: 1050 loss: 9.3540342e-07
Iter: 1051 loss: 9.35367552e-07
Iter: 1052 loss: 9.35010746e-07
Iter: 1053 loss: 9.40628695e-07
Iter: 1054 loss: 9.35004607e-07
Iter: 1055 loss: 9.34742104e-07
Iter: 1056 loss: 9.3565734e-07
Iter: 1057 loss: 9.34649165e-07
Iter: 1058 loss: 9.34327943e-07
Iter: 1059 loss: 9.34191064e-07
Iter: 1060 loss: 9.33993647e-07
Iter: 1061 loss: 9.33584147e-07
Iter: 1062 loss: 9.34380864e-07
Iter: 1063 loss: 9.33388037e-07
Iter: 1064 loss: 9.33001e-07
Iter: 1065 loss: 9.33001672e-07
Iter: 1066 loss: 9.32731041e-07
Iter: 1067 loss: 9.31981731e-07
Iter: 1068 loss: 9.376256e-07
Iter: 1069 loss: 9.31841441e-07
Iter: 1070 loss: 9.31536078e-07
Iter: 1071 loss: 9.3138658e-07
Iter: 1072 loss: 9.31019656e-07
Iter: 1073 loss: 9.31002148e-07
Iter: 1074 loss: 9.30718272e-07
Iter: 1075 loss: 9.30352257e-07
Iter: 1076 loss: 9.29958901e-07
Iter: 1077 loss: 9.29815542e-07
Iter: 1078 loss: 9.29491534e-07
Iter: 1079 loss: 9.29494945e-07
Iter: 1080 loss: 9.29134387e-07
Iter: 1081 loss: 9.29857435e-07
Iter: 1082 loss: 9.28990971e-07
Iter: 1083 loss: 9.28605687e-07
Iter: 1084 loss: 9.28450106e-07
Iter: 1085 loss: 9.28257e-07
Iter: 1086 loss: 9.27752524e-07
Iter: 1087 loss: 9.31869863e-07
Iter: 1088 loss: 9.27722283e-07
Iter: 1089 loss: 9.27364795e-07
Iter: 1090 loss: 9.29058615e-07
Iter: 1091 loss: 9.27280951e-07
Iter: 1092 loss: 9.26925225e-07
Iter: 1093 loss: 9.26501912e-07
Iter: 1094 loss: 9.26428697e-07
Iter: 1095 loss: 9.26080133e-07
Iter: 1096 loss: 9.26096504e-07
Iter: 1097 loss: 9.25800805e-07
Iter: 1098 loss: 9.26598659e-07
Iter: 1099 loss: 9.25698316e-07
Iter: 1100 loss: 9.25427e-07
Iter: 1101 loss: 9.24889719e-07
Iter: 1102 loss: 9.34793547e-07
Iter: 1103 loss: 9.24868914e-07
Iter: 1104 loss: 9.24603285e-07
Iter: 1105 loss: 9.24506594e-07
Iter: 1106 loss: 9.2425114e-07
Iter: 1107 loss: 9.23738867e-07
Iter: 1108 loss: 9.35558603e-07
Iter: 1109 loss: 9.23737332e-07
Iter: 1110 loss: 9.23110406e-07
Iter: 1111 loss: 9.22785944e-07
Iter: 1112 loss: 9.22491665e-07
Iter: 1113 loss: 9.22673564e-07
Iter: 1114 loss: 9.22125e-07
Iter: 1115 loss: 9.2188e-07
Iter: 1116 loss: 9.21646915e-07
Iter: 1117 loss: 9.21562275e-07
Iter: 1118 loss: 9.21222522e-07
Iter: 1119 loss: 9.22142135e-07
Iter: 1120 loss: 9.21104402e-07
Iter: 1121 loss: 9.20685125e-07
Iter: 1122 loss: 9.23786e-07
Iter: 1123 loss: 9.20682055e-07
Iter: 1124 loss: 9.20392949e-07
Iter: 1125 loss: 9.20734692e-07
Iter: 1126 loss: 9.20218781e-07
Iter: 1127 loss: 9.19827244e-07
Iter: 1128 loss: 9.19170816e-07
Iter: 1129 loss: 9.19190256e-07
Iter: 1130 loss: 9.18800311e-07
Iter: 1131 loss: 9.1870578e-07
Iter: 1132 loss: 9.18346814e-07
Iter: 1133 loss: 9.17704483e-07
Iter: 1134 loss: 9.17691e-07
Iter: 1135 loss: 9.16972e-07
Iter: 1136 loss: 9.1732818e-07
Iter: 1137 loss: 9.16474278e-07
Iter: 1138 loss: 9.16423801e-07
Iter: 1139 loss: 9.16088425e-07
Iter: 1140 loss: 9.15929377e-07
Iter: 1141 loss: 9.15507258e-07
Iter: 1142 loss: 9.2020457e-07
Iter: 1143 loss: 9.155e-07
Iter: 1144 loss: 9.14977818e-07
Iter: 1145 loss: 9.15652095e-07
Iter: 1146 loss: 9.14659836e-07
Iter: 1147 loss: 9.14436e-07
Iter: 1148 loss: 9.14357258e-07
Iter: 1149 loss: 9.14093505e-07
Iter: 1150 loss: 9.13589304e-07
Iter: 1151 loss: 9.21484911e-07
Iter: 1152 loss: 9.13539566e-07
Iter: 1153 loss: 9.12958853e-07
Iter: 1154 loss: 9.17871716e-07
Iter: 1155 loss: 9.12973178e-07
Iter: 1156 loss: 9.12513201e-07
Iter: 1157 loss: 9.15506e-07
Iter: 1158 loss: 9.12469091e-07
Iter: 1159 loss: 9.12185726e-07
Iter: 1160 loss: 9.12356029e-07
Iter: 1161 loss: 9.11978e-07
Iter: 1162 loss: 9.11605184e-07
Iter: 1163 loss: 9.11791062e-07
Iter: 1164 loss: 9.11352117e-07
Iter: 1165 loss: 9.1114714e-07
Iter: 1166 loss: 9.11103939e-07
Iter: 1167 loss: 9.10915674e-07
Iter: 1168 loss: 9.10429435e-07
Iter: 1169 loss: 9.13907286e-07
Iter: 1170 loss: 9.10321e-07
Iter: 1171 loss: 9.09629534e-07
Iter: 1172 loss: 9.10305801e-07
Iter: 1173 loss: 9.09261757e-07
Iter: 1174 loss: 9.08690311e-07
Iter: 1175 loss: 9.14395798e-07
Iter: 1176 loss: 9.08670756e-07
Iter: 1177 loss: 9.08135121e-07
Iter: 1178 loss: 9.12083181e-07
Iter: 1179 loss: 9.08093625e-07
Iter: 1180 loss: 9.077188e-07
Iter: 1181 loss: 9.0753673e-07
Iter: 1182 loss: 9.07331582e-07
Iter: 1183 loss: 9.07141612e-07
Iter: 1184 loss: 9.07085905e-07
Iter: 1185 loss: 9.0688394e-07
Iter: 1186 loss: 9.06458524e-07
Iter: 1187 loss: 9.15865371e-07
Iter: 1188 loss: 9.06457615e-07
Iter: 1189 loss: 9.06080572e-07
Iter: 1190 loss: 9.08572474e-07
Iter: 1191 loss: 9.06041123e-07
Iter: 1192 loss: 9.05647084e-07
Iter: 1193 loss: 9.06782361e-07
Iter: 1194 loss: 9.05510319e-07
Iter: 1195 loss: 9.05135835e-07
Iter: 1196 loss: 9.05284537e-07
Iter: 1197 loss: 9.04871854e-07
Iter: 1198 loss: 9.04271e-07
Iter: 1199 loss: 9.05651518e-07
Iter: 1200 loss: 9.04115609e-07
Iter: 1201 loss: 9.03826958e-07
Iter: 1202 loss: 9.0382548e-07
Iter: 1203 loss: 9.03577e-07
Iter: 1204 loss: 9.03101352e-07
Iter: 1205 loss: 9.11230472e-07
Iter: 1206 loss: 9.03103739e-07
Iter: 1207 loss: 9.02629836e-07
Iter: 1208 loss: 9.03459295e-07
Iter: 1209 loss: 9.02414399e-07
Iter: 1210 loss: 9.01999044e-07
Iter: 1211 loss: 9.02616648e-07
Iter: 1212 loss: 9.01829935e-07
Iter: 1213 loss: 9.01284466e-07
Iter: 1214 loss: 9.05813749e-07
Iter: 1215 loss: 9.01276e-07
Iter: 1216 loss: 9.00974214e-07
Iter: 1217 loss: 9.00742577e-07
Iter: 1218 loss: 9.00644523e-07
Iter: 1219 loss: 9.003071e-07
Iter: 1220 loss: 9.0030494e-07
Iter: 1221 loss: 9.00071825e-07
Iter: 1222 loss: 8.99488725e-07
Iter: 1223 loss: 9.04926708e-07
Iter: 1224 loss: 8.99419319e-07
Iter: 1225 loss: 8.99377483e-07
Iter: 1226 loss: 8.99178417e-07
Iter: 1227 loss: 8.98972075e-07
Iter: 1228 loss: 8.9859833e-07
Iter: 1229 loss: 9.06320111e-07
Iter: 1230 loss: 8.98604412e-07
Iter: 1231 loss: 8.98265625e-07
Iter: 1232 loss: 8.99368047e-07
Iter: 1233 loss: 8.98167968e-07
Iter: 1234 loss: 8.97886252e-07
Iter: 1235 loss: 8.97680877e-07
Iter: 1236 loss: 8.97545533e-07
Iter: 1237 loss: 8.97064297e-07
Iter: 1238 loss: 8.99964732e-07
Iter: 1239 loss: 8.96987444e-07
Iter: 1240 loss: 8.96466304e-07
Iter: 1241 loss: 8.96549295e-07
Iter: 1242 loss: 8.96091706e-07
Iter: 1243 loss: 8.95605922e-07
Iter: 1244 loss: 8.97360337e-07
Iter: 1245 loss: 8.95469498e-07
Iter: 1246 loss: 8.95094445e-07
Iter: 1247 loss: 8.95363485e-07
Iter: 1248 loss: 8.94865309e-07
Iter: 1249 loss: 8.94327115e-07
Iter: 1250 loss: 8.96041797e-07
Iter: 1251 loss: 8.94137e-07
Iter: 1252 loss: 8.93693539e-07
Iter: 1253 loss: 8.95973244e-07
Iter: 1254 loss: 8.93633569e-07
Iter: 1255 loss: 8.93194169e-07
Iter: 1256 loss: 8.95775e-07
Iter: 1257 loss: 8.93148751e-07
Iter: 1258 loss: 8.92754883e-07
Iter: 1259 loss: 8.91835157e-07
Iter: 1260 loss: 9.03814453e-07
Iter: 1261 loss: 8.91775528e-07
Iter: 1262 loss: 8.91475679e-07
Iter: 1263 loss: 8.9125524e-07
Iter: 1264 loss: 8.90881e-07
Iter: 1265 loss: 8.90220633e-07
Iter: 1266 loss: 8.9021205e-07
Iter: 1267 loss: 8.89587341e-07
Iter: 1268 loss: 8.96204313e-07
Iter: 1269 loss: 8.89583248e-07
Iter: 1270 loss: 8.89144758e-07
Iter: 1271 loss: 8.89543742e-07
Iter: 1272 loss: 8.88885381e-07
Iter: 1273 loss: 8.88552e-07
Iter: 1274 loss: 8.92051958e-07
Iter: 1275 loss: 8.88550687e-07
Iter: 1276 loss: 8.88140107e-07
Iter: 1277 loss: 8.87138071e-07
Iter: 1278 loss: 8.96236941e-07
Iter: 1279 loss: 8.87011822e-07
Iter: 1280 loss: 8.86024679e-07
Iter: 1281 loss: 8.9339062e-07
Iter: 1282 loss: 8.85968404e-07
Iter: 1283 loss: 8.85287818e-07
Iter: 1284 loss: 8.89624289e-07
Iter: 1285 loss: 8.85197096e-07
Iter: 1286 loss: 8.84334156e-07
Iter: 1287 loss: 8.84811584e-07
Iter: 1288 loss: 8.83784e-07
Iter: 1289 loss: 8.83214739e-07
Iter: 1290 loss: 8.83220537e-07
Iter: 1291 loss: 8.82749532e-07
Iter: 1292 loss: 8.83176e-07
Iter: 1293 loss: 8.82481402e-07
Iter: 1294 loss: 8.81995e-07
Iter: 1295 loss: 8.81560823e-07
Iter: 1296 loss: 8.81449921e-07
Iter: 1297 loss: 8.8094248e-07
Iter: 1298 loss: 8.80897232e-07
Iter: 1299 loss: 8.80569416e-07
Iter: 1300 loss: 8.79916456e-07
Iter: 1301 loss: 8.93595427e-07
Iter: 1302 loss: 8.79919298e-07
Iter: 1303 loss: 8.7889174e-07
Iter: 1304 loss: 8.83691e-07
Iter: 1305 loss: 8.78702053e-07
Iter: 1306 loss: 8.77892717e-07
Iter: 1307 loss: 8.80145421e-07
Iter: 1308 loss: 8.77638968e-07
Iter: 1309 loss: 8.76917909e-07
Iter: 1310 loss: 8.80900188e-07
Iter: 1311 loss: 8.7680786e-07
Iter: 1312 loss: 8.76203899e-07
Iter: 1313 loss: 8.75263424e-07
Iter: 1314 loss: 8.75276e-07
Iter: 1315 loss: 8.74397472e-07
Iter: 1316 loss: 8.80673497e-07
Iter: 1317 loss: 8.7435933e-07
Iter: 1318 loss: 8.73757926e-07
Iter: 1319 loss: 8.80095627e-07
Iter: 1320 loss: 8.73735e-07
Iter: 1321 loss: 8.73084161e-07
Iter: 1322 loss: 8.72168641e-07
Iter: 1323 loss: 8.72122484e-07
Iter: 1324 loss: 8.71772556e-07
Iter: 1325 loss: 8.71614589e-07
Iter: 1326 loss: 8.712e-07
Iter: 1327 loss: 8.70411611e-07
Iter: 1328 loss: 8.88123907e-07
Iter: 1329 loss: 8.70381371e-07
Iter: 1330 loss: 8.69565611e-07
Iter: 1331 loss: 8.74424074e-07
Iter: 1332 loss: 8.69499786e-07
Iter: 1333 loss: 8.68681241e-07
Iter: 1334 loss: 8.72578084e-07
Iter: 1335 loss: 8.685289e-07
Iter: 1336 loss: 8.68060681e-07
Iter: 1337 loss: 8.68374855e-07
Iter: 1338 loss: 8.67778795e-07
Iter: 1339 loss: 8.67130041e-07
Iter: 1340 loss: 8.70231474e-07
Iter: 1341 loss: 8.6701516e-07
Iter: 1342 loss: 8.66443145e-07
Iter: 1343 loss: 8.67920221e-07
Iter: 1344 loss: 8.66269147e-07
Iter: 1345 loss: 8.65729703e-07
Iter: 1346 loss: 8.66273581e-07
Iter: 1347 loss: 8.65424511e-07
Iter: 1348 loss: 8.64830383e-07
Iter: 1349 loss: 8.64003823e-07
Iter: 1350 loss: 8.63959144e-07
Iter: 1351 loss: 8.63091373e-07
Iter: 1352 loss: 8.71165867e-07
Iter: 1353 loss: 8.63024297e-07
Iter: 1354 loss: 8.62280842e-07
Iter: 1355 loss: 8.69787243e-07
Iter: 1356 loss: 8.62249749e-07
Iter: 1357 loss: 8.6153193e-07
Iter: 1358 loss: 8.60728562e-07
Iter: 1359 loss: 8.60634032e-07
Iter: 1360 loss: 8.60345153e-07
Iter: 1361 loss: 8.60183718e-07
Iter: 1362 loss: 8.59799e-07
Iter: 1363 loss: 8.58937767e-07
Iter: 1364 loss: 8.6644809e-07
Iter: 1365 loss: 8.58781846e-07
Iter: 1366 loss: 8.57928512e-07
Iter: 1367 loss: 8.69919745e-07
Iter: 1368 loss: 8.57910095e-07
Iter: 1369 loss: 8.57124519e-07
Iter: 1370 loss: 8.59364889e-07
Iter: 1371 loss: 8.56940687e-07
Iter: 1372 loss: 8.56443762e-07
Iter: 1373 loss: 8.5649458e-07
Iter: 1374 loss: 8.56059273e-07
Iter: 1375 loss: 8.55276767e-07
Iter: 1376 loss: 8.59510465e-07
Iter: 1377 loss: 8.55141366e-07
Iter: 1378 loss: 8.54489031e-07
Iter: 1379 loss: 8.55579628e-07
Iter: 1380 loss: 8.54182133e-07
Iter: 1381 loss: 8.53399115e-07
Iter: 1382 loss: 8.52653898e-07
Iter: 1383 loss: 8.52479843e-07
Iter: 1384 loss: 8.51319271e-07
Iter: 1385 loss: 8.5502603e-07
Iter: 1386 loss: 8.50993786e-07
Iter: 1387 loss: 8.5016444e-07
Iter: 1388 loss: 8.53198e-07
Iter: 1389 loss: 8.49922799e-07
Iter: 1390 loss: 8.49237779e-07
Iter: 1391 loss: 8.49249147e-07
Iter: 1392 loss: 8.48789568e-07
Iter: 1393 loss: 8.48469767e-07
Iter: 1394 loss: 8.48321861e-07
Iter: 1395 loss: 8.47887122e-07
Iter: 1396 loss: 8.4785438e-07
Iter: 1397 loss: 8.47539923e-07
Iter: 1398 loss: 8.46589387e-07
Iter: 1399 loss: 8.53625068e-07
Iter: 1400 loss: 8.46391e-07
Iter: 1401 loss: 8.45395903e-07
Iter: 1402 loss: 8.56640952e-07
Iter: 1403 loss: 8.4537e-07
Iter: 1404 loss: 8.44582928e-07
Iter: 1405 loss: 8.52064261e-07
Iter: 1406 loss: 8.44575595e-07
Iter: 1407 loss: 8.44129488e-07
Iter: 1408 loss: 8.43286898e-07
Iter: 1409 loss: 8.58817884e-07
Iter: 1410 loss: 8.43287694e-07
Iter: 1411 loss: 8.42851364e-07
Iter: 1412 loss: 8.42720283e-07
Iter: 1413 loss: 8.42338522e-07
Iter: 1414 loss: 8.42280429e-07
Iter: 1415 loss: 8.42045722e-07
Iter: 1416 loss: 8.41507585e-07
Iter: 1417 loss: 8.418981e-07
Iter: 1418 loss: 8.41200062e-07
Iter: 1419 loss: 8.40387031e-07
Iter: 1420 loss: 8.39934273e-07
Iter: 1421 loss: 8.39581276e-07
Iter: 1422 loss: 8.38802407e-07
Iter: 1423 loss: 8.49982712e-07
Iter: 1424 loss: 8.38813037e-07
Iter: 1425 loss: 8.37987045e-07
Iter: 1426 loss: 8.39183599e-07
Iter: 1427 loss: 8.37600282e-07
Iter: 1428 loss: 8.3685444e-07
Iter: 1429 loss: 8.38408482e-07
Iter: 1430 loss: 8.36557319e-07
Iter: 1431 loss: 8.35889296e-07
Iter: 1432 loss: 8.44422118e-07
Iter: 1433 loss: 8.35879632e-07
Iter: 1434 loss: 8.35614912e-07
Iter: 1435 loss: 8.34980142e-07
Iter: 1436 loss: 8.4056586e-07
Iter: 1437 loss: 8.34892262e-07
Iter: 1438 loss: 8.34345599e-07
Iter: 1439 loss: 8.34306888e-07
Iter: 1440 loss: 8.33776767e-07
Iter: 1441 loss: 8.33266711e-07
Iter: 1442 loss: 8.33163426e-07
Iter: 1443 loss: 8.32478918e-07
Iter: 1444 loss: 8.35420565e-07
Iter: 1445 loss: 8.32352043e-07
Iter: 1446 loss: 8.31608816e-07
Iter: 1447 loss: 8.35308583e-07
Iter: 1448 loss: 8.31517355e-07
Iter: 1449 loss: 8.30936813e-07
Iter: 1450 loss: 8.31021453e-07
Iter: 1451 loss: 8.30513216e-07
Iter: 1452 loss: 8.29903911e-07
Iter: 1453 loss: 8.32503474e-07
Iter: 1454 loss: 8.29786e-07
Iter: 1455 loss: 8.2929273e-07
Iter: 1456 loss: 8.30039596e-07
Iter: 1457 loss: 8.29094176e-07
Iter: 1458 loss: 8.28712928e-07
Iter: 1459 loss: 8.28723955e-07
Iter: 1460 loss: 8.2847049e-07
Iter: 1461 loss: 8.27980898e-07
Iter: 1462 loss: 8.36550157e-07
Iter: 1463 loss: 8.279589e-07
Iter: 1464 loss: 8.2746044e-07
Iter: 1465 loss: 8.35793173e-07
Iter: 1466 loss: 8.27469194e-07
Iter: 1467 loss: 8.2699944e-07
Iter: 1468 loss: 8.26218695e-07
Iter: 1469 loss: 8.44163878e-07
Iter: 1470 loss: 8.26232849e-07
Iter: 1471 loss: 8.25691359e-07
Iter: 1472 loss: 8.30511738e-07
Iter: 1473 loss: 8.25670327e-07
Iter: 1474 loss: 8.25048119e-07
Iter: 1475 loss: 8.27022e-07
Iter: 1476 loss: 8.24905726e-07
Iter: 1477 loss: 8.244794e-07
Iter: 1478 loss: 8.24372592e-07
Iter: 1479 loss: 8.24131064e-07
Iter: 1480 loss: 8.23838946e-07
Iter: 1481 loss: 8.23807568e-07
Iter: 1482 loss: 8.23564278e-07
Iter: 1483 loss: 8.23168079e-07
Iter: 1484 loss: 8.23161145e-07
Iter: 1485 loss: 8.22613686e-07
Iter: 1486 loss: 8.23861967e-07
Iter: 1487 loss: 8.22405127e-07
Iter: 1488 loss: 8.21847209e-07
Iter: 1489 loss: 8.23100208e-07
Iter: 1490 loss: 8.2159346e-07
Iter: 1491 loss: 8.21105971e-07
Iter: 1492 loss: 8.26160601e-07
Iter: 1493 loss: 8.21116657e-07
Iter: 1494 loss: 8.20633e-07
Iter: 1495 loss: 8.20737228e-07
Iter: 1496 loss: 8.20299761e-07
Iter: 1497 loss: 8.19895149e-07
Iter: 1498 loss: 8.23625214e-07
Iter: 1499 loss: 8.19886509e-07
Iter: 1500 loss: 8.19509694e-07
Iter: 1501 loss: 8.19357581e-07
Iter: 1502 loss: 8.1914277e-07
Iter: 1503 loss: 8.18729802e-07
Iter: 1504 loss: 8.18510898e-07
Iter: 1505 loss: 8.18290459e-07
Iter: 1506 loss: 8.18089518e-07
Iter: 1507 loss: 8.17950877e-07
Iter: 1508 loss: 8.17696446e-07
Iter: 1509 loss: 8.17071623e-07
Iter: 1510 loss: 8.24708422e-07
Iter: 1511 loss: 8.1705366e-07
Iter: 1512 loss: 8.16459305e-07
Iter: 1513 loss: 8.22329355e-07
Iter: 1514 loss: 8.16422244e-07
Iter: 1515 loss: 8.15874898e-07
Iter: 1516 loss: 8.18162675e-07
Iter: 1517 loss: 8.15774683e-07
Iter: 1518 loss: 8.15472674e-07
Iter: 1519 loss: 8.15201247e-07
Iter: 1520 loss: 8.15127919e-07
Iter: 1521 loss: 8.14572559e-07
Iter: 1522 loss: 8.18898911e-07
Iter: 1523 loss: 8.1453959e-07
Iter: 1524 loss: 8.14224506e-07
Iter: 1525 loss: 8.15613078e-07
Iter: 1526 loss: 8.14163172e-07
Iter: 1527 loss: 8.13836323e-07
Iter: 1528 loss: 8.14479e-07
Iter: 1529 loss: 8.13695351e-07
Iter: 1530 loss: 8.13349402e-07
Iter: 1531 loss: 8.13363954e-07
Iter: 1532 loss: 8.13077179e-07
Iter: 1533 loss: 8.12485837e-07
Iter: 1534 loss: 8.15320675e-07
Iter: 1535 loss: 8.12413361e-07
Iter: 1536 loss: 8.12089468e-07
Iter: 1537 loss: 8.117e-07
Iter: 1538 loss: 8.11688778e-07
Iter: 1539 loss: 8.11334644e-07
Iter: 1540 loss: 8.11312361e-07
Iter: 1541 loss: 8.10922302e-07
Iter: 1542 loss: 8.10867391e-07
Iter: 1543 loss: 8.10596418e-07
Iter: 1544 loss: 8.10246888e-07
Iter: 1545 loss: 8.10901156e-07
Iter: 1546 loss: 8.10134225e-07
Iter: 1547 loss: 8.09743483e-07
Iter: 1548 loss: 8.13444e-07
Iter: 1549 loss: 8.09727737e-07
Iter: 1550 loss: 8.09428457e-07
Iter: 1551 loss: 8.08866162e-07
Iter: 1552 loss: 8.18638114e-07
Iter: 1553 loss: 8.08839559e-07
Iter: 1554 loss: 8.08392031e-07
Iter: 1555 loss: 8.08375262e-07
Iter: 1556 loss: 8.08059553e-07
Iter: 1557 loss: 8.08019706e-07
Iter: 1558 loss: 8.07748961e-07
Iter: 1559 loss: 8.07280799e-07
Iter: 1560 loss: 8.11444579e-07
Iter: 1561 loss: 8.07277047e-07
Iter: 1562 loss: 8.0694457e-07
Iter: 1563 loss: 8.06938488e-07
Iter: 1564 loss: 8.06697813e-07
Iter: 1565 loss: 8.06394496e-07
Iter: 1566 loss: 8.06402568e-07
Iter: 1567 loss: 8.06153366e-07
Iter: 1568 loss: 8.05551508e-07
Iter: 1569 loss: 8.10399968e-07
Iter: 1570 loss: 8.05446405e-07
Iter: 1571 loss: 8.05013e-07
Iter: 1572 loss: 8.05010473e-07
Iter: 1573 loss: 8.0461507e-07
Iter: 1574 loss: 8.06590151e-07
Iter: 1575 loss: 8.04562035e-07
Iter: 1576 loss: 8.04289925e-07
Iter: 1577 loss: 8.03793171e-07
Iter: 1578 loss: 8.14945338e-07
Iter: 1579 loss: 8.03814373e-07
Iter: 1580 loss: 8.03580406e-07
Iter: 1581 loss: 8.03480077e-07
Iter: 1582 loss: 8.03242756e-07
Iter: 1583 loss: 8.02697116e-07
Iter: 1584 loss: 8.12935582e-07
Iter: 1585 loss: 8.02713e-07
Iter: 1586 loss: 8.02206102e-07
Iter: 1587 loss: 8.04899457e-07
Iter: 1588 loss: 8.02142722e-07
Iter: 1589 loss: 8.01766305e-07
Iter: 1590 loss: 8.05316802e-07
Iter: 1591 loss: 8.01757892e-07
Iter: 1592 loss: 8.0145918e-07
Iter: 1593 loss: 8.02021304e-07
Iter: 1594 loss: 8.01328e-07
Iter: 1595 loss: 8.00971236e-07
Iter: 1596 loss: 8.00743e-07
Iter: 1597 loss: 8.00596126e-07
Iter: 1598 loss: 8.00272801e-07
Iter: 1599 loss: 8.00274108e-07
Iter: 1600 loss: 7.99974032e-07
Iter: 1601 loss: 7.99604322e-07
Iter: 1602 loss: 7.99558165e-07
Iter: 1603 loss: 7.99127861e-07
Iter: 1604 loss: 7.9884569e-07
Iter: 1605 loss: 7.9869767e-07
Iter: 1606 loss: 7.98732401e-07
Iter: 1607 loss: 7.98420388e-07
Iter: 1608 loss: 7.98214273e-07
Iter: 1609 loss: 7.97802613e-07
Iter: 1610 loss: 8.03584385e-07
Iter: 1611 loss: 7.97788914e-07
Iter: 1612 loss: 7.97333598e-07
Iter: 1613 loss: 7.99968689e-07
Iter: 1614 loss: 7.97309553e-07
Iter: 1615 loss: 7.96901872e-07
Iter: 1616 loss: 7.9904e-07
Iter: 1617 loss: 7.96845541e-07
Iter: 1618 loss: 7.96609925e-07
Iter: 1619 loss: 7.96136305e-07
Iter: 1620 loss: 8.03529929e-07
Iter: 1621 loss: 7.96142444e-07
Iter: 1622 loss: 7.95637106e-07
Iter: 1623 loss: 7.99148211e-07
Iter: 1624 loss: 7.955922e-07
Iter: 1625 loss: 7.95173491e-07
Iter: 1626 loss: 7.95167296e-07
Iter: 1627 loss: 7.94941968e-07
Iter: 1628 loss: 7.94494895e-07
Iter: 1629 loss: 7.9450831e-07
Iter: 1630 loss: 7.94046855e-07
Iter: 1631 loss: 7.97990822e-07
Iter: 1632 loss: 7.93997515e-07
Iter: 1633 loss: 7.9365384e-07
Iter: 1634 loss: 7.95715664e-07
Iter: 1635 loss: 7.93636332e-07
Iter: 1636 loss: 7.93382e-07
Iter: 1637 loss: 7.92815229e-07
Iter: 1638 loss: 7.97548751e-07
Iter: 1639 loss: 7.92726041e-07
Iter: 1640 loss: 7.92313585e-07
Iter: 1641 loss: 7.92264245e-07
Iter: 1642 loss: 7.91886919e-07
Iter: 1643 loss: 7.93762e-07
Iter: 1644 loss: 7.91795117e-07
Iter: 1645 loss: 7.91576724e-07
Iter: 1646 loss: 7.91095488e-07
Iter: 1647 loss: 7.9964e-07
Iter: 1648 loss: 7.91063655e-07
Iter: 1649 loss: 7.90837248e-07
Iter: 1650 loss: 7.90741638e-07
Iter: 1651 loss: 7.90502099e-07
Iter: 1652 loss: 7.90082709e-07
Iter: 1653 loss: 7.90107038e-07
Iter: 1654 loss: 7.89599312e-07
Iter: 1655 loss: 7.89790306e-07
Iter: 1656 loss: 7.89246428e-07
Iter: 1657 loss: 7.88848297e-07
Iter: 1658 loss: 7.88839486e-07
Iter: 1659 loss: 7.88532077e-07
Iter: 1660 loss: 7.89773196e-07
Iter: 1661 loss: 7.88503144e-07
Iter: 1662 loss: 7.88257751e-07
Iter: 1663 loss: 7.88129e-07
Iter: 1664 loss: 7.88011e-07
Iter: 1665 loss: 7.87649469e-07
Iter: 1666 loss: 7.9008305e-07
Iter: 1667 loss: 7.87596719e-07
Iter: 1668 loss: 7.87235535e-07
Iter: 1669 loss: 7.87127533e-07
Iter: 1670 loss: 7.86940859e-07
Iter: 1671 loss: 7.865155e-07
Iter: 1672 loss: 7.86129249e-07
Iter: 1673 loss: 7.86018177e-07
Iter: 1674 loss: 7.85856287e-07
Iter: 1675 loss: 7.85664099e-07
Iter: 1676 loss: 7.85390966e-07
Iter: 1677 loss: 7.85009e-07
Iter: 1678 loss: 7.84978624e-07
Iter: 1679 loss: 7.84596068e-07
Iter: 1680 loss: 7.85305701e-07
Iter: 1681 loss: 7.84483746e-07
Iter: 1682 loss: 7.8399421e-07
Iter: 1683 loss: 7.87395152e-07
Iter: 1684 loss: 7.8394612e-07
Iter: 1685 loss: 7.8373489e-07
Iter: 1686 loss: 7.83422536e-07
Iter: 1687 loss: 7.83422763e-07
Iter: 1688 loss: 7.82969437e-07
Iter: 1689 loss: 7.83949304e-07
Iter: 1690 loss: 7.82785207e-07
Iter: 1691 loss: 7.82370648e-07
Iter: 1692 loss: 7.88183229e-07
Iter: 1693 loss: 7.82375707e-07
Iter: 1694 loss: 7.82084157e-07
Iter: 1695 loss: 7.82337793e-07
Iter: 1696 loss: 7.81925507e-07
Iter: 1697 loss: 7.81589051e-07
Iter: 1698 loss: 7.82498432e-07
Iter: 1699 loss: 7.81500205e-07
Iter: 1700 loss: 7.81126118e-07
Iter: 1701 loss: 7.82098e-07
Iter: 1702 loss: 7.80975256e-07
Iter: 1703 loss: 7.8070525e-07
Iter: 1704 loss: 7.80602761e-07
Iter: 1705 loss: 7.80452694e-07
Iter: 1706 loss: 7.80069854e-07
Iter: 1707 loss: 7.81449899e-07
Iter: 1708 loss: 7.80001358e-07
Iter: 1709 loss: 7.79630227e-07
Iter: 1710 loss: 7.83775647e-07
Iter: 1711 loss: 7.79622496e-07
Iter: 1712 loss: 7.79442928e-07
Iter: 1713 loss: 7.79043717e-07
Iter: 1714 loss: 7.84441113e-07
Iter: 1715 loss: 7.79031666e-07
Iter: 1716 loss: 7.7867162e-07
Iter: 1717 loss: 7.78652861e-07
Iter: 1718 loss: 7.7830282e-07
Iter: 1719 loss: 7.77907758e-07
Iter: 1720 loss: 7.77870696e-07
Iter: 1721 loss: 7.77490641e-07
Iter: 1722 loss: 7.77499054e-07
Iter: 1723 loss: 7.77210914e-07
Iter: 1724 loss: 7.76880711e-07
Iter: 1725 loss: 7.76837169e-07
Iter: 1726 loss: 7.76574723e-07
Iter: 1727 loss: 7.76993602e-07
Iter: 1728 loss: 7.7640459e-07
Iter: 1729 loss: 7.76180286e-07
Iter: 1730 loss: 7.7708512e-07
Iter: 1731 loss: 7.76116394e-07
Iter: 1732 loss: 7.75864748e-07
Iter: 1733 loss: 7.76379352e-07
Iter: 1734 loss: 7.75782553e-07
Iter: 1735 loss: 7.75426543e-07
Iter: 1736 loss: 7.75201784e-07
Iter: 1737 loss: 7.75103501e-07
Iter: 1738 loss: 7.74720434e-07
Iter: 1739 loss: 7.75241404e-07
Iter: 1740 loss: 7.74515286e-07
Iter: 1741 loss: 7.74196678e-07
Iter: 1742 loss: 7.74164675e-07
Iter: 1743 loss: 7.73900751e-07
Iter: 1744 loss: 7.73652346e-07
Iter: 1745 loss: 7.73573561e-07
Iter: 1746 loss: 7.73341526e-07
Iter: 1747 loss: 7.74492491e-07
Iter: 1748 loss: 7.73337888e-07
Iter: 1749 loss: 7.7300183e-07
Iter: 1750 loss: 7.73786041e-07
Iter: 1751 loss: 7.72885301e-07
Iter: 1752 loss: 7.72678618e-07
Iter: 1753 loss: 7.72412932e-07
Iter: 1754 loss: 7.72398948e-07
Iter: 1755 loss: 7.72049248e-07
Iter: 1756 loss: 7.74312753e-07
Iter: 1757 loss: 7.72009969e-07
Iter: 1758 loss: 7.71578868e-07
Iter: 1759 loss: 7.73373e-07
Iter: 1760 loss: 7.7150014e-07
Iter: 1761 loss: 7.71236728e-07
Iter: 1762 loss: 7.71624059e-07
Iter: 1763 loss: 7.71107182e-07
Iter: 1764 loss: 7.70832116e-07
Iter: 1765 loss: 7.72762689e-07
Iter: 1766 loss: 7.70806139e-07
Iter: 1767 loss: 7.7053005e-07
Iter: 1768 loss: 7.70363158e-07
Iter: 1769 loss: 7.70263625e-07
Iter: 1770 loss: 7.698834e-07
Iter: 1771 loss: 7.70301313e-07
Iter: 1772 loss: 7.69704172e-07
Iter: 1773 loss: 7.69442522e-07
Iter: 1774 loss: 7.72993e-07
Iter: 1775 loss: 7.69431608e-07
Iter: 1776 loss: 7.69121925e-07
Iter: 1777 loss: 7.69109249e-07
Iter: 1778 loss: 7.68850327e-07
Iter: 1779 loss: 7.68539621e-07
Iter: 1780 loss: 7.68676443e-07
Iter: 1781 loss: 7.68304801e-07
Iter: 1782 loss: 7.68088626e-07
Iter: 1783 loss: 7.68083055e-07
Iter: 1784 loss: 7.67891038e-07
Iter: 1785 loss: 7.67452434e-07
Iter: 1786 loss: 7.7287882e-07
Iter: 1787 loss: 7.67414463e-07
Iter: 1788 loss: 7.67033498e-07
Iter: 1789 loss: 7.68208e-07
Iter: 1790 loss: 7.66908101e-07
Iter: 1791 loss: 7.66724156e-07
Iter: 1792 loss: 7.66701532e-07
Iter: 1793 loss: 7.66479047e-07
Iter: 1794 loss: 7.66045673e-07
Iter: 1795 loss: 7.75895614e-07
Iter: 1796 loss: 7.6606068e-07
Iter: 1797 loss: 7.6582e-07
Iter: 1798 loss: 7.65826769e-07
Iter: 1799 loss: 7.6560525e-07
Iter: 1800 loss: 7.65684149e-07
Iter: 1801 loss: 7.65494804e-07
Iter: 1802 loss: 7.65227128e-07
Iter: 1803 loss: 7.64768799e-07
Iter: 1804 loss: 7.6474771e-07
Iter: 1805 loss: 7.64383685e-07
Iter: 1806 loss: 7.67974143e-07
Iter: 1807 loss: 7.64362198e-07
Iter: 1808 loss: 7.64151423e-07
Iter: 1809 loss: 7.641612e-07
Iter: 1810 loss: 7.63965261e-07
Iter: 1811 loss: 7.63610615e-07
Iter: 1812 loss: 7.70279712e-07
Iter: 1813 loss: 7.63597654e-07
Iter: 1814 loss: 7.63393871e-07
Iter: 1815 loss: 7.66351661e-07
Iter: 1816 loss: 7.63402454e-07
Iter: 1817 loss: 7.63174171e-07
Iter: 1818 loss: 7.63243747e-07
Iter: 1819 loss: 7.63008643e-07
Iter: 1820 loss: 7.62738068e-07
Iter: 1821 loss: 7.62552759e-07
Iter: 1822 loss: 7.62410423e-07
Iter: 1823 loss: 7.62103696e-07
Iter: 1824 loss: 7.63057869e-07
Iter: 1825 loss: 7.62001605e-07
Iter: 1826 loss: 7.61661738e-07
Iter: 1827 loss: 7.66954372e-07
Iter: 1828 loss: 7.61648607e-07
Iter: 1829 loss: 7.61508431e-07
Iter: 1830 loss: 7.61342449e-07
Iter: 1831 loss: 7.61287538e-07
Iter: 1832 loss: 7.61088756e-07
Iter: 1833 loss: 7.64063316e-07
Iter: 1834 loss: 7.61076876e-07
Iter: 1835 loss: 7.60896683e-07
Iter: 1836 loss: 7.60609737e-07
Iter: 1837 loss: 7.60629632e-07
Iter: 1838 loss: 7.60240255e-07
Iter: 1839 loss: 7.61428169e-07
Iter: 1840 loss: 7.60130604e-07
Iter: 1841 loss: 7.59868385e-07
Iter: 1842 loss: 7.60377873e-07
Iter: 1843 loss: 7.59749696e-07
Iter: 1844 loss: 7.59354e-07
Iter: 1845 loss: 7.61516276e-07
Iter: 1846 loss: 7.59282102e-07
Iter: 1847 loss: 7.5898015e-07
Iter: 1848 loss: 7.58760393e-07
Iter: 1849 loss: 7.58695364e-07
Iter: 1850 loss: 7.58492263e-07
Iter: 1851 loss: 7.58485385e-07
Iter: 1852 loss: 7.58256533e-07
Iter: 1853 loss: 7.58164e-07
Iter: 1854 loss: 7.58015517e-07
Iter: 1855 loss: 7.5777416e-07
Iter: 1856 loss: 7.57818839e-07
Iter: 1857 loss: 7.57599366e-07
Iter: 1858 loss: 7.57345e-07
Iter: 1859 loss: 7.6121637e-07
Iter: 1860 loss: 7.57345106e-07
Iter: 1861 loss: 7.57024452e-07
Iter: 1862 loss: 7.56815552e-07
Iter: 1863 loss: 7.56729094e-07
Iter: 1864 loss: 7.56437657e-07
Iter: 1865 loss: 7.57986811e-07
Iter: 1866 loss: 7.56401732e-07
Iter: 1867 loss: 7.56060331e-07
Iter: 1868 loss: 7.56349891e-07
Iter: 1869 loss: 7.55840915e-07
Iter: 1870 loss: 7.55488145e-07
Iter: 1871 loss: 7.55714268e-07
Iter: 1872 loss: 7.55276631e-07
Iter: 1873 loss: 7.54969619e-07
Iter: 1874 loss: 7.56619841e-07
Iter: 1875 loss: 7.54908342e-07
Iter: 1876 loss: 7.54667e-07
Iter: 1877 loss: 7.56909913e-07
Iter: 1878 loss: 7.54657947e-07
Iter: 1879 loss: 7.54399366e-07
Iter: 1880 loss: 7.54237135e-07
Iter: 1881 loss: 7.54162556e-07
Iter: 1882 loss: 7.53877657e-07
Iter: 1883 loss: 7.54036137e-07
Iter: 1884 loss: 7.53716563e-07
Iter: 1885 loss: 7.53464747e-07
Iter: 1886 loss: 7.53435245e-07
Iter: 1887 loss: 7.53243341e-07
Iter: 1888 loss: 7.52722656e-07
Iter: 1889 loss: 7.60988314e-07
Iter: 1890 loss: 7.5269952e-07
Iter: 1891 loss: 7.52427e-07
Iter: 1892 loss: 7.54840812e-07
Iter: 1893 loss: 7.5240041e-07
Iter: 1894 loss: 7.521258e-07
Iter: 1895 loss: 7.5412936e-07
Iter: 1896 loss: 7.52106416e-07
Iter: 1897 loss: 7.51904224e-07
Iter: 1898 loss: 7.51558e-07
Iter: 1899 loss: 7.59312059e-07
Iter: 1900 loss: 7.51559242e-07
Iter: 1901 loss: 7.51378138e-07
Iter: 1902 loss: 7.5133471e-07
Iter: 1903 loss: 7.51158836e-07
Iter: 1904 loss: 7.50792765e-07
Iter: 1905 loss: 7.57599253e-07
Iter: 1906 loss: 7.50781282e-07
Iter: 1907 loss: 7.50402364e-07
Iter: 1908 loss: 7.51653374e-07
Iter: 1909 loss: 7.50267191e-07
Iter: 1910 loss: 7.4994341e-07
Iter: 1911 loss: 7.51705e-07
Iter: 1912 loss: 7.49905553e-07
Iter: 1913 loss: 7.49575577e-07
Iter: 1914 loss: 7.5186864e-07
Iter: 1915 loss: 7.49549827e-07
Iter: 1916 loss: 7.49341325e-07
Iter: 1917 loss: 7.49105425e-07
Iter: 1918 loss: 7.49073e-07
Iter: 1919 loss: 7.48831212e-07
Iter: 1920 loss: 7.49513902e-07
Iter: 1921 loss: 7.48772663e-07
Iter: 1922 loss: 7.48424895e-07
Iter: 1923 loss: 7.50281799e-07
Iter: 1924 loss: 7.4837817e-07
Iter: 1925 loss: 7.48170066e-07
Iter: 1926 loss: 7.47837362e-07
Iter: 1927 loss: 7.47822355e-07
Iter: 1928 loss: 7.47484933e-07
Iter: 1929 loss: 7.48536365e-07
Iter: 1930 loss: 7.47358911e-07
Iter: 1931 loss: 7.47039735e-07
Iter: 1932 loss: 7.52317078e-07
Iter: 1933 loss: 7.47033823e-07
Iter: 1934 loss: 7.46905243e-07
Iter: 1935 loss: 7.4660278e-07
Iter: 1936 loss: 7.46614091e-07
Iter: 1937 loss: 7.46382511e-07
Iter: 1938 loss: 7.46385e-07
Iter: 1939 loss: 7.46153205e-07
Iter: 1940 loss: 7.45903776e-07
Iter: 1941 loss: 7.45882403e-07
Iter: 1942 loss: 7.45619843e-07
Iter: 1943 loss: 7.45727732e-07
Iter: 1944 loss: 7.4542811e-07
Iter: 1945 loss: 7.45049363e-07
Iter: 1946 loss: 7.46367164e-07
Iter: 1947 loss: 7.44959209e-07
Iter: 1948 loss: 7.44653846e-07
Iter: 1949 loss: 7.44655381e-07
Iter: 1950 loss: 7.44428803e-07
Iter: 1951 loss: 7.44822955e-07
Iter: 1952 loss: 7.44339104e-07
Iter: 1953 loss: 7.44144e-07
Iter: 1954 loss: 7.43959163e-07
Iter: 1955 loss: 7.43893111e-07
Iter: 1956 loss: 7.43512032e-07
Iter: 1957 loss: 7.46842659e-07
Iter: 1958 loss: 7.4348668e-07
Iter: 1959 loss: 7.4325169e-07
Iter: 1960 loss: 7.43045177e-07
Iter: 1961 loss: 7.42995439e-07
Iter: 1962 loss: 7.42679219e-07
Iter: 1963 loss: 7.42659097e-07
Iter: 1964 loss: 7.42397731e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.8
+ date
Sat Nov  7 13:41:49 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.8/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.8_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.8_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.8_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.8/500_500_500_500_1 --optimizer lbfgs --function f2 --psi 2 --alpha 0.8 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi0.8_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d21d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d21d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d0ff840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d11e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d11e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d0a87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d0a8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d084268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d084400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d063620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d085598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d084158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cfa0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cfcc9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7d084598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cfa0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cf44378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cf44ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cea2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cf44e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cf446a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cfa0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7ce36840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7ce36378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7ce0d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cdeed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cdc2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cdee9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cdeef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6be5d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb7cdee620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6be24620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6bdebb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6bdebf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6bdaaa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffb6bdb4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.2275317e-05
Iter: 2 loss: 1.90525061e-05
Iter: 3 loss: 4.99075832e-05
Iter: 4 loss: 1.89267666e-05
Iter: 5 loss: 1.70153216e-05
Iter: 6 loss: 1.59460124e-05
Iter: 7 loss: 1.51097101e-05
Iter: 8 loss: 1.32130826e-05
Iter: 9 loss: 1.75403475e-05
Iter: 10 loss: 1.25068555e-05
Iter: 11 loss: 1.15263483e-05
Iter: 12 loss: 1.14456152e-05
Iter: 13 loss: 1.09062712e-05
Iter: 14 loss: 1.10782148e-05
Iter: 15 loss: 1.05222125e-05
Iter: 16 loss: 9.80722e-06
Iter: 17 loss: 9.82913753e-06
Iter: 18 loss: 9.24292e-06
Iter: 19 loss: 8.69943142e-06
Iter: 20 loss: 8.68225925e-06
Iter: 21 loss: 8.28237808e-06
Iter: 22 loss: 8.11011887e-06
Iter: 23 loss: 7.90391732e-06
Iter: 24 loss: 7.55560541e-06
Iter: 25 loss: 1.04553583e-05
Iter: 26 loss: 7.53503036e-06
Iter: 27 loss: 7.15937131e-06
Iter: 28 loss: 7.62029595e-06
Iter: 29 loss: 6.96334973e-06
Iter: 30 loss: 6.6776106e-06
Iter: 31 loss: 6.57081773e-06
Iter: 32 loss: 6.41375209e-06
Iter: 33 loss: 6.00961e-06
Iter: 34 loss: 6.78650576e-06
Iter: 35 loss: 5.84053669e-06
Iter: 36 loss: 5.68478663e-06
Iter: 37 loss: 5.63178082e-06
Iter: 38 loss: 5.42762973e-06
Iter: 39 loss: 5.42956059e-06
Iter: 40 loss: 5.26499207e-06
Iter: 41 loss: 5.10154177e-06
Iter: 42 loss: 5.09849269e-06
Iter: 43 loss: 4.96989742e-06
Iter: 44 loss: 4.85238797e-06
Iter: 45 loss: 4.83825443e-06
Iter: 46 loss: 4.72927513e-06
Iter: 47 loss: 4.69948736e-06
Iter: 48 loss: 4.63244123e-06
Iter: 49 loss: 4.51937558e-06
Iter: 50 loss: 4.78605261e-06
Iter: 51 loss: 4.47805178e-06
Iter: 52 loss: 4.35524453e-06
Iter: 53 loss: 5.03497859e-06
Iter: 54 loss: 4.33764399e-06
Iter: 55 loss: 4.23444453e-06
Iter: 56 loss: 4.49664958e-06
Iter: 57 loss: 4.19866956e-06
Iter: 58 loss: 4.11465862e-06
Iter: 59 loss: 4.26708357e-06
Iter: 60 loss: 4.07838525e-06
Iter: 61 loss: 3.98992233e-06
Iter: 62 loss: 4.66347865e-06
Iter: 63 loss: 3.98331031e-06
Iter: 64 loss: 3.91176127e-06
Iter: 65 loss: 3.85142948e-06
Iter: 66 loss: 3.83127826e-06
Iter: 67 loss: 3.73577745e-06
Iter: 68 loss: 3.77074e-06
Iter: 69 loss: 3.66910831e-06
Iter: 70 loss: 3.56440614e-06
Iter: 71 loss: 4.45101796e-06
Iter: 72 loss: 3.55860084e-06
Iter: 73 loss: 3.48776348e-06
Iter: 74 loss: 3.48765252e-06
Iter: 75 loss: 3.4428308e-06
Iter: 76 loss: 3.35383902e-06
Iter: 77 loss: 5.0752742e-06
Iter: 78 loss: 3.35279674e-06
Iter: 79 loss: 3.28809756e-06
Iter: 80 loss: 3.872869e-06
Iter: 81 loss: 3.28510714e-06
Iter: 82 loss: 3.22657525e-06
Iter: 83 loss: 3.68524661e-06
Iter: 84 loss: 3.22251117e-06
Iter: 85 loss: 3.19072046e-06
Iter: 86 loss: 3.13682312e-06
Iter: 87 loss: 3.13674809e-06
Iter: 88 loss: 3.09345296e-06
Iter: 89 loss: 3.78179e-06
Iter: 90 loss: 3.09345569e-06
Iter: 91 loss: 3.05011372e-06
Iter: 92 loss: 3.08770086e-06
Iter: 93 loss: 3.02482522e-06
Iter: 94 loss: 2.98636701e-06
Iter: 95 loss: 3.10568112e-06
Iter: 96 loss: 2.97504175e-06
Iter: 97 loss: 2.93830499e-06
Iter: 98 loss: 3.17493436e-06
Iter: 99 loss: 2.93416906e-06
Iter: 100 loss: 2.90315211e-06
Iter: 101 loss: 2.90259345e-06
Iter: 102 loss: 2.87827265e-06
Iter: 103 loss: 2.84016346e-06
Iter: 104 loss: 2.94064421e-06
Iter: 105 loss: 2.82732299e-06
Iter: 106 loss: 2.79229198e-06
Iter: 107 loss: 2.79537107e-06
Iter: 108 loss: 2.76503215e-06
Iter: 109 loss: 2.75109778e-06
Iter: 110 loss: 2.74110766e-06
Iter: 111 loss: 2.72212833e-06
Iter: 112 loss: 2.68745407e-06
Iter: 113 loss: 3.50765231e-06
Iter: 114 loss: 2.68738222e-06
Iter: 115 loss: 2.65303402e-06
Iter: 116 loss: 2.70791224e-06
Iter: 117 loss: 2.63724155e-06
Iter: 118 loss: 2.61969535e-06
Iter: 119 loss: 2.61474815e-06
Iter: 120 loss: 2.6015864e-06
Iter: 121 loss: 2.57369584e-06
Iter: 122 loss: 3.02940589e-06
Iter: 123 loss: 2.57295073e-06
Iter: 124 loss: 2.54596125e-06
Iter: 125 loss: 2.66832922e-06
Iter: 126 loss: 2.54079896e-06
Iter: 127 loss: 2.52057589e-06
Iter: 128 loss: 2.52061909e-06
Iter: 129 loss: 2.50824655e-06
Iter: 130 loss: 2.4846222e-06
Iter: 131 loss: 2.98547548e-06
Iter: 132 loss: 2.4845167e-06
Iter: 133 loss: 2.4646647e-06
Iter: 134 loss: 2.46421155e-06
Iter: 135 loss: 2.44877265e-06
Iter: 136 loss: 2.43546037e-06
Iter: 137 loss: 2.43135946e-06
Iter: 138 loss: 2.41134876e-06
Iter: 139 loss: 2.46263289e-06
Iter: 140 loss: 2.40442705e-06
Iter: 141 loss: 2.38075791e-06
Iter: 142 loss: 2.42820397e-06
Iter: 143 loss: 2.37113682e-06
Iter: 144 loss: 2.35720131e-06
Iter: 145 loss: 2.35688117e-06
Iter: 146 loss: 2.34309778e-06
Iter: 147 loss: 2.32032858e-06
Iter: 148 loss: 2.32025786e-06
Iter: 149 loss: 2.30164437e-06
Iter: 150 loss: 2.35457946e-06
Iter: 151 loss: 2.295689e-06
Iter: 152 loss: 2.28513682e-06
Iter: 153 loss: 2.28390627e-06
Iter: 154 loss: 2.27619512e-06
Iter: 155 loss: 2.26045609e-06
Iter: 156 loss: 2.53878875e-06
Iter: 157 loss: 2.2601339e-06
Iter: 158 loss: 2.24229279e-06
Iter: 159 loss: 2.28422641e-06
Iter: 160 loss: 2.23584561e-06
Iter: 161 loss: 2.22334484e-06
Iter: 162 loss: 2.22280642e-06
Iter: 163 loss: 2.21377377e-06
Iter: 164 loss: 2.1974115e-06
Iter: 165 loss: 2.58875161e-06
Iter: 166 loss: 2.19744675e-06
Iter: 167 loss: 2.18235391e-06
Iter: 168 loss: 2.41413272e-06
Iter: 169 loss: 2.18237346e-06
Iter: 170 loss: 2.16971739e-06
Iter: 171 loss: 2.17709498e-06
Iter: 172 loss: 2.16139415e-06
Iter: 173 loss: 2.14982879e-06
Iter: 174 loss: 2.14243209e-06
Iter: 175 loss: 2.13786e-06
Iter: 176 loss: 2.12521445e-06
Iter: 177 loss: 2.32458865e-06
Iter: 178 loss: 2.12523969e-06
Iter: 179 loss: 2.1150895e-06
Iter: 180 loss: 2.1637984e-06
Iter: 181 loss: 2.1132937e-06
Iter: 182 loss: 2.10227381e-06
Iter: 183 loss: 2.099227e-06
Iter: 184 loss: 2.09254858e-06
Iter: 185 loss: 2.08153824e-06
Iter: 186 loss: 2.10933194e-06
Iter: 187 loss: 2.07761514e-06
Iter: 188 loss: 2.06832169e-06
Iter: 189 loss: 2.15350838e-06
Iter: 190 loss: 2.067894e-06
Iter: 191 loss: 2.05761853e-06
Iter: 192 loss: 2.05584661e-06
Iter: 193 loss: 2.04892012e-06
Iter: 194 loss: 2.03960099e-06
Iter: 195 loss: 2.04616254e-06
Iter: 196 loss: 2.03387663e-06
Iter: 197 loss: 2.02601e-06
Iter: 198 loss: 2.14007332e-06
Iter: 199 loss: 2.02599585e-06
Iter: 200 loss: 2.01746843e-06
Iter: 201 loss: 2.01296052e-06
Iter: 202 loss: 2.00901786e-06
Iter: 203 loss: 2.00075692e-06
Iter: 204 loss: 2.03980062e-06
Iter: 205 loss: 1.9991453e-06
Iter: 206 loss: 1.98905036e-06
Iter: 207 loss: 2.01294461e-06
Iter: 208 loss: 1.98533849e-06
Iter: 209 loss: 1.97822146e-06
Iter: 210 loss: 1.97101326e-06
Iter: 211 loss: 1.9697095e-06
Iter: 212 loss: 1.9583656e-06
Iter: 213 loss: 2.01391776e-06
Iter: 214 loss: 1.95638063e-06
Iter: 215 loss: 1.94706513e-06
Iter: 216 loss: 1.94707e-06
Iter: 217 loss: 1.94208e-06
Iter: 218 loss: 1.93819392e-06
Iter: 219 loss: 1.93669121e-06
Iter: 220 loss: 1.92851712e-06
Iter: 221 loss: 1.94015274e-06
Iter: 222 loss: 1.92467041e-06
Iter: 223 loss: 1.91649178e-06
Iter: 224 loss: 2.00208183e-06
Iter: 225 loss: 1.91624167e-06
Iter: 226 loss: 1.90926312e-06
Iter: 227 loss: 1.91851927e-06
Iter: 228 loss: 1.9057544e-06
Iter: 229 loss: 1.89972525e-06
Iter: 230 loss: 1.892461e-06
Iter: 231 loss: 1.89181037e-06
Iter: 232 loss: 1.88273145e-06
Iter: 233 loss: 1.98634507e-06
Iter: 234 loss: 1.88256104e-06
Iter: 235 loss: 1.87361081e-06
Iter: 236 loss: 1.90015135e-06
Iter: 237 loss: 1.87088835e-06
Iter: 238 loss: 1.86556304e-06
Iter: 239 loss: 1.86573925e-06
Iter: 240 loss: 1.86134537e-06
Iter: 241 loss: 1.85321767e-06
Iter: 242 loss: 1.92344169e-06
Iter: 243 loss: 1.85283307e-06
Iter: 244 loss: 1.84801104e-06
Iter: 245 loss: 1.84086014e-06
Iter: 246 loss: 1.84065971e-06
Iter: 247 loss: 1.8335453e-06
Iter: 248 loss: 1.87426122e-06
Iter: 249 loss: 1.83257498e-06
Iter: 250 loss: 1.82710414e-06
Iter: 251 loss: 1.91257595e-06
Iter: 252 loss: 1.82712938e-06
Iter: 253 loss: 1.82285976e-06
Iter: 254 loss: 1.81467294e-06
Iter: 255 loss: 1.99307897e-06
Iter: 256 loss: 1.81467726e-06
Iter: 257 loss: 1.80801396e-06
Iter: 258 loss: 1.84876149e-06
Iter: 259 loss: 1.80715369e-06
Iter: 260 loss: 1.80083566e-06
Iter: 261 loss: 1.84696387e-06
Iter: 262 loss: 1.80034658e-06
Iter: 263 loss: 1.79527274e-06
Iter: 264 loss: 1.79918061e-06
Iter: 265 loss: 1.79222275e-06
Iter: 266 loss: 1.7868839e-06
Iter: 267 loss: 1.78909249e-06
Iter: 268 loss: 1.78324888e-06
Iter: 269 loss: 1.77736547e-06
Iter: 270 loss: 1.81311748e-06
Iter: 271 loss: 1.77658069e-06
Iter: 272 loss: 1.7708528e-06
Iter: 273 loss: 1.80116047e-06
Iter: 274 loss: 1.76991034e-06
Iter: 275 loss: 1.76567562e-06
Iter: 276 loss: 1.76165463e-06
Iter: 277 loss: 1.7606834e-06
Iter: 278 loss: 1.75608204e-06
Iter: 279 loss: 1.75604737e-06
Iter: 280 loss: 1.75243667e-06
Iter: 281 loss: 1.74759271e-06
Iter: 282 loss: 1.74736033e-06
Iter: 283 loss: 1.74117508e-06
Iter: 284 loss: 1.74631816e-06
Iter: 285 loss: 1.73752846e-06
Iter: 286 loss: 1.73621788e-06
Iter: 287 loss: 1.73419687e-06
Iter: 288 loss: 1.73154319e-06
Iter: 289 loss: 1.72552791e-06
Iter: 290 loss: 1.79917697e-06
Iter: 291 loss: 1.7250477e-06
Iter: 292 loss: 1.71897625e-06
Iter: 293 loss: 1.73983449e-06
Iter: 294 loss: 1.7173777e-06
Iter: 295 loss: 1.71359761e-06
Iter: 296 loss: 1.71333761e-06
Iter: 297 loss: 1.71091574e-06
Iter: 298 loss: 1.70633484e-06
Iter: 299 loss: 1.80426628e-06
Iter: 300 loss: 1.70632518e-06
Iter: 301 loss: 1.70030683e-06
Iter: 302 loss: 1.71704778e-06
Iter: 303 loss: 1.69845589e-06
Iter: 304 loss: 1.69333691e-06
Iter: 305 loss: 1.73500166e-06
Iter: 306 loss: 1.69302393e-06
Iter: 307 loss: 1.6888423e-06
Iter: 308 loss: 1.70611884e-06
Iter: 309 loss: 1.68801091e-06
Iter: 310 loss: 1.68424026e-06
Iter: 311 loss: 1.68093061e-06
Iter: 312 loss: 1.67994949e-06
Iter: 313 loss: 1.67639871e-06
Iter: 314 loss: 1.67640451e-06
Iter: 315 loss: 1.67343501e-06
Iter: 316 loss: 1.6706183e-06
Iter: 317 loss: 1.66997756e-06
Iter: 318 loss: 1.6660299e-06
Iter: 319 loss: 1.66787424e-06
Iter: 320 loss: 1.66335246e-06
Iter: 321 loss: 1.65940583e-06
Iter: 322 loss: 1.65924928e-06
Iter: 323 loss: 1.65663573e-06
Iter: 324 loss: 1.6524084e-06
Iter: 325 loss: 1.65237748e-06
Iter: 326 loss: 1.64835205e-06
Iter: 327 loss: 1.65563222e-06
Iter: 328 loss: 1.64656956e-06
Iter: 329 loss: 1.64124253e-06
Iter: 330 loss: 1.69604982e-06
Iter: 331 loss: 1.6411592e-06
Iter: 332 loss: 1.63910329e-06
Iter: 333 loss: 1.63573009e-06
Iter: 334 loss: 1.63574543e-06
Iter: 335 loss: 1.63127402e-06
Iter: 336 loss: 1.65547112e-06
Iter: 337 loss: 1.63060122e-06
Iter: 338 loss: 1.62729782e-06
Iter: 339 loss: 1.65411404e-06
Iter: 340 loss: 1.62710194e-06
Iter: 341 loss: 1.62420019e-06
Iter: 342 loss: 1.62430092e-06
Iter: 343 loss: 1.62190815e-06
Iter: 344 loss: 1.61766809e-06
Iter: 345 loss: 1.62546507e-06
Iter: 346 loss: 1.61592197e-06
Iter: 347 loss: 1.6131811e-06
Iter: 348 loss: 1.61319758e-06
Iter: 349 loss: 1.6111361e-06
Iter: 350 loss: 1.60645914e-06
Iter: 351 loss: 1.66414657e-06
Iter: 352 loss: 1.60606464e-06
Iter: 353 loss: 1.60213244e-06
Iter: 354 loss: 1.66197287e-06
Iter: 355 loss: 1.60216371e-06
Iter: 356 loss: 1.5989707e-06
Iter: 357 loss: 1.62173228e-06
Iter: 358 loss: 1.5986966e-06
Iter: 359 loss: 1.59675642e-06
Iter: 360 loss: 1.59333604e-06
Iter: 361 loss: 1.67694543e-06
Iter: 362 loss: 1.59328727e-06
Iter: 363 loss: 1.58991384e-06
Iter: 364 loss: 1.61723835e-06
Iter: 365 loss: 1.589661e-06
Iter: 366 loss: 1.58580769e-06
Iter: 367 loss: 1.59507988e-06
Iter: 368 loss: 1.58437729e-06
Iter: 369 loss: 1.58164221e-06
Iter: 370 loss: 1.57919874e-06
Iter: 371 loss: 1.57849513e-06
Iter: 372 loss: 1.57488444e-06
Iter: 373 loss: 1.60226045e-06
Iter: 374 loss: 1.57451973e-06
Iter: 375 loss: 1.57104466e-06
Iter: 376 loss: 1.58997284e-06
Iter: 377 loss: 1.5705441e-06
Iter: 378 loss: 1.56799524e-06
Iter: 379 loss: 1.57034e-06
Iter: 380 loss: 1.56649151e-06
Iter: 381 loss: 1.56401779e-06
Iter: 382 loss: 1.57660816e-06
Iter: 383 loss: 1.56351246e-06
Iter: 384 loss: 1.56106762e-06
Iter: 385 loss: 1.56569445e-06
Iter: 386 loss: 1.56007525e-06
Iter: 387 loss: 1.55717032e-06
Iter: 388 loss: 1.55886846e-06
Iter: 389 loss: 1.5552107e-06
Iter: 390 loss: 1.5528276e-06
Iter: 391 loss: 1.56725093e-06
Iter: 392 loss: 1.55247494e-06
Iter: 393 loss: 1.54960378e-06
Iter: 394 loss: 1.55842747e-06
Iter: 395 loss: 1.54879103e-06
Iter: 396 loss: 1.54668055e-06
Iter: 397 loss: 1.5433061e-06
Iter: 398 loss: 1.54329496e-06
Iter: 399 loss: 1.54042266e-06
Iter: 400 loss: 1.54043175e-06
Iter: 401 loss: 1.53733674e-06
Iter: 402 loss: 1.53993847e-06
Iter: 403 loss: 1.53550286e-06
Iter: 404 loss: 1.53299936e-06
Iter: 405 loss: 1.53043493e-06
Iter: 406 loss: 1.52998348e-06
Iter: 407 loss: 1.52661858e-06
Iter: 408 loss: 1.56460669e-06
Iter: 409 loss: 1.52659459e-06
Iter: 410 loss: 1.52335122e-06
Iter: 411 loss: 1.53650785e-06
Iter: 412 loss: 1.52262669e-06
Iter: 413 loss: 1.52046914e-06
Iter: 414 loss: 1.52105554e-06
Iter: 415 loss: 1.51895415e-06
Iter: 416 loss: 1.51634208e-06
Iter: 417 loss: 1.53407177e-06
Iter: 418 loss: 1.51604468e-06
Iter: 419 loss: 1.5135272e-06
Iter: 420 loss: 1.51451263e-06
Iter: 421 loss: 1.51179495e-06
Iter: 422 loss: 1.50881226e-06
Iter: 423 loss: 1.518354e-06
Iter: 424 loss: 1.50792187e-06
Iter: 425 loss: 1.50588312e-06
Iter: 426 loss: 1.52297616e-06
Iter: 427 loss: 1.50573328e-06
Iter: 428 loss: 1.50364679e-06
Iter: 429 loss: 1.5066563e-06
Iter: 430 loss: 1.50269148e-06
Iter: 431 loss: 1.50068e-06
Iter: 432 loss: 1.49687207e-06
Iter: 433 loss: 1.57895204e-06
Iter: 434 loss: 1.49685661e-06
Iter: 435 loss: 1.49575681e-06
Iter: 436 loss: 1.4948539e-06
Iter: 437 loss: 1.49286871e-06
Iter: 438 loss: 1.49006871e-06
Iter: 439 loss: 1.4899091e-06
Iter: 440 loss: 1.48687786e-06
Iter: 441 loss: 1.49037044e-06
Iter: 442 loss: 1.48527852e-06
Iter: 443 loss: 1.48242907e-06
Iter: 444 loss: 1.50203891e-06
Iter: 445 loss: 1.48216509e-06
Iter: 446 loss: 1.4795512e-06
Iter: 447 loss: 1.49908283e-06
Iter: 448 loss: 1.47930928e-06
Iter: 449 loss: 1.47765411e-06
Iter: 450 loss: 1.47534183e-06
Iter: 451 loss: 1.47527442e-06
Iter: 452 loss: 1.47263017e-06
Iter: 453 loss: 1.50262633e-06
Iter: 454 loss: 1.47255923e-06
Iter: 455 loss: 1.47021331e-06
Iter: 456 loss: 1.47225126e-06
Iter: 457 loss: 1.46886509e-06
Iter: 458 loss: 1.46688114e-06
Iter: 459 loss: 1.4707548e-06
Iter: 460 loss: 1.46611114e-06
Iter: 461 loss: 1.46408206e-06
Iter: 462 loss: 1.48193249e-06
Iter: 463 loss: 1.46392904e-06
Iter: 464 loss: 1.46206798e-06
Iter: 465 loss: 1.46264915e-06
Iter: 466 loss: 1.46071147e-06
Iter: 467 loss: 1.45844831e-06
Iter: 468 loss: 1.45894933e-06
Iter: 469 loss: 1.45677359e-06
Iter: 470 loss: 1.45466743e-06
Iter: 471 loss: 1.47312949e-06
Iter: 472 loss: 1.45455942e-06
Iter: 473 loss: 1.45207036e-06
Iter: 474 loss: 1.45559534e-06
Iter: 475 loss: 1.45083675e-06
Iter: 476 loss: 1.44861292e-06
Iter: 477 loss: 1.44763294e-06
Iter: 478 loss: 1.4465943e-06
Iter: 479 loss: 1.4440493e-06
Iter: 480 loss: 1.44872774e-06
Iter: 481 loss: 1.44297132e-06
Iter: 482 loss: 1.44050853e-06
Iter: 483 loss: 1.44047772e-06
Iter: 484 loss: 1.43887007e-06
Iter: 485 loss: 1.43647e-06
Iter: 486 loss: 1.43638363e-06
Iter: 487 loss: 1.43453599e-06
Iter: 488 loss: 1.45699937e-06
Iter: 489 loss: 1.43452803e-06
Iter: 490 loss: 1.43225009e-06
Iter: 491 loss: 1.43017132e-06
Iter: 492 loss: 1.42965246e-06
Iter: 493 loss: 1.42646604e-06
Iter: 494 loss: 1.43829436e-06
Iter: 495 loss: 1.42565705e-06
Iter: 496 loss: 1.42425165e-06
Iter: 497 loss: 1.42416309e-06
Iter: 498 loss: 1.42303054e-06
Iter: 499 loss: 1.42080739e-06
Iter: 500 loss: 1.4614443e-06
Iter: 501 loss: 1.42078886e-06
Iter: 502 loss: 1.41806549e-06
Iter: 503 loss: 1.427303e-06
Iter: 504 loss: 1.41735086e-06
Iter: 505 loss: 1.41529586e-06
Iter: 506 loss: 1.43414184e-06
Iter: 507 loss: 1.41520309e-06
Iter: 508 loss: 1.41340661e-06
Iter: 509 loss: 1.41863507e-06
Iter: 510 loss: 1.41289456e-06
Iter: 511 loss: 1.41111468e-06
Iter: 512 loss: 1.40741156e-06
Iter: 513 loss: 1.47073126e-06
Iter: 514 loss: 1.40735199e-06
Iter: 515 loss: 1.40366149e-06
Iter: 516 loss: 1.42276281e-06
Iter: 517 loss: 1.40307634e-06
Iter: 518 loss: 1.40187842e-06
Iter: 519 loss: 1.40136763e-06
Iter: 520 loss: 1.40025759e-06
Iter: 521 loss: 1.39767747e-06
Iter: 522 loss: 1.44015598e-06
Iter: 523 loss: 1.39759436e-06
Iter: 524 loss: 1.39517761e-06
Iter: 525 loss: 1.40894872e-06
Iter: 526 loss: 1.3948503e-06
Iter: 527 loss: 1.39245788e-06
Iter: 528 loss: 1.40841871e-06
Iter: 529 loss: 1.39216286e-06
Iter: 530 loss: 1.39090457e-06
Iter: 531 loss: 1.3895891e-06
Iter: 532 loss: 1.38935661e-06
Iter: 533 loss: 1.38766904e-06
Iter: 534 loss: 1.38760549e-06
Iter: 535 loss: 1.38637165e-06
Iter: 536 loss: 1.38540713e-06
Iter: 537 loss: 1.38503515e-06
Iter: 538 loss: 1.38341363e-06
Iter: 539 loss: 1.3828826e-06
Iter: 540 loss: 1.38199653e-06
Iter: 541 loss: 1.37989252e-06
Iter: 542 loss: 1.41347118e-06
Iter: 543 loss: 1.37987809e-06
Iter: 544 loss: 1.37819256e-06
Iter: 545 loss: 1.37911411e-06
Iter: 546 loss: 1.37705103e-06
Iter: 547 loss: 1.37497352e-06
Iter: 548 loss: 1.37542042e-06
Iter: 549 loss: 1.3734865e-06
Iter: 550 loss: 1.37066286e-06
Iter: 551 loss: 1.37279926e-06
Iter: 552 loss: 1.36888593e-06
Iter: 553 loss: 1.36724157e-06
Iter: 554 loss: 1.36714061e-06
Iter: 555 loss: 1.36555695e-06
Iter: 556 loss: 1.36768426e-06
Iter: 557 loss: 1.36470646e-06
Iter: 558 loss: 1.36317294e-06
Iter: 559 loss: 1.36120275e-06
Iter: 560 loss: 1.36110202e-06
Iter: 561 loss: 1.35918617e-06
Iter: 562 loss: 1.35918185e-06
Iter: 563 loss: 1.35748337e-06
Iter: 564 loss: 1.357781e-06
Iter: 565 loss: 1.35620485e-06
Iter: 566 loss: 1.35471339e-06
Iter: 567 loss: 1.36353015e-06
Iter: 568 loss: 1.3545349e-06
Iter: 569 loss: 1.35272376e-06
Iter: 570 loss: 1.35520168e-06
Iter: 571 loss: 1.35185724e-06
Iter: 572 loss: 1.3505437e-06
Iter: 573 loss: 1.34888353e-06
Iter: 574 loss: 1.34870072e-06
Iter: 575 loss: 1.34698416e-06
Iter: 576 loss: 1.36960466e-06
Iter: 577 loss: 1.34692345e-06
Iter: 578 loss: 1.34487868e-06
Iter: 579 loss: 1.34715128e-06
Iter: 580 loss: 1.34382992e-06
Iter: 581 loss: 1.34201412e-06
Iter: 582 loss: 1.34184188e-06
Iter: 583 loss: 1.34056427e-06
Iter: 584 loss: 1.33846015e-06
Iter: 585 loss: 1.34998231e-06
Iter: 586 loss: 1.33814319e-06
Iter: 587 loss: 1.3362843e-06
Iter: 588 loss: 1.3429551e-06
Iter: 589 loss: 1.33579329e-06
Iter: 590 loss: 1.33389733e-06
Iter: 591 loss: 1.34616039e-06
Iter: 592 loss: 1.33372623e-06
Iter: 593 loss: 1.33226843e-06
Iter: 594 loss: 1.33063145e-06
Iter: 595 loss: 1.33038429e-06
Iter: 596 loss: 1.32832156e-06
Iter: 597 loss: 1.33064191e-06
Iter: 598 loss: 1.32717514e-06
Iter: 599 loss: 1.3251115e-06
Iter: 600 loss: 1.32504897e-06
Iter: 601 loss: 1.32366483e-06
Iter: 602 loss: 1.32313119e-06
Iter: 603 loss: 1.32229638e-06
Iter: 604 loss: 1.32095101e-06
Iter: 605 loss: 1.32096307e-06
Iter: 606 loss: 1.31983882e-06
Iter: 607 loss: 1.31736272e-06
Iter: 608 loss: 1.35494111e-06
Iter: 609 loss: 1.3172546e-06
Iter: 610 loss: 1.315193e-06
Iter: 611 loss: 1.32345485e-06
Iter: 612 loss: 1.31465958e-06
Iter: 613 loss: 1.31293359e-06
Iter: 614 loss: 1.33773108e-06
Iter: 615 loss: 1.31296099e-06
Iter: 616 loss: 1.31137585e-06
Iter: 617 loss: 1.310843e-06
Iter: 618 loss: 1.30989906e-06
Iter: 619 loss: 1.30821581e-06
Iter: 620 loss: 1.30592832e-06
Iter: 621 loss: 1.30585795e-06
Iter: 622 loss: 1.30410558e-06
Iter: 623 loss: 1.30403703e-06
Iter: 624 loss: 1.30241597e-06
Iter: 625 loss: 1.30992544e-06
Iter: 626 loss: 1.30202966e-06
Iter: 627 loss: 1.30064018e-06
Iter: 628 loss: 1.29857813e-06
Iter: 629 loss: 1.2985455e-06
Iter: 630 loss: 1.2963651e-06
Iter: 631 loss: 1.30935314e-06
Iter: 632 loss: 1.29603575e-06
Iter: 633 loss: 1.29437421e-06
Iter: 634 loss: 1.30986768e-06
Iter: 635 loss: 1.29428395e-06
Iter: 636 loss: 1.29293983e-06
Iter: 637 loss: 1.29609089e-06
Iter: 638 loss: 1.2924778e-06
Iter: 639 loss: 1.2909577e-06
Iter: 640 loss: 1.29217074e-06
Iter: 641 loss: 1.29006457e-06
Iter: 642 loss: 1.28818738e-06
Iter: 643 loss: 1.29985824e-06
Iter: 644 loss: 1.28795853e-06
Iter: 645 loss: 1.28680858e-06
Iter: 646 loss: 1.2860412e-06
Iter: 647 loss: 1.28555212e-06
Iter: 648 loss: 1.28397164e-06
Iter: 649 loss: 1.28812565e-06
Iter: 650 loss: 1.2833957e-06
Iter: 651 loss: 1.28141573e-06
Iter: 652 loss: 1.29928947e-06
Iter: 653 loss: 1.28134729e-06
Iter: 654 loss: 1.28037345e-06
Iter: 655 loss: 1.27857811e-06
Iter: 656 loss: 1.31769582e-06
Iter: 657 loss: 1.27857402e-06
Iter: 658 loss: 1.27637941e-06
Iter: 659 loss: 1.28083457e-06
Iter: 660 loss: 1.27556939e-06
Iter: 661 loss: 1.2745013e-06
Iter: 662 loss: 1.2742704e-06
Iter: 663 loss: 1.27314581e-06
Iter: 664 loss: 1.27157875e-06
Iter: 665 loss: 1.27155431e-06
Iter: 666 loss: 1.26987698e-06
Iter: 667 loss: 1.27029102e-06
Iter: 668 loss: 1.26864938e-06
Iter: 669 loss: 1.26690031e-06
Iter: 670 loss: 1.28823785e-06
Iter: 671 loss: 1.26689156e-06
Iter: 672 loss: 1.26505472e-06
Iter: 673 loss: 1.26968496e-06
Iter: 674 loss: 1.26441728e-06
Iter: 675 loss: 1.26323778e-06
Iter: 676 loss: 1.26842485e-06
Iter: 677 loss: 1.26297527e-06
Iter: 678 loss: 1.2616315e-06
Iter: 679 loss: 1.26311647e-06
Iter: 680 loss: 1.26087593e-06
Iter: 681 loss: 1.25938982e-06
Iter: 682 loss: 1.26038799e-06
Iter: 683 loss: 1.25847464e-06
Iter: 684 loss: 1.2569393e-06
Iter: 685 loss: 1.26476448e-06
Iter: 686 loss: 1.25670158e-06
Iter: 687 loss: 1.25547069e-06
Iter: 688 loss: 1.26556915e-06
Iter: 689 loss: 1.25544261e-06
Iter: 690 loss: 1.25428085e-06
Iter: 691 loss: 1.25264751e-06
Iter: 692 loss: 1.25263853e-06
Iter: 693 loss: 1.2508383e-06
Iter: 694 loss: 1.25403608e-06
Iter: 695 loss: 1.25008728e-06
Iter: 696 loss: 1.24802705e-06
Iter: 697 loss: 1.25112535e-06
Iter: 698 loss: 1.24709834e-06
Iter: 699 loss: 1.24631333e-06
Iter: 700 loss: 1.2459243e-06
Iter: 701 loss: 1.24505027e-06
Iter: 702 loss: 1.24341079e-06
Iter: 703 loss: 1.2724737e-06
Iter: 704 loss: 1.24333155e-06
Iter: 705 loss: 1.24134499e-06
Iter: 706 loss: 1.24345411e-06
Iter: 707 loss: 1.24026474e-06
Iter: 708 loss: 1.23991026e-06
Iter: 709 loss: 1.23932159e-06
Iter: 710 loss: 1.2384628e-06
Iter: 711 loss: 1.2372692e-06
Iter: 712 loss: 1.23724772e-06
Iter: 713 loss: 1.23595669e-06
Iter: 714 loss: 1.24713142e-06
Iter: 715 loss: 1.23585482e-06
Iter: 716 loss: 1.23457846e-06
Iter: 717 loss: 1.23471943e-06
Iter: 718 loss: 1.2336136e-06
Iter: 719 loss: 1.23232712e-06
Iter: 720 loss: 1.23114978e-06
Iter: 721 loss: 1.23095344e-06
Iter: 722 loss: 1.2296739e-06
Iter: 723 loss: 1.22948722e-06
Iter: 724 loss: 1.22862934e-06
Iter: 725 loss: 1.22712288e-06
Iter: 726 loss: 1.26351154e-06
Iter: 727 loss: 1.22712743e-06
Iter: 728 loss: 1.22540428e-06
Iter: 729 loss: 1.23289863e-06
Iter: 730 loss: 1.22499773e-06
Iter: 731 loss: 1.22343181e-06
Iter: 732 loss: 1.22473307e-06
Iter: 733 loss: 1.22246297e-06
Iter: 734 loss: 1.22095889e-06
Iter: 735 loss: 1.23428458e-06
Iter: 736 loss: 1.2208792e-06
Iter: 737 loss: 1.21941e-06
Iter: 738 loss: 1.22554798e-06
Iter: 739 loss: 1.21906987e-06
Iter: 740 loss: 1.21803521e-06
Iter: 741 loss: 1.21673509e-06
Iter: 742 loss: 1.21663379e-06
Iter: 743 loss: 1.21484504e-06
Iter: 744 loss: 1.21986454e-06
Iter: 745 loss: 1.21428934e-06
Iter: 746 loss: 1.21308608e-06
Iter: 747 loss: 1.21299229e-06
Iter: 748 loss: 1.21225742e-06
Iter: 749 loss: 1.21103062e-06
Iter: 750 loss: 1.21102164e-06
Iter: 751 loss: 1.20988e-06
Iter: 752 loss: 1.22510448e-06
Iter: 753 loss: 1.20984419e-06
Iter: 754 loss: 1.20879747e-06
Iter: 755 loss: 1.20741549e-06
Iter: 756 loss: 1.20735274e-06
Iter: 757 loss: 1.2058124e-06
Iter: 758 loss: 1.21231949e-06
Iter: 759 loss: 1.20546179e-06
Iter: 760 loss: 1.20412949e-06
Iter: 761 loss: 1.22216647e-06
Iter: 762 loss: 1.20412517e-06
Iter: 763 loss: 1.20331799e-06
Iter: 764 loss: 1.20160337e-06
Iter: 765 loss: 1.22858842e-06
Iter: 766 loss: 1.20154834e-06
Iter: 767 loss: 1.19973629e-06
Iter: 768 loss: 1.20625282e-06
Iter: 769 loss: 1.19928e-06
Iter: 770 loss: 1.19769516e-06
Iter: 771 loss: 1.20102391e-06
Iter: 772 loss: 1.19714991e-06
Iter: 773 loss: 1.1958191e-06
Iter: 774 loss: 1.19577112e-06
Iter: 775 loss: 1.19487174e-06
Iter: 776 loss: 1.19595757e-06
Iter: 777 loss: 1.19437232e-06
Iter: 778 loss: 1.19320339e-06
Iter: 779 loss: 1.19235574e-06
Iter: 780 loss: 1.19194397e-06
Iter: 781 loss: 1.19034814e-06
Iter: 782 loss: 1.19650053e-06
Iter: 783 loss: 1.18998241e-06
Iter: 784 loss: 1.18909247e-06
Iter: 785 loss: 1.18901039e-06
Iter: 786 loss: 1.18832918e-06
Iter: 787 loss: 1.18684216e-06
Iter: 788 loss: 1.20997288e-06
Iter: 789 loss: 1.18677121e-06
Iter: 790 loss: 1.1855293e-06
Iter: 791 loss: 1.20281493e-06
Iter: 792 loss: 1.18553908e-06
Iter: 793 loss: 1.18440926e-06
Iter: 794 loss: 1.18472076e-06
Iter: 795 loss: 1.18353398e-06
Iter: 796 loss: 1.18244031e-06
Iter: 797 loss: 1.18434173e-06
Iter: 798 loss: 1.18190894e-06
Iter: 799 loss: 1.18053617e-06
Iter: 800 loss: 1.19180709e-06
Iter: 801 loss: 1.18042271e-06
Iter: 802 loss: 1.17938373e-06
Iter: 803 loss: 1.1771574e-06
Iter: 804 loss: 1.21119865e-06
Iter: 805 loss: 1.1771042e-06
Iter: 806 loss: 1.17526167e-06
Iter: 807 loss: 1.18425726e-06
Iter: 808 loss: 1.17492141e-06
Iter: 809 loss: 1.17340505e-06
Iter: 810 loss: 1.17787374e-06
Iter: 811 loss: 1.17286891e-06
Iter: 812 loss: 1.17210936e-06
Iter: 813 loss: 1.17196987e-06
Iter: 814 loss: 1.17120976e-06
Iter: 815 loss: 1.1701e-06
Iter: 816 loss: 1.17009574e-06
Iter: 817 loss: 1.16867363e-06
Iter: 818 loss: 1.16998513e-06
Iter: 819 loss: 1.16780188e-06
Iter: 820 loss: 1.16681463e-06
Iter: 821 loss: 1.16668241e-06
Iter: 822 loss: 1.16587603e-06
Iter: 823 loss: 1.16590832e-06
Iter: 824 loss: 1.16523165e-06
Iter: 825 loss: 1.1643117e-06
Iter: 826 loss: 1.16566889e-06
Iter: 827 loss: 1.1638424e-06
Iter: 828 loss: 1.16273532e-06
Iter: 829 loss: 1.16729677e-06
Iter: 830 loss: 1.1625059e-06
Iter: 831 loss: 1.16128876e-06
Iter: 832 loss: 1.16362594e-06
Iter: 833 loss: 1.16077149e-06
Iter: 834 loss: 1.15992043e-06
Iter: 835 loss: 1.16195565e-06
Iter: 836 loss: 1.15959438e-06
Iter: 837 loss: 1.15842056e-06
Iter: 838 loss: 1.16179638e-06
Iter: 839 loss: 1.158038e-06
Iter: 840 loss: 1.15706518e-06
Iter: 841 loss: 1.15578882e-06
Iter: 842 loss: 1.15574244e-06
Iter: 843 loss: 1.15412695e-06
Iter: 844 loss: 1.15988246e-06
Iter: 845 loss: 1.15373052e-06
Iter: 846 loss: 1.15243392e-06
Iter: 847 loss: 1.16295109e-06
Iter: 848 loss: 1.15239322e-06
Iter: 849 loss: 1.15118746e-06
Iter: 850 loss: 1.15825958e-06
Iter: 851 loss: 1.15098533e-06
Iter: 852 loss: 1.15022669e-06
Iter: 853 loss: 1.14870261e-06
Iter: 854 loss: 1.17795844e-06
Iter: 855 loss: 1.14871273e-06
Iter: 856 loss: 1.14823706e-06
Iter: 857 loss: 1.14792397e-06
Iter: 858 loss: 1.14715522e-06
Iter: 859 loss: 1.14635282e-06
Iter: 860 loss: 1.1462364e-06
Iter: 861 loss: 1.1450403e-06
Iter: 862 loss: 1.14497607e-06
Iter: 863 loss: 1.14409147e-06
Iter: 864 loss: 1.14276349e-06
Iter: 865 loss: 1.14274644e-06
Iter: 866 loss: 1.14191926e-06
Iter: 867 loss: 1.14356658e-06
Iter: 868 loss: 1.14159252e-06
Iter: 869 loss: 1.1406388e-06
Iter: 870 loss: 1.14089198e-06
Iter: 871 loss: 1.13996384e-06
Iter: 872 loss: 1.13875444e-06
Iter: 873 loss: 1.15100659e-06
Iter: 874 loss: 1.13875979e-06
Iter: 875 loss: 1.1379899e-06
Iter: 876 loss: 1.13723672e-06
Iter: 877 loss: 1.13705062e-06
Iter: 878 loss: 1.13587635e-06
Iter: 879 loss: 1.1349988e-06
Iter: 880 loss: 1.1346558e-06
Iter: 881 loss: 1.13297085e-06
Iter: 882 loss: 1.15014723e-06
Iter: 883 loss: 1.13295175e-06
Iter: 884 loss: 1.13151691e-06
Iter: 885 loss: 1.14311206e-06
Iter: 886 loss: 1.13139527e-06
Iter: 887 loss: 1.13074225e-06
Iter: 888 loss: 1.12977796e-06
Iter: 889 loss: 1.12974317e-06
Iter: 890 loss: 1.12890802e-06
Iter: 891 loss: 1.12890461e-06
Iter: 892 loss: 1.12809096e-06
Iter: 893 loss: 1.12761563e-06
Iter: 894 loss: 1.12720579e-06
Iter: 895 loss: 1.12623081e-06
Iter: 896 loss: 1.12688622e-06
Iter: 897 loss: 1.12557063e-06
Iter: 898 loss: 1.12468661e-06
Iter: 899 loss: 1.13741521e-06
Iter: 900 loss: 1.1246658e-06
Iter: 901 loss: 1.12374175e-06
Iter: 902 loss: 1.12307794e-06
Iter: 903 loss: 1.12282078e-06
Iter: 904 loss: 1.1217528e-06
Iter: 905 loss: 1.13095871e-06
Iter: 906 loss: 1.12169937e-06
Iter: 907 loss: 1.12079726e-06
Iter: 908 loss: 1.12395242e-06
Iter: 909 loss: 1.12060343e-06
Iter: 910 loss: 1.1197908e-06
Iter: 911 loss: 1.11937084e-06
Iter: 912 loss: 1.11903842e-06
Iter: 913 loss: 1.11768838e-06
Iter: 914 loss: 1.11897043e-06
Iter: 915 loss: 1.11687723e-06
Iter: 916 loss: 1.11540658e-06
Iter: 917 loss: 1.1187002e-06
Iter: 918 loss: 1.11484462e-06
Iter: 919 loss: 1.1137862e-06
Iter: 920 loss: 1.11374652e-06
Iter: 921 loss: 1.11305474e-06
Iter: 922 loss: 1.11179679e-06
Iter: 923 loss: 1.11178929e-06
Iter: 924 loss: 1.11058603e-06
Iter: 925 loss: 1.1170838e-06
Iter: 926 loss: 1.11042641e-06
Iter: 927 loss: 1.10936924e-06
Iter: 928 loss: 1.12200178e-06
Iter: 929 loss: 1.10934695e-06
Iter: 930 loss: 1.10876442e-06
Iter: 931 loss: 1.1075839e-06
Iter: 932 loss: 1.12280782e-06
Iter: 933 loss: 1.10750921e-06
Iter: 934 loss: 1.10678661e-06
Iter: 935 loss: 1.10671817e-06
Iter: 936 loss: 1.10597284e-06
Iter: 937 loss: 1.10581914e-06
Iter: 938 loss: 1.10529686e-06
Iter: 939 loss: 1.10434371e-06
Iter: 940 loss: 1.10804558e-06
Iter: 941 loss: 1.10412e-06
Iter: 942 loss: 1.10310521e-06
Iter: 943 loss: 1.10816563e-06
Iter: 944 loss: 1.10294764e-06
Iter: 945 loss: 1.10229394e-06
Iter: 946 loss: 1.10117344e-06
Iter: 947 loss: 1.10118935e-06
Iter: 948 loss: 1.09988014e-06
Iter: 949 loss: 1.10888391e-06
Iter: 950 loss: 1.09971631e-06
Iter: 951 loss: 1.09859991e-06
Iter: 952 loss: 1.10147289e-06
Iter: 953 loss: 1.09826192e-06
Iter: 954 loss: 1.09732207e-06
Iter: 955 loss: 1.09733583e-06
Iter: 956 loss: 1.09671237e-06
Iter: 957 loss: 1.0953986e-06
Iter: 958 loss: 1.11339273e-06
Iter: 959 loss: 1.09529992e-06
Iter: 960 loss: 1.0939533e-06
Iter: 961 loss: 1.10558926e-06
Iter: 962 loss: 1.09390567e-06
Iter: 963 loss: 1.09289158e-06
Iter: 964 loss: 1.10532085e-06
Iter: 965 loss: 1.09287475e-06
Iter: 966 loss: 1.09238795e-06
Iter: 967 loss: 1.09119992e-06
Iter: 968 loss: 1.10062092e-06
Iter: 969 loss: 1.09099221e-06
Iter: 970 loss: 1.08987865e-06
Iter: 971 loss: 1.08989116e-06
Iter: 972 loss: 1.08874383e-06
Iter: 973 loss: 1.09148095e-06
Iter: 974 loss: 1.08837708e-06
Iter: 975 loss: 1.08762424e-06
Iter: 976 loss: 1.08887514e-06
Iter: 977 loss: 1.08722929e-06
Iter: 978 loss: 1.08624795e-06
Iter: 979 loss: 1.09170196e-06
Iter: 980 loss: 1.08605627e-06
Iter: 981 loss: 1.08535914e-06
Iter: 982 loss: 1.08457857e-06
Iter: 983 loss: 1.08442885e-06
Iter: 984 loss: 1.08322956e-06
Iter: 985 loss: 1.08394875e-06
Iter: 986 loss: 1.08246581e-06
Iter: 987 loss: 1.08157633e-06
Iter: 988 loss: 1.08153949e-06
Iter: 989 loss: 1.08079462e-06
Iter: 990 loss: 1.08317647e-06
Iter: 991 loss: 1.08064091e-06
Iter: 992 loss: 1.07997221e-06
Iter: 993 loss: 1.0795909e-06
Iter: 994 loss: 1.07927735e-06
Iter: 995 loss: 1.07820915e-06
Iter: 996 loss: 1.08039171e-06
Iter: 997 loss: 1.07774736e-06
Iter: 998 loss: 1.07681149e-06
Iter: 999 loss: 1.07681376e-06
Iter: 1000 loss: 1.07632559e-06
Iter: 1001 loss: 1.07542814e-06
Iter: 1002 loss: 1.09613302e-06
Iter: 1003 loss: 1.07543156e-06
Iter: 1004 loss: 1.07438154e-06
Iter: 1005 loss: 1.07621292e-06
Iter: 1006 loss: 1.0739011e-06
Iter: 1007 loss: 1.07286655e-06
Iter: 1008 loss: 1.07287974e-06
Iter: 1009 loss: 1.07229755e-06
Iter: 1010 loss: 1.07146627e-06
Iter: 1011 loss: 1.07143592e-06
Iter: 1012 loss: 1.07067365e-06
Iter: 1013 loss: 1.07064147e-06
Iter: 1014 loss: 1.07003939e-06
Iter: 1015 loss: 1.06867276e-06
Iter: 1016 loss: 1.08953009e-06
Iter: 1017 loss: 1.06860728e-06
Iter: 1018 loss: 1.06744619e-06
Iter: 1019 loss: 1.07329356e-06
Iter: 1020 loss: 1.06724042e-06
Iter: 1021 loss: 1.06644825e-06
Iter: 1022 loss: 1.06644484e-06
Iter: 1023 loss: 1.0657825e-06
Iter: 1024 loss: 1.06551829e-06
Iter: 1025 loss: 1.06512334e-06
Iter: 1026 loss: 1.06421e-06
Iter: 1027 loss: 1.06660491e-06
Iter: 1028 loss: 1.06390803e-06
Iter: 1029 loss: 1.06308289e-06
Iter: 1030 loss: 1.06717812e-06
Iter: 1031 loss: 1.06293669e-06
Iter: 1032 loss: 1.06210223e-06
Iter: 1033 loss: 1.06538835e-06
Iter: 1034 loss: 1.06188463e-06
Iter: 1035 loss: 1.06123139e-06
Iter: 1036 loss: 1.06027255e-06
Iter: 1037 loss: 1.06024527e-06
Iter: 1038 loss: 1.05912773e-06
Iter: 1039 loss: 1.06626817e-06
Iter: 1040 loss: 1.05898812e-06
Iter: 1041 loss: 1.0581258e-06
Iter: 1042 loss: 1.06913376e-06
Iter: 1043 loss: 1.05813137e-06
Iter: 1044 loss: 1.05767788e-06
Iter: 1045 loss: 1.05707568e-06
Iter: 1046 loss: 1.05710342e-06
Iter: 1047 loss: 1.05607171e-06
Iter: 1048 loss: 1.06177401e-06
Iter: 1049 loss: 1.05590311e-06
Iter: 1050 loss: 1.05511845e-06
Iter: 1051 loss: 1.05461868e-06
Iter: 1052 loss: 1.05434799e-06
Iter: 1053 loss: 1.05333959e-06
Iter: 1054 loss: 1.0560434e-06
Iter: 1055 loss: 1.05303661e-06
Iter: 1056 loss: 1.05219283e-06
Iter: 1057 loss: 1.06509447e-06
Iter: 1058 loss: 1.05217839e-06
Iter: 1059 loss: 1.05150502e-06
Iter: 1060 loss: 1.05072786e-06
Iter: 1061 loss: 1.05063555e-06
Iter: 1062 loss: 1.04973731e-06
Iter: 1063 loss: 1.0547999e-06
Iter: 1064 loss: 1.04963374e-06
Iter: 1065 loss: 1.04880849e-06
Iter: 1066 loss: 1.05443689e-06
Iter: 1067 loss: 1.04874869e-06
Iter: 1068 loss: 1.04802132e-06
Iter: 1069 loss: 1.0483e-06
Iter: 1070 loss: 1.0475826e-06
Iter: 1071 loss: 1.04670607e-06
Iter: 1072 loss: 1.04639571e-06
Iter: 1073 loss: 1.04593141e-06
Iter: 1074 loss: 1.04512583e-06
Iter: 1075 loss: 1.0564554e-06
Iter: 1076 loss: 1.04511264e-06
Iter: 1077 loss: 1.04427136e-06
Iter: 1078 loss: 1.04621631e-06
Iter: 1079 loss: 1.04396122e-06
Iter: 1080 loss: 1.04339483e-06
Iter: 1081 loss: 1.04344338e-06
Iter: 1082 loss: 1.04290052e-06
Iter: 1083 loss: 1.04196647e-06
Iter: 1084 loss: 1.04868036e-06
Iter: 1085 loss: 1.04189428e-06
Iter: 1086 loss: 1.04129185e-06
Iter: 1087 loss: 1.04028436e-06
Iter: 1088 loss: 1.06431503e-06
Iter: 1089 loss: 1.0402955e-06
Iter: 1090 loss: 1.03934372e-06
Iter: 1091 loss: 1.05216327e-06
Iter: 1092 loss: 1.03935463e-06
Iter: 1093 loss: 1.03856257e-06
Iter: 1094 loss: 1.04328694e-06
Iter: 1095 loss: 1.03848356e-06
Iter: 1096 loss: 1.03795526e-06
Iter: 1097 loss: 1.03709203e-06
Iter: 1098 loss: 1.0370718e-06
Iter: 1099 loss: 1.03635796e-06
Iter: 1100 loss: 1.03636648e-06
Iter: 1101 loss: 1.03571801e-06
Iter: 1102 loss: 1.03692503e-06
Iter: 1103 loss: 1.03551895e-06
Iter: 1104 loss: 1.03482228e-06
Iter: 1105 loss: 1.03457126e-06
Iter: 1106 loss: 1.03420734e-06
Iter: 1107 loss: 1.03325078e-06
Iter: 1108 loss: 1.03547e-06
Iter: 1109 loss: 1.0328946e-06
Iter: 1110 loss: 1.03227569e-06
Iter: 1111 loss: 1.03227251e-06
Iter: 1112 loss: 1.03172033e-06
Iter: 1113 loss: 1.03127013e-06
Iter: 1114 loss: 1.03108073e-06
Iter: 1115 loss: 1.03040963e-06
Iter: 1116 loss: 1.0348765e-06
Iter: 1117 loss: 1.03037462e-06
Iter: 1118 loss: 1.02968829e-06
Iter: 1119 loss: 1.03125308e-06
Iter: 1120 loss: 1.02946751e-06
Iter: 1121 loss: 1.02885622e-06
Iter: 1122 loss: 1.0279856e-06
Iter: 1123 loss: 1.02794138e-06
Iter: 1124 loss: 1.02719446e-06
Iter: 1125 loss: 1.02718207e-06
Iter: 1126 loss: 1.02642366e-06
Iter: 1127 loss: 1.02687727e-06
Iter: 1128 loss: 1.02587637e-06
Iter: 1129 loss: 1.02521108e-06
Iter: 1130 loss: 1.02532101e-06
Iter: 1131 loss: 1.02469846e-06
Iter: 1132 loss: 1.02409e-06
Iter: 1133 loss: 1.02404965e-06
Iter: 1134 loss: 1.02350236e-06
Iter: 1135 loss: 1.02290574e-06
Iter: 1136 loss: 1.02278796e-06
Iter: 1137 loss: 1.02203649e-06
Iter: 1138 loss: 1.02439571e-06
Iter: 1139 loss: 1.02181616e-06
Iter: 1140 loss: 1.02100171e-06
Iter: 1141 loss: 1.0224602e-06
Iter: 1142 loss: 1.02059778e-06
Iter: 1143 loss: 1.01985597e-06
Iter: 1144 loss: 1.03031107e-06
Iter: 1145 loss: 1.01988689e-06
Iter: 1146 loss: 1.01936882e-06
Iter: 1147 loss: 1.01873525e-06
Iter: 1148 loss: 1.01866851e-06
Iter: 1149 loss: 1.01796331e-06
Iter: 1150 loss: 1.02744366e-06
Iter: 1151 loss: 1.01798764e-06
Iter: 1152 loss: 1.01734838e-06
Iter: 1153 loss: 1.0166608e-06
Iter: 1154 loss: 1.01655735e-06
Iter: 1155 loss: 1.01569071e-06
Iter: 1156 loss: 1.01675016e-06
Iter: 1157 loss: 1.01524461e-06
Iter: 1158 loss: 1.01454702e-06
Iter: 1159 loss: 1.01451928e-06
Iter: 1160 loss: 1.01394539e-06
Iter: 1161 loss: 1.01396301e-06
Iter: 1162 loss: 1.01347894e-06
Iter: 1163 loss: 1.01294177e-06
Iter: 1164 loss: 1.01330625e-06
Iter: 1165 loss: 1.01262276e-06
Iter: 1166 loss: 1.01200283e-06
Iter: 1167 loss: 1.01199862e-06
Iter: 1168 loss: 1.01155774e-06
Iter: 1169 loss: 1.01061778e-06
Iter: 1170 loss: 1.02616423e-06
Iter: 1171 loss: 1.01061119e-06
Iter: 1172 loss: 1.00974512e-06
Iter: 1173 loss: 1.01393698e-06
Iter: 1174 loss: 1.00957527e-06
Iter: 1175 loss: 1.00868192e-06
Iter: 1176 loss: 1.01371063e-06
Iter: 1177 loss: 1.00859506e-06
Iter: 1178 loss: 1.00782859e-06
Iter: 1179 loss: 1.01167416e-06
Iter: 1180 loss: 1.00771649e-06
Iter: 1181 loss: 1.00717875e-06
Iter: 1182 loss: 1.00661384e-06
Iter: 1183 loss: 1.00652028e-06
Iter: 1184 loss: 1.00586453e-06
Iter: 1185 loss: 1.00585703e-06
Iter: 1186 loss: 1.00538477e-06
Iter: 1187 loss: 1.00475643e-06
Iter: 1188 loss: 1.00468662e-06
Iter: 1189 loss: 1.00392072e-06
Iter: 1190 loss: 1.00729676e-06
Iter: 1191 loss: 1.00377952e-06
Iter: 1192 loss: 1.00304601e-06
Iter: 1193 loss: 1.00990064e-06
Iter: 1194 loss: 1.00302213e-06
Iter: 1195 loss: 1.0025858e-06
Iter: 1196 loss: 1.00202703e-06
Iter: 1197 loss: 1.0019877e-06
Iter: 1198 loss: 1.00126795e-06
Iter: 1199 loss: 1.0060819e-06
Iter: 1200 loss: 1.00115403e-06
Iter: 1201 loss: 1.00038619e-06
Iter: 1202 loss: 1.00382749e-06
Iter: 1203 loss: 1.00022874e-06
Iter: 1204 loss: 9.9979161e-07
Iter: 1205 loss: 9.99007625e-07
Iter: 1206 loss: 9.99040822e-07
Iter: 1207 loss: 9.98185214e-07
Iter: 1208 loss: 1.00554098e-06
Iter: 1209 loss: 9.98174528e-07
Iter: 1210 loss: 9.97498546e-07
Iter: 1211 loss: 1.00171576e-06
Iter: 1212 loss: 9.97371444e-07
Iter: 1213 loss: 9.96752647e-07
Iter: 1214 loss: 9.97270718e-07
Iter: 1215 loss: 9.9638919e-07
Iter: 1216 loss: 9.95748678e-07
Iter: 1217 loss: 9.97136e-07
Iter: 1218 loss: 9.95548817e-07
Iter: 1219 loss: 9.94822358e-07
Iter: 1220 loss: 9.98041742e-07
Iter: 1221 loss: 9.94689799e-07
Iter: 1222 loss: 9.94062248e-07
Iter: 1223 loss: 9.94383072e-07
Iter: 1224 loss: 9.93668436e-07
Iter: 1225 loss: 9.93078743e-07
Iter: 1226 loss: 9.9491e-07
Iter: 1227 loss: 9.92902e-07
Iter: 1228 loss: 9.92111723e-07
Iter: 1229 loss: 9.94644097e-07
Iter: 1230 loss: 9.91920842e-07
Iter: 1231 loss: 9.91307161e-07
Iter: 1232 loss: 9.91026127e-07
Iter: 1233 loss: 9.90748504e-07
Iter: 1234 loss: 9.90309218e-07
Iter: 1235 loss: 9.90261128e-07
Iter: 1236 loss: 9.89823e-07
Iter: 1237 loss: 9.88849706e-07
Iter: 1238 loss: 1.00507032e-06
Iter: 1239 loss: 9.88845841e-07
Iter: 1240 loss: 9.87985e-07
Iter: 1241 loss: 9.91271122e-07
Iter: 1242 loss: 9.87803105e-07
Iter: 1243 loss: 9.87111889e-07
Iter: 1244 loss: 9.91156639e-07
Iter: 1245 loss: 9.86984787e-07
Iter: 1246 loss: 9.86212171e-07
Iter: 1247 loss: 9.88961233e-07
Iter: 1248 loss: 9.85987526e-07
Iter: 1249 loss: 9.85395445e-07
Iter: 1250 loss: 9.8574e-07
Iter: 1251 loss: 9.84967073e-07
Iter: 1252 loss: 9.84295e-07
Iter: 1253 loss: 9.88265583e-07
Iter: 1254 loss: 9.84237772e-07
Iter: 1255 loss: 9.83581913e-07
Iter: 1256 loss: 9.84845e-07
Iter: 1257 loss: 9.83372843e-07
Iter: 1258 loss: 9.82705387e-07
Iter: 1259 loss: 9.82871143e-07
Iter: 1260 loss: 9.82259e-07
Iter: 1261 loss: 9.8167186e-07
Iter: 1262 loss: 9.86342798e-07
Iter: 1263 loss: 9.81631274e-07
Iter: 1264 loss: 9.81005769e-07
Iter: 1265 loss: 9.82599204e-07
Iter: 1266 loss: 9.80791e-07
Iter: 1267 loss: 9.8026419e-07
Iter: 1268 loss: 9.79791594e-07
Iter: 1269 loss: 9.79692e-07
Iter: 1270 loss: 9.79142e-07
Iter: 1271 loss: 9.79133461e-07
Iter: 1272 loss: 9.78622666e-07
Iter: 1273 loss: 9.78037292e-07
Iter: 1274 loss: 9.7800671e-07
Iter: 1275 loss: 9.77302307e-07
Iter: 1276 loss: 9.77121e-07
Iter: 1277 loss: 9.76698743e-07
Iter: 1278 loss: 9.76096885e-07
Iter: 1279 loss: 9.76091428e-07
Iter: 1280 loss: 9.754541e-07
Iter: 1281 loss: 9.76210458e-07
Iter: 1282 loss: 9.75155672e-07
Iter: 1283 loss: 9.74556883e-07
Iter: 1284 loss: 9.7493e-07
Iter: 1285 loss: 9.74211275e-07
Iter: 1286 loss: 9.73550755e-07
Iter: 1287 loss: 9.79204287e-07
Iter: 1288 loss: 9.73545866e-07
Iter: 1289 loss: 9.73025863e-07
Iter: 1290 loss: 9.73322358e-07
Iter: 1291 loss: 9.72665475e-07
Iter: 1292 loss: 9.71999e-07
Iter: 1293 loss: 9.72492103e-07
Iter: 1294 loss: 9.71582381e-07
Iter: 1295 loss: 9.71013378e-07
Iter: 1296 loss: 9.78755224e-07
Iter: 1297 loss: 9.7102e-07
Iter: 1298 loss: 9.70506562e-07
Iter: 1299 loss: 9.70654128e-07
Iter: 1300 loss: 9.70117753e-07
Iter: 1301 loss: 9.69490657e-07
Iter: 1302 loss: 9.69439157e-07
Iter: 1303 loss: 9.68975e-07
Iter: 1304 loss: 9.68511472e-07
Iter: 1305 loss: 9.68478616e-07
Iter: 1306 loss: 9.68045e-07
Iter: 1307 loss: 9.67302753e-07
Iter: 1308 loss: 9.82164693e-07
Iter: 1309 loss: 9.67293659e-07
Iter: 1310 loss: 9.66516495e-07
Iter: 1311 loss: 9.6835447e-07
Iter: 1312 loss: 9.66215111e-07
Iter: 1313 loss: 9.65649633e-07
Iter: 1314 loss: 9.65629e-07
Iter: 1315 loss: 9.65108e-07
Iter: 1316 loss: 9.65382e-07
Iter: 1317 loss: 9.64709443e-07
Iter: 1318 loss: 9.64192282e-07
Iter: 1319 loss: 9.64361902e-07
Iter: 1320 loss: 9.63801654e-07
Iter: 1321 loss: 9.62918421e-07
Iter: 1322 loss: 9.669e-07
Iter: 1323 loss: 9.62780632e-07
Iter: 1324 loss: 9.62104536e-07
Iter: 1325 loss: 9.63431489e-07
Iter: 1326 loss: 9.61808155e-07
Iter: 1327 loss: 9.61257228e-07
Iter: 1328 loss: 9.62793e-07
Iter: 1329 loss: 9.61032356e-07
Iter: 1330 loss: 9.60576244e-07
Iter: 1331 loss: 9.64711489e-07
Iter: 1332 loss: 9.60532475e-07
Iter: 1333 loss: 9.60060561e-07
Iter: 1334 loss: 9.59470754e-07
Iter: 1335 loss: 9.59390718e-07
Iter: 1336 loss: 9.58694272e-07
Iter: 1337 loss: 9.61471414e-07
Iter: 1338 loss: 9.58571491e-07
Iter: 1339 loss: 9.58014084e-07
Iter: 1340 loss: 9.64643732e-07
Iter: 1341 loss: 9.58011128e-07
Iter: 1342 loss: 9.57555585e-07
Iter: 1343 loss: 9.56788e-07
Iter: 1344 loss: 9.73265e-07
Iter: 1345 loss: 9.56738859e-07
Iter: 1346 loss: 9.55939868e-07
Iter: 1347 loss: 9.58835358e-07
Iter: 1348 loss: 9.55725e-07
Iter: 1349 loss: 9.55171686e-07
Iter: 1350 loss: 9.55152359e-07
Iter: 1351 loss: 9.54708071e-07
Iter: 1352 loss: 9.54343932e-07
Iter: 1353 loss: 9.54258098e-07
Iter: 1354 loss: 9.53659423e-07
Iter: 1355 loss: 9.555215e-07
Iter: 1356 loss: 9.53531639e-07
Iter: 1357 loss: 9.52775508e-07
Iter: 1358 loss: 9.54597681e-07
Iter: 1359 loss: 9.52509936e-07
Iter: 1360 loss: 9.51890684e-07
Iter: 1361 loss: 9.52736741e-07
Iter: 1362 loss: 9.51607149e-07
Iter: 1363 loss: 9.50974425e-07
Iter: 1364 loss: 9.5351362e-07
Iter: 1365 loss: 9.50823448e-07
Iter: 1366 loss: 9.50230799e-07
Iter: 1367 loss: 9.54712846e-07
Iter: 1368 loss: 9.50194817e-07
Iter: 1369 loss: 9.49741093e-07
Iter: 1370 loss: 9.49614332e-07
Iter: 1371 loss: 9.49379e-07
Iter: 1372 loss: 9.48794366e-07
Iter: 1373 loss: 9.50619e-07
Iter: 1374 loss: 9.48659647e-07
Iter: 1375 loss: 9.47976105e-07
Iter: 1376 loss: 9.51057473e-07
Iter: 1377 loss: 9.47808871e-07
Iter: 1378 loss: 9.47405056e-07
Iter: 1379 loss: 9.46488171e-07
Iter: 1380 loss: 9.62043828e-07
Iter: 1381 loss: 9.46486807e-07
Iter: 1382 loss: 9.45625857e-07
Iter: 1383 loss: 9.5513451e-07
Iter: 1384 loss: 9.45554177e-07
Iter: 1385 loss: 9.44869043e-07
Iter: 1386 loss: 9.51545303e-07
Iter: 1387 loss: 9.44870749e-07
Iter: 1388 loss: 9.44448232e-07
Iter: 1389 loss: 9.43925954e-07
Iter: 1390 loss: 9.43835744e-07
Iter: 1391 loss: 9.43274586e-07
Iter: 1392 loss: 9.49328296e-07
Iter: 1393 loss: 9.43266343e-07
Iter: 1394 loss: 9.42660677e-07
Iter: 1395 loss: 9.42604743e-07
Iter: 1396 loss: 9.42147039e-07
Iter: 1397 loss: 9.41501412e-07
Iter: 1398 loss: 9.43278337e-07
Iter: 1399 loss: 9.41241638e-07
Iter: 1400 loss: 9.40609425e-07
Iter: 1401 loss: 9.45907686e-07
Iter: 1402 loss: 9.40575205e-07
Iter: 1403 loss: 9.40066968e-07
Iter: 1404 loss: 9.40547238e-07
Iter: 1405 loss: 9.39743757e-07
Iter: 1406 loss: 9.39051233e-07
Iter: 1407 loss: 9.39711128e-07
Iter: 1408 loss: 9.38654296e-07
Iter: 1409 loss: 9.38226435e-07
Iter: 1410 loss: 9.38233484e-07
Iter: 1411 loss: 9.37781465e-07
Iter: 1412 loss: 9.37239065e-07
Iter: 1413 loss: 9.37176196e-07
Iter: 1414 loss: 9.36583319e-07
Iter: 1415 loss: 9.36930064e-07
Iter: 1416 loss: 9.3617291e-07
Iter: 1417 loss: 9.35442e-07
Iter: 1418 loss: 9.40041e-07
Iter: 1419 loss: 9.35387789e-07
Iter: 1420 loss: 9.34659511e-07
Iter: 1421 loss: 9.3841561e-07
Iter: 1422 loss: 9.34586296e-07
Iter: 1423 loss: 9.34190552e-07
Iter: 1424 loss: 9.33782303e-07
Iter: 1425 loss: 9.33726e-07
Iter: 1426 loss: 9.33211595e-07
Iter: 1427 loss: 9.40944e-07
Iter: 1428 loss: 9.33211709e-07
Iter: 1429 loss: 9.32719331e-07
Iter: 1430 loss: 9.32455123e-07
Iter: 1431 loss: 9.32292494e-07
Iter: 1432 loss: 9.31696945e-07
Iter: 1433 loss: 9.3318954e-07
Iter: 1434 loss: 9.3152272e-07
Iter: 1435 loss: 9.31003797e-07
Iter: 1436 loss: 9.36391643e-07
Iter: 1437 loss: 9.30978956e-07
Iter: 1438 loss: 9.30500164e-07
Iter: 1439 loss: 9.30451506e-07
Iter: 1440 loss: 9.30074407e-07
Iter: 1441 loss: 9.2953195e-07
Iter: 1442 loss: 9.31189788e-07
Iter: 1443 loss: 9.29366706e-07
Iter: 1444 loss: 9.28833515e-07
Iter: 1445 loss: 9.32996443e-07
Iter: 1446 loss: 9.28805321e-07
Iter: 1447 loss: 9.2834e-07
Iter: 1448 loss: 9.27902477e-07
Iter: 1449 loss: 9.27779411e-07
Iter: 1450 loss: 9.27145265e-07
Iter: 1451 loss: 9.27750648e-07
Iter: 1452 loss: 9.26768053e-07
Iter: 1453 loss: 9.2617114e-07
Iter: 1454 loss: 9.31304953e-07
Iter: 1455 loss: 9.26131065e-07
Iter: 1456 loss: 9.25455083e-07
Iter: 1457 loss: 9.27339556e-07
Iter: 1458 loss: 9.25253119e-07
Iter: 1459 loss: 9.24831454e-07
Iter: 1460 loss: 9.24450092e-07
Iter: 1461 loss: 9.24375684e-07
Iter: 1462 loss: 9.23810717e-07
Iter: 1463 loss: 9.2380219e-07
Iter: 1464 loss: 9.23378366e-07
Iter: 1465 loss: 9.2304424e-07
Iter: 1466 loss: 9.22872061e-07
Iter: 1467 loss: 9.22297602e-07
Iter: 1468 loss: 9.2364769e-07
Iter: 1469 loss: 9.22014578e-07
Iter: 1470 loss: 9.21498724e-07
Iter: 1471 loss: 9.21520439e-07
Iter: 1472 loss: 9.21123842e-07
Iter: 1473 loss: 9.20513116e-07
Iter: 1474 loss: 9.20507716e-07
Iter: 1475 loss: 9.19890908e-07
Iter: 1476 loss: 9.26382427e-07
Iter: 1477 loss: 9.19837134e-07
Iter: 1478 loss: 9.19444e-07
Iter: 1479 loss: 9.22197955e-07
Iter: 1480 loss: 9.19355784e-07
Iter: 1481 loss: 9.19041895e-07
Iter: 1482 loss: 9.18545652e-07
Iter: 1483 loss: 9.18533829e-07
Iter: 1484 loss: 9.17859893e-07
Iter: 1485 loss: 9.18350793e-07
Iter: 1486 loss: 9.17486261e-07
Iter: 1487 loss: 9.17063403e-07
Iter: 1488 loss: 9.17005309e-07
Iter: 1489 loss: 9.16616386e-07
Iter: 1490 loss: 9.16542547e-07
Iter: 1491 loss: 9.16235763e-07
Iter: 1492 loss: 9.15766634e-07
Iter: 1493 loss: 9.15478097e-07
Iter: 1494 loss: 9.15265673e-07
Iter: 1495 loss: 9.14841337e-07
Iter: 1496 loss: 9.14806037e-07
Iter: 1497 loss: 9.14391137e-07
Iter: 1498 loss: 9.13950146e-07
Iter: 1499 loss: 9.13853683e-07
Iter: 1500 loss: 9.13326687e-07
Iter: 1501 loss: 9.14968155e-07
Iter: 1502 loss: 9.13175768e-07
Iter: 1503 loss: 9.12567771e-07
Iter: 1504 loss: 9.1754373e-07
Iter: 1505 loss: 9.12516384e-07
Iter: 1506 loss: 9.12089945e-07
Iter: 1507 loss: 9.11768382e-07
Iter: 1508 loss: 9.11631219e-07
Iter: 1509 loss: 9.11085522e-07
Iter: 1510 loss: 9.17031684e-07
Iter: 1511 loss: 9.11056645e-07
Iter: 1512 loss: 9.10579274e-07
Iter: 1513 loss: 9.11116047e-07
Iter: 1514 loss: 9.10333483e-07
Iter: 1515 loss: 9.09754817e-07
Iter: 1516 loss: 9.09700475e-07
Iter: 1517 loss: 9.09322239e-07
Iter: 1518 loss: 9.08687639e-07
Iter: 1519 loss: 9.10546305e-07
Iter: 1520 loss: 9.08510742e-07
Iter: 1521 loss: 9.08029165e-07
Iter: 1522 loss: 9.08023253e-07
Iter: 1523 loss: 9.07565095e-07
Iter: 1524 loss: 9.07154515e-07
Iter: 1525 loss: 9.07040544e-07
Iter: 1526 loss: 9.0648814e-07
Iter: 1527 loss: 9.0712831e-07
Iter: 1528 loss: 9.0619335e-07
Iter: 1529 loss: 9.05722345e-07
Iter: 1530 loss: 9.05745253e-07
Iter: 1531 loss: 9.05365198e-07
Iter: 1532 loss: 9.05195066e-07
Iter: 1533 loss: 9.04998501e-07
Iter: 1534 loss: 9.04512945e-07
Iter: 1535 loss: 9.0460162e-07
Iter: 1536 loss: 9.04152444e-07
Iter: 1537 loss: 9.0348226e-07
Iter: 1538 loss: 9.13215217e-07
Iter: 1539 loss: 9.03502496e-07
Iter: 1540 loss: 9.03088221e-07
Iter: 1541 loss: 9.02785246e-07
Iter: 1542 loss: 9.02642228e-07
Iter: 1543 loss: 9.0227411e-07
Iter: 1544 loss: 9.02237844e-07
Iter: 1545 loss: 9.01933049e-07
Iter: 1546 loss: 9.01412648e-07
Iter: 1547 loss: 9.01418161e-07
Iter: 1548 loss: 9.0072291e-07
Iter: 1549 loss: 9.02693614e-07
Iter: 1550 loss: 9.00488885e-07
Iter: 1551 loss: 8.99955864e-07
Iter: 1552 loss: 9.01680494e-07
Iter: 1553 loss: 8.99758561e-07
Iter: 1554 loss: 8.99329848e-07
Iter: 1555 loss: 9.06205571e-07
Iter: 1556 loss: 8.993253e-07
Iter: 1557 loss: 8.99004647e-07
Iter: 1558 loss: 8.98380222e-07
Iter: 1559 loss: 9.12997677e-07
Iter: 1560 loss: 8.98392102e-07
Iter: 1561 loss: 8.97740733e-07
Iter: 1562 loss: 8.99102133e-07
Iter: 1563 loss: 8.97474e-07
Iter: 1564 loss: 8.96996198e-07
Iter: 1565 loss: 8.96987615e-07
Iter: 1566 loss: 8.96510073e-07
Iter: 1567 loss: 8.96168785e-07
Iter: 1568 loss: 8.96012693e-07
Iter: 1569 loss: 8.95417e-07
Iter: 1570 loss: 8.96990684e-07
Iter: 1571 loss: 8.95207791e-07
Iter: 1572 loss: 8.94778907e-07
Iter: 1573 loss: 8.94782602e-07
Iter: 1574 loss: 8.94454217e-07
Iter: 1575 loss: 8.93894196e-07
Iter: 1576 loss: 8.93903916e-07
Iter: 1577 loss: 8.93436322e-07
Iter: 1578 loss: 8.93442461e-07
Iter: 1579 loss: 8.92989533e-07
Iter: 1580 loss: 8.92603452e-07
Iter: 1581 loss: 8.92502783e-07
Iter: 1582 loss: 8.91886543e-07
Iter: 1583 loss: 8.92802177e-07
Iter: 1584 loss: 8.9162495e-07
Iter: 1585 loss: 8.90988531e-07
Iter: 1586 loss: 8.9339585e-07
Iter: 1587 loss: 8.90843921e-07
Iter: 1588 loss: 8.9031721e-07
Iter: 1589 loss: 8.95279868e-07
Iter: 1590 loss: 8.90295269e-07
Iter: 1591 loss: 8.89804483e-07
Iter: 1592 loss: 8.90359047e-07
Iter: 1593 loss: 8.89562102e-07
Iter: 1594 loss: 8.89126909e-07
Iter: 1595 loss: 8.88600823e-07
Iter: 1596 loss: 8.88578541e-07
Iter: 1597 loss: 8.87874876e-07
Iter: 1598 loss: 8.94246909e-07
Iter: 1599 loss: 8.87853844e-07
Iter: 1600 loss: 8.87330032e-07
Iter: 1601 loss: 8.91367563e-07
Iter: 1602 loss: 8.87257272e-07
Iter: 1603 loss: 8.8685897e-07
Iter: 1604 loss: 8.8640553e-07
Iter: 1605 loss: 8.8639058e-07
Iter: 1606 loss: 8.85949817e-07
Iter: 1607 loss: 8.85927079e-07
Iter: 1608 loss: 8.85563395e-07
Iter: 1609 loss: 8.85733471e-07
Iter: 1610 loss: 8.85297595e-07
Iter: 1611 loss: 8.8487235e-07
Iter: 1612 loss: 8.85231941e-07
Iter: 1613 loss: 8.84663677e-07
Iter: 1614 loss: 8.84037206e-07
Iter: 1615 loss: 8.86753696e-07
Iter: 1616 loss: 8.83896178e-07
Iter: 1617 loss: 8.83482699e-07
Iter: 1618 loss: 8.83400162e-07
Iter: 1619 loss: 8.83162215e-07
Iter: 1620 loss: 8.82587699e-07
Iter: 1621 loss: 8.83007658e-07
Iter: 1622 loss: 8.82270911e-07
Iter: 1623 loss: 8.81705603e-07
Iter: 1624 loss: 8.90321189e-07
Iter: 1625 loss: 8.81735e-07
Iter: 1626 loss: 8.81329356e-07
Iter: 1627 loss: 8.82920801e-07
Iter: 1628 loss: 8.81254493e-07
Iter: 1629 loss: 8.80898e-07
Iter: 1630 loss: 8.8037342e-07
Iter: 1631 loss: 8.8037109e-07
Iter: 1632 loss: 8.79647814e-07
Iter: 1633 loss: 8.82259314e-07
Iter: 1634 loss: 8.79527818e-07
Iter: 1635 loss: 8.78994797e-07
Iter: 1636 loss: 8.86808039e-07
Iter: 1637 loss: 8.78992466e-07
Iter: 1638 loss: 8.78630885e-07
Iter: 1639 loss: 8.78155049e-07
Iter: 1640 loss: 8.78138849e-07
Iter: 1641 loss: 8.77684215e-07
Iter: 1642 loss: 8.77681032e-07
Iter: 1643 loss: 8.77304899e-07
Iter: 1644 loss: 8.77438652e-07
Iter: 1645 loss: 8.77018806e-07
Iter: 1646 loss: 8.76591628e-07
Iter: 1647 loss: 8.773074e-07
Iter: 1648 loss: 8.76441447e-07
Iter: 1649 loss: 8.75978913e-07
Iter: 1650 loss: 8.79949539e-07
Iter: 1651 loss: 8.75934802e-07
Iter: 1652 loss: 8.75676847e-07
Iter: 1653 loss: 8.75010926e-07
Iter: 1654 loss: 8.84935162e-07
Iter: 1655 loss: 8.75005128e-07
Iter: 1656 loss: 8.74258376e-07
Iter: 1657 loss: 8.78055289e-07
Iter: 1658 loss: 8.7419005e-07
Iter: 1659 loss: 8.73643046e-07
Iter: 1660 loss: 8.7960268e-07
Iter: 1661 loss: 8.73633269e-07
Iter: 1662 loss: 8.73208705e-07
Iter: 1663 loss: 8.74582952e-07
Iter: 1664 loss: 8.73158911e-07
Iter: 1665 loss: 8.72792441e-07
Iter: 1666 loss: 8.72786416e-07
Iter: 1667 loss: 8.72540454e-07
Iter: 1668 loss: 8.72089117e-07
Iter: 1669 loss: 8.72598662e-07
Iter: 1670 loss: 8.71875272e-07
Iter: 1671 loss: 8.71355383e-07
Iter: 1672 loss: 8.77508114e-07
Iter: 1673 loss: 8.71369821e-07
Iter: 1674 loss: 8.70971633e-07
Iter: 1675 loss: 8.70716121e-07
Iter: 1676 loss: 8.70558665e-07
Iter: 1677 loss: 8.7017844e-07
Iter: 1678 loss: 8.739039e-07
Iter: 1679 loss: 8.70145186e-07
Iter: 1680 loss: 8.69647579e-07
Iter: 1681 loss: 8.69973803e-07
Iter: 1682 loss: 8.69328e-07
Iter: 1683 loss: 8.68956192e-07
Iter: 1684 loss: 8.69408836e-07
Iter: 1685 loss: 8.68729046e-07
Iter: 1686 loss: 8.68150323e-07
Iter: 1687 loss: 8.7230103e-07
Iter: 1688 loss: 8.68101836e-07
Iter: 1689 loss: 8.67803465e-07
Iter: 1690 loss: 8.67486278e-07
Iter: 1691 loss: 8.67428867e-07
Iter: 1692 loss: 8.66922903e-07
Iter: 1693 loss: 8.67717404e-07
Iter: 1694 loss: 8.66724747e-07
Iter: 1695 loss: 8.66280175e-07
Iter: 1696 loss: 8.66302116e-07
Iter: 1697 loss: 8.65891252e-07
Iter: 1698 loss: 8.66135565e-07
Iter: 1699 loss: 8.65667e-07
Iter: 1700 loss: 8.65244317e-07
Iter: 1701 loss: 8.65279958e-07
Iter: 1702 loss: 8.64887e-07
Iter: 1703 loss: 8.64315e-07
Iter: 1704 loss: 8.66096286e-07
Iter: 1705 loss: 8.6411859e-07
Iter: 1706 loss: 8.6372205e-07
Iter: 1707 loss: 8.63715172e-07
Iter: 1708 loss: 8.63409468e-07
Iter: 1709 loss: 8.62864e-07
Iter: 1710 loss: 8.62871275e-07
Iter: 1711 loss: 8.62403454e-07
Iter: 1712 loss: 8.69080452e-07
Iter: 1713 loss: 8.62411639e-07
Iter: 1714 loss: 8.61943704e-07
Iter: 1715 loss: 8.6251805e-07
Iter: 1716 loss: 8.61674835e-07
Iter: 1717 loss: 8.61274771e-07
Iter: 1718 loss: 8.61451952e-07
Iter: 1719 loss: 8.60975945e-07
Iter: 1720 loss: 8.60432863e-07
Iter: 1721 loss: 8.65742322e-07
Iter: 1722 loss: 8.60400121e-07
Iter: 1723 loss: 8.60114199e-07
Iter: 1724 loss: 8.59602096e-07
Iter: 1725 loss: 8.59600334e-07
Iter: 1726 loss: 8.58968065e-07
Iter: 1727 loss: 8.61435524e-07
Iter: 1728 loss: 8.58838689e-07
Iter: 1729 loss: 8.58436465e-07
Iter: 1730 loss: 8.58415888e-07
Iter: 1731 loss: 8.58157478e-07
Iter: 1732 loss: 8.57885652e-07
Iter: 1733 loss: 8.57830059e-07
Iter: 1734 loss: 8.57317957e-07
Iter: 1735 loss: 8.57552777e-07
Iter: 1736 loss: 8.56998724e-07
Iter: 1737 loss: 8.56432109e-07
Iter: 1738 loss: 8.60176101e-07
Iter: 1739 loss: 8.56375436e-07
Iter: 1740 loss: 8.5593615e-07
Iter: 1741 loss: 8.58679073e-07
Iter: 1742 loss: 8.55882604e-07
Iter: 1743 loss: 8.55512781e-07
Iter: 1744 loss: 8.55270912e-07
Iter: 1745 loss: 8.55137216e-07
Iter: 1746 loss: 8.54716632e-07
Iter: 1747 loss: 8.54736072e-07
Iter: 1748 loss: 8.54398138e-07
Iter: 1749 loss: 8.54018708e-07
Iter: 1750 loss: 8.53939866e-07
Iter: 1751 loss: 8.53549182e-07
Iter: 1752 loss: 8.56053134e-07
Iter: 1753 loss: 8.53473693e-07
Iter: 1754 loss: 8.53013375e-07
Iter: 1755 loss: 8.53972381e-07
Iter: 1756 loss: 8.52823121e-07
Iter: 1757 loss: 8.52447158e-07
Iter: 1758 loss: 8.52021685e-07
Iter: 1759 loss: 8.51964387e-07
Iter: 1760 loss: 8.51415734e-07
Iter: 1761 loss: 8.56001861e-07
Iter: 1762 loss: 8.51388336e-07
Iter: 1763 loss: 8.50829451e-07
Iter: 1764 loss: 8.53671509e-07
Iter: 1765 loss: 8.50761e-07
Iter: 1766 loss: 8.50426488e-07
Iter: 1767 loss: 8.50439392e-07
Iter: 1768 loss: 8.5012897e-07
Iter: 1769 loss: 8.4970543e-07
Iter: 1770 loss: 8.50680578e-07
Iter: 1771 loss: 8.49531318e-07
Iter: 1772 loss: 8.4906776e-07
Iter: 1773 loss: 8.51266236e-07
Iter: 1774 loss: 8.48946172e-07
Iter: 1775 loss: 8.484609e-07
Iter: 1776 loss: 8.50238962e-07
Iter: 1777 loss: 8.48357843e-07
Iter: 1778 loss: 8.47947e-07
Iter: 1779 loss: 8.47688057e-07
Iter: 1780 loss: 8.47498086e-07
Iter: 1781 loss: 8.47050501e-07
Iter: 1782 loss: 8.47025603e-07
Iter: 1783 loss: 8.46728142e-07
Iter: 1784 loss: 8.46509124e-07
Iter: 1785 loss: 8.46432272e-07
Iter: 1786 loss: 8.46096327e-07
Iter: 1787 loss: 8.49674393e-07
Iter: 1788 loss: 8.46096555e-07
Iter: 1789 loss: 8.45754e-07
Iter: 1790 loss: 8.4525476e-07
Iter: 1791 loss: 8.45265674e-07
Iter: 1792 loss: 8.4464358e-07
Iter: 1793 loss: 8.45704221e-07
Iter: 1794 loss: 8.44396936e-07
Iter: 1795 loss: 8.43950033e-07
Iter: 1796 loss: 8.47513434e-07
Iter: 1797 loss: 8.43931e-07
Iter: 1798 loss: 8.43396947e-07
Iter: 1799 loss: 8.43896942e-07
Iter: 1800 loss: 8.43046564e-07
Iter: 1801 loss: 8.42613133e-07
Iter: 1802 loss: 8.43232442e-07
Iter: 1803 loss: 8.42416e-07
Iter: 1804 loss: 8.41944598e-07
Iter: 1805 loss: 8.4418167e-07
Iter: 1806 loss: 8.41904352e-07
Iter: 1807 loss: 8.41477572e-07
Iter: 1808 loss: 8.42424356e-07
Iter: 1809 loss: 8.41334156e-07
Iter: 1810 loss: 8.40829159e-07
Iter: 1811 loss: 8.420526e-07
Iter: 1812 loss: 8.40656412e-07
Iter: 1813 loss: 8.40222128e-07
Iter: 1814 loss: 8.41450856e-07
Iter: 1815 loss: 8.40141638e-07
Iter: 1816 loss: 8.39685072e-07
Iter: 1817 loss: 8.42193856e-07
Iter: 1818 loss: 8.39616291e-07
Iter: 1819 loss: 8.3931036e-07
Iter: 1820 loss: 8.38945482e-07
Iter: 1821 loss: 8.3890734e-07
Iter: 1822 loss: 8.38490678e-07
Iter: 1823 loss: 8.38464132e-07
Iter: 1824 loss: 8.38160076e-07
Iter: 1825 loss: 8.37673497e-07
Iter: 1826 loss: 8.3766713e-07
Iter: 1827 loss: 8.37093864e-07
Iter: 1828 loss: 8.37826121e-07
Iter: 1829 loss: 8.36822437e-07
Iter: 1830 loss: 8.36349386e-07
Iter: 1831 loss: 8.42485861e-07
Iter: 1832 loss: 8.36345293e-07
Iter: 1833 loss: 8.35890432e-07
Iter: 1834 loss: 8.37087214e-07
Iter: 1835 loss: 8.35755429e-07
Iter: 1836 loss: 8.35374919e-07
Iter: 1837 loss: 8.34917728e-07
Iter: 1838 loss: 8.34926652e-07
Iter: 1839 loss: 8.34465311e-07
Iter: 1840 loss: 8.39176209e-07
Iter: 1841 loss: 8.3445542e-07
Iter: 1842 loss: 8.34068601e-07
Iter: 1843 loss: 8.35756396e-07
Iter: 1844 loss: 8.33959746e-07
Iter: 1845 loss: 8.33618628e-07
Iter: 1846 loss: 8.33733566e-07
Iter: 1847 loss: 8.33343165e-07
Iter: 1848 loss: 8.32877504e-07
Iter: 1849 loss: 8.35365199e-07
Iter: 1850 loss: 8.32788487e-07
Iter: 1851 loss: 8.32413548e-07
Iter: 1852 loss: 8.34422167e-07
Iter: 1853 loss: 8.32333967e-07
Iter: 1854 loss: 8.32053047e-07
Iter: 1855 loss: 8.3164548e-07
Iter: 1856 loss: 8.31613761e-07
Iter: 1857 loss: 8.31181467e-07
Iter: 1858 loss: 8.31184366e-07
Iter: 1859 loss: 8.30817839e-07
Iter: 1860 loss: 8.30229453e-07
Iter: 1861 loss: 8.30228032e-07
Iter: 1862 loss: 8.29643113e-07
Iter: 1863 loss: 8.31242687e-07
Iter: 1864 loss: 8.29462351e-07
Iter: 1865 loss: 8.29000101e-07
Iter: 1866 loss: 8.32538603e-07
Iter: 1867 loss: 8.28977704e-07
Iter: 1868 loss: 8.28500902e-07
Iter: 1869 loss: 8.30576482e-07
Iter: 1870 loss: 8.28381872e-07
Iter: 1871 loss: 8.2809288e-07
Iter: 1872 loss: 8.27718964e-07
Iter: 1873 loss: 8.27687359e-07
Iter: 1874 loss: 8.27164627e-07
Iter: 1875 loss: 8.28460884e-07
Iter: 1876 loss: 8.27008e-07
Iter: 1877 loss: 8.26515532e-07
Iter: 1878 loss: 8.26538553e-07
Iter: 1879 loss: 8.26256041e-07
Iter: 1880 loss: 8.26219036e-07
Iter: 1881 loss: 8.26077269e-07
Iter: 1882 loss: 8.25690961e-07
Iter: 1883 loss: 8.27936162e-07
Iter: 1884 loss: 8.25629684e-07
Iter: 1885 loss: 8.25290385e-07
Iter: 1886 loss: 8.2548047e-07
Iter: 1887 loss: 8.25060056e-07
Iter: 1888 loss: 8.2460474e-07
Iter: 1889 loss: 8.25660152e-07
Iter: 1890 loss: 8.24454617e-07
Iter: 1891 loss: 8.24049437e-07
Iter: 1892 loss: 8.26853466e-07
Iter: 1893 loss: 8.24025619e-07
Iter: 1894 loss: 8.2368183e-07
Iter: 1895 loss: 8.23355549e-07
Iter: 1896 loss: 8.23261871e-07
Iter: 1897 loss: 8.22718789e-07
Iter: 1898 loss: 8.22745847e-07
Iter: 1899 loss: 8.22271261e-07
Iter: 1900 loss: 8.21848516e-07
Iter: 1901 loss: 8.2184448e-07
Iter: 1902 loss: 8.21409e-07
Iter: 1903 loss: 8.22986635e-07
Iter: 1904 loss: 8.21279173e-07
Iter: 1905 loss: 8.20978642e-07
Iter: 1906 loss: 8.20484161e-07
Iter: 1907 loss: 8.20483e-07
Iter: 1908 loss: 8.19910213e-07
Iter: 1909 loss: 8.23999073e-07
Iter: 1910 loss: 8.1989981e-07
Iter: 1911 loss: 8.19465527e-07
Iter: 1912 loss: 8.24230881e-07
Iter: 1913 loss: 8.19431534e-07
Iter: 1914 loss: 8.19108209e-07
Iter: 1915 loss: 8.18752e-07
Iter: 1916 loss: 8.18696776e-07
Iter: 1917 loss: 8.18330477e-07
Iter: 1918 loss: 8.18312174e-07
Iter: 1919 loss: 8.17982709e-07
Iter: 1920 loss: 8.17768921e-07
Iter: 1921 loss: 8.1767547e-07
Iter: 1922 loss: 8.17245848e-07
Iter: 1923 loss: 8.19832394e-07
Iter: 1924 loss: 8.17212367e-07
Iter: 1925 loss: 8.16865509e-07
Iter: 1926 loss: 8.18165518e-07
Iter: 1927 loss: 8.16746478e-07
Iter: 1928 loss: 8.16397232e-07
Iter: 1929 loss: 8.16152522e-07
Iter: 1930 loss: 8.16034401e-07
Iter: 1931 loss: 8.15530257e-07
Iter: 1932 loss: 8.16551278e-07
Iter: 1933 loss: 8.15279122e-07
Iter: 1934 loss: 8.14865643e-07
Iter: 1935 loss: 8.183099e-07
Iter: 1936 loss: 8.14830628e-07
Iter: 1937 loss: 8.14338478e-07
Iter: 1938 loss: 8.16325382e-07
Iter: 1939 loss: 8.14231896e-07
Iter: 1940 loss: 8.13943245e-07
Iter: 1941 loss: 8.13482814e-07
Iter: 1942 loss: 8.13487e-07
Iter: 1943 loss: 8.13025224e-07
Iter: 1944 loss: 8.15433737e-07
Iter: 1945 loss: 8.12935127e-07
Iter: 1946 loss: 8.12505505e-07
Iter: 1947 loss: 8.18387093e-07
Iter: 1948 loss: 8.12512781e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi0.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.2
+ date
Sat Nov  7 14:08:16 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.2/500_500_500_500_1 --optimizer lbfgs --function f2 --psi 2 --alpha 1.2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3f6e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3ff9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3efb400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3f10378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3eb7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3eb7f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3eb7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3eb7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3e35e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3e262f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8993934ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89939a50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89939a1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89938ef6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89939a5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89938d4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89938d2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89938a7840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f891421a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89938a7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3e59598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c3e59d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f891417c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8914137730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89141737b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89140cb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89140dad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89140dabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89141090d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8914109400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89140eee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f891408c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8914040400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8914076bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89140408c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89140402f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 2.87068906e-05
Iter: 2 loss: 2.60392408e-05
Iter: 3 loss: 2.43158211e-05
Iter: 4 loss: 2.32798957e-05
Iter: 5 loss: 2.03043692e-05
Iter: 6 loss: 4.85883393e-05
Iter: 7 loss: 2.01882776e-05
Iter: 8 loss: 1.80634088e-05
Iter: 9 loss: 1.96660603e-05
Iter: 10 loss: 1.67694197e-05
Iter: 11 loss: 1.53253604e-05
Iter: 12 loss: 3.48590074e-05
Iter: 13 loss: 1.53184665e-05
Iter: 14 loss: 1.44501118e-05
Iter: 15 loss: 1.66159589e-05
Iter: 16 loss: 1.41440141e-05
Iter: 17 loss: 1.33076483e-05
Iter: 18 loss: 1.41067212e-05
Iter: 19 loss: 1.28310294e-05
Iter: 20 loss: 1.19809638e-05
Iter: 21 loss: 1.28771371e-05
Iter: 22 loss: 1.15101675e-05
Iter: 23 loss: 1.07511505e-05
Iter: 24 loss: 2.07725952e-05
Iter: 25 loss: 1.07469259e-05
Iter: 26 loss: 1.00702937e-05
Iter: 27 loss: 1.04402216e-05
Iter: 28 loss: 9.62598915e-06
Iter: 29 loss: 9.04909939e-06
Iter: 30 loss: 9.83196e-06
Iter: 31 loss: 8.76027752e-06
Iter: 32 loss: 8.3165869e-06
Iter: 33 loss: 1.49058778e-05
Iter: 34 loss: 8.31626858e-06
Iter: 35 loss: 7.95653887e-06
Iter: 36 loss: 7.85788689e-06
Iter: 37 loss: 7.63687603e-06
Iter: 38 loss: 7.23390713e-06
Iter: 39 loss: 7.86483361e-06
Iter: 40 loss: 7.04486138e-06
Iter: 41 loss: 6.69752899e-06
Iter: 42 loss: 8.293272e-06
Iter: 43 loss: 6.63221545e-06
Iter: 44 loss: 6.33747732e-06
Iter: 45 loss: 6.873026e-06
Iter: 46 loss: 6.20998435e-06
Iter: 47 loss: 6.03609851e-06
Iter: 48 loss: 6.0275388e-06
Iter: 49 loss: 5.85880161e-06
Iter: 50 loss: 6.16297075e-06
Iter: 51 loss: 5.78568415e-06
Iter: 52 loss: 5.65534719e-06
Iter: 53 loss: 5.75255899e-06
Iter: 54 loss: 5.57565909e-06
Iter: 55 loss: 5.38520362e-06
Iter: 56 loss: 6.52918334e-06
Iter: 57 loss: 5.36158495e-06
Iter: 58 loss: 5.25308906e-06
Iter: 59 loss: 5.17043463e-06
Iter: 60 loss: 5.13539726e-06
Iter: 61 loss: 5.00021724e-06
Iter: 62 loss: 5.9747681e-06
Iter: 63 loss: 4.98856934e-06
Iter: 64 loss: 4.86708086e-06
Iter: 65 loss: 5.425567e-06
Iter: 66 loss: 4.84421e-06
Iter: 67 loss: 4.74763783e-06
Iter: 68 loss: 5.04101354e-06
Iter: 69 loss: 4.71885051e-06
Iter: 70 loss: 4.63856395e-06
Iter: 71 loss: 4.74264198e-06
Iter: 72 loss: 4.59766125e-06
Iter: 73 loss: 4.5075144e-06
Iter: 74 loss: 4.53402708e-06
Iter: 75 loss: 4.44293437e-06
Iter: 76 loss: 4.35302081e-06
Iter: 77 loss: 4.353e-06
Iter: 78 loss: 4.27967188e-06
Iter: 79 loss: 4.21059303e-06
Iter: 80 loss: 4.19364733e-06
Iter: 81 loss: 4.09838412e-06
Iter: 82 loss: 4.31805211e-06
Iter: 83 loss: 4.06283561e-06
Iter: 84 loss: 3.97592976e-06
Iter: 85 loss: 4.09477479e-06
Iter: 86 loss: 3.93233768e-06
Iter: 87 loss: 3.86544798e-06
Iter: 88 loss: 3.86543252e-06
Iter: 89 loss: 3.80922893e-06
Iter: 90 loss: 4.24242899e-06
Iter: 91 loss: 3.80500342e-06
Iter: 92 loss: 3.76961339e-06
Iter: 93 loss: 3.70290059e-06
Iter: 94 loss: 5.16306545e-06
Iter: 95 loss: 3.7027753e-06
Iter: 96 loss: 3.65861479e-06
Iter: 97 loss: 3.65403184e-06
Iter: 98 loss: 3.61746288e-06
Iter: 99 loss: 3.55883185e-06
Iter: 100 loss: 3.55832526e-06
Iter: 101 loss: 3.50225127e-06
Iter: 102 loss: 3.59188198e-06
Iter: 103 loss: 3.47625109e-06
Iter: 104 loss: 3.43527154e-06
Iter: 105 loss: 3.4317768e-06
Iter: 106 loss: 3.40475617e-06
Iter: 107 loss: 3.35355753e-06
Iter: 108 loss: 4.44540956e-06
Iter: 109 loss: 3.35332629e-06
Iter: 110 loss: 3.30083321e-06
Iter: 111 loss: 3.53466089e-06
Iter: 112 loss: 3.2905109e-06
Iter: 113 loss: 3.25036945e-06
Iter: 114 loss: 3.51594258e-06
Iter: 115 loss: 3.24625671e-06
Iter: 116 loss: 3.20888739e-06
Iter: 117 loss: 3.34960441e-06
Iter: 118 loss: 3.199817e-06
Iter: 119 loss: 3.17073227e-06
Iter: 120 loss: 3.16164187e-06
Iter: 121 loss: 3.14445379e-06
Iter: 122 loss: 3.10992436e-06
Iter: 123 loss: 3.28918941e-06
Iter: 124 loss: 3.10442692e-06
Iter: 125 loss: 3.07166829e-06
Iter: 126 loss: 3.22088681e-06
Iter: 127 loss: 3.06545235e-06
Iter: 128 loss: 3.04174159e-06
Iter: 129 loss: 3.17368927e-06
Iter: 130 loss: 3.03828688e-06
Iter: 131 loss: 3.01067439e-06
Iter: 132 loss: 3.04353534e-06
Iter: 133 loss: 2.99611202e-06
Iter: 134 loss: 2.9734565e-06
Iter: 135 loss: 2.97551833e-06
Iter: 136 loss: 2.95589371e-06
Iter: 137 loss: 2.93075732e-06
Iter: 138 loss: 3.22572669e-06
Iter: 139 loss: 2.93030553e-06
Iter: 140 loss: 2.9076441e-06
Iter: 141 loss: 2.9202813e-06
Iter: 142 loss: 2.89286481e-06
Iter: 143 loss: 2.87017269e-06
Iter: 144 loss: 2.85358919e-06
Iter: 145 loss: 2.84559383e-06
Iter: 146 loss: 2.83594727e-06
Iter: 147 loss: 2.83035752e-06
Iter: 148 loss: 2.81652501e-06
Iter: 149 loss: 2.80251493e-06
Iter: 150 loss: 2.79970664e-06
Iter: 151 loss: 2.77722575e-06
Iter: 152 loss: 2.7746546e-06
Iter: 153 loss: 2.75837328e-06
Iter: 154 loss: 2.73137812e-06
Iter: 155 loss: 2.87461171e-06
Iter: 156 loss: 2.72715147e-06
Iter: 157 loss: 2.708279e-06
Iter: 158 loss: 2.9180851e-06
Iter: 159 loss: 2.70796636e-06
Iter: 160 loss: 2.69063321e-06
Iter: 161 loss: 2.69908764e-06
Iter: 162 loss: 2.67889482e-06
Iter: 163 loss: 2.66180723e-06
Iter: 164 loss: 2.68787335e-06
Iter: 165 loss: 2.65365816e-06
Iter: 166 loss: 2.64024675e-06
Iter: 167 loss: 2.79919595e-06
Iter: 168 loss: 2.64003756e-06
Iter: 169 loss: 2.6237135e-06
Iter: 170 loss: 2.6161083e-06
Iter: 171 loss: 2.60806019e-06
Iter: 172 loss: 2.59475951e-06
Iter: 173 loss: 2.59668673e-06
Iter: 174 loss: 2.58474256e-06
Iter: 175 loss: 2.57051556e-06
Iter: 176 loss: 2.57040392e-06
Iter: 177 loss: 2.55839814e-06
Iter: 178 loss: 2.54818951e-06
Iter: 179 loss: 2.54487486e-06
Iter: 180 loss: 2.53215899e-06
Iter: 181 loss: 2.55149803e-06
Iter: 182 loss: 2.52621453e-06
Iter: 183 loss: 2.51074221e-06
Iter: 184 loss: 2.65650374e-06
Iter: 185 loss: 2.5101856e-06
Iter: 186 loss: 2.49825325e-06
Iter: 187 loss: 2.51214283e-06
Iter: 188 loss: 2.49196091e-06
Iter: 189 loss: 2.47771254e-06
Iter: 190 loss: 2.51764095e-06
Iter: 191 loss: 2.47321464e-06
Iter: 192 loss: 2.46267791e-06
Iter: 193 loss: 2.45234401e-06
Iter: 194 loss: 2.45013098e-06
Iter: 195 loss: 2.43192835e-06
Iter: 196 loss: 2.51284405e-06
Iter: 197 loss: 2.42834403e-06
Iter: 198 loss: 2.41464772e-06
Iter: 199 loss: 2.51616621e-06
Iter: 200 loss: 2.41366865e-06
Iter: 201 loss: 2.40105783e-06
Iter: 202 loss: 2.45443107e-06
Iter: 203 loss: 2.398378e-06
Iter: 204 loss: 2.38881012e-06
Iter: 205 loss: 2.39526435e-06
Iter: 206 loss: 2.38272878e-06
Iter: 207 loss: 2.37460858e-06
Iter: 208 loss: 2.37451877e-06
Iter: 209 loss: 2.36761116e-06
Iter: 210 loss: 2.35655625e-06
Iter: 211 loss: 2.35654511e-06
Iter: 212 loss: 2.3441653e-06
Iter: 213 loss: 2.35299103e-06
Iter: 214 loss: 2.33658352e-06
Iter: 215 loss: 2.32970024e-06
Iter: 216 loss: 2.3288087e-06
Iter: 217 loss: 2.32118191e-06
Iter: 218 loss: 2.31203512e-06
Iter: 219 loss: 2.31108197e-06
Iter: 220 loss: 2.29996954e-06
Iter: 221 loss: 2.31564582e-06
Iter: 222 loss: 2.29455213e-06
Iter: 223 loss: 2.28506315e-06
Iter: 224 loss: 2.28507315e-06
Iter: 225 loss: 2.27691362e-06
Iter: 226 loss: 2.28692943e-06
Iter: 227 loss: 2.27275314e-06
Iter: 228 loss: 2.26486804e-06
Iter: 229 loss: 2.2525553e-06
Iter: 230 loss: 2.25247459e-06
Iter: 231 loss: 2.23875327e-06
Iter: 232 loss: 2.30641945e-06
Iter: 233 loss: 2.2364743e-06
Iter: 234 loss: 2.2255465e-06
Iter: 235 loss: 2.28790896e-06
Iter: 236 loss: 2.22411245e-06
Iter: 237 loss: 2.21657388e-06
Iter: 238 loss: 2.30029946e-06
Iter: 239 loss: 2.21642381e-06
Iter: 240 loss: 2.20952688e-06
Iter: 241 loss: 2.21180926e-06
Iter: 242 loss: 2.20471975e-06
Iter: 243 loss: 2.19774347e-06
Iter: 244 loss: 2.27773171e-06
Iter: 245 loss: 2.1976266e-06
Iter: 246 loss: 2.19164781e-06
Iter: 247 loss: 2.18359264e-06
Iter: 248 loss: 2.18306513e-06
Iter: 249 loss: 2.17410434e-06
Iter: 250 loss: 2.23901657e-06
Iter: 251 loss: 2.17335037e-06
Iter: 252 loss: 2.1656906e-06
Iter: 253 loss: 2.16295416e-06
Iter: 254 loss: 2.15863565e-06
Iter: 255 loss: 2.15051546e-06
Iter: 256 loss: 2.27494706e-06
Iter: 257 loss: 2.15045725e-06
Iter: 258 loss: 2.14422334e-06
Iter: 259 loss: 2.15954242e-06
Iter: 260 loss: 2.14191641e-06
Iter: 261 loss: 2.1358353e-06
Iter: 262 loss: 2.12380519e-06
Iter: 263 loss: 2.3720836e-06
Iter: 264 loss: 2.12380064e-06
Iter: 265 loss: 2.12110058e-06
Iter: 266 loss: 2.11818292e-06
Iter: 267 loss: 2.11287352e-06
Iter: 268 loss: 2.10813505e-06
Iter: 269 loss: 2.10680105e-06
Iter: 270 loss: 2.10027542e-06
Iter: 271 loss: 2.09232985e-06
Iter: 272 loss: 2.09151312e-06
Iter: 273 loss: 2.0832133e-06
Iter: 274 loss: 2.17625734e-06
Iter: 275 loss: 2.08306119e-06
Iter: 276 loss: 2.07674657e-06
Iter: 277 loss: 2.14705597e-06
Iter: 278 loss: 2.07669632e-06
Iter: 279 loss: 2.07114408e-06
Iter: 280 loss: 2.07452877e-06
Iter: 281 loss: 2.06751497e-06
Iter: 282 loss: 2.06184973e-06
Iter: 283 loss: 2.11027236e-06
Iter: 284 loss: 2.06148297e-06
Iter: 285 loss: 2.05693095e-06
Iter: 286 loss: 2.04950084e-06
Iter: 287 loss: 2.04945536e-06
Iter: 288 loss: 2.04090816e-06
Iter: 289 loss: 2.0793359e-06
Iter: 290 loss: 2.03927812e-06
Iter: 291 loss: 2.03336685e-06
Iter: 292 loss: 2.07671633e-06
Iter: 293 loss: 2.03284208e-06
Iter: 294 loss: 2.02695583e-06
Iter: 295 loss: 2.0355892e-06
Iter: 296 loss: 2.02409501e-06
Iter: 297 loss: 2.01819466e-06
Iter: 298 loss: 2.05667607e-06
Iter: 299 loss: 2.01752619e-06
Iter: 300 loss: 2.01348348e-06
Iter: 301 loss: 2.00705244e-06
Iter: 302 loss: 2.00698355e-06
Iter: 303 loss: 2.0012219e-06
Iter: 304 loss: 2.00119484e-06
Iter: 305 loss: 1.99620399e-06
Iter: 306 loss: 2.00927616e-06
Iter: 307 loss: 1.99457236e-06
Iter: 308 loss: 1.99008309e-06
Iter: 309 loss: 1.98415569e-06
Iter: 310 loss: 1.98379348e-06
Iter: 311 loss: 1.9768e-06
Iter: 312 loss: 2.00003842e-06
Iter: 313 loss: 1.97487952e-06
Iter: 314 loss: 1.96653241e-06
Iter: 315 loss: 1.9731815e-06
Iter: 316 loss: 1.96161136e-06
Iter: 317 loss: 1.95437588e-06
Iter: 318 loss: 2.01914872e-06
Iter: 319 loss: 1.95402095e-06
Iter: 320 loss: 1.94852964e-06
Iter: 321 loss: 2.00020486e-06
Iter: 322 loss: 1.94828817e-06
Iter: 323 loss: 1.94371569e-06
Iter: 324 loss: 1.94771837e-06
Iter: 325 loss: 1.94109816e-06
Iter: 326 loss: 1.93742835e-06
Iter: 327 loss: 1.9922993e-06
Iter: 328 loss: 1.93744222e-06
Iter: 329 loss: 1.93447886e-06
Iter: 330 loss: 1.928036e-06
Iter: 331 loss: 2.02128649e-06
Iter: 332 loss: 1.92766515e-06
Iter: 333 loss: 1.92070502e-06
Iter: 334 loss: 1.95790381e-06
Iter: 335 loss: 1.91964227e-06
Iter: 336 loss: 1.91556819e-06
Iter: 337 loss: 1.95758321e-06
Iter: 338 loss: 1.91544586e-06
Iter: 339 loss: 1.91161416e-06
Iter: 340 loss: 1.91416166e-06
Iter: 341 loss: 1.90915694e-06
Iter: 342 loss: 1.9041571e-06
Iter: 343 loss: 1.92178709e-06
Iter: 344 loss: 1.90287483e-06
Iter: 345 loss: 1.89866432e-06
Iter: 346 loss: 1.89984803e-06
Iter: 347 loss: 1.89567368e-06
Iter: 348 loss: 1.89116531e-06
Iter: 349 loss: 1.91612526e-06
Iter: 350 loss: 1.8905597e-06
Iter: 351 loss: 1.88477179e-06
Iter: 352 loss: 1.89159789e-06
Iter: 353 loss: 1.88175011e-06
Iter: 354 loss: 1.87803062e-06
Iter: 355 loss: 1.87352191e-06
Iter: 356 loss: 1.87302703e-06
Iter: 357 loss: 1.86625925e-06
Iter: 358 loss: 1.89167872e-06
Iter: 359 loss: 1.86462512e-06
Iter: 360 loss: 1.85868134e-06
Iter: 361 loss: 1.8779001e-06
Iter: 362 loss: 1.8569848e-06
Iter: 363 loss: 1.85315162e-06
Iter: 364 loss: 1.85309091e-06
Iter: 365 loss: 1.84948306e-06
Iter: 366 loss: 1.85301656e-06
Iter: 367 loss: 1.84743033e-06
Iter: 368 loss: 1.84378371e-06
Iter: 369 loss: 1.84493888e-06
Iter: 370 loss: 1.84120063e-06
Iter: 371 loss: 1.83644397e-06
Iter: 372 loss: 1.87007674e-06
Iter: 373 loss: 1.83592306e-06
Iter: 374 loss: 1.83251473e-06
Iter: 375 loss: 1.83026293e-06
Iter: 376 loss: 1.82896144e-06
Iter: 377 loss: 1.82375982e-06
Iter: 378 loss: 1.84095302e-06
Iter: 379 loss: 1.82239773e-06
Iter: 380 loss: 1.81814949e-06
Iter: 381 loss: 1.86043951e-06
Iter: 382 loss: 1.81808309e-06
Iter: 383 loss: 1.81494397e-06
Iter: 384 loss: 1.82385475e-06
Iter: 385 loss: 1.81399764e-06
Iter: 386 loss: 1.81055839e-06
Iter: 387 loss: 1.81441692e-06
Iter: 388 loss: 1.80880863e-06
Iter: 389 loss: 1.8047773e-06
Iter: 390 loss: 1.80271718e-06
Iter: 391 loss: 1.80093298e-06
Iter: 392 loss: 1.7973033e-06
Iter: 393 loss: 1.79730159e-06
Iter: 394 loss: 1.79395261e-06
Iter: 395 loss: 1.79688857e-06
Iter: 396 loss: 1.79196763e-06
Iter: 397 loss: 1.78882647e-06
Iter: 398 loss: 1.78537482e-06
Iter: 399 loss: 1.78493167e-06
Iter: 400 loss: 1.77906236e-06
Iter: 401 loss: 1.804063e-06
Iter: 402 loss: 1.77775405e-06
Iter: 403 loss: 1.77548043e-06
Iter: 404 loss: 1.77510265e-06
Iter: 405 loss: 1.77248194e-06
Iter: 406 loss: 1.76794526e-06
Iter: 407 loss: 1.76791411e-06
Iter: 408 loss: 1.76435128e-06
Iter: 409 loss: 1.77771881e-06
Iter: 410 loss: 1.76347726e-06
Iter: 411 loss: 1.75910031e-06
Iter: 412 loss: 1.77668846e-06
Iter: 413 loss: 1.75812852e-06
Iter: 414 loss: 1.75514697e-06
Iter: 415 loss: 1.75731611e-06
Iter: 416 loss: 1.75335413e-06
Iter: 417 loss: 1.74939271e-06
Iter: 418 loss: 1.74994318e-06
Iter: 419 loss: 1.74648096e-06
Iter: 420 loss: 1.74231332e-06
Iter: 421 loss: 1.74229501e-06
Iter: 422 loss: 1.73929232e-06
Iter: 423 loss: 1.73953117e-06
Iter: 424 loss: 1.73700516e-06
Iter: 425 loss: 1.73364697e-06
Iter: 426 loss: 1.74738352e-06
Iter: 427 loss: 1.7328623e-06
Iter: 428 loss: 1.72964542e-06
Iter: 429 loss: 1.72901389e-06
Iter: 430 loss: 1.72687976e-06
Iter: 431 loss: 1.72313014e-06
Iter: 432 loss: 1.77169591e-06
Iter: 433 loss: 1.72306704e-06
Iter: 434 loss: 1.71991292e-06
Iter: 435 loss: 1.72497028e-06
Iter: 436 loss: 1.71840293e-06
Iter: 437 loss: 1.71600641e-06
Iter: 438 loss: 1.71060606e-06
Iter: 439 loss: 1.78308346e-06
Iter: 440 loss: 1.71023976e-06
Iter: 441 loss: 1.70558769e-06
Iter: 442 loss: 1.77011088e-06
Iter: 443 loss: 1.70556928e-06
Iter: 444 loss: 1.70169665e-06
Iter: 445 loss: 1.71399324e-06
Iter: 446 loss: 1.70056956e-06
Iter: 447 loss: 1.69779173e-06
Iter: 448 loss: 1.69777331e-06
Iter: 449 loss: 1.69583245e-06
Iter: 450 loss: 1.69312352e-06
Iter: 451 loss: 1.69303564e-06
Iter: 452 loss: 1.68947304e-06
Iter: 453 loss: 1.71740703e-06
Iter: 454 loss: 1.68916722e-06
Iter: 455 loss: 1.68653514e-06
Iter: 456 loss: 1.68627412e-06
Iter: 457 loss: 1.6844001e-06
Iter: 458 loss: 1.68137217e-06
Iter: 459 loss: 1.68215536e-06
Iter: 460 loss: 1.67920678e-06
Iter: 461 loss: 1.67588496e-06
Iter: 462 loss: 1.67589e-06
Iter: 463 loss: 1.67322742e-06
Iter: 464 loss: 1.67406915e-06
Iter: 465 loss: 1.67134124e-06
Iter: 466 loss: 1.66857399e-06
Iter: 467 loss: 1.67964686e-06
Iter: 468 loss: 1.66793006e-06
Iter: 469 loss: 1.66512518e-06
Iter: 470 loss: 1.6658189e-06
Iter: 471 loss: 1.66314544e-06
Iter: 472 loss: 1.65994231e-06
Iter: 473 loss: 1.6977001e-06
Iter: 474 loss: 1.65991332e-06
Iter: 475 loss: 1.65741335e-06
Iter: 476 loss: 1.65551728e-06
Iter: 477 loss: 1.6547267e-06
Iter: 478 loss: 1.65124993e-06
Iter: 479 loss: 1.65424399e-06
Iter: 480 loss: 1.6492088e-06
Iter: 481 loss: 1.64522362e-06
Iter: 482 loss: 1.65324627e-06
Iter: 483 loss: 1.6434758e-06
Iter: 484 loss: 1.64262087e-06
Iter: 485 loss: 1.64143842e-06
Iter: 486 loss: 1.63984623e-06
Iter: 487 loss: 1.63652203e-06
Iter: 488 loss: 1.69643977e-06
Iter: 489 loss: 1.63648633e-06
Iter: 490 loss: 1.6331378e-06
Iter: 491 loss: 1.64618132e-06
Iter: 492 loss: 1.63240281e-06
Iter: 493 loss: 1.62908066e-06
Iter: 494 loss: 1.65333574e-06
Iter: 495 loss: 1.62881076e-06
Iter: 496 loss: 1.62685183e-06
Iter: 497 loss: 1.62547508e-06
Iter: 498 loss: 1.62475135e-06
Iter: 499 loss: 1.62137394e-06
Iter: 500 loss: 1.63692687e-06
Iter: 501 loss: 1.62066476e-06
Iter: 502 loss: 1.61716594e-06
Iter: 503 loss: 1.63616141e-06
Iter: 504 loss: 1.6165875e-06
Iter: 505 loss: 1.61469427e-06
Iter: 506 loss: 1.61253718e-06
Iter: 507 loss: 1.61228013e-06
Iter: 508 loss: 1.60887589e-06
Iter: 509 loss: 1.63215077e-06
Iter: 510 loss: 1.60856371e-06
Iter: 511 loss: 1.60504248e-06
Iter: 512 loss: 1.6152959e-06
Iter: 513 loss: 1.60397099e-06
Iter: 514 loss: 1.60158947e-06
Iter: 515 loss: 1.60031686e-06
Iter: 516 loss: 1.59929868e-06
Iter: 517 loss: 1.5957645e-06
Iter: 518 loss: 1.61423804e-06
Iter: 519 loss: 1.59523779e-06
Iter: 520 loss: 1.59187243e-06
Iter: 521 loss: 1.60128661e-06
Iter: 522 loss: 1.59082992e-06
Iter: 523 loss: 1.58895125e-06
Iter: 524 loss: 1.61772709e-06
Iter: 525 loss: 1.58899536e-06
Iter: 526 loss: 1.58704415e-06
Iter: 527 loss: 1.58485466e-06
Iter: 528 loss: 1.58459727e-06
Iter: 529 loss: 1.58186924e-06
Iter: 530 loss: 1.58192017e-06
Iter: 531 loss: 1.57977274e-06
Iter: 532 loss: 1.57668478e-06
Iter: 533 loss: 1.60737181e-06
Iter: 534 loss: 1.57661646e-06
Iter: 535 loss: 1.57391867e-06
Iter: 536 loss: 1.58481066e-06
Iter: 537 loss: 1.57325576e-06
Iter: 538 loss: 1.57096042e-06
Iter: 539 loss: 1.5711687e-06
Iter: 540 loss: 1.56926421e-06
Iter: 541 loss: 1.5668777e-06
Iter: 542 loss: 1.56690385e-06
Iter: 543 loss: 1.56526585e-06
Iter: 544 loss: 1.56254805e-06
Iter: 545 loss: 1.56250701e-06
Iter: 546 loss: 1.55971975e-06
Iter: 547 loss: 1.5689676e-06
Iter: 548 loss: 1.55889427e-06
Iter: 549 loss: 1.55673877e-06
Iter: 550 loss: 1.55672751e-06
Iter: 551 loss: 1.5549183e-06
Iter: 552 loss: 1.55299267e-06
Iter: 553 loss: 1.55271778e-06
Iter: 554 loss: 1.54997986e-06
Iter: 555 loss: 1.55021507e-06
Iter: 556 loss: 1.54777103e-06
Iter: 557 loss: 1.54470604e-06
Iter: 558 loss: 1.58074795e-06
Iter: 559 loss: 1.54463964e-06
Iter: 560 loss: 1.5424896e-06
Iter: 561 loss: 1.56693e-06
Iter: 562 loss: 1.54240547e-06
Iter: 563 loss: 1.54081727e-06
Iter: 564 loss: 1.53780502e-06
Iter: 565 loss: 1.60417699e-06
Iter: 566 loss: 1.53778262e-06
Iter: 567 loss: 1.53487872e-06
Iter: 568 loss: 1.56011015e-06
Iter: 569 loss: 1.534641e-06
Iter: 570 loss: 1.53238454e-06
Iter: 571 loss: 1.53354699e-06
Iter: 572 loss: 1.53085125e-06
Iter: 573 loss: 1.52808889e-06
Iter: 574 loss: 1.54132726e-06
Iter: 575 loss: 1.52755945e-06
Iter: 576 loss: 1.52512962e-06
Iter: 577 loss: 1.54584586e-06
Iter: 578 loss: 1.5250024e-06
Iter: 579 loss: 1.52355517e-06
Iter: 580 loss: 1.52279802e-06
Iter: 581 loss: 1.52213477e-06
Iter: 582 loss: 1.51985387e-06
Iter: 583 loss: 1.53821691e-06
Iter: 584 loss: 1.51974564e-06
Iter: 585 loss: 1.5181156e-06
Iter: 586 loss: 1.51618815e-06
Iter: 587 loss: 1.51602239e-06
Iter: 588 loss: 1.51334689e-06
Iter: 589 loss: 1.52937446e-06
Iter: 590 loss: 1.5130355e-06
Iter: 591 loss: 1.51065433e-06
Iter: 592 loss: 1.5272351e-06
Iter: 593 loss: 1.51048812e-06
Iter: 594 loss: 1.50861752e-06
Iter: 595 loss: 1.50527376e-06
Iter: 596 loss: 1.58766591e-06
Iter: 597 loss: 1.50529058e-06
Iter: 598 loss: 1.50223718e-06
Iter: 599 loss: 1.51465747e-06
Iter: 600 loss: 1.50160656e-06
Iter: 601 loss: 1.49926973e-06
Iter: 602 loss: 1.49920561e-06
Iter: 603 loss: 1.49792777e-06
Iter: 604 loss: 1.495069e-06
Iter: 605 loss: 1.54149848e-06
Iter: 606 loss: 1.49501693e-06
Iter: 607 loss: 1.49217249e-06
Iter: 608 loss: 1.49740799e-06
Iter: 609 loss: 1.49101015e-06
Iter: 610 loss: 1.48816957e-06
Iter: 611 loss: 1.50846972e-06
Iter: 612 loss: 1.48791912e-06
Iter: 613 loss: 1.48579238e-06
Iter: 614 loss: 1.51014092e-06
Iter: 615 loss: 1.48580068e-06
Iter: 616 loss: 1.48426409e-06
Iter: 617 loss: 1.48269555e-06
Iter: 618 loss: 1.48242407e-06
Iter: 619 loss: 1.48008371e-06
Iter: 620 loss: 1.50016831e-06
Iter: 621 loss: 1.48000265e-06
Iter: 622 loss: 1.47808646e-06
Iter: 623 loss: 1.48021604e-06
Iter: 624 loss: 1.4770992e-06
Iter: 625 loss: 1.47533979e-06
Iter: 626 loss: 1.47614855e-06
Iter: 627 loss: 1.47420133e-06
Iter: 628 loss: 1.47169544e-06
Iter: 629 loss: 1.49525408e-06
Iter: 630 loss: 1.47161722e-06
Iter: 631 loss: 1.47005517e-06
Iter: 632 loss: 1.46991397e-06
Iter: 633 loss: 1.46876255e-06
Iter: 634 loss: 1.46667526e-06
Iter: 635 loss: 1.47205242e-06
Iter: 636 loss: 1.46591606e-06
Iter: 637 loss: 1.46376112e-06
Iter: 638 loss: 1.4743805e-06
Iter: 639 loss: 1.46334469e-06
Iter: 640 loss: 1.46153673e-06
Iter: 641 loss: 1.47511116e-06
Iter: 642 loss: 1.46153593e-06
Iter: 643 loss: 1.46015111e-06
Iter: 644 loss: 1.4584873e-06
Iter: 645 loss: 1.45834656e-06
Iter: 646 loss: 1.45605782e-06
Iter: 647 loss: 1.45568606e-06
Iter: 648 loss: 1.45410854e-06
Iter: 649 loss: 1.45130775e-06
Iter: 650 loss: 1.46447746e-06
Iter: 651 loss: 1.45076808e-06
Iter: 652 loss: 1.44821161e-06
Iter: 653 loss: 1.45119679e-06
Iter: 654 loss: 1.44683918e-06
Iter: 655 loss: 1.4448392e-06
Iter: 656 loss: 1.44476257e-06
Iter: 657 loss: 1.4429811e-06
Iter: 658 loss: 1.44176852e-06
Iter: 659 loss: 1.44119656e-06
Iter: 660 loss: 1.4394069e-06
Iter: 661 loss: 1.46316484e-06
Iter: 662 loss: 1.43938473e-06
Iter: 663 loss: 1.43782768e-06
Iter: 664 loss: 1.43685884e-06
Iter: 665 loss: 1.43618922e-06
Iter: 666 loss: 1.43403531e-06
Iter: 667 loss: 1.43861928e-06
Iter: 668 loss: 1.43311263e-06
Iter: 669 loss: 1.43127022e-06
Iter: 670 loss: 1.45274703e-06
Iter: 671 loss: 1.43124407e-06
Iter: 672 loss: 1.42958856e-06
Iter: 673 loss: 1.43004308e-06
Iter: 674 loss: 1.42841554e-06
Iter: 675 loss: 1.42664953e-06
Iter: 676 loss: 1.43277214e-06
Iter: 677 loss: 1.42623765e-06
Iter: 678 loss: 1.42447686e-06
Iter: 679 loss: 1.43070315e-06
Iter: 680 loss: 1.4240461e-06
Iter: 681 loss: 1.42248609e-06
Iter: 682 loss: 1.43318721e-06
Iter: 683 loss: 1.42243368e-06
Iter: 684 loss: 1.42127715e-06
Iter: 685 loss: 1.41946509e-06
Iter: 686 loss: 1.41941496e-06
Iter: 687 loss: 1.41706471e-06
Iter: 688 loss: 1.41916917e-06
Iter: 689 loss: 1.41575731e-06
Iter: 690 loss: 1.41290866e-06
Iter: 691 loss: 1.4178845e-06
Iter: 692 loss: 1.41169335e-06
Iter: 693 loss: 1.40905672e-06
Iter: 694 loss: 1.42837132e-06
Iter: 695 loss: 1.40888415e-06
Iter: 696 loss: 1.40674888e-06
Iter: 697 loss: 1.43402633e-06
Iter: 698 loss: 1.40673524e-06
Iter: 699 loss: 1.40546604e-06
Iter: 700 loss: 1.40424436e-06
Iter: 701 loss: 1.4039415e-06
Iter: 702 loss: 1.40213979e-06
Iter: 703 loss: 1.41537225e-06
Iter: 704 loss: 1.40199404e-06
Iter: 705 loss: 1.4001422e-06
Iter: 706 loss: 1.40158306e-06
Iter: 707 loss: 1.39908502e-06
Iter: 708 loss: 1.39755616e-06
Iter: 709 loss: 1.40125644e-06
Iter: 710 loss: 1.39703411e-06
Iter: 711 loss: 1.39523183e-06
Iter: 712 loss: 1.40649763e-06
Iter: 713 loss: 1.3949716e-06
Iter: 714 loss: 1.39374174e-06
Iter: 715 loss: 1.3927048e-06
Iter: 716 loss: 1.39237068e-06
Iter: 717 loss: 1.39104532e-06
Iter: 718 loss: 1.39103088e-06
Iter: 719 loss: 1.38967198e-06
Iter: 720 loss: 1.38745054e-06
Iter: 721 loss: 1.38743235e-06
Iter: 722 loss: 1.3854758e-06
Iter: 723 loss: 1.38600103e-06
Iter: 724 loss: 1.38411224e-06
Iter: 725 loss: 1.38133782e-06
Iter: 726 loss: 1.40177144e-06
Iter: 727 loss: 1.38114285e-06
Iter: 728 loss: 1.37934876e-06
Iter: 729 loss: 1.38554242e-06
Iter: 730 loss: 1.37876089e-06
Iter: 731 loss: 1.37680604e-06
Iter: 732 loss: 1.37801362e-06
Iter: 733 loss: 1.37559061e-06
Iter: 734 loss: 1.37361098e-06
Iter: 735 loss: 1.37791369e-06
Iter: 736 loss: 1.37284133e-06
Iter: 737 loss: 1.3710669e-06
Iter: 738 loss: 1.371076e-06
Iter: 739 loss: 1.36962308e-06
Iter: 740 loss: 1.36915219e-06
Iter: 741 loss: 1.36836547e-06
Iter: 742 loss: 1.36692825e-06
Iter: 743 loss: 1.37845245e-06
Iter: 744 loss: 1.36683548e-06
Iter: 745 loss: 1.36535232e-06
Iter: 746 loss: 1.36402809e-06
Iter: 747 loss: 1.36363133e-06
Iter: 748 loss: 1.36158451e-06
Iter: 749 loss: 1.37062352e-06
Iter: 750 loss: 1.36119957e-06
Iter: 751 loss: 1.3597421e-06
Iter: 752 loss: 1.37319557e-06
Iter: 753 loss: 1.35969685e-06
Iter: 754 loss: 1.3581207e-06
Iter: 755 loss: 1.35682308e-06
Iter: 756 loss: 1.35634934e-06
Iter: 757 loss: 1.35487915e-06
Iter: 758 loss: 1.3666247e-06
Iter: 759 loss: 1.35480627e-06
Iter: 760 loss: 1.35326218e-06
Iter: 761 loss: 1.35746291e-06
Iter: 762 loss: 1.35267646e-06
Iter: 763 loss: 1.3515147e-06
Iter: 764 loss: 1.34967945e-06
Iter: 765 loss: 1.34967922e-06
Iter: 766 loss: 1.34761581e-06
Iter: 767 loss: 1.35948176e-06
Iter: 768 loss: 1.34732613e-06
Iter: 769 loss: 1.34560673e-06
Iter: 770 loss: 1.35204482e-06
Iter: 771 loss: 1.34518189e-06
Iter: 772 loss: 1.34319146e-06
Iter: 773 loss: 1.34562924e-06
Iter: 774 loss: 1.34224285e-06
Iter: 775 loss: 1.34045672e-06
Iter: 776 loss: 1.35101277e-06
Iter: 777 loss: 1.34026459e-06
Iter: 778 loss: 1.3387255e-06
Iter: 779 loss: 1.3489896e-06
Iter: 780 loss: 1.33854087e-06
Iter: 781 loss: 1.33740139e-06
Iter: 782 loss: 1.33571416e-06
Iter: 783 loss: 1.33565209e-06
Iter: 784 loss: 1.33402193e-06
Iter: 785 loss: 1.35036817e-06
Iter: 786 loss: 1.33402068e-06
Iter: 787 loss: 1.33249205e-06
Iter: 788 loss: 1.33596188e-06
Iter: 789 loss: 1.33190701e-06
Iter: 790 loss: 1.33057733e-06
Iter: 791 loss: 1.33253047e-06
Iter: 792 loss: 1.32994273e-06
Iter: 793 loss: 1.32828063e-06
Iter: 794 loss: 1.3382579e-06
Iter: 795 loss: 1.32808339e-06
Iter: 796 loss: 1.32695595e-06
Iter: 797 loss: 1.32690491e-06
Iter: 798 loss: 1.32609898e-06
Iter: 799 loss: 1.32453283e-06
Iter: 800 loss: 1.33948447e-06
Iter: 801 loss: 1.32448702e-06
Iter: 802 loss: 1.32345895e-06
Iter: 803 loss: 1.32190235e-06
Iter: 804 loss: 1.32188484e-06
Iter: 805 loss: 1.32005721e-06
Iter: 806 loss: 1.32240621e-06
Iter: 807 loss: 1.31908837e-06
Iter: 808 loss: 1.31683623e-06
Iter: 809 loss: 1.3252693e-06
Iter: 810 loss: 1.31624847e-06
Iter: 811 loss: 1.31463526e-06
Iter: 812 loss: 1.32224773e-06
Iter: 813 loss: 1.31430238e-06
Iter: 814 loss: 1.31279853e-06
Iter: 815 loss: 1.32916011e-06
Iter: 816 loss: 1.31273418e-06
Iter: 817 loss: 1.31168088e-06
Iter: 818 loss: 1.31124477e-06
Iter: 819 loss: 1.3106594e-06
Iter: 820 loss: 1.30899912e-06
Iter: 821 loss: 1.3143773e-06
Iter: 822 loss: 1.30847957e-06
Iter: 823 loss: 1.30713954e-06
Iter: 824 loss: 1.30961485e-06
Iter: 825 loss: 1.3065378e-06
Iter: 826 loss: 1.30517083e-06
Iter: 827 loss: 1.31644367e-06
Iter: 828 loss: 1.30506851e-06
Iter: 829 loss: 1.30373769e-06
Iter: 830 loss: 1.30316675e-06
Iter: 831 loss: 1.30243779e-06
Iter: 832 loss: 1.30112255e-06
Iter: 833 loss: 1.31609079e-06
Iter: 834 loss: 1.30112505e-06
Iter: 835 loss: 1.29994442e-06
Iter: 836 loss: 1.30036972e-06
Iter: 837 loss: 1.29914e-06
Iter: 838 loss: 1.29787486e-06
Iter: 839 loss: 1.30228091e-06
Iter: 840 loss: 1.297474e-06
Iter: 841 loss: 1.29613341e-06
Iter: 842 loss: 1.29841624e-06
Iter: 843 loss: 1.29548948e-06
Iter: 844 loss: 1.29420664e-06
Iter: 845 loss: 1.29390048e-06
Iter: 846 loss: 1.29305977e-06
Iter: 847 loss: 1.29130831e-06
Iter: 848 loss: 1.29427656e-06
Iter: 849 loss: 1.29039972e-06
Iter: 850 loss: 1.28866907e-06
Iter: 851 loss: 1.29911473e-06
Iter: 852 loss: 1.28845318e-06
Iter: 853 loss: 1.28702141e-06
Iter: 854 loss: 1.30656076e-06
Iter: 855 loss: 1.28704426e-06
Iter: 856 loss: 1.2860869e-06
Iter: 857 loss: 1.2845353e-06
Iter: 858 loss: 1.28452609e-06
Iter: 859 loss: 1.28292936e-06
Iter: 860 loss: 1.28845727e-06
Iter: 861 loss: 1.28247132e-06
Iter: 862 loss: 1.28160536e-06
Iter: 863 loss: 1.28163424e-06
Iter: 864 loss: 1.28074976e-06
Iter: 865 loss: 1.27900466e-06
Iter: 866 loss: 1.31282877e-06
Iter: 867 loss: 1.27898795e-06
Iter: 868 loss: 1.27788235e-06
Iter: 869 loss: 1.277813e-06
Iter: 870 loss: 1.27689259e-06
Iter: 871 loss: 1.27666135e-06
Iter: 872 loss: 1.2761833e-06
Iter: 873 loss: 1.27482849e-06
Iter: 874 loss: 1.27746739e-06
Iter: 875 loss: 1.27432668e-06
Iter: 876 loss: 1.27260273e-06
Iter: 877 loss: 1.27547173e-06
Iter: 878 loss: 1.27182591e-06
Iter: 879 loss: 1.2708399e-06
Iter: 880 loss: 1.27730675e-06
Iter: 881 loss: 1.2707269e-06
Iter: 882 loss: 1.26964051e-06
Iter: 883 loss: 1.2684992e-06
Iter: 884 loss: 1.26829298e-06
Iter: 885 loss: 1.26645909e-06
Iter: 886 loss: 1.27407884e-06
Iter: 887 loss: 1.26607313e-06
Iter: 888 loss: 1.26446264e-06
Iter: 889 loss: 1.26494547e-06
Iter: 890 loss: 1.26333839e-06
Iter: 891 loss: 1.26176315e-06
Iter: 892 loss: 1.261747e-06
Iter: 893 loss: 1.26039902e-06
Iter: 894 loss: 1.26454461e-06
Iter: 895 loss: 1.2600201e-06
Iter: 896 loss: 1.258868e-06
Iter: 897 loss: 1.25744111e-06
Iter: 898 loss: 1.25734653e-06
Iter: 899 loss: 1.25564804e-06
Iter: 900 loss: 1.26122541e-06
Iter: 901 loss: 1.25511383e-06
Iter: 902 loss: 1.25399686e-06
Iter: 903 loss: 1.25395e-06
Iter: 904 loss: 1.25300357e-06
Iter: 905 loss: 1.25181714e-06
Iter: 906 loss: 1.25166457e-06
Iter: 907 loss: 1.25039503e-06
Iter: 908 loss: 1.26655982e-06
Iter: 909 loss: 1.25037855e-06
Iter: 910 loss: 1.24932774e-06
Iter: 911 loss: 1.251399e-06
Iter: 912 loss: 1.24893734e-06
Iter: 913 loss: 1.24794633e-06
Iter: 914 loss: 1.25029908e-06
Iter: 915 loss: 1.24760629e-06
Iter: 916 loss: 1.24629287e-06
Iter: 917 loss: 1.24660767e-06
Iter: 918 loss: 1.24534313e-06
Iter: 919 loss: 1.24406165e-06
Iter: 920 loss: 1.24882058e-06
Iter: 921 loss: 1.24370627e-06
Iter: 922 loss: 1.24229371e-06
Iter: 923 loss: 1.24407507e-06
Iter: 924 loss: 1.24166172e-06
Iter: 925 loss: 1.24010114e-06
Iter: 926 loss: 1.24028657e-06
Iter: 927 loss: 1.23897462e-06
Iter: 928 loss: 1.23738414e-06
Iter: 929 loss: 1.24866062e-06
Iter: 930 loss: 1.23721009e-06
Iter: 931 loss: 1.23606583e-06
Iter: 932 loss: 1.24868018e-06
Iter: 933 loss: 1.23610334e-06
Iter: 934 loss: 1.23489724e-06
Iter: 935 loss: 1.23428526e-06
Iter: 936 loss: 1.23373047e-06
Iter: 937 loss: 1.23229802e-06
Iter: 938 loss: 1.233592e-06
Iter: 939 loss: 1.23147709e-06
Iter: 940 loss: 1.23013933e-06
Iter: 941 loss: 1.23775726e-06
Iter: 942 loss: 1.2299256e-06
Iter: 943 loss: 1.22867937e-06
Iter: 944 loss: 1.24189978e-06
Iter: 945 loss: 1.22866459e-06
Iter: 946 loss: 1.22789129e-06
Iter: 947 loss: 1.2266911e-06
Iter: 948 loss: 1.22669724e-06
Iter: 949 loss: 1.22523591e-06
Iter: 950 loss: 1.24523513e-06
Iter: 951 loss: 1.22521101e-06
Iter: 952 loss: 1.22436813e-06
Iter: 953 loss: 1.22375741e-06
Iter: 954 loss: 1.22347637e-06
Iter: 955 loss: 1.22223048e-06
Iter: 956 loss: 1.22470055e-06
Iter: 957 loss: 1.22177721e-06
Iter: 958 loss: 1.2202878e-06
Iter: 959 loss: 1.22782376e-06
Iter: 960 loss: 1.22010897e-06
Iter: 961 loss: 1.2189505e-06
Iter: 962 loss: 1.22155245e-06
Iter: 963 loss: 1.21853748e-06
Iter: 964 loss: 1.21739083e-06
Iter: 965 loss: 1.22000665e-06
Iter: 966 loss: 1.21698099e-06
Iter: 967 loss: 1.21555468e-06
Iter: 968 loss: 1.21551659e-06
Iter: 969 loss: 1.21445646e-06
Iter: 970 loss: 1.21290816e-06
Iter: 971 loss: 1.21824678e-06
Iter: 972 loss: 1.21252765e-06
Iter: 973 loss: 1.21119683e-06
Iter: 974 loss: 1.23124562e-06
Iter: 975 loss: 1.21117614e-06
Iter: 976 loss: 1.21037488e-06
Iter: 977 loss: 1.20921618e-06
Iter: 978 loss: 1.20921254e-06
Iter: 979 loss: 1.20774735e-06
Iter: 980 loss: 1.20970128e-06
Iter: 981 loss: 1.20701623e-06
Iter: 982 loss: 1.20587242e-06
Iter: 983 loss: 1.20588118e-06
Iter: 984 loss: 1.20468621e-06
Iter: 985 loss: 1.20547065e-06
Iter: 986 loss: 1.20393508e-06
Iter: 987 loss: 1.20289883e-06
Iter: 988 loss: 1.20187644e-06
Iter: 989 loss: 1.20172444e-06
Iter: 990 loss: 1.2007032e-06
Iter: 991 loss: 1.20056188e-06
Iter: 992 loss: 1.19994445e-06
Iter: 993 loss: 1.19887864e-06
Iter: 994 loss: 1.19886886e-06
Iter: 995 loss: 1.19767014e-06
Iter: 996 loss: 1.20168454e-06
Iter: 997 loss: 1.19733409e-06
Iter: 998 loss: 1.19583046e-06
Iter: 999 loss: 1.1998244e-06
Iter: 1000 loss: 1.19535912e-06
Iter: 1001 loss: 1.19414221e-06
Iter: 1002 loss: 1.20037771e-06
Iter: 1003 loss: 1.1939195e-06
Iter: 1004 loss: 1.19281594e-06
Iter: 1005 loss: 1.19536116e-06
Iter: 1006 loss: 1.19241349e-06
Iter: 1007 loss: 1.19123843e-06
Iter: 1008 loss: 1.19266019e-06
Iter: 1009 loss: 1.19057813e-06
Iter: 1010 loss: 1.1897057e-06
Iter: 1011 loss: 1.1982761e-06
Iter: 1012 loss: 1.18965636e-06
Iter: 1013 loss: 1.18872094e-06
Iter: 1014 loss: 1.18895105e-06
Iter: 1015 loss: 1.18799426e-06
Iter: 1016 loss: 1.1869364e-06
Iter: 1017 loss: 1.18657329e-06
Iter: 1018 loss: 1.18593994e-06
Iter: 1019 loss: 1.18442745e-06
Iter: 1020 loss: 1.18886499e-06
Iter: 1021 loss: 1.18394632e-06
Iter: 1022 loss: 1.18303876e-06
Iter: 1023 loss: 1.18293735e-06
Iter: 1024 loss: 1.18224284e-06
Iter: 1025 loss: 1.18083631e-06
Iter: 1026 loss: 1.20184336e-06
Iter: 1027 loss: 1.18072785e-06
Iter: 1028 loss: 1.17921468e-06
Iter: 1029 loss: 1.18521734e-06
Iter: 1030 loss: 1.17887726e-06
Iter: 1031 loss: 1.17778654e-06
Iter: 1032 loss: 1.18014623e-06
Iter: 1033 loss: 1.17740501e-06
Iter: 1034 loss: 1.1761814e-06
Iter: 1035 loss: 1.18325067e-06
Iter: 1036 loss: 1.17601621e-06
Iter: 1037 loss: 1.17482341e-06
Iter: 1038 loss: 1.17886293e-06
Iter: 1039 loss: 1.1745442e-06
Iter: 1040 loss: 1.17352283e-06
Iter: 1041 loss: 1.17677814e-06
Iter: 1042 loss: 1.17327841e-06
Iter: 1043 loss: 1.17214199e-06
Iter: 1044 loss: 1.17311311e-06
Iter: 1045 loss: 1.17151467e-06
Iter: 1046 loss: 1.17040213e-06
Iter: 1047 loss: 1.17879858e-06
Iter: 1048 loss: 1.17026832e-06
Iter: 1049 loss: 1.16926685e-06
Iter: 1050 loss: 1.16954129e-06
Iter: 1051 loss: 1.16854119e-06
Iter: 1052 loss: 1.16757519e-06
Iter: 1053 loss: 1.16992101e-06
Iter: 1054 loss: 1.16731508e-06
Iter: 1055 loss: 1.16606304e-06
Iter: 1056 loss: 1.17180434e-06
Iter: 1057 loss: 1.16581259e-06
Iter: 1058 loss: 1.16475451e-06
Iter: 1059 loss: 1.16432852e-06
Iter: 1060 loss: 1.16377942e-06
Iter: 1061 loss: 1.16290164e-06
Iter: 1062 loss: 1.17252387e-06
Iter: 1063 loss: 1.16283786e-06
Iter: 1064 loss: 1.16183378e-06
Iter: 1065 loss: 1.16290698e-06
Iter: 1066 loss: 1.16129149e-06
Iter: 1067 loss: 1.16046203e-06
Iter: 1068 loss: 1.15920147e-06
Iter: 1069 loss: 1.15919397e-06
Iter: 1070 loss: 1.15755972e-06
Iter: 1071 loss: 1.16517197e-06
Iter: 1072 loss: 1.15726584e-06
Iter: 1073 loss: 1.15590547e-06
Iter: 1074 loss: 1.16045453e-06
Iter: 1075 loss: 1.15551677e-06
Iter: 1076 loss: 1.1542129e-06
Iter: 1077 loss: 1.1646373e-06
Iter: 1078 loss: 1.15416287e-06
Iter: 1079 loss: 1.15307512e-06
Iter: 1080 loss: 1.15475518e-06
Iter: 1081 loss: 1.15254772e-06
Iter: 1082 loss: 1.15144644e-06
Iter: 1083 loss: 1.15536409e-06
Iter: 1084 loss: 1.15108037e-06
Iter: 1085 loss: 1.15011812e-06
Iter: 1086 loss: 1.1529919e-06
Iter: 1087 loss: 1.14974227e-06
Iter: 1088 loss: 1.14883289e-06
Iter: 1089 loss: 1.15332523e-06
Iter: 1090 loss: 1.14863678e-06
Iter: 1091 loss: 1.14760701e-06
Iter: 1092 loss: 1.14768932e-06
Iter: 1093 loss: 1.14677948e-06
Iter: 1094 loss: 1.1458867e-06
Iter: 1095 loss: 1.14812428e-06
Iter: 1096 loss: 1.14563022e-06
Iter: 1097 loss: 1.1447903e-06
Iter: 1098 loss: 1.15486398e-06
Iter: 1099 loss: 1.14478371e-06
Iter: 1100 loss: 1.14407806e-06
Iter: 1101 loss: 1.14293152e-06
Iter: 1102 loss: 1.17297395e-06
Iter: 1103 loss: 1.14293164e-06
Iter: 1104 loss: 1.14189743e-06
Iter: 1105 loss: 1.15277294e-06
Iter: 1106 loss: 1.14189072e-06
Iter: 1107 loss: 1.1408614e-06
Iter: 1108 loss: 1.14459465e-06
Iter: 1109 loss: 1.14061663e-06
Iter: 1110 loss: 1.13979831e-06
Iter: 1111 loss: 1.13822989e-06
Iter: 1112 loss: 1.17581749e-06
Iter: 1113 loss: 1.13821966e-06
Iter: 1114 loss: 1.13690771e-06
Iter: 1115 loss: 1.14508816e-06
Iter: 1116 loss: 1.13672274e-06
Iter: 1117 loss: 1.13553324e-06
Iter: 1118 loss: 1.13583712e-06
Iter: 1119 loss: 1.13467377e-06
Iter: 1120 loss: 1.1333675e-06
Iter: 1121 loss: 1.13335523e-06
Iter: 1122 loss: 1.13251633e-06
Iter: 1123 loss: 1.13483077e-06
Iter: 1124 loss: 1.13228043e-06
Iter: 1125 loss: 1.13134229e-06
Iter: 1126 loss: 1.13418696e-06
Iter: 1127 loss: 1.13111275e-06
Iter: 1128 loss: 1.13019348e-06
Iter: 1129 loss: 1.13006399e-06
Iter: 1130 loss: 1.12939347e-06
Iter: 1131 loss: 1.12831015e-06
Iter: 1132 loss: 1.13367901e-06
Iter: 1133 loss: 1.12818316e-06
Iter: 1134 loss: 1.12715657e-06
Iter: 1135 loss: 1.13369606e-06
Iter: 1136 loss: 1.12705834e-06
Iter: 1137 loss: 1.12637304e-06
Iter: 1138 loss: 1.1257996e-06
Iter: 1139 loss: 1.12559974e-06
Iter: 1140 loss: 1.12431894e-06
Iter: 1141 loss: 1.13347221e-06
Iter: 1142 loss: 1.12423118e-06
Iter: 1143 loss: 1.12332577e-06
Iter: 1144 loss: 1.12419525e-06
Iter: 1145 loss: 1.12281668e-06
Iter: 1146 loss: 1.12201155e-06
Iter: 1147 loss: 1.13260865e-06
Iter: 1148 loss: 1.12200848e-06
Iter: 1149 loss: 1.12143516e-06
Iter: 1150 loss: 1.12036571e-06
Iter: 1151 loss: 1.13887506e-06
Iter: 1152 loss: 1.1202726e-06
Iter: 1153 loss: 1.1190175e-06
Iter: 1154 loss: 1.12195016e-06
Iter: 1155 loss: 1.11853296e-06
Iter: 1156 loss: 1.11723762e-06
Iter: 1157 loss: 1.12050134e-06
Iter: 1158 loss: 1.11677969e-06
Iter: 1159 loss: 1.11557119e-06
Iter: 1160 loss: 1.12289229e-06
Iter: 1161 loss: 1.11537395e-06
Iter: 1162 loss: 1.11442989e-06
Iter: 1163 loss: 1.11964903e-06
Iter: 1164 loss: 1.11432541e-06
Iter: 1165 loss: 1.11339637e-06
Iter: 1166 loss: 1.11767e-06
Iter: 1167 loss: 1.11324766e-06
Iter: 1168 loss: 1.11255508e-06
Iter: 1169 loss: 1.11483791e-06
Iter: 1170 loss: 1.11232566e-06
Iter: 1171 loss: 1.11166787e-06
Iter: 1172 loss: 1.11152258e-06
Iter: 1173 loss: 1.11107602e-06
Iter: 1174 loss: 1.11022257e-06
Iter: 1175 loss: 1.11233658e-06
Iter: 1176 loss: 1.1098881e-06
Iter: 1177 loss: 1.10875226e-06
Iter: 1178 loss: 1.11619397e-06
Iter: 1179 loss: 1.10866335e-06
Iter: 1180 loss: 1.10807696e-06
Iter: 1181 loss: 1.10835185e-06
Iter: 1182 loss: 1.10767871e-06
Iter: 1183 loss: 1.10679639e-06
Iter: 1184 loss: 1.11029362e-06
Iter: 1185 loss: 1.10653741e-06
Iter: 1186 loss: 1.10576502e-06
Iter: 1187 loss: 1.1055796e-06
Iter: 1188 loss: 1.10506164e-06
Iter: 1189 loss: 1.1040122e-06
Iter: 1190 loss: 1.11370832e-06
Iter: 1191 loss: 1.10396911e-06
Iter: 1192 loss: 1.10330654e-06
Iter: 1193 loss: 1.10261249e-06
Iter: 1194 loss: 1.10254678e-06
Iter: 1195 loss: 1.10136045e-06
Iter: 1196 loss: 1.10323253e-06
Iter: 1197 loss: 1.10082567e-06
Iter: 1198 loss: 1.09973394e-06
Iter: 1199 loss: 1.10140536e-06
Iter: 1200 loss: 1.09918801e-06
Iter: 1201 loss: 1.09802579e-06
Iter: 1202 loss: 1.10863118e-06
Iter: 1203 loss: 1.09792757e-06
Iter: 1204 loss: 1.09718962e-06
Iter: 1205 loss: 1.10348765e-06
Iter: 1206 loss: 1.09711857e-06
Iter: 1207 loss: 1.09643383e-06
Iter: 1208 loss: 1.09755729e-06
Iter: 1209 loss: 1.09610392e-06
Iter: 1210 loss: 1.09529992e-06
Iter: 1211 loss: 1.09648613e-06
Iter: 1212 loss: 1.09485757e-06
Iter: 1213 loss: 1.09410905e-06
Iter: 1214 loss: 1.09554276e-06
Iter: 1215 loss: 1.09372695e-06
Iter: 1216 loss: 1.09308826e-06
Iter: 1217 loss: 1.10354358e-06
Iter: 1218 loss: 1.09312282e-06
Iter: 1219 loss: 1.09254381e-06
Iter: 1220 loss: 1.09186863e-06
Iter: 1221 loss: 1.09175733e-06
Iter: 1222 loss: 1.09108441e-06
Iter: 1223 loss: 1.09791745e-06
Iter: 1224 loss: 1.09105633e-06
Iter: 1225 loss: 1.09019925e-06
Iter: 1226 loss: 1.08987206e-06
Iter: 1227 loss: 1.08944e-06
Iter: 1228 loss: 1.0885451e-06
Iter: 1229 loss: 1.08859365e-06
Iter: 1230 loss: 1.08780682e-06
Iter: 1231 loss: 1.08698168e-06
Iter: 1232 loss: 1.08695838e-06
Iter: 1233 loss: 1.08624681e-06
Iter: 1234 loss: 1.08679842e-06
Iter: 1235 loss: 1.08579547e-06
Iter: 1236 loss: 1.08494135e-06
Iter: 1237 loss: 1.08536096e-06
Iter: 1238 loss: 1.08436541e-06
Iter: 1239 loss: 1.08340498e-06
Iter: 1240 loss: 1.08475228e-06
Iter: 1241 loss: 1.08295239e-06
Iter: 1242 loss: 1.08223867e-06
Iter: 1243 loss: 1.08220979e-06
Iter: 1244 loss: 1.08161692e-06
Iter: 1245 loss: 1.08063568e-06
Iter: 1246 loss: 1.08063261e-06
Iter: 1247 loss: 1.07962774e-06
Iter: 1248 loss: 1.08306563e-06
Iter: 1249 loss: 1.07936353e-06
Iter: 1250 loss: 1.07872393e-06
Iter: 1251 loss: 1.07869243e-06
Iter: 1252 loss: 1.07822507e-06
Iter: 1253 loss: 1.07753976e-06
Iter: 1254 loss: 1.07751828e-06
Iter: 1255 loss: 1.07674055e-06
Iter: 1256 loss: 1.08341646e-06
Iter: 1257 loss: 1.0767593e-06
Iter: 1258 loss: 1.07599908e-06
Iter: 1259 loss: 1.0762393e-06
Iter: 1260 loss: 1.07551227e-06
Iter: 1261 loss: 1.07452911e-06
Iter: 1262 loss: 1.07824712e-06
Iter: 1263 loss: 1.07427525e-06
Iter: 1264 loss: 1.0735323e-06
Iter: 1265 loss: 1.07368078e-06
Iter: 1266 loss: 1.07301048e-06
Iter: 1267 loss: 1.07213418e-06
Iter: 1268 loss: 1.07552114e-06
Iter: 1269 loss: 1.07192113e-06
Iter: 1270 loss: 1.07113419e-06
Iter: 1271 loss: 1.07854737e-06
Iter: 1272 loss: 1.07107871e-06
Iter: 1273 loss: 1.07056076e-06
Iter: 1274 loss: 1.0696217e-06
Iter: 1275 loss: 1.069571e-06
Iter: 1276 loss: 1.06856908e-06
Iter: 1277 loss: 1.07803453e-06
Iter: 1278 loss: 1.06850371e-06
Iter: 1279 loss: 1.06786558e-06
Iter: 1280 loss: 1.07638266e-06
Iter: 1281 loss: 1.06782045e-06
Iter: 1282 loss: 1.06734092e-06
Iter: 1283 loss: 1.06618631e-06
Iter: 1284 loss: 1.07835922e-06
Iter: 1285 loss: 1.06609548e-06
Iter: 1286 loss: 1.06536731e-06
Iter: 1287 loss: 1.06534594e-06
Iter: 1288 loss: 1.06458879e-06
Iter: 1289 loss: 1.06641494e-06
Iter: 1290 loss: 1.06438279e-06
Iter: 1291 loss: 1.06372681e-06
Iter: 1292 loss: 1.06296545e-06
Iter: 1293 loss: 1.06286257e-06
Iter: 1294 loss: 1.06230061e-06
Iter: 1295 loss: 1.06225252e-06
Iter: 1296 loss: 1.06168488e-06
Iter: 1297 loss: 1.06096991e-06
Iter: 1298 loss: 1.06093307e-06
Iter: 1299 loss: 1.06008122e-06
Iter: 1300 loss: 1.06189168e-06
Iter: 1301 loss: 1.05972117e-06
Iter: 1302 loss: 1.05901108e-06
Iter: 1303 loss: 1.06476796e-06
Iter: 1304 loss: 1.05888353e-06
Iter: 1305 loss: 1.05805316e-06
Iter: 1306 loss: 1.05838512e-06
Iter: 1307 loss: 1.05749632e-06
Iter: 1308 loss: 1.05662116e-06
Iter: 1309 loss: 1.06284153e-06
Iter: 1310 loss: 1.05650111e-06
Iter: 1311 loss: 1.05580159e-06
Iter: 1312 loss: 1.05601362e-06
Iter: 1313 loss: 1.05530114e-06
Iter: 1314 loss: 1.05448635e-06
Iter: 1315 loss: 1.05925335e-06
Iter: 1316 loss: 1.05438698e-06
Iter: 1317 loss: 1.05355389e-06
Iter: 1318 loss: 1.05766367e-06
Iter: 1319 loss: 1.05345748e-06
Iter: 1320 loss: 1.05294635e-06
Iter: 1321 loss: 1.05236245e-06
Iter: 1322 loss: 1.05231243e-06
Iter: 1323 loss: 1.05158688e-06
Iter: 1324 loss: 1.05162724e-06
Iter: 1325 loss: 1.05095751e-06
Iter: 1326 loss: 1.05094352e-06
Iter: 1327 loss: 1.05042761e-06
Iter: 1328 loss: 1.04982325e-06
Iter: 1329 loss: 1.05002857e-06
Iter: 1330 loss: 1.04931155e-06
Iter: 1331 loss: 1.04863898e-06
Iter: 1332 loss: 1.0485935e-06
Iter: 1333 loss: 1.04814353e-06
Iter: 1334 loss: 1.04715832e-06
Iter: 1335 loss: 1.06249399e-06
Iter: 1336 loss: 1.04713126e-06
Iter: 1337 loss: 1.04606011e-06
Iter: 1338 loss: 1.04984031e-06
Iter: 1339 loss: 1.04574076e-06
Iter: 1340 loss: 1.0449088e-06
Iter: 1341 loss: 1.05709591e-06
Iter: 1342 loss: 1.04489413e-06
Iter: 1343 loss: 1.04418268e-06
Iter: 1344 loss: 1.04418598e-06
Iter: 1345 loss: 1.04363426e-06
Iter: 1346 loss: 1.04288506e-06
Iter: 1347 loss: 1.04593562e-06
Iter: 1348 loss: 1.04271055e-06
Iter: 1349 loss: 1.04201297e-06
Iter: 1350 loss: 1.04562866e-06
Iter: 1351 loss: 1.04190644e-06
Iter: 1352 loss: 1.04124706e-06
Iter: 1353 loss: 1.04320384e-06
Iter: 1354 loss: 1.04103253e-06
Iter: 1355 loss: 1.04044284e-06
Iter: 1356 loss: 1.04195033e-06
Iter: 1357 loss: 1.0402016e-06
Iter: 1358 loss: 1.03972229e-06
Iter: 1359 loss: 1.04054368e-06
Iter: 1360 loss: 1.03949515e-06
Iter: 1361 loss: 1.03872071e-06
Iter: 1362 loss: 1.04088053e-06
Iter: 1363 loss: 1.03843331e-06
Iter: 1364 loss: 1.03780326e-06
Iter: 1365 loss: 1.03721459e-06
Iter: 1366 loss: 1.03707225e-06
Iter: 1367 loss: 1.03636512e-06
Iter: 1368 loss: 1.04704452e-06
Iter: 1369 loss: 1.03633272e-06
Iter: 1370 loss: 1.03560137e-06
Iter: 1371 loss: 1.0354413e-06
Iter: 1372 loss: 1.03496689e-06
Iter: 1373 loss: 1.03411537e-06
Iter: 1374 loss: 1.03472416e-06
Iter: 1375 loss: 1.03359889e-06
Iter: 1376 loss: 1.03262437e-06
Iter: 1377 loss: 1.03362981e-06
Iter: 1378 loss: 1.03212506e-06
Iter: 1379 loss: 1.03129241e-06
Iter: 1380 loss: 1.03132083e-06
Iter: 1381 loss: 1.03063473e-06
Iter: 1382 loss: 1.03245031e-06
Iter: 1383 loss: 1.03043453e-06
Iter: 1384 loss: 1.02979413e-06
Iter: 1385 loss: 1.02905403e-06
Iter: 1386 loss: 1.02899583e-06
Iter: 1387 loss: 1.02843967e-06
Iter: 1388 loss: 1.02833189e-06
Iter: 1389 loss: 1.02783724e-06
Iter: 1390 loss: 1.02716547e-06
Iter: 1391 loss: 1.02707622e-06
Iter: 1392 loss: 1.02648357e-06
Iter: 1393 loss: 1.03334173e-06
Iter: 1394 loss: 1.02647414e-06
Iter: 1395 loss: 1.02580566e-06
Iter: 1396 loss: 1.02624165e-06
Iter: 1397 loss: 1.02539855e-06
Iter: 1398 loss: 1.0246946e-06
Iter: 1399 loss: 1.02558965e-06
Iter: 1400 loss: 1.0243624e-06
Iter: 1401 loss: 1.02370223e-06
Iter: 1402 loss: 1.02773174e-06
Iter: 1403 loss: 1.0236248e-06
Iter: 1404 loss: 1.02302988e-06
Iter: 1405 loss: 1.02449758e-06
Iter: 1406 loss: 1.0228e-06
Iter: 1407 loss: 1.02203933e-06
Iter: 1408 loss: 1.02283911e-06
Iter: 1409 loss: 1.02159606e-06
Iter: 1410 loss: 1.02087097e-06
Iter: 1411 loss: 1.02147158e-06
Iter: 1412 loss: 1.0204526e-06
Iter: 1413 loss: 1.01961007e-06
Iter: 1414 loss: 1.02059266e-06
Iter: 1415 loss: 1.01919261e-06
Iter: 1416 loss: 1.01843443e-06
Iter: 1417 loss: 1.02901276e-06
Iter: 1418 loss: 1.01841601e-06
Iter: 1419 loss: 1.0176343e-06
Iter: 1420 loss: 1.01751857e-06
Iter: 1421 loss: 1.01697538e-06
Iter: 1422 loss: 1.01621686e-06
Iter: 1423 loss: 1.01938667e-06
Iter: 1424 loss: 1.01606304e-06
Iter: 1425 loss: 1.01507749e-06
Iter: 1426 loss: 1.0186393e-06
Iter: 1427 loss: 1.0149256e-06
Iter: 1428 loss: 1.01428873e-06
Iter: 1429 loss: 1.0149223e-06
Iter: 1430 loss: 1.01402134e-06
Iter: 1431 loss: 1.01340243e-06
Iter: 1432 loss: 1.01935154e-06
Iter: 1433 loss: 1.01338446e-06
Iter: 1434 loss: 1.01283467e-06
Iter: 1435 loss: 1.01187425e-06
Iter: 1436 loss: 1.01187425e-06
Iter: 1437 loss: 1.0110283e-06
Iter: 1438 loss: 1.01643025e-06
Iter: 1439 loss: 1.01091268e-06
Iter: 1440 loss: 1.01009732e-06
Iter: 1441 loss: 1.01374235e-06
Iter: 1442 loss: 1.00994089e-06
Iter: 1443 loss: 1.00920784e-06
Iter: 1444 loss: 1.01079968e-06
Iter: 1445 loss: 1.00891009e-06
Iter: 1446 loss: 1.00813304e-06
Iter: 1447 loss: 1.00915372e-06
Iter: 1448 loss: 1.0077523e-06
Iter: 1449 loss: 1.00702619e-06
Iter: 1450 loss: 1.00672958e-06
Iter: 1451 loss: 1.00628154e-06
Iter: 1452 loss: 1.0052479e-06
Iter: 1453 loss: 1.01311673e-06
Iter: 1454 loss: 1.00515956e-06
Iter: 1455 loss: 1.00459818e-06
Iter: 1456 loss: 1.01127318e-06
Iter: 1457 loss: 1.00456191e-06
Iter: 1458 loss: 1.00402985e-06
Iter: 1459 loss: 1.0037345e-06
Iter: 1460 loss: 1.00349075e-06
Iter: 1461 loss: 1.0028125e-06
Iter: 1462 loss: 1.00870739e-06
Iter: 1463 loss: 1.00276975e-06
Iter: 1464 loss: 1.00217403e-06
Iter: 1465 loss: 1.00317538e-06
Iter: 1466 loss: 1.00189573e-06
Iter: 1467 loss: 1.00139027e-06
Iter: 1468 loss: 1.00170541e-06
Iter: 1469 loss: 1.00103625e-06
Iter: 1470 loss: 1.00016177e-06
Iter: 1471 loss: 1.00239049e-06
Iter: 1472 loss: 9.99877443e-07
Iter: 1473 loss: 9.99229087e-07
Iter: 1474 loss: 9.98818678e-07
Iter: 1475 loss: 9.98581413e-07
Iter: 1476 loss: 9.97846e-07
Iter: 1477 loss: 1.00361444e-06
Iter: 1478 loss: 9.97765e-07
Iter: 1479 loss: 9.97048119e-07
Iter: 1480 loss: 9.99995905e-07
Iter: 1481 loss: 9.96915787e-07
Iter: 1482 loss: 9.96196377e-07
Iter: 1483 loss: 9.97001393e-07
Iter: 1484 loss: 9.95841674e-07
Iter: 1485 loss: 9.95193432e-07
Iter: 1486 loss: 9.97180678e-07
Iter: 1487 loss: 9.95017e-07
Iter: 1488 loss: 9.94290758e-07
Iter: 1489 loss: 9.94095e-07
Iter: 1490 loss: 9.93687081e-07
Iter: 1491 loss: 9.92775085e-07
Iter: 1492 loss: 9.96090648e-07
Iter: 1493 loss: 9.92589776e-07
Iter: 1494 loss: 9.91852858e-07
Iter: 1495 loss: 9.97436928e-07
Iter: 1496 loss: 9.91790785e-07
Iter: 1497 loss: 9.91010438e-07
Iter: 1498 loss: 9.91916636e-07
Iter: 1499 loss: 9.90563194e-07
Iter: 1500 loss: 9.89874707e-07
Iter: 1501 loss: 9.9314957e-07
Iter: 1502 loss: 9.8982548e-07
Iter: 1503 loss: 9.89126193e-07
Iter: 1504 loss: 9.91573643e-07
Iter: 1505 loss: 9.88960778e-07
Iter: 1506 loss: 9.88428155e-07
Iter: 1507 loss: 9.88262855e-07
Iter: 1508 loss: 9.87956923e-07
Iter: 1509 loss: 9.87282306e-07
Iter: 1510 loss: 9.87281737e-07
Iter: 1511 loss: 9.86896e-07
Iter: 1512 loss: 9.86031182e-07
Iter: 1513 loss: 9.9983265e-07
Iter: 1514 loss: 9.86016857e-07
Iter: 1515 loss: 9.85111683e-07
Iter: 1516 loss: 9.8884891e-07
Iter: 1517 loss: 9.84884309e-07
Iter: 1518 loss: 9.8418468e-07
Iter: 1519 loss: 9.94304628e-07
Iter: 1520 loss: 9.84215831e-07
Iter: 1521 loss: 9.83637e-07
Iter: 1522 loss: 9.83175e-07
Iter: 1523 loss: 9.83003929e-07
Iter: 1524 loss: 9.82291567e-07
Iter: 1525 loss: 9.86498e-07
Iter: 1526 loss: 9.82249844e-07
Iter: 1527 loss: 9.81617e-07
Iter: 1528 loss: 9.81816811e-07
Iter: 1529 loss: 9.81184485e-07
Iter: 1530 loss: 9.8034775e-07
Iter: 1531 loss: 9.81794301e-07
Iter: 1532 loss: 9.80044092e-07
Iter: 1533 loss: 9.79327297e-07
Iter: 1534 loss: 9.85272209e-07
Iter: 1535 loss: 9.79295805e-07
Iter: 1536 loss: 9.78681214e-07
Iter: 1537 loss: 9.80602636e-07
Iter: 1538 loss: 9.78521e-07
Iter: 1539 loss: 9.77912464e-07
Iter: 1540 loss: 9.78343678e-07
Iter: 1541 loss: 9.77553e-07
Iter: 1542 loss: 9.7684358e-07
Iter: 1543 loss: 9.84220264e-07
Iter: 1544 loss: 9.76813e-07
Iter: 1545 loss: 9.76426463e-07
Iter: 1546 loss: 9.75856778e-07
Iter: 1547 loss: 9.75787543e-07
Iter: 1548 loss: 9.75304602e-07
Iter: 1549 loss: 9.75274588e-07
Iter: 1550 loss: 9.74826094e-07
Iter: 1551 loss: 9.74089517e-07
Iter: 1552 loss: 9.74113391e-07
Iter: 1553 loss: 9.733767e-07
Iter: 1554 loss: 9.74462864e-07
Iter: 1555 loss: 9.73033934e-07
Iter: 1556 loss: 9.72449243e-07
Iter: 1557 loss: 9.72459929e-07
Iter: 1558 loss: 9.71879e-07
Iter: 1559 loss: 9.71906161e-07
Iter: 1560 loss: 9.71431518e-07
Iter: 1561 loss: 9.7074053e-07
Iter: 1562 loss: 9.71096597e-07
Iter: 1563 loss: 9.70311476e-07
Iter: 1564 loss: 9.69404709e-07
Iter: 1565 loss: 9.73843271e-07
Iter: 1566 loss: 9.69161761e-07
Iter: 1567 loss: 9.68555241e-07
Iter: 1568 loss: 9.68968379e-07
Iter: 1569 loss: 9.6824192e-07
Iter: 1570 loss: 9.67430083e-07
Iter: 1571 loss: 9.70997462e-07
Iter: 1572 loss: 9.6729093e-07
Iter: 1573 loss: 9.66628136e-07
Iter: 1574 loss: 9.72777116e-07
Iter: 1575 loss: 9.66600624e-07
Iter: 1576 loss: 9.66252287e-07
Iter: 1577 loss: 9.66239213e-07
Iter: 1578 loss: 9.65906111e-07
Iter: 1579 loss: 9.65332333e-07
Iter: 1580 loss: 9.70362635e-07
Iter: 1581 loss: 9.6531619e-07
Iter: 1582 loss: 9.64865e-07
Iter: 1583 loss: 9.64469791e-07
Iter: 1584 loss: 9.64394758e-07
Iter: 1585 loss: 9.63801767e-07
Iter: 1586 loss: 9.72089651e-07
Iter: 1587 loss: 9.63797902e-07
Iter: 1588 loss: 9.63357479e-07
Iter: 1589 loss: 9.62692411e-07
Iter: 1590 loss: 9.62671493e-07
Iter: 1591 loss: 9.62029503e-07
Iter: 1592 loss: 9.62626e-07
Iter: 1593 loss: 9.61614091e-07
Iter: 1594 loss: 9.61004503e-07
Iter: 1595 loss: 9.60985e-07
Iter: 1596 loss: 9.60460511e-07
Iter: 1597 loss: 9.61158094e-07
Iter: 1598 loss: 9.60226316e-07
Iter: 1599 loss: 9.59711087e-07
Iter: 1600 loss: 9.59621e-07
Iter: 1601 loss: 9.59295335e-07
Iter: 1602 loss: 9.58552846e-07
Iter: 1603 loss: 9.62278364e-07
Iter: 1604 loss: 9.58394935e-07
Iter: 1605 loss: 9.5772657e-07
Iter: 1606 loss: 9.57687348e-07
Iter: 1607 loss: 9.57109933e-07
Iter: 1608 loss: 9.56305712e-07
Iter: 1609 loss: 9.59690624e-07
Iter: 1610 loss: 9.56169288e-07
Iter: 1611 loss: 9.55444648e-07
Iter: 1612 loss: 9.64421929e-07
Iter: 1613 loss: 9.55449195e-07
Iter: 1614 loss: 9.54979e-07
Iter: 1615 loss: 9.54753091e-07
Iter: 1616 loss: 9.54521624e-07
Iter: 1617 loss: 9.53853373e-07
Iter: 1618 loss: 9.58807732e-07
Iter: 1619 loss: 9.5378914e-07
Iter: 1620 loss: 9.53185577e-07
Iter: 1621 loss: 9.53891231e-07
Iter: 1622 loss: 9.52816606e-07
Iter: 1623 loss: 9.52279379e-07
Iter: 1624 loss: 9.53675453e-07
Iter: 1625 loss: 9.52145683e-07
Iter: 1626 loss: 9.51522736e-07
Iter: 1627 loss: 9.5484711e-07
Iter: 1628 loss: 9.51433435e-07
Iter: 1629 loss: 9.50984713e-07
Iter: 1630 loss: 9.50244043e-07
Iter: 1631 loss: 9.50253821e-07
Iter: 1632 loss: 9.49556409e-07
Iter: 1633 loss: 9.54701704e-07
Iter: 1634 loss: 9.49514515e-07
Iter: 1635 loss: 9.48973e-07
Iter: 1636 loss: 9.54133156e-07
Iter: 1637 loss: 9.48906347e-07
Iter: 1638 loss: 9.48519869e-07
Iter: 1639 loss: 9.47813078e-07
Iter: 1640 loss: 9.64929541e-07
Iter: 1641 loss: 9.47804438e-07
Iter: 1642 loss: 9.46872319e-07
Iter: 1643 loss: 9.52158814e-07
Iter: 1644 loss: 9.4674192e-07
Iter: 1645 loss: 9.45959528e-07
Iter: 1646 loss: 9.47994408e-07
Iter: 1647 loss: 9.45702823e-07
Iter: 1648 loss: 9.45040256e-07
Iter: 1649 loss: 9.4526473e-07
Iter: 1650 loss: 9.44543842e-07
Iter: 1651 loss: 9.44039527e-07
Iter: 1652 loss: 9.44020144e-07
Iter: 1653 loss: 9.43529756e-07
Iter: 1654 loss: 9.43384407e-07
Iter: 1655 loss: 9.43199097e-07
Iter: 1656 loss: 9.42478209e-07
Iter: 1657 loss: 9.44169301e-07
Iter: 1658 loss: 9.42222641e-07
Iter: 1659 loss: 9.41484e-07
Iter: 1660 loss: 9.4814385e-07
Iter: 1661 loss: 9.41460371e-07
Iter: 1662 loss: 9.41088217e-07
Iter: 1663 loss: 9.40582652e-07
Iter: 1664 loss: 9.40578104e-07
Iter: 1665 loss: 9.40049404e-07
Iter: 1666 loss: 9.47811031e-07
Iter: 1667 loss: 9.40001655e-07
Iter: 1668 loss: 9.39514e-07
Iter: 1669 loss: 9.39207553e-07
Iter: 1670 loss: 9.38938115e-07
Iter: 1671 loss: 9.38367691e-07
Iter: 1672 loss: 9.38842334e-07
Iter: 1673 loss: 9.38034418e-07
Iter: 1674 loss: 9.37459959e-07
Iter: 1675 loss: 9.44429644e-07
Iter: 1676 loss: 9.37526693e-07
Iter: 1677 loss: 9.37007485e-07
Iter: 1678 loss: 9.3703818e-07
Iter: 1679 loss: 9.36582751e-07
Iter: 1680 loss: 9.36027845e-07
Iter: 1681 loss: 9.3700703e-07
Iter: 1682 loss: 9.35753519e-07
Iter: 1683 loss: 9.35068613e-07
Iter: 1684 loss: 9.37758841e-07
Iter: 1685 loss: 9.34994716e-07
Iter: 1686 loss: 9.3444379e-07
Iter: 1687 loss: 9.34114382e-07
Iter: 1688 loss: 9.33867511e-07
Iter: 1689 loss: 9.33190734e-07
Iter: 1690 loss: 9.41962469e-07
Iter: 1691 loss: 9.33143156e-07
Iter: 1692 loss: 9.32553405e-07
Iter: 1693 loss: 9.33425554e-07
Iter: 1694 loss: 9.32200521e-07
Iter: 1695 loss: 9.31670456e-07
Iter: 1696 loss: 9.32570117e-07
Iter: 1697 loss: 9.31379134e-07
Iter: 1698 loss: 9.30766305e-07
Iter: 1699 loss: 9.36762376e-07
Iter: 1700 loss: 9.30739589e-07
Iter: 1701 loss: 9.30283477e-07
Iter: 1702 loss: 9.29988175e-07
Iter: 1703 loss: 9.29836119e-07
Iter: 1704 loss: 9.29337261e-07
Iter: 1705 loss: 9.32395437e-07
Iter: 1706 loss: 9.2924131e-07
Iter: 1707 loss: 9.2861012e-07
Iter: 1708 loss: 9.3049e-07
Iter: 1709 loss: 9.28431291e-07
Iter: 1710 loss: 9.27984388e-07
Iter: 1711 loss: 9.27668509e-07
Iter: 1712 loss: 9.27541805e-07
Iter: 1713 loss: 9.26918688e-07
Iter: 1714 loss: 9.3078711e-07
Iter: 1715 loss: 9.26868211e-07
Iter: 1716 loss: 9.26200244e-07
Iter: 1717 loss: 9.2787127e-07
Iter: 1718 loss: 9.25966845e-07
Iter: 1719 loss: 9.25465088e-07
Iter: 1720 loss: 9.25940867e-07
Iter: 1721 loss: 9.25126756e-07
Iter: 1722 loss: 9.24541e-07
Iter: 1723 loss: 9.26368557e-07
Iter: 1724 loss: 9.24305311e-07
Iter: 1725 loss: 9.23655762e-07
Iter: 1726 loss: 9.24242386e-07
Iter: 1727 loss: 9.23247171e-07
Iter: 1728 loss: 9.22761046e-07
Iter: 1729 loss: 9.28352165e-07
Iter: 1730 loss: 9.22743141e-07
Iter: 1731 loss: 9.22241384e-07
Iter: 1732 loss: 9.22066704e-07
Iter: 1733 loss: 9.21745595e-07
Iter: 1734 loss: 9.21036246e-07
Iter: 1735 loss: 9.23014341e-07
Iter: 1736 loss: 9.20776188e-07
Iter: 1737 loss: 9.20228956e-07
Iter: 1738 loss: 9.27201597e-07
Iter: 1739 loss: 9.20258344e-07
Iter: 1740 loss: 9.19761248e-07
Iter: 1741 loss: 9.19268587e-07
Iter: 1742 loss: 9.1916877e-07
Iter: 1743 loss: 9.18484375e-07
Iter: 1744 loss: 9.20310072e-07
Iter: 1745 loss: 9.18193336e-07
Iter: 1746 loss: 9.1765628e-07
Iter: 1747 loss: 9.17647867e-07
Iter: 1748 loss: 9.17369562e-07
Iter: 1749 loss: 9.16893555e-07
Iter: 1750 loss: 9.29094654e-07
Iter: 1751 loss: 9.16892532e-07
Iter: 1752 loss: 9.16315628e-07
Iter: 1753 loss: 9.18605906e-07
Iter: 1754 loss: 9.16150896e-07
Iter: 1755 loss: 9.15631631e-07
Iter: 1756 loss: 9.20445416e-07
Iter: 1757 loss: 9.15598093e-07
Iter: 1758 loss: 9.15201e-07
Iter: 1759 loss: 9.14822351e-07
Iter: 1760 loss: 9.14782618e-07
Iter: 1761 loss: 9.14073667e-07
Iter: 1762 loss: 9.16258386e-07
Iter: 1763 loss: 9.13842655e-07
Iter: 1764 loss: 9.1323443e-07
Iter: 1765 loss: 9.14565874e-07
Iter: 1766 loss: 9.13014333e-07
Iter: 1767 loss: 9.12431233e-07
Iter: 1768 loss: 9.13769782e-07
Iter: 1769 loss: 9.12249e-07
Iter: 1770 loss: 9.1152117e-07
Iter: 1771 loss: 9.15821147e-07
Iter: 1772 loss: 9.11450627e-07
Iter: 1773 loss: 9.10958079e-07
Iter: 1774 loss: 9.10761173e-07
Iter: 1775 loss: 9.10510494e-07
Iter: 1776 loss: 9.09899768e-07
Iter: 1777 loss: 9.1365041e-07
Iter: 1778 loss: 9.09814332e-07
Iter: 1779 loss: 9.0924118e-07
Iter: 1780 loss: 9.12272e-07
Iter: 1781 loss: 9.09152959e-07
Iter: 1782 loss: 9.0872345e-07
Iter: 1783 loss: 9.08404274e-07
Iter: 1784 loss: 9.0827524e-07
Iter: 1785 loss: 9.07575668e-07
Iter: 1786 loss: 9.07676622e-07
Iter: 1787 loss: 9.07084825e-07
Iter: 1788 loss: 9.06773835e-07
Iter: 1789 loss: 9.06641617e-07
Iter: 1790 loss: 9.06225864e-07
Iter: 1791 loss: 9.06154298e-07
Iter: 1792 loss: 9.05949321e-07
Iter: 1793 loss: 9.05438924e-07
Iter: 1794 loss: 9.07084427e-07
Iter: 1795 loss: 9.05339107e-07
Iter: 1796 loss: 9.04831722e-07
Iter: 1797 loss: 9.06669072e-07
Iter: 1798 loss: 9.0470752e-07
Iter: 1799 loss: 9.04208491e-07
Iter: 1800 loss: 9.04789488e-07
Iter: 1801 loss: 9.03933824e-07
Iter: 1802 loss: 9.03383466e-07
Iter: 1803 loss: 9.0369e-07
Iter: 1804 loss: 9.03065484e-07
Iter: 1805 loss: 9.02494889e-07
Iter: 1806 loss: 9.03300929e-07
Iter: 1807 loss: 9.02112163e-07
Iter: 1808 loss: 9.01616545e-07
Iter: 1809 loss: 9.09928303e-07
Iter: 1810 loss: 9.01599435e-07
Iter: 1811 loss: 9.0115185e-07
Iter: 1812 loss: 9.00970235e-07
Iter: 1813 loss: 9.00734676e-07
Iter: 1814 loss: 9.00171926e-07
Iter: 1815 loss: 9.00351893e-07
Iter: 1816 loss: 8.99797556e-07
Iter: 1817 loss: 8.99062e-07
Iter: 1818 loss: 9.02730676e-07
Iter: 1819 loss: 8.98995268e-07
Iter: 1820 loss: 8.98523524e-07
Iter: 1821 loss: 9.05268848e-07
Iter: 1822 loss: 8.98516646e-07
Iter: 1823 loss: 8.98110613e-07
Iter: 1824 loss: 8.97830091e-07
Iter: 1825 loss: 8.97651148e-07
Iter: 1826 loss: 8.97068503e-07
Iter: 1827 loss: 8.97575546e-07
Iter: 1828 loss: 8.96727897e-07
Iter: 1829 loss: 8.96332949e-07
Iter: 1830 loss: 8.96278721e-07
Iter: 1831 loss: 8.959463e-07
Iter: 1832 loss: 8.96045265e-07
Iter: 1833 loss: 8.95713356e-07
Iter: 1834 loss: 8.95228823e-07
Iter: 1835 loss: 8.96289407e-07
Iter: 1836 loss: 8.95036806e-07
Iter: 1837 loss: 8.94527489e-07
Iter: 1838 loss: 8.97033885e-07
Iter: 1839 loss: 8.94457912e-07
Iter: 1840 loss: 8.93935862e-07
Iter: 1841 loss: 8.94557672e-07
Iter: 1842 loss: 8.93744868e-07
Iter: 1843 loss: 8.93213496e-07
Iter: 1844 loss: 8.93000504e-07
Iter: 1845 loss: 8.92734931e-07
Iter: 1846 loss: 8.92178605e-07
Iter: 1847 loss: 8.9613377e-07
Iter: 1848 loss: 8.92153196e-07
Iter: 1849 loss: 8.91595732e-07
Iter: 1850 loss: 8.9368416e-07
Iter: 1851 loss: 8.91466698e-07
Iter: 1852 loss: 8.90992112e-07
Iter: 1853 loss: 8.90477338e-07
Iter: 1854 loss: 8.90410547e-07
Iter: 1855 loss: 8.89686362e-07
Iter: 1856 loss: 8.93292054e-07
Iter: 1857 loss: 8.89587e-07
Iter: 1858 loss: 8.88980708e-07
Iter: 1859 loss: 8.89927378e-07
Iter: 1860 loss: 8.8870172e-07
Iter: 1861 loss: 8.88216618e-07
Iter: 1862 loss: 8.88189959e-07
Iter: 1863 loss: 8.87814281e-07
Iter: 1864 loss: 8.872438e-07
Iter: 1865 loss: 8.8725e-07
Iter: 1866 loss: 8.86660814e-07
Iter: 1867 loss: 8.90613364e-07
Iter: 1868 loss: 8.86571058e-07
Iter: 1869 loss: 8.86128475e-07
Iter: 1870 loss: 8.88568366e-07
Iter: 1871 loss: 8.86091357e-07
Iter: 1872 loss: 8.85676741e-07
Iter: 1873 loss: 8.87197189e-07
Iter: 1874 loss: 8.85520194e-07
Iter: 1875 loss: 8.85084262e-07
Iter: 1876 loss: 8.85513487e-07
Iter: 1877 loss: 8.8484569e-07
Iter: 1878 loss: 8.84442443e-07
Iter: 1879 loss: 8.86846863e-07
Iter: 1880 loss: 8.84399583e-07
Iter: 1881 loss: 8.83932501e-07
Iter: 1882 loss: 8.83898565e-07
Iter: 1883 loss: 8.835529e-07
Iter: 1884 loss: 8.83086102e-07
Iter: 1885 loss: 8.8385093e-07
Iter: 1886 loss: 8.82911422e-07
Iter: 1887 loss: 8.82385507e-07
Iter: 1888 loss: 8.85704935e-07
Iter: 1889 loss: 8.82350207e-07
Iter: 1890 loss: 8.81851349e-07
Iter: 1891 loss: 8.81739879e-07
Iter: 1892 loss: 8.81441792e-07
Iter: 1893 loss: 8.80890866e-07
Iter: 1894 loss: 8.81659162e-07
Iter: 1895 loss: 8.80635241e-07
Iter: 1896 loss: 8.79916342e-07
Iter: 1897 loss: 8.80830157e-07
Iter: 1898 loss: 8.79599611e-07
Iter: 1899 loss: 8.78943638e-07
Iter: 1900 loss: 8.84520091e-07
Iter: 1901 loss: 8.78920787e-07
Iter: 1902 loss: 8.7836429e-07
Iter: 1903 loss: 8.82263294e-07
Iter: 1904 loss: 8.78307e-07
Iter: 1905 loss: 8.77998161e-07
Iter: 1906 loss: 8.77572802e-07
Iter: 1907 loss: 8.7753e-07
Iter: 1908 loss: 8.76965771e-07
Iter: 1909 loss: 8.81561618e-07
Iter: 1910 loss: 8.76941726e-07
Iter: 1911 loss: 8.76499e-07
Iter: 1912 loss: 8.78199671e-07
Iter: 1913 loss: 8.7640376e-07
Iter: 1914 loss: 8.75934916e-07
Iter: 1915 loss: 8.77184959e-07
Iter: 1916 loss: 8.75758928e-07
Iter: 1917 loss: 8.75399223e-07
Iter: 1918 loss: 8.75235173e-07
Iter: 1919 loss: 8.75041621e-07
Iter: 1920 loss: 8.74617399e-07
Iter: 1921 loss: 8.8197487e-07
Iter: 1922 loss: 8.7461558e-07
Iter: 1923 loss: 8.74285433e-07
Iter: 1924 loss: 8.73761451e-07
Iter: 1925 loss: 8.73762644e-07
Iter: 1926 loss: 8.73141175e-07
Iter: 1927 loss: 8.74792477e-07
Iter: 1928 loss: 8.72928695e-07
Iter: 1929 loss: 8.72359578e-07
Iter: 1930 loss: 8.78758556e-07
Iter: 1931 loss: 8.72348153e-07
Iter: 1932 loss: 8.71931206e-07
Iter: 1933 loss: 8.72008854e-07
Iter: 1934 loss: 8.71631187e-07
Iter: 1935 loss: 8.71073098e-07
Iter: 1936 loss: 8.70802864e-07
Iter: 1937 loss: 8.705656e-07
Iter: 1938 loss: 8.69971302e-07
Iter: 1939 loss: 8.76383126e-07
Iter: 1940 loss: 8.69963856e-07
Iter: 1941 loss: 8.69453061e-07
Iter: 1942 loss: 8.70031045e-07
Iter: 1943 loss: 8.69217615e-07
Iter: 1944 loss: 8.68759798e-07
Iter: 1945 loss: 8.6877526e-07
Iter: 1946 loss: 8.68416691e-07
Iter: 1947 loss: 8.68503321e-07
Iter: 1948 loss: 8.68143331e-07
Iter: 1949 loss: 8.67645895e-07
Iter: 1950 loss: 8.69087728e-07
Iter: 1951 loss: 8.67516292e-07
Iter: 1952 loss: 8.67106962e-07
Iter: 1953 loss: 8.69264113e-07
Iter: 1954 loss: 8.67036761e-07
Iter: 1955 loss: 8.66590312e-07
Iter: 1956 loss: 8.66679557e-07
Iter: 1957 loss: 8.66289668e-07
Iter: 1958 loss: 8.65834068e-07
Iter: 1959 loss: 8.65595439e-07
Iter: 1960 loss: 8.65409561e-07
Iter: 1961 loss: 8.64812478e-07
Iter: 1962 loss: 8.71107318e-07
Iter: 1963 loss: 8.64784681e-07
Iter: 1964 loss: 8.64374158e-07
Iter: 1965 loss: 8.66932226e-07
Iter: 1966 loss: 8.64313847e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.6
+ date
Sat Nov  7 14:36:26 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.6/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.6_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.6_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.6_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.6/500_500_500_500_1 --optimizer lbfgs --function f2 --psi 2 --alpha 1.6 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi1.6_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190e55598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190e55730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190d3c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190d3a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190d3aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190ce4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190c91bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190cd0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190c7d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190caeae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190c3e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190bde268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190bdc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190bcc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190bcef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190b7ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190b73840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190b73c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190aea510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190b73e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190b4dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190ccdd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190a776a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2190a77840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186f2e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186ef6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186f1c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186ef6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186ec9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186e80950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186e80c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186e28268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186e5b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186dfba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186df1e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2186df1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 4.91956307e-05
Iter: 2 loss: 4.20895303e-05
Iter: 3 loss: 4.05969076e-05
Iter: 4 loss: 3.61732309e-05
Iter: 5 loss: 2.9779294e-05
Iter: 6 loss: 6.88211876e-05
Iter: 7 loss: 2.8989256e-05
Iter: 8 loss: 2.51295733e-05
Iter: 9 loss: 3.30467228e-05
Iter: 10 loss: 2.35633961e-05
Iter: 11 loss: 2.10874568e-05
Iter: 12 loss: 4.48377759e-05
Iter: 13 loss: 2.09906902e-05
Iter: 14 loss: 1.89173752e-05
Iter: 15 loss: 2.31546874e-05
Iter: 16 loss: 1.80834959e-05
Iter: 17 loss: 1.67104263e-05
Iter: 18 loss: 2.10472917e-05
Iter: 19 loss: 1.63167715e-05
Iter: 20 loss: 1.5037338e-05
Iter: 21 loss: 1.83961711e-05
Iter: 22 loss: 1.46045104e-05
Iter: 23 loss: 1.35579585e-05
Iter: 24 loss: 1.74150682e-05
Iter: 25 loss: 1.32995247e-05
Iter: 26 loss: 1.23541568e-05
Iter: 27 loss: 1.60681138e-05
Iter: 28 loss: 1.21372432e-05
Iter: 29 loss: 1.13087408e-05
Iter: 30 loss: 1.27215972e-05
Iter: 31 loss: 1.09382918e-05
Iter: 32 loss: 1.0305057e-05
Iter: 33 loss: 1.05953022e-05
Iter: 34 loss: 9.87527528e-06
Iter: 35 loss: 9.16312456e-06
Iter: 36 loss: 1.5229e-05
Iter: 37 loss: 9.12377345e-06
Iter: 38 loss: 8.62352499e-06
Iter: 39 loss: 1.12230955e-05
Iter: 40 loss: 8.54395057e-06
Iter: 41 loss: 8.19575507e-06
Iter: 42 loss: 8.75591559e-06
Iter: 43 loss: 8.03485909e-06
Iter: 44 loss: 7.72944622e-06
Iter: 45 loss: 1.21830226e-05
Iter: 46 loss: 7.72890871e-06
Iter: 47 loss: 7.52638e-06
Iter: 48 loss: 7.46375463e-06
Iter: 49 loss: 7.3438664e-06
Iter: 50 loss: 7.11231314e-06
Iter: 51 loss: 1.04976361e-05
Iter: 52 loss: 7.11200391e-06
Iter: 53 loss: 6.96278403e-06
Iter: 54 loss: 6.76030777e-06
Iter: 55 loss: 6.75012598e-06
Iter: 56 loss: 6.5133122e-06
Iter: 57 loss: 7.73198e-06
Iter: 58 loss: 6.47503703e-06
Iter: 59 loss: 6.25213215e-06
Iter: 60 loss: 7.23677113e-06
Iter: 61 loss: 6.20796391e-06
Iter: 62 loss: 6.04388606e-06
Iter: 63 loss: 6.39985046e-06
Iter: 64 loss: 5.980477e-06
Iter: 65 loss: 5.82519e-06
Iter: 66 loss: 6.61574722e-06
Iter: 67 loss: 5.79983953e-06
Iter: 68 loss: 5.66521339e-06
Iter: 69 loss: 5.61054549e-06
Iter: 70 loss: 5.53892505e-06
Iter: 71 loss: 5.36911921e-06
Iter: 72 loss: 5.77312403e-06
Iter: 73 loss: 5.30757779e-06
Iter: 74 loss: 5.18345678e-06
Iter: 75 loss: 6.29752958e-06
Iter: 76 loss: 5.17735498e-06
Iter: 77 loss: 5.06132e-06
Iter: 78 loss: 5.38857512e-06
Iter: 79 loss: 5.02431612e-06
Iter: 80 loss: 4.94616143e-06
Iter: 81 loss: 5.64786023e-06
Iter: 82 loss: 4.94244932e-06
Iter: 83 loss: 4.87339821e-06
Iter: 84 loss: 4.9429118e-06
Iter: 85 loss: 4.83466829e-06
Iter: 86 loss: 4.75619e-06
Iter: 87 loss: 5.07359164e-06
Iter: 88 loss: 4.73882437e-06
Iter: 89 loss: 4.66179654e-06
Iter: 90 loss: 4.81344614e-06
Iter: 91 loss: 4.62982962e-06
Iter: 92 loss: 4.55937425e-06
Iter: 93 loss: 4.51952928e-06
Iter: 94 loss: 4.48891205e-06
Iter: 95 loss: 4.40584063e-06
Iter: 96 loss: 5.4304146e-06
Iter: 97 loss: 4.40506665e-06
Iter: 98 loss: 4.34504136e-06
Iter: 99 loss: 4.55225927e-06
Iter: 100 loss: 4.32940942e-06
Iter: 101 loss: 4.27812029e-06
Iter: 102 loss: 4.28595376e-06
Iter: 103 loss: 4.23936308e-06
Iter: 104 loss: 4.17757747e-06
Iter: 105 loss: 4.62736716e-06
Iter: 106 loss: 4.17234787e-06
Iter: 107 loss: 4.12044756e-06
Iter: 108 loss: 4.11557494e-06
Iter: 109 loss: 4.07748439e-06
Iter: 110 loss: 4.00970657e-06
Iter: 111 loss: 4.1408066e-06
Iter: 112 loss: 3.98120483e-06
Iter: 113 loss: 3.92033689e-06
Iter: 114 loss: 4.1494086e-06
Iter: 115 loss: 3.9055767e-06
Iter: 116 loss: 3.85809881e-06
Iter: 117 loss: 4.60473439e-06
Iter: 118 loss: 3.85812837e-06
Iter: 119 loss: 3.82191092e-06
Iter: 120 loss: 3.83202814e-06
Iter: 121 loss: 3.79577295e-06
Iter: 122 loss: 3.75164132e-06
Iter: 123 loss: 4.08287815e-06
Iter: 124 loss: 3.74823094e-06
Iter: 125 loss: 3.7187624e-06
Iter: 126 loss: 3.74742353e-06
Iter: 127 loss: 3.70177395e-06
Iter: 128 loss: 3.66485642e-06
Iter: 129 loss: 3.73746639e-06
Iter: 130 loss: 3.64971265e-06
Iter: 131 loss: 3.61227603e-06
Iter: 132 loss: 3.62439141e-06
Iter: 133 loss: 3.58567377e-06
Iter: 134 loss: 3.55254929e-06
Iter: 135 loss: 4.05510582e-06
Iter: 136 loss: 3.55244174e-06
Iter: 137 loss: 3.5219939e-06
Iter: 138 loss: 3.50295022e-06
Iter: 139 loss: 3.49065931e-06
Iter: 140 loss: 3.45243984e-06
Iter: 141 loss: 3.62947367e-06
Iter: 142 loss: 3.44532418e-06
Iter: 143 loss: 3.4168911e-06
Iter: 144 loss: 3.55417615e-06
Iter: 145 loss: 3.41172381e-06
Iter: 146 loss: 3.38070367e-06
Iter: 147 loss: 3.37419306e-06
Iter: 148 loss: 3.35402683e-06
Iter: 149 loss: 3.31816454e-06
Iter: 150 loss: 3.34208698e-06
Iter: 151 loss: 3.29562044e-06
Iter: 152 loss: 3.27399152e-06
Iter: 153 loss: 3.27135035e-06
Iter: 154 loss: 3.24969824e-06
Iter: 155 loss: 3.2862863e-06
Iter: 156 loss: 3.23980544e-06
Iter: 157 loss: 3.21808056e-06
Iter: 158 loss: 3.28681381e-06
Iter: 159 loss: 3.21191055e-06
Iter: 160 loss: 3.19232572e-06
Iter: 161 loss: 3.2652697e-06
Iter: 162 loss: 3.18744742e-06
Iter: 163 loss: 3.16794694e-06
Iter: 164 loss: 3.14828549e-06
Iter: 165 loss: 3.14431099e-06
Iter: 166 loss: 3.11859708e-06
Iter: 167 loss: 3.35987534e-06
Iter: 168 loss: 3.11768918e-06
Iter: 169 loss: 3.09609277e-06
Iter: 170 loss: 3.11386748e-06
Iter: 171 loss: 3.08326571e-06
Iter: 172 loss: 3.06236734e-06
Iter: 173 loss: 3.25202245e-06
Iter: 174 loss: 3.06138463e-06
Iter: 175 loss: 3.04353398e-06
Iter: 176 loss: 3.03959e-06
Iter: 177 loss: 3.02796798e-06
Iter: 178 loss: 3.00800116e-06
Iter: 179 loss: 3.04203968e-06
Iter: 180 loss: 2.99892918e-06
Iter: 181 loss: 2.97879865e-06
Iter: 182 loss: 3.16109799e-06
Iter: 183 loss: 2.97786073e-06
Iter: 184 loss: 2.96077133e-06
Iter: 185 loss: 2.95761424e-06
Iter: 186 loss: 2.94603569e-06
Iter: 187 loss: 2.92237473e-06
Iter: 188 loss: 2.972532e-06
Iter: 189 loss: 2.91298284e-06
Iter: 190 loss: 2.89324043e-06
Iter: 191 loss: 3.11126223e-06
Iter: 192 loss: 2.89274521e-06
Iter: 193 loss: 2.87305193e-06
Iter: 194 loss: 2.92153118e-06
Iter: 195 loss: 2.86603427e-06
Iter: 196 loss: 2.85359147e-06
Iter: 197 loss: 2.87015882e-06
Iter: 198 loss: 2.84727412e-06
Iter: 199 loss: 2.82993801e-06
Iter: 200 loss: 2.88568526e-06
Iter: 201 loss: 2.82489327e-06
Iter: 202 loss: 2.81100756e-06
Iter: 203 loss: 2.80507811e-06
Iter: 204 loss: 2.79807864e-06
Iter: 205 loss: 2.78243533e-06
Iter: 206 loss: 2.90755065e-06
Iter: 207 loss: 2.78153266e-06
Iter: 208 loss: 2.76634182e-06
Iter: 209 loss: 2.80803215e-06
Iter: 210 loss: 2.76148489e-06
Iter: 211 loss: 2.74808144e-06
Iter: 212 loss: 2.78073912e-06
Iter: 213 loss: 2.74346121e-06
Iter: 214 loss: 2.7308804e-06
Iter: 215 loss: 2.75973889e-06
Iter: 216 loss: 2.72628085e-06
Iter: 217 loss: 2.71082376e-06
Iter: 218 loss: 2.7117062e-06
Iter: 219 loss: 2.69865086e-06
Iter: 220 loss: 2.68069562e-06
Iter: 221 loss: 2.77001186e-06
Iter: 222 loss: 2.67765972e-06
Iter: 223 loss: 2.66403595e-06
Iter: 224 loss: 2.75658249e-06
Iter: 225 loss: 2.66267375e-06
Iter: 226 loss: 2.65116432e-06
Iter: 227 loss: 2.65965e-06
Iter: 228 loss: 2.64395521e-06
Iter: 229 loss: 2.63222637e-06
Iter: 230 loss: 2.75642583e-06
Iter: 231 loss: 2.63202014e-06
Iter: 232 loss: 2.62135859e-06
Iter: 233 loss: 2.6337093e-06
Iter: 234 loss: 2.61571404e-06
Iter: 235 loss: 2.60606475e-06
Iter: 236 loss: 2.60901629e-06
Iter: 237 loss: 2.59922535e-06
Iter: 238 loss: 2.58872205e-06
Iter: 239 loss: 2.70333317e-06
Iter: 240 loss: 2.58846421e-06
Iter: 241 loss: 2.57945544e-06
Iter: 242 loss: 2.57081774e-06
Iter: 243 loss: 2.56875387e-06
Iter: 244 loss: 2.55630948e-06
Iter: 245 loss: 2.58884916e-06
Iter: 246 loss: 2.55199211e-06
Iter: 247 loss: 2.54071688e-06
Iter: 248 loss: 2.64025448e-06
Iter: 249 loss: 2.54011502e-06
Iter: 250 loss: 2.52896052e-06
Iter: 251 loss: 2.53876e-06
Iter: 252 loss: 2.52239852e-06
Iter: 253 loss: 2.51243364e-06
Iter: 254 loss: 2.51082588e-06
Iter: 255 loss: 2.50389166e-06
Iter: 256 loss: 2.49087043e-06
Iter: 257 loss: 2.58802493e-06
Iter: 258 loss: 2.48984043e-06
Iter: 259 loss: 2.4787696e-06
Iter: 260 loss: 2.51820165e-06
Iter: 261 loss: 2.47607204e-06
Iter: 262 loss: 2.46594777e-06
Iter: 263 loss: 2.47195521e-06
Iter: 264 loss: 2.45954493e-06
Iter: 265 loss: 2.45077536e-06
Iter: 266 loss: 2.45086221e-06
Iter: 267 loss: 2.443011e-06
Iter: 268 loss: 2.44743205e-06
Iter: 269 loss: 2.43786417e-06
Iter: 270 loss: 2.42949409e-06
Iter: 271 loss: 2.46017044e-06
Iter: 272 loss: 2.42741089e-06
Iter: 273 loss: 2.41890302e-06
Iter: 274 loss: 2.41264433e-06
Iter: 275 loss: 2.40984855e-06
Iter: 276 loss: 2.40308623e-06
Iter: 277 loss: 2.40260488e-06
Iter: 278 loss: 2.39692918e-06
Iter: 279 loss: 2.38754387e-06
Iter: 280 loss: 2.38748248e-06
Iter: 281 loss: 2.37668837e-06
Iter: 282 loss: 2.42934357e-06
Iter: 283 loss: 2.37474251e-06
Iter: 284 loss: 2.36707297e-06
Iter: 285 loss: 2.41433827e-06
Iter: 286 loss: 2.36609503e-06
Iter: 287 loss: 2.35832772e-06
Iter: 288 loss: 2.37896029e-06
Iter: 289 loss: 2.35585458e-06
Iter: 290 loss: 2.34826439e-06
Iter: 291 loss: 2.34123081e-06
Iter: 292 loss: 2.33944456e-06
Iter: 293 loss: 2.3282123e-06
Iter: 294 loss: 2.35389416e-06
Iter: 295 loss: 2.32414436e-06
Iter: 296 loss: 2.31458034e-06
Iter: 297 loss: 2.42552392e-06
Iter: 298 loss: 2.31438707e-06
Iter: 299 loss: 2.3079092e-06
Iter: 300 loss: 2.34680965e-06
Iter: 301 loss: 2.3071716e-06
Iter: 302 loss: 2.30134606e-06
Iter: 303 loss: 2.31564059e-06
Iter: 304 loss: 2.29927628e-06
Iter: 305 loss: 2.29260627e-06
Iter: 306 loss: 2.30229625e-06
Iter: 307 loss: 2.28917133e-06
Iter: 308 loss: 2.28273939e-06
Iter: 309 loss: 2.28044405e-06
Iter: 310 loss: 2.27681448e-06
Iter: 311 loss: 2.27030478e-06
Iter: 312 loss: 2.27025248e-06
Iter: 313 loss: 2.26444399e-06
Iter: 314 loss: 2.25878e-06
Iter: 315 loss: 2.2574377e-06
Iter: 316 loss: 2.25019448e-06
Iter: 317 loss: 2.32267735e-06
Iter: 318 loss: 2.24998121e-06
Iter: 319 loss: 2.24353562e-06
Iter: 320 loss: 2.23724737e-06
Iter: 321 loss: 2.23583902e-06
Iter: 322 loss: 2.22929521e-06
Iter: 323 loss: 2.32517141e-06
Iter: 324 loss: 2.2293375e-06
Iter: 325 loss: 2.22274275e-06
Iter: 326 loss: 2.22407516e-06
Iter: 327 loss: 2.21786649e-06
Iter: 328 loss: 2.21030791e-06
Iter: 329 loss: 2.21994196e-06
Iter: 330 loss: 2.20637185e-06
Iter: 331 loss: 2.19907088e-06
Iter: 332 loss: 2.21861319e-06
Iter: 333 loss: 2.19653521e-06
Iter: 334 loss: 2.1885262e-06
Iter: 335 loss: 2.20550783e-06
Iter: 336 loss: 2.18538662e-06
Iter: 337 loss: 2.1812948e-06
Iter: 338 loss: 2.1805904e-06
Iter: 339 loss: 2.17669503e-06
Iter: 340 loss: 2.17048728e-06
Iter: 341 loss: 2.17043453e-06
Iter: 342 loss: 2.16339913e-06
Iter: 343 loss: 2.20270294e-06
Iter: 344 loss: 2.16241051e-06
Iter: 345 loss: 2.1566193e-06
Iter: 346 loss: 2.17426077e-06
Iter: 347 loss: 2.15485579e-06
Iter: 348 loss: 2.14975216e-06
Iter: 349 loss: 2.15619821e-06
Iter: 350 loss: 2.14716738e-06
Iter: 351 loss: 2.14050215e-06
Iter: 352 loss: 2.17727188e-06
Iter: 353 loss: 2.13957878e-06
Iter: 354 loss: 2.13496332e-06
Iter: 355 loss: 2.13272733e-06
Iter: 356 loss: 2.13048861e-06
Iter: 357 loss: 2.12474538e-06
Iter: 358 loss: 2.15852515e-06
Iter: 359 loss: 2.12401233e-06
Iter: 360 loss: 2.11791667e-06
Iter: 361 loss: 2.13894805e-06
Iter: 362 loss: 2.11643101e-06
Iter: 363 loss: 2.11098836e-06
Iter: 364 loss: 2.11777e-06
Iter: 365 loss: 2.10822532e-06
Iter: 366 loss: 2.10280746e-06
Iter: 367 loss: 2.12766e-06
Iter: 368 loss: 2.10180269e-06
Iter: 369 loss: 2.09638074e-06
Iter: 370 loss: 2.09434529e-06
Iter: 371 loss: 2.09140308e-06
Iter: 372 loss: 2.08523738e-06
Iter: 373 loss: 2.10481221e-06
Iter: 374 loss: 2.08356869e-06
Iter: 375 loss: 2.07834091e-06
Iter: 376 loss: 2.07833091e-06
Iter: 377 loss: 2.07401945e-06
Iter: 378 loss: 2.07534e-06
Iter: 379 loss: 2.07092171e-06
Iter: 380 loss: 2.06691698e-06
Iter: 381 loss: 2.06045547e-06
Iter: 382 loss: 2.06034e-06
Iter: 383 loss: 2.05429842e-06
Iter: 384 loss: 2.05430638e-06
Iter: 385 loss: 2.04974549e-06
Iter: 386 loss: 2.06798472e-06
Iter: 387 loss: 2.04887692e-06
Iter: 388 loss: 2.04486309e-06
Iter: 389 loss: 2.04242497e-06
Iter: 390 loss: 2.04089338e-06
Iter: 391 loss: 2.03509171e-06
Iter: 392 loss: 2.06140771e-06
Iter: 393 loss: 2.0340085e-06
Iter: 394 loss: 2.02857495e-06
Iter: 395 loss: 2.054172e-06
Iter: 396 loss: 2.02744536e-06
Iter: 397 loss: 2.02317779e-06
Iter: 398 loss: 2.02746378e-06
Iter: 399 loss: 2.02078172e-06
Iter: 400 loss: 2.01552575e-06
Iter: 401 loss: 2.04633284e-06
Iter: 402 loss: 2.01475814e-06
Iter: 403 loss: 2.01044031e-06
Iter: 404 loss: 2.00949853e-06
Iter: 405 loss: 2.00670956e-06
Iter: 406 loss: 2.00101431e-06
Iter: 407 loss: 2.00356e-06
Iter: 408 loss: 1.99706938e-06
Iter: 409 loss: 1.99178658e-06
Iter: 410 loss: 1.9916688e-06
Iter: 411 loss: 1.98743555e-06
Iter: 412 loss: 2.00618865e-06
Iter: 413 loss: 1.98659791e-06
Iter: 414 loss: 1.98336693e-06
Iter: 415 loss: 1.98213661e-06
Iter: 416 loss: 1.98044245e-06
Iter: 417 loss: 1.97552345e-06
Iter: 418 loss: 1.99057058e-06
Iter: 419 loss: 1.97400414e-06
Iter: 420 loss: 1.96969359e-06
Iter: 421 loss: 1.97089275e-06
Iter: 422 loss: 1.96657925e-06
Iter: 423 loss: 1.96178462e-06
Iter: 424 loss: 2.00860131e-06
Iter: 425 loss: 1.96172368e-06
Iter: 426 loss: 1.9568015e-06
Iter: 427 loss: 1.9628169e-06
Iter: 428 loss: 1.95426901e-06
Iter: 429 loss: 1.95012785e-06
Iter: 430 loss: 1.94785412e-06
Iter: 431 loss: 1.94599693e-06
Iter: 432 loss: 1.94071663e-06
Iter: 433 loss: 2.00011573e-06
Iter: 434 loss: 1.94059498e-06
Iter: 435 loss: 1.9360773e-06
Iter: 436 loss: 1.95236362e-06
Iter: 437 loss: 1.93504366e-06
Iter: 438 loss: 1.93144706e-06
Iter: 439 loss: 1.93429969e-06
Iter: 440 loss: 1.92929406e-06
Iter: 441 loss: 1.92498965e-06
Iter: 442 loss: 1.93285177e-06
Iter: 443 loss: 1.92311336e-06
Iter: 444 loss: 1.91852e-06
Iter: 445 loss: 1.95016582e-06
Iter: 446 loss: 1.91801792e-06
Iter: 447 loss: 1.91425806e-06
Iter: 448 loss: 1.91640834e-06
Iter: 449 loss: 1.911852e-06
Iter: 450 loss: 1.90669039e-06
Iter: 451 loss: 1.95399912e-06
Iter: 452 loss: 1.90647211e-06
Iter: 453 loss: 1.90368269e-06
Iter: 454 loss: 1.89883315e-06
Iter: 455 loss: 1.89887226e-06
Iter: 456 loss: 1.89324942e-06
Iter: 457 loss: 1.90710875e-06
Iter: 458 loss: 1.8912192e-06
Iter: 459 loss: 1.88663171e-06
Iter: 460 loss: 1.92365019e-06
Iter: 461 loss: 1.8862371e-06
Iter: 462 loss: 1.88185095e-06
Iter: 463 loss: 1.90164326e-06
Iter: 464 loss: 1.88108868e-06
Iter: 465 loss: 1.87716034e-06
Iter: 466 loss: 1.87732485e-06
Iter: 467 loss: 1.87415503e-06
Iter: 468 loss: 1.87010687e-06
Iter: 469 loss: 1.88354181e-06
Iter: 470 loss: 1.86906e-06
Iter: 471 loss: 1.86401212e-06
Iter: 472 loss: 1.87492424e-06
Iter: 473 loss: 1.86209365e-06
Iter: 474 loss: 1.85849058e-06
Iter: 475 loss: 1.88534648e-06
Iter: 476 loss: 1.85824069e-06
Iter: 477 loss: 1.85474846e-06
Iter: 478 loss: 1.85434419e-06
Iter: 479 loss: 1.85168938e-06
Iter: 480 loss: 1.84760381e-06
Iter: 481 loss: 1.85364456e-06
Iter: 482 loss: 1.84567364e-06
Iter: 483 loss: 1.84192822e-06
Iter: 484 loss: 1.887606e-06
Iter: 485 loss: 1.84185774e-06
Iter: 486 loss: 1.8385382e-06
Iter: 487 loss: 1.84861278e-06
Iter: 488 loss: 1.83759607e-06
Iter: 489 loss: 1.83481006e-06
Iter: 490 loss: 1.83283532e-06
Iter: 491 loss: 1.83181396e-06
Iter: 492 loss: 1.82799158e-06
Iter: 493 loss: 1.85147894e-06
Iter: 494 loss: 1.82744702e-06
Iter: 495 loss: 1.82361373e-06
Iter: 496 loss: 1.8243943e-06
Iter: 497 loss: 1.8206606e-06
Iter: 498 loss: 1.81629161e-06
Iter: 499 loss: 1.82110875e-06
Iter: 500 loss: 1.81389339e-06
Iter: 501 loss: 1.81017037e-06
Iter: 502 loss: 1.86830607e-06
Iter: 503 loss: 1.81015525e-06
Iter: 504 loss: 1.80642814e-06
Iter: 505 loss: 1.80766051e-06
Iter: 506 loss: 1.80373593e-06
Iter: 507 loss: 1.79998e-06
Iter: 508 loss: 1.80982238e-06
Iter: 509 loss: 1.7987154e-06
Iter: 510 loss: 1.7953912e-06
Iter: 511 loss: 1.79765505e-06
Iter: 512 loss: 1.79329072e-06
Iter: 513 loss: 1.78893458e-06
Iter: 514 loss: 1.83987561e-06
Iter: 515 loss: 1.7888558e-06
Iter: 516 loss: 1.7866405e-06
Iter: 517 loss: 1.78491905e-06
Iter: 518 loss: 1.78417781e-06
Iter: 519 loss: 1.7804316e-06
Iter: 520 loss: 1.79781523e-06
Iter: 521 loss: 1.77977336e-06
Iter: 522 loss: 1.77658853e-06
Iter: 523 loss: 1.80045936e-06
Iter: 524 loss: 1.7763881e-06
Iter: 525 loss: 1.77395304e-06
Iter: 526 loss: 1.77939523e-06
Iter: 527 loss: 1.77290372e-06
Iter: 528 loss: 1.77029574e-06
Iter: 529 loss: 1.76764809e-06
Iter: 530 loss: 1.7671332e-06
Iter: 531 loss: 1.76265098e-06
Iter: 532 loss: 1.76664093e-06
Iter: 533 loss: 1.76006199e-06
Iter: 534 loss: 1.75512059e-06
Iter: 535 loss: 1.78304663e-06
Iter: 536 loss: 1.75441073e-06
Iter: 537 loss: 1.75061155e-06
Iter: 538 loss: 1.76836011e-06
Iter: 539 loss: 1.74989736e-06
Iter: 540 loss: 1.74638308e-06
Iter: 541 loss: 1.76816684e-06
Iter: 542 loss: 1.74594948e-06
Iter: 543 loss: 1.74330216e-06
Iter: 544 loss: 1.74482943e-06
Iter: 545 loss: 1.74155309e-06
Iter: 546 loss: 1.73830153e-06
Iter: 547 loss: 1.75565106e-06
Iter: 548 loss: 1.73779836e-06
Iter: 549 loss: 1.73510989e-06
Iter: 550 loss: 1.73587387e-06
Iter: 551 loss: 1.73315459e-06
Iter: 552 loss: 1.7295929e-06
Iter: 553 loss: 1.73704473e-06
Iter: 554 loss: 1.72825366e-06
Iter: 555 loss: 1.72513091e-06
Iter: 556 loss: 1.76563105e-06
Iter: 557 loss: 1.72511602e-06
Iter: 558 loss: 1.72262355e-06
Iter: 559 loss: 1.71942156e-06
Iter: 560 loss: 1.71914576e-06
Iter: 561 loss: 1.71675106e-06
Iter: 562 loss: 1.71659929e-06
Iter: 563 loss: 1.714463e-06
Iter: 564 loss: 1.71153488e-06
Iter: 565 loss: 1.7114935e-06
Iter: 566 loss: 1.70798546e-06
Iter: 567 loss: 1.70955104e-06
Iter: 568 loss: 1.70567341e-06
Iter: 569 loss: 1.70140652e-06
Iter: 570 loss: 1.73221167e-06
Iter: 571 loss: 1.70099486e-06
Iter: 572 loss: 1.69810357e-06
Iter: 573 loss: 1.71274246e-06
Iter: 574 loss: 1.69759971e-06
Iter: 575 loss: 1.69495195e-06
Iter: 576 loss: 1.69180646e-06
Iter: 577 loss: 1.69149394e-06
Iter: 578 loss: 1.68855206e-06
Iter: 579 loss: 1.68860061e-06
Iter: 580 loss: 1.68607039e-06
Iter: 581 loss: 1.69401665e-06
Iter: 582 loss: 1.68532938e-06
Iter: 583 loss: 1.68306337e-06
Iter: 584 loss: 1.68002589e-06
Iter: 585 loss: 1.6797535e-06
Iter: 586 loss: 1.6764219e-06
Iter: 587 loss: 1.70560679e-06
Iter: 588 loss: 1.67624751e-06
Iter: 589 loss: 1.67336157e-06
Iter: 590 loss: 1.68543477e-06
Iter: 591 loss: 1.67263215e-06
Iter: 592 loss: 1.66968528e-06
Iter: 593 loss: 1.67473684e-06
Iter: 594 loss: 1.66839118e-06
Iter: 595 loss: 1.66617497e-06
Iter: 596 loss: 1.69000043e-06
Iter: 597 loss: 1.6662168e-06
Iter: 598 loss: 1.6643603e-06
Iter: 599 loss: 1.66309485e-06
Iter: 600 loss: 1.66236566e-06
Iter: 601 loss: 1.65947199e-06
Iter: 602 loss: 1.66683253e-06
Iter: 603 loss: 1.65857932e-06
Iter: 604 loss: 1.65545816e-06
Iter: 605 loss: 1.663749e-06
Iter: 606 loss: 1.65448546e-06
Iter: 607 loss: 1.65202221e-06
Iter: 608 loss: 1.65026313e-06
Iter: 609 loss: 1.64941821e-06
Iter: 610 loss: 1.6458838e-06
Iter: 611 loss: 1.66492055e-06
Iter: 612 loss: 1.64534879e-06
Iter: 613 loss: 1.64223434e-06
Iter: 614 loss: 1.66139534e-06
Iter: 615 loss: 1.64187054e-06
Iter: 616 loss: 1.63932589e-06
Iter: 617 loss: 1.64368896e-06
Iter: 618 loss: 1.63820164e-06
Iter: 619 loss: 1.63544451e-06
Iter: 620 loss: 1.64157348e-06
Iter: 621 loss: 1.63433435e-06
Iter: 622 loss: 1.63166487e-06
Iter: 623 loss: 1.66044538e-06
Iter: 624 loss: 1.63154925e-06
Iter: 625 loss: 1.62971764e-06
Iter: 626 loss: 1.62642198e-06
Iter: 627 loss: 1.62637241e-06
Iter: 628 loss: 1.62308015e-06
Iter: 629 loss: 1.64062772e-06
Iter: 630 loss: 1.62259732e-06
Iter: 631 loss: 1.62058859e-06
Iter: 632 loss: 1.62053311e-06
Iter: 633 loss: 1.61895559e-06
Iter: 634 loss: 1.61664741e-06
Iter: 635 loss: 1.61659659e-06
Iter: 636 loss: 1.61414641e-06
Iter: 637 loss: 1.6378325e-06
Iter: 638 loss: 1.61402909e-06
Iter: 639 loss: 1.61201672e-06
Iter: 640 loss: 1.61318712e-06
Iter: 641 loss: 1.61067499e-06
Iter: 642 loss: 1.6083377e-06
Iter: 643 loss: 1.61120215e-06
Iter: 644 loss: 1.60715945e-06
Iter: 645 loss: 1.60452328e-06
Iter: 646 loss: 1.61506682e-06
Iter: 647 loss: 1.60396917e-06
Iter: 648 loss: 1.60117088e-06
Iter: 649 loss: 1.60645573e-06
Iter: 650 loss: 1.60002492e-06
Iter: 651 loss: 1.59734873e-06
Iter: 652 loss: 1.59626552e-06
Iter: 653 loss: 1.59491424e-06
Iter: 654 loss: 1.5917733e-06
Iter: 655 loss: 1.61835078e-06
Iter: 656 loss: 1.59165302e-06
Iter: 657 loss: 1.58895011e-06
Iter: 658 loss: 1.60172829e-06
Iter: 659 loss: 1.58844546e-06
Iter: 660 loss: 1.58619957e-06
Iter: 661 loss: 1.59201511e-06
Iter: 662 loss: 1.58529781e-06
Iter: 663 loss: 1.58288572e-06
Iter: 664 loss: 1.59325668e-06
Iter: 665 loss: 1.58242574e-06
Iter: 666 loss: 1.58025819e-06
Iter: 667 loss: 1.57995601e-06
Iter: 668 loss: 1.57831892e-06
Iter: 669 loss: 1.57592945e-06
Iter: 670 loss: 1.5951955e-06
Iter: 671 loss: 1.57574061e-06
Iter: 672 loss: 1.5734463e-06
Iter: 673 loss: 1.58351827e-06
Iter: 674 loss: 1.57291765e-06
Iter: 675 loss: 1.57142972e-06
Iter: 676 loss: 1.56878775e-06
Iter: 677 loss: 1.56879025e-06
Iter: 678 loss: 1.56618148e-06
Iter: 679 loss: 1.5879466e-06
Iter: 680 loss: 1.56606438e-06
Iter: 681 loss: 1.56358078e-06
Iter: 682 loss: 1.57394311e-06
Iter: 683 loss: 1.56306794e-06
Iter: 684 loss: 1.5611314e-06
Iter: 685 loss: 1.56064823e-06
Iter: 686 loss: 1.55938267e-06
Iter: 687 loss: 1.55651901e-06
Iter: 688 loss: 1.56087344e-06
Iter: 689 loss: 1.555116e-06
Iter: 690 loss: 1.55267912e-06
Iter: 691 loss: 1.58109071e-06
Iter: 692 loss: 1.55268629e-06
Iter: 693 loss: 1.55048224e-06
Iter: 694 loss: 1.55092232e-06
Iter: 695 loss: 1.54898885e-06
Iter: 696 loss: 1.54641691e-06
Iter: 697 loss: 1.55455268e-06
Iter: 698 loss: 1.54578333e-06
Iter: 699 loss: 1.54341137e-06
Iter: 700 loss: 1.54645318e-06
Iter: 701 loss: 1.54215468e-06
Iter: 702 loss: 1.53936219e-06
Iter: 703 loss: 1.56732881e-06
Iter: 704 loss: 1.5392543e-06
Iter: 705 loss: 1.5373264e-06
Iter: 706 loss: 1.53996734e-06
Iter: 707 loss: 1.53646579e-06
Iter: 708 loss: 1.53435758e-06
Iter: 709 loss: 1.544013e-06
Iter: 710 loss: 1.53397798e-06
Iter: 711 loss: 1.5321616e-06
Iter: 712 loss: 1.53739268e-06
Iter: 713 loss: 1.53161818e-06
Iter: 714 loss: 1.52951395e-06
Iter: 715 loss: 1.53046449e-06
Iter: 716 loss: 1.5281081e-06
Iter: 717 loss: 1.52578491e-06
Iter: 718 loss: 1.52695975e-06
Iter: 719 loss: 1.52418465e-06
Iter: 720 loss: 1.5217546e-06
Iter: 721 loss: 1.52568805e-06
Iter: 722 loss: 1.52061705e-06
Iter: 723 loss: 1.51799532e-06
Iter: 724 loss: 1.53237215e-06
Iter: 725 loss: 1.51757536e-06
Iter: 726 loss: 1.51552138e-06
Iter: 727 loss: 1.54134136e-06
Iter: 728 loss: 1.51548772e-06
Iter: 729 loss: 1.51405277e-06
Iter: 730 loss: 1.51280665e-06
Iter: 731 loss: 1.51251572e-06
Iter: 732 loss: 1.51001575e-06
Iter: 733 loss: 1.51079837e-06
Iter: 734 loss: 1.50827373e-06
Iter: 735 loss: 1.505505e-06
Iter: 736 loss: 1.5355572e-06
Iter: 737 loss: 1.50540654e-06
Iter: 738 loss: 1.50316373e-06
Iter: 739 loss: 1.50982987e-06
Iter: 740 loss: 1.50248923e-06
Iter: 741 loss: 1.50073549e-06
Iter: 742 loss: 1.49950142e-06
Iter: 743 loss: 1.49880907e-06
Iter: 744 loss: 1.49722928e-06
Iter: 745 loss: 1.49704147e-06
Iter: 746 loss: 1.49585185e-06
Iter: 747 loss: 1.49679727e-06
Iter: 748 loss: 1.49513221e-06
Iter: 749 loss: 1.49349978e-06
Iter: 750 loss: 1.49309358e-06
Iter: 751 loss: 1.49194966e-06
Iter: 752 loss: 1.48965705e-06
Iter: 753 loss: 1.50745313e-06
Iter: 754 loss: 1.48945628e-06
Iter: 755 loss: 1.48805123e-06
Iter: 756 loss: 1.48951688e-06
Iter: 757 loss: 1.48728031e-06
Iter: 758 loss: 1.48519791e-06
Iter: 759 loss: 1.48645381e-06
Iter: 760 loss: 1.48382492e-06
Iter: 761 loss: 1.48179231e-06
Iter: 762 loss: 1.48263825e-06
Iter: 763 loss: 1.48036929e-06
Iter: 764 loss: 1.47764763e-06
Iter: 765 loss: 1.4857244e-06
Iter: 766 loss: 1.47681874e-06
Iter: 767 loss: 1.47450419e-06
Iter: 768 loss: 1.49926348e-06
Iter: 769 loss: 1.47447349e-06
Iter: 770 loss: 1.47260357e-06
Iter: 771 loss: 1.48031211e-06
Iter: 772 loss: 1.4722292e-06
Iter: 773 loss: 1.47062553e-06
Iter: 774 loss: 1.46834498e-06
Iter: 775 loss: 1.46828347e-06
Iter: 776 loss: 1.46599905e-06
Iter: 777 loss: 1.489851e-06
Iter: 778 loss: 1.46589468e-06
Iter: 779 loss: 1.46406057e-06
Iter: 780 loss: 1.47090987e-06
Iter: 781 loss: 1.46360367e-06
Iter: 782 loss: 1.46188006e-06
Iter: 783 loss: 1.46095476e-06
Iter: 784 loss: 1.46015759e-06
Iter: 785 loss: 1.45865033e-06
Iter: 786 loss: 1.45859826e-06
Iter: 787 loss: 1.45709396e-06
Iter: 788 loss: 1.4565536e-06
Iter: 789 loss: 1.45580884e-06
Iter: 790 loss: 1.45392096e-06
Iter: 791 loss: 1.45836611e-06
Iter: 792 loss: 1.45320087e-06
Iter: 793 loss: 1.45133095e-06
Iter: 794 loss: 1.45659851e-06
Iter: 795 loss: 1.45069794e-06
Iter: 796 loss: 1.44898149e-06
Iter: 797 loss: 1.45510512e-06
Iter: 798 loss: 1.44854744e-06
Iter: 799 loss: 1.4467164e-06
Iter: 800 loss: 1.45220906e-06
Iter: 801 loss: 1.44611954e-06
Iter: 802 loss: 1.44444368e-06
Iter: 803 loss: 1.44580247e-06
Iter: 804 loss: 1.44339913e-06
Iter: 805 loss: 1.44139017e-06
Iter: 806 loss: 1.44107833e-06
Iter: 807 loss: 1.43970738e-06
Iter: 808 loss: 1.43724628e-06
Iter: 809 loss: 1.45617764e-06
Iter: 810 loss: 1.43705552e-06
Iter: 811 loss: 1.43530417e-06
Iter: 812 loss: 1.45375316e-06
Iter: 813 loss: 1.43523766e-06
Iter: 814 loss: 1.43372654e-06
Iter: 815 loss: 1.43249974e-06
Iter: 816 loss: 1.43208388e-06
Iter: 817 loss: 1.42994827e-06
Iter: 818 loss: 1.43321154e-06
Iter: 819 loss: 1.42899489e-06
Iter: 820 loss: 1.42712224e-06
Iter: 821 loss: 1.44706792e-06
Iter: 822 loss: 1.42706153e-06
Iter: 823 loss: 1.42547424e-06
Iter: 824 loss: 1.42751514e-06
Iter: 825 loss: 1.42466558e-06
Iter: 826 loss: 1.42301019e-06
Iter: 827 loss: 1.42950421e-06
Iter: 828 loss: 1.42270756e-06
Iter: 829 loss: 1.42067836e-06
Iter: 830 loss: 1.4264964e-06
Iter: 831 loss: 1.42006786e-06
Iter: 832 loss: 1.41874204e-06
Iter: 833 loss: 1.41864643e-06
Iter: 834 loss: 1.4175821e-06
Iter: 835 loss: 1.41589487e-06
Iter: 836 loss: 1.42232375e-06
Iter: 837 loss: 1.41546275e-06
Iter: 838 loss: 1.41359237e-06
Iter: 839 loss: 1.42116596e-06
Iter: 840 loss: 1.41315957e-06
Iter: 841 loss: 1.41173518e-06
Iter: 842 loss: 1.415876e-06
Iter: 843 loss: 1.41136343e-06
Iter: 844 loss: 1.40976942e-06
Iter: 845 loss: 1.41074156e-06
Iter: 846 loss: 1.40880411e-06
Iter: 847 loss: 1.40679595e-06
Iter: 848 loss: 1.40784277e-06
Iter: 849 loss: 1.40551106e-06
Iter: 850 loss: 1.40327768e-06
Iter: 851 loss: 1.40706265e-06
Iter: 852 loss: 1.40220391e-06
Iter: 853 loss: 1.40065754e-06
Iter: 854 loss: 1.40062821e-06
Iter: 855 loss: 1.39931899e-06
Iter: 856 loss: 1.39939721e-06
Iter: 857 loss: 1.39831673e-06
Iter: 858 loss: 1.39680742e-06
Iter: 859 loss: 1.39809322e-06
Iter: 860 loss: 1.39602844e-06
Iter: 861 loss: 1.39416579e-06
Iter: 862 loss: 1.40292559e-06
Iter: 863 loss: 1.39390193e-06
Iter: 864 loss: 1.39249482e-06
Iter: 865 loss: 1.40091151e-06
Iter: 866 loss: 1.39230542e-06
Iter: 867 loss: 1.39097074e-06
Iter: 868 loss: 1.39256167e-06
Iter: 869 loss: 1.39022404e-06
Iter: 870 loss: 1.38836106e-06
Iter: 871 loss: 1.39657141e-06
Iter: 872 loss: 1.38789414e-06
Iter: 873 loss: 1.3867932e-06
Iter: 874 loss: 1.3860905e-06
Iter: 875 loss: 1.38558585e-06
Iter: 876 loss: 1.38376765e-06
Iter: 877 loss: 1.38786902e-06
Iter: 878 loss: 1.3830653e-06
Iter: 879 loss: 1.38101973e-06
Iter: 880 loss: 1.39915664e-06
Iter: 881 loss: 1.38094788e-06
Iter: 882 loss: 1.37954908e-06
Iter: 883 loss: 1.37906852e-06
Iter: 884 loss: 1.37833069e-06
Iter: 885 loss: 1.37654729e-06
Iter: 886 loss: 1.38922917e-06
Iter: 887 loss: 1.37645429e-06
Iter: 888 loss: 1.37525899e-06
Iter: 889 loss: 1.37612392e-06
Iter: 890 loss: 1.37446932e-06
Iter: 891 loss: 1.37279471e-06
Iter: 892 loss: 1.3731642e-06
Iter: 893 loss: 1.37152392e-06
Iter: 894 loss: 1.36996937e-06
Iter: 895 loss: 1.39062104e-06
Iter: 896 loss: 1.36996596e-06
Iter: 897 loss: 1.36837139e-06
Iter: 898 loss: 1.37047687e-06
Iter: 899 loss: 1.36760491e-06
Iter: 900 loss: 1.36629478e-06
Iter: 901 loss: 1.36527115e-06
Iter: 902 loss: 1.36480162e-06
Iter: 903 loss: 1.36278072e-06
Iter: 904 loss: 1.37260827e-06
Iter: 905 loss: 1.36237236e-06
Iter: 906 loss: 1.36046742e-06
Iter: 907 loss: 1.37630173e-06
Iter: 908 loss: 1.36035874e-06
Iter: 909 loss: 1.35924233e-06
Iter: 910 loss: 1.36355175e-06
Iter: 911 loss: 1.35893742e-06
Iter: 912 loss: 1.35763298e-06
Iter: 913 loss: 1.36097765e-06
Iter: 914 loss: 1.35717505e-06
Iter: 915 loss: 1.35607206e-06
Iter: 916 loss: 1.35581899e-06
Iter: 917 loss: 1.35504581e-06
Iter: 918 loss: 1.35349046e-06
Iter: 919 loss: 1.35672644e-06
Iter: 920 loss: 1.35286609e-06
Iter: 921 loss: 1.35161645e-06
Iter: 922 loss: 1.35162213e-06
Iter: 923 loss: 1.35060372e-06
Iter: 924 loss: 1.34894321e-06
Iter: 925 loss: 1.34893082e-06
Iter: 926 loss: 1.34731044e-06
Iter: 927 loss: 1.36514939e-06
Iter: 928 loss: 1.3473234e-06
Iter: 929 loss: 1.34604613e-06
Iter: 930 loss: 1.34601532e-06
Iter: 931 loss: 1.34499658e-06
Iter: 932 loss: 1.34335562e-06
Iter: 933 loss: 1.34879838e-06
Iter: 934 loss: 1.34282413e-06
Iter: 935 loss: 1.34123707e-06
Iter: 936 loss: 1.34731306e-06
Iter: 937 loss: 1.34087213e-06
Iter: 938 loss: 1.33895446e-06
Iter: 939 loss: 1.34497895e-06
Iter: 940 loss: 1.33831304e-06
Iter: 941 loss: 1.33717117e-06
Iter: 942 loss: 1.33586684e-06
Iter: 943 loss: 1.33565163e-06
Iter: 944 loss: 1.33382753e-06
Iter: 945 loss: 1.34771267e-06
Iter: 946 loss: 1.33366939e-06
Iter: 947 loss: 1.33252991e-06
Iter: 948 loss: 1.3501076e-06
Iter: 949 loss: 1.33251115e-06
Iter: 950 loss: 1.33146966e-06
Iter: 951 loss: 1.33139372e-06
Iter: 952 loss: 1.33056938e-06
Iter: 953 loss: 1.32937294e-06
Iter: 954 loss: 1.33419087e-06
Iter: 955 loss: 1.32903324e-06
Iter: 956 loss: 1.32768696e-06
Iter: 957 loss: 1.32687956e-06
Iter: 958 loss: 1.32635932e-06
Iter: 959 loss: 1.32464265e-06
Iter: 960 loss: 1.33087781e-06
Iter: 961 loss: 1.32428829e-06
Iter: 962 loss: 1.32305763e-06
Iter: 963 loss: 1.33886329e-06
Iter: 964 loss: 1.3229876e-06
Iter: 965 loss: 1.32193486e-06
Iter: 966 loss: 1.32161676e-06
Iter: 967 loss: 1.32092055e-06
Iter: 968 loss: 1.31933325e-06
Iter: 969 loss: 1.32252273e-06
Iter: 970 loss: 1.3186733e-06
Iter: 971 loss: 1.31696765e-06
Iter: 972 loss: 1.32435423e-06
Iter: 973 loss: 1.31665684e-06
Iter: 974 loss: 1.31533e-06
Iter: 975 loss: 1.316012e-06
Iter: 976 loss: 1.31453385e-06
Iter: 977 loss: 1.31287368e-06
Iter: 978 loss: 1.31726449e-06
Iter: 979 loss: 1.31229672e-06
Iter: 980 loss: 1.31081106e-06
Iter: 981 loss: 1.31479487e-06
Iter: 982 loss: 1.3103197e-06
Iter: 983 loss: 1.30906869e-06
Iter: 984 loss: 1.32623e-06
Iter: 985 loss: 1.309053e-06
Iter: 986 loss: 1.3077979e-06
Iter: 987 loss: 1.30865681e-06
Iter: 988 loss: 1.30701915e-06
Iter: 989 loss: 1.30586022e-06
Iter: 990 loss: 1.3094741e-06
Iter: 991 loss: 1.30549279e-06
Iter: 992 loss: 1.30425178e-06
Iter: 993 loss: 1.3052163e-06
Iter: 994 loss: 1.30350588e-06
Iter: 995 loss: 1.30188812e-06
Iter: 996 loss: 1.30688591e-06
Iter: 997 loss: 1.30147816e-06
Iter: 998 loss: 1.30018248e-06
Iter: 999 loss: 1.30673061e-06
Iter: 1000 loss: 1.29993259e-06
Iter: 1001 loss: 1.29881255e-06
Iter: 1002 loss: 1.29804266e-06
Iter: 1003 loss: 1.29759655e-06
Iter: 1004 loss: 1.29590956e-06
Iter: 1005 loss: 1.29900786e-06
Iter: 1006 loss: 1.29523187e-06
Iter: 1007 loss: 1.29387843e-06
Iter: 1008 loss: 1.29385637e-06
Iter: 1009 loss: 1.29278533e-06
Iter: 1010 loss: 1.29268869e-06
Iter: 1011 loss: 1.29191233e-06
Iter: 1012 loss: 1.29064574e-06
Iter: 1013 loss: 1.29940088e-06
Iter: 1014 loss: 1.29050181e-06
Iter: 1015 loss: 1.28940837e-06
Iter: 1016 loss: 1.28860029e-06
Iter: 1017 loss: 1.28821102e-06
Iter: 1018 loss: 1.28650095e-06
Iter: 1019 loss: 1.28943793e-06
Iter: 1020 loss: 1.28561373e-06
Iter: 1021 loss: 1.28441991e-06
Iter: 1022 loss: 1.28441184e-06
Iter: 1023 loss: 1.28330055e-06
Iter: 1024 loss: 1.28756596e-06
Iter: 1025 loss: 1.2830692e-06
Iter: 1026 loss: 1.28207319e-06
Iter: 1027 loss: 1.2813482e-06
Iter: 1028 loss: 1.28103102e-06
Iter: 1029 loss: 1.27976318e-06
Iter: 1030 loss: 1.28202441e-06
Iter: 1031 loss: 1.27909857e-06
Iter: 1032 loss: 1.27757232e-06
Iter: 1033 loss: 1.28973579e-06
Iter: 1034 loss: 1.27740316e-06
Iter: 1035 loss: 1.27630767e-06
Iter: 1036 loss: 1.2770081e-06
Iter: 1037 loss: 1.27558428e-06
Iter: 1038 loss: 1.2742687e-06
Iter: 1039 loss: 1.28140277e-06
Iter: 1040 loss: 1.27410249e-06
Iter: 1041 loss: 1.27277872e-06
Iter: 1042 loss: 1.27476369e-06
Iter: 1043 loss: 1.27210546e-06
Iter: 1044 loss: 1.27074122e-06
Iter: 1045 loss: 1.2716639e-06
Iter: 1046 loss: 1.26990108e-06
Iter: 1047 loss: 1.26876421e-06
Iter: 1048 loss: 1.27867338e-06
Iter: 1049 loss: 1.26865746e-06
Iter: 1050 loss: 1.2674825e-06
Iter: 1051 loss: 1.27011083e-06
Iter: 1052 loss: 1.26708107e-06
Iter: 1053 loss: 1.26594614e-06
Iter: 1054 loss: 1.26872658e-06
Iter: 1055 loss: 1.2655737e-06
Iter: 1056 loss: 1.26434259e-06
Iter: 1057 loss: 1.26701036e-06
Iter: 1058 loss: 1.26386692e-06
Iter: 1059 loss: 1.26272573e-06
Iter: 1060 loss: 1.26254099e-06
Iter: 1061 loss: 1.26176474e-06
Iter: 1062 loss: 1.26112445e-06
Iter: 1063 loss: 1.26093528e-06
Iter: 1064 loss: 1.26019e-06
Iter: 1065 loss: 1.25936481e-06
Iter: 1066 loss: 1.25925726e-06
Iter: 1067 loss: 1.2579344e-06
Iter: 1068 loss: 1.25787551e-06
Iter: 1069 loss: 1.2568845e-06
Iter: 1070 loss: 1.2554118e-06
Iter: 1071 loss: 1.26224018e-06
Iter: 1072 loss: 1.25508654e-06
Iter: 1073 loss: 1.25387396e-06
Iter: 1074 loss: 1.26385817e-06
Iter: 1075 loss: 1.25376823e-06
Iter: 1076 loss: 1.2526383e-06
Iter: 1077 loss: 1.25223596e-06
Iter: 1078 loss: 1.25163524e-06
Iter: 1079 loss: 1.25012491e-06
Iter: 1080 loss: 1.25436316e-06
Iter: 1081 loss: 1.24949793e-06
Iter: 1082 loss: 1.24823703e-06
Iter: 1083 loss: 1.25897691e-06
Iter: 1084 loss: 1.24812323e-06
Iter: 1085 loss: 1.24714461e-06
Iter: 1086 loss: 1.25144322e-06
Iter: 1087 loss: 1.24691974e-06
Iter: 1088 loss: 1.24579879e-06
Iter: 1089 loss: 1.24534154e-06
Iter: 1090 loss: 1.24480766e-06
Iter: 1091 loss: 1.24358576e-06
Iter: 1092 loss: 1.25726979e-06
Iter: 1093 loss: 1.24357985e-06
Iter: 1094 loss: 1.24282269e-06
Iter: 1095 loss: 1.24253233e-06
Iter: 1096 loss: 1.24208714e-06
Iter: 1097 loss: 1.24086034e-06
Iter: 1098 loss: 1.25094675e-06
Iter: 1099 loss: 1.240801e-06
Iter: 1100 loss: 1.23970119e-06
Iter: 1101 loss: 1.24048927e-06
Iter: 1102 loss: 1.23912662e-06
Iter: 1103 loss: 1.23813629e-06
Iter: 1104 loss: 1.24852261e-06
Iter: 1105 loss: 1.23814675e-06
Iter: 1106 loss: 1.23741461e-06
Iter: 1107 loss: 1.23634663e-06
Iter: 1108 loss: 1.23632185e-06
Iter: 1109 loss: 1.23503696e-06
Iter: 1110 loss: 1.2386281e-06
Iter: 1111 loss: 1.23462587e-06
Iter: 1112 loss: 1.23336736e-06
Iter: 1113 loss: 1.23240693e-06
Iter: 1114 loss: 1.2319972e-06
Iter: 1115 loss: 1.23010216e-06
Iter: 1116 loss: 1.23982181e-06
Iter: 1117 loss: 1.22982874e-06
Iter: 1118 loss: 1.22872757e-06
Iter: 1119 loss: 1.2287212e-06
Iter: 1120 loss: 1.22774384e-06
Iter: 1121 loss: 1.22876725e-06
Iter: 1122 loss: 1.22720462e-06
Iter: 1123 loss: 1.22606389e-06
Iter: 1124 loss: 1.22817357e-06
Iter: 1125 loss: 1.22545816e-06
Iter: 1126 loss: 1.22440179e-06
Iter: 1127 loss: 1.23058089e-06
Iter: 1128 loss: 1.22425445e-06
Iter: 1129 loss: 1.22332744e-06
Iter: 1130 loss: 1.22387974e-06
Iter: 1131 loss: 1.22278948e-06
Iter: 1132 loss: 1.22173981e-06
Iter: 1133 loss: 1.22974575e-06
Iter: 1134 loss: 1.22163624e-06
Iter: 1135 loss: 1.22065774e-06
Iter: 1136 loss: 1.22207666e-06
Iter: 1137 loss: 1.22017263e-06
Iter: 1138 loss: 1.21920516e-06
Iter: 1139 loss: 1.22315157e-06
Iter: 1140 loss: 1.218958e-06
Iter: 1141 loss: 1.21796461e-06
Iter: 1142 loss: 1.21987659e-06
Iter: 1143 loss: 1.21770756e-06
Iter: 1144 loss: 1.21683934e-06
Iter: 1145 loss: 1.21764594e-06
Iter: 1146 loss: 1.21636685e-06
Iter: 1147 loss: 1.2152143e-06
Iter: 1148 loss: 1.21810251e-06
Iter: 1149 loss: 1.21476273e-06
Iter: 1150 loss: 1.21376797e-06
Iter: 1151 loss: 1.21420953e-06
Iter: 1152 loss: 1.21298626e-06
Iter: 1153 loss: 1.21156791e-06
Iter: 1154 loss: 1.21359403e-06
Iter: 1155 loss: 1.21084554e-06
Iter: 1156 loss: 1.20940945e-06
Iter: 1157 loss: 1.21586527e-06
Iter: 1158 loss: 1.20909567e-06
Iter: 1159 loss: 1.20782943e-06
Iter: 1160 loss: 1.21272569e-06
Iter: 1161 loss: 1.20755203e-06
Iter: 1162 loss: 1.20659934e-06
Iter: 1163 loss: 1.22201516e-06
Iter: 1164 loss: 1.2065974e-06
Iter: 1165 loss: 1.20591e-06
Iter: 1166 loss: 1.20453376e-06
Iter: 1167 loss: 1.22824576e-06
Iter: 1168 loss: 1.20452478e-06
Iter: 1169 loss: 1.20340837e-06
Iter: 1170 loss: 1.20339701e-06
Iter: 1171 loss: 1.20253048e-06
Iter: 1172 loss: 1.20598634e-06
Iter: 1173 loss: 1.20233267e-06
Iter: 1174 loss: 1.20158347e-06
Iter: 1175 loss: 1.20173854e-06
Iter: 1176 loss: 1.2010014e-06
Iter: 1177 loss: 1.19998117e-06
Iter: 1178 loss: 1.20499658e-06
Iter: 1179 loss: 1.19976107e-06
Iter: 1180 loss: 1.19892752e-06
Iter: 1181 loss: 1.19873789e-06
Iter: 1182 loss: 1.19825722e-06
Iter: 1183 loss: 1.19711012e-06
Iter: 1184 loss: 1.20382788e-06
Iter: 1185 loss: 1.19699757e-06
Iter: 1186 loss: 1.1960102e-06
Iter: 1187 loss: 1.19538436e-06
Iter: 1188 loss: 1.1950408e-06
Iter: 1189 loss: 1.19374431e-06
Iter: 1190 loss: 1.19898368e-06
Iter: 1191 loss: 1.19342792e-06
Iter: 1192 loss: 1.19216725e-06
Iter: 1193 loss: 1.19661399e-06
Iter: 1194 loss: 1.19186711e-06
Iter: 1195 loss: 1.19068454e-06
Iter: 1196 loss: 1.19746653e-06
Iter: 1197 loss: 1.19051765e-06
Iter: 1198 loss: 1.1895886e-06
Iter: 1199 loss: 1.18957655e-06
Iter: 1200 loss: 1.18876665e-06
Iter: 1201 loss: 1.1876e-06
Iter: 1202 loss: 1.19381582e-06
Iter: 1203 loss: 1.18741559e-06
Iter: 1204 loss: 1.18664707e-06
Iter: 1205 loss: 1.19651565e-06
Iter: 1206 loss: 1.18663399e-06
Iter: 1207 loss: 1.18594244e-06
Iter: 1208 loss: 1.18512548e-06
Iter: 1209 loss: 1.18507751e-06
Iter: 1210 loss: 1.1842634e-06
Iter: 1211 loss: 1.18427886e-06
Iter: 1212 loss: 1.18358878e-06
Iter: 1213 loss: 1.18280332e-06
Iter: 1214 loss: 1.18269918e-06
Iter: 1215 loss: 1.18164235e-06
Iter: 1216 loss: 1.18469052e-06
Iter: 1217 loss: 1.18138121e-06
Iter: 1218 loss: 1.18051037e-06
Iter: 1219 loss: 1.18896378e-06
Iter: 1220 loss: 1.18049013e-06
Iter: 1221 loss: 1.17974218e-06
Iter: 1222 loss: 1.17878335e-06
Iter: 1223 loss: 1.17870877e-06
Iter: 1224 loss: 1.17755405e-06
Iter: 1225 loss: 1.18146897e-06
Iter: 1226 loss: 1.17726256e-06
Iter: 1227 loss: 1.17619857e-06
Iter: 1228 loss: 1.18297874e-06
Iter: 1229 loss: 1.17608067e-06
Iter: 1230 loss: 1.17511877e-06
Iter: 1231 loss: 1.17482705e-06
Iter: 1232 loss: 1.17433706e-06
Iter: 1233 loss: 1.17311583e-06
Iter: 1234 loss: 1.17439959e-06
Iter: 1235 loss: 1.17243394e-06
Iter: 1236 loss: 1.17129662e-06
Iter: 1237 loss: 1.18814046e-06
Iter: 1238 loss: 1.171343e-06
Iter: 1239 loss: 1.17040599e-06
Iter: 1240 loss: 1.17250534e-06
Iter: 1241 loss: 1.17008119e-06
Iter: 1242 loss: 1.16916613e-06
Iter: 1243 loss: 1.17133095e-06
Iter: 1244 loss: 1.16885383e-06
Iter: 1245 loss: 1.16779324e-06
Iter: 1246 loss: 1.17531351e-06
Iter: 1247 loss: 1.16773981e-06
Iter: 1248 loss: 1.16705542e-06
Iter: 1249 loss: 1.16723686e-06
Iter: 1250 loss: 1.16655269e-06
Iter: 1251 loss: 1.1657977e-06
Iter: 1252 loss: 1.17116417e-06
Iter: 1253 loss: 1.16573187e-06
Iter: 1254 loss: 1.16501963e-06
Iter: 1255 loss: 1.16405965e-06
Iter: 1256 loss: 1.16404271e-06
Iter: 1257 loss: 1.16287129e-06
Iter: 1258 loss: 1.16728665e-06
Iter: 1259 loss: 1.16261049e-06
Iter: 1260 loss: 1.16182377e-06
Iter: 1261 loss: 1.1692199e-06
Iter: 1262 loss: 1.16174692e-06
Iter: 1263 loss: 1.16094395e-06
Iter: 1264 loss: 1.16137244e-06
Iter: 1265 loss: 1.16033857e-06
Iter: 1266 loss: 1.15940418e-06
Iter: 1267 loss: 1.16006447e-06
Iter: 1268 loss: 1.15876981e-06
Iter: 1269 loss: 1.157611e-06
Iter: 1270 loss: 1.15967748e-06
Iter: 1271 loss: 1.15706098e-06
Iter: 1272 loss: 1.15595219e-06
Iter: 1273 loss: 1.16890578e-06
Iter: 1274 loss: 1.15594526e-06
Iter: 1275 loss: 1.15520879e-06
Iter: 1276 loss: 1.15468515e-06
Iter: 1277 loss: 1.15439809e-06
Iter: 1278 loss: 1.15323121e-06
Iter: 1279 loss: 1.15769762e-06
Iter: 1280 loss: 1.15301737e-06
Iter: 1281 loss: 1.1521463e-06
Iter: 1282 loss: 1.15213766e-06
Iter: 1283 loss: 1.15151204e-06
Iter: 1284 loss: 1.1509253e-06
Iter: 1285 loss: 1.15080229e-06
Iter: 1286 loss: 1.15006776e-06
Iter: 1287 loss: 1.15648913e-06
Iter: 1288 loss: 1.15004707e-06
Iter: 1289 loss: 1.14930822e-06
Iter: 1290 loss: 1.14889463e-06
Iter: 1291 loss: 1.14860825e-06
Iter: 1292 loss: 1.14762634e-06
Iter: 1293 loss: 1.15054831e-06
Iter: 1294 loss: 1.14735883e-06
Iter: 1295 loss: 1.14629279e-06
Iter: 1296 loss: 1.15105718e-06
Iter: 1297 loss: 1.14604086e-06
Iter: 1298 loss: 1.1452579e-06
Iter: 1299 loss: 1.14580462e-06
Iter: 1300 loss: 1.14474892e-06
Iter: 1301 loss: 1.14376633e-06
Iter: 1302 loss: 1.15014211e-06
Iter: 1303 loss: 1.1436664e-06
Iter: 1304 loss: 1.14276486e-06
Iter: 1305 loss: 1.14443446e-06
Iter: 1306 loss: 1.14235684e-06
Iter: 1307 loss: 1.14161855e-06
Iter: 1308 loss: 1.14152181e-06
Iter: 1309 loss: 1.14105444e-06
Iter: 1310 loss: 1.13985539e-06
Iter: 1311 loss: 1.14243221e-06
Iter: 1312 loss: 1.13934971e-06
Iter: 1313 loss: 1.13831732e-06
Iter: 1314 loss: 1.14450427e-06
Iter: 1315 loss: 1.13819021e-06
Iter: 1316 loss: 1.13717397e-06
Iter: 1317 loss: 1.1439663e-06
Iter: 1318 loss: 1.13714054e-06
Iter: 1319 loss: 1.13638771e-06
Iter: 1320 loss: 1.13949989e-06
Iter: 1321 loss: 1.13626845e-06
Iter: 1322 loss: 1.13550209e-06
Iter: 1323 loss: 1.13503165e-06
Iter: 1324 loss: 1.13475289e-06
Iter: 1325 loss: 1.1337994e-06
Iter: 1326 loss: 1.13674719e-06
Iter: 1327 loss: 1.13357282e-06
Iter: 1328 loss: 1.13260194e-06
Iter: 1329 loss: 1.13851752e-06
Iter: 1330 loss: 1.13248984e-06
Iter: 1331 loss: 1.13168721e-06
Iter: 1332 loss: 1.13180204e-06
Iter: 1333 loss: 1.13105557e-06
Iter: 1334 loss: 1.13020269e-06
Iter: 1335 loss: 1.13048441e-06
Iter: 1336 loss: 1.12960379e-06
Iter: 1337 loss: 1.12869452e-06
Iter: 1338 loss: 1.12868315e-06
Iter: 1339 loss: 1.12801808e-06
Iter: 1340 loss: 1.12765338e-06
Iter: 1341 loss: 1.12743123e-06
Iter: 1342 loss: 1.12652845e-06
Iter: 1343 loss: 1.12733505e-06
Iter: 1344 loss: 1.12605596e-06
Iter: 1345 loss: 1.12496491e-06
Iter: 1346 loss: 1.13324563e-06
Iter: 1347 loss: 1.12490375e-06
Iter: 1348 loss: 1.12405689e-06
Iter: 1349 loss: 1.12425505e-06
Iter: 1350 loss: 1.12346561e-06
Iter: 1351 loss: 1.12246357e-06
Iter: 1352 loss: 1.12702321e-06
Iter: 1353 loss: 1.12230759e-06
Iter: 1354 loss: 1.12167049e-06
Iter: 1355 loss: 1.12168118e-06
Iter: 1356 loss: 1.12115765e-06
Iter: 1357 loss: 1.12038083e-06
Iter: 1358 loss: 1.12031034e-06
Iter: 1359 loss: 1.11935867e-06
Iter: 1360 loss: 1.12058763e-06
Iter: 1361 loss: 1.11891268e-06
Iter: 1362 loss: 1.11782e-06
Iter: 1363 loss: 1.12812438e-06
Iter: 1364 loss: 1.11777183e-06
Iter: 1365 loss: 1.11705299e-06
Iter: 1366 loss: 1.11790553e-06
Iter: 1367 loss: 1.11667941e-06
Iter: 1368 loss: 1.11565919e-06
Iter: 1369 loss: 1.11720772e-06
Iter: 1370 loss: 1.11519978e-06
Iter: 1371 loss: 1.11425732e-06
Iter: 1372 loss: 1.11718145e-06
Iter: 1373 loss: 1.11397333e-06
Iter: 1374 loss: 1.11314978e-06
Iter: 1375 loss: 1.11357031e-06
Iter: 1376 loss: 1.11261784e-06
Iter: 1377 loss: 1.11160898e-06
Iter: 1378 loss: 1.12544967e-06
Iter: 1379 loss: 1.11162444e-06
Iter: 1380 loss: 1.11103168e-06
Iter: 1381 loss: 1.11041504e-06
Iter: 1382 loss: 1.11027691e-06
Iter: 1383 loss: 1.10925055e-06
Iter: 1384 loss: 1.10929909e-06
Iter: 1385 loss: 1.10844633e-06
Iter: 1386 loss: 1.10727069e-06
Iter: 1387 loss: 1.11729332e-06
Iter: 1388 loss: 1.10717622e-06
Iter: 1389 loss: 1.10640462e-06
Iter: 1390 loss: 1.10640372e-06
Iter: 1391 loss: 1.10588417e-06
Iter: 1392 loss: 1.10503663e-06
Iter: 1393 loss: 1.10506016e-06
Iter: 1394 loss: 1.10413202e-06
Iter: 1395 loss: 1.10607914e-06
Iter: 1396 loss: 1.10370274e-06
Iter: 1397 loss: 1.10283213e-06
Iter: 1398 loss: 1.11358645e-06
Iter: 1399 loss: 1.10281815e-06
Iter: 1400 loss: 1.10225767e-06
Iter: 1401 loss: 1.10235271e-06
Iter: 1402 loss: 1.10183475e-06
Iter: 1403 loss: 1.10104372e-06
Iter: 1404 loss: 1.10524456e-06
Iter: 1405 loss: 1.1009065e-06
Iter: 1406 loss: 1.10021472e-06
Iter: 1407 loss: 1.09977088e-06
Iter: 1408 loss: 1.09948394e-06
Iter: 1409 loss: 1.09849179e-06
Iter: 1410 loss: 1.10373162e-06
Iter: 1411 loss: 1.09833468e-06
Iter: 1412 loss: 1.09744235e-06
Iter: 1413 loss: 1.10108647e-06
Iter: 1414 loss: 1.09725158e-06
Iter: 1415 loss: 1.09650114e-06
Iter: 1416 loss: 1.09818313e-06
Iter: 1417 loss: 1.09619316e-06
Iter: 1418 loss: 1.0953936e-06
Iter: 1419 loss: 1.09894859e-06
Iter: 1420 loss: 1.09524831e-06
Iter: 1421 loss: 1.09445944e-06
Iter: 1422 loss: 1.09500547e-06
Iter: 1423 loss: 1.09394568e-06
Iter: 1424 loss: 1.09312396e-06
Iter: 1425 loss: 1.09429186e-06
Iter: 1426 loss: 1.09271195e-06
Iter: 1427 loss: 1.09212181e-06
Iter: 1428 loss: 1.0920794e-06
Iter: 1429 loss: 1.09162829e-06
Iter: 1430 loss: 1.09064717e-06
Iter: 1431 loss: 1.10332758e-06
Iter: 1432 loss: 1.09059738e-06
Iter: 1433 loss: 1.08932761e-06
Iter: 1434 loss: 1.09313828e-06
Iter: 1435 loss: 1.08901293e-06
Iter: 1436 loss: 1.08822223e-06
Iter: 1437 loss: 1.09342022e-06
Iter: 1438 loss: 1.0881605e-06
Iter: 1439 loss: 1.08721633e-06
Iter: 1440 loss: 1.08998677e-06
Iter: 1441 loss: 1.08697463e-06
Iter: 1442 loss: 1.08619804e-06
Iter: 1443 loss: 1.0858862e-06
Iter: 1444 loss: 1.08549443e-06
Iter: 1445 loss: 1.08453901e-06
Iter: 1446 loss: 1.08732104e-06
Iter: 1447 loss: 1.08429242e-06
Iter: 1448 loss: 1.08332677e-06
Iter: 1449 loss: 1.09149414e-06
Iter: 1450 loss: 1.08322809e-06
Iter: 1451 loss: 1.08246809e-06
Iter: 1452 loss: 1.08269353e-06
Iter: 1453 loss: 1.08188135e-06
Iter: 1454 loss: 1.0809722e-06
Iter: 1455 loss: 1.08821234e-06
Iter: 1456 loss: 1.08087431e-06
Iter: 1457 loss: 1.0802263e-06
Iter: 1458 loss: 1.08061317e-06
Iter: 1459 loss: 1.07983692e-06
Iter: 1460 loss: 1.07901133e-06
Iter: 1461 loss: 1.08170104e-06
Iter: 1462 loss: 1.07880305e-06
Iter: 1463 loss: 1.07807091e-06
Iter: 1464 loss: 1.08459926e-06
Iter: 1465 loss: 1.07801395e-06
Iter: 1466 loss: 1.07753817e-06
Iter: 1467 loss: 1.07740823e-06
Iter: 1468 loss: 1.07702397e-06
Iter: 1469 loss: 1.07628489e-06
Iter: 1470 loss: 1.0782818e-06
Iter: 1471 loss: 1.07606297e-06
Iter: 1472 loss: 1.07525045e-06
Iter: 1473 loss: 1.07483197e-06
Iter: 1474 loss: 1.07448022e-06
Iter: 1475 loss: 1.07331061e-06
Iter: 1476 loss: 1.07929532e-06
Iter: 1477 loss: 1.07309438e-06
Iter: 1478 loss: 1.07231358e-06
Iter: 1479 loss: 1.08234519e-06
Iter: 1480 loss: 1.07230824e-06
Iter: 1481 loss: 1.07156029e-06
Iter: 1482 loss: 1.07113135e-06
Iter: 1483 loss: 1.07084929e-06
Iter: 1484 loss: 1.07001654e-06
Iter: 1485 loss: 1.07086737e-06
Iter: 1486 loss: 1.06949426e-06
Iter: 1487 loss: 1.06853e-06
Iter: 1488 loss: 1.07321466e-06
Iter: 1489 loss: 1.06837774e-06
Iter: 1490 loss: 1.06772779e-06
Iter: 1491 loss: 1.07621054e-06
Iter: 1492 loss: 1.06775224e-06
Iter: 1493 loss: 1.06711468e-06
Iter: 1494 loss: 1.06646939e-06
Iter: 1495 loss: 1.06637344e-06
Iter: 1496 loss: 1.06545235e-06
Iter: 1497 loss: 1.06898653e-06
Iter: 1498 loss: 1.06519565e-06
Iter: 1499 loss: 1.06459106e-06
Iter: 1500 loss: 1.06458242e-06
Iter: 1501 loss: 1.06412631e-06
Iter: 1502 loss: 1.06382447e-06
Iter: 1503 loss: 1.06367156e-06
Iter: 1504 loss: 1.06292873e-06
Iter: 1505 loss: 1.06380912e-06
Iter: 1506 loss: 1.06254265e-06
Iter: 1507 loss: 1.06164862e-06
Iter: 1508 loss: 1.0635323e-06
Iter: 1509 loss: 1.06126731e-06
Iter: 1510 loss: 1.06038533e-06
Iter: 1511 loss: 1.06070866e-06
Iter: 1512 loss: 1.05980109e-06
Iter: 1513 loss: 1.05932281e-06
Iter: 1514 loss: 1.05919526e-06
Iter: 1515 loss: 1.05880417e-06
Iter: 1516 loss: 1.05790673e-06
Iter: 1517 loss: 1.07658821e-06
Iter: 1518 loss: 1.05786694e-06
Iter: 1519 loss: 1.05695563e-06
Iter: 1520 loss: 1.06253924e-06
Iter: 1521 loss: 1.05680465e-06
Iter: 1522 loss: 1.05607751e-06
Iter: 1523 loss: 1.0586e-06
Iter: 1524 loss: 1.05587912e-06
Iter: 1525 loss: 1.05504182e-06
Iter: 1526 loss: 1.05644244e-06
Iter: 1527 loss: 1.05466427e-06
Iter: 1528 loss: 1.05380855e-06
Iter: 1529 loss: 1.05522849e-06
Iter: 1530 loss: 1.05344179e-06
Iter: 1531 loss: 1.05266565e-06
Iter: 1532 loss: 1.06166453e-06
Iter: 1533 loss: 1.05266099e-06
Iter: 1534 loss: 1.05201195e-06
Iter: 1535 loss: 1.05220101e-06
Iter: 1536 loss: 1.05160404e-06
Iter: 1537 loss: 1.05094114e-06
Iter: 1538 loss: 1.05839058e-06
Iter: 1539 loss: 1.05093909e-06
Iter: 1540 loss: 1.05042182e-06
Iter: 1541 loss: 1.05008451e-06
Iter: 1542 loss: 1.04992068e-06
Iter: 1543 loss: 1.04922879e-06
Iter: 1544 loss: 1.04968444e-06
Iter: 1545 loss: 1.04882952e-06
Iter: 1546 loss: 1.04795208e-06
Iter: 1547 loss: 1.0519077e-06
Iter: 1548 loss: 1.04781452e-06
Iter: 1549 loss: 1.04694027e-06
Iter: 1550 loss: 1.04963215e-06
Iter: 1551 loss: 1.04672188e-06
Iter: 1552 loss: 1.04601475e-06
Iter: 1553 loss: 1.04591993e-06
Iter: 1554 loss: 1.04540368e-06
Iter: 1555 loss: 1.04456706e-06
Iter: 1556 loss: 1.05211871e-06
Iter: 1557 loss: 1.04454057e-06
Iter: 1558 loss: 1.04365176e-06
Iter: 1559 loss: 1.04541482e-06
Iter: 1560 loss: 1.04321225e-06
Iter: 1561 loss: 1.04259482e-06
Iter: 1562 loss: 1.04327205e-06
Iter: 1563 loss: 1.04225637e-06
Iter: 1564 loss: 1.04150638e-06
Iter: 1565 loss: 1.0451904e-06
Iter: 1566 loss: 1.04133755e-06
Iter: 1567 loss: 1.04065725e-06
Iter: 1568 loss: 1.04254309e-06
Iter: 1569 loss: 1.04043079e-06
Iter: 1570 loss: 1.03986088e-06
Iter: 1571 loss: 1.04215974e-06
Iter: 1572 loss: 1.03977413e-06
Iter: 1573 loss: 1.03909065e-06
Iter: 1574 loss: 1.0414393e-06
Iter: 1575 loss: 1.03899561e-06
Iter: 1576 loss: 1.03839943e-06
Iter: 1577 loss: 1.03797652e-06
Iter: 1578 loss: 1.0377878e-06
Iter: 1579 loss: 1.03703496e-06
Iter: 1580 loss: 1.03816365e-06
Iter: 1581 loss: 1.03665957e-06
Iter: 1582 loss: 1.0358101e-06
Iter: 1583 loss: 1.04596711e-06
Iter: 1584 loss: 1.03582443e-06
Iter: 1585 loss: 1.0352594e-06
Iter: 1586 loss: 1.03516072e-06
Iter: 1587 loss: 1.03482466e-06
Iter: 1588 loss: 1.03401067e-06
Iter: 1589 loss: 1.03620391e-06
Iter: 1590 loss: 1.03374555e-06
Iter: 1591 loss: 1.03296793e-06
Iter: 1592 loss: 1.03537582e-06
Iter: 1593 loss: 1.03279444e-06
Iter: 1594 loss: 1.03203672e-06
Iter: 1595 loss: 1.03213483e-06
Iter: 1596 loss: 1.03158095e-06
Iter: 1597 loss: 1.03069613e-06
Iter: 1598 loss: 1.03398133e-06
Iter: 1599 loss: 1.03052434e-06
Iter: 1600 loss: 1.02962031e-06
Iter: 1601 loss: 1.03656953e-06
Iter: 1602 loss: 1.02952754e-06
Iter: 1603 loss: 1.02898844e-06
Iter: 1604 loss: 1.02909917e-06
Iter: 1605 loss: 1.02858951e-06
Iter: 1606 loss: 1.02788977e-06
Iter: 1607 loss: 1.0312807e-06
Iter: 1608 loss: 1.02772e-06
Iter: 1609 loss: 1.02703859e-06
Iter: 1610 loss: 1.02737818e-06
Iter: 1611 loss: 1.02667104e-06
Iter: 1612 loss: 1.02599415e-06
Iter: 1613 loss: 1.02883655e-06
Iter: 1614 loss: 1.02577383e-06
Iter: 1615 loss: 1.02510751e-06
Iter: 1616 loss: 1.03079276e-06
Iter: 1617 loss: 1.02512809e-06
Iter: 1618 loss: 1.02454578e-06
Iter: 1619 loss: 1.0239678e-06
Iter: 1620 loss: 1.023913e-06
Iter: 1621 loss: 1.02312504e-06
Iter: 1622 loss: 1.02565355e-06
Iter: 1623 loss: 1.02291847e-06
Iter: 1624 loss: 1.02220429e-06
Iter: 1625 loss: 1.02708816e-06
Iter: 1626 loss: 1.02209242e-06
Iter: 1627 loss: 1.02149193e-06
Iter: 1628 loss: 1.02168383e-06
Iter: 1629 loss: 1.02104877e-06
Iter: 1630 loss: 1.02031186e-06
Iter: 1631 loss: 1.02403499e-06
Iter: 1632 loss: 1.02024364e-06
Iter: 1633 loss: 1.01956948e-06
Iter: 1634 loss: 1.01965668e-06
Iter: 1635 loss: 1.01906301e-06
Iter: 1636 loss: 1.01821593e-06
Iter: 1637 loss: 1.02028378e-06
Iter: 1638 loss: 1.01785588e-06
Iter: 1639 loss: 1.01710043e-06
Iter: 1640 loss: 1.02040735e-06
Iter: 1641 loss: 1.01695377e-06
Iter: 1642 loss: 1.01627245e-06
Iter: 1643 loss: 1.02328352e-06
Iter: 1644 loss: 1.0162679e-06
Iter: 1645 loss: 1.0157629e-06
Iter: 1646 loss: 1.01544049e-06
Iter: 1647 loss: 1.01530554e-06
Iter: 1648 loss: 1.01452838e-06
Iter: 1649 loss: 1.01922546e-06
Iter: 1650 loss: 1.01446869e-06
Iter: 1651 loss: 1.01378623e-06
Iter: 1652 loss: 1.01431579e-06
Iter: 1653 loss: 1.01342096e-06
Iter: 1654 loss: 1.01267574e-06
Iter: 1655 loss: 1.0133549e-06
Iter: 1656 loss: 1.01226442e-06
Iter: 1657 loss: 1.01180478e-06
Iter: 1658 loss: 1.01175726e-06
Iter: 1659 loss: 1.01137607e-06
Iter: 1660 loss: 1.01078058e-06
Iter: 1661 loss: 1.01075989e-06
Iter: 1662 loss: 1.01009448e-06
Iter: 1663 loss: 1.01323894e-06
Iter: 1664 loss: 1.00998318e-06
Iter: 1665 loss: 1.00930561e-06
Iter: 1666 loss: 1.01164278e-06
Iter: 1667 loss: 1.00916452e-06
Iter: 1668 loss: 1.00854504e-06
Iter: 1669 loss: 1.00886791e-06
Iter: 1670 loss: 1.00814191e-06
Iter: 1671 loss: 1.00751288e-06
Iter: 1672 loss: 1.01099488e-06
Iter: 1673 loss: 1.00733359e-06
Iter: 1674 loss: 1.00670832e-06
Iter: 1675 loss: 1.00608656e-06
Iter: 1676 loss: 1.00596117e-06
Iter: 1677 loss: 1.00512079e-06
Iter: 1678 loss: 1.01019077e-06
Iter: 1679 loss: 1.00499597e-06
Iter: 1680 loss: 1.00417014e-06
Iter: 1681 loss: 1.00706711e-06
Iter: 1682 loss: 1.00396187e-06
Iter: 1683 loss: 1.00328975e-06
Iter: 1684 loss: 1.00981515e-06
Iter: 1685 loss: 1.00331374e-06
Iter: 1686 loss: 1.00287104e-06
Iter: 1687 loss: 1.00238e-06
Iter: 1688 loss: 1.00232637e-06
Iter: 1689 loss: 1.00154432e-06
Iter: 1690 loss: 1.00726e-06
Iter: 1691 loss: 1.00144052e-06
Iter: 1692 loss: 1.00091847e-06
Iter: 1693 loss: 1.0010441e-06
Iter: 1694 loss: 1.00048123e-06
Iter: 1695 loss: 1.00000807e-06
Iter: 1696 loss: 1.00696604e-06
Iter: 1697 loss: 9.99947929e-07
Iter: 1698 loss: 9.99407121e-07
Iter: 1699 loss: 9.99235226e-07
Iter: 1700 loss: 9.98897235e-07
Iter: 1701 loss: 9.9828776e-07
Iter: 1702 loss: 9.98793439e-07
Iter: 1703 loss: 9.9797353e-07
Iter: 1704 loss: 9.97246843e-07
Iter: 1705 loss: 9.98987844e-07
Iter: 1706 loss: 9.96983886e-07
Iter: 1707 loss: 9.9631427e-07
Iter: 1708 loss: 1.00245802e-06
Iter: 1709 loss: 9.96258109e-07
Iter: 1710 loss: 9.95719347e-07
Iter: 1711 loss: 9.9598617e-07
Iter: 1712 loss: 9.95397613e-07
Iter: 1713 loss: 9.94676157e-07
Iter: 1714 loss: 9.97933739e-07
Iter: 1715 loss: 9.94560196e-07
Iter: 1716 loss: 9.94046673e-07
Iter: 1717 loss: 9.93829644e-07
Iter: 1718 loss: 9.93508593e-07
Iter: 1719 loss: 9.92727905e-07
Iter: 1720 loss: 9.9609565e-07
Iter: 1721 loss: 9.92585228e-07
Iter: 1722 loss: 9.919695e-07
Iter: 1723 loss: 9.96803124e-07
Iter: 1724 loss: 9.91917091e-07
Iter: 1725 loss: 9.9130466e-07
Iter: 1726 loss: 9.91728371e-07
Iter: 1727 loss: 9.90937e-07
Iter: 1728 loss: 9.90292e-07
Iter: 1729 loss: 9.90393914e-07
Iter: 1730 loss: 9.89833325e-07
Iter: 1731 loss: 9.8951034e-07
Iter: 1732 loss: 9.89404384e-07
Iter: 1733 loss: 9.89030809e-07
Iter: 1734 loss: 9.88463853e-07
Iter: 1735 loss: 9.88459078e-07
Iter: 1736 loss: 9.87804697e-07
Iter: 1737 loss: 9.89687123e-07
Iter: 1738 loss: 9.8753867e-07
Iter: 1739 loss: 9.86773557e-07
Iter: 1740 loss: 9.90344233e-07
Iter: 1741 loss: 9.86666e-07
Iter: 1742 loss: 9.86062105e-07
Iter: 1743 loss: 9.85586439e-07
Iter: 1744 loss: 9.85420456e-07
Iter: 1745 loss: 9.84503458e-07
Iter: 1746 loss: 9.93492563e-07
Iter: 1747 loss: 9.84485496e-07
Iter: 1748 loss: 9.83871928e-07
Iter: 1749 loss: 9.8671e-07
Iter: 1750 loss: 9.83753e-07
Iter: 1751 loss: 9.83159907e-07
Iter: 1752 loss: 9.83104428e-07
Iter: 1753 loss: 9.82642064e-07
Iter: 1754 loss: 9.81944709e-07
Iter: 1755 loss: 9.87597559e-07
Iter: 1756 loss: 9.81897529e-07
Iter: 1757 loss: 9.81431867e-07
Iter: 1758 loss: 9.81229164e-07
Iter: 1759 loss: 9.80927553e-07
Iter: 1760 loss: 9.80259529e-07
Iter: 1761 loss: 9.84411827e-07
Iter: 1762 loss: 9.80138111e-07
Iter: 1763 loss: 9.79499305e-07
Iter: 1764 loss: 9.82887741e-07
Iter: 1765 loss: 9.79401534e-07
Iter: 1766 loss: 9.78896082e-07
Iter: 1767 loss: 9.78508751e-07
Iter: 1768 loss: 9.78223852e-07
Iter: 1769 loss: 9.77662921e-07
Iter: 1770 loss: 9.7768e-07
Iter: 1771 loss: 9.77209766e-07
Iter: 1772 loss: 9.77245463e-07
Iter: 1773 loss: 9.76875299e-07
Iter: 1774 loss: 9.76377805e-07
Iter: 1775 loss: 9.75805733e-07
Iter: 1776 loss: 9.75710918e-07
Iter: 1777 loss: 9.74964e-07
Iter: 1778 loss: 9.81355925e-07
Iter: 1779 loss: 9.748926e-07
Iter: 1780 loss: 9.74210479e-07
Iter: 1781 loss: 9.78067874e-07
Iter: 1782 loss: 9.7415932e-07
Iter: 1783 loss: 9.73618171e-07
Iter: 1784 loss: 9.7304212e-07
Iter: 1785 loss: 9.72909902e-07
Iter: 1786 loss: 9.72130351e-07
Iter: 1787 loss: 9.78502385e-07
Iter: 1788 loss: 9.72126145e-07
Iter: 1789 loss: 9.71447321e-07
Iter: 1790 loss: 9.74359295e-07
Iter: 1791 loss: 9.7137854e-07
Iter: 1792 loss: 9.70784299e-07
Iter: 1793 loss: 9.71436179e-07
Iter: 1794 loss: 9.70509177e-07
Iter: 1795 loss: 9.69820121e-07
Iter: 1796 loss: 9.73942178e-07
Iter: 1797 loss: 9.69757707e-07
Iter: 1798 loss: 9.69212806e-07
Iter: 1799 loss: 9.68966674e-07
Iter: 1800 loss: 9.68695417e-07
Iter: 1801 loss: 9.68082077e-07
Iter: 1802 loss: 9.72283487e-07
Iter: 1803 loss: 9.67974756e-07
Iter: 1804 loss: 9.67403821e-07
Iter: 1805 loss: 9.71194e-07
Iter: 1806 loss: 9.67312644e-07
Iter: 1807 loss: 9.66891662e-07
Iter: 1808 loss: 9.66659627e-07
Iter: 1809 loss: 9.66523885e-07
Iter: 1810 loss: 9.65955678e-07
Iter: 1811 loss: 9.71298e-07
Iter: 1812 loss: 9.65986374e-07
Iter: 1813 loss: 9.65466143e-07
Iter: 1814 loss: 9.65121444e-07
Iter: 1815 loss: 9.64981155e-07
Iter: 1816 loss: 9.64252877e-07
Iter: 1817 loss: 9.65215349e-07
Iter: 1818 loss: 9.63895786e-07
Iter: 1819 loss: 9.63063485e-07
Iter: 1820 loss: 9.64726155e-07
Iter: 1821 loss: 9.62815307e-07
Iter: 1822 loss: 9.62002105e-07
Iter: 1823 loss: 9.69146186e-07
Iter: 1824 loss: 9.61967885e-07
Iter: 1825 loss: 9.61275646e-07
Iter: 1826 loss: 9.61856813e-07
Iter: 1827 loss: 9.60818852e-07
Iter: 1828 loss: 9.60252123e-07
Iter: 1829 loss: 9.60721422e-07
Iter: 1830 loss: 9.59849103e-07
Iter: 1831 loss: 9.59122644e-07
Iter: 1832 loss: 9.65651111e-07
Iter: 1833 loss: 9.59076374e-07
Iter: 1834 loss: 9.58519877e-07
Iter: 1835 loss: 9.60210286e-07
Iter: 1836 loss: 9.58329224e-07
Iter: 1837 loss: 9.57825932e-07
Iter: 1838 loss: 9.60134685e-07
Iter: 1839 loss: 9.57686666e-07
Iter: 1840 loss: 9.57069e-07
Iter: 1841 loss: 9.5734481e-07
Iter: 1842 loss: 9.56666781e-07
Iter: 1843 loss: 9.56129e-07
Iter: 1844 loss: 9.63465482e-07
Iter: 1845 loss: 9.56104259e-07
Iter: 1846 loss: 9.55673841e-07
Iter: 1847 loss: 9.55344262e-07
Iter: 1848 loss: 9.55244104e-07
Iter: 1849 loss: 9.54593247e-07
Iter: 1850 loss: 9.5515e-07
Iter: 1851 loss: 9.54243433e-07
Iter: 1852 loss: 9.53677159e-07
Iter: 1853 loss: 9.61884552e-07
Iter: 1854 loss: 9.53675908e-07
Iter: 1855 loss: 9.53100823e-07
Iter: 1856 loss: 9.52935693e-07
Iter: 1857 loss: 9.52652954e-07
Iter: 1858 loss: 9.52057349e-07
Iter: 1859 loss: 9.52332584e-07
Iter: 1860 loss: 9.5167718e-07
Iter: 1861 loss: 9.50931337e-07
Iter: 1862 loss: 9.53399422e-07
Iter: 1863 loss: 9.50774904e-07
Iter: 1864 loss: 9.50005301e-07
Iter: 1865 loss: 9.51576e-07
Iter: 1866 loss: 9.49666685e-07
Iter: 1867 loss: 9.48941306e-07
Iter: 1868 loss: 9.52777e-07
Iter: 1869 loss: 9.48777256e-07
Iter: 1870 loss: 9.47981107e-07
Iter: 1871 loss: 9.50846299e-07
Iter: 1872 loss: 9.47756689e-07
Iter: 1873 loss: 9.47199453e-07
Iter: 1874 loss: 9.50871e-07
Iter: 1875 loss: 9.4714909e-07
Iter: 1876 loss: 9.46549335e-07
Iter: 1877 loss: 9.47439275e-07
Iter: 1878 loss: 9.46359819e-07
Iter: 1879 loss: 9.45865963e-07
Iter: 1880 loss: 9.48900549e-07
Iter: 1881 loss: 9.45823615e-07
Iter: 1882 loss: 9.45411216e-07
Iter: 1883 loss: 9.45103352e-07
Iter: 1884 loss: 9.44991029e-07
Iter: 1885 loss: 9.44405e-07
Iter: 1886 loss: 9.45921897e-07
Iter: 1887 loss: 9.44163673e-07
Iter: 1888 loss: 9.43518671e-07
Iter: 1889 loss: 9.47002604e-07
Iter: 1890 loss: 9.43378723e-07
Iter: 1891 loss: 9.42797442e-07
Iter: 1892 loss: 9.43218765e-07
Iter: 1893 loss: 9.42402266e-07
Iter: 1894 loss: 9.41821838e-07
Iter: 1895 loss: 9.46697e-07
Iter: 1896 loss: 9.4176994e-07
Iter: 1897 loss: 9.41204462e-07
Iter: 1898 loss: 9.40803659e-07
Iter: 1899 loss: 9.40650807e-07
Iter: 1900 loss: 9.39985796e-07
Iter: 1901 loss: 9.41042231e-07
Iter: 1902 loss: 9.39600568e-07
Iter: 1903 loss: 9.38802714e-07
Iter: 1904 loss: 9.41313829e-07
Iter: 1905 loss: 9.3853339e-07
Iter: 1906 loss: 9.37914933e-07
Iter: 1907 loss: 9.44389171e-07
Iter: 1908 loss: 9.37920731e-07
Iter: 1909 loss: 9.37355139e-07
Iter: 1910 loss: 9.39946062e-07
Iter: 1911 loss: 9.37213485e-07
Iter: 1912 loss: 9.36838092e-07
Iter: 1913 loss: 9.37687446e-07
Iter: 1914 loss: 9.36693368e-07
Iter: 1915 loss: 9.36236688e-07
Iter: 1916 loss: 9.3728255e-07
Iter: 1917 loss: 9.36042625e-07
Iter: 1918 loss: 9.35534e-07
Iter: 1919 loss: 9.35686103e-07
Iter: 1920 loss: 9.35181333e-07
Iter: 1921 loss: 9.3461631e-07
Iter: 1922 loss: 9.3664346e-07
Iter: 1923 loss: 9.34468517e-07
Iter: 1924 loss: 9.33781052e-07
Iter: 1925 loss: 9.36183085e-07
Iter: 1926 loss: 9.33643207e-07
Iter: 1927 loss: 9.33182946e-07
Iter: 1928 loss: 9.35085495e-07
Iter: 1929 loss: 9.33109277e-07
Iter: 1930 loss: 9.32644e-07
Iter: 1931 loss: 9.32615649e-07
Iter: 1932 loss: 9.32191426e-07
Iter: 1933 loss: 9.31654199e-07
Iter: 1934 loss: 9.33392869e-07
Iter: 1935 loss: 9.31475824e-07
Iter: 1936 loss: 9.30889769e-07
Iter: 1937 loss: 9.32497642e-07
Iter: 1938 loss: 9.30696103e-07
Iter: 1939 loss: 9.30053886e-07
Iter: 1940 loss: 9.30809165e-07
Iter: 1941 loss: 9.29720045e-07
Iter: 1942 loss: 9.290261e-07
Iter: 1943 loss: 9.30000169e-07
Iter: 1944 loss: 9.28695499e-07
Iter: 1945 loss: 9.28229326e-07
Iter: 1946 loss: 9.28227109e-07
Iter: 1947 loss: 9.27708129e-07
Iter: 1948 loss: 9.28129452e-07
Iter: 1949 loss: 9.27359395e-07
Iter: 1950 loss: 9.26948644e-07
Iter: 1951 loss: 9.27536462e-07
Iter: 1952 loss: 9.26758958e-07
Iter: 1953 loss: 9.26049324e-07
Iter: 1954 loss: 9.2783e-07
Iter: 1955 loss: 9.25879e-07
Iter: 1956 loss: 9.25350719e-07
Iter: 1957 loss: 9.25158758e-07
Iter: 1958 loss: 9.24898814e-07
Iter: 1959 loss: 9.24298e-07
Iter: 1960 loss: 9.30111753e-07
Iter: 1961 loss: 9.24275298e-07
Iter: 1962 loss: 9.23824e-07
Iter: 1963 loss: 9.26535677e-07
Iter: 1964 loss: 9.23773655e-07
Iter: 1965 loss: 9.23336074e-07
Iter: 1966 loss: 9.22717334e-07
Iter: 1967 loss: 9.22721085e-07
Iter: 1968 loss: 9.22038339e-07
Iter: 1969 loss: 9.26500604e-07
Iter: 1970 loss: 9.21952392e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi1.6/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2
+ date
Sat Nov  7 15:03:07 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2/500_500_500_500_1 --optimizer lbfgs --function f2 --psi 2 --alpha 2 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e128d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e11d1488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1162598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e11882f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1188620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1188730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1131840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e11ee9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e11197b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e10c7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e10607b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1052268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e10267b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1058e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1058950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93e1013f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8b5e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8b24598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8b11268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8b117b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8aee6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8a78a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8a78598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93a8a63d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9384301620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93843070d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9384307598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93842c41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93842e3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9384274e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9384274d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9384238268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9384238840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9384243400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93841c69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f93841af2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.62097853e-05
Iter: 2 loss: 3.2783777e-05
Iter: 3 loss: 3.55063639e-05
Iter: 4 loss: 3.07148621e-05
Iter: 5 loss: 2.72189482e-05
Iter: 6 loss: 3.23248423e-05
Iter: 7 loss: 2.55327504e-05
Iter: 8 loss: 2.22519557e-05
Iter: 9 loss: 2.93568282e-05
Iter: 10 loss: 2.09749214e-05
Iter: 11 loss: 1.84505698e-05
Iter: 12 loss: 3.00019965e-05
Iter: 13 loss: 1.79734088e-05
Iter: 14 loss: 1.65277706e-05
Iter: 15 loss: 2.13808489e-05
Iter: 16 loss: 1.61319676e-05
Iter: 17 loss: 1.45636723e-05
Iter: 18 loss: 1.92348e-05
Iter: 19 loss: 1.40863121e-05
Iter: 20 loss: 1.28842694e-05
Iter: 21 loss: 1.48159279e-05
Iter: 22 loss: 1.23293903e-05
Iter: 23 loss: 1.13280294e-05
Iter: 24 loss: 1.51129507e-05
Iter: 25 loss: 1.10870069e-05
Iter: 26 loss: 1.01008427e-05
Iter: 27 loss: 1.72532909e-05
Iter: 28 loss: 1.001694e-05
Iter: 29 loss: 9.50198228e-06
Iter: 30 loss: 1.11333684e-05
Iter: 31 loss: 9.35442768e-06
Iter: 32 loss: 8.86062e-06
Iter: 33 loss: 9.25409222e-06
Iter: 34 loss: 8.56262795e-06
Iter: 35 loss: 8.03281182e-06
Iter: 36 loss: 1.01662645e-05
Iter: 37 loss: 7.91479579e-06
Iter: 38 loss: 7.5259768e-06
Iter: 39 loss: 8.24862764e-06
Iter: 40 loss: 7.35973435e-06
Iter: 41 loss: 6.96774168e-06
Iter: 42 loss: 8.00523776e-06
Iter: 43 loss: 6.83656663e-06
Iter: 44 loss: 6.49174399e-06
Iter: 45 loss: 7.49090214e-06
Iter: 46 loss: 6.38442589e-06
Iter: 47 loss: 6.19358343e-06
Iter: 48 loss: 6.18113427e-06
Iter: 49 loss: 5.99520126e-06
Iter: 50 loss: 6.05169771e-06
Iter: 51 loss: 5.86219e-06
Iter: 52 loss: 5.68063479e-06
Iter: 53 loss: 5.73886791e-06
Iter: 54 loss: 5.55150291e-06
Iter: 55 loss: 5.3427857e-06
Iter: 56 loss: 6.16465331e-06
Iter: 57 loss: 5.29497493e-06
Iter: 58 loss: 5.11640792e-06
Iter: 59 loss: 6.5067843e-06
Iter: 60 loss: 5.10376321e-06
Iter: 61 loss: 4.98957661e-06
Iter: 62 loss: 5.0484241e-06
Iter: 63 loss: 4.91361152e-06
Iter: 64 loss: 4.79388382e-06
Iter: 65 loss: 6.33305808e-06
Iter: 66 loss: 4.79316532e-06
Iter: 67 loss: 4.71263684e-06
Iter: 68 loss: 4.58560908e-06
Iter: 69 loss: 4.58420345e-06
Iter: 70 loss: 4.45545538e-06
Iter: 71 loss: 5.50622281e-06
Iter: 72 loss: 4.44747184e-06
Iter: 73 loss: 4.35678749e-06
Iter: 74 loss: 4.94776395e-06
Iter: 75 loss: 4.34707e-06
Iter: 76 loss: 4.26306588e-06
Iter: 77 loss: 4.40026452e-06
Iter: 78 loss: 4.22480343e-06
Iter: 79 loss: 4.14706756e-06
Iter: 80 loss: 4.33182595e-06
Iter: 81 loss: 4.11879682e-06
Iter: 82 loss: 4.04197363e-06
Iter: 83 loss: 4.30585669e-06
Iter: 84 loss: 4.02153546e-06
Iter: 85 loss: 3.95489042e-06
Iter: 86 loss: 3.91833146e-06
Iter: 87 loss: 3.88849e-06
Iter: 88 loss: 3.79798803e-06
Iter: 89 loss: 4.23875872e-06
Iter: 90 loss: 3.78226741e-06
Iter: 91 loss: 3.71868555e-06
Iter: 92 loss: 4.19923344e-06
Iter: 93 loss: 3.71390342e-06
Iter: 94 loss: 3.64661582e-06
Iter: 95 loss: 4.01853049e-06
Iter: 96 loss: 3.63686081e-06
Iter: 97 loss: 3.60024069e-06
Iter: 98 loss: 3.53982614e-06
Iter: 99 loss: 3.53956284e-06
Iter: 100 loss: 3.48806725e-06
Iter: 101 loss: 3.48806816e-06
Iter: 102 loss: 3.44694627e-06
Iter: 103 loss: 3.46132447e-06
Iter: 104 loss: 3.41802479e-06
Iter: 105 loss: 3.37579331e-06
Iter: 106 loss: 3.69256031e-06
Iter: 107 loss: 3.37251e-06
Iter: 108 loss: 3.33458502e-06
Iter: 109 loss: 3.39205644e-06
Iter: 110 loss: 3.31671731e-06
Iter: 111 loss: 3.27489943e-06
Iter: 112 loss: 3.29286763e-06
Iter: 113 loss: 3.24647181e-06
Iter: 114 loss: 3.20486743e-06
Iter: 115 loss: 3.37610095e-06
Iter: 116 loss: 3.19592073e-06
Iter: 117 loss: 3.1534255e-06
Iter: 118 loss: 3.41361283e-06
Iter: 119 loss: 3.14834824e-06
Iter: 120 loss: 3.1144823e-06
Iter: 121 loss: 3.18988987e-06
Iter: 122 loss: 3.101723e-06
Iter: 123 loss: 3.07296818e-06
Iter: 124 loss: 3.13675e-06
Iter: 125 loss: 3.06193806e-06
Iter: 126 loss: 3.03451225e-06
Iter: 127 loss: 3.10832911e-06
Iter: 128 loss: 3.02540229e-06
Iter: 129 loss: 2.99313911e-06
Iter: 130 loss: 2.99695398e-06
Iter: 131 loss: 2.96831104e-06
Iter: 132 loss: 2.93648372e-06
Iter: 133 loss: 3.11335157e-06
Iter: 134 loss: 2.93192124e-06
Iter: 135 loss: 2.9096e-06
Iter: 136 loss: 2.90954358e-06
Iter: 137 loss: 2.89109221e-06
Iter: 138 loss: 2.87205194e-06
Iter: 139 loss: 2.86856562e-06
Iter: 140 loss: 2.84090333e-06
Iter: 141 loss: 2.85787769e-06
Iter: 142 loss: 2.8232862e-06
Iter: 143 loss: 2.7941353e-06
Iter: 144 loss: 2.85695796e-06
Iter: 145 loss: 2.78292691e-06
Iter: 146 loss: 2.75062189e-06
Iter: 147 loss: 2.88588944e-06
Iter: 148 loss: 2.74373951e-06
Iter: 149 loss: 2.7222477e-06
Iter: 150 loss: 2.98019563e-06
Iter: 151 loss: 2.72204625e-06
Iter: 152 loss: 2.70562396e-06
Iter: 153 loss: 2.71733234e-06
Iter: 154 loss: 2.6954408e-06
Iter: 155 loss: 2.67787664e-06
Iter: 156 loss: 2.77099798e-06
Iter: 157 loss: 2.67510927e-06
Iter: 158 loss: 2.65713834e-06
Iter: 159 loss: 2.69881161e-06
Iter: 160 loss: 2.65059703e-06
Iter: 161 loss: 2.63344373e-06
Iter: 162 loss: 2.62442018e-06
Iter: 163 loss: 2.61670039e-06
Iter: 164 loss: 2.5967222e-06
Iter: 165 loss: 2.77674371e-06
Iter: 166 loss: 2.59575745e-06
Iter: 167 loss: 2.57669e-06
Iter: 168 loss: 2.64261166e-06
Iter: 169 loss: 2.57168676e-06
Iter: 170 loss: 2.55751161e-06
Iter: 171 loss: 2.5517943e-06
Iter: 172 loss: 2.54436964e-06
Iter: 173 loss: 2.52702876e-06
Iter: 174 loss: 2.76202263e-06
Iter: 175 loss: 2.52707241e-06
Iter: 176 loss: 2.51675601e-06
Iter: 177 loss: 2.54711631e-06
Iter: 178 loss: 2.51351548e-06
Iter: 179 loss: 2.49860182e-06
Iter: 180 loss: 2.50025892e-06
Iter: 181 loss: 2.48728657e-06
Iter: 182 loss: 2.47519029e-06
Iter: 183 loss: 2.47181833e-06
Iter: 184 loss: 2.46443528e-06
Iter: 185 loss: 2.44680223e-06
Iter: 186 loss: 2.50161611e-06
Iter: 187 loss: 2.44181365e-06
Iter: 188 loss: 2.42402666e-06
Iter: 189 loss: 2.47927051e-06
Iter: 190 loss: 2.41870839e-06
Iter: 191 loss: 2.40290115e-06
Iter: 192 loss: 2.41797284e-06
Iter: 193 loss: 2.39385213e-06
Iter: 194 loss: 2.37745917e-06
Iter: 195 loss: 2.59620901e-06
Iter: 196 loss: 2.37739e-06
Iter: 197 loss: 2.36631536e-06
Iter: 198 loss: 2.38425605e-06
Iter: 199 loss: 2.36133019e-06
Iter: 200 loss: 2.34829713e-06
Iter: 201 loss: 2.37144218e-06
Iter: 202 loss: 2.34244908e-06
Iter: 203 loss: 2.3313e-06
Iter: 204 loss: 2.42208148e-06
Iter: 205 loss: 2.33045421e-06
Iter: 206 loss: 2.32025559e-06
Iter: 207 loss: 2.34116851e-06
Iter: 208 loss: 2.31619219e-06
Iter: 209 loss: 2.30665205e-06
Iter: 210 loss: 2.30682235e-06
Iter: 211 loss: 2.29917055e-06
Iter: 212 loss: 2.28873432e-06
Iter: 213 loss: 2.36583537e-06
Iter: 214 loss: 2.28788e-06
Iter: 215 loss: 2.27527721e-06
Iter: 216 loss: 2.29620173e-06
Iter: 217 loss: 2.26944121e-06
Iter: 218 loss: 2.25983104e-06
Iter: 219 loss: 2.28463296e-06
Iter: 220 loss: 2.25652389e-06
Iter: 221 loss: 2.24779296e-06
Iter: 222 loss: 2.25902249e-06
Iter: 223 loss: 2.2433278e-06
Iter: 224 loss: 2.2322165e-06
Iter: 225 loss: 2.25578401e-06
Iter: 226 loss: 2.22797826e-06
Iter: 227 loss: 2.21878827e-06
Iter: 228 loss: 2.31767399e-06
Iter: 229 loss: 2.21860273e-06
Iter: 230 loss: 2.21199434e-06
Iter: 231 loss: 2.2069944e-06
Iter: 232 loss: 2.20471748e-06
Iter: 233 loss: 2.19274716e-06
Iter: 234 loss: 2.19816457e-06
Iter: 235 loss: 2.18475498e-06
Iter: 236 loss: 2.17182469e-06
Iter: 237 loss: 2.21882783e-06
Iter: 238 loss: 2.16853914e-06
Iter: 239 loss: 2.15658838e-06
Iter: 240 loss: 2.16516901e-06
Iter: 241 loss: 2.14905435e-06
Iter: 242 loss: 2.13846761e-06
Iter: 243 loss: 2.13833437e-06
Iter: 244 loss: 2.13072212e-06
Iter: 245 loss: 2.14261809e-06
Iter: 246 loss: 2.12714349e-06
Iter: 247 loss: 2.1181138e-06
Iter: 248 loss: 2.12662144e-06
Iter: 249 loss: 2.1129265e-06
Iter: 250 loss: 2.10599683e-06
Iter: 251 loss: 2.1059268e-06
Iter: 252 loss: 2.09935592e-06
Iter: 253 loss: 2.09390396e-06
Iter: 254 loss: 2.09191603e-06
Iter: 255 loss: 2.08492565e-06
Iter: 256 loss: 2.16750914e-06
Iter: 257 loss: 2.08480333e-06
Iter: 258 loss: 2.07908761e-06
Iter: 259 loss: 2.07769972e-06
Iter: 260 loss: 2.07402081e-06
Iter: 261 loss: 2.06707341e-06
Iter: 262 loss: 2.06625737e-06
Iter: 263 loss: 2.0612124e-06
Iter: 264 loss: 2.0513678e-06
Iter: 265 loss: 2.12084183e-06
Iter: 266 loss: 2.05039942e-06
Iter: 267 loss: 2.04280332e-06
Iter: 268 loss: 2.05545166e-06
Iter: 269 loss: 2.03935315e-06
Iter: 270 loss: 2.03074433e-06
Iter: 271 loss: 2.05820288e-06
Iter: 272 loss: 2.0282248e-06
Iter: 273 loss: 2.02064894e-06
Iter: 274 loss: 2.04804792e-06
Iter: 275 loss: 2.0187108e-06
Iter: 276 loss: 2.01123203e-06
Iter: 277 loss: 2.05644938e-06
Iter: 278 loss: 2.01037392e-06
Iter: 279 loss: 2.00478553e-06
Iter: 280 loss: 1.99680471e-06
Iter: 281 loss: 1.99662895e-06
Iter: 282 loss: 1.98681391e-06
Iter: 283 loss: 2.04765479e-06
Iter: 284 loss: 1.98570365e-06
Iter: 285 loss: 1.97843815e-06
Iter: 286 loss: 1.97941063e-06
Iter: 287 loss: 1.97289205e-06
Iter: 288 loss: 1.9702461e-06
Iter: 289 loss: 1.96808878e-06
Iter: 290 loss: 1.96438941e-06
Iter: 291 loss: 1.96529982e-06
Iter: 292 loss: 1.96166343e-06
Iter: 293 loss: 1.95636449e-06
Iter: 294 loss: 1.95538883e-06
Iter: 295 loss: 1.95167854e-06
Iter: 296 loss: 1.94471318e-06
Iter: 297 loss: 1.9999668e-06
Iter: 298 loss: 1.94426548e-06
Iter: 299 loss: 1.93949768e-06
Iter: 300 loss: 1.94389804e-06
Iter: 301 loss: 1.93675828e-06
Iter: 302 loss: 1.92994162e-06
Iter: 303 loss: 1.95089115e-06
Iter: 304 loss: 1.92798575e-06
Iter: 305 loss: 1.92312518e-06
Iter: 306 loss: 1.92013476e-06
Iter: 307 loss: 1.91809477e-06
Iter: 308 loss: 1.90938817e-06
Iter: 309 loss: 1.9236652e-06
Iter: 310 loss: 1.90554397e-06
Iter: 311 loss: 1.89880711e-06
Iter: 312 loss: 1.95092298e-06
Iter: 313 loss: 1.89837613e-06
Iter: 314 loss: 1.89145021e-06
Iter: 315 loss: 1.91617914e-06
Iter: 316 loss: 1.88965259e-06
Iter: 317 loss: 1.88508136e-06
Iter: 318 loss: 1.90956553e-06
Iter: 319 loss: 1.88433614e-06
Iter: 320 loss: 1.87957255e-06
Iter: 321 loss: 1.88092486e-06
Iter: 322 loss: 1.87619071e-06
Iter: 323 loss: 1.87005253e-06
Iter: 324 loss: 1.87780734e-06
Iter: 325 loss: 1.86696889e-06
Iter: 326 loss: 1.8611986e-06
Iter: 327 loss: 1.88312356e-06
Iter: 328 loss: 1.85971146e-06
Iter: 329 loss: 1.85356657e-06
Iter: 330 loss: 1.85015779e-06
Iter: 331 loss: 1.84742157e-06
Iter: 332 loss: 1.8416406e-06
Iter: 333 loss: 1.84160444e-06
Iter: 334 loss: 1.83687484e-06
Iter: 335 loss: 1.84356304e-06
Iter: 336 loss: 1.83460622e-06
Iter: 337 loss: 1.82825249e-06
Iter: 338 loss: 1.86527132e-06
Iter: 339 loss: 1.82744805e-06
Iter: 340 loss: 1.82351687e-06
Iter: 341 loss: 1.83520456e-06
Iter: 342 loss: 1.8223991e-06
Iter: 343 loss: 1.81760538e-06
Iter: 344 loss: 1.8237721e-06
Iter: 345 loss: 1.81514827e-06
Iter: 346 loss: 1.8101673e-06
Iter: 347 loss: 1.81885878e-06
Iter: 348 loss: 1.80801305e-06
Iter: 349 loss: 1.80215534e-06
Iter: 350 loss: 1.81178757e-06
Iter: 351 loss: 1.79942731e-06
Iter: 352 loss: 1.79461449e-06
Iter: 353 loss: 1.80031043e-06
Iter: 354 loss: 1.79200129e-06
Iter: 355 loss: 1.78610276e-06
Iter: 356 loss: 1.79039239e-06
Iter: 357 loss: 1.78254527e-06
Iter: 358 loss: 1.77526158e-06
Iter: 359 loss: 1.81453208e-06
Iter: 360 loss: 1.77423431e-06
Iter: 361 loss: 1.76918297e-06
Iter: 362 loss: 1.79608969e-06
Iter: 363 loss: 1.76840877e-06
Iter: 364 loss: 1.76345543e-06
Iter: 365 loss: 1.77612844e-06
Iter: 366 loss: 1.76166736e-06
Iter: 367 loss: 1.75727871e-06
Iter: 368 loss: 1.76827098e-06
Iter: 369 loss: 1.75559626e-06
Iter: 370 loss: 1.75073046e-06
Iter: 371 loss: 1.78063715e-06
Iter: 372 loss: 1.7501369e-06
Iter: 373 loss: 1.74612239e-06
Iter: 374 loss: 1.74473212e-06
Iter: 375 loss: 1.74253057e-06
Iter: 376 loss: 1.73764101e-06
Iter: 377 loss: 1.75343416e-06
Iter: 378 loss: 1.73628155e-06
Iter: 379 loss: 1.731456e-06
Iter: 380 loss: 1.74288471e-06
Iter: 381 loss: 1.72985926e-06
Iter: 382 loss: 1.72539251e-06
Iter: 383 loss: 1.72538375e-06
Iter: 384 loss: 1.72303749e-06
Iter: 385 loss: 1.71864201e-06
Iter: 386 loss: 1.71861325e-06
Iter: 387 loss: 1.71428474e-06
Iter: 388 loss: 1.77477068e-06
Iter: 389 loss: 1.71421823e-06
Iter: 390 loss: 1.71151692e-06
Iter: 391 loss: 1.71015358e-06
Iter: 392 loss: 1.70882629e-06
Iter: 393 loss: 1.70458009e-06
Iter: 394 loss: 1.72856039e-06
Iter: 395 loss: 1.70399881e-06
Iter: 396 loss: 1.7004794e-06
Iter: 397 loss: 1.69798091e-06
Iter: 398 loss: 1.69670864e-06
Iter: 399 loss: 1.69133091e-06
Iter: 400 loss: 1.70628812e-06
Iter: 401 loss: 1.68967847e-06
Iter: 402 loss: 1.68463532e-06
Iter: 403 loss: 1.71392458e-06
Iter: 404 loss: 1.68406382e-06
Iter: 405 loss: 1.67991675e-06
Iter: 406 loss: 1.6887775e-06
Iter: 407 loss: 1.6782684e-06
Iter: 408 loss: 1.67374151e-06
Iter: 409 loss: 1.70153703e-06
Iter: 410 loss: 1.67312555e-06
Iter: 411 loss: 1.66999143e-06
Iter: 412 loss: 1.67733924e-06
Iter: 413 loss: 1.6688806e-06
Iter: 414 loss: 1.6647424e-06
Iter: 415 loss: 1.66343352e-06
Iter: 416 loss: 1.66110271e-06
Iter: 417 loss: 1.6556213e-06
Iter: 418 loss: 1.67766234e-06
Iter: 419 loss: 1.65440974e-06
Iter: 420 loss: 1.65121196e-06
Iter: 421 loss: 1.68707879e-06
Iter: 422 loss: 1.65110919e-06
Iter: 423 loss: 1.64775884e-06
Iter: 424 loss: 1.65153426e-06
Iter: 425 loss: 1.64585458e-06
Iter: 426 loss: 1.64280618e-06
Iter: 427 loss: 1.64287462e-06
Iter: 428 loss: 1.64041944e-06
Iter: 429 loss: 1.63721279e-06
Iter: 430 loss: 1.67512542e-06
Iter: 431 loss: 1.63720597e-06
Iter: 432 loss: 1.63439267e-06
Iter: 433 loss: 1.63363575e-06
Iter: 434 loss: 1.63186519e-06
Iter: 435 loss: 1.62823187e-06
Iter: 436 loss: 1.63501863e-06
Iter: 437 loss: 1.62652657e-06
Iter: 438 loss: 1.62233e-06
Iter: 439 loss: 1.63857214e-06
Iter: 440 loss: 1.62144374e-06
Iter: 441 loss: 1.61718958e-06
Iter: 442 loss: 1.62529432e-06
Iter: 443 loss: 1.61544313e-06
Iter: 444 loss: 1.61146772e-06
Iter: 445 loss: 1.61107346e-06
Iter: 446 loss: 1.60809964e-06
Iter: 447 loss: 1.60282764e-06
Iter: 448 loss: 1.62749973e-06
Iter: 449 loss: 1.60176614e-06
Iter: 450 loss: 1.59788499e-06
Iter: 451 loss: 1.63751372e-06
Iter: 452 loss: 1.59774095e-06
Iter: 453 loss: 1.59416572e-06
Iter: 454 loss: 1.60131492e-06
Iter: 455 loss: 1.59264664e-06
Iter: 456 loss: 1.58938747e-06
Iter: 457 loss: 1.59307524e-06
Iter: 458 loss: 1.58770035e-06
Iter: 459 loss: 1.58380408e-06
Iter: 460 loss: 1.59956539e-06
Iter: 461 loss: 1.58289799e-06
Iter: 462 loss: 1.57949728e-06
Iter: 463 loss: 1.581535e-06
Iter: 464 loss: 1.57736076e-06
Iter: 465 loss: 1.57397687e-06
Iter: 466 loss: 1.60055106e-06
Iter: 467 loss: 1.57360182e-06
Iter: 468 loss: 1.56995293e-06
Iter: 469 loss: 1.58410501e-06
Iter: 470 loss: 1.56906708e-06
Iter: 471 loss: 1.56626891e-06
Iter: 472 loss: 1.5653834e-06
Iter: 473 loss: 1.56361489e-06
Iter: 474 loss: 1.56077499e-06
Iter: 475 loss: 1.60356535e-06
Iter: 476 loss: 1.56081228e-06
Iter: 477 loss: 1.5586204e-06
Iter: 478 loss: 1.55471446e-06
Iter: 479 loss: 1.55468888e-06
Iter: 480 loss: 1.55022894e-06
Iter: 481 loss: 1.57421914e-06
Iter: 482 loss: 1.54953511e-06
Iter: 483 loss: 1.54632562e-06
Iter: 484 loss: 1.5614014e-06
Iter: 485 loss: 1.54571421e-06
Iter: 486 loss: 1.54258146e-06
Iter: 487 loss: 1.54701354e-06
Iter: 488 loss: 1.541041e-06
Iter: 489 loss: 1.53721544e-06
Iter: 490 loss: 1.54416171e-06
Iter: 491 loss: 1.5356236e-06
Iter: 492 loss: 1.5325968e-06
Iter: 493 loss: 1.53909855e-06
Iter: 494 loss: 1.53140195e-06
Iter: 495 loss: 1.52737744e-06
Iter: 496 loss: 1.55278804e-06
Iter: 497 loss: 1.52694565e-06
Iter: 498 loss: 1.52395933e-06
Iter: 499 loss: 1.52936673e-06
Iter: 500 loss: 1.5226351e-06
Iter: 501 loss: 1.51993777e-06
Iter: 502 loss: 1.52044117e-06
Iter: 503 loss: 1.51785252e-06
Iter: 504 loss: 1.51414633e-06
Iter: 505 loss: 1.52588814e-06
Iter: 506 loss: 1.51309746e-06
Iter: 507 loss: 1.50926735e-06
Iter: 508 loss: 1.5438327e-06
Iter: 509 loss: 1.50912297e-06
Iter: 510 loss: 1.50715039e-06
Iter: 511 loss: 1.52708958e-06
Iter: 512 loss: 1.50711548e-06
Iter: 513 loss: 1.50560379e-06
Iter: 514 loss: 1.50191818e-06
Iter: 515 loss: 1.53717485e-06
Iter: 516 loss: 1.50140158e-06
Iter: 517 loss: 1.49770767e-06
Iter: 518 loss: 1.55064345e-06
Iter: 519 loss: 1.49769744e-06
Iter: 520 loss: 1.49504967e-06
Iter: 521 loss: 1.50437495e-06
Iter: 522 loss: 1.49429786e-06
Iter: 523 loss: 1.492048e-06
Iter: 524 loss: 1.48859931e-06
Iter: 525 loss: 1.48857487e-06
Iter: 526 loss: 1.48436686e-06
Iter: 527 loss: 1.51158565e-06
Iter: 528 loss: 1.48392155e-06
Iter: 529 loss: 1.48087952e-06
Iter: 530 loss: 1.49098923e-06
Iter: 531 loss: 1.48000117e-06
Iter: 532 loss: 1.47678452e-06
Iter: 533 loss: 1.49295556e-06
Iter: 534 loss: 1.47620062e-06
Iter: 535 loss: 1.47392257e-06
Iter: 536 loss: 1.47129572e-06
Iter: 537 loss: 1.47093021e-06
Iter: 538 loss: 1.46819946e-06
Iter: 539 loss: 1.46808497e-06
Iter: 540 loss: 1.4657719e-06
Iter: 541 loss: 1.4645957e-06
Iter: 542 loss: 1.46343496e-06
Iter: 543 loss: 1.4608429e-06
Iter: 544 loss: 1.46127991e-06
Iter: 545 loss: 1.45887338e-06
Iter: 546 loss: 1.4549056e-06
Iter: 547 loss: 1.47576782e-06
Iter: 548 loss: 1.45416254e-06
Iter: 549 loss: 1.45189483e-06
Iter: 550 loss: 1.48873312e-06
Iter: 551 loss: 1.45188392e-06
Iter: 552 loss: 1.44959517e-06
Iter: 553 loss: 1.45069021e-06
Iter: 554 loss: 1.44811929e-06
Iter: 555 loss: 1.4456682e-06
Iter: 556 loss: 1.44490525e-06
Iter: 557 loss: 1.44350543e-06
Iter: 558 loss: 1.44050273e-06
Iter: 559 loss: 1.45803665e-06
Iter: 560 loss: 1.44017645e-06
Iter: 561 loss: 1.4372406e-06
Iter: 562 loss: 1.45332433e-06
Iter: 563 loss: 1.43684599e-06
Iter: 564 loss: 1.43491604e-06
Iter: 565 loss: 1.43322632e-06
Iter: 566 loss: 1.43278317e-06
Iter: 567 loss: 1.42980753e-06
Iter: 568 loss: 1.44916703e-06
Iter: 569 loss: 1.42956878e-06
Iter: 570 loss: 1.42718432e-06
Iter: 571 loss: 1.43271131e-06
Iter: 572 loss: 1.42623639e-06
Iter: 573 loss: 1.42390263e-06
Iter: 574 loss: 1.42405054e-06
Iter: 575 loss: 1.42208501e-06
Iter: 576 loss: 1.41899682e-06
Iter: 577 loss: 1.4333508e-06
Iter: 578 loss: 1.41832231e-06
Iter: 579 loss: 1.41599116e-06
Iter: 580 loss: 1.44816795e-06
Iter: 581 loss: 1.4160064e-06
Iter: 582 loss: 1.41431042e-06
Iter: 583 loss: 1.41339501e-06
Iter: 584 loss: 1.41264763e-06
Iter: 585 loss: 1.40975271e-06
Iter: 586 loss: 1.4118466e-06
Iter: 587 loss: 1.40799102e-06
Iter: 588 loss: 1.40549218e-06
Iter: 589 loss: 1.43333932e-06
Iter: 590 loss: 1.40545455e-06
Iter: 591 loss: 1.40317945e-06
Iter: 592 loss: 1.41062014e-06
Iter: 593 loss: 1.40252496e-06
Iter: 594 loss: 1.40056738e-06
Iter: 595 loss: 1.41084797e-06
Iter: 596 loss: 1.40018233e-06
Iter: 597 loss: 1.39854592e-06
Iter: 598 loss: 1.39612985e-06
Iter: 599 loss: 1.39609369e-06
Iter: 600 loss: 1.39289045e-06
Iter: 601 loss: 1.3954259e-06
Iter: 602 loss: 1.3909372e-06
Iter: 603 loss: 1.38796634e-06
Iter: 604 loss: 1.4128625e-06
Iter: 605 loss: 1.38778955e-06
Iter: 606 loss: 1.38549694e-06
Iter: 607 loss: 1.40197335e-06
Iter: 608 loss: 1.38531789e-06
Iter: 609 loss: 1.38304267e-06
Iter: 610 loss: 1.38416431e-06
Iter: 611 loss: 1.38157122e-06
Iter: 612 loss: 1.3792004e-06
Iter: 613 loss: 1.38153791e-06
Iter: 614 loss: 1.37789175e-06
Iter: 615 loss: 1.37529719e-06
Iter: 616 loss: 1.38028759e-06
Iter: 617 loss: 1.37425491e-06
Iter: 618 loss: 1.37122925e-06
Iter: 619 loss: 1.38449491e-06
Iter: 620 loss: 1.37065604e-06
Iter: 621 loss: 1.36833944e-06
Iter: 622 loss: 1.37868983e-06
Iter: 623 loss: 1.36793869e-06
Iter: 624 loss: 1.3655856e-06
Iter: 625 loss: 1.36710389e-06
Iter: 626 loss: 1.36411086e-06
Iter: 627 loss: 1.3613012e-06
Iter: 628 loss: 1.37179154e-06
Iter: 629 loss: 1.36058e-06
Iter: 630 loss: 1.35865594e-06
Iter: 631 loss: 1.38183918e-06
Iter: 632 loss: 1.35857817e-06
Iter: 633 loss: 1.35682205e-06
Iter: 634 loss: 1.35512482e-06
Iter: 635 loss: 1.35474079e-06
Iter: 636 loss: 1.35276036e-06
Iter: 637 loss: 1.35270841e-06
Iter: 638 loss: 1.35104597e-06
Iter: 639 loss: 1.3508386e-06
Iter: 640 loss: 1.34963091e-06
Iter: 641 loss: 1.34773359e-06
Iter: 642 loss: 1.34687377e-06
Iter: 643 loss: 1.3458482e-06
Iter: 644 loss: 1.34327843e-06
Iter: 645 loss: 1.35354765e-06
Iter: 646 loss: 1.34272864e-06
Iter: 647 loss: 1.34026027e-06
Iter: 648 loss: 1.35364769e-06
Iter: 649 loss: 1.33993967e-06
Iter: 650 loss: 1.33771141e-06
Iter: 651 loss: 1.34151969e-06
Iter: 652 loss: 1.33667891e-06
Iter: 653 loss: 1.33484912e-06
Iter: 654 loss: 1.34300785e-06
Iter: 655 loss: 1.33445508e-06
Iter: 656 loss: 1.33226467e-06
Iter: 657 loss: 1.33720732e-06
Iter: 658 loss: 1.33136155e-06
Iter: 659 loss: 1.32947991e-06
Iter: 660 loss: 1.32833543e-06
Iter: 661 loss: 1.32752314e-06
Iter: 662 loss: 1.32505215e-06
Iter: 663 loss: 1.32705441e-06
Iter: 664 loss: 1.32351317e-06
Iter: 665 loss: 1.32059893e-06
Iter: 666 loss: 1.35239907e-06
Iter: 667 loss: 1.32055459e-06
Iter: 668 loss: 1.31850379e-06
Iter: 669 loss: 1.32018704e-06
Iter: 670 loss: 1.31728427e-06
Iter: 671 loss: 1.31512729e-06
Iter: 672 loss: 1.34279969e-06
Iter: 673 loss: 1.31505567e-06
Iter: 674 loss: 1.31349293e-06
Iter: 675 loss: 1.31777176e-06
Iter: 676 loss: 1.31295474e-06
Iter: 677 loss: 1.31115928e-06
Iter: 678 loss: 1.31470347e-06
Iter: 679 loss: 1.31044567e-06
Iter: 680 loss: 1.3088528e-06
Iter: 681 loss: 1.31286629e-06
Iter: 682 loss: 1.30827095e-06
Iter: 683 loss: 1.3065295e-06
Iter: 684 loss: 1.30865737e-06
Iter: 685 loss: 1.30553826e-06
Iter: 686 loss: 1.30363446e-06
Iter: 687 loss: 1.30281376e-06
Iter: 688 loss: 1.30182639e-06
Iter: 689 loss: 1.29913178e-06
Iter: 690 loss: 1.31783065e-06
Iter: 691 loss: 1.29886132e-06
Iter: 692 loss: 1.29697821e-06
Iter: 693 loss: 1.29456862e-06
Iter: 694 loss: 1.29439309e-06
Iter: 695 loss: 1.29318016e-06
Iter: 696 loss: 1.29277441e-06
Iter: 697 loss: 1.29135924e-06
Iter: 698 loss: 1.29335842e-06
Iter: 699 loss: 1.29062425e-06
Iter: 700 loss: 1.28878742e-06
Iter: 701 loss: 1.29044213e-06
Iter: 702 loss: 1.28768261e-06
Iter: 703 loss: 1.28569081e-06
Iter: 704 loss: 1.30002036e-06
Iter: 705 loss: 1.28553904e-06
Iter: 706 loss: 1.28404577e-06
Iter: 707 loss: 1.28225236e-06
Iter: 708 loss: 1.2820941e-06
Iter: 709 loss: 1.27957969e-06
Iter: 710 loss: 1.28801025e-06
Iter: 711 loss: 1.27886869e-06
Iter: 712 loss: 1.27742101e-06
Iter: 713 loss: 1.27733892e-06
Iter: 714 loss: 1.27595933e-06
Iter: 715 loss: 1.27629232e-06
Iter: 716 loss: 1.27492694e-06
Iter: 717 loss: 1.27345447e-06
Iter: 718 loss: 1.27744715e-06
Iter: 719 loss: 1.27297335e-06
Iter: 720 loss: 1.2712826e-06
Iter: 721 loss: 1.27497378e-06
Iter: 722 loss: 1.27062174e-06
Iter: 723 loss: 1.26915074e-06
Iter: 724 loss: 1.27152032e-06
Iter: 725 loss: 1.26850784e-06
Iter: 726 loss: 1.26644966e-06
Iter: 727 loss: 1.26879888e-06
Iter: 728 loss: 1.26537907e-06
Iter: 729 loss: 1.26336192e-06
Iter: 730 loss: 1.26836471e-06
Iter: 731 loss: 1.26266377e-06
Iter: 732 loss: 1.26060661e-06
Iter: 733 loss: 1.26358441e-06
Iter: 734 loss: 1.25957149e-06
Iter: 735 loss: 1.25741121e-06
Iter: 736 loss: 1.26532643e-06
Iter: 737 loss: 1.25680458e-06
Iter: 738 loss: 1.2550563e-06
Iter: 739 loss: 1.278024e-06
Iter: 740 loss: 1.25506313e-06
Iter: 741 loss: 1.25369195e-06
Iter: 742 loss: 1.25375459e-06
Iter: 743 loss: 1.25259771e-06
Iter: 744 loss: 1.25081942e-06
Iter: 745 loss: 1.25448628e-06
Iter: 746 loss: 1.25012662e-06
Iter: 747 loss: 1.24828011e-06
Iter: 748 loss: 1.25475663e-06
Iter: 749 loss: 1.24780695e-06
Iter: 750 loss: 1.24590269e-06
Iter: 751 loss: 1.24873804e-06
Iter: 752 loss: 1.24493477e-06
Iter: 753 loss: 1.24383973e-06
Iter: 754 loss: 1.24383951e-06
Iter: 755 loss: 1.24269764e-06
Iter: 756 loss: 1.24117855e-06
Iter: 757 loss: 1.24108692e-06
Iter: 758 loss: 1.23915811e-06
Iter: 759 loss: 1.24216899e-06
Iter: 760 loss: 1.2382468e-06
Iter: 761 loss: 1.23663585e-06
Iter: 762 loss: 1.25523013e-06
Iter: 763 loss: 1.23662198e-06
Iter: 764 loss: 1.23509972e-06
Iter: 765 loss: 1.234499e-06
Iter: 766 loss: 1.23372888e-06
Iter: 767 loss: 1.231792e-06
Iter: 768 loss: 1.23502628e-06
Iter: 769 loss: 1.23094e-06
Iter: 770 loss: 1.22880442e-06
Iter: 771 loss: 1.23399832e-06
Iter: 772 loss: 1.2280218e-06
Iter: 773 loss: 1.22601045e-06
Iter: 774 loss: 1.2430196e-06
Iter: 775 loss: 1.22591268e-06
Iter: 776 loss: 1.22447659e-06
Iter: 777 loss: 1.22489905e-06
Iter: 778 loss: 1.22346228e-06
Iter: 779 loss: 1.22201925e-06
Iter: 780 loss: 1.23792586e-06
Iter: 781 loss: 1.22195638e-06
Iter: 782 loss: 1.22050687e-06
Iter: 783 loss: 1.22150357e-06
Iter: 784 loss: 1.21964774e-06
Iter: 785 loss: 1.2182536e-06
Iter: 786 loss: 1.21878725e-06
Iter: 787 loss: 1.21735764e-06
Iter: 788 loss: 1.21540438e-06
Iter: 789 loss: 1.21991934e-06
Iter: 790 loss: 1.21462267e-06
Iter: 791 loss: 1.2133828e-06
Iter: 792 loss: 1.21334244e-06
Iter: 793 loss: 1.21228936e-06
Iter: 794 loss: 1.21189987e-06
Iter: 795 loss: 1.21140454e-06
Iter: 796 loss: 1.20971754e-06
Iter: 797 loss: 1.21269602e-06
Iter: 798 loss: 1.2089929e-06
Iter: 799 loss: 1.20738162e-06
Iter: 800 loss: 1.20821596e-06
Iter: 801 loss: 1.20631285e-06
Iter: 802 loss: 1.20469394e-06
Iter: 803 loss: 1.21556013e-06
Iter: 804 loss: 1.20452648e-06
Iter: 805 loss: 1.2028712e-06
Iter: 806 loss: 1.20749723e-06
Iter: 807 loss: 1.20232835e-06
Iter: 808 loss: 1.20098491e-06
Iter: 809 loss: 1.20128266e-06
Iter: 810 loss: 1.20002096e-06
Iter: 811 loss: 1.19816696e-06
Iter: 812 loss: 1.2024027e-06
Iter: 813 loss: 1.19745255e-06
Iter: 814 loss: 1.19563583e-06
Iter: 815 loss: 1.19873687e-06
Iter: 816 loss: 1.19482524e-06
Iter: 817 loss: 1.19316655e-06
Iter: 818 loss: 1.20088202e-06
Iter: 819 loss: 1.19278252e-06
Iter: 820 loss: 1.19099036e-06
Iter: 821 loss: 1.20318714e-06
Iter: 822 loss: 1.19084098e-06
Iter: 823 loss: 1.18946036e-06
Iter: 824 loss: 1.19085553e-06
Iter: 825 loss: 1.18871333e-06
Iter: 826 loss: 1.18715798e-06
Iter: 827 loss: 1.19376591e-06
Iter: 828 loss: 1.18689104e-06
Iter: 829 loss: 1.18569949e-06
Iter: 830 loss: 1.1870095e-06
Iter: 831 loss: 1.18505034e-06
Iter: 832 loss: 1.18356513e-06
Iter: 833 loss: 1.19876893e-06
Iter: 834 loss: 1.18351272e-06
Iter: 835 loss: 1.18256435e-06
Iter: 836 loss: 1.18102707e-06
Iter: 837 loss: 1.1809866e-06
Iter: 838 loss: 1.17937e-06
Iter: 839 loss: 1.18266246e-06
Iter: 840 loss: 1.17865864e-06
Iter: 841 loss: 1.17682703e-06
Iter: 842 loss: 1.18949038e-06
Iter: 843 loss: 1.17661511e-06
Iter: 844 loss: 1.17545881e-06
Iter: 845 loss: 1.18388607e-06
Iter: 846 loss: 1.17529498e-06
Iter: 847 loss: 1.17413299e-06
Iter: 848 loss: 1.17375589e-06
Iter: 849 loss: 1.17309742e-06
Iter: 850 loss: 1.17164427e-06
Iter: 851 loss: 1.18442881e-06
Iter: 852 loss: 1.17155173e-06
Iter: 853 loss: 1.17035927e-06
Iter: 854 loss: 1.16979641e-06
Iter: 855 loss: 1.16920148e-06
Iter: 856 loss: 1.16754427e-06
Iter: 857 loss: 1.17190234e-06
Iter: 858 loss: 1.16703541e-06
Iter: 859 loss: 1.16551428e-06
Iter: 860 loss: 1.17642708e-06
Iter: 861 loss: 1.16540809e-06
Iter: 862 loss: 1.16403351e-06
Iter: 863 loss: 1.16953072e-06
Iter: 864 loss: 1.16368278e-06
Iter: 865 loss: 1.16259889e-06
Iter: 866 loss: 1.16170906e-06
Iter: 867 loss: 1.16141291e-06
Iter: 868 loss: 1.1602009e-06
Iter: 869 loss: 1.16016474e-06
Iter: 870 loss: 1.15928674e-06
Iter: 871 loss: 1.15941259e-06
Iter: 872 loss: 1.15859257e-06
Iter: 873 loss: 1.15742102e-06
Iter: 874 loss: 1.15703961e-06
Iter: 875 loss: 1.15638977e-06
Iter: 876 loss: 1.15466048e-06
Iter: 877 loss: 1.1625574e-06
Iter: 878 loss: 1.15431828e-06
Iter: 879 loss: 1.15291198e-06
Iter: 880 loss: 1.15807086e-06
Iter: 881 loss: 1.15260059e-06
Iter: 882 loss: 1.15153409e-06
Iter: 883 loss: 1.15165085e-06
Iter: 884 loss: 1.15068872e-06
Iter: 885 loss: 1.14907982e-06
Iter: 886 loss: 1.16510637e-06
Iter: 887 loss: 1.14909722e-06
Iter: 888 loss: 1.14806062e-06
Iter: 889 loss: 1.14816635e-06
Iter: 890 loss: 1.14727334e-06
Iter: 891 loss: 1.14604109e-06
Iter: 892 loss: 1.15044236e-06
Iter: 893 loss: 1.14571219e-06
Iter: 894 loss: 1.14453724e-06
Iter: 895 loss: 1.14842896e-06
Iter: 896 loss: 1.14423938e-06
Iter: 897 loss: 1.14280715e-06
Iter: 898 loss: 1.14237321e-06
Iter: 899 loss: 1.14163061e-06
Iter: 900 loss: 1.14021361e-06
Iter: 901 loss: 1.16110584e-06
Iter: 902 loss: 1.14022987e-06
Iter: 903 loss: 1.13891065e-06
Iter: 904 loss: 1.14052955e-06
Iter: 905 loss: 1.13830663e-06
Iter: 906 loss: 1.13730539e-06
Iter: 907 loss: 1.14331851e-06
Iter: 908 loss: 1.13718602e-06
Iter: 909 loss: 1.13612e-06
Iter: 910 loss: 1.1367556e-06
Iter: 911 loss: 1.13540614e-06
Iter: 912 loss: 1.13421243e-06
Iter: 913 loss: 1.13340343e-06
Iter: 914 loss: 1.1329912e-06
Iter: 915 loss: 1.13145893e-06
Iter: 916 loss: 1.13512101e-06
Iter: 917 loss: 1.13087822e-06
Iter: 918 loss: 1.12923533e-06
Iter: 919 loss: 1.13608223e-06
Iter: 920 loss: 1.12886369e-06
Iter: 921 loss: 1.12720102e-06
Iter: 922 loss: 1.13515216e-06
Iter: 923 loss: 1.12689327e-06
Iter: 924 loss: 1.12544024e-06
Iter: 925 loss: 1.13003375e-06
Iter: 926 loss: 1.12508974e-06
Iter: 927 loss: 1.12392513e-06
Iter: 928 loss: 1.13118881e-06
Iter: 929 loss: 1.12385089e-06
Iter: 930 loss: 1.12289808e-06
Iter: 931 loss: 1.12143573e-06
Iter: 932 loss: 1.12139469e-06
Iter: 933 loss: 1.11992313e-06
Iter: 934 loss: 1.12918008e-06
Iter: 935 loss: 1.11975976e-06
Iter: 936 loss: 1.11884799e-06
Iter: 937 loss: 1.12812734e-06
Iter: 938 loss: 1.11878023e-06
Iter: 939 loss: 1.11785187e-06
Iter: 940 loss: 1.11700683e-06
Iter: 941 loss: 1.11678958e-06
Iter: 942 loss: 1.11555585e-06
Iter: 943 loss: 1.11552481e-06
Iter: 944 loss: 1.11472582e-06
Iter: 945 loss: 1.11478607e-06
Iter: 946 loss: 1.11404506e-06
Iter: 947 loss: 1.1128011e-06
Iter: 948 loss: 1.11763893e-06
Iter: 949 loss: 1.11247289e-06
Iter: 950 loss: 1.1115294e-06
Iter: 951 loss: 1.11295094e-06
Iter: 952 loss: 1.11108136e-06
Iter: 953 loss: 1.10999918e-06
Iter: 954 loss: 1.10862152e-06
Iter: 955 loss: 1.10849692e-06
Iter: 956 loss: 1.10683209e-06
Iter: 957 loss: 1.12254816e-06
Iter: 958 loss: 1.10675228e-06
Iter: 959 loss: 1.10554379e-06
Iter: 960 loss: 1.10731332e-06
Iter: 961 loss: 1.10498308e-06
Iter: 962 loss: 1.10343899e-06
Iter: 963 loss: 1.11597149e-06
Iter: 964 loss: 1.10338942e-06
Iter: 965 loss: 1.10230474e-06
Iter: 966 loss: 1.10466522e-06
Iter: 967 loss: 1.10191286e-06
Iter: 968 loss: 1.10092742e-06
Iter: 969 loss: 1.10125131e-06
Iter: 970 loss: 1.10022688e-06
Iter: 971 loss: 1.09877658e-06
Iter: 972 loss: 1.10391659e-06
Iter: 973 loss: 1.0984354e-06
Iter: 974 loss: 1.09724613e-06
Iter: 975 loss: 1.10031692e-06
Iter: 976 loss: 1.09682844e-06
Iter: 977 loss: 1.0959991e-06
Iter: 978 loss: 1.10580754e-06
Iter: 979 loss: 1.09602047e-06
Iter: 980 loss: 1.09519124e-06
Iter: 981 loss: 1.09472194e-06
Iter: 982 loss: 1.09435086e-06
Iter: 983 loss: 1.09339578e-06
Iter: 984 loss: 1.10409917e-06
Iter: 985 loss: 1.09335497e-06
Iter: 986 loss: 1.09251118e-06
Iter: 987 loss: 1.09218104e-06
Iter: 988 loss: 1.09181451e-06
Iter: 989 loss: 1.09067696e-06
Iter: 990 loss: 1.09408415e-06
Iter: 991 loss: 1.09033e-06
Iter: 992 loss: 1.08914242e-06
Iter: 993 loss: 1.09118378e-06
Iter: 994 loss: 1.0886306e-06
Iter: 995 loss: 1.08750328e-06
Iter: 996 loss: 1.08825134e-06
Iter: 997 loss: 1.08675158e-06
Iter: 998 loss: 1.085451e-06
Iter: 999 loss: 1.08853942e-06
Iter: 1000 loss: 1.08500387e-06
Iter: 1001 loss: 1.08373229e-06
Iter: 1002 loss: 1.10121709e-06
Iter: 1003 loss: 1.08376639e-06
Iter: 1004 loss: 1.08281301e-06
Iter: 1005 loss: 1.08222e-06
Iter: 1006 loss: 1.08185839e-06
Iter: 1007 loss: 1.0806051e-06
Iter: 1008 loss: 1.08557163e-06
Iter: 1009 loss: 1.08022675e-06
Iter: 1010 loss: 1.07914457e-06
Iter: 1011 loss: 1.08410063e-06
Iter: 1012 loss: 1.07895858e-06
Iter: 1013 loss: 1.07791e-06
Iter: 1014 loss: 1.08026256e-06
Iter: 1015 loss: 1.07754056e-06
Iter: 1016 loss: 1.07663766e-06
Iter: 1017 loss: 1.08678842e-06
Iter: 1018 loss: 1.07662811e-06
Iter: 1019 loss: 1.07594212e-06
Iter: 1020 loss: 1.07541359e-06
Iter: 1021 loss: 1.07518053e-06
Iter: 1022 loss: 1.07416008e-06
Iter: 1023 loss: 1.08157315e-06
Iter: 1024 loss: 1.07409619e-06
Iter: 1025 loss: 1.07314668e-06
Iter: 1026 loss: 1.07217147e-06
Iter: 1027 loss: 1.07206745e-06
Iter: 1028 loss: 1.07069593e-06
Iter: 1029 loss: 1.07836127e-06
Iter: 1030 loss: 1.07052017e-06
Iter: 1031 loss: 1.06934726e-06
Iter: 1032 loss: 1.07199594e-06
Iter: 1033 loss: 1.06897562e-06
Iter: 1034 loss: 1.06780885e-06
Iter: 1035 loss: 1.06930156e-06
Iter: 1036 loss: 1.0671888e-06
Iter: 1037 loss: 1.06607024e-06
Iter: 1038 loss: 1.07042365e-06
Iter: 1039 loss: 1.06583821e-06
Iter: 1040 loss: 1.06481298e-06
Iter: 1041 loss: 1.07115295e-06
Iter: 1042 loss: 1.06466496e-06
Iter: 1043 loss: 1.0636237e-06
Iter: 1044 loss: 1.06458151e-06
Iter: 1045 loss: 1.0629758e-06
Iter: 1046 loss: 1.06193431e-06
Iter: 1047 loss: 1.06218818e-06
Iter: 1048 loss: 1.06114226e-06
Iter: 1049 loss: 1.05989318e-06
Iter: 1050 loss: 1.06913035e-06
Iter: 1051 loss: 1.05976699e-06
Iter: 1052 loss: 1.05886966e-06
Iter: 1053 loss: 1.06591438e-06
Iter: 1054 loss: 1.05874915e-06
Iter: 1055 loss: 1.05790843e-06
Iter: 1056 loss: 1.05879622e-06
Iter: 1057 loss: 1.0574488e-06
Iter: 1058 loss: 1.05653862e-06
Iter: 1059 loss: 1.06056189e-06
Iter: 1060 loss: 1.05632671e-06
Iter: 1061 loss: 1.05557774e-06
Iter: 1062 loss: 1.05632512e-06
Iter: 1063 loss: 1.05515642e-06
Iter: 1064 loss: 1.05408185e-06
Iter: 1065 loss: 1.05516688e-06
Iter: 1066 loss: 1.05347226e-06
Iter: 1067 loss: 1.05226832e-06
Iter: 1068 loss: 1.05363256e-06
Iter: 1069 loss: 1.05160132e-06
Iter: 1070 loss: 1.05060803e-06
Iter: 1071 loss: 1.05666879e-06
Iter: 1072 loss: 1.05045842e-06
Iter: 1073 loss: 1.04945286e-06
Iter: 1074 loss: 1.05073457e-06
Iter: 1075 loss: 1.04887681e-06
Iter: 1076 loss: 1.04768401e-06
Iter: 1077 loss: 1.05086815e-06
Iter: 1078 loss: 1.04731646e-06
Iter: 1079 loss: 1.04638821e-06
Iter: 1080 loss: 1.05164065e-06
Iter: 1081 loss: 1.04622359e-06
Iter: 1082 loss: 1.04516585e-06
Iter: 1083 loss: 1.04760113e-06
Iter: 1084 loss: 1.04483615e-06
Iter: 1085 loss: 1.04385413e-06
Iter: 1086 loss: 1.0433389e-06
Iter: 1087 loss: 1.04285493e-06
Iter: 1088 loss: 1.04173751e-06
Iter: 1089 loss: 1.05007314e-06
Iter: 1090 loss: 1.04162e-06
Iter: 1091 loss: 1.04065953e-06
Iter: 1092 loss: 1.05116328e-06
Iter: 1093 loss: 1.04062838e-06
Iter: 1094 loss: 1.04011292e-06
Iter: 1095 loss: 1.039837e-06
Iter: 1096 loss: 1.03963043e-06
Iter: 1097 loss: 1.03864681e-06
Iter: 1098 loss: 1.04292508e-06
Iter: 1099 loss: 1.03844627e-06
Iter: 1100 loss: 1.03783077e-06
Iter: 1101 loss: 1.03867114e-06
Iter: 1102 loss: 1.03748368e-06
Iter: 1103 loss: 1.03658635e-06
Iter: 1104 loss: 1.03667901e-06
Iter: 1105 loss: 1.03584011e-06
Iter: 1106 loss: 1.0347228e-06
Iter: 1107 loss: 1.03747766e-06
Iter: 1108 loss: 1.03428727e-06
Iter: 1109 loss: 1.03318257e-06
Iter: 1110 loss: 1.03748914e-06
Iter: 1111 loss: 1.03298044e-06
Iter: 1112 loss: 1.03196373e-06
Iter: 1113 loss: 1.0358799e-06
Iter: 1114 loss: 1.03171135e-06
Iter: 1115 loss: 1.03080583e-06
Iter: 1116 loss: 1.03172329e-06
Iter: 1117 loss: 1.03031857e-06
Iter: 1118 loss: 1.029278e-06
Iter: 1119 loss: 1.03558648e-06
Iter: 1120 loss: 1.02910235e-06
Iter: 1121 loss: 1.02811566e-06
Iter: 1122 loss: 1.03021785e-06
Iter: 1123 loss: 1.02772287e-06
Iter: 1124 loss: 1.0268468e-06
Iter: 1125 loss: 1.02803119e-06
Iter: 1126 loss: 1.02641627e-06
Iter: 1127 loss: 1.02563195e-06
Iter: 1128 loss: 1.03140121e-06
Iter: 1129 loss: 1.0255568e-06
Iter: 1130 loss: 1.02456659e-06
Iter: 1131 loss: 1.02627234e-06
Iter: 1132 loss: 1.02416072e-06
Iter: 1133 loss: 1.02346087e-06
Iter: 1134 loss: 1.02410422e-06
Iter: 1135 loss: 1.02299259e-06
Iter: 1136 loss: 1.02205411e-06
Iter: 1137 loss: 1.02574131e-06
Iter: 1138 loss: 1.02177751e-06
Iter: 1139 loss: 1.02084778e-06
Iter: 1140 loss: 1.02175784e-06
Iter: 1141 loss: 1.02031049e-06
Iter: 1142 loss: 1.01935393e-06
Iter: 1143 loss: 1.02174545e-06
Iter: 1144 loss: 1.01903743e-06
Iter: 1145 loss: 1.01794933e-06
Iter: 1146 loss: 1.02002127e-06
Iter: 1147 loss: 1.01747946e-06
Iter: 1148 loss: 1.01645469e-06
Iter: 1149 loss: 1.01977434e-06
Iter: 1150 loss: 1.01613807e-06
Iter: 1151 loss: 1.01534715e-06
Iter: 1152 loss: 1.0175122e-06
Iter: 1153 loss: 1.01505304e-06
Iter: 1154 loss: 1.0141049e-06
Iter: 1155 loss: 1.0172779e-06
Iter: 1156 loss: 1.01382614e-06
Iter: 1157 loss: 1.0127934e-06
Iter: 1158 loss: 1.01509818e-06
Iter: 1159 loss: 1.01237902e-06
Iter: 1160 loss: 1.01151159e-06
Iter: 1161 loss: 1.01778869e-06
Iter: 1162 loss: 1.01146475e-06
Iter: 1163 loss: 1.01069736e-06
Iter: 1164 loss: 1.01025717e-06
Iter: 1165 loss: 1.00996613e-06
Iter: 1166 loss: 1.009171e-06
Iter: 1167 loss: 1.01862656e-06
Iter: 1168 loss: 1.00918646e-06
Iter: 1169 loss: 1.00829288e-06
Iter: 1170 loss: 1.00810155e-06
Iter: 1171 loss: 1.00754323e-06
Iter: 1172 loss: 1.00674379e-06
Iter: 1173 loss: 1.00763521e-06
Iter: 1174 loss: 1.00629813e-06
Iter: 1175 loss: 1.00536658e-06
Iter: 1176 loss: 1.01509147e-06
Iter: 1177 loss: 1.00533612e-06
Iter: 1178 loss: 1.00469015e-06
Iter: 1179 loss: 1.00384568e-06
Iter: 1180 loss: 1.0037794e-06
Iter: 1181 loss: 1.0026472e-06
Iter: 1182 loss: 1.0069831e-06
Iter: 1183 loss: 1.00239663e-06
Iter: 1184 loss: 1.00141369e-06
Iter: 1185 loss: 1.00746456e-06
Iter: 1186 loss: 1.00136708e-06
Iter: 1187 loss: 1.00053023e-06
Iter: 1188 loss: 1.00040916e-06
Iter: 1189 loss: 9.99884378e-07
Iter: 1190 loss: 9.98701807e-07
Iter: 1191 loss: 1.00168802e-06
Iter: 1192 loss: 9.98291739e-07
Iter: 1193 loss: 9.97275e-07
Iter: 1194 loss: 1.00531656e-06
Iter: 1195 loss: 9.97282314e-07
Iter: 1196 loss: 9.96411245e-07
Iter: 1197 loss: 9.98200676e-07
Iter: 1198 loss: 9.96018912e-07
Iter: 1199 loss: 9.95252663e-07
Iter: 1200 loss: 9.98778205e-07
Iter: 1201 loss: 9.95077926e-07
Iter: 1202 loss: 9.94335778e-07
Iter: 1203 loss: 9.94629318e-07
Iter: 1204 loss: 9.93726644e-07
Iter: 1205 loss: 9.93026447e-07
Iter: 1206 loss: 1.00105683e-06
Iter: 1207 loss: 9.92950163e-07
Iter: 1208 loss: 9.923466e-07
Iter: 1209 loss: 9.94334e-07
Iter: 1210 loss: 9.92146283e-07
Iter: 1211 loss: 9.9152453e-07
Iter: 1212 loss: 9.90850594e-07
Iter: 1213 loss: 9.90785452e-07
Iter: 1214 loss: 9.89757e-07
Iter: 1215 loss: 9.97472739e-07
Iter: 1216 loss: 9.89704745e-07
Iter: 1217 loss: 9.8884675e-07
Iter: 1218 loss: 9.9133058e-07
Iter: 1219 loss: 9.88504326e-07
Iter: 1220 loss: 9.87814246e-07
Iter: 1221 loss: 9.87020371e-07
Iter: 1222 loss: 9.86917598e-07
Iter: 1223 loss: 9.85684551e-07
Iter: 1224 loss: 9.95679e-07
Iter: 1225 loss: 9.85609631e-07
Iter: 1226 loss: 9.84830422e-07
Iter: 1227 loss: 9.87152362e-07
Iter: 1228 loss: 9.84519943e-07
Iter: 1229 loss: 9.83644895e-07
Iter: 1230 loss: 9.86042096e-07
Iter: 1231 loss: 9.83398309e-07
Iter: 1232 loss: 9.82530651e-07
Iter: 1233 loss: 9.82931397e-07
Iter: 1234 loss: 9.81888434e-07
Iter: 1235 loss: 9.81317726e-07
Iter: 1236 loss: 9.81292715e-07
Iter: 1237 loss: 9.80732921e-07
Iter: 1238 loss: 9.79703373e-07
Iter: 1239 loss: 1.00218722e-06
Iter: 1240 loss: 9.79722699e-07
Iter: 1241 loss: 9.78595608e-07
Iter: 1242 loss: 9.90580702e-07
Iter: 1243 loss: 9.78591629e-07
Iter: 1244 loss: 9.77813215e-07
Iter: 1245 loss: 9.80059099e-07
Iter: 1246 loss: 9.77562195e-07
Iter: 1247 loss: 9.76745923e-07
Iter: 1248 loss: 9.80224286e-07
Iter: 1249 loss: 9.76604383e-07
Iter: 1250 loss: 9.75907483e-07
Iter: 1251 loss: 9.76134857e-07
Iter: 1252 loss: 9.7545535e-07
Iter: 1253 loss: 9.74667273e-07
Iter: 1254 loss: 9.74132263e-07
Iter: 1255 loss: 9.73881129e-07
Iter: 1256 loss: 9.7323e-07
Iter: 1257 loss: 9.73126589e-07
Iter: 1258 loss: 9.72555426e-07
Iter: 1259 loss: 9.71839881e-07
Iter: 1260 loss: 9.71759619e-07
Iter: 1261 loss: 9.70844212e-07
Iter: 1262 loss: 9.73824854e-07
Iter: 1263 loss: 9.70548854e-07
Iter: 1264 loss: 9.69732355e-07
Iter: 1265 loss: 9.70416863e-07
Iter: 1266 loss: 9.69289e-07
Iter: 1267 loss: 9.68300242e-07
Iter: 1268 loss: 9.77617219e-07
Iter: 1269 loss: 9.68258405e-07
Iter: 1270 loss: 9.67494316e-07
Iter: 1271 loss: 9.67355732e-07
Iter: 1272 loss: 9.6681606e-07
Iter: 1273 loss: 9.65892468e-07
Iter: 1274 loss: 9.71184363e-07
Iter: 1275 loss: 9.65760819e-07
Iter: 1276 loss: 9.6484564e-07
Iter: 1277 loss: 9.69785901e-07
Iter: 1278 loss: 9.64679657e-07
Iter: 1279 loss: 9.64051e-07
Iter: 1280 loss: 9.6393228e-07
Iter: 1281 loss: 9.63527782e-07
Iter: 1282 loss: 9.62621243e-07
Iter: 1283 loss: 9.73272904e-07
Iter: 1284 loss: 9.62617378e-07
Iter: 1285 loss: 9.62012109e-07
Iter: 1286 loss: 9.62204695e-07
Iter: 1287 loss: 9.61462774e-07
Iter: 1288 loss: 9.60718125e-07
Iter: 1289 loss: 9.62889771e-07
Iter: 1290 loss: 9.60445504e-07
Iter: 1291 loss: 9.59735871e-07
Iter: 1292 loss: 9.59884687e-07
Iter: 1293 loss: 9.59186082e-07
Iter: 1294 loss: 9.5821315e-07
Iter: 1295 loss: 9.63975253e-07
Iter: 1296 loss: 9.58085252e-07
Iter: 1297 loss: 9.57384e-07
Iter: 1298 loss: 9.61860451e-07
Iter: 1299 loss: 9.57308657e-07
Iter: 1300 loss: 9.56731128e-07
Iter: 1301 loss: 9.56226586e-07
Iter: 1302 loss: 9.5603059e-07
Iter: 1303 loss: 9.55098812e-07
Iter: 1304 loss: 9.55251835e-07
Iter: 1305 loss: 9.54401457e-07
Iter: 1306 loss: 9.53413917e-07
Iter: 1307 loss: 9.63284378e-07
Iter: 1308 loss: 9.53358494e-07
Iter: 1309 loss: 9.52635332e-07
Iter: 1310 loss: 9.55902919e-07
Iter: 1311 loss: 9.5249618e-07
Iter: 1312 loss: 9.51759489e-07
Iter: 1313 loss: 9.52005905e-07
Iter: 1314 loss: 9.51285415e-07
Iter: 1315 loss: 9.50331241e-07
Iter: 1316 loss: 9.55736368e-07
Iter: 1317 loss: 9.50170829e-07
Iter: 1318 loss: 9.49318348e-07
Iter: 1319 loss: 9.52117546e-07
Iter: 1320 loss: 9.49055902e-07
Iter: 1321 loss: 9.48431591e-07
Iter: 1322 loss: 9.50035883e-07
Iter: 1323 loss: 9.48176876e-07
Iter: 1324 loss: 9.47390845e-07
Iter: 1325 loss: 9.51547804e-07
Iter: 1326 loss: 9.47263288e-07
Iter: 1327 loss: 9.46742716e-07
Iter: 1328 loss: 9.46501132e-07
Iter: 1329 loss: 9.46283194e-07
Iter: 1330 loss: 9.4555395e-07
Iter: 1331 loss: 9.48106845e-07
Iter: 1332 loss: 9.45312081e-07
Iter: 1333 loss: 9.44440501e-07
Iter: 1334 loss: 9.46462819e-07
Iter: 1335 loss: 9.44158671e-07
Iter: 1336 loss: 9.4346e-07
Iter: 1337 loss: 9.48147544e-07
Iter: 1338 loss: 9.43392195e-07
Iter: 1339 loss: 9.42739348e-07
Iter: 1340 loss: 9.42509359e-07
Iter: 1341 loss: 9.4211407e-07
Iter: 1342 loss: 9.41329631e-07
Iter: 1343 loss: 9.42463771e-07
Iter: 1344 loss: 9.40879488e-07
Iter: 1345 loss: 9.39889389e-07
Iter: 1346 loss: 9.4132497e-07
Iter: 1347 loss: 9.39413212e-07
Iter: 1348 loss: 9.3840913e-07
Iter: 1349 loss: 9.43917769e-07
Iter: 1350 loss: 9.38277424e-07
Iter: 1351 loss: 9.37463597e-07
Iter: 1352 loss: 9.43391626e-07
Iter: 1353 loss: 9.37436e-07
Iter: 1354 loss: 9.36741515e-07
Iter: 1355 loss: 9.37075697e-07
Iter: 1356 loss: 9.3628779e-07
Iter: 1357 loss: 9.35483115e-07
Iter: 1358 loss: 9.41801261e-07
Iter: 1359 loss: 9.35437924e-07
Iter: 1360 loss: 9.34840045e-07
Iter: 1361 loss: 9.36244078e-07
Iter: 1362 loss: 9.34600052e-07
Iter: 1363 loss: 9.33969e-07
Iter: 1364 loss: 9.3606883e-07
Iter: 1365 loss: 9.33748254e-07
Iter: 1366 loss: 9.3304061e-07
Iter: 1367 loss: 9.33127e-07
Iter: 1368 loss: 9.32506623e-07
Iter: 1369 loss: 9.31674435e-07
Iter: 1370 loss: 9.32841431e-07
Iter: 1371 loss: 9.31299667e-07
Iter: 1372 loss: 9.30612487e-07
Iter: 1373 loss: 9.34972377e-07
Iter: 1374 loss: 9.30598958e-07
Iter: 1375 loss: 9.29883413e-07
Iter: 1376 loss: 9.3128574e-07
Iter: 1377 loss: 9.29615283e-07
Iter: 1378 loss: 9.28847896e-07
Iter: 1379 loss: 9.31232137e-07
Iter: 1380 loss: 9.28683562e-07
Iter: 1381 loss: 9.28125928e-07
Iter: 1382 loss: 9.29531211e-07
Iter: 1383 loss: 9.27921405e-07
Iter: 1384 loss: 9.2718858e-07
Iter: 1385 loss: 9.26222924e-07
Iter: 1386 loss: 9.26188818e-07
Iter: 1387 loss: 9.25084464e-07
Iter: 1388 loss: 9.31877594e-07
Iter: 1389 loss: 9.24950314e-07
Iter: 1390 loss: 9.24104711e-07
Iter: 1391 loss: 9.25828e-07
Iter: 1392 loss: 9.23721586e-07
Iter: 1393 loss: 9.22917e-07
Iter: 1394 loss: 9.33319029e-07
Iter: 1395 loss: 9.22928393e-07
Iter: 1396 loss: 9.22319941e-07
Iter: 1397 loss: 9.2350632e-07
Iter: 1398 loss: 9.22024697e-07
Iter: 1399 loss: 9.21370429e-07
Iter: 1400 loss: 9.22920321e-07
Iter: 1401 loss: 9.21165167e-07
Iter: 1402 loss: 9.20418927e-07
Iter: 1403 loss: 9.24604876e-07
Iter: 1404 loss: 9.2035441e-07
Iter: 1405 loss: 9.19865442e-07
Iter: 1406 loss: 9.21357469e-07
Iter: 1407 loss: 9.1967911e-07
Iter: 1408 loss: 9.19157287e-07
Iter: 1409 loss: 9.18259161e-07
Iter: 1410 loss: 9.18211072e-07
Iter: 1411 loss: 9.17411626e-07
Iter: 1412 loss: 9.23055666e-07
Iter: 1413 loss: 9.17327554e-07
Iter: 1414 loss: 9.16636168e-07
Iter: 1415 loss: 9.21010951e-07
Iter: 1416 loss: 9.16546526e-07
Iter: 1417 loss: 9.15857186e-07
Iter: 1418 loss: 9.15893054e-07
Iter: 1419 loss: 9.15310807e-07
Iter: 1420 loss: 9.14640054e-07
Iter: 1421 loss: 9.19357262e-07
Iter: 1422 loss: 9.14617829e-07
Iter: 1423 loss: 9.14026e-07
Iter: 1424 loss: 9.13606243e-07
Iter: 1425 loss: 9.13409e-07
Iter: 1426 loss: 9.12403948e-07
Iter: 1427 loss: 9.16123668e-07
Iter: 1428 loss: 9.12247e-07
Iter: 1429 loss: 9.11437837e-07
Iter: 1430 loss: 9.13542522e-07
Iter: 1431 loss: 9.11151574e-07
Iter: 1432 loss: 9.10423637e-07
Iter: 1433 loss: 9.12360235e-07
Iter: 1434 loss: 9.10142433e-07
Iter: 1435 loss: 9.09296205e-07
Iter: 1436 loss: 9.17014063e-07
Iter: 1437 loss: 9.0927773e-07
Iter: 1438 loss: 9.08700827e-07
Iter: 1439 loss: 9.09613448e-07
Iter: 1440 loss: 9.08509151e-07
Iter: 1441 loss: 9.07909566e-07
Iter: 1442 loss: 9.11124459e-07
Iter: 1443 loss: 9.07818333e-07
Iter: 1444 loss: 9.07360857e-07
Iter: 1445 loss: 9.07473122e-07
Iter: 1446 loss: 9.07032472e-07
Iter: 1447 loss: 9.06462901e-07
Iter: 1448 loss: 9.07469939e-07
Iter: 1449 loss: 9.06155492e-07
Iter: 1450 loss: 9.05416414e-07
Iter: 1451 loss: 9.0680021e-07
Iter: 1452 loss: 9.05086779e-07
Iter: 1453 loss: 9.04511808e-07
Iter: 1454 loss: 9.07286449e-07
Iter: 1455 loss: 9.04374417e-07
Iter: 1456 loss: 9.03718274e-07
Iter: 1457 loss: 9.05455295e-07
Iter: 1458 loss: 9.03451109e-07
Iter: 1459 loss: 9.02745455e-07
Iter: 1460 loss: 9.02648708e-07
Iter: 1461 loss: 9.02133252e-07
Iter: 1462 loss: 9.01364e-07
Iter: 1463 loss: 9.03647049e-07
Iter: 1464 loss: 9.01122689e-07
Iter: 1465 loss: 9.00279531e-07
Iter: 1466 loss: 9.03768353e-07
Iter: 1467 loss: 9.00131056e-07
Iter: 1468 loss: 8.99364181e-07
Iter: 1469 loss: 9.0206197e-07
Iter: 1470 loss: 8.9919314e-07
Iter: 1471 loss: 8.98557573e-07
Iter: 1472 loss: 8.98653752e-07
Iter: 1473 loss: 8.98098392e-07
Iter: 1474 loss: 8.97507562e-07
Iter: 1475 loss: 8.97492555e-07
Iter: 1476 loss: 8.96952429e-07
Iter: 1477 loss: 8.97061341e-07
Iter: 1478 loss: 8.96552194e-07
Iter: 1479 loss: 8.96026904e-07
Iter: 1480 loss: 9.00115424e-07
Iter: 1481 loss: 8.95979383e-07
Iter: 1482 loss: 8.95478934e-07
Iter: 1483 loss: 8.94675054e-07
Iter: 1484 loss: 8.94655159e-07
Iter: 1485 loss: 8.93806373e-07
Iter: 1486 loss: 8.98564679e-07
Iter: 1487 loss: 8.93657784e-07
Iter: 1488 loss: 8.93024946e-07
Iter: 1489 loss: 8.96904453e-07
Iter: 1490 loss: 8.9291359e-07
Iter: 1491 loss: 8.92296157e-07
Iter: 1492 loss: 8.93219635e-07
Iter: 1493 loss: 8.92033313e-07
Iter: 1494 loss: 8.91348463e-07
Iter: 1495 loss: 8.94442167e-07
Iter: 1496 loss: 8.91239097e-07
Iter: 1497 loss: 8.90629053e-07
Iter: 1498 loss: 8.90538047e-07
Iter: 1499 loss: 8.90076421e-07
Iter: 1500 loss: 8.89391686e-07
Iter: 1501 loss: 8.9115963e-07
Iter: 1502 loss: 8.89081946e-07
Iter: 1503 loss: 8.88301429e-07
Iter: 1504 loss: 8.89951366e-07
Iter: 1505 loss: 8.88001523e-07
Iter: 1506 loss: 8.87200372e-07
Iter: 1507 loss: 8.89350645e-07
Iter: 1508 loss: 8.86979706e-07
Iter: 1509 loss: 8.86217435e-07
Iter: 1510 loss: 8.91618413e-07
Iter: 1511 loss: 8.86097496e-07
Iter: 1512 loss: 8.85508598e-07
Iter: 1513 loss: 8.86569524e-07
Iter: 1514 loss: 8.85306804e-07
Iter: 1515 loss: 8.84715291e-07
Iter: 1516 loss: 8.90967328e-07
Iter: 1517 loss: 8.84692383e-07
Iter: 1518 loss: 8.84221151e-07
Iter: 1519 loss: 8.84090298e-07
Iter: 1520 loss: 8.83779364e-07
Iter: 1521 loss: 8.83300686e-07
Iter: 1522 loss: 8.87876809e-07
Iter: 1523 loss: 8.83244638e-07
Iter: 1524 loss: 8.82743507e-07
Iter: 1525 loss: 8.82192694e-07
Iter: 1526 loss: 8.82108338e-07
Iter: 1527 loss: 8.81413939e-07
Iter: 1528 loss: 8.84028282e-07
Iter: 1529 loss: 8.81228118e-07
Iter: 1530 loss: 8.80563107e-07
Iter: 1531 loss: 8.84489907e-07
Iter: 1532 loss: 8.80481934e-07
Iter: 1533 loss: 8.79789809e-07
Iter: 1534 loss: 8.80929804e-07
Iter: 1535 loss: 8.79510708e-07
Iter: 1536 loss: 8.78889409e-07
Iter: 1537 loss: 8.79259971e-07
Iter: 1538 loss: 8.78465926e-07
Iter: 1539 loss: 8.77707691e-07
Iter: 1540 loss: 8.82828147e-07
Iter: 1541 loss: 8.77608727e-07
Iter: 1542 loss: 8.77079174e-07
Iter: 1543 loss: 8.76846855e-07
Iter: 1544 loss: 8.76536092e-07
Iter: 1545 loss: 8.75769388e-07
Iter: 1546 loss: 8.7816818e-07
Iter: 1547 loss: 8.75574756e-07
Iter: 1548 loss: 8.74781733e-07
Iter: 1549 loss: 8.78482069e-07
Iter: 1550 loss: 8.74649231e-07
Iter: 1551 loss: 8.73976774e-07
Iter: 1552 loss: 8.79229731e-07
Iter: 1553 loss: 8.73915212e-07
Iter: 1554 loss: 8.73378724e-07
Iter: 1555 loss: 8.75498927e-07
Iter: 1556 loss: 8.733291e-07
Iter: 1557 loss: 8.72875717e-07
Iter: 1558 loss: 8.72673922e-07
Iter: 1559 loss: 8.7242887e-07
Iter: 1560 loss: 8.71906593e-07
Iter: 1561 loss: 8.76520801e-07
Iter: 1562 loss: 8.7185316e-07
Iter: 1563 loss: 8.7142763e-07
Iter: 1564 loss: 8.71548366e-07
Iter: 1565 loss: 8.71154043e-07
Iter: 1566 loss: 8.7046152e-07
Iter: 1567 loss: 8.70462713e-07
Iter: 1568 loss: 8.69974201e-07
Iter: 1569 loss: 8.69267183e-07
Iter: 1570 loss: 8.75631599e-07
Iter: 1571 loss: 8.69232622e-07
Iter: 1572 loss: 8.6858023e-07
Iter: 1573 loss: 8.69645874e-07
Iter: 1574 loss: 8.68247525e-07
Iter: 1575 loss: 8.67703761e-07
Iter: 1576 loss: 8.68491156e-07
Iter: 1577 loss: 8.67383221e-07
Iter: 1578 loss: 8.66779601e-07
Iter: 1579 loss: 8.69533778e-07
Iter: 1580 loss: 8.66658183e-07
Iter: 1581 loss: 8.66041887e-07
Iter: 1582 loss: 8.66495668e-07
Iter: 1583 loss: 8.65713105e-07
Iter: 1584 loss: 8.64961294e-07
Iter: 1585 loss: 8.67110771e-07
Iter: 1586 loss: 8.64734261e-07
Iter: 1587 loss: 8.64134392e-07
Iter: 1588 loss: 8.6546072e-07
Iter: 1589 loss: 8.6384739e-07
Iter: 1590 loss: 8.63383093e-07
Iter: 1591 loss: 8.63384287e-07
Iter: 1592 loss: 8.63015828e-07
Iter: 1593 loss: 8.62502816e-07
Iter: 1594 loss: 8.62469619e-07
Iter: 1595 loss: 8.61816773e-07
Iter: 1596 loss: 8.65204697e-07
Iter: 1597 loss: 8.61724914e-07
Iter: 1598 loss: 8.61157957e-07
Iter: 1599 loss: 8.63107402e-07
Iter: 1600 loss: 8.61060471e-07
Iter: 1601 loss: 8.60513296e-07
Iter: 1602 loss: 8.60896478e-07
Iter: 1603 loss: 8.60204921e-07
Iter: 1604 loss: 8.59539341e-07
Iter: 1605 loss: 8.61995943e-07
Iter: 1606 loss: 8.59358352e-07
Iter: 1607 loss: 8.58932651e-07
Iter: 1608 loss: 8.59100396e-07
Iter: 1609 loss: 8.58550777e-07
Iter: 1610 loss: 8.58017188e-07
Iter: 1611 loss: 8.66223445e-07
Iter: 1612 loss: 8.58012413e-07
Iter: 1613 loss: 8.57617636e-07
Iter: 1614 loss: 8.57056534e-07
Iter: 1615 loss: 8.57031637e-07
Iter: 1616 loss: 8.56298698e-07
Iter: 1617 loss: 8.57671353e-07
Iter: 1618 loss: 8.56005272e-07
Iter: 1619 loss: 8.55215319e-07
Iter: 1620 loss: 8.59381032e-07
Iter: 1621 loss: 8.55166149e-07
Iter: 1622 loss: 8.54519271e-07
Iter: 1623 loss: 8.57712621e-07
Iter: 1624 loss: 8.5440854e-07
Iter: 1625 loss: 8.53938218e-07
Iter: 1626 loss: 8.53593349e-07
Iter: 1627 loss: 8.53451752e-07
Iter: 1628 loss: 8.52809762e-07
Iter: 1629 loss: 8.52834e-07
Iter: 1630 loss: 8.52434312e-07
Iter: 1631 loss: 8.52047322e-07
Iter: 1632 loss: 8.51927723e-07
Iter: 1633 loss: 8.51362529e-07
Iter: 1634 loss: 8.53053734e-07
Iter: 1635 loss: 8.51168693e-07
Iter: 1636 loss: 8.5047634e-07
Iter: 1637 loss: 8.52882522e-07
Iter: 1638 loss: 8.50319338e-07
Iter: 1639 loss: 8.4973442e-07
Iter: 1640 loss: 8.50101742e-07
Iter: 1641 loss: 8.49404728e-07
Iter: 1642 loss: 8.48819e-07
Iter: 1643 loss: 8.52161804e-07
Iter: 1644 loss: 8.48745913e-07
Iter: 1645 loss: 8.48137915e-07
Iter: 1646 loss: 8.48707828e-07
Iter: 1647 loss: 8.47853926e-07
Iter: 1648 loss: 8.47287197e-07
Iter: 1649 loss: 8.530576e-07
Iter: 1650 loss: 8.47304136e-07
Iter: 1651 loss: 8.46862577e-07
Iter: 1652 loss: 8.46493549e-07
Iter: 1653 loss: 8.46377645e-07
Iter: 1654 loss: 8.45717921e-07
Iter: 1655 loss: 8.46712965e-07
Iter: 1656 loss: 8.4537e-07
Iter: 1657 loss: 8.44752662e-07
Iter: 1658 loss: 8.47886554e-07
Iter: 1659 loss: 8.44647332e-07
Iter: 1660 loss: 8.43911153e-07
Iter: 1661 loss: 8.45740374e-07
Iter: 1662 loss: 8.43765406e-07
Iter: 1663 loss: 8.43152804e-07
Iter: 1664 loss: 8.48564184e-07
Iter: 1665 loss: 8.43170596e-07
Iter: 1666 loss: 8.4264434e-07
Iter: 1667 loss: 8.4425244e-07
Iter: 1668 loss: 8.42550094e-07
Iter: 1669 loss: 8.42155032e-07
Iter: 1670 loss: 8.4191015e-07
Iter: 1671 loss: 8.41733424e-07
Iter: 1672 loss: 8.41211715e-07
Iter: 1673 loss: 8.42409406e-07
Iter: 1674 loss: 8.40990822e-07
Iter: 1675 loss: 8.40354801e-07
Iter: 1676 loss: 8.45237423e-07
Iter: 1677 loss: 8.4031069e-07
Iter: 1678 loss: 8.39836957e-07
Iter: 1679 loss: 8.39534323e-07
Iter: 1680 loss: 8.39428651e-07
Iter: 1681 loss: 8.38751362e-07
Iter: 1682 loss: 8.40821713e-07
Iter: 1683 loss: 8.38560709e-07
Iter: 1684 loss: 8.37888649e-07
Iter: 1685 loss: 8.43666612e-07
Iter: 1686 loss: 8.379e-07
Iter: 1687 loss: 8.37455104e-07
Iter: 1688 loss: 8.37434868e-07
Iter: 1689 loss: 8.3707323e-07
Iter: 1690 loss: 8.36349784e-07
Iter: 1691 loss: 8.39023642e-07
Iter: 1692 loss: 8.36211029e-07
Iter: 1693 loss: 8.3569563e-07
Iter: 1694 loss: 8.36523441e-07
Iter: 1695 loss: 8.3541795e-07
Iter: 1696 loss: 8.34760385e-07
Iter: 1697 loss: 8.35087917e-07
Iter: 1698 loss: 8.34284606e-07
Iter: 1699 loss: 8.33863282e-07
Iter: 1700 loss: 8.33856859e-07
Iter: 1701 loss: 8.3329e-07
Iter: 1702 loss: 8.3339205e-07
Iter: 1703 loss: 8.32912463e-07
Iter: 1704 loss: 8.32385581e-07
Iter: 1705 loss: 8.35571484e-07
Iter: 1706 loss: 8.3225973e-07
Iter: 1707 loss: 8.31928162e-07
Iter: 1708 loss: 8.31639795e-07
Iter: 1709 loss: 8.31483931e-07
Iter: 1710 loss: 8.30807039e-07
Iter: 1711 loss: 8.33472768e-07
Iter: 1712 loss: 8.30685849e-07
Iter: 1713 loss: 8.29917042e-07
Iter: 1714 loss: 8.33103854e-07
Iter: 1715 loss: 8.29814212e-07
Iter: 1716 loss: 8.29308874e-07
Iter: 1717 loss: 8.29133342e-07
Iter: 1718 loss: 8.28778241e-07
Iter: 1719 loss: 8.28176553e-07
Iter: 1720 loss: 8.33098e-07
Iter: 1721 loss: 8.28157226e-07
Iter: 1722 loss: 8.27576685e-07
Iter: 1723 loss: 8.30295676e-07
Iter: 1724 loss: 8.27475446e-07
Iter: 1725 loss: 8.27120516e-07
Iter: 1726 loss: 8.26771611e-07
Iter: 1727 loss: 8.26674864e-07
Iter: 1728 loss: 8.26047e-07
Iter: 1729 loss: 8.30682e-07
Iter: 1730 loss: 8.25997063e-07
Iter: 1731 loss: 8.25481152e-07
Iter: 1732 loss: 8.25763266e-07
Iter: 1733 loss: 8.25172378e-07
Iter: 1734 loss: 8.24536698e-07
Iter: 1735 loss: 8.26128371e-07
Iter: 1736 loss: 8.24334847e-07
Iter: 1737 loss: 8.23802964e-07
Iter: 1738 loss: 8.23784774e-07
Iter: 1739 loss: 8.23510845e-07
Iter: 1740 loss: 8.23119422e-07
Iter: 1741 loss: 8.23102141e-07
Iter: 1742 loss: 8.22448669e-07
Iter: 1743 loss: 8.22900745e-07
Iter: 1744 loss: 8.22060656e-07
Iter: 1745 loss: 8.21295203e-07
Iter: 1746 loss: 8.27293547e-07
Iter: 1747 loss: 8.21274853e-07
Iter: 1748 loss: 8.20895821e-07
Iter: 1749 loss: 8.22004381e-07
Iter: 1750 loss: 8.20700166e-07
Iter: 1751 loss: 8.20185448e-07
Iter: 1752 loss: 8.20717162e-07
Iter: 1753 loss: 8.19961542e-07
Iter: 1754 loss: 8.19358434e-07
Iter: 1755 loss: 8.20015771e-07
Iter: 1756 loss: 8.19040451e-07
Iter: 1757 loss: 8.18553644e-07
Iter: 1758 loss: 8.24241909e-07
Iter: 1759 loss: 8.18556032e-07
Iter: 1760 loss: 8.18218439e-07
Iter: 1761 loss: 8.1858127e-07
Iter: 1762 loss: 8.17938485e-07
Iter: 1763 loss: 8.1743292e-07
Iter: 1764 loss: 8.17553314e-07
Iter: 1765 loss: 8.17070656e-07
Iter: 1766 loss: 8.1652604e-07
Iter: 1767 loss: 8.17905629e-07
Iter: 1768 loss: 8.16297074e-07
Iter: 1769 loss: 8.157e-07
Iter: 1770 loss: 8.186488e-07
Iter: 1771 loss: 8.15600515e-07
Iter: 1772 loss: 8.15016563e-07
Iter: 1773 loss: 8.1755536e-07
Iter: 1774 loss: 8.1496e-07
Iter: 1775 loss: 8.14369514e-07
Iter: 1776 loss: 8.1632794e-07
Iter: 1777 loss: 8.14277769e-07
Iter: 1778 loss: 8.13903966e-07
Iter: 1779 loss: 8.13553527e-07
Iter: 1780 loss: 8.13453084e-07
Iter: 1781 loss: 8.12881581e-07
Iter: 1782 loss: 8.14641e-07
Iter: 1783 loss: 8.1272708e-07
Iter: 1784 loss: 8.12150233e-07
Iter: 1785 loss: 8.15893941e-07
Iter: 1786 loss: 8.12110216e-07
Iter: 1787 loss: 8.11553377e-07
Iter: 1788 loss: 8.11423774e-07
Iter: 1789 loss: 8.11115456e-07
Iter: 1790 loss: 8.10583e-07
Iter: 1791 loss: 8.17907278e-07
Iter: 1792 loss: 8.10566235e-07
Iter: 1793 loss: 8.10206416e-07
Iter: 1794 loss: 8.09789185e-07
Iter: 1795 loss: 8.09744904e-07
Iter: 1796 loss: 8.0921825e-07
Iter: 1797 loss: 8.15163162e-07
Iter: 1798 loss: 8.09216658e-07
Iter: 1799 loss: 8.08690174e-07
Iter: 1800 loss: 8.09364e-07
Iter: 1801 loss: 8.08495599e-07
Iter: 1802 loss: 8.07915e-07
Iter: 1803 loss: 8.08071604e-07
Iter: 1804 loss: 8.07543699e-07
Iter: 1805 loss: 8.06896594e-07
Iter: 1806 loss: 8.07717811e-07
Iter: 1807 loss: 8.06567584e-07
Iter: 1808 loss: 8.06009211e-07
Iter: 1809 loss: 8.14505654e-07
Iter: 1810 loss: 8.05992045e-07
Iter: 1811 loss: 8.05563559e-07
Iter: 1812 loss: 8.06926607e-07
Iter: 1813 loss: 8.05380466e-07
Iter: 1814 loss: 8.04994841e-07
Iter: 1815 loss: 8.05794343e-07
Iter: 1816 loss: 8.04750471e-07
Iter: 1817 loss: 8.04300953e-07
Iter: 1818 loss: 8.04079946e-07
Iter: 1819 loss: 8.0386144e-07
Iter: 1820 loss: 8.03218143e-07
Iter: 1821 loss: 8.05605112e-07
Iter: 1822 loss: 8.03092348e-07
Iter: 1823 loss: 8.02549948e-07
Iter: 1824 loss: 8.07776132e-07
Iter: 1825 loss: 8.02579052e-07
Iter: 1826 loss: 8.02104523e-07
Iter: 1827 loss: 8.02323086e-07
Iter: 1828 loss: 8.01835654e-07
Iter: 1829 loss: 8.01389035e-07
Iter: 1830 loss: 8.02899251e-07
Iter: 1831 loss: 8.01273245e-07
Iter: 1832 loss: 8.00739e-07
Iter: 1833 loss: 8.01723104e-07
Iter: 1834 loss: 8.00471184e-07
Iter: 1835 loss: 8.00022804e-07
Iter: 1836 loss: 8.01235103e-07
Iter: 1837 loss: 7.9985e-07
Iter: 1838 loss: 7.99198688e-07
Iter: 1839 loss: 8.0265886e-07
Iter: 1840 loss: 7.99179361e-07
Iter: 1841 loss: 7.98725409e-07
Iter: 1842 loss: 7.98331484e-07
Iter: 1843 loss: 7.98204724e-07
Iter: 1844 loss: 7.97542157e-07
Iter: 1845 loss: 7.98946928e-07
Iter: 1846 loss: 7.97253392e-07
Iter: 1847 loss: 7.96711788e-07
Iter: 1848 loss: 7.96755103e-07
Iter: 1849 loss: 7.96317295e-07
Iter: 1850 loss: 7.97660277e-07
Iter: 1851 loss: 7.96204574e-07
Iter: 1852 loss: 7.95827475e-07
Iter: 1853 loss: 7.95291498e-07
Iter: 1854 loss: 7.95302128e-07
Iter: 1855 loss: 7.94672133e-07
Iter: 1856 loss: 8.0163727e-07
Iter: 1857 loss: 7.94619325e-07
Iter: 1858 loss: 7.94224661e-07
Iter: 1859 loss: 7.94398773e-07
Iter: 1860 loss: 7.93941297e-07
Iter: 1861 loss: 7.93482343e-07
Iter: 1862 loss: 7.96561494e-07
Iter: 1863 loss: 7.93439597e-07
Iter: 1864 loss: 7.92957167e-07
Iter: 1865 loss: 7.93423339e-07
Iter: 1866 loss: 7.92681419e-07
Iter: 1867 loss: 7.92140213e-07
Iter: 1868 loss: 7.92637934e-07
Iter: 1869 loss: 7.91839682e-07
Iter: 1870 loss: 7.91236403e-07
Iter: 1871 loss: 7.95029337e-07
Iter: 1872 loss: 7.91195589e-07
Iter: 1873 loss: 7.90662796e-07
Iter: 1874 loss: 7.92295737e-07
Iter: 1875 loss: 7.90549393e-07
Iter: 1876 loss: 7.90012734e-07
Iter: 1877 loss: 7.90894205e-07
Iter: 1878 loss: 7.89807473e-07
Iter: 1879 loss: 7.89223691e-07
Iter: 1880 loss: 7.90281661e-07
Iter: 1881 loss: 7.89003707e-07
Iter: 1882 loss: 7.8846864e-07
Iter: 1883 loss: 7.89208684e-07
Iter: 1884 loss: 7.8819113e-07
Iter: 1885 loss: 7.87880879e-07
Iter: 1886 loss: 7.87877752e-07
Iter: 1887 loss: 7.87519411e-07
Iter: 1888 loss: 7.87186536e-07
Iter: 1889 loss: 7.8708257e-07
Iter: 1890 loss: 7.86563874e-07
Iter: 1891 loss: 7.86444787e-07
Iter: 1892 loss: 7.86134365e-07
Iter: 1893 loss: 7.85556381e-07
Iter: 1894 loss: 7.91387265e-07
Iter: 1895 loss: 7.85531597e-07
Iter: 1896 loss: 7.85107716e-07
Iter: 1897 loss: 7.85857537e-07
Iter: 1898 loss: 7.84844815e-07
Iter: 1899 loss: 7.84265808e-07
Iter: 1900 loss: 7.85670409e-07
Iter: 1901 loss: 7.8410244e-07
Iter: 1902 loss: 7.83618475e-07
Iter: 1903 loss: 7.88124794e-07
Iter: 1904 loss: 7.83592e-07
Iter: 1905 loss: 7.83240125e-07
Iter: 1906 loss: 7.82963468e-07
Iter: 1907 loss: 7.82845632e-07
Iter: 1908 loss: 7.82325174e-07
Iter: 1909 loss: 7.84614826e-07
Iter: 1910 loss: 7.8225321e-07
Iter: 1911 loss: 7.81746166e-07
Iter: 1912 loss: 7.85488965e-07
Iter: 1913 loss: 7.81736617e-07
Iter: 1914 loss: 7.81382823e-07
Iter: 1915 loss: 7.81152835e-07
Iter: 1916 loss: 7.80998789e-07
Iter: 1917 loss: 7.80439905e-07
Iter: 1918 loss: 7.83426231e-07
Iter: 1919 loss: 7.80326559e-07
Iter: 1920 loss: 7.79748461e-07
Iter: 1921 loss: 7.79857146e-07
Iter: 1922 loss: 7.79387847e-07
Iter: 1923 loss: 7.78987896e-07
Iter: 1924 loss: 7.7897505e-07
Iter: 1925 loss: 7.78576123e-07
Iter: 1926 loss: 7.78269339e-07
Iter: 1927 loss: 7.78153492e-07
Iter: 1928 loss: 7.77731e-07
Iter: 1929 loss: 7.77936179e-07
Iter: 1930 loss: 7.77441471e-07
Iter: 1931 loss: 7.76800334e-07
Iter: 1932 loss: 7.78689241e-07
Iter: 1933 loss: 7.76583761e-07
Iter: 1934 loss: 7.76190177e-07
Iter: 1935 loss: 7.81624294e-07
Iter: 1936 loss: 7.76183242e-07
Iter: 1937 loss: 7.75823196e-07
Iter: 1938 loss: 7.75650278e-07
Iter: 1939 loss: 7.7545883e-07
Iter: 1940 loss: 7.74910404e-07
Iter: 1941 loss: 7.79319578e-07
Iter: 1942 loss: 7.7490472e-07
Iter: 1943 loss: 7.74505111e-07
Iter: 1944 loss: 7.74645287e-07
Iter: 1945 loss: 7.74227658e-07
Iter: 1946 loss: 7.7375023e-07
Iter: 1947 loss: 7.74955e-07
Iter: 1948 loss: 7.73520924e-07
Iter: 1949 loss: 7.73055945e-07
Iter: 1950 loss: 7.76385946e-07
Iter: 1951 loss: 7.73021611e-07
Iter: 1952 loss: 7.72591306e-07
Iter: 1953 loss: 7.72673445e-07
Iter: 1954 loss: 7.72328292e-07
Iter: 1955 loss: 7.71817895e-07
Iter: 1956 loss: 7.73489774e-07
Iter: 1957 loss: 7.71687837e-07
Iter: 1958 loss: 7.71262421e-07
Iter: 1959 loss: 7.73799684e-07
Iter: 1960 loss: 7.71197847e-07
Iter: 1961 loss: 7.70784254e-07
Iter: 1962 loss: 7.7254316e-07
Iter: 1963 loss: 7.70690917e-07
Iter: 1964 loss: 7.70342695e-07
Iter: 1965 loss: 7.70535053e-07
Iter: 1966 loss: 7.70075701e-07
Iter: 1967 loss: 7.69731287e-07
Iter: 1968 loss: 7.69460939e-07
Iter: 1969 loss: 7.69300527e-07
Iter: 1970 loss: 7.68686e-07
Iter: 1971 loss: 7.70798238e-07
Iter: 1972 loss: 7.68515861e-07
Iter: 1973 loss: 7.67934239e-07
Iter: 1974 loss: 7.71900091e-07
Iter: 1975 loss: 7.67821689e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.4
+ date
Sat Nov  7 15:31:39 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.4/500_500_500_500_1 ']'
+ for npairs in 8000
+ OUTDIR2=/home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2.4_8000
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2.4_8000
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2.4_8000/500_500_500_500_1 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 8000 --load_model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.4/500_500_500_500_1 --optimizer lbfgs --function f2 --psi 2 --alpha 2.4 --layers 500_500_500_500_1 --save_dir /home/mrdouglas/Manifold/experiments.final/output69/f2_psi2_phi2.4_8000/ --save_name 500_500_500_500_1 --max_epochs 2000 --loss_func weighted_MSE
Processing model: 500_500_500_500_1
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d324a76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d324a7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32398510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32397400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32397d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d323b2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d323b2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d322e02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d322e00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32294598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32294d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32294840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d322b9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d3227d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32235d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d322357b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d321b0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d321e6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d32149598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d321490d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d3210b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d3210b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d320f0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d320f0400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d186db8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d18694730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d186be268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d186beb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d1865b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d1866dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d1863fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d185d2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d185d28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d320f02f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d185b6bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5d185cba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 3.15183315e-05
Iter: 2 loss: 2.82653236e-05
Iter: 3 loss: 2.79154483e-05
Iter: 4 loss: 2.5547939e-05
Iter: 5 loss: 2.25948897e-05
Iter: 6 loss: 3.29756367e-05
Iter: 7 loss: 2.18226432e-05
Iter: 8 loss: 1.91309773e-05
Iter: 9 loss: 2.22068065e-05
Iter: 10 loss: 1.77040238e-05
Iter: 11 loss: 1.55366979e-05
Iter: 12 loss: 3.09459028e-05
Iter: 13 loss: 1.53415804e-05
Iter: 14 loss: 1.4142227e-05
Iter: 15 loss: 1.80269981e-05
Iter: 16 loss: 1.38046562e-05
Iter: 17 loss: 1.27834701e-05
Iter: 18 loss: 1.52237499e-05
Iter: 19 loss: 1.24139069e-05
Iter: 20 loss: 1.15076245e-05
Iter: 21 loss: 1.21718604e-05
Iter: 22 loss: 1.09495122e-05
Iter: 23 loss: 9.94911534e-06
Iter: 24 loss: 1.60623058e-05
Iter: 25 loss: 9.82738675e-06
Iter: 26 loss: 9.1072543e-06
Iter: 27 loss: 1.42588196e-05
Iter: 28 loss: 9.0441572e-06
Iter: 29 loss: 8.57373107e-06
Iter: 30 loss: 8.91889795e-06
Iter: 31 loss: 8.28433622e-06
Iter: 32 loss: 7.73545071e-06
Iter: 33 loss: 1.03706e-05
Iter: 34 loss: 7.63727076e-06
Iter: 35 loss: 7.2707744e-06
Iter: 36 loss: 7.86603e-06
Iter: 37 loss: 7.10229324e-06
Iter: 38 loss: 6.72045326e-06
Iter: 39 loss: 7.13753298e-06
Iter: 40 loss: 6.51230948e-06
Iter: 41 loss: 6.1810224e-06
Iter: 42 loss: 1.01733031e-05
Iter: 43 loss: 6.17708429e-06
Iter: 44 loss: 6.02161845e-06
Iter: 45 loss: 6.0216762e-06
Iter: 46 loss: 5.87450131e-06
Iter: 47 loss: 5.64292441e-06
Iter: 48 loss: 5.64023958e-06
Iter: 49 loss: 5.42330508e-06
Iter: 50 loss: 6.98902568e-06
Iter: 51 loss: 5.40500878e-06
Iter: 52 loss: 5.24903589e-06
Iter: 53 loss: 6.15255203e-06
Iter: 54 loss: 5.22801e-06
Iter: 55 loss: 5.09926076e-06
Iter: 56 loss: 5.05782191e-06
Iter: 57 loss: 4.98251e-06
Iter: 58 loss: 4.82562382e-06
Iter: 59 loss: 5.55520728e-06
Iter: 60 loss: 4.79643495e-06
Iter: 61 loss: 4.66173e-06
Iter: 62 loss: 5.2664027e-06
Iter: 63 loss: 4.63537708e-06
Iter: 64 loss: 4.52025779e-06
Iter: 65 loss: 4.6657633e-06
Iter: 66 loss: 4.46059585e-06
Iter: 67 loss: 4.34069307e-06
Iter: 68 loss: 5.23055587e-06
Iter: 69 loss: 4.33088098e-06
Iter: 70 loss: 4.23641313e-06
Iter: 71 loss: 4.28561862e-06
Iter: 72 loss: 4.17368619e-06
Iter: 73 loss: 4.07297648e-06
Iter: 74 loss: 4.28717249e-06
Iter: 75 loss: 4.03322e-06
Iter: 76 loss: 3.93290202e-06
Iter: 77 loss: 4.16975035e-06
Iter: 78 loss: 3.89608977e-06
Iter: 79 loss: 3.79066296e-06
Iter: 80 loss: 4.50062726e-06
Iter: 81 loss: 3.78010645e-06
Iter: 82 loss: 3.7149473e-06
Iter: 83 loss: 4.23452047e-06
Iter: 84 loss: 3.7105151e-06
Iter: 85 loss: 3.64559514e-06
Iter: 86 loss: 3.71229817e-06
Iter: 87 loss: 3.60936178e-06
Iter: 88 loss: 3.55124621e-06
Iter: 89 loss: 3.54451959e-06
Iter: 90 loss: 3.5027731e-06
Iter: 91 loss: 3.44337013e-06
Iter: 92 loss: 4.03274908e-06
Iter: 93 loss: 3.44148839e-06
Iter: 94 loss: 3.38802488e-06
Iter: 95 loss: 3.53213773e-06
Iter: 96 loss: 3.370375e-06
Iter: 97 loss: 3.33137586e-06
Iter: 98 loss: 3.26476038e-06
Iter: 99 loss: 3.26478039e-06
Iter: 100 loss: 3.20694971e-06
Iter: 101 loss: 3.2062128e-06
Iter: 102 loss: 3.15901934e-06
Iter: 103 loss: 3.22626238e-06
Iter: 104 loss: 3.13586543e-06
Iter: 105 loss: 3.08543667e-06
Iter: 106 loss: 3.22575534e-06
Iter: 107 loss: 3.06905076e-06
Iter: 108 loss: 3.02116814e-06
Iter: 109 loss: 3.22414326e-06
Iter: 110 loss: 3.0109386e-06
Iter: 111 loss: 2.97334691e-06
Iter: 112 loss: 3.0268211e-06
Iter: 113 loss: 2.95482232e-06
Iter: 114 loss: 2.91493666e-06
Iter: 115 loss: 2.92779555e-06
Iter: 116 loss: 2.8864747e-06
Iter: 117 loss: 2.85523174e-06
Iter: 118 loss: 2.85499573e-06
Iter: 119 loss: 2.82435076e-06
Iter: 120 loss: 2.9035748e-06
Iter: 121 loss: 2.81396706e-06
Iter: 122 loss: 2.78645712e-06
Iter: 123 loss: 2.8251925e-06
Iter: 124 loss: 2.77279e-06
Iter: 125 loss: 2.74494869e-06
Iter: 126 loss: 2.77660524e-06
Iter: 127 loss: 2.72991247e-06
Iter: 128 loss: 2.70185251e-06
Iter: 129 loss: 2.79515962e-06
Iter: 130 loss: 2.69409702e-06
Iter: 131 loss: 2.66188181e-06
Iter: 132 loss: 2.82982819e-06
Iter: 133 loss: 2.65677409e-06
Iter: 134 loss: 2.63644051e-06
Iter: 135 loss: 2.61785453e-06
Iter: 136 loss: 2.61280957e-06
Iter: 137 loss: 2.58094201e-06
Iter: 138 loss: 2.75101115e-06
Iter: 139 loss: 2.57614442e-06
Iter: 140 loss: 2.5495774e-06
Iter: 141 loss: 2.67678979e-06
Iter: 142 loss: 2.54484326e-06
Iter: 143 loss: 2.52154723e-06
Iter: 144 loss: 2.63543689e-06
Iter: 145 loss: 2.517251e-06
Iter: 146 loss: 2.50035146e-06
Iter: 147 loss: 2.48809738e-06
Iter: 148 loss: 2.48230344e-06
Iter: 149 loss: 2.45922752e-06
Iter: 150 loss: 2.71951e-06
Iter: 151 loss: 2.45877141e-06
Iter: 152 loss: 2.44107878e-06
Iter: 153 loss: 2.43196155e-06
Iter: 154 loss: 2.42375563e-06
Iter: 155 loss: 2.40334725e-06
Iter: 156 loss: 2.56751605e-06
Iter: 157 loss: 2.40196869e-06
Iter: 158 loss: 2.37799554e-06
Iter: 159 loss: 2.43613067e-06
Iter: 160 loss: 2.36943424e-06
Iter: 161 loss: 2.35541847e-06
Iter: 162 loss: 2.35706329e-06
Iter: 163 loss: 2.34466279e-06
Iter: 164 loss: 2.32716752e-06
Iter: 165 loss: 2.38576558e-06
Iter: 166 loss: 2.32236e-06
Iter: 167 loss: 2.30168644e-06
Iter: 168 loss: 2.35697371e-06
Iter: 169 loss: 2.29497959e-06
Iter: 170 loss: 2.27909e-06
Iter: 171 loss: 2.40557392e-06
Iter: 172 loss: 2.27799092e-06
Iter: 173 loss: 2.26529323e-06
Iter: 174 loss: 2.25689132e-06
Iter: 175 loss: 2.2518218e-06
Iter: 176 loss: 2.23441953e-06
Iter: 177 loss: 2.25607846e-06
Iter: 178 loss: 2.22545805e-06
Iter: 179 loss: 2.20662832e-06
Iter: 180 loss: 2.38935195e-06
Iter: 181 loss: 2.20599804e-06
Iter: 182 loss: 2.19206731e-06
Iter: 183 loss: 2.24968448e-06
Iter: 184 loss: 2.1891733e-06
Iter: 185 loss: 2.17625211e-06
Iter: 186 loss: 2.16744093e-06
Iter: 187 loss: 2.1627518e-06
Iter: 188 loss: 2.14708734e-06
Iter: 189 loss: 2.26643442e-06
Iter: 190 loss: 2.14587521e-06
Iter: 191 loss: 2.13246312e-06
Iter: 192 loss: 2.16586068e-06
Iter: 193 loss: 2.12764257e-06
Iter: 194 loss: 2.1167466e-06
Iter: 195 loss: 2.23425377e-06
Iter: 196 loss: 2.11636234e-06
Iter: 197 loss: 2.10732787e-06
Iter: 198 loss: 2.12049304e-06
Iter: 199 loss: 2.10287908e-06
Iter: 200 loss: 2.09275868e-06
Iter: 201 loss: 2.08759297e-06
Iter: 202 loss: 2.08295251e-06
Iter: 203 loss: 2.06942946e-06
Iter: 204 loss: 2.08891652e-06
Iter: 205 loss: 2.06267532e-06
Iter: 206 loss: 2.04969683e-06
Iter: 207 loss: 2.17913612e-06
Iter: 208 loss: 2.04919479e-06
Iter: 209 loss: 2.03755485e-06
Iter: 210 loss: 2.06772e-06
Iter: 211 loss: 2.0336247e-06
Iter: 212 loss: 2.02307501e-06
Iter: 213 loss: 2.03761556e-06
Iter: 214 loss: 2.01784587e-06
Iter: 215 loss: 2.00834961e-06
Iter: 216 loss: 2.02133742e-06
Iter: 217 loss: 2.00366685e-06
Iter: 218 loss: 1.99085343e-06
Iter: 219 loss: 2.04599678e-06
Iter: 220 loss: 1.98813291e-06
Iter: 221 loss: 1.97839472e-06
Iter: 222 loss: 2.00155455e-06
Iter: 223 loss: 1.97483268e-06
Iter: 224 loss: 1.96255405e-06
Iter: 225 loss: 2.00206296e-06
Iter: 226 loss: 1.95906114e-06
Iter: 227 loss: 1.94936138e-06
Iter: 228 loss: 1.95825169e-06
Iter: 229 loss: 1.94379777e-06
Iter: 230 loss: 1.93356482e-06
Iter: 231 loss: 1.95387815e-06
Iter: 232 loss: 1.92932498e-06
Iter: 233 loss: 1.92094308e-06
Iter: 234 loss: 1.92069047e-06
Iter: 235 loss: 1.91521895e-06
Iter: 236 loss: 1.90977698e-06
Iter: 237 loss: 1.9086051e-06
Iter: 238 loss: 1.90058199e-06
Iter: 239 loss: 1.93681171e-06
Iter: 240 loss: 1.89906928e-06
Iter: 241 loss: 1.89137904e-06
Iter: 242 loss: 1.88700983e-06
Iter: 243 loss: 1.88359127e-06
Iter: 244 loss: 1.87314629e-06
Iter: 245 loss: 1.95647362e-06
Iter: 246 loss: 1.87246e-06
Iter: 247 loss: 1.86538182e-06
Iter: 248 loss: 1.89967409e-06
Iter: 249 loss: 1.86412012e-06
Iter: 250 loss: 1.85573913e-06
Iter: 251 loss: 1.85683916e-06
Iter: 252 loss: 1.84948453e-06
Iter: 253 loss: 1.84107955e-06
Iter: 254 loss: 1.84141061e-06
Iter: 255 loss: 1.83458019e-06
Iter: 256 loss: 1.825347e-06
Iter: 257 loss: 1.93006508e-06
Iter: 258 loss: 1.8251792e-06
Iter: 259 loss: 1.81860969e-06
Iter: 260 loss: 1.85518093e-06
Iter: 261 loss: 1.81763312e-06
Iter: 262 loss: 1.81171481e-06
Iter: 263 loss: 1.8120254e-06
Iter: 264 loss: 1.80716245e-06
Iter: 265 loss: 1.79870597e-06
Iter: 266 loss: 1.82510394e-06
Iter: 267 loss: 1.79623305e-06
Iter: 268 loss: 1.78981315e-06
Iter: 269 loss: 1.83287102e-06
Iter: 270 loss: 1.7892155e-06
Iter: 271 loss: 1.783779e-06
Iter: 272 loss: 1.81038172e-06
Iter: 273 loss: 1.7827565e-06
Iter: 274 loss: 1.77684558e-06
Iter: 275 loss: 1.77006905e-06
Iter: 276 loss: 1.7690993e-06
Iter: 277 loss: 1.76161973e-06
Iter: 278 loss: 1.76371589e-06
Iter: 279 loss: 1.75623654e-06
Iter: 280 loss: 1.74764523e-06
Iter: 281 loss: 1.85227475e-06
Iter: 282 loss: 1.74744321e-06
Iter: 283 loss: 1.74052298e-06
Iter: 284 loss: 1.74981506e-06
Iter: 285 loss: 1.73702676e-06
Iter: 286 loss: 1.7303887e-06
Iter: 287 loss: 1.76183369e-06
Iter: 288 loss: 1.72914838e-06
Iter: 289 loss: 1.72190164e-06
Iter: 290 loss: 1.73819217e-06
Iter: 291 loss: 1.71923625e-06
Iter: 292 loss: 1.71382089e-06
Iter: 293 loss: 1.71041722e-06
Iter: 294 loss: 1.70837518e-06
Iter: 295 loss: 1.70028147e-06
Iter: 296 loss: 1.74978686e-06
Iter: 297 loss: 1.69931309e-06
Iter: 298 loss: 1.69244913e-06
Iter: 299 loss: 1.72766909e-06
Iter: 300 loss: 1.69137809e-06
Iter: 301 loss: 1.68549604e-06
Iter: 302 loss: 1.70410237e-06
Iter: 303 loss: 1.68382508e-06
Iter: 304 loss: 1.67814312e-06
Iter: 305 loss: 1.67731423e-06
Iter: 306 loss: 1.67340272e-06
Iter: 307 loss: 1.66974326e-06
Iter: 308 loss: 1.66941595e-06
Iter: 309 loss: 1.6655074e-06
Iter: 310 loss: 1.65954862e-06
Iter: 311 loss: 1.65941913e-06
Iter: 312 loss: 1.65331267e-06
Iter: 313 loss: 1.69695841e-06
Iter: 314 loss: 1.65276015e-06
Iter: 315 loss: 1.6477793e-06
Iter: 316 loss: 1.64135827e-06
Iter: 317 loss: 1.64095923e-06
Iter: 318 loss: 1.63333709e-06
Iter: 319 loss: 1.70808653e-06
Iter: 320 loss: 1.63314644e-06
Iter: 321 loss: 1.62806793e-06
Iter: 322 loss: 1.64442395e-06
Iter: 323 loss: 1.62665469e-06
Iter: 324 loss: 1.61991238e-06
Iter: 325 loss: 1.62754986e-06
Iter: 326 loss: 1.61628441e-06
Iter: 327 loss: 1.6108628e-06
Iter: 328 loss: 1.66675932e-06
Iter: 329 loss: 1.61078628e-06
Iter: 330 loss: 1.60717013e-06
Iter: 331 loss: 1.60501827e-06
Iter: 332 loss: 1.60357695e-06
Iter: 333 loss: 1.59637261e-06
Iter: 334 loss: 1.60022898e-06
Iter: 335 loss: 1.59153979e-06
Iter: 336 loss: 1.58582532e-06
Iter: 337 loss: 1.60944251e-06
Iter: 338 loss: 1.58453599e-06
Iter: 339 loss: 1.57786133e-06
Iter: 340 loss: 1.61679611e-06
Iter: 341 loss: 1.57700561e-06
Iter: 342 loss: 1.57246654e-06
Iter: 343 loss: 1.57522607e-06
Iter: 344 loss: 1.56955662e-06
Iter: 345 loss: 1.56543308e-06
Iter: 346 loss: 1.5654042e-06
Iter: 347 loss: 1.56231363e-06
Iter: 348 loss: 1.56159786e-06
Iter: 349 loss: 1.55972111e-06
Iter: 350 loss: 1.55539692e-06
Iter: 351 loss: 1.54815416e-06
Iter: 352 loss: 1.54815893e-06
Iter: 353 loss: 1.54267639e-06
Iter: 354 loss: 1.54262943e-06
Iter: 355 loss: 1.53866404e-06
Iter: 356 loss: 1.54209749e-06
Iter: 357 loss: 1.5363396e-06
Iter: 358 loss: 1.53082181e-06
Iter: 359 loss: 1.53863357e-06
Iter: 360 loss: 1.52802204e-06
Iter: 361 loss: 1.52373434e-06
Iter: 362 loss: 1.52372468e-06
Iter: 363 loss: 1.5206183e-06
Iter: 364 loss: 1.51657378e-06
Iter: 365 loss: 1.51625011e-06
Iter: 366 loss: 1.51092911e-06
Iter: 367 loss: 1.54388658e-06
Iter: 368 loss: 1.51028848e-06
Iter: 369 loss: 1.5058622e-06
Iter: 370 loss: 1.51585277e-06
Iter: 371 loss: 1.50429105e-06
Iter: 372 loss: 1.49992024e-06
Iter: 373 loss: 1.50049073e-06
Iter: 374 loss: 1.49645962e-06
Iter: 375 loss: 1.49242965e-06
Iter: 376 loss: 1.49244772e-06
Iter: 377 loss: 1.48927188e-06
Iter: 378 loss: 1.49571702e-06
Iter: 379 loss: 1.48793356e-06
Iter: 380 loss: 1.48446247e-06
Iter: 381 loss: 1.4951404e-06
Iter: 382 loss: 1.48344532e-06
Iter: 383 loss: 1.47945389e-06
Iter: 384 loss: 1.48842082e-06
Iter: 385 loss: 1.47798232e-06
Iter: 386 loss: 1.47462811e-06
Iter: 387 loss: 1.473579e-06
Iter: 388 loss: 1.47154424e-06
Iter: 389 loss: 1.46668071e-06
Iter: 390 loss: 1.47587457e-06
Iter: 391 loss: 1.4646339e-06
Iter: 392 loss: 1.45993522e-06
Iter: 393 loss: 1.4700172e-06
Iter: 394 loss: 1.45809645e-06
Iter: 395 loss: 1.45371678e-06
Iter: 396 loss: 1.49358107e-06
Iter: 397 loss: 1.45363288e-06
Iter: 398 loss: 1.45011313e-06
Iter: 399 loss: 1.46315301e-06
Iter: 400 loss: 1.44916589e-06
Iter: 401 loss: 1.44621242e-06
Iter: 402 loss: 1.45404704e-06
Iter: 403 loss: 1.44522937e-06
Iter: 404 loss: 1.44149283e-06
Iter: 405 loss: 1.44294086e-06
Iter: 406 loss: 1.43899479e-06
Iter: 407 loss: 1.43481452e-06
Iter: 408 loss: 1.43977468e-06
Iter: 409 loss: 1.43267175e-06
Iter: 410 loss: 1.42808665e-06
Iter: 411 loss: 1.46413117e-06
Iter: 412 loss: 1.42780993e-06
Iter: 413 loss: 1.42410818e-06
Iter: 414 loss: 1.4283595e-06
Iter: 415 loss: 1.42210672e-06
Iter: 416 loss: 1.41892951e-06
Iter: 417 loss: 1.45487854e-06
Iter: 418 loss: 1.41887074e-06
Iter: 419 loss: 1.41569717e-06
Iter: 420 loss: 1.4174849e-06
Iter: 421 loss: 1.41380565e-06
Iter: 422 loss: 1.41101111e-06
Iter: 423 loss: 1.43775753e-06
Iter: 424 loss: 1.41096655e-06
Iter: 425 loss: 1.40903808e-06
Iter: 426 loss: 1.4053735e-06
Iter: 427 loss: 1.49199377e-06
Iter: 428 loss: 1.40536554e-06
Iter: 429 loss: 1.40098348e-06
Iter: 430 loss: 1.41966655e-06
Iter: 431 loss: 1.40012298e-06
Iter: 432 loss: 1.39654583e-06
Iter: 433 loss: 1.39842086e-06
Iter: 434 loss: 1.39419342e-06
Iter: 435 loss: 1.39001133e-06
Iter: 436 loss: 1.41127748e-06
Iter: 437 loss: 1.3892635e-06
Iter: 438 loss: 1.38545352e-06
Iter: 439 loss: 1.41609689e-06
Iter: 440 loss: 1.38515179e-06
Iter: 441 loss: 1.38223368e-06
Iter: 442 loss: 1.38817268e-06
Iter: 443 loss: 1.38104554e-06
Iter: 444 loss: 1.37790721e-06
Iter: 445 loss: 1.38167695e-06
Iter: 446 loss: 1.37638563e-06
Iter: 447 loss: 1.37290067e-06
Iter: 448 loss: 1.38405483e-06
Iter: 449 loss: 1.37191796e-06
Iter: 450 loss: 1.36848143e-06
Iter: 451 loss: 1.37134225e-06
Iter: 452 loss: 1.36659332e-06
Iter: 453 loss: 1.36245058e-06
Iter: 454 loss: 1.38324924e-06
Iter: 455 loss: 1.36185622e-06
Iter: 456 loss: 1.3586041e-06
Iter: 457 loss: 1.38626478e-06
Iter: 458 loss: 1.35839809e-06
Iter: 459 loss: 1.35619007e-06
Iter: 460 loss: 1.36295898e-06
Iter: 461 loss: 1.35544587e-06
Iter: 462 loss: 1.3532557e-06
Iter: 463 loss: 1.35485755e-06
Iter: 464 loss: 1.35184951e-06
Iter: 465 loss: 1.34909851e-06
Iter: 466 loss: 1.3548464e-06
Iter: 467 loss: 1.34801462e-06
Iter: 468 loss: 1.34446532e-06
Iter: 469 loss: 1.34522702e-06
Iter: 470 loss: 1.34196534e-06
Iter: 471 loss: 1.33838546e-06
Iter: 472 loss: 1.35265145e-06
Iter: 473 loss: 1.33760636e-06
Iter: 474 loss: 1.33421054e-06
Iter: 475 loss: 1.33934759e-06
Iter: 476 loss: 1.33265144e-06
Iter: 477 loss: 1.32898458e-06
Iter: 478 loss: 1.33347567e-06
Iter: 479 loss: 1.32704031e-06
Iter: 480 loss: 1.32549371e-06
Iter: 481 loss: 1.32484752e-06
Iter: 482 loss: 1.32337448e-06
Iter: 483 loss: 1.32041737e-06
Iter: 484 loss: 1.38236067e-06
Iter: 485 loss: 1.32039827e-06
Iter: 486 loss: 1.31662716e-06
Iter: 487 loss: 1.33005983e-06
Iter: 488 loss: 1.31553736e-06
Iter: 489 loss: 1.31256024e-06
Iter: 490 loss: 1.32512275e-06
Iter: 491 loss: 1.31197316e-06
Iter: 492 loss: 1.30861065e-06
Iter: 493 loss: 1.31900674e-06
Iter: 494 loss: 1.30765488e-06
Iter: 495 loss: 1.30510921e-06
Iter: 496 loss: 1.32815239e-06
Iter: 497 loss: 1.30496051e-06
Iter: 498 loss: 1.30251351e-06
Iter: 499 loss: 1.30216063e-06
Iter: 500 loss: 1.30056401e-06
Iter: 501 loss: 1.2980156e-06
Iter: 502 loss: 1.3095223e-06
Iter: 503 loss: 1.29754312e-06
Iter: 504 loss: 1.29484897e-06
Iter: 505 loss: 1.29622549e-06
Iter: 506 loss: 1.29301907e-06
Iter: 507 loss: 1.29031719e-06
Iter: 508 loss: 1.29897069e-06
Iter: 509 loss: 1.28945e-06
Iter: 510 loss: 1.2867672e-06
Iter: 511 loss: 1.29170189e-06
Iter: 512 loss: 1.2855744e-06
Iter: 513 loss: 1.28236434e-06
Iter: 514 loss: 1.28962824e-06
Iter: 515 loss: 1.2810691e-06
Iter: 516 loss: 1.27783835e-06
Iter: 517 loss: 1.27987755e-06
Iter: 518 loss: 1.27573117e-06
Iter: 519 loss: 1.27332771e-06
Iter: 520 loss: 1.27326666e-06
Iter: 521 loss: 1.27112298e-06
Iter: 522 loss: 1.26933969e-06
Iter: 523 loss: 1.26877478e-06
Iter: 524 loss: 1.26528084e-06
Iter: 525 loss: 1.2695707e-06
Iter: 526 loss: 1.26353598e-06
Iter: 527 loss: 1.26069119e-06
Iter: 528 loss: 1.28305498e-06
Iter: 529 loss: 1.26052521e-06
Iter: 530 loss: 1.25808788e-06
Iter: 531 loss: 1.26766531e-06
Iter: 532 loss: 1.25754082e-06
Iter: 533 loss: 1.25467295e-06
Iter: 534 loss: 1.26388102e-06
Iter: 535 loss: 1.2540163e-06
Iter: 536 loss: 1.25202939e-06
Iter: 537 loss: 1.2564991e-06
Iter: 538 loss: 1.25127144e-06
Iter: 539 loss: 1.24908888e-06
Iter: 540 loss: 1.25015845e-06
Iter: 541 loss: 1.2476512e-06
Iter: 542 loss: 1.24519136e-06
Iter: 543 loss: 1.25839279e-06
Iter: 544 loss: 1.24491976e-06
Iter: 545 loss: 1.24231281e-06
Iter: 546 loss: 1.24235237e-06
Iter: 547 loss: 1.2403724e-06
Iter: 548 loss: 1.23756922e-06
Iter: 549 loss: 1.24358201e-06
Iter: 550 loss: 1.23655036e-06
Iter: 551 loss: 1.23360815e-06
Iter: 552 loss: 1.24841677e-06
Iter: 553 loss: 1.23309314e-06
Iter: 554 loss: 1.23057634e-06
Iter: 555 loss: 1.2332805e-06
Iter: 556 loss: 1.22915526e-06
Iter: 557 loss: 1.22640074e-06
Iter: 558 loss: 1.25216479e-06
Iter: 559 loss: 1.22633833e-06
Iter: 560 loss: 1.2244293e-06
Iter: 561 loss: 1.2291539e-06
Iter: 562 loss: 1.22381391e-06
Iter: 563 loss: 1.22126721e-06
Iter: 564 loss: 1.21914559e-06
Iter: 565 loss: 1.21853952e-06
Iter: 566 loss: 1.2149377e-06
Iter: 567 loss: 1.22919073e-06
Iter: 568 loss: 1.21409551e-06
Iter: 569 loss: 1.21273115e-06
Iter: 570 loss: 1.21256085e-06
Iter: 571 loss: 1.21079916e-06
Iter: 572 loss: 1.20777713e-06
Iter: 573 loss: 1.28057229e-06
Iter: 574 loss: 1.20778054e-06
Iter: 575 loss: 1.20518848e-06
Iter: 576 loss: 1.2267999e-06
Iter: 577 loss: 1.20507252e-06
Iter: 578 loss: 1.20306072e-06
Iter: 579 loss: 1.2095345e-06
Iter: 580 loss: 1.20249422e-06
Iter: 581 loss: 1.20059349e-06
Iter: 582 loss: 1.20008576e-06
Iter: 583 loss: 1.19885885e-06
Iter: 584 loss: 1.19627134e-06
Iter: 585 loss: 1.21985e-06
Iter: 586 loss: 1.19619506e-06
Iter: 587 loss: 1.19451465e-06
Iter: 588 loss: 1.19321805e-06
Iter: 589 loss: 1.19266542e-06
Iter: 590 loss: 1.1894715e-06
Iter: 591 loss: 1.19658876e-06
Iter: 592 loss: 1.18840228e-06
Iter: 593 loss: 1.18556909e-06
Iter: 594 loss: 1.19598826e-06
Iter: 595 loss: 1.18485218e-06
Iter: 596 loss: 1.18192736e-06
Iter: 597 loss: 1.20109098e-06
Iter: 598 loss: 1.18149183e-06
Iter: 599 loss: 1.17960712e-06
Iter: 600 loss: 1.18706896e-06
Iter: 601 loss: 1.1792315e-06
Iter: 602 loss: 1.17746299e-06
Iter: 603 loss: 1.17834747e-06
Iter: 604 loss: 1.17636318e-06
Iter: 605 loss: 1.17395859e-06
Iter: 606 loss: 1.17528168e-06
Iter: 607 loss: 1.17244815e-06
Iter: 608 loss: 1.17074035e-06
Iter: 609 loss: 1.17055026e-06
Iter: 610 loss: 1.169283e-06
Iter: 611 loss: 1.16819206e-06
Iter: 612 loss: 1.16784759e-06
Iter: 613 loss: 1.16575768e-06
Iter: 614 loss: 1.16466811e-06
Iter: 615 loss: 1.16371564e-06
Iter: 616 loss: 1.16145065e-06
Iter: 617 loss: 1.16142633e-06
Iter: 618 loss: 1.15983573e-06
Iter: 619 loss: 1.15942134e-06
Iter: 620 loss: 1.15847831e-06
Iter: 621 loss: 1.15619832e-06
Iter: 622 loss: 1.16326737e-06
Iter: 623 loss: 1.15550108e-06
Iter: 624 loss: 1.15373905e-06
Iter: 625 loss: 1.16043054e-06
Iter: 626 loss: 1.1533233e-06
Iter: 627 loss: 1.15113539e-06
Iter: 628 loss: 1.15102e-06
Iter: 629 loss: 1.1493546e-06
Iter: 630 loss: 1.14698491e-06
Iter: 631 loss: 1.15797889e-06
Iter: 632 loss: 1.14662555e-06
Iter: 633 loss: 1.14444492e-06
Iter: 634 loss: 1.15532623e-06
Iter: 635 loss: 1.14406453e-06
Iter: 636 loss: 1.14195154e-06
Iter: 637 loss: 1.15007242e-06
Iter: 638 loss: 1.1414968e-06
Iter: 639 loss: 1.14005104e-06
Iter: 640 loss: 1.14003751e-06
Iter: 641 loss: 1.13886495e-06
Iter: 642 loss: 1.13689339e-06
Iter: 643 loss: 1.15072e-06
Iter: 644 loss: 1.13677675e-06
Iter: 645 loss: 1.13516899e-06
Iter: 646 loss: 1.1454232e-06
Iter: 647 loss: 1.13504825e-06
Iter: 648 loss: 1.13373937e-06
Iter: 649 loss: 1.13253691e-06
Iter: 650 loss: 1.13216629e-06
Iter: 651 loss: 1.13036117e-06
Iter: 652 loss: 1.13866429e-06
Iter: 653 loss: 1.13002648e-06
Iter: 654 loss: 1.1282184e-06
Iter: 655 loss: 1.12640771e-06
Iter: 656 loss: 1.12601174e-06
Iter: 657 loss: 1.12394878e-06
Iter: 658 loss: 1.1239523e-06
Iter: 659 loss: 1.12251007e-06
Iter: 660 loss: 1.12174189e-06
Iter: 661 loss: 1.12119278e-06
Iter: 662 loss: 1.11928784e-06
Iter: 663 loss: 1.12159898e-06
Iter: 664 loss: 1.11835539e-06
Iter: 665 loss: 1.11630254e-06
Iter: 666 loss: 1.13164697e-06
Iter: 667 loss: 1.11608983e-06
Iter: 668 loss: 1.11428835e-06
Iter: 669 loss: 1.1159e-06
Iter: 670 loss: 1.1132463e-06
Iter: 671 loss: 1.11131158e-06
Iter: 672 loss: 1.11663746e-06
Iter: 673 loss: 1.11071472e-06
Iter: 674 loss: 1.108775e-06
Iter: 675 loss: 1.12582529e-06
Iter: 676 loss: 1.10864448e-06
Iter: 677 loss: 1.1072616e-06
Iter: 678 loss: 1.10705446e-06
Iter: 679 loss: 1.10604412e-06
Iter: 680 loss: 1.10435144e-06
Iter: 681 loss: 1.11313989e-06
Iter: 682 loss: 1.10410542e-06
Iter: 683 loss: 1.10237409e-06
Iter: 684 loss: 1.11264444e-06
Iter: 685 loss: 1.10213045e-06
Iter: 686 loss: 1.10096357e-06
Iter: 687 loss: 1.09939583e-06
Iter: 688 loss: 1.0993358e-06
Iter: 689 loss: 1.09758753e-06
Iter: 690 loss: 1.1078331e-06
Iter: 691 loss: 1.0973589e-06
Iter: 692 loss: 1.09546522e-06
Iter: 693 loss: 1.09499751e-06
Iter: 694 loss: 1.09379425e-06
Iter: 695 loss: 1.09223186e-06
Iter: 696 loss: 1.09223686e-06
Iter: 697 loss: 1.09100483e-06
Iter: 698 loss: 1.08930362e-06
Iter: 699 loss: 1.08925155e-06
Iter: 700 loss: 1.08683548e-06
Iter: 701 loss: 1.09605776e-06
Iter: 702 loss: 1.0863032e-06
Iter: 703 loss: 1.0845755e-06
Iter: 704 loss: 1.08874951e-06
Iter: 705 loss: 1.08392715e-06
Iter: 706 loss: 1.08205131e-06
Iter: 707 loss: 1.08668337e-06
Iter: 708 loss: 1.0813435e-06
Iter: 709 loss: 1.07961409e-06
Iter: 710 loss: 1.09649022e-06
Iter: 711 loss: 1.07954907e-06
Iter: 712 loss: 1.07813366e-06
Iter: 713 loss: 1.07826327e-06
Iter: 714 loss: 1.07711685e-06
Iter: 715 loss: 1.07525773e-06
Iter: 716 loss: 1.08948234e-06
Iter: 717 loss: 1.07512187e-06
Iter: 718 loss: 1.07402627e-06
Iter: 719 loss: 1.07570327e-06
Iter: 720 loss: 1.07344499e-06
Iter: 721 loss: 1.07195183e-06
Iter: 722 loss: 1.08003212e-06
Iter: 723 loss: 1.07176106e-06
Iter: 724 loss: 1.07061169e-06
Iter: 725 loss: 1.06983032e-06
Iter: 726 loss: 1.06943651e-06
Iter: 727 loss: 1.06769869e-06
Iter: 728 loss: 1.06919902e-06
Iter: 729 loss: 1.06667721e-06
Iter: 730 loss: 1.06459515e-06
Iter: 731 loss: 1.06866901e-06
Iter: 732 loss: 1.06367918e-06
Iter: 733 loss: 1.06172683e-06
Iter: 734 loss: 1.07286269e-06
Iter: 735 loss: 1.06146763e-06
Iter: 736 loss: 1.05984168e-06
Iter: 737 loss: 1.07205824e-06
Iter: 738 loss: 1.05973891e-06
Iter: 739 loss: 1.05834738e-06
Iter: 740 loss: 1.06042921e-06
Iter: 741 loss: 1.05771778e-06
Iter: 742 loss: 1.05623008e-06
Iter: 743 loss: 1.05605159e-06
Iter: 744 loss: 1.05504705e-06
Iter: 745 loss: 1.05291133e-06
Iter: 746 loss: 1.06806749e-06
Iter: 747 loss: 1.05276604e-06
Iter: 748 loss: 1.0512797e-06
Iter: 749 loss: 1.05175138e-06
Iter: 750 loss: 1.0501567e-06
Iter: 751 loss: 1.04864421e-06
Iter: 752 loss: 1.06563527e-06
Iter: 753 loss: 1.04859532e-06
Iter: 754 loss: 1.04715934e-06
Iter: 755 loss: 1.04983224e-06
Iter: 756 loss: 1.04664298e-06
Iter: 757 loss: 1.04549338e-06
Iter: 758 loss: 1.05147114e-06
Iter: 759 loss: 1.04531728e-06
Iter: 760 loss: 1.04421122e-06
Iter: 761 loss: 1.04630089e-06
Iter: 762 loss: 1.04371452e-06
Iter: 763 loss: 1.04242804e-06
Iter: 764 loss: 1.04275728e-06
Iter: 765 loss: 1.04156061e-06
Iter: 766 loss: 1.04012065e-06
Iter: 767 loss: 1.04723767e-06
Iter: 768 loss: 1.03991169e-06
Iter: 769 loss: 1.03873845e-06
Iter: 770 loss: 1.0374772e-06
Iter: 771 loss: 1.0372512e-06
Iter: 772 loss: 1.03531806e-06
Iter: 773 loss: 1.03805132e-06
Iter: 774 loss: 1.0343872e-06
Iter: 775 loss: 1.03244361e-06
Iter: 776 loss: 1.04877563e-06
Iter: 777 loss: 1.03232787e-06
Iter: 778 loss: 1.03087802e-06
Iter: 779 loss: 1.04553988e-06
Iter: 780 loss: 1.03091361e-06
Iter: 781 loss: 1.02971853e-06
Iter: 782 loss: 1.02917534e-06
Iter: 783 loss: 1.02860656e-06
Iter: 784 loss: 1.0269456e-06
Iter: 785 loss: 1.03180616e-06
Iter: 786 loss: 1.02645458e-06
Iter: 787 loss: 1.0249114e-06
Iter: 788 loss: 1.02799299e-06
Iter: 789 loss: 1.02425349e-06
Iter: 790 loss: 1.02296121e-06
Iter: 791 loss: 1.03708351e-06
Iter: 792 loss: 1.0229694e-06
Iter: 793 loss: 1.02176591e-06
Iter: 794 loss: 1.02334081e-06
Iter: 795 loss: 1.02114575e-06
Iter: 796 loss: 1.0201162e-06
Iter: 797 loss: 1.02688807e-06
Iter: 798 loss: 1.01997944e-06
Iter: 799 loss: 1.01886383e-06
Iter: 800 loss: 1.01846808e-06
Iter: 801 loss: 1.01785236e-06
Iter: 802 loss: 1.0163501e-06
Iter: 803 loss: 1.02484557e-06
Iter: 804 loss: 1.01616843e-06
Iter: 805 loss: 1.01518981e-06
Iter: 806 loss: 1.01399064e-06
Iter: 807 loss: 1.01384489e-06
Iter: 808 loss: 1.01194826e-06
Iter: 809 loss: 1.02325646e-06
Iter: 810 loss: 1.01176386e-06
Iter: 811 loss: 1.01016758e-06
Iter: 812 loss: 1.01551018e-06
Iter: 813 loss: 1.00987972e-06
Iter: 814 loss: 1.0085048e-06
Iter: 815 loss: 1.01159026e-06
Iter: 816 loss: 1.00798388e-06
Iter: 817 loss: 1.00657144e-06
Iter: 818 loss: 1.00600141e-06
Iter: 819 loss: 1.00516729e-06
Iter: 820 loss: 1.00362877e-06
Iter: 821 loss: 1.02600643e-06
Iter: 822 loss: 1.00365673e-06
Iter: 823 loss: 1.00259047e-06
Iter: 824 loss: 1.00826458e-06
Iter: 825 loss: 1.00242301e-06
Iter: 826 loss: 1.00133241e-06
Iter: 827 loss: 1.0000399e-06
Iter: 828 loss: 9.99886879e-07
Iter: 829 loss: 9.98383598e-07
Iter: 830 loss: 1.00697139e-06
Iter: 831 loss: 9.98183509e-07
Iter: 832 loss: 9.96943072e-07
Iter: 833 loss: 1.00699845e-06
Iter: 834 loss: 9.96876111e-07
Iter: 835 loss: 9.95635446e-07
Iter: 836 loss: 9.96871449e-07
Iter: 837 loss: 9.94979928e-07
Iter: 838 loss: 9.93861931e-07
Iter: 839 loss: 9.98316e-07
Iter: 840 loss: 9.93547474e-07
Iter: 841 loss: 9.92358082e-07
Iter: 842 loss: 9.94372499e-07
Iter: 843 loss: 9.91841489e-07
Iter: 844 loss: 9.90777e-07
Iter: 845 loss: 9.89678e-07
Iter: 846 loss: 9.89420414e-07
Iter: 847 loss: 9.87962721e-07
Iter: 848 loss: 9.97951929e-07
Iter: 849 loss: 9.87796511e-07
Iter: 850 loss: 9.8636076e-07
Iter: 851 loss: 9.91244065e-07
Iter: 852 loss: 9.859898e-07
Iter: 853 loss: 9.84699568e-07
Iter: 854 loss: 9.88022293e-07
Iter: 855 loss: 9.84366579e-07
Iter: 856 loss: 9.83169457e-07
Iter: 857 loss: 9.8297e-07
Iter: 858 loss: 9.82294637e-07
Iter: 859 loss: 9.8049145e-07
Iter: 860 loss: 9.93216872e-07
Iter: 861 loss: 9.80374352e-07
Iter: 862 loss: 9.79270908e-07
Iter: 863 loss: 9.8798364e-07
Iter: 864 loss: 9.79192919e-07
Iter: 865 loss: 9.78292292e-07
Iter: 866 loss: 9.7838074e-07
Iter: 867 loss: 9.77635409e-07
Iter: 868 loss: 9.76289471e-07
Iter: 869 loss: 9.77783429e-07
Iter: 870 loss: 9.7559041e-07
Iter: 871 loss: 9.74738214e-07
Iter: 872 loss: 9.74703312e-07
Iter: 873 loss: 9.73899e-07
Iter: 874 loss: 9.74055183e-07
Iter: 875 loss: 9.73379542e-07
Iter: 876 loss: 9.72207772e-07
Iter: 877 loss: 9.73121587e-07
Iter: 878 loss: 9.71487339e-07
Iter: 879 loss: 9.70214387e-07
Iter: 880 loss: 9.78285698e-07
Iter: 881 loss: 9.7009729e-07
Iter: 882 loss: 9.69337407e-07
Iter: 883 loss: 9.713483e-07
Iter: 884 loss: 9.69028633e-07
Iter: 885 loss: 9.68035124e-07
Iter: 886 loss: 9.66802872e-07
Iter: 887 loss: 9.66810831e-07
Iter: 888 loss: 9.65174536e-07
Iter: 889 loss: 9.69012376e-07
Iter: 890 loss: 9.64568926e-07
Iter: 891 loss: 9.63197522e-07
Iter: 892 loss: 9.73727197e-07
Iter: 893 loss: 9.63078264e-07
Iter: 894 loss: 9.61719138e-07
Iter: 895 loss: 9.63587922e-07
Iter: 896 loss: 9.61021e-07
Iter: 897 loss: 9.59649924e-07
Iter: 898 loss: 9.69321e-07
Iter: 899 loss: 9.59504519e-07
Iter: 900 loss: 9.58546e-07
Iter: 901 loss: 9.59233603e-07
Iter: 902 loss: 9.57974635e-07
Iter: 903 loss: 9.56789336e-07
Iter: 904 loss: 9.66361767e-07
Iter: 905 loss: 9.56694635e-07
Iter: 906 loss: 9.55773885e-07
Iter: 907 loss: 9.54679763e-07
Iter: 908 loss: 9.5456e-07
Iter: 909 loss: 9.54016059e-07
Iter: 910 loss: 9.53768222e-07
Iter: 911 loss: 9.531052e-07
Iter: 912 loss: 9.52402843e-07
Iter: 913 loss: 9.52335199e-07
Iter: 914 loss: 9.51329184e-07
Iter: 915 loss: 9.54014467e-07
Iter: 916 loss: 9.51014215e-07
Iter: 917 loss: 9.4977753e-07
Iter: 918 loss: 9.51953893e-07
Iter: 919 loss: 9.49239734e-07
Iter: 920 loss: 9.48001741e-07
Iter: 921 loss: 9.50965784e-07
Iter: 922 loss: 9.47582294e-07
Iter: 923 loss: 9.4657355e-07
Iter: 924 loss: 9.46685532e-07
Iter: 925 loss: 9.45733404e-07
Iter: 926 loss: 9.44117176e-07
Iter: 927 loss: 9.53068081e-07
Iter: 928 loss: 9.4388804e-07
Iter: 929 loss: 9.42683414e-07
Iter: 930 loss: 9.43263103e-07
Iter: 931 loss: 9.4189113e-07
Iter: 932 loss: 9.40389327e-07
Iter: 933 loss: 9.43392251e-07
Iter: 934 loss: 9.39808842e-07
Iter: 935 loss: 9.38258495e-07
Iter: 936 loss: 9.42734687e-07
Iter: 937 loss: 9.37812672e-07
Iter: 938 loss: 9.36412e-07
Iter: 939 loss: 9.48536126e-07
Iter: 940 loss: 9.36350034e-07
Iter: 941 loss: 9.353e-07
Iter: 942 loss: 9.37878724e-07
Iter: 943 loss: 9.3489848e-07
Iter: 944 loss: 9.33863703e-07
Iter: 945 loss: 9.36863444e-07
Iter: 946 loss: 9.33521619e-07
Iter: 947 loss: 9.32683861e-07
Iter: 948 loss: 9.45395641e-07
Iter: 949 loss: 9.32689034e-07
Iter: 950 loss: 9.32089165e-07
Iter: 951 loss: 9.31213378e-07
Iter: 952 loss: 9.31216505e-07
Iter: 953 loss: 9.30108286e-07
Iter: 954 loss: 9.35079e-07
Iter: 955 loss: 9.29967e-07
Iter: 956 loss: 9.28818167e-07
Iter: 957 loss: 9.30556666e-07
Iter: 958 loss: 9.28229611e-07
Iter: 959 loss: 9.27313863e-07
Iter: 960 loss: 9.28484155e-07
Iter: 961 loss: 9.2685957e-07
Iter: 962 loss: 9.25582128e-07
Iter: 963 loss: 9.25747258e-07
Iter: 964 loss: 9.24549454e-07
Iter: 965 loss: 9.23604262e-07
Iter: 966 loss: 9.23534799e-07
Iter: 967 loss: 9.22851e-07
Iter: 968 loss: 9.21771289e-07
Iter: 969 loss: 9.21728656e-07
Iter: 970 loss: 9.20328546e-07
Iter: 971 loss: 9.26917266e-07
Iter: 972 loss: 9.20049501e-07
Iter: 973 loss: 9.19119429e-07
Iter: 974 loss: 9.23633706e-07
Iter: 975 loss: 9.1885704e-07
Iter: 976 loss: 9.17961756e-07
Iter: 977 loss: 9.17784519e-07
Iter: 978 loss: 9.17137072e-07
Iter: 979 loss: 9.15719056e-07
Iter: 980 loss: 9.19226409e-07
Iter: 981 loss: 9.15272267e-07
Iter: 982 loss: 9.14274835e-07
Iter: 983 loss: 9.23336188e-07
Iter: 984 loss: 9.14212e-07
Iter: 985 loss: 9.13230394e-07
Iter: 986 loss: 9.18044179e-07
Iter: 987 loss: 9.12949929e-07
Iter: 988 loss: 9.12181576e-07
Iter: 989 loss: 9.13209931e-07
Iter: 990 loss: 9.11757922e-07
Iter: 991 loss: 9.10826145e-07
Iter: 992 loss: 9.12368591e-07
Iter: 993 loss: 9.1042682e-07
Iter: 994 loss: 9.09545804e-07
Iter: 995 loss: 9.11339271e-07
Iter: 996 loss: 9.09190248e-07
Iter: 997 loss: 9.080768e-07
Iter: 998 loss: 9.12773771e-07
Iter: 999 loss: 9.07891319e-07
Iter: 1000 loss: 9.06997684e-07
Iter: 1001 loss: 9.06491778e-07
Iter: 1002 loss: 9.06172488e-07
Iter: 1003 loss: 9.05018737e-07
Iter: 1004 loss: 9.1337472e-07
Iter: 1005 loss: 9.0492523e-07
Iter: 1006 loss: 9.0404717e-07
Iter: 1007 loss: 9.09388348e-07
Iter: 1008 loss: 9.03896137e-07
Iter: 1009 loss: 9.03070941e-07
Iter: 1010 loss: 9.03377327e-07
Iter: 1011 loss: 9.02543832e-07
Iter: 1012 loss: 9.01561e-07
Iter: 1013 loss: 9.00681e-07
Iter: 1014 loss: 9.00505597e-07
Iter: 1015 loss: 8.99084228e-07
Iter: 1016 loss: 9.10683809e-07
Iter: 1017 loss: 8.9899919e-07
Iter: 1018 loss: 8.97735788e-07
Iter: 1019 loss: 9.00829434e-07
Iter: 1020 loss: 8.97319e-07
Iter: 1021 loss: 8.96146275e-07
Iter: 1022 loss: 9.01470798e-07
Iter: 1023 loss: 8.95935159e-07
Iter: 1024 loss: 8.94866048e-07
Iter: 1025 loss: 8.97653194e-07
Iter: 1026 loss: 8.94526238e-07
Iter: 1027 loss: 8.93721847e-07
Iter: 1028 loss: 8.93723609e-07
Iter: 1029 loss: 8.93087e-07
Iter: 1030 loss: 8.91963396e-07
Iter: 1031 loss: 9.14347311e-07
Iter: 1032 loss: 8.9192838e-07
Iter: 1033 loss: 8.90804756e-07
Iter: 1034 loss: 8.97015298e-07
Iter: 1035 loss: 8.9063974e-07
Iter: 1036 loss: 8.89805392e-07
Iter: 1037 loss: 8.92859248e-07
Iter: 1038 loss: 8.89489797e-07
Iter: 1039 loss: 8.88636123e-07
Iter: 1040 loss: 8.92255912e-07
Iter: 1041 loss: 8.88422733e-07
Iter: 1042 loss: 8.8758577e-07
Iter: 1043 loss: 8.88350314e-07
Iter: 1044 loss: 8.87152737e-07
Iter: 1045 loss: 8.85991255e-07
Iter: 1046 loss: 8.89251396e-07
Iter: 1047 loss: 8.85647296e-07
Iter: 1048 loss: 8.84705969e-07
Iter: 1049 loss: 8.88763282e-07
Iter: 1050 loss: 8.84484052e-07
Iter: 1051 loss: 8.83670737e-07
Iter: 1052 loss: 8.84906456e-07
Iter: 1053 loss: 8.83267887e-07
Iter: 1054 loss: 8.82101858e-07
Iter: 1055 loss: 8.86954808e-07
Iter: 1056 loss: 8.81892561e-07
Iter: 1057 loss: 8.81160133e-07
Iter: 1058 loss: 8.80270761e-07
Iter: 1059 loss: 8.80181574e-07
Iter: 1060 loss: 8.78980586e-07
Iter: 1061 loss: 8.8488548e-07
Iter: 1062 loss: 8.78823471e-07
Iter: 1063 loss: 8.7792381e-07
Iter: 1064 loss: 8.8262334e-07
Iter: 1065 loss: 8.77768798e-07
Iter: 1066 loss: 8.76996751e-07
Iter: 1067 loss: 8.86466069e-07
Iter: 1068 loss: 8.77007892e-07
Iter: 1069 loss: 8.76463332e-07
Iter: 1070 loss: 8.75514161e-07
Iter: 1071 loss: 8.99461156e-07
Iter: 1072 loss: 8.75505748e-07
Iter: 1073 loss: 8.74555e-07
Iter: 1074 loss: 8.78639071e-07
Iter: 1075 loss: 8.74340344e-07
Iter: 1076 loss: 8.73365821e-07
Iter: 1077 loss: 8.76393301e-07
Iter: 1078 loss: 8.73037322e-07
Iter: 1079 loss: 8.72074224e-07
Iter: 1080 loss: 8.73941815e-07
Iter: 1081 loss: 8.71690133e-07
Iter: 1082 loss: 8.70633698e-07
Iter: 1083 loss: 8.77300806e-07
Iter: 1084 loss: 8.70517283e-07
Iter: 1085 loss: 8.69730911e-07
Iter: 1086 loss: 8.70514e-07
Iter: 1087 loss: 8.69268547e-07
Iter: 1088 loss: 8.68439e-07
Iter: 1089 loss: 8.69853352e-07
Iter: 1090 loss: 8.68112295e-07
Iter: 1091 loss: 8.66969685e-07
Iter: 1092 loss: 8.71003e-07
Iter: 1093 loss: 8.66682569e-07
Iter: 1094 loss: 8.65824461e-07
Iter: 1095 loss: 8.69154e-07
Iter: 1096 loss: 8.65598565e-07
Iter: 1097 loss: 8.64722438e-07
Iter: 1098 loss: 8.65659047e-07
Iter: 1099 loss: 8.6427417e-07
Iter: 1100 loss: 8.63311e-07
Iter: 1101 loss: 8.66319681e-07
Iter: 1102 loss: 8.63093817e-07
Iter: 1103 loss: 8.62229172e-07
Iter: 1104 loss: 8.61841443e-07
Iter: 1105 loss: 8.61448086e-07
Iter: 1106 loss: 8.60235104e-07
Iter: 1107 loss: 8.69443625e-07
Iter: 1108 loss: 8.60086971e-07
Iter: 1109 loss: 8.59402e-07
Iter: 1110 loss: 8.59401894e-07
Iter: 1111 loss: 8.58780766e-07
Iter: 1112 loss: 8.58254111e-07
Iter: 1113 loss: 8.58074202e-07
Iter: 1114 loss: 8.57326881e-07
Iter: 1115 loss: 8.56861277e-07
Iter: 1116 loss: 8.56565748e-07
Iter: 1117 loss: 8.55305188e-07
Iter: 1118 loss: 8.61982585e-07
Iter: 1119 loss: 8.55186158e-07
Iter: 1120 loss: 8.54154791e-07
Iter: 1121 loss: 8.56363272e-07
Iter: 1122 loss: 8.5381032e-07
Iter: 1123 loss: 8.52971709e-07
Iter: 1124 loss: 8.61284263e-07
Iter: 1125 loss: 8.52943685e-07
Iter: 1126 loss: 8.52084952e-07
Iter: 1127 loss: 8.52389348e-07
Iter: 1128 loss: 8.51539767e-07
Iter: 1129 loss: 8.50725769e-07
Iter: 1130 loss: 8.51464e-07
Iter: 1131 loss: 8.50259084e-07
Iter: 1132 loss: 8.49342882e-07
Iter: 1133 loss: 8.61705757e-07
Iter: 1134 loss: 8.49376931e-07
Iter: 1135 loss: 8.48740797e-07
Iter: 1136 loss: 8.48647403e-07
Iter: 1137 loss: 8.48232389e-07
Iter: 1138 loss: 8.47244678e-07
Iter: 1139 loss: 8.49607773e-07
Iter: 1140 loss: 8.46876389e-07
Iter: 1141 loss: 8.45903969e-07
Iter: 1142 loss: 8.48129105e-07
Iter: 1143 loss: 8.45511863e-07
Iter: 1144 loss: 8.44683768e-07
Iter: 1145 loss: 8.46004639e-07
Iter: 1146 loss: 8.44237604e-07
Iter: 1147 loss: 8.4331e-07
Iter: 1148 loss: 8.52209837e-07
Iter: 1149 loss: 8.43266264e-07
Iter: 1150 loss: 8.42545091e-07
Iter: 1151 loss: 8.46717967e-07
Iter: 1152 loss: 8.42404688e-07
Iter: 1153 loss: 8.41935844e-07
Iter: 1154 loss: 8.41756219e-07
Iter: 1155 loss: 8.41477458e-07
Iter: 1156 loss: 8.40614234e-07
Iter: 1157 loss: 8.40262715e-07
Iter: 1158 loss: 8.39757945e-07
Iter: 1159 loss: 8.38764322e-07
Iter: 1160 loss: 8.4270971e-07
Iter: 1161 loss: 8.385407e-07
Iter: 1162 loss: 8.37558673e-07
Iter: 1163 loss: 8.39969402e-07
Iter: 1164 loss: 8.37205164e-07
Iter: 1165 loss: 8.36140657e-07
Iter: 1166 loss: 8.40298924e-07
Iter: 1167 loss: 8.35896174e-07
Iter: 1168 loss: 8.3511037e-07
Iter: 1169 loss: 8.42750296e-07
Iter: 1170 loss: 8.35088656e-07
Iter: 1171 loss: 8.34406e-07
Iter: 1172 loss: 8.34316552e-07
Iter: 1173 loss: 8.33839465e-07
Iter: 1174 loss: 8.33127388e-07
Iter: 1175 loss: 8.34283071e-07
Iter: 1176 loss: 8.32838623e-07
Iter: 1177 loss: 8.31786451e-07
Iter: 1178 loss: 8.37012067e-07
Iter: 1179 loss: 8.3164889e-07
Iter: 1180 loss: 8.30979729e-07
Iter: 1181 loss: 8.32181115e-07
Iter: 1182 loss: 8.30616955e-07
Iter: 1183 loss: 8.29923124e-07
Iter: 1184 loss: 8.30796694e-07
Iter: 1185 loss: 8.29584394e-07
Iter: 1186 loss: 8.28810357e-07
Iter: 1187 loss: 8.34810066e-07
Iter: 1188 loss: 8.28732368e-07
Iter: 1189 loss: 8.28145517e-07
Iter: 1190 loss: 8.30603824e-07
Iter: 1191 loss: 8.27998178e-07
Iter: 1192 loss: 8.27231815e-07
Iter: 1193 loss: 8.26861708e-07
Iter: 1194 loss: 8.26509051e-07
Iter: 1195 loss: 8.25744905e-07
Iter: 1196 loss: 8.28295e-07
Iter: 1197 loss: 8.25609732e-07
Iter: 1198 loss: 8.24827453e-07
Iter: 1199 loss: 8.25698294e-07
Iter: 1200 loss: 8.24376571e-07
Iter: 1201 loss: 8.23358505e-07
Iter: 1202 loss: 8.27417466e-07
Iter: 1203 loss: 8.23175128e-07
Iter: 1204 loss: 8.22448271e-07
Iter: 1205 loss: 8.24333256e-07
Iter: 1206 loss: 8.22186166e-07
Iter: 1207 loss: 8.21451238e-07
Iter: 1208 loss: 8.21806793e-07
Iter: 1209 loss: 8.21003937e-07
Iter: 1210 loss: 8.20037258e-07
Iter: 1211 loss: 8.30510885e-07
Iter: 1212 loss: 8.20018613e-07
Iter: 1213 loss: 8.19449042e-07
Iter: 1214 loss: 8.19721e-07
Iter: 1215 loss: 8.18980254e-07
Iter: 1216 loss: 8.18233843e-07
Iter: 1217 loss: 8.18433762e-07
Iter: 1218 loss: 8.17645855e-07
Iter: 1219 loss: 8.16811394e-07
Iter: 1220 loss: 8.30643728e-07
Iter: 1221 loss: 8.16812076e-07
Iter: 1222 loss: 8.16230227e-07
Iter: 1223 loss: 8.15747796e-07
Iter: 1224 loss: 8.1557414e-07
Iter: 1225 loss: 8.14792713e-07
Iter: 1226 loss: 8.19984905e-07
Iter: 1227 loss: 8.14682039e-07
Iter: 1228 loss: 8.1404e-07
Iter: 1229 loss: 8.20135824e-07
Iter: 1230 loss: 8.1404994e-07
Iter: 1231 loss: 8.13530107e-07
Iter: 1232 loss: 8.12762664e-07
Iter: 1233 loss: 8.12755047e-07
Iter: 1234 loss: 8.11849532e-07
Iter: 1235 loss: 8.1576934e-07
Iter: 1236 loss: 8.11737323e-07
Iter: 1237 loss: 8.10931965e-07
Iter: 1238 loss: 8.13426368e-07
Iter: 1239 loss: 8.10709707e-07
Iter: 1240 loss: 8.10017923e-07
Iter: 1241 loss: 8.11562188e-07
Iter: 1242 loss: 8.09711878e-07
Iter: 1243 loss: 8.08888899e-07
Iter: 1244 loss: 8.09966764e-07
Iter: 1245 loss: 8.08530217e-07
Iter: 1246 loss: 8.07707238e-07
Iter: 1247 loss: 8.12019834e-07
Iter: 1248 loss: 8.07535343e-07
Iter: 1249 loss: 8.06727599e-07
Iter: 1250 loss: 8.09226492e-07
Iter: 1251 loss: 8.06603907e-07
Iter: 1252 loss: 8.05842e-07
Iter: 1253 loss: 8.08547384e-07
Iter: 1254 loss: 8.0561756e-07
Iter: 1255 loss: 8.04901e-07
Iter: 1256 loss: 8.0693485e-07
Iter: 1257 loss: 8.04721253e-07
Iter: 1258 loss: 8.04106435e-07
Iter: 1259 loss: 8.0393545e-07
Iter: 1260 loss: 8.03478258e-07
Iter: 1261 loss: 8.02813815e-07
Iter: 1262 loss: 8.11849532e-07
Iter: 1263 loss: 8.02757825e-07
Iter: 1264 loss: 8.02117938e-07
Iter: 1265 loss: 8.02781074e-07
Iter: 1266 loss: 8.01728561e-07
Iter: 1267 loss: 8.01244369e-07
Iter: 1268 loss: 8.0644304e-07
Iter: 1269 loss: 8.01249371e-07
Iter: 1270 loss: 8.00675309e-07
Iter: 1271 loss: 8.00077032e-07
Iter: 1272 loss: 7.99990858e-07
Iter: 1273 loss: 7.9931533e-07
Iter: 1274 loss: 7.99642066e-07
Iter: 1275 loss: 7.98848873e-07
Iter: 1276 loss: 7.97924599e-07
Iter: 1277 loss: 8.01916485e-07
Iter: 1278 loss: 7.97756115e-07
Iter: 1279 loss: 7.97024e-07
Iter: 1280 loss: 7.97765949e-07
Iter: 1281 loss: 7.96589404e-07
Iter: 1282 loss: 7.95706455e-07
Iter: 1283 loss: 8.01412057e-07
Iter: 1284 loss: 7.95563722e-07
Iter: 1285 loss: 7.94828679e-07
Iter: 1286 loss: 7.97475366e-07
Iter: 1287 loss: 7.94655534e-07
Iter: 1288 loss: 7.93955508e-07
Iter: 1289 loss: 7.95399558e-07
Iter: 1290 loss: 7.93679e-07
Iter: 1291 loss: 7.92982519e-07
Iter: 1292 loss: 7.96503741e-07
Iter: 1293 loss: 7.92908509e-07
Iter: 1294 loss: 7.92293918e-07
Iter: 1295 loss: 7.93941354e-07
Iter: 1296 loss: 7.920504e-07
Iter: 1297 loss: 7.91449224e-07
Iter: 1298 loss: 7.91284492e-07
Iter: 1299 loss: 7.90934109e-07
Iter: 1300 loss: 7.90216859e-07
Iter: 1301 loss: 7.98283736e-07
Iter: 1302 loss: 7.90207e-07
Iter: 1303 loss: 7.89631542e-07
Iter: 1304 loss: 7.91328148e-07
Iter: 1305 loss: 7.89425883e-07
Iter: 1306 loss: 7.88896386e-07
Iter: 1307 loss: 7.90503577e-07
Iter: 1308 loss: 7.88761781e-07
Iter: 1309 loss: 7.88123771e-07
Iter: 1310 loss: 7.88386444e-07
Iter: 1311 loss: 7.87702277e-07
Iter: 1312 loss: 7.87071031e-07
Iter: 1313 loss: 7.87973931e-07
Iter: 1314 loss: 7.86729174e-07
Iter: 1315 loss: 7.86080363e-07
Iter: 1316 loss: 7.88386501e-07
Iter: 1317 loss: 7.85914949e-07
Iter: 1318 loss: 7.85203838e-07
Iter: 1319 loss: 7.85985776e-07
Iter: 1320 loss: 7.84836516e-07
Iter: 1321 loss: 7.83982728e-07
Iter: 1322 loss: 7.85671887e-07
Iter: 1323 loss: 7.83590963e-07
Iter: 1324 loss: 7.82818177e-07
Iter: 1325 loss: 7.85197244e-07
Iter: 1326 loss: 7.82645088e-07
Iter: 1327 loss: 7.81784479e-07
Iter: 1328 loss: 7.86053079e-07
Iter: 1329 loss: 7.81680569e-07
Iter: 1330 loss: 7.80996402e-07
Iter: 1331 loss: 7.8534265e-07
Iter: 1332 loss: 7.80950927e-07
Iter: 1333 loss: 7.8043422e-07
Iter: 1334 loss: 7.80309506e-07
Iter: 1335 loss: 7.79985726e-07
Iter: 1336 loss: 7.79297636e-07
Iter: 1337 loss: 7.84175199e-07
Iter: 1338 loss: 7.79232664e-07
Iter: 1339 loss: 7.78651952e-07
Iter: 1340 loss: 7.79971401e-07
Iter: 1341 loss: 7.78465449e-07
Iter: 1342 loss: 7.7792572e-07
Iter: 1343 loss: 7.8257608e-07
Iter: 1344 loss: 7.7790105e-07
Iter: 1345 loss: 7.77558796e-07
Iter: 1346 loss: 7.77095238e-07
Iter: 1347 loss: 7.77061e-07
Iter: 1348 loss: 7.76258616e-07
Iter: 1349 loss: 7.80819676e-07
Iter: 1350 loss: 7.76181537e-07
Iter: 1351 loss: 7.75683588e-07
Iter: 1352 loss: 7.75168701e-07
Iter: 1353 loss: 7.75044441e-07
Iter: 1354 loss: 7.74323098e-07
Iter: 1355 loss: 7.78090907e-07
Iter: 1356 loss: 7.7418207e-07
Iter: 1357 loss: 7.73556508e-07
Iter: 1358 loss: 7.75447461e-07
Iter: 1359 loss: 7.73376883e-07
Iter: 1360 loss: 7.7271e-07
Iter: 1361 loss: 7.74658361e-07
Iter: 1362 loss: 7.72432827e-07
Iter: 1363 loss: 7.71856e-07
Iter: 1364 loss: 7.73205102e-07
Iter: 1365 loss: 7.71610644e-07
Iter: 1366 loss: 7.70992e-07
Iter: 1367 loss: 7.75821604e-07
Iter: 1368 loss: 7.70941824e-07
Iter: 1369 loss: 7.70374186e-07
Iter: 1370 loss: 7.71072564e-07
Iter: 1371 loss: 7.70101224e-07
Iter: 1372 loss: 7.69603844e-07
Iter: 1373 loss: 7.70350653e-07
Iter: 1374 loss: 7.69324799e-07
Iter: 1375 loss: 7.68726863e-07
Iter: 1376 loss: 7.74569e-07
Iter: 1377 loss: 7.68682355e-07
Iter: 1378 loss: 7.68206917e-07
Iter: 1379 loss: 7.68716e-07
Iter: 1380 loss: 7.67965332e-07
Iter: 1381 loss: 7.67388315e-07
Iter: 1382 loss: 7.68815312e-07
Iter: 1383 loss: 7.67227277e-07
Iter: 1384 loss: 7.66707785e-07
Iter: 1385 loss: 7.67055781e-07
Iter: 1386 loss: 7.66419305e-07
Iter: 1387 loss: 7.65623099e-07
Iter: 1388 loss: 7.67445499e-07
Iter: 1389 loss: 7.65319214e-07
Iter: 1390 loss: 7.64643175e-07
Iter: 1391 loss: 7.66000539e-07
Iter: 1392 loss: 7.64448487e-07
Iter: 1393 loss: 7.63728394e-07
Iter: 1394 loss: 7.64964625e-07
Iter: 1395 loss: 7.63472485e-07
Iter: 1396 loss: 7.62761147e-07
Iter: 1397 loss: 7.63265689e-07
Iter: 1398 loss: 7.62368472e-07
Iter: 1399 loss: 7.61548336e-07
Iter: 1400 loss: 7.67443112e-07
Iter: 1401 loss: 7.61466822e-07
Iter: 1402 loss: 7.61032084e-07
Iter: 1403 loss: 7.6338938e-07
Iter: 1404 loss: 7.61001274e-07
Iter: 1405 loss: 7.60333876e-07
Iter: 1406 loss: 7.60419937e-07
Iter: 1407 loss: 7.59840418e-07
Iter: 1408 loss: 7.59175123e-07
Iter: 1409 loss: 7.64109927e-07
Iter: 1410 loss: 7.59129307e-07
Iter: 1411 loss: 7.58657e-07
Iter: 1412 loss: 7.60251282e-07
Iter: 1413 loss: 7.58510225e-07
Iter: 1414 loss: 7.58055762e-07
Iter: 1415 loss: 7.60083822e-07
Iter: 1416 loss: 7.57950147e-07
Iter: 1417 loss: 7.57492785e-07
Iter: 1418 loss: 7.56996542e-07
Iter: 1419 loss: 7.56912073e-07
Iter: 1420 loss: 7.56470968e-07
Iter: 1421 loss: 7.56451925e-07
Iter: 1422 loss: 7.56128657e-07
Iter: 1423 loss: 7.55810333e-07
Iter: 1424 loss: 7.55740416e-07
Iter: 1425 loss: 7.55128497e-07
Iter: 1426 loss: 7.5636251e-07
Iter: 1427 loss: 7.54832399e-07
Iter: 1428 loss: 7.54209509e-07
Iter: 1429 loss: 7.56679412e-07
Iter: 1430 loss: 7.53992367e-07
Iter: 1431 loss: 7.53415e-07
Iter: 1432 loss: 7.54593202e-07
Iter: 1433 loss: 7.53121299e-07
Iter: 1434 loss: 7.52458277e-07
Iter: 1435 loss: 7.52695883e-07
Iter: 1436 loss: 7.52006258e-07
Iter: 1437 loss: 7.51120808e-07
Iter: 1438 loss: 7.53770451e-07
Iter: 1439 loss: 7.50799359e-07
Iter: 1440 loss: 7.50203753e-07
Iter: 1441 loss: 7.53940867e-07
Iter: 1442 loss: 7.5009666e-07
Iter: 1443 loss: 7.4952959e-07
Iter: 1444 loss: 7.52758126e-07
Iter: 1445 loss: 7.49390495e-07
Iter: 1446 loss: 7.48767832e-07
Iter: 1447 loss: 7.49977175e-07
Iter: 1448 loss: 7.48528407e-07
Iter: 1449 loss: 7.4807258e-07
Iter: 1450 loss: 7.52400638e-07
Iter: 1451 loss: 7.4806519e-07
Iter: 1452 loss: 7.47595493e-07
Iter: 1453 loss: 7.47265233e-07
Iter: 1454 loss: 7.47122613e-07
Iter: 1455 loss: 7.46542412e-07
Iter: 1456 loss: 7.47201454e-07
Iter: 1457 loss: 7.46198907e-07
Iter: 1458 loss: 7.45622856e-07
Iter: 1459 loss: 7.52581911e-07
Iter: 1460 loss: 7.45591137e-07
Iter: 1461 loss: 7.45177772e-07
Iter: 1462 loss: 7.44937779e-07
Iter: 1463 loss: 7.44808744e-07
Iter: 1464 loss: 7.44093825e-07
Iter: 1465 loss: 7.45899968e-07
Iter: 1466 loss: 7.43927558e-07
Iter: 1467 loss: 7.43259591e-07
Iter: 1468 loss: 7.44752072e-07
Iter: 1469 loss: 7.43053874e-07
Iter: 1470 loss: 7.42361863e-07
Iter: 1471 loss: 7.44254748e-07
Iter: 1472 loss: 7.42163e-07
Iter: 1473 loss: 7.41501935e-07
Iter: 1474 loss: 7.42065936e-07
Iter: 1475 loss: 7.41121767e-07
Iter: 1476 loss: 7.40377345e-07
Iter: 1477 loss: 7.44830288e-07
Iter: 1478 loss: 7.40280143e-07
Iter: 1479 loss: 7.39684594e-07
Iter: 1480 loss: 7.41785129e-07
Iter: 1481 loss: 7.39521852e-07
Iter: 1482 loss: 7.38874519e-07
Iter: 1483 loss: 7.41909957e-07
Iter: 1484 loss: 7.38757194e-07
Iter: 1485 loss: 7.38258109e-07
Iter: 1486 loss: 7.40618248e-07
Iter: 1487 loss: 7.38188874e-07
Iter: 1488 loss: 7.3771497e-07
Iter: 1489 loss: 7.37803589e-07
Iter: 1490 loss: 7.37350888e-07
Iter: 1491 loss: 7.36824177e-07
Iter: 1492 loss: 7.41385179e-07
Iter: 1493 loss: 7.36778475e-07
Iter: 1494 loss: 7.36388415e-07
Iter: 1495 loss: 7.35829815e-07
Iter: 1496 loss: 7.35837489e-07
Iter: 1497 loss: 7.35166566e-07
Iter: 1498 loss: 7.36990387e-07
Iter: 1499 loss: 7.34968e-07
Iter: 1500 loss: 7.34337448e-07
Iter: 1501 loss: 7.41732379e-07
Iter: 1502 loss: 7.34311698e-07
Iter: 1503 loss: 7.3387e-07
Iter: 1504 loss: 7.34002299e-07
Iter: 1505 loss: 7.33515151e-07
Iter: 1506 loss: 7.32938133e-07
Iter: 1507 loss: 7.33025217e-07
Iter: 1508 loss: 7.32537501e-07
Iter: 1509 loss: 7.31779608e-07
Iter: 1510 loss: 7.35223921e-07
Iter: 1511 loss: 7.3163875e-07
Iter: 1512 loss: 7.30884381e-07
Iter: 1513 loss: 7.32138801e-07
Iter: 1514 loss: 7.30555428e-07
Iter: 1515 loss: 7.29970793e-07
Iter: 1516 loss: 7.35786216e-07
Iter: 1517 loss: 7.29968747e-07
Iter: 1518 loss: 7.29455735e-07
Iter: 1519 loss: 7.30496822e-07
Iter: 1520 loss: 7.29240583e-07
Iter: 1521 loss: 7.28661234e-07
Iter: 1522 loss: 7.33627928e-07
Iter: 1523 loss: 7.28643784e-07
Iter: 1524 loss: 7.28335351e-07
Iter: 1525 loss: 7.27994859e-07
Iter: 1526 loss: 7.27925624e-07
Iter: 1527 loss: 7.27320639e-07
Iter: 1528 loss: 7.30407692e-07
Iter: 1529 loss: 7.2720627e-07
Iter: 1530 loss: 7.26643179e-07
Iter: 1531 loss: 7.27798692e-07
Iter: 1532 loss: 7.26419e-07
Iter: 1533 loss: 7.25859081e-07
Iter: 1534 loss: 7.25829068e-07
Iter: 1535 loss: 7.25455266e-07
Iter: 1536 loss: 7.24733354e-07
Iter: 1537 loss: 7.28226382e-07
Iter: 1538 loss: 7.24619554e-07
Iter: 1539 loss: 7.23964206e-07
Iter: 1540 loss: 7.2669792e-07
Iter: 1541 loss: 7.23824542e-07
Iter: 1542 loss: 7.23328071e-07
Iter: 1543 loss: 7.24804522e-07
Iter: 1544 loss: 7.23211599e-07
Iter: 1545 loss: 7.22652658e-07
Iter: 1546 loss: 7.24057259e-07
Iter: 1547 loss: 7.22473544e-07
Iter: 1548 loss: 7.21903632e-07
Iter: 1549 loss: 7.22816424e-07
Iter: 1550 loss: 7.21709625e-07
Iter: 1551 loss: 7.21129e-07
Iter: 1552 loss: 7.21702918e-07
Iter: 1553 loss: 7.20836056e-07
Iter: 1554 loss: 7.20241246e-07
Iter: 1555 loss: 7.21717583e-07
Iter: 1556 loss: 7.20055596e-07
Iter: 1557 loss: 7.19526952e-07
Iter: 1558 loss: 7.25118298e-07
Iter: 1559 loss: 7.1955418e-07
Iter: 1560 loss: 7.18998535e-07
Iter: 1561 loss: 7.2046447e-07
Iter: 1562 loss: 7.1880072e-07
Iter: 1563 loss: 7.18391277e-07
Iter: 1564 loss: 7.17975126e-07
Iter: 1565 loss: 7.17929652e-07
Iter: 1566 loss: 7.17354737e-07
Iter: 1567 loss: 7.22653112e-07
Iter: 1568 loss: 7.17360081e-07
Iter: 1569 loss: 7.16870886e-07
Iter: 1570 loss: 7.1767613e-07
Iter: 1571 loss: 7.16652892e-07
Iter: 1572 loss: 7.16101397e-07
Iter: 1573 loss: 7.16783063e-07
Iter: 1574 loss: 7.15814451e-07
Iter: 1575 loss: 7.15136309e-07
Iter: 1576 loss: 7.17111504e-07
Iter: 1577 loss: 7.14966518e-07
Iter: 1578 loss: 7.14412067e-07
Iter: 1579 loss: 7.14246312e-07
Iter: 1580 loss: 7.13975737e-07
Iter: 1581 loss: 7.13286113e-07
Iter: 1582 loss: 7.18993647e-07
Iter: 1583 loss: 7.13254565e-07
Iter: 1584 loss: 7.12714382e-07
Iter: 1585 loss: 7.14415705e-07
Iter: 1586 loss: 7.12533904e-07
Iter: 1587 loss: 7.11978942e-07
Iter: 1588 loss: 7.12929364e-07
Iter: 1589 loss: 7.11698817e-07
Iter: 1590 loss: 7.11179496e-07
Iter: 1591 loss: 7.1537e-07
Iter: 1592 loss: 7.11177108e-07
Iter: 1593 loss: 7.10741688e-07
Iter: 1594 loss: 7.10597419e-07
Iter: 1595 loss: 7.10365498e-07
Iter: 1596 loss: 7.0979587e-07
Iter: 1597 loss: 7.13147244e-07
Iter: 1598 loss: 7.09717597e-07
Iter: 1599 loss: 7.09101528e-07
Iter: 1600 loss: 7.12168116e-07
Iter: 1601 loss: 7.09072197e-07
Iter: 1602 loss: 7.08735513e-07
Iter: 1603 loss: 7.08213463e-07
Iter: 1604 loss: 7.08205e-07
Iter: 1605 loss: 7.07473248e-07
Iter: 1606 loss: 7.08454081e-07
Iter: 1607 loss: 7.07102174e-07
Iter: 1608 loss: 7.06547439e-07
Iter: 1609 loss: 7.06544768e-07
Iter: 1610 loss: 7.06116225e-07
Iter: 1611 loss: 7.06549031e-07
Iter: 1612 loss: 7.0577687e-07
Iter: 1613 loss: 7.05236118e-07
Iter: 1614 loss: 7.06046762e-07
Iter: 1615 loss: 7.04960826e-07
Iter: 1616 loss: 7.04332422e-07
Iter: 1617 loss: 7.05970933e-07
Iter: 1618 loss: 7.04142e-07
Iter: 1619 loss: 7.03634214e-07
Iter: 1620 loss: 7.05330876e-07
Iter: 1621 loss: 7.03466469e-07
Iter: 1622 loss: 7.02905197e-07
Iter: 1623 loss: 7.0412284e-07
Iter: 1624 loss: 7.02756267e-07
Iter: 1625 loss: 7.02248087e-07
Iter: 1626 loss: 7.04264551e-07
Iter: 1627 loss: 7.02136731e-07
Iter: 1628 loss: 7.0155977e-07
Iter: 1629 loss: 7.03144e-07
Iter: 1630 loss: 7.01271e-07
Iter: 1631 loss: 7.00878275e-07
Iter: 1632 loss: 7.01880936e-07
Iter: 1633 loss: 7.00703595e-07
Iter: 1634 loss: 7.00184785e-07
Iter: 1635 loss: 7.03488354e-07
Iter: 1636 loss: 7.00136297e-07
Iter: 1637 loss: 6.99752832e-07
Iter: 1638 loss: 6.99772727e-07
Iter: 1639 loss: 6.99407224e-07
Iter: 1640 loss: 6.98871304e-07
Iter: 1641 loss: 6.98527288e-07
Iter: 1642 loss: 6.98399163e-07
Iter: 1643 loss: 6.9765332e-07
Iter: 1644 loss: 7.06156925e-07
Iter: 1645 loss: 6.97673158e-07
Iter: 1646 loss: 6.97235521e-07
Iter: 1647 loss: 6.9871794e-07
Iter: 1648 loss: 6.97115638e-07
Iter: 1649 loss: 6.96675045e-07
Iter: 1650 loss: 6.96677262e-07
Iter: 1651 loss: 6.96338816e-07
Iter: 1652 loss: 6.9577186e-07
Iter: 1653 loss: 7.03187652e-07
Iter: 1654 loss: 6.95783058e-07
Iter: 1655 loss: 6.95441e-07
Iter: 1656 loss: 6.9515329e-07
Iter: 1657 loss: 6.95096048e-07
Iter: 1658 loss: 6.9458315e-07
Iter: 1659 loss: 6.94943651e-07
Iter: 1660 loss: 6.94203777e-07
Iter: 1661 loss: 6.93573043e-07
Iter: 1662 loss: 6.96724e-07
Iter: 1663 loss: 6.93402399e-07
Iter: 1664 loss: 6.92908202e-07
Iter: 1665 loss: 6.98839813e-07
Iter: 1666 loss: 6.92911271e-07
Iter: 1667 loss: 6.9250757e-07
Iter: 1668 loss: 6.9249711e-07
Iter: 1669 loss: 6.92206527e-07
Iter: 1670 loss: 6.91805894e-07
Iter: 1671 loss: 6.91794071e-07
Iter: 1672 loss: 6.91507921e-07
Iter: 1673 loss: 6.9093943e-07
Iter: 1674 loss: 7.00375381e-07
Iter: 1675 loss: 6.90920899e-07
Iter: 1676 loss: 6.90271236e-07
Iter: 1677 loss: 6.94670689e-07
Iter: 1678 loss: 6.90281183e-07
Iter: 1679 loss: 6.89777721e-07
Iter: 1680 loss: 6.90382535e-07
Iter: 1681 loss: 6.8954e-07
Iter: 1682 loss: 6.88996e-07
Iter: 1683 loss: 6.91573405e-07
Iter: 1684 loss: 6.88919954e-07
Iter: 1685 loss: 6.88473847e-07
Iter: 1686 loss: 6.89501178e-07
Iter: 1687 loss: 6.88273758e-07
Iter: 1688 loss: 6.87777629e-07
Iter: 1689 loss: 6.90288687e-07
Iter: 1690 loss: 6.87671445e-07
Iter: 1691 loss: 6.87317595e-07
Iter: 1692 loss: 6.87148031e-07
Iter: 1693 loss: 6.86963631e-07
Iter: 1694 loss: 6.86327e-07
Iter: 1695 loss: 6.88986233e-07
Iter: 1696 loss: 6.8624621e-07
Iter: 1697 loss: 6.85717623e-07
Iter: 1698 loss: 6.86859153e-07
Iter: 1699 loss: 6.85445343e-07
Iter: 1700 loss: 6.85038742e-07
Iter: 1701 loss: 6.87045599e-07
Iter: 1702 loss: 6.8497485e-07
Iter: 1703 loss: 6.84521353e-07
Iter: 1704 loss: 6.87107502e-07
Iter: 1705 loss: 6.84466954e-07
Iter: 1706 loss: 6.83976737e-07
Iter: 1707 loss: 6.84674e-07
Iter: 1708 loss: 6.83770281e-07
Iter: 1709 loss: 6.83385281e-07
Iter: 1710 loss: 6.85624855e-07
Iter: 1711 loss: 6.83332644e-07
Iter: 1712 loss: 6.82960206e-07
Iter: 1713 loss: 6.82548375e-07
Iter: 1714 loss: 6.82514269e-07
Iter: 1715 loss: 6.81922245e-07
Iter: 1716 loss: 6.83708549e-07
Iter: 1717 loss: 6.8173108e-07
Iter: 1718 loss: 6.81202494e-07
Iter: 1719 loss: 6.82953e-07
Iter: 1720 loss: 6.81043389e-07
Iter: 1721 loss: 6.80534868e-07
Iter: 1722 loss: 6.82902737e-07
Iter: 1723 loss: 6.80457447e-07
Iter: 1724 loss: 6.79993718e-07
Iter: 1725 loss: 6.82396148e-07
Iter: 1726 loss: 6.79881964e-07
Iter: 1727 loss: 6.7951305e-07
Iter: 1728 loss: 6.79825234e-07
Iter: 1729 loss: 6.79297614e-07
Iter: 1730 loss: 6.78826268e-07
Iter: 1731 loss: 6.80099845e-07
Iter: 1732 loss: 6.78669608e-07
Iter: 1733 loss: 6.78125843e-07
Iter: 1734 loss: 6.78310187e-07
Iter: 1735 loss: 6.77737546e-07
Iter: 1736 loss: 6.77227831e-07
Iter: 1737 loss: 6.80594553e-07
Iter: 1738 loss: 6.77175819e-07
Iter: 1739 loss: 6.76774619e-07
Iter: 1740 loss: 6.80801804e-07
Iter: 1741 loss: 6.76764557e-07
Iter: 1742 loss: 6.76441175e-07
Iter: 1743 loss: 6.76742161e-07
Iter: 1744 loss: 6.7626479e-07
Iter: 1745 loss: 6.75842784e-07
Iter: 1746 loss: 6.76626485e-07
Iter: 1747 loss: 6.75690785e-07
Iter: 1748 loss: 6.75234e-07
Iter: 1749 loss: 6.76329933e-07
Iter: 1750 loss: 6.75082788e-07
Iter: 1751 loss: 6.74733258e-07
Iter: 1752 loss: 6.75571414e-07
Iter: 1753 loss: 6.74592457e-07
Iter: 1754 loss: 6.74060175e-07
Iter: 1755 loss: 6.74010948e-07
Iter: 1756 loss: 6.73663521e-07
Iter: 1757 loss: 6.73103784e-07
Iter: 1758 loss: 6.73903457e-07
Iter: 1759 loss: 6.72777333e-07
Iter: 1760 loss: 6.72218277e-07
Iter: 1761 loss: 6.7955807e-07
Iter: 1762 loss: 6.72206511e-07
Iter: 1763 loss: 6.71740509e-07
Iter: 1764 loss: 6.7353011e-07
Iter: 1765 loss: 6.71611588e-07
Iter: 1766 loss: 6.71228122e-07
Iter: 1767 loss: 6.71040084e-07
Iter: 1768 loss: 6.70842496e-07
Iter: 1769 loss: 6.70295321e-07
Iter: 1770 loss: 6.72237206e-07
Iter: 1771 loss: 6.70174927e-07
Iter: 1772 loss: 6.6968687e-07
Iter: 1773 loss: 6.72376e-07
Iter: 1774 loss: 6.6960331e-07
Iter: 1775 loss: 6.69167832e-07
Iter: 1776 loss: 6.71339308e-07
Iter: 1777 loss: 6.69079327e-07
Iter: 1778 loss: 6.68783173e-07
Iter: 1779 loss: 6.7042248e-07
Iter: 1780 loss: 6.68737812e-07
Iter: 1781 loss: 6.68417272e-07
Iter: 1782 loss: 6.68133055e-07
Iter: 1783 loss: 6.68071266e-07
Iter: 1784 loss: 6.67577751e-07
Iter: 1785 loss: 6.70311465e-07
Iter: 1786 loss: 6.67535687e-07
Iter: 1787 loss: 6.67146878e-07
Iter: 1788 loss: 6.67982704e-07
Iter: 1789 loss: 6.67002155e-07
Iter: 1790 loss: 6.66614e-07
Iter: 1791 loss: 6.66631308e-07
Iter: 1792 loss: 6.66299911e-07
Iter: 1793 loss: 6.65737957e-07
Iter: 1794 loss: 6.67112886e-07
Iter: 1795 loss: 6.65533207e-07
Iter: 1796 loss: 6.6508278e-07
Iter: 1797 loss: 6.67321387e-07
Iter: 1798 loss: 6.65025e-07
Iter: 1799 loss: 6.6450508e-07
Iter: 1800 loss: 6.66234314e-07
Iter: 1801 loss: 6.64396e-07
Iter: 1802 loss: 6.63988772e-07
Iter: 1803 loss: 6.65887569e-07
Iter: 1804 loss: 6.63925505e-07
Iter: 1805 loss: 6.63521e-07
Iter: 1806 loss: 6.635467e-07
Iter: 1807 loss: 6.63235824e-07
Iter: 1808 loss: 6.62742821e-07
Iter: 1809 loss: 6.64295499e-07
Iter: 1810 loss: 6.62630782e-07
Iter: 1811 loss: 6.62209914e-07
Iter: 1812 loss: 6.64684876e-07
Iter: 1813 loss: 6.62171487e-07
Iter: 1814 loss: 6.61662909e-07
Iter: 1815 loss: 6.62910168e-07
Iter: 1816 loss: 6.6153e-07
Iter: 1817 loss: 6.61182753e-07
Iter: 1818 loss: 6.61275692e-07
Iter: 1819 loss: 6.60944806e-07
Iter: 1820 loss: 6.60430203e-07
Iter: 1821 loss: 6.62456159e-07
Iter: 1822 loss: 6.60321291e-07
Iter: 1823 loss: 6.59909801e-07
Iter: 1824 loss: 6.60441e-07
Iter: 1825 loss: 6.59719717e-07
Iter: 1826 loss: 6.59277759e-07
Iter: 1827 loss: 6.60961234e-07
Iter: 1828 loss: 6.59201646e-07
Iter: 1829 loss: 6.5882773e-07
Iter: 1830 loss: 6.59272928e-07
Iter: 1831 loss: 6.58543627e-07
Iter: 1832 loss: 6.58140777e-07
Iter: 1833 loss: 6.58284875e-07
Iter: 1834 loss: 6.57786131e-07
Iter: 1835 loss: 6.57349119e-07
Iter: 1836 loss: 6.62882712e-07
Iter: 1837 loss: 6.57357191e-07
Iter: 1838 loss: 6.56930069e-07
Iter: 1839 loss: 6.57753844e-07
Iter: 1840 loss: 6.56828263e-07
Iter: 1841 loss: 6.56431666e-07
Iter: 1842 loss: 6.56475436e-07
Iter: 1843 loss: 6.56099132e-07
Iter: 1844 loss: 6.55639951e-07
Iter: 1845 loss: 6.58099111e-07
Iter: 1846 loss: 6.55587314e-07
Iter: 1847 loss: 6.55227097e-07
Iter: 1848 loss: 6.58311251e-07
Iter: 1849 loss: 6.55180486e-07
Iter: 1850 loss: 6.54863811e-07
Iter: 1851 loss: 6.5527297e-07
Iter: 1852 loss: 6.54662699e-07
Iter: 1853 loss: 6.54213125e-07
Iter: 1854 loss: 6.54267922e-07
Iter: 1855 loss: 6.53951929e-07
Iter: 1856 loss: 6.53571817e-07
Iter: 1857 loss: 6.56368798e-07
Iter: 1858 loss: 6.53534698e-07
Iter: 1859 loss: 6.53187044e-07
Iter: 1860 loss: 6.5351486e-07
Iter: 1861 loss: 6.52933068e-07
Iter: 1862 loss: 6.52522658e-07
Iter: 1863 loss: 6.53616553e-07
Iter: 1864 loss: 6.52358665e-07
Iter: 1865 loss: 6.51873734e-07
Iter: 1866 loss: 6.52151471e-07
Iter: 1867 loss: 6.51575817e-07
Iter: 1868 loss: 6.51067467e-07
Iter: 1869 loss: 6.54930375e-07
Iter: 1870 loss: 6.51018354e-07
Iter: 1871 loss: 6.50566903e-07
Iter: 1872 loss: 6.51350888e-07
Iter: 1873 loss: 6.50346522e-07
Iter: 1874 loss: 6.49975846e-07
Iter: 1875 loss: 6.53156917e-07
Iter: 1876 loss: 6.49975448e-07
Iter: 1877 loss: 6.49590675e-07
Iter: 1878 loss: 6.49436743e-07
Iter: 1879 loss: 6.49277922e-07
Iter: 1880 loss: 6.48834771e-07
Iter: 1881 loss: 6.50380571e-07
Iter: 1882 loss: 6.48713922e-07
Iter: 1883 loss: 6.48411174e-07
Iter: 1884 loss: 6.51773121e-07
Iter: 1885 loss: 6.4836081e-07
Iter: 1886 loss: 6.48030721e-07
Iter: 1887 loss: 6.4806062e-07
Iter: 1888 loss: 6.47800334e-07
Iter: 1889 loss: 6.47464276e-07
Iter: 1890 loss: 6.47444722e-07
Iter: 1891 loss: 6.4718256e-07
Iter: 1892 loss: 6.46661135e-07
Iter: 1893 loss: 6.49987783e-07
Iter: 1894 loss: 6.46607759e-07
Iter: 1895 loss: 6.4623913e-07
Iter: 1896 loss: 6.46822912e-07
Iter: 1897 loss: 6.46020681e-07
Iter: 1898 loss: 6.45607372e-07
Iter: 1899 loss: 6.4686742e-07
Iter: 1900 loss: 6.45453497e-07
Iter: 1901 loss: 6.45002e-07
Iter: 1902 loss: 6.45628347e-07
Iter: 1903 loss: 6.44776151e-07
Iter: 1904 loss: 6.44323904e-07
Iter: 1905 loss: 6.45380624e-07
Iter: 1906 loss: 6.4418532e-07
Iter: 1907 loss: 6.43651674e-07
Iter: 1908 loss: 6.45592877e-07
Iter: 1909 loss: 6.43479211e-07
Iter: 1910 loss: 6.43107342e-07
Iter: 1911 loss: 6.4572157e-07
Iter: 1912 loss: 6.43021053e-07
Iter: 1913 loss: 6.42696477e-07
Iter: 1914 loss: 6.43494104e-07
Iter: 1915 loss: 6.42584666e-07
Iter: 1916 loss: 6.42194948e-07
Iter: 1917 loss: 6.42244743e-07
Iter: 1918 loss: 6.41914539e-07
Iter: 1919 loss: 6.41474458e-07
Iter: 1920 loss: 6.45701732e-07
Iter: 1921 loss: 6.41448651e-07
Iter: 1922 loss: 6.41083716e-07
Iter: 1923 loss: 6.43154237e-07
Iter: 1924 loss: 6.41042334e-07
Iter: 1925 loss: 6.40811436e-07
Iter: 1926 loss: 6.4020486e-07
Iter: 1927 loss: 6.44547583e-07
Iter: 1928 loss: 6.40118628e-07
Iter: 1929 loss: 6.39568725e-07
Iter: 1930 loss: 6.39569635e-07
Iter: 1931 loss: 6.39193217e-07
Iter: 1932 loss: 6.40725432e-07
Iter: 1933 loss: 6.39113296e-07
Iter: 1934 loss: 6.38755e-07
Iter: 1935 loss: 6.3863564e-07
Iter: 1936 loss: 6.3842424e-07
Iter: 1937 loss: 6.3793857e-07
Iter: 1938 loss: 6.39106474e-07
Iter: 1939 loss: 6.37785092e-07
Iter: 1940 loss: 6.37231949e-07
Iter: 1941 loss: 6.40762551e-07
Iter: 1942 loss: 6.37246103e-07
Iter: 1943 loss: 6.36825291e-07
Iter: 1944 loss: 6.37351832e-07
Iter: 1945 loss: 6.36615084e-07
Iter: 1946 loss: 6.36197115e-07
Iter: 1947 loss: 6.38703568e-07
Iter: 1948 loss: 6.36130778e-07
Iter: 1949 loss: 6.35787671e-07
Iter: 1950 loss: 6.36538289e-07
Iter: 1951 loss: 6.35642436e-07
Iter: 1952 loss: 6.35330707e-07
Iter: 1953 loss: 6.36256232e-07
Iter: 1954 loss: 6.35220317e-07
Iter: 1955 loss: 6.34919331e-07
Iter: 1956 loss: 6.37445794e-07
Iter: 1957 loss: 6.34890284e-07
Iter: 1958 loss: 6.34624428e-07
Iter: 1959 loss: 6.34292633e-07
Iter: 1960 loss: 6.34248636e-07
Iter: 1961 loss: 6.33873867e-07
Iter: 1962 loss: 6.36158518e-07
Iter: 1963 loss: 6.33801449e-07
Iter: 1964 loss: 6.3345351e-07
Iter: 1965 loss: 6.33276898e-07
Iter: 1966 loss: 6.33090622e-07
Iter: 1967 loss: 6.32622232e-07
Iter: 1968 loss: 6.36439268e-07
Iter: 1969 loss: 6.32604269e-07
Iter: 1970 loss: 6.32176523e-07
Iter: 1971 loss: 6.34102207e-07
Iter: 1972 loss: 6.32075228e-07
Iter: 1973 loss: 6.31816874e-07
Iter: 1974 loss: 6.31537546e-07
Iter: 1975 loss: 6.31446142e-07
Iter: 1976 loss: 6.31016803e-07
Iter: 1977 loss: 6.33161619e-07
Iter: 1978 loss: 6.3095e-07
Iter: 1979 loss: 6.30528234e-07
Iter: 1980 loss: 6.32841306e-07
Iter: 1981 loss: 6.30507827e-07
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.8
+ date
Sat Nov  7 16:00:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.8/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.8!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.8!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi2.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi3
+ date
Sat Nov  7 16:00:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi3/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi3!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi3!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi2_phi3/500_500_500_500_1
+ for psi in $PSI
+ for layers in $LAYERS
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0
+ date
Sat Nov  7 16:00:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.4
+ date
Sat Nov  7 16:00:32 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.4/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.4!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.4!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.8
+ date
Sat Nov  7 16:00:33 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.8/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.8!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.8!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi0.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.2
+ date
Sat Nov  7 16:00:33 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.2/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.2!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.2!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.6
+ date
Sat Nov  7 16:00:33 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.6/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.6!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.6!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi1.6/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2
+ date
Sat Nov  7 16:00:33 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.4
+ date
Sat Nov  7 16:00:33 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.4/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.4!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.4!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.4/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.8
+ date
Sat Nov  7 16:00:33 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.8/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.8!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.8!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi2.8/500_500_500_500_1
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi3
+ date
Sat Nov  7 16:00:33 EST 2020
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi3/500_500_500_500_1 ']'
+ echo 'No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi3!'
No model /home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi3!
++ basename experiments.final/script73
+ '[' -r STOP.script73 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output61/f2_psi3_phi3/500_500_500_500_1
