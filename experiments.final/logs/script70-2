+ RUN=2
+ export CUDA_VISIBLE_DEVICES=2
+ CUDA_VISIBLE_DEVICES=2
+ LAYERS='k4 k3 k2'
+ case $RUN in
+ PSI='0 1'
++ pwd
+ OUT=/home/mrdouglas/Manifold/experiments.final/output70
+ for fn in f1 f2
+ case $fn in
+ OPT=--phi
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0
+ date
Tue Oct 27 14:42:53 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f19227648c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f192276b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f19227c5c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18e0066730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18e005e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18e00acbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18e00d46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18e0037158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18e0043b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18787df620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18787840d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878785ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878748598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878764048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f187876fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f187872c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f187872df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18786ef950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878695400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f187869ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18786518c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878678378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878600d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18785bb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18785db2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18785e6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18785a87b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f187854d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878552c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18784fd730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18785341e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18784bbbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f18784ed6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1878496158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f187849ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f187845e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.60515429e-05
Iter: 2 loss: 8.57218402e-05
Iter: 3 loss: 8.44442402e-05
Iter: 4 loss: 7.90505583e-05
Iter: 5 loss: 7.67654856e-05
Iter: 6 loss: 7.27242877e-05
Iter: 7 loss: 6.57801138e-05
Iter: 8 loss: 9.54770367e-05
Iter: 9 loss: 6.43234671e-05
Iter: 10 loss: 6.07030743e-05
Iter: 11 loss: 6.42010418e-05
Iter: 12 loss: 5.86474926e-05
Iter: 13 loss: 5.54971448e-05
Iter: 14 loss: 9.66835432e-05
Iter: 15 loss: 5.54791914e-05
Iter: 16 loss: 5.31198566e-05
Iter: 17 loss: 5.24554271e-05
Iter: 18 loss: 5.10192294e-05
Iter: 19 loss: 4.85422206e-05
Iter: 20 loss: 5.35867948e-05
Iter: 21 loss: 4.75449779e-05
Iter: 22 loss: 4.57743045e-05
Iter: 23 loss: 6.84955594e-05
Iter: 24 loss: 4.57618662e-05
Iter: 25 loss: 4.42950331e-05
Iter: 26 loss: 4.92347172e-05
Iter: 27 loss: 4.38986172e-05
Iter: 28 loss: 4.29441498e-05
Iter: 29 loss: 4.29549327e-05
Iter: 30 loss: 4.21843433e-05
Iter: 31 loss: 4.13085363e-05
Iter: 32 loss: 4.92223298e-05
Iter: 33 loss: 4.12682e-05
Iter: 34 loss: 4.06270847e-05
Iter: 35 loss: 4.62218522e-05
Iter: 36 loss: 4.05937972e-05
Iter: 37 loss: 4.02095175e-05
Iter: 38 loss: 3.99295604e-05
Iter: 39 loss: 3.97987824e-05
Iter: 40 loss: 3.9391336e-05
Iter: 41 loss: 4.42228848e-05
Iter: 42 loss: 3.9385759e-05
Iter: 43 loss: 3.90304704e-05
Iter: 44 loss: 3.97473086e-05
Iter: 45 loss: 3.88862245e-05
Iter: 46 loss: 3.85980675e-05
Iter: 47 loss: 3.85156673e-05
Iter: 48 loss: 3.8340746e-05
Iter: 49 loss: 3.79920057e-05
Iter: 50 loss: 3.91881404e-05
Iter: 51 loss: 3.78993136e-05
Iter: 52 loss: 3.76086973e-05
Iter: 53 loss: 3.88200642e-05
Iter: 54 loss: 3.7546477e-05
Iter: 55 loss: 3.73745861e-05
Iter: 56 loss: 3.73739531e-05
Iter: 57 loss: 3.72295617e-05
Iter: 58 loss: 3.73880612e-05
Iter: 59 loss: 3.71509086e-05
Iter: 60 loss: 3.70217676e-05
Iter: 61 loss: 3.70765774e-05
Iter: 62 loss: 3.69333175e-05
Iter: 63 loss: 3.68035799e-05
Iter: 64 loss: 3.76913631e-05
Iter: 65 loss: 3.67909452e-05
Iter: 66 loss: 3.66883687e-05
Iter: 67 loss: 3.75269665e-05
Iter: 68 loss: 3.6681944e-05
Iter: 69 loss: 3.66121603e-05
Iter: 70 loss: 3.65850428e-05
Iter: 71 loss: 3.65473097e-05
Iter: 72 loss: 3.64708176e-05
Iter: 73 loss: 3.73655e-05
Iter: 74 loss: 3.6469668e-05
Iter: 75 loss: 3.64086809e-05
Iter: 76 loss: 3.64645311e-05
Iter: 77 loss: 3.63733634e-05
Iter: 78 loss: 3.63142608e-05
Iter: 79 loss: 3.63833678e-05
Iter: 80 loss: 3.62829232e-05
Iter: 81 loss: 3.62332576e-05
Iter: 82 loss: 3.62332248e-05
Iter: 83 loss: 3.61941966e-05
Iter: 84 loss: 3.61776401e-05
Iter: 85 loss: 3.61573839e-05
Iter: 86 loss: 3.61113816e-05
Iter: 87 loss: 3.61889179e-05
Iter: 88 loss: 3.60906415e-05
Iter: 89 loss: 3.60551967e-05
Iter: 90 loss: 3.6582911e-05
Iter: 91 loss: 3.60552294e-05
Iter: 92 loss: 3.60251579e-05
Iter: 93 loss: 3.60411141e-05
Iter: 94 loss: 3.60052509e-05
Iter: 95 loss: 3.59754486e-05
Iter: 96 loss: 3.59871301e-05
Iter: 97 loss: 3.59549304e-05
Iter: 98 loss: 3.59214973e-05
Iter: 99 loss: 3.60373051e-05
Iter: 100 loss: 3.59126861e-05
Iter: 101 loss: 3.58839752e-05
Iter: 102 loss: 3.59706755e-05
Iter: 103 loss: 3.58755e-05
Iter: 104 loss: 3.58506659e-05
Iter: 105 loss: 3.59381374e-05
Iter: 106 loss: 3.58442921e-05
Iter: 107 loss: 3.58281904e-05
Iter: 108 loss: 3.60781924e-05
Iter: 109 loss: 3.58281795e-05
Iter: 110 loss: 3.5814046e-05
Iter: 111 loss: 3.5851448e-05
Iter: 112 loss: 3.58093312e-05
Iter: 113 loss: 3.57983299e-05
Iter: 114 loss: 3.57934587e-05
Iter: 115 loss: 3.57878671e-05
Iter: 116 loss: 3.57744066e-05
Iter: 117 loss: 3.58521138e-05
Iter: 118 loss: 3.57726385e-05
Iter: 119 loss: 3.57617828e-05
Iter: 120 loss: 3.5866251e-05
Iter: 121 loss: 3.57614699e-05
Iter: 122 loss: 3.5754194e-05
Iter: 123 loss: 3.57543031e-05
Iter: 124 loss: 3.57484969e-05
Iter: 125 loss: 3.57408135e-05
Iter: 126 loss: 3.5822115e-05
Iter: 127 loss: 3.57406789e-05
Iter: 128 loss: 3.57344616e-05
Iter: 129 loss: 3.57361423e-05
Iter: 130 loss: 3.57299286e-05
Iter: 131 loss: 3.57233876e-05
Iter: 132 loss: 3.57280078e-05
Iter: 133 loss: 3.57192112e-05
Iter: 134 loss: 3.57128374e-05
Iter: 135 loss: 3.57711979e-05
Iter: 136 loss: 3.571259e-05
Iter: 137 loss: 3.57069075e-05
Iter: 138 loss: 3.57314639e-05
Iter: 139 loss: 3.57057543e-05
Iter: 140 loss: 3.57015851e-05
Iter: 141 loss: 3.56997771e-05
Iter: 142 loss: 3.56976e-05
Iter: 143 loss: 3.56921555e-05
Iter: 144 loss: 3.57081699e-05
Iter: 145 loss: 3.56905075e-05
Iter: 146 loss: 3.56867167e-05
Iter: 147 loss: 3.57404497e-05
Iter: 148 loss: 3.56866876e-05
Iter: 149 loss: 3.56832825e-05
Iter: 150 loss: 3.56888559e-05
Iter: 151 loss: 3.56817509e-05
Iter: 152 loss: 3.56788587e-05
Iter: 153 loss: 3.56778146e-05
Iter: 154 loss: 3.56762393e-05
Iter: 155 loss: 3.56724049e-05
Iter: 156 loss: 3.56840246e-05
Iter: 157 loss: 3.56712844e-05
Iter: 158 loss: 3.56679302e-05
Iter: 159 loss: 3.56788551e-05
Iter: 160 loss: 3.56669261e-05
Iter: 161 loss: 3.56644596e-05
Iter: 162 loss: 3.56828095e-05
Iter: 163 loss: 3.5664285e-05
Iter: 164 loss: 3.56622404e-05
Iter: 165 loss: 3.56853416e-05
Iter: 166 loss: 3.56622331e-05
Iter: 167 loss: 3.56610035e-05
Iter: 168 loss: 3.56595483e-05
Iter: 169 loss: 3.5659381e-05
Iter: 170 loss: 3.56576202e-05
Iter: 171 loss: 3.56636956e-05
Iter: 172 loss: 3.56570235e-05
Iter: 173 loss: 3.56558157e-05
Iter: 174 loss: 3.56558121e-05
Iter: 175 loss: 3.56547716e-05
Iter: 176 loss: 3.5654266e-05
Iter: 177 loss: 3.5653833e-05
Iter: 178 loss: 3.5652658e-05
Iter: 179 loss: 3.56604141e-05
Iter: 180 loss: 3.56525925e-05
Iter: 181 loss: 3.56515811e-05
Iter: 182 loss: 3.56540841e-05
Iter: 183 loss: 3.56510791e-05
Iter: 184 loss: 3.5650246e-05
Iter: 185 loss: 3.56505152e-05
Iter: 186 loss: 3.56496566e-05
Iter: 187 loss: 3.56487108e-05
Iter: 188 loss: 3.56531673e-05
Iter: 189 loss: 3.56486198e-05
Iter: 190 loss: 3.56477685e-05
Iter: 191 loss: 3.5655863e-05
Iter: 192 loss: 3.56477576e-05
Iter: 193 loss: 3.56471937e-05
Iter: 194 loss: 3.56470337e-05
Iter: 195 loss: 3.56466699e-05
Iter: 196 loss: 3.56460405e-05
Iter: 197 loss: 3.56470482e-05
Iter: 198 loss: 3.5645764e-05
Iter: 199 loss: 3.56450801e-05
Iter: 200 loss: 3.56471937e-05
Iter: 201 loss: 3.564488e-05
Iter: 202 loss: 3.56442833e-05
Iter: 203 loss: 3.56464188e-05
Iter: 204 loss: 3.56442324e-05
Iter: 205 loss: 3.56438031e-05
Iter: 206 loss: 3.56497767e-05
Iter: 207 loss: 3.56437777e-05
Iter: 208 loss: 3.56433957e-05
Iter: 209 loss: 3.5643905e-05
Iter: 210 loss: 3.56432211e-05
Iter: 211 loss: 3.564297e-05
Iter: 212 loss: 3.56430246e-05
Iter: 213 loss: 3.56427627e-05
Iter: 214 loss: 3.56424425e-05
Iter: 215 loss: 3.56454e-05
Iter: 216 loss: 3.56423479e-05
Iter: 217 loss: 3.56420569e-05
Iter: 218 loss: 3.56437558e-05
Iter: 219 loss: 3.56420715e-05
Iter: 220 loss: 3.56418823e-05
Iter: 221 loss: 3.56416422e-05
Iter: 222 loss: 3.56417e-05
Iter: 223 loss: 3.56414675e-05
Iter: 224 loss: 3.56425335e-05
Iter: 225 loss: 3.56414239e-05
Iter: 226 loss: 3.56412129e-05
Iter: 227 loss: 3.5643774e-05
Iter: 228 loss: 3.56412784e-05
Iter: 229 loss: 3.56410965e-05
Iter: 230 loss: 3.56410128e-05
Iter: 231 loss: 3.56409255e-05
Iter: 232 loss: 3.56407836e-05
Iter: 233 loss: 3.56419696e-05
Iter: 234 loss: 3.56407763e-05
Iter: 235 loss: 3.56406163e-05
Iter: 236 loss: 3.56408673e-05
Iter: 237 loss: 3.56406235e-05
Iter: 238 loss: 3.56404198e-05
Iter: 239 loss: 3.56405071e-05
Iter: 240 loss: 3.56403398e-05
Iter: 241 loss: 3.5640147e-05
Iter: 242 loss: 3.56409109e-05
Iter: 243 loss: 3.56402161e-05
Iter: 244 loss: 3.56400778e-05
Iter: 245 loss: 3.56414312e-05
Iter: 246 loss: 3.56401288e-05
Iter: 247 loss: 3.56401069e-05
Iter: 248 loss: 3.56400051e-05
Iter: 249 loss: 3.56399432e-05
Iter: 250 loss: 3.56398705e-05
Iter: 251 loss: 3.56401e-05
Iter: 252 loss: 3.56398377e-05
Iter: 253 loss: 3.56397941e-05
Iter: 254 loss: 3.56405253e-05
Iter: 255 loss: 3.56397722e-05
Iter: 256 loss: 3.56397e-05
Iter: 257 loss: 3.56402088e-05
Iter: 258 loss: 3.56397286e-05
Iter: 259 loss: 3.56396522e-05
Iter: 260 loss: 3.56395685e-05
Iter: 261 loss: 3.56395904e-05
Iter: 262 loss: 3.56395612e-05
Iter: 263 loss: 3.56399469e-05
Iter: 264 loss: 3.56395685e-05
Iter: 265 loss: 3.5639514e-05
Iter: 266 loss: 3.56398232e-05
Iter: 267 loss: 3.56395176e-05
Iter: 268 loss: 3.56394121e-05
Iter: 269 loss: 3.56394376e-05
Iter: 270 loss: 3.5639423e-05
Iter: 271 loss: 3.56393721e-05
Iter: 272 loss: 3.5639554e-05
Iter: 273 loss: 3.56393866e-05
Iter: 274 loss: 3.56393721e-05
Iter: 275 loss: 3.56393502e-05
Iter: 276 loss: 3.56393684e-05
Iter: 277 loss: 3.56392629e-05
Iter: 278 loss: 3.56392338e-05
Iter: 279 loss: 3.56392484e-05
Iter: 280 loss: 3.56394703e-05
Iter: 281 loss: 3.56392593e-05
Iter: 282 loss: 3.56391974e-05
Iter: 283 loss: 3.5639292e-05
Iter: 284 loss: 3.56392447e-05
Iter: 285 loss: 3.56391902e-05
Iter: 286 loss: 3.56392084e-05
Iter: 287 loss: 3.56392156e-05
Iter: 288 loss: 3.56391465e-05
Iter: 289 loss: 3.56392557e-05
Iter: 290 loss: 3.56391829e-05
Iter: 291 loss: 3.56391029e-05
Iter: 292 loss: 3.5639303e-05
Iter: 293 loss: 3.5639081e-05
Iter: 294 loss: 3.56391465e-05
Iter: 295 loss: 3.56391065e-05
Iter: 296 loss: 3.56391138e-05
Iter: 297 loss: 3.56391138e-05
Iter: 298 loss: 3.56391247e-05
Iter: 299 loss: 3.56390883e-05
Iter: 300 loss: 3.5639132e-05
Iter: 301 loss: 3.56391211e-05
Iter: 302 loss: 3.56390956e-05
Iter: 303 loss: 3.56391247e-05
Iter: 304 loss: 3.5639132e-05
Iter: 305 loss: 3.5639132e-05
Iter: 306 loss: 3.56391101e-05
Iter: 307 loss: 3.56391283e-05
Iter: 308 loss: 3.56391174e-05
Iter: 309 loss: 3.56391247e-05
Iter: 310 loss: 3.56391211e-05
Iter: 311 loss: 3.56391174e-05
Iter: 312 loss: 3.56391247e-05
Iter: 313 loss: 3.56391174e-05
Iter: 314 loss: 3.56391174e-05
Iter: 315 loss: 3.56391174e-05
Iter: 316 loss: 3.56391211e-05
Iter: 317 loss: 3.56391211e-05
Iter: 318 loss: 3.56391211e-05
Iter: 319 loss: 3.56391174e-05
Iter: 320 loss: 3.56390774e-05
Iter: 321 loss: 3.56391793e-05
Iter: 322 loss: 3.56391101e-05
Iter: 323 loss: 3.56391101e-05
Iter: 324 loss: 3.56390265e-05
Iter: 325 loss: 3.56390774e-05
Iter: 326 loss: 3.56390374e-05
Iter: 327 loss: 3.56390265e-05
Iter: 328 loss: 3.56390301e-05
Iter: 329 loss: 3.56390519e-05
Iter: 330 loss: 3.56393648e-05
Iter: 331 loss: 3.56390665e-05
Iter: 332 loss: 3.56390883e-05
Iter: 333 loss: 3.56390556e-05
Iter: 334 loss: 3.56390374e-05
Iter: 335 loss: 3.56390483e-05
Iter: 336 loss: 3.56390374e-05
Iter: 337 loss: 3.56390628e-05
Iter: 338 loss: 3.56390374e-05
Iter: 339 loss: 3.56390519e-05
Iter: 340 loss: 3.56390447e-05
Iter: 341 loss: 3.56390701e-05
Iter: 342 loss: 3.56390519e-05
Iter: 343 loss: 3.56390628e-05
Iter: 344 loss: 3.5639041e-05
Iter: 345 loss: 3.56391e-05
Iter: 346 loss: 3.5639081e-05
Iter: 347 loss: 3.56391029e-05
Iter: 348 loss: 3.56390738e-05
Iter: 349 loss: 3.56390592e-05
Iter: 350 loss: 3.56390228e-05
Iter: 351 loss: 3.56390301e-05
Iter: 352 loss: 3.56390156e-05
Iter: 353 loss: 3.56390774e-05
Iter: 354 loss: 3.56390447e-05
Iter: 355 loss: 3.56389974e-05
Iter: 356 loss: 3.56389646e-05
Iter: 357 loss: 3.56390119e-05
Iter: 358 loss: 3.56390046e-05
Iter: 359 loss: 3.56390301e-05
Iter: 360 loss: 3.56390447e-05
Iter: 361 loss: 3.56390556e-05
Iter: 362 loss: 3.56390228e-05
Iter: 363 loss: 3.56390337e-05
Iter: 364 loss: 3.56390519e-05
Iter: 365 loss: 3.56390519e-05
Iter: 366 loss: 3.56390519e-05
Iter: 367 loss: 3.56390519e-05
Iter: 368 loss: 3.56390592e-05
Iter: 369 loss: 3.56390592e-05
Iter: 370 loss: 3.56390519e-05
Iter: 371 loss: 3.56390592e-05
Iter: 372 loss: 3.56390519e-05
Iter: 373 loss: 3.56390519e-05
Iter: 374 loss: 3.56390556e-05
Iter: 375 loss: 3.56390519e-05
Iter: 376 loss: 3.56390519e-05
Iter: 377 loss: 3.56390519e-05
Iter: 378 loss: 3.56390556e-05
Iter: 379 loss: 3.56390083e-05
Iter: 380 loss: 3.56391611e-05
Iter: 381 loss: 3.56390156e-05
Iter: 382 loss: 3.56389937e-05
Iter: 383 loss: 3.56389719e-05
Iter: 384 loss: 3.56389646e-05
Iter: 385 loss: 3.56389864e-05
Iter: 386 loss: 3.5639e-05
Iter: 387 loss: 3.56389646e-05
Iter: 388 loss: 3.56389864e-05
Iter: 389 loss: 3.56390265e-05
Iter: 390 loss: 3.56390046e-05
Iter: 391 loss: 3.56390228e-05
Iter: 392 loss: 3.56389864e-05
Iter: 393 loss: 3.5638961e-05
Iter: 394 loss: 3.56389646e-05
Iter: 395 loss: 3.56390046e-05
Iter: 396 loss: 3.56390301e-05
Iter: 397 loss: 3.56390046e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4
+ date
Tue Oct 27 14:48:23 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df42462f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df425c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3e189fd1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df42787b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df427e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df427eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df427e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df41e2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df41e2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df4189158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df41899d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df4189a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df4100b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df41271e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df40aef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df4070ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df4095378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df40caae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df4065d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3df40aee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de0618400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de063d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de063d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de06441e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de0618598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de05b3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de056ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de0516158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de0516620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de04de2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de05161e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de0516a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de04a9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de04de6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de04a9e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3de04ca378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0266897231
Iter: 2 loss: 0.0262746848
Iter: 3 loss: 0.0246678889
Iter: 4 loss: 0.01785524
Iter: 5 loss: 0.0111272354
Iter: 6 loss: 0.00834020693
Iter: 7 loss: 0.00413177814
Iter: 8 loss: 0.00403903332
Iter: 9 loss: 0.00233069062
Iter: 10 loss: 0.0148453359
Iter: 11 loss: 0.00204070378
Iter: 12 loss: 0.00128640665
Iter: 13 loss: 0.00539799687
Iter: 14 loss: 0.00115051819
Iter: 15 loss: 0.000738535775
Iter: 16 loss: 0.00523302192
Iter: 17 loss: 0.00072778936
Iter: 18 loss: 0.000531460275
Iter: 19 loss: 0.000530173071
Iter: 20 loss: 0.000431372551
Iter: 21 loss: 0.00057317
Iter: 22 loss: 0.000383261096
Iter: 23 loss: 0.000299637672
Iter: 24 loss: 0.000848028
Iter: 25 loss: 0.000289643358
Iter: 26 loss: 0.000241769172
Iter: 27 loss: 0.000317878876
Iter: 28 loss: 0.000219506386
Iter: 29 loss: 0.000183075972
Iter: 30 loss: 0.000350154965
Iter: 31 loss: 0.000176255635
Iter: 32 loss: 0.000150718319
Iter: 33 loss: 0.000338146521
Iter: 34 loss: 0.000148473569
Iter: 35 loss: 0.000131444
Iter: 36 loss: 0.000163222852
Iter: 37 loss: 0.000124164711
Iter: 38 loss: 0.00010950274
Iter: 39 loss: 0.000173636334
Iter: 40 loss: 0.000106553984
Iter: 41 loss: 9.60382167e-05
Iter: 42 loss: 0.000163747289
Iter: 43 loss: 9.4865376e-05
Iter: 44 loss: 8.75320256e-05
Iter: 45 loss: 0.000139160751
Iter: 46 loss: 8.68813149e-05
Iter: 47 loss: 8.17158289e-05
Iter: 48 loss: 9.1288508e-05
Iter: 49 loss: 7.94943335e-05
Iter: 50 loss: 7.4821859e-05
Iter: 51 loss: 9.60604739e-05
Iter: 52 loss: 7.39169554e-05
Iter: 53 loss: 7.0276e-05
Iter: 54 loss: 7.7769575e-05
Iter: 55 loss: 6.88121218e-05
Iter: 56 loss: 6.56490811e-05
Iter: 57 loss: 7.91402272e-05
Iter: 58 loss: 6.49896101e-05
Iter: 59 loss: 6.26588735e-05
Iter: 60 loss: 7.63530552e-05
Iter: 61 loss: 6.23525266e-05
Iter: 62 loss: 6.03946537e-05
Iter: 63 loss: 6.91346359e-05
Iter: 64 loss: 6.00089188e-05
Iter: 65 loss: 5.84676e-05
Iter: 66 loss: 6.03253502e-05
Iter: 67 loss: 5.76601051e-05
Iter: 68 loss: 5.61635607e-05
Iter: 69 loss: 6.21377549e-05
Iter: 70 loss: 5.58238899e-05
Iter: 71 loss: 5.45038e-05
Iter: 72 loss: 5.78323779e-05
Iter: 73 loss: 5.40448236e-05
Iter: 74 loss: 5.28527162e-05
Iter: 75 loss: 5.48995486e-05
Iter: 76 loss: 5.23209528e-05
Iter: 77 loss: 5.11943726e-05
Iter: 78 loss: 5.49679862e-05
Iter: 79 loss: 5.0886978e-05
Iter: 80 loss: 4.99378657e-05
Iter: 81 loss: 5.42623056e-05
Iter: 82 loss: 4.97559413e-05
Iter: 83 loss: 4.90006969e-05
Iter: 84 loss: 5.20013782e-05
Iter: 85 loss: 4.88289334e-05
Iter: 86 loss: 4.82040705e-05
Iter: 87 loss: 5.14586245e-05
Iter: 88 loss: 4.81048919e-05
Iter: 89 loss: 4.76086e-05
Iter: 90 loss: 4.90082821e-05
Iter: 91 loss: 4.74510816e-05
Iter: 92 loss: 4.69941224e-05
Iter: 93 loss: 4.93581465e-05
Iter: 94 loss: 4.69206861e-05
Iter: 95 loss: 4.65478261e-05
Iter: 96 loss: 4.6711797e-05
Iter: 97 loss: 4.62934477e-05
Iter: 98 loss: 4.59036928e-05
Iter: 99 loss: 4.81330935e-05
Iter: 100 loss: 4.58506e-05
Iter: 101 loss: 4.55313711e-05
Iter: 102 loss: 4.70397972e-05
Iter: 103 loss: 4.54731889e-05
Iter: 104 loss: 4.52085187e-05
Iter: 105 loss: 4.59722214e-05
Iter: 106 loss: 4.51258238e-05
Iter: 107 loss: 4.48663595e-05
Iter: 108 loss: 4.53876237e-05
Iter: 109 loss: 4.47607963e-05
Iter: 110 loss: 4.45188e-05
Iter: 111 loss: 4.50480911e-05
Iter: 112 loss: 4.44256366e-05
Iter: 113 loss: 4.42126038e-05
Iter: 114 loss: 4.49542858e-05
Iter: 115 loss: 4.41565644e-05
Iter: 116 loss: 4.39663345e-05
Iter: 117 loss: 4.47808234e-05
Iter: 118 loss: 4.39269425e-05
Iter: 119 loss: 4.37664567e-05
Iter: 120 loss: 4.39687356e-05
Iter: 121 loss: 4.36836744e-05
Iter: 122 loss: 4.35309194e-05
Iter: 123 loss: 4.41985685e-05
Iter: 124 loss: 4.35000948e-05
Iter: 125 loss: 4.3369153e-05
Iter: 126 loss: 4.42528908e-05
Iter: 127 loss: 4.33561218e-05
Iter: 128 loss: 4.32568922e-05
Iter: 129 loss: 4.33894311e-05
Iter: 130 loss: 4.32069646e-05
Iter: 131 loss: 4.3103e-05
Iter: 132 loss: 4.36851624e-05
Iter: 133 loss: 4.30884102e-05
Iter: 134 loss: 4.30078944e-05
Iter: 135 loss: 4.30617e-05
Iter: 136 loss: 4.29572829e-05
Iter: 137 loss: 4.28748317e-05
Iter: 138 loss: 4.33747337e-05
Iter: 139 loss: 4.28648054e-05
Iter: 140 loss: 4.27919294e-05
Iter: 141 loss: 4.31279623e-05
Iter: 142 loss: 4.2778207e-05
Iter: 143 loss: 4.27241248e-05
Iter: 144 loss: 4.27960913e-05
Iter: 145 loss: 4.26969091e-05
Iter: 146 loss: 4.26367915e-05
Iter: 147 loss: 4.28281528e-05
Iter: 148 loss: 4.26196493e-05
Iter: 149 loss: 4.25697181e-05
Iter: 150 loss: 4.26572224e-05
Iter: 151 loss: 4.25476865e-05
Iter: 152 loss: 4.24980826e-05
Iter: 153 loss: 4.27112936e-05
Iter: 154 loss: 4.2487889e-05
Iter: 155 loss: 4.24458631e-05
Iter: 156 loss: 4.25777216e-05
Iter: 157 loss: 4.2433654e-05
Iter: 158 loss: 4.23977181e-05
Iter: 159 loss: 4.25205726e-05
Iter: 160 loss: 4.23879719e-05
Iter: 161 loss: 4.23560741e-05
Iter: 162 loss: 4.24879545e-05
Iter: 163 loss: 4.23491947e-05
Iter: 164 loss: 4.23221791e-05
Iter: 165 loss: 4.24288592e-05
Iter: 166 loss: 4.23160454e-05
Iter: 167 loss: 4.22925659e-05
Iter: 168 loss: 4.23446072e-05
Iter: 169 loss: 4.22834091e-05
Iter: 170 loss: 4.2260428e-05
Iter: 171 loss: 4.23177698e-05
Iter: 172 loss: 4.22523663e-05
Iter: 173 loss: 4.223219e-05
Iter: 174 loss: 4.23255224e-05
Iter: 175 loss: 4.2228341e-05
Iter: 176 loss: 4.22110315e-05
Iter: 177 loss: 4.22853263e-05
Iter: 178 loss: 4.22075755e-05
Iter: 179 loss: 4.21927252e-05
Iter: 180 loss: 4.22322191e-05
Iter: 181 loss: 4.21877921e-05
Iter: 182 loss: 4.21735313e-05
Iter: 183 loss: 4.2189291e-05
Iter: 184 loss: 4.21657169e-05
Iter: 185 loss: 4.21517143e-05
Iter: 186 loss: 4.21934128e-05
Iter: 187 loss: 4.21474615e-05
Iter: 188 loss: 4.21345794e-05
Iter: 189 loss: 4.21943805e-05
Iter: 190 loss: 4.21321965e-05
Iter: 191 loss: 4.21210207e-05
Iter: 192 loss: 4.21421646e-05
Iter: 193 loss: 4.21162622e-05
Iter: 194 loss: 4.21057703e-05
Iter: 195 loss: 4.21399418e-05
Iter: 196 loss: 4.21027798e-05
Iter: 197 loss: 4.20932411e-05
Iter: 198 loss: 4.21478326e-05
Iter: 199 loss: 4.20919096e-05
Iter: 200 loss: 4.20840224e-05
Iter: 201 loss: 4.21028e-05
Iter: 202 loss: 4.20812139e-05
Iter: 203 loss: 4.20741e-05
Iter: 204 loss: 4.21005607e-05
Iter: 205 loss: 4.20723045e-05
Iter: 206 loss: 4.20660617e-05
Iter: 207 loss: 4.20787183e-05
Iter: 208 loss: 4.20634096e-05
Iter: 209 loss: 4.20572542e-05
Iter: 210 loss: 4.20773795e-05
Iter: 211 loss: 4.20555807e-05
Iter: 212 loss: 4.20501274e-05
Iter: 213 loss: 4.20826764e-05
Iter: 214 loss: 4.20494362e-05
Iter: 215 loss: 4.20449142e-05
Iter: 216 loss: 4.20537326e-05
Iter: 217 loss: 4.20430297e-05
Iter: 218 loss: 4.20386496e-05
Iter: 219 loss: 4.2044936e-05
Iter: 220 loss: 4.2036525e-05
Iter: 221 loss: 4.20321703e-05
Iter: 222 loss: 4.20504075e-05
Iter: 223 loss: 4.20311808e-05
Iter: 224 loss: 4.20273354e-05
Iter: 225 loss: 4.20322795e-05
Iter: 226 loss: 4.20252582e-05
Iter: 227 loss: 4.20214e-05
Iter: 228 loss: 4.20400138e-05
Iter: 229 loss: 4.20207507e-05
Iter: 230 loss: 4.20172364e-05
Iter: 231 loss: 4.20307333e-05
Iter: 232 loss: 4.20164215e-05
Iter: 233 loss: 4.20137148e-05
Iter: 234 loss: 4.20217657e-05
Iter: 235 loss: 4.20127944e-05
Iter: 236 loss: 4.20102515e-05
Iter: 237 loss: 4.20232318e-05
Iter: 238 loss: 4.20098659e-05
Iter: 239 loss: 4.2007694e-05
Iter: 240 loss: 4.20105134e-05
Iter: 241 loss: 4.20066135e-05
Iter: 242 loss: 4.20043871e-05
Iter: 243 loss: 4.20110628e-05
Iter: 244 loss: 4.20036959e-05
Iter: 245 loss: 4.20015858e-05
Iter: 246 loss: 4.20102e-05
Iter: 247 loss: 4.20011202e-05
Iter: 248 loss: 4.19992939e-05
Iter: 249 loss: 4.20070028e-05
Iter: 250 loss: 4.19989883e-05
Iter: 251 loss: 4.19974604e-05
Iter: 252 loss: 4.20022079e-05
Iter: 253 loss: 4.19969729e-05
Iter: 254 loss: 4.19955395e-05
Iter: 255 loss: 4.19968565e-05
Iter: 256 loss: 4.19947901e-05
Iter: 257 loss: 4.19933131e-05
Iter: 258 loss: 4.19982644e-05
Iter: 259 loss: 4.19929638e-05
Iter: 260 loss: 4.19916396e-05
Iter: 261 loss: 4.19951029e-05
Iter: 262 loss: 4.19911157e-05
Iter: 263 loss: 4.19899443e-05
Iter: 264 loss: 4.19949647e-05
Iter: 265 loss: 4.19896824e-05
Iter: 266 loss: 4.19886419e-05
Iter: 267 loss: 4.19924691e-05
Iter: 268 loss: 4.19884309e-05
Iter: 269 loss: 4.19875141e-05
Iter: 270 loss: 4.19904973e-05
Iter: 271 loss: 4.19871503e-05
Iter: 272 loss: 4.19863863e-05
Iter: 273 loss: 4.19897297e-05
Iter: 274 loss: 4.19861644e-05
Iter: 275 loss: 4.19855241e-05
Iter: 276 loss: 4.19865792e-05
Iter: 277 loss: 4.19851858e-05
Iter: 278 loss: 4.19844582e-05
Iter: 279 loss: 4.19871503e-05
Iter: 280 loss: 4.19842e-05
Iter: 281 loss: 4.19835851e-05
Iter: 282 loss: 4.19859498e-05
Iter: 283 loss: 4.19834505e-05
Iter: 284 loss: 4.19829776e-05
Iter: 285 loss: 4.19852877e-05
Iter: 286 loss: 4.19828539e-05
Iter: 287 loss: 4.19822536e-05
Iter: 288 loss: 4.19832359e-05
Iter: 289 loss: 4.19820572e-05
Iter: 290 loss: 4.19816279e-05
Iter: 291 loss: 4.19821736e-05
Iter: 292 loss: 4.19814e-05
Iter: 293 loss: 4.19808566e-05
Iter: 294 loss: 4.19833086e-05
Iter: 295 loss: 4.19807802e-05
Iter: 296 loss: 4.19803764e-05
Iter: 297 loss: 4.19809585e-05
Iter: 298 loss: 4.19801945e-05
Iter: 299 loss: 4.19798307e-05
Iter: 300 loss: 4.19815333e-05
Iter: 301 loss: 4.19796925e-05
Iter: 302 loss: 4.19793578e-05
Iter: 303 loss: 4.19811768e-05
Iter: 304 loss: 4.19793105e-05
Iter: 305 loss: 4.19790085e-05
Iter: 306 loss: 4.19798816e-05
Iter: 307 loss: 4.19788339e-05
Iter: 308 loss: 4.1978521e-05
Iter: 309 loss: 4.19794414e-05
Iter: 310 loss: 4.19785501e-05
Iter: 311 loss: 4.19782154e-05
Iter: 312 loss: 4.19786484e-05
Iter: 313 loss: 4.19781063e-05
Iter: 314 loss: 4.1977939e-05
Iter: 315 loss: 4.19788885e-05
Iter: 316 loss: 4.19778298e-05
Iter: 317 loss: 4.19776261e-05
Iter: 318 loss: 4.19784919e-05
Iter: 319 loss: 4.19776479e-05
Iter: 320 loss: 4.19773896e-05
Iter: 321 loss: 4.1978321e-05
Iter: 322 loss: 4.19773787e-05
Iter: 323 loss: 4.19772368e-05
Iter: 324 loss: 4.19773605e-05
Iter: 325 loss: 4.19771386e-05
Iter: 326 loss: 4.19769785e-05
Iter: 327 loss: 4.1977426e-05
Iter: 328 loss: 4.1976964e-05
Iter: 329 loss: 4.19767166e-05
Iter: 330 loss: 4.19773387e-05
Iter: 331 loss: 4.19766839e-05
Iter: 332 loss: 4.19765565e-05
Iter: 333 loss: 4.19768548e-05
Iter: 334 loss: 4.19764838e-05
Iter: 335 loss: 4.19763091e-05
Iter: 336 loss: 4.19768694e-05
Iter: 337 loss: 4.19763601e-05
Iter: 338 loss: 4.197628e-05
Iter: 339 loss: 4.19768803e-05
Iter: 340 loss: 4.19762073e-05
Iter: 341 loss: 4.19761491e-05
Iter: 342 loss: 4.19763674e-05
Iter: 343 loss: 4.19760909e-05
Iter: 344 loss: 4.19759672e-05
Iter: 345 loss: 4.19763746e-05
Iter: 346 loss: 4.19760618e-05
Iter: 347 loss: 4.19758726e-05
Iter: 348 loss: 4.19759672e-05
Iter: 349 loss: 4.19758362e-05
Iter: 350 loss: 4.19757453e-05
Iter: 351 loss: 4.19761127e-05
Iter: 352 loss: 4.19757562e-05
Iter: 353 loss: 4.19757343e-05
Iter: 354 loss: 4.19759381e-05
Iter: 355 loss: 4.19757198e-05
Iter: 356 loss: 4.19756398e-05
Iter: 357 loss: 4.19757598e-05
Iter: 358 loss: 4.19756e-05
Iter: 359 loss: 4.19755706e-05
Iter: 360 loss: 4.19756034e-05
Iter: 361 loss: 4.19755233e-05
Iter: 362 loss: 4.19754724e-05
Iter: 363 loss: 4.19755888e-05
Iter: 364 loss: 4.19754397e-05
Iter: 365 loss: 4.19753669e-05
Iter: 366 loss: 4.19755524e-05
Iter: 367 loss: 4.19753778e-05
Iter: 368 loss: 4.19753669e-05
Iter: 369 loss: 4.19754469e-05
Iter: 370 loss: 4.19753e-05
Iter: 371 loss: 4.19752942e-05
Iter: 372 loss: 4.19754069e-05
Iter: 373 loss: 4.19752396e-05
Iter: 374 loss: 4.19751595e-05
Iter: 375 loss: 4.1975436e-05
Iter: 376 loss: 4.19751741e-05
Iter: 377 loss: 4.19751086e-05
Iter: 378 loss: 4.19752614e-05
Iter: 379 loss: 4.19751668e-05
Iter: 380 loss: 4.1975105e-05
Iter: 381 loss: 4.1975225e-05
Iter: 382 loss: 4.19751377e-05
Iter: 383 loss: 4.1975105e-05
Iter: 384 loss: 4.19750868e-05
Iter: 385 loss: 4.19751304e-05
Iter: 386 loss: 4.19750359e-05
Iter: 387 loss: 4.19751304e-05
Iter: 388 loss: 4.19750359e-05
Iter: 389 loss: 4.1975e-05
Iter: 390 loss: 4.19750904e-05
Iter: 391 loss: 4.19750068e-05
Iter: 392 loss: 4.19750249e-05
Iter: 393 loss: 4.1975065e-05
Iter: 394 loss: 4.19749522e-05
Iter: 395 loss: 4.19749485e-05
Iter: 396 loss: 4.19749922e-05
Iter: 397 loss: 4.19749122e-05
Iter: 398 loss: 4.19749e-05
Iter: 399 loss: 4.19749886e-05
Iter: 400 loss: 4.19748831e-05
Iter: 401 loss: 4.19748249e-05
Iter: 402 loss: 4.19749267e-05
Iter: 403 loss: 4.19749049e-05
Iter: 404 loss: 4.19748576e-05
Iter: 405 loss: 4.19749485e-05
Iter: 406 loss: 4.19748976e-05
Iter: 407 loss: 4.19749413e-05
Iter: 408 loss: 4.1974934e-05
Iter: 409 loss: 4.19748831e-05
Iter: 410 loss: 4.19748976e-05
Iter: 411 loss: 4.19749231e-05
Iter: 412 loss: 4.19748758e-05
Iter: 413 loss: 4.19747666e-05
Iter: 414 loss: 4.19749194e-05
Iter: 415 loss: 4.1974803e-05
Iter: 416 loss: 4.1974854e-05
Iter: 417 loss: 4.19747776e-05
Iter: 418 loss: 4.19747921e-05
Iter: 419 loss: 4.19747812e-05
Iter: 420 loss: 4.1974803e-05
Iter: 421 loss: 4.19748103e-05
Iter: 422 loss: 4.19748139e-05
Iter: 423 loss: 4.19748103e-05
Iter: 424 loss: 4.19748176e-05
Iter: 425 loss: 4.19747921e-05
Iter: 426 loss: 4.19748394e-05
Iter: 427 loss: 4.19748358e-05
Iter: 428 loss: 4.19748358e-05
Iter: 429 loss: 4.19748576e-05
Iter: 430 loss: 4.19748467e-05
Iter: 431 loss: 4.1974854e-05
Iter: 432 loss: 4.1974854e-05
Iter: 433 loss: 4.19748467e-05
Iter: 434 loss: 4.1974854e-05
Iter: 435 loss: 4.19748467e-05
Iter: 436 loss: 4.1974854e-05
Iter: 437 loss: 4.19748503e-05
Iter: 438 loss: 4.19748467e-05
Iter: 439 loss: 4.19748503e-05
Iter: 440 loss: 4.19748467e-05
Iter: 441 loss: 4.19748503e-05
Iter: 442 loss: 4.19748103e-05
Iter: 443 loss: 4.19749085e-05
Iter: 444 loss: 4.19747375e-05
Iter: 445 loss: 4.19747885e-05
Iter: 446 loss: 4.19748e-05
Iter: 447 loss: 4.19748139e-05
Iter: 448 loss: 4.19748176e-05
Iter: 449 loss: 4.1974803e-05
Iter: 450 loss: 4.19748358e-05
Iter: 451 loss: 4.1974803e-05
Iter: 452 loss: 4.19747666e-05
Iter: 453 loss: 4.19748139e-05
Iter: 454 loss: 4.19748e-05
Iter: 455 loss: 4.19747521e-05
Iter: 456 loss: 4.19748176e-05
Iter: 457 loss: 4.19747776e-05
Iter: 458 loss: 4.19747739e-05
Iter: 459 loss: 4.19747957e-05
Iter: 460 loss: 4.19748e-05
Iter: 461 loss: 4.19747776e-05
Iter: 462 loss: 4.19747885e-05
Iter: 463 loss: 4.19747776e-05
Iter: 464 loss: 4.19747812e-05
Iter: 465 loss: 4.19747885e-05
Iter: 466 loss: 4.19747885e-05
Iter: 467 loss: 4.19747848e-05
Iter: 468 loss: 4.19747848e-05
Iter: 469 loss: 4.19747812e-05
Iter: 470 loss: 4.19747812e-05
Iter: 471 loss: 4.19747812e-05
Iter: 472 loss: 4.19747848e-05
Iter: 473 loss: 4.19747848e-05
Iter: 474 loss: 4.19747848e-05
Iter: 475 loss: 4.19747848e-05
Iter: 476 loss: 4.19747812e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8
+ date
Tue Oct 27 14:54:57 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2746c5488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2746fa840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2746fa378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274704730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274704488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27472fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27472f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27465d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27465d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274636158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2746369d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27458fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27458fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2745d39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27454d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274508ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274529488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274564268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274484d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274529e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2744478c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2744752f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274475268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2743e9d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2743e9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2743e98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2743a8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274359c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27437a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27431a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27437a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27437a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2742de8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc27431a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc2742debf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fc274305378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0192409661
Iter: 2 loss: 0.0188674629
Iter: 3 loss: 0.0174454972
Iter: 4 loss: 0.0125825554
Iter: 5 loss: 24006.5273
Iter: 6 loss: 0.0621088408
Iter: 7 loss: 0.0183891878
Iter: 8 loss: 0.0233781952
Iter: 9 loss: 0.012304008
Iter: 10 loss: 0.0122411959
Iter: 11 loss: 0.00819525681
Iter: 12 loss: 0.02703817
Iter: 13 loss: 0.00693644164
Iter: 14 loss: 0.00334770745
Iter: 15 loss: 0.00332788518
Iter: 16 loss: 0.00238405145
Iter: 17 loss: 0.00228531286
Iter: 18 loss: 0.00175504503
Iter: 19 loss: 0.00505667087
Iter: 20 loss: 0.001649788
Iter: 21 loss: 0.00129788485
Iter: 22 loss: 0.00255547091
Iter: 23 loss: 0.00119326089
Iter: 24 loss: 0.000932918047
Iter: 25 loss: 0.00276171067
Iter: 26 loss: 0.000914939796
Iter: 27 loss: 0.000733390392
Iter: 28 loss: 0.00198453432
Iter: 29 loss: 0.000710489636
Iter: 30 loss: 0.000597109902
Iter: 31 loss: 0.000874763
Iter: 32 loss: 0.00055561692
Iter: 33 loss: 0.000454141264
Iter: 34 loss: 0.000809043064
Iter: 35 loss: 0.000425094942
Iter: 36 loss: 0.000349185546
Iter: 37 loss: 0.000629959337
Iter: 38 loss: 0.000330667943
Iter: 39 loss: 0.000278652675
Iter: 40 loss: 0.000664040446
Iter: 41 loss: 0.000273786776
Iter: 42 loss: 0.000238130335
Iter: 43 loss: 0.000321599015
Iter: 44 loss: 0.000224677526
Iter: 45 loss: 0.000196732159
Iter: 46 loss: 0.000298358907
Iter: 47 loss: 0.000189579558
Iter: 48 loss: 0.000167505234
Iter: 49 loss: 0.000325412373
Iter: 50 loss: 0.000165555801
Iter: 51 loss: 0.000150166015
Iter: 52 loss: 0.000185420184
Iter: 53 loss: 0.000144356265
Iter: 54 loss: 0.00013207653
Iter: 55 loss: 0.000186157471
Iter: 56 loss: 0.000129627617
Iter: 57 loss: 0.000120580888
Iter: 58 loss: 0.00020789713
Iter: 59 loss: 0.000120190307
Iter: 60 loss: 0.00011340627
Iter: 61 loss: 0.000146469596
Iter: 62 loss: 0.000112285372
Iter: 63 loss: 0.000107186686
Iter: 64 loss: 0.000112676164
Iter: 65 loss: 0.000104354891
Iter: 66 loss: 9.9123019e-05
Iter: 67 loss: 0.000118565076
Iter: 68 loss: 9.78387616e-05
Iter: 69 loss: 9.31953837e-05
Iter: 70 loss: 0.000106935317
Iter: 71 loss: 9.17650686e-05
Iter: 72 loss: 8.78600404e-05
Iter: 73 loss: 9.45667707e-05
Iter: 74 loss: 8.60964064e-05
Iter: 75 loss: 8.24468589e-05
Iter: 76 loss: 9.09208466e-05
Iter: 77 loss: 8.10942729e-05
Iter: 78 loss: 7.77872337e-05
Iter: 79 loss: 9.24806081e-05
Iter: 80 loss: 7.71325649e-05
Iter: 81 loss: 7.4460695e-05
Iter: 82 loss: 8.43029338e-05
Iter: 83 loss: 7.37967493e-05
Iter: 84 loss: 7.15015631e-05
Iter: 85 loss: 7.90124614e-05
Iter: 86 loss: 7.08575244e-05
Iter: 87 loss: 6.88662549e-05
Iter: 88 loss: 7.49390165e-05
Iter: 89 loss: 6.82746177e-05
Iter: 90 loss: 6.66497508e-05
Iter: 91 loss: 7.2390656e-05
Iter: 92 loss: 6.62312959e-05
Iter: 93 loss: 6.49336216e-05
Iter: 94 loss: 7.84026633e-05
Iter: 95 loss: 6.48944551e-05
Iter: 96 loss: 6.38581332e-05
Iter: 97 loss: 6.81994425e-05
Iter: 98 loss: 6.36411933e-05
Iter: 99 loss: 6.28577327e-05
Iter: 100 loss: 6.31421572e-05
Iter: 101 loss: 6.23078085e-05
Iter: 102 loss: 6.139178e-05
Iter: 103 loss: 6.62081438e-05
Iter: 104 loss: 6.12488802e-05
Iter: 105 loss: 6.04656307e-05
Iter: 106 loss: 6.25282846e-05
Iter: 107 loss: 6.02016553e-05
Iter: 108 loss: 5.94667472e-05
Iter: 109 loss: 5.99235427e-05
Iter: 110 loss: 5.89954689e-05
Iter: 111 loss: 5.81888089e-05
Iter: 112 loss: 6.03301924e-05
Iter: 113 loss: 5.79184889e-05
Iter: 114 loss: 5.71833225e-05
Iter: 115 loss: 5.99183622e-05
Iter: 116 loss: 5.70028715e-05
Iter: 117 loss: 5.63664034e-05
Iter: 118 loss: 5.87488394e-05
Iter: 119 loss: 5.62113892e-05
Iter: 120 loss: 5.56440355e-05
Iter: 121 loss: 5.7097408e-05
Iter: 122 loss: 5.5448716e-05
Iter: 123 loss: 5.49168544e-05
Iter: 124 loss: 5.61012894e-05
Iter: 125 loss: 5.47141026e-05
Iter: 126 loss: 5.42470225e-05
Iter: 127 loss: 5.72664867e-05
Iter: 128 loss: 5.41966801e-05
Iter: 129 loss: 5.38440145e-05
Iter: 130 loss: 5.69342374e-05
Iter: 131 loss: 5.38251e-05
Iter: 132 loss: 5.353089e-05
Iter: 133 loss: 5.41579793e-05
Iter: 134 loss: 5.34161954e-05
Iter: 135 loss: 5.31502337e-05
Iter: 136 loss: 5.31811966e-05
Iter: 137 loss: 5.2946456e-05
Iter: 138 loss: 5.264028e-05
Iter: 139 loss: 5.52715646e-05
Iter: 140 loss: 5.26235526e-05
Iter: 141 loss: 5.23720591e-05
Iter: 142 loss: 5.2639647e-05
Iter: 143 loss: 5.22333285e-05
Iter: 144 loss: 5.19715e-05
Iter: 145 loss: 5.24592506e-05
Iter: 146 loss: 5.18599118e-05
Iter: 147 loss: 5.15992651e-05
Iter: 148 loss: 5.21609509e-05
Iter: 149 loss: 5.14976928e-05
Iter: 150 loss: 5.12474908e-05
Iter: 151 loss: 5.20415779e-05
Iter: 152 loss: 5.11757171e-05
Iter: 153 loss: 5.09548954e-05
Iter: 154 loss: 5.15424144e-05
Iter: 155 loss: 5.08810845e-05
Iter: 156 loss: 5.0660612e-05
Iter: 157 loss: 5.15768807e-05
Iter: 158 loss: 5.06132128e-05
Iter: 159 loss: 5.04258533e-05
Iter: 160 loss: 5.08588892e-05
Iter: 161 loss: 5.03562078e-05
Iter: 162 loss: 5.01890245e-05
Iter: 163 loss: 5.09255697e-05
Iter: 164 loss: 5.0155777e-05
Iter: 165 loss: 5.00338829e-05
Iter: 166 loss: 5.18731467e-05
Iter: 167 loss: 5.00338101e-05
Iter: 168 loss: 4.99429952e-05
Iter: 169 loss: 4.99365924e-05
Iter: 170 loss: 4.98682966e-05
Iter: 171 loss: 4.97586e-05
Iter: 172 loss: 4.99632515e-05
Iter: 173 loss: 4.97117508e-05
Iter: 174 loss: 4.96066023e-05
Iter: 175 loss: 5.0245224e-05
Iter: 176 loss: 4.95936729e-05
Iter: 177 loss: 4.94994893e-05
Iter: 178 loss: 4.97020337e-05
Iter: 179 loss: 4.94628184e-05
Iter: 180 loss: 4.93745029e-05
Iter: 181 loss: 4.93799671e-05
Iter: 182 loss: 4.93055522e-05
Iter: 183 loss: 4.9200833e-05
Iter: 184 loss: 4.96766843e-05
Iter: 185 loss: 4.91807696e-05
Iter: 186 loss: 4.90889215e-05
Iter: 187 loss: 4.93659245e-05
Iter: 188 loss: 4.90612583e-05
Iter: 189 loss: 4.89752529e-05
Iter: 190 loss: 4.9125294e-05
Iter: 191 loss: 4.89371887e-05
Iter: 192 loss: 4.88549631e-05
Iter: 193 loss: 4.91153551e-05
Iter: 194 loss: 4.88314072e-05
Iter: 195 loss: 4.87547404e-05
Iter: 196 loss: 4.91370847e-05
Iter: 197 loss: 4.87418e-05
Iter: 198 loss: 4.86803765e-05
Iter: 199 loss: 4.89682134e-05
Iter: 200 loss: 4.86690806e-05
Iter: 201 loss: 4.86225799e-05
Iter: 202 loss: 4.91164974e-05
Iter: 203 loss: 4.86213903e-05
Iter: 204 loss: 4.8582202e-05
Iter: 205 loss: 4.85483833e-05
Iter: 206 loss: 4.85378296e-05
Iter: 207 loss: 4.84893681e-05
Iter: 208 loss: 4.8646456e-05
Iter: 209 loss: 4.84756893e-05
Iter: 210 loss: 4.84317097e-05
Iter: 211 loss: 4.87440411e-05
Iter: 212 loss: 4.84277443e-05
Iter: 213 loss: 4.83901822e-05
Iter: 214 loss: 4.84362681e-05
Iter: 215 loss: 4.83706717e-05
Iter: 216 loss: 4.83330259e-05
Iter: 217 loss: 4.83734329e-05
Iter: 218 loss: 4.83122967e-05
Iter: 219 loss: 4.82712785e-05
Iter: 220 loss: 4.84301054e-05
Iter: 221 loss: 4.82617288e-05
Iter: 222 loss: 4.82252326e-05
Iter: 223 loss: 4.82702453e-05
Iter: 224 loss: 4.82061951e-05
Iter: 225 loss: 4.81675088e-05
Iter: 226 loss: 4.83399708e-05
Iter: 227 loss: 4.81598909e-05
Iter: 228 loss: 4.81268507e-05
Iter: 229 loss: 4.82267278e-05
Iter: 230 loss: 4.81169118e-05
Iter: 231 loss: 4.8087506e-05
Iter: 232 loss: 4.81982534e-05
Iter: 233 loss: 4.80803938e-05
Iter: 234 loss: 4.80562303e-05
Iter: 235 loss: 4.81494608e-05
Iter: 236 loss: 4.80506351e-05
Iter: 237 loss: 4.80293165e-05
Iter: 238 loss: 4.82908508e-05
Iter: 239 loss: 4.8029171e-05
Iter: 240 loss: 4.8015514e-05
Iter: 241 loss: 4.80052295e-05
Iter: 242 loss: 4.80008021e-05
Iter: 243 loss: 4.79808223e-05
Iter: 244 loss: 4.80341914e-05
Iter: 245 loss: 4.79742666e-05
Iter: 246 loss: 4.79567898e-05
Iter: 247 loss: 4.80535418e-05
Iter: 248 loss: 4.79542869e-05
Iter: 249 loss: 4.79379305e-05
Iter: 250 loss: 4.79882765e-05
Iter: 251 loss: 4.79329465e-05
Iter: 252 loss: 4.7918802e-05
Iter: 253 loss: 4.79242e-05
Iter: 254 loss: 4.79088449e-05
Iter: 255 loss: 4.78923612e-05
Iter: 256 loss: 4.79320952e-05
Iter: 257 loss: 4.78864749e-05
Iter: 258 loss: 4.78696747e-05
Iter: 259 loss: 4.79307928e-05
Iter: 260 loss: 4.78655384e-05
Iter: 261 loss: 4.78505608e-05
Iter: 262 loss: 4.78809379e-05
Iter: 263 loss: 4.78445e-05
Iter: 264 loss: 4.78308611e-05
Iter: 265 loss: 4.78681468e-05
Iter: 266 loss: 4.78264119e-05
Iter: 267 loss: 4.78130714e-05
Iter: 268 loss: 4.78892107e-05
Iter: 269 loss: 4.7811307e-05
Iter: 270 loss: 4.78002148e-05
Iter: 271 loss: 4.78207367e-05
Iter: 272 loss: 4.77955691e-05
Iter: 273 loss: 4.77879876e-05
Iter: 274 loss: 4.77878384e-05
Iter: 275 loss: 4.77812282e-05
Iter: 276 loss: 4.77758113e-05
Iter: 277 loss: 4.77738213e-05
Iter: 278 loss: 4.77654139e-05
Iter: 279 loss: 4.77697358e-05
Iter: 280 loss: 4.77597532e-05
Iter: 281 loss: 4.77507856e-05
Iter: 282 loss: 4.78384318e-05
Iter: 283 loss: 4.77505382e-05
Iter: 284 loss: 4.77429567e-05
Iter: 285 loss: 4.77695357e-05
Iter: 286 loss: 4.77410795e-05
Iter: 287 loss: 4.77349131e-05
Iter: 288 loss: 4.77425492e-05
Iter: 289 loss: 4.77316789e-05
Iter: 290 loss: 4.77246322e-05
Iter: 291 loss: 4.77347276e-05
Iter: 292 loss: 4.77210961e-05
Iter: 293 loss: 4.77139583e-05
Iter: 294 loss: 4.7731377e-05
Iter: 295 loss: 4.77113863e-05
Iter: 296 loss: 4.77044596e-05
Iter: 297 loss: 4.77248977e-05
Iter: 298 loss: 4.77023641e-05
Iter: 299 loss: 4.76957212e-05
Iter: 300 loss: 4.77151043e-05
Iter: 301 loss: 4.76935893e-05
Iter: 302 loss: 4.76873756e-05
Iter: 303 loss: 4.77097346e-05
Iter: 304 loss: 4.76858731e-05
Iter: 305 loss: 4.76803762e-05
Iter: 306 loss: 4.76994464e-05
Iter: 307 loss: 4.76788773e-05
Iter: 308 loss: 4.76744644e-05
Iter: 309 loss: 4.77104732e-05
Iter: 310 loss: 4.76741843e-05
Iter: 311 loss: 4.76699643e-05
Iter: 312 loss: 4.76845453e-05
Iter: 313 loss: 4.7668851e-05
Iter: 314 loss: 4.76657515e-05
Iter: 315 loss: 4.76635432e-05
Iter: 316 loss: 4.76624919e-05
Iter: 317 loss: 4.76582281e-05
Iter: 318 loss: 4.76732312e-05
Iter: 319 loss: 4.76571076e-05
Iter: 320 loss: 4.76534333e-05
Iter: 321 loss: 4.76771529e-05
Iter: 322 loss: 4.76529895e-05
Iter: 323 loss: 4.76498572e-05
Iter: 324 loss: 4.76637e-05
Iter: 325 loss: 4.76491477e-05
Iter: 326 loss: 4.76464375e-05
Iter: 327 loss: 4.76471614e-05
Iter: 328 loss: 4.76444548e-05
Iter: 329 loss: 4.76411806e-05
Iter: 330 loss: 4.76493406e-05
Iter: 331 loss: 4.76398818e-05
Iter: 332 loss: 4.7636895e-05
Iter: 333 loss: 4.76432542e-05
Iter: 334 loss: 4.76357163e-05
Iter: 335 loss: 4.76326131e-05
Iter: 336 loss: 4.76431269e-05
Iter: 337 loss: 4.76316745e-05
Iter: 338 loss: 4.7628826e-05
Iter: 339 loss: 4.76395e-05
Iter: 340 loss: 4.76281893e-05
Iter: 341 loss: 4.76255082e-05
Iter: 342 loss: 4.7632715e-05
Iter: 343 loss: 4.76246278e-05
Iter: 344 loss: 4.76223358e-05
Iter: 345 loss: 4.76270361e-05
Iter: 346 loss: 4.76214082e-05
Iter: 347 loss: 4.76199129e-05
Iter: 348 loss: 4.76197711e-05
Iter: 349 loss: 4.76184141e-05
Iter: 350 loss: 4.76173664e-05
Iter: 351 loss: 4.76169735e-05
Iter: 352 loss: 4.76150672e-05
Iter: 353 loss: 4.76168789e-05
Iter: 354 loss: 4.76139903e-05
Iter: 355 loss: 4.76119421e-05
Iter: 356 loss: 4.76186942e-05
Iter: 357 loss: 4.76113419e-05
Iter: 358 loss: 4.76094283e-05
Iter: 359 loss: 4.76187925e-05
Iter: 360 loss: 4.76091154e-05
Iter: 361 loss: 4.76075e-05
Iter: 362 loss: 4.76174173e-05
Iter: 363 loss: 4.76074201e-05
Iter: 364 loss: 4.76060886e-05
Iter: 365 loss: 4.76072e-05
Iter: 366 loss: 4.76052446e-05
Iter: 367 loss: 4.76038404e-05
Iter: 368 loss: 4.76049099e-05
Iter: 369 loss: 4.76029418e-05
Iter: 370 loss: 4.76012428e-05
Iter: 371 loss: 4.76062305e-05
Iter: 372 loss: 4.76007554e-05
Iter: 373 loss: 4.75992165e-05
Iter: 374 loss: 4.76062778e-05
Iter: 375 loss: 4.759898e-05
Iter: 376 loss: 4.75977e-05
Iter: 377 loss: 4.75988782e-05
Iter: 378 loss: 4.75969209e-05
Iter: 379 loss: 4.75955385e-05
Iter: 380 loss: 4.76027599e-05
Iter: 381 loss: 4.7595262e-05
Iter: 382 loss: 4.75940578e-05
Iter: 383 loss: 4.75989582e-05
Iter: 384 loss: 4.75937923e-05
Iter: 385 loss: 4.75929883e-05
Iter: 386 loss: 4.76035e-05
Iter: 387 loss: 4.75929264e-05
Iter: 388 loss: 4.75921042e-05
Iter: 389 loss: 4.7592177e-05
Iter: 390 loss: 4.75915658e-05
Iter: 391 loss: 4.75907873e-05
Iter: 392 loss: 4.75910711e-05
Iter: 393 loss: 4.7590067e-05
Iter: 394 loss: 4.75891466e-05
Iter: 395 loss: 4.75920533e-05
Iter: 396 loss: 4.75887064e-05
Iter: 397 loss: 4.75877023e-05
Iter: 398 loss: 4.75916022e-05
Iter: 399 loss: 4.75875568e-05
Iter: 400 loss: 4.758676e-05
Iter: 401 loss: 4.75920606e-05
Iter: 402 loss: 4.75866109e-05
Iter: 403 loss: 4.75859269e-05
Iter: 404 loss: 4.75889101e-05
Iter: 405 loss: 4.7585796e-05
Iter: 406 loss: 4.75852357e-05
Iter: 407 loss: 4.75850466e-05
Iter: 408 loss: 4.75847046e-05
Iter: 409 loss: 4.75839915e-05
Iter: 410 loss: 4.75854904e-05
Iter: 411 loss: 4.75836641e-05
Iter: 412 loss: 4.75828638e-05
Iter: 413 loss: 4.75858396e-05
Iter: 414 loss: 4.75828274e-05
Iter: 415 loss: 4.75821507e-05
Iter: 416 loss: 4.75842317e-05
Iter: 417 loss: 4.75819725e-05
Iter: 418 loss: 4.75813504e-05
Iter: 419 loss: 4.75831257e-05
Iter: 420 loss: 4.75812194e-05
Iter: 421 loss: 4.75805791e-05
Iter: 422 loss: 4.75820052e-05
Iter: 423 loss: 4.75803681e-05
Iter: 424 loss: 4.75800189e-05
Iter: 425 loss: 4.75799097e-05
Iter: 426 loss: 4.75795605e-05
Iter: 427 loss: 4.75797133e-05
Iter: 428 loss: 4.75792622e-05
Iter: 429 loss: 4.75788838e-05
Iter: 430 loss: 4.75789275e-05
Iter: 431 loss: 4.75786437e-05
Iter: 432 loss: 4.75780653e-05
Iter: 433 loss: 4.75801789e-05
Iter: 434 loss: 4.7577927e-05
Iter: 435 loss: 4.75775887e-05
Iter: 436 loss: 4.75785164e-05
Iter: 437 loss: 4.75773159e-05
Iter: 438 loss: 4.75770175e-05
Iter: 439 loss: 4.75782435e-05
Iter: 440 loss: 4.75768247e-05
Iter: 441 loss: 4.75764609e-05
Iter: 442 loss: 4.75800734e-05
Iter: 443 loss: 4.75764391e-05
Iter: 444 loss: 4.7576239e-05
Iter: 445 loss: 4.75763954e-05
Iter: 446 loss: 4.75759916e-05
Iter: 447 loss: 4.7575697e-05
Iter: 448 loss: 4.75759916e-05
Iter: 449 loss: 4.75755151e-05
Iter: 450 loss: 4.75751294e-05
Iter: 451 loss: 4.75757952e-05
Iter: 452 loss: 4.75750057e-05
Iter: 453 loss: 4.75746601e-05
Iter: 454 loss: 4.75762718e-05
Iter: 455 loss: 4.75745073e-05
Iter: 456 loss: 4.75743363e-05
Iter: 457 loss: 4.75751658e-05
Iter: 458 loss: 4.75741217e-05
Iter: 459 loss: 4.75739e-05
Iter: 460 loss: 4.75743836e-05
Iter: 461 loss: 4.75737179e-05
Iter: 462 loss: 4.7573456e-05
Iter: 463 loss: 4.75735069e-05
Iter: 464 loss: 4.75733104e-05
Iter: 465 loss: 4.75736306e-05
Iter: 466 loss: 4.75732413e-05
Iter: 467 loss: 4.75729612e-05
Iter: 468 loss: 4.75730849e-05
Iter: 469 loss: 4.7572863e-05
Iter: 470 loss: 4.75726192e-05
Iter: 471 loss: 4.75732268e-05
Iter: 472 loss: 4.75725392e-05
Iter: 473 loss: 4.75723573e-05
Iter: 474 loss: 4.75727356e-05
Iter: 475 loss: 4.75721827e-05
Iter: 476 loss: 4.7571968e-05
Iter: 477 loss: 4.75726847e-05
Iter: 478 loss: 4.75718844e-05
Iter: 479 loss: 4.75717061e-05
Iter: 480 loss: 4.75735214e-05
Iter: 481 loss: 4.75717461e-05
Iter: 482 loss: 4.7571586e-05
Iter: 483 loss: 4.75721426e-05
Iter: 484 loss: 4.75715569e-05
Iter: 485 loss: 4.75713605e-05
Iter: 486 loss: 4.75716552e-05
Iter: 487 loss: 4.75712368e-05
Iter: 488 loss: 4.75711859e-05
Iter: 489 loss: 4.75713823e-05
Iter: 490 loss: 4.75710622e-05
Iter: 491 loss: 4.75708694e-05
Iter: 492 loss: 4.75712222e-05
Iter: 493 loss: 4.75707493e-05
Iter: 494 loss: 4.75706183e-05
Iter: 495 loss: 4.75711895e-05
Iter: 496 loss: 4.75706329e-05
Iter: 497 loss: 4.75704328e-05
Iter: 498 loss: 4.75710112e-05
Iter: 499 loss: 4.75704073e-05
Iter: 500 loss: 4.75703e-05
Iter: 501 loss: 4.75709676e-05
Iter: 502 loss: 4.75701745e-05
Iter: 503 loss: 4.75701709e-05
Iter: 504 loss: 4.75713277e-05
Iter: 505 loss: 4.75700981e-05
Iter: 506 loss: 4.7570029e-05
Iter: 507 loss: 4.75700217e-05
Iter: 508 loss: 4.75699853e-05
Iter: 509 loss: 4.75698253e-05
Iter: 510 loss: 4.75699417e-05
Iter: 511 loss: 4.75697452e-05
Iter: 512 loss: 4.75695961e-05
Iter: 513 loss: 4.75701672e-05
Iter: 514 loss: 4.75695742e-05
Iter: 515 loss: 4.75694505e-05
Iter: 516 loss: 4.75696797e-05
Iter: 517 loss: 4.7569396e-05
Iter: 518 loss: 4.75693341e-05
Iter: 519 loss: 4.75696288e-05
Iter: 520 loss: 4.75693378e-05
Iter: 521 loss: 4.75692068e-05
Iter: 522 loss: 4.75698507e-05
Iter: 523 loss: 4.75693087e-05
Iter: 524 loss: 4.75691049e-05
Iter: 525 loss: 4.75694978e-05
Iter: 526 loss: 4.75690904e-05
Iter: 527 loss: 4.75690831e-05
Iter: 528 loss: 4.75690576e-05
Iter: 529 loss: 4.75689267e-05
Iter: 530 loss: 4.75689485e-05
Iter: 531 loss: 4.75691231e-05
Iter: 532 loss: 4.75688939e-05
Iter: 533 loss: 4.75687812e-05
Iter: 534 loss: 4.75689667e-05
Iter: 535 loss: 4.75687048e-05
Iter: 536 loss: 4.75686429e-05
Iter: 537 loss: 4.75689e-05
Iter: 538 loss: 4.75686538e-05
Iter: 539 loss: 4.75686247e-05
Iter: 540 loss: 4.75689812e-05
Iter: 541 loss: 4.75685774e-05
Iter: 542 loss: 4.75684865e-05
Iter: 543 loss: 4.75691559e-05
Iter: 544 loss: 4.75685665e-05
Iter: 545 loss: 4.7568421e-05
Iter: 546 loss: 4.75685229e-05
Iter: 547 loss: 4.75683919e-05
Iter: 548 loss: 4.756833e-05
Iter: 549 loss: 4.75684e-05
Iter: 550 loss: 4.75683846e-05
Iter: 551 loss: 4.75682864e-05
Iter: 552 loss: 4.75684e-05
Iter: 553 loss: 4.75682609e-05
Iter: 554 loss: 4.75682064e-05
Iter: 555 loss: 4.7568341e-05
Iter: 556 loss: 4.75681518e-05
Iter: 557 loss: 4.75680717e-05
Iter: 558 loss: 4.75683482e-05
Iter: 559 loss: 4.75681227e-05
Iter: 560 loss: 4.75680645e-05
Iter: 561 loss: 4.75682136e-05
Iter: 562 loss: 4.75680499e-05
Iter: 563 loss: 4.75679735e-05
Iter: 564 loss: 4.75683482e-05
Iter: 565 loss: 4.75680135e-05
Iter: 566 loss: 4.75679772e-05
Iter: 567 loss: 4.75680863e-05
Iter: 568 loss: 4.75678753e-05
Iter: 569 loss: 4.75679553e-05
Iter: 570 loss: 4.75678426e-05
Iter: 571 loss: 4.75678607e-05
Iter: 572 loss: 4.7567919e-05
Iter: 573 loss: 4.75679626e-05
Iter: 574 loss: 4.75679735e-05
Iter: 575 loss: 4.75679335e-05
Iter: 576 loss: 4.75679299e-05
Iter: 577 loss: 4.75678971e-05
Iter: 578 loss: 4.75679262e-05
Iter: 579 loss: 4.7567908e-05
Iter: 580 loss: 4.75679117e-05
Iter: 581 loss: 4.75679262e-05
Iter: 582 loss: 4.75679262e-05
Iter: 583 loss: 4.75679299e-05
Iter: 584 loss: 4.75679117e-05
Iter: 585 loss: 4.75679335e-05
Iter: 586 loss: 4.75679335e-05
Iter: 587 loss: 4.7567919e-05
Iter: 588 loss: 4.75679335e-05
Iter: 589 loss: 4.75679335e-05
Iter: 590 loss: 4.75679117e-05
Iter: 591 loss: 4.75679117e-05
Iter: 592 loss: 4.75679335e-05
Iter: 593 loss: 4.75679335e-05
Iter: 594 loss: 4.75679117e-05
Iter: 595 loss: 4.75678899e-05
Iter: 596 loss: 4.756833e-05
Iter: 597 loss: 4.75678607e-05
Iter: 598 loss: 4.75678535e-05
Iter: 599 loss: 4.75679117e-05
Iter: 600 loss: 4.75678389e-05
Iter: 601 loss: 4.75677152e-05
Iter: 602 loss: 4.756817e-05
Iter: 603 loss: 4.75677043e-05
Iter: 604 loss: 4.75677552e-05
Iter: 605 loss: 4.75677625e-05
Iter: 606 loss: 4.75677e-05
Iter: 607 loss: 4.75677371e-05
Iter: 608 loss: 4.75677698e-05
Iter: 609 loss: 4.75677298e-05
Iter: 610 loss: 4.75677189e-05
Iter: 611 loss: 4.75677734e-05
Iter: 612 loss: 4.75677334e-05
Iter: 613 loss: 4.75677807e-05
Iter: 614 loss: 4.75677807e-05
Iter: 615 loss: 4.75677516e-05
Iter: 616 loss: 4.75677516e-05
Iter: 617 loss: 4.75677916e-05
Iter: 618 loss: 4.75677589e-05
Iter: 619 loss: 4.75677371e-05
Iter: 620 loss: 4.75677589e-05
Iter: 621 loss: 4.75677371e-05
Iter: 622 loss: 4.75677552e-05
Iter: 623 loss: 4.75677298e-05
Iter: 624 loss: 4.75677552e-05
Iter: 625 loss: 4.75677371e-05
Iter: 626 loss: 4.75677552e-05
Iter: 627 loss: 4.75677371e-05
Iter: 628 loss: 4.75677589e-05
Iter: 629 loss: 4.75677371e-05
Iter: 630 loss: 4.75677589e-05
Iter: 631 loss: 4.7567708e-05
Iter: 632 loss: 4.75681263e-05
Iter: 633 loss: 4.75677589e-05
Iter: 634 loss: 4.75675697e-05
Iter: 635 loss: 4.75679517e-05
Iter: 636 loss: 4.75676279e-05
Iter: 637 loss: 4.75675479e-05
Iter: 638 loss: 4.75676352e-05
Iter: 639 loss: 4.75676425e-05
Iter: 640 loss: 4.75675624e-05
Iter: 641 loss: 4.75675624e-05
Iter: 642 loss: 4.7568079e-05
Iter: 643 loss: 4.75675406e-05
Iter: 644 loss: 4.75675479e-05
Iter: 645 loss: 4.75675697e-05
Iter: 646 loss: 4.75675188e-05
Iter: 647 loss: 4.75674533e-05
Iter: 648 loss: 4.75676825e-05
Iter: 649 loss: 4.75674751e-05
Iter: 650 loss: 4.75675115e-05
Iter: 651 loss: 4.75675806e-05
Iter: 652 loss: 4.75675333e-05
Iter: 653 loss: 4.75674533e-05
Iter: 654 loss: 4.75674897e-05
Iter: 655 loss: 4.75675e-05
Iter: 656 loss: 4.75674678e-05
Iter: 657 loss: 4.75674533e-05
Iter: 658 loss: 4.75674242e-05
Iter: 659 loss: 4.75674969e-05
Iter: 660 loss: 4.75675406e-05
Iter: 661 loss: 4.75675042e-05
Iter: 662 loss: 4.75675261e-05
Iter: 663 loss: 4.75675261e-05
Iter: 664 loss: 4.7567537e-05
Iter: 665 loss: 4.75675333e-05
Iter: 666 loss: 4.75675188e-05
Iter: 667 loss: 4.75675188e-05
Iter: 668 loss: 4.75675297e-05
Iter: 669 loss: 4.75675261e-05
Iter: 670 loss: 4.75675188e-05
Iter: 671 loss: 4.75675188e-05
Iter: 672 loss: 4.75675188e-05
Iter: 673 loss: 4.75675224e-05
Iter: 674 loss: 4.75675224e-05
Iter: 675 loss: 4.75675261e-05
Iter: 676 loss: 4.75675224e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2
+ date
Tue Oct 27 15:04:05 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fe28d8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fe28dd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fe28b28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0b39620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0b39840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0b390d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6fa0abf598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c393840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c393268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c34f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c34f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c34f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c2abea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c2d31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c265f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c226ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c239378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c265510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c217d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c265378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c1648c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c1942f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c194268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c0fe048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c0fe598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c10cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c0c2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c0a70d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c092400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c0342f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c092840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c092950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c02af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f7c0340d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f60794488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6f60794ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0208741557
Iter: 2 loss: 0.0194908977
Iter: 3 loss: 0.015163037
Iter: 4 loss: 5117.58691
Iter: 5 loss: 0.015163037
Iter: 6 loss: 0.0121713411
Iter: 7 loss: 0.0116982553
Iter: 8 loss: 0.00888346881
Iter: 9 loss: 0.108355626
Iter: 10 loss: 0.00888292305
Iter: 11 loss: 0.00659607816
Iter: 12 loss: 0.0190607794
Iter: 13 loss: 0.0062443791
Iter: 14 loss: 0.00489733368
Iter: 15 loss: 0.00895042531
Iter: 16 loss: 0.00453248713
Iter: 17 loss: 0.0034166337
Iter: 18 loss: 0.00940749049
Iter: 19 loss: 0.00310734473
Iter: 20 loss: 0.00235233945
Iter: 21 loss: 0.00233913772
Iter: 22 loss: 0.00196974445
Iter: 23 loss: 0.00289681321
Iter: 24 loss: 0.00185355637
Iter: 25 loss: 0.00164272403
Iter: 26 loss: 0.00178911036
Iter: 27 loss: 0.00150409644
Iter: 28 loss: 0.0012878261
Iter: 29 loss: 0.00164440461
Iter: 30 loss: 0.00118258852
Iter: 31 loss: 0.000993339461
Iter: 32 loss: 0.00258067599
Iter: 33 loss: 0.000979540171
Iter: 34 loss: 0.000841312693
Iter: 35 loss: 0.00164082309
Iter: 36 loss: 0.000821369234
Iter: 37 loss: 0.000724604819
Iter: 38 loss: 0.0010057101
Iter: 39 loss: 0.000692279777
Iter: 40 loss: 0.000621625863
Iter: 41 loss: 0.00119021628
Iter: 42 loss: 0.000616129721
Iter: 43 loss: 0.000552267651
Iter: 44 loss: 0.000734386616
Iter: 45 loss: 0.000531895901
Iter: 46 loss: 0.000476147514
Iter: 47 loss: 0.000844957074
Iter: 48 loss: 0.000470135
Iter: 49 loss: 0.000431361696
Iter: 50 loss: 0.000608363771
Iter: 51 loss: 0.000422835816
Iter: 52 loss: 0.000386994332
Iter: 53 loss: 0.000494461
Iter: 54 loss: 0.00037599
Iter: 55 loss: 0.000346159854
Iter: 56 loss: 0.000430616376
Iter: 57 loss: 0.000336506491
Iter: 58 loss: 0.000308333954
Iter: 59 loss: 0.000479620561
Iter: 60 loss: 0.000305260532
Iter: 61 loss: 0.000287924573
Iter: 62 loss: 0.000482914504
Iter: 63 loss: 0.000287346193
Iter: 64 loss: 0.000272706908
Iter: 65 loss: 0.000272666512
Iter: 66 loss: 0.000261072943
Iter: 67 loss: 0.000243164512
Iter: 68 loss: 0.000278593769
Iter: 69 loss: 0.000235690022
Iter: 70 loss: 0.000218099289
Iter: 71 loss: 0.000258460699
Iter: 72 loss: 0.000211581617
Iter: 73 loss: 0.000197034096
Iter: 74 loss: 0.000266767194
Iter: 75 loss: 0.000194295339
Iter: 76 loss: 0.000182438336
Iter: 77 loss: 0.00025203664
Iter: 78 loss: 0.000180846313
Iter: 79 loss: 0.000171633495
Iter: 80 loss: 0.000190740233
Iter: 81 loss: 0.000167911421
Iter: 82 loss: 0.000158731506
Iter: 83 loss: 0.000189576618
Iter: 84 loss: 0.000156265916
Iter: 85 loss: 0.000148840947
Iter: 86 loss: 0.0002010772
Iter: 87 loss: 0.000148086197
Iter: 88 loss: 0.000141977172
Iter: 89 loss: 0.00016054383
Iter: 90 loss: 0.000140170188
Iter: 91 loss: 0.000135003327
Iter: 92 loss: 0.000143162935
Iter: 93 loss: 0.0001325583
Iter: 94 loss: 0.000127789011
Iter: 95 loss: 0.000168518949
Iter: 96 loss: 0.000127560197
Iter: 97 loss: 0.000123093283
Iter: 98 loss: 0.00013841255
Iter: 99 loss: 0.000121860736
Iter: 100 loss: 0.00011841832
Iter: 101 loss: 0.000121824007
Iter: 102 loss: 0.000116490075
Iter: 103 loss: 0.000112730588
Iter: 104 loss: 0.000116216223
Iter: 105 loss: 0.000110542809
Iter: 106 loss: 0.000106391271
Iter: 107 loss: 0.000114595314
Iter: 108 loss: 0.000104683968
Iter: 109 loss: 0.000100716978
Iter: 110 loss: 0.000126136962
Iter: 111 loss: 0.000100271405
Iter: 112 loss: 9.7048789e-05
Iter: 113 loss: 0.000107716347
Iter: 114 loss: 9.61532787e-05
Iter: 115 loss: 9.32680414e-05
Iter: 116 loss: 0.000101826568
Iter: 117 loss: 9.23858461e-05
Iter: 118 loss: 8.97561549e-05
Iter: 119 loss: 9.6669246e-05
Iter: 120 loss: 8.88775903e-05
Iter: 121 loss: 8.66722839e-05
Iter: 122 loss: 0.000115578587
Iter: 123 loss: 8.6654909e-05
Iter: 124 loss: 8.51704317e-05
Iter: 125 loss: 8.53855308e-05
Iter: 126 loss: 8.40450521e-05
Iter: 127 loss: 8.21566209e-05
Iter: 128 loss: 8.88244904e-05
Iter: 129 loss: 8.16584507e-05
Iter: 130 loss: 8.03315634e-05
Iter: 131 loss: 8.03309958e-05
Iter: 132 loss: 7.92111605e-05
Iter: 133 loss: 7.82988573e-05
Iter: 134 loss: 7.79669354e-05
Iter: 135 loss: 7.65211807e-05
Iter: 136 loss: 7.99555564e-05
Iter: 137 loss: 7.59968534e-05
Iter: 138 loss: 7.45861689e-05
Iter: 139 loss: 7.78051763e-05
Iter: 140 loss: 7.40546166e-05
Iter: 141 loss: 7.2692128e-05
Iter: 142 loss: 7.49303e-05
Iter: 143 loss: 7.20677926e-05
Iter: 144 loss: 7.06631254e-05
Iter: 145 loss: 7.90192425e-05
Iter: 146 loss: 7.04833656e-05
Iter: 147 loss: 6.93743641e-05
Iter: 148 loss: 7.24089768e-05
Iter: 149 loss: 6.90105953e-05
Iter: 150 loss: 6.79125369e-05
Iter: 151 loss: 7.05608254e-05
Iter: 152 loss: 6.75143383e-05
Iter: 153 loss: 6.65859116e-05
Iter: 154 loss: 7.32306653e-05
Iter: 155 loss: 6.65054395e-05
Iter: 156 loss: 6.57314522e-05
Iter: 157 loss: 6.84976476e-05
Iter: 158 loss: 6.55319163e-05
Iter: 159 loss: 6.47801498e-05
Iter: 160 loss: 6.67973945e-05
Iter: 161 loss: 6.45315158e-05
Iter: 162 loss: 6.39405771e-05
Iter: 163 loss: 6.57895725e-05
Iter: 164 loss: 6.37665507e-05
Iter: 165 loss: 6.3103e-05
Iter: 166 loss: 6.683416e-05
Iter: 167 loss: 6.30118e-05
Iter: 168 loss: 6.25615212e-05
Iter: 169 loss: 6.21774816e-05
Iter: 170 loss: 6.20529172e-05
Iter: 171 loss: 6.13681041e-05
Iter: 172 loss: 6.34226162e-05
Iter: 173 loss: 6.1162209e-05
Iter: 174 loss: 6.05410642e-05
Iter: 175 loss: 6.26090768e-05
Iter: 176 loss: 6.03697554e-05
Iter: 177 loss: 5.98061924e-05
Iter: 178 loss: 6.09338567e-05
Iter: 179 loss: 5.95756e-05
Iter: 180 loss: 5.89600277e-05
Iter: 181 loss: 6.01111533e-05
Iter: 182 loss: 5.86975875e-05
Iter: 183 loss: 5.81272107e-05
Iter: 184 loss: 6.21628e-05
Iter: 185 loss: 5.80761771e-05
Iter: 186 loss: 5.75983322e-05
Iter: 187 loss: 5.82639768e-05
Iter: 188 loss: 5.73616344e-05
Iter: 189 loss: 5.68955729e-05
Iter: 190 loss: 5.97788676e-05
Iter: 191 loss: 5.68410251e-05
Iter: 192 loss: 5.64225775e-05
Iter: 193 loss: 5.85284142e-05
Iter: 194 loss: 5.63519206e-05
Iter: 195 loss: 5.60329536e-05
Iter: 196 loss: 5.63598769e-05
Iter: 197 loss: 5.58554639e-05
Iter: 198 loss: 5.55176157e-05
Iter: 199 loss: 5.86172573e-05
Iter: 200 loss: 5.55020852e-05
Iter: 201 loss: 5.52190322e-05
Iter: 202 loss: 5.52253514e-05
Iter: 203 loss: 5.49946e-05
Iter: 204 loss: 5.46778501e-05
Iter: 205 loss: 5.510337e-05
Iter: 206 loss: 5.45182338e-05
Iter: 207 loss: 5.41426489e-05
Iter: 208 loss: 5.46253905e-05
Iter: 209 loss: 5.39502798e-05
Iter: 210 loss: 5.35525323e-05
Iter: 211 loss: 5.58352622e-05
Iter: 212 loss: 5.34984792e-05
Iter: 213 loss: 5.31738697e-05
Iter: 214 loss: 5.35681902e-05
Iter: 215 loss: 5.30037942e-05
Iter: 216 loss: 5.26688564e-05
Iter: 217 loss: 5.39240718e-05
Iter: 218 loss: 5.25873693e-05
Iter: 219 loss: 5.22453665e-05
Iter: 220 loss: 5.32051235e-05
Iter: 221 loss: 5.21361253e-05
Iter: 222 loss: 5.18332381e-05
Iter: 223 loss: 5.29628123e-05
Iter: 224 loss: 5.17589069e-05
Iter: 225 loss: 5.15123247e-05
Iter: 226 loss: 5.37342967e-05
Iter: 227 loss: 5.15010906e-05
Iter: 228 loss: 5.13059094e-05
Iter: 229 loss: 5.16995788e-05
Iter: 230 loss: 5.12262886e-05
Iter: 231 loss: 5.10288228e-05
Iter: 232 loss: 5.16707805e-05
Iter: 233 loss: 5.09737656e-05
Iter: 234 loss: 5.07738514e-05
Iter: 235 loss: 5.15712491e-05
Iter: 236 loss: 5.07283585e-05
Iter: 237 loss: 5.05647658e-05
Iter: 238 loss: 5.0476483e-05
Iter: 239 loss: 5.04032287e-05
Iter: 240 loss: 5.01621034e-05
Iter: 241 loss: 5.05717908e-05
Iter: 242 loss: 5.00539318e-05
Iter: 243 loss: 4.98209629e-05
Iter: 244 loss: 5.09506899e-05
Iter: 245 loss: 4.97801811e-05
Iter: 246 loss: 4.95672975e-05
Iter: 247 loss: 5.01671384e-05
Iter: 248 loss: 4.94994165e-05
Iter: 249 loss: 4.92970867e-05
Iter: 250 loss: 4.93721163e-05
Iter: 251 loss: 4.91555766e-05
Iter: 252 loss: 4.89257654e-05
Iter: 253 loss: 5.08742523e-05
Iter: 254 loss: 4.89125559e-05
Iter: 255 loss: 4.8735561e-05
Iter: 256 loss: 4.90713646e-05
Iter: 257 loss: 4.86610079e-05
Iter: 258 loss: 4.84910779e-05
Iter: 259 loss: 4.95576678e-05
Iter: 260 loss: 4.84711964e-05
Iter: 261 loss: 4.83269032e-05
Iter: 262 loss: 4.90810562e-05
Iter: 263 loss: 4.83043368e-05
Iter: 264 loss: 4.81827374e-05
Iter: 265 loss: 4.83719887e-05
Iter: 266 loss: 4.81254319e-05
Iter: 267 loss: 4.80017916e-05
Iter: 268 loss: 4.88229234e-05
Iter: 269 loss: 4.79891823e-05
Iter: 270 loss: 4.7889127e-05
Iter: 271 loss: 4.78312795e-05
Iter: 272 loss: 4.77885478e-05
Iter: 273 loss: 4.76531823e-05
Iter: 274 loss: 4.80289964e-05
Iter: 275 loss: 4.76095593e-05
Iter: 276 loss: 4.74854605e-05
Iter: 277 loss: 4.76310452e-05
Iter: 278 loss: 4.74194603e-05
Iter: 279 loss: 4.72837e-05
Iter: 280 loss: 4.81053685e-05
Iter: 281 loss: 4.72669562e-05
Iter: 282 loss: 4.71499043e-05
Iter: 283 loss: 4.72249812e-05
Iter: 284 loss: 4.70755112e-05
Iter: 285 loss: 4.69421e-05
Iter: 286 loss: 4.76102578e-05
Iter: 287 loss: 4.6919653e-05
Iter: 288 loss: 4.68091312e-05
Iter: 289 loss: 4.70641571e-05
Iter: 290 loss: 4.67679201e-05
Iter: 291 loss: 4.66623351e-05
Iter: 292 loss: 4.71887543e-05
Iter: 293 loss: 4.6644629e-05
Iter: 294 loss: 4.6556841e-05
Iter: 295 loss: 4.71634739e-05
Iter: 296 loss: 4.65483099e-05
Iter: 297 loss: 4.64738e-05
Iter: 298 loss: 4.66482088e-05
Iter: 299 loss: 4.6446472e-05
Iter: 300 loss: 4.63804754e-05
Iter: 301 loss: 4.66398124e-05
Iter: 302 loss: 4.63651668e-05
Iter: 303 loss: 4.62964599e-05
Iter: 304 loss: 4.63488905e-05
Iter: 305 loss: 4.62546086e-05
Iter: 306 loss: 4.61790441e-05
Iter: 307 loss: 4.63258402e-05
Iter: 308 loss: 4.61477175e-05
Iter: 309 loss: 4.60725569e-05
Iter: 310 loss: 4.60727133e-05
Iter: 311 loss: 4.60123774e-05
Iter: 312 loss: 4.59230178e-05
Iter: 313 loss: 4.64373079e-05
Iter: 314 loss: 4.59109142e-05
Iter: 315 loss: 4.58289142e-05
Iter: 316 loss: 4.61211275e-05
Iter: 317 loss: 4.58080031e-05
Iter: 318 loss: 4.57393144e-05
Iter: 319 loss: 4.58210416e-05
Iter: 320 loss: 4.57029673e-05
Iter: 321 loss: 4.56254093e-05
Iter: 322 loss: 4.59335461e-05
Iter: 323 loss: 4.56079579e-05
Iter: 324 loss: 4.55389854e-05
Iter: 325 loss: 4.579706e-05
Iter: 326 loss: 4.55223053e-05
Iter: 327 loss: 4.54694746e-05
Iter: 328 loss: 4.59385119e-05
Iter: 329 loss: 4.54668952e-05
Iter: 330 loss: 4.54220863e-05
Iter: 331 loss: 4.55583868e-05
Iter: 332 loss: 4.54087349e-05
Iter: 333 loss: 4.53668472e-05
Iter: 334 loss: 4.54433903e-05
Iter: 335 loss: 4.53488756e-05
Iter: 336 loss: 4.53043976e-05
Iter: 337 loss: 4.54930596e-05
Iter: 338 loss: 4.5295e-05
Iter: 339 loss: 4.52587337e-05
Iter: 340 loss: 4.52645399e-05
Iter: 341 loss: 4.52314453e-05
Iter: 342 loss: 4.51837332e-05
Iter: 343 loss: 4.52427121e-05
Iter: 344 loss: 4.51589294e-05
Iter: 345 loss: 4.51086e-05
Iter: 346 loss: 4.52372624e-05
Iter: 347 loss: 4.50912557e-05
Iter: 348 loss: 4.50425941e-05
Iter: 349 loss: 4.53191751e-05
Iter: 350 loss: 4.50358348e-05
Iter: 351 loss: 4.49963372e-05
Iter: 352 loss: 4.5034918e-05
Iter: 353 loss: 4.49739891e-05
Iter: 354 loss: 4.49314466e-05
Iter: 355 loss: 4.51489868e-05
Iter: 356 loss: 4.49244908e-05
Iter: 357 loss: 4.48861829e-05
Iter: 358 loss: 4.49493236e-05
Iter: 359 loss: 4.48685751e-05
Iter: 360 loss: 4.48321844e-05
Iter: 361 loss: 4.50649095e-05
Iter: 362 loss: 4.48281426e-05
Iter: 363 loss: 4.47994935e-05
Iter: 364 loss: 4.5068442e-05
Iter: 365 loss: 4.47982966e-05
Iter: 366 loss: 4.47776401e-05
Iter: 367 loss: 4.47955535e-05
Iter: 368 loss: 4.47653874e-05
Iter: 369 loss: 4.474253e-05
Iter: 370 loss: 4.48403371e-05
Iter: 371 loss: 4.47378698e-05
Iter: 372 loss: 4.47162456e-05
Iter: 373 loss: 4.47205348e-05
Iter: 374 loss: 4.47000857e-05
Iter: 375 loss: 4.46727499e-05
Iter: 376 loss: 4.47344282e-05
Iter: 377 loss: 4.46624326e-05
Iter: 378 loss: 4.46358754e-05
Iter: 379 loss: 4.46673876e-05
Iter: 380 loss: 4.46217928e-05
Iter: 381 loss: 4.45934129e-05
Iter: 382 loss: 4.46919294e-05
Iter: 383 loss: 4.45860314e-05
Iter: 384 loss: 4.45596088e-05
Iter: 385 loss: 4.46636586e-05
Iter: 386 loss: 4.45536243e-05
Iter: 387 loss: 4.45302176e-05
Iter: 388 loss: 4.45879123e-05
Iter: 389 loss: 4.4522e-05
Iter: 390 loss: 4.44973593e-05
Iter: 391 loss: 4.45569676e-05
Iter: 392 loss: 4.44885882e-05
Iter: 393 loss: 4.44665638e-05
Iter: 394 loss: 4.45419973e-05
Iter: 395 loss: 4.44607249e-05
Iter: 396 loss: 4.44430843e-05
Iter: 397 loss: 4.46802624e-05
Iter: 398 loss: 4.44429534e-05
Iter: 399 loss: 4.44290527e-05
Iter: 400 loss: 4.44507823e-05
Iter: 401 loss: 4.44226e-05
Iter: 402 loss: 4.44086872e-05
Iter: 403 loss: 4.44386787e-05
Iter: 404 loss: 4.44033649e-05
Iter: 405 loss: 4.43877252e-05
Iter: 406 loss: 4.44187281e-05
Iter: 407 loss: 4.43813115e-05
Iter: 408 loss: 4.43664139e-05
Iter: 409 loss: 4.43886311e-05
Iter: 410 loss: 4.43592726e-05
Iter: 411 loss: 4.43428726e-05
Iter: 412 loss: 4.43624667e-05
Iter: 413 loss: 4.43342215e-05
Iter: 414 loss: 4.43172394e-05
Iter: 415 loss: 4.43651516e-05
Iter: 416 loss: 4.43119e-05
Iter: 417 loss: 4.4295557e-05
Iter: 418 loss: 4.43531681e-05
Iter: 419 loss: 4.42913079e-05
Iter: 420 loss: 4.4275941e-05
Iter: 421 loss: 4.43256431e-05
Iter: 422 loss: 4.42716118e-05
Iter: 423 loss: 4.42574274e-05
Iter: 424 loss: 4.42948767e-05
Iter: 425 loss: 4.42527671e-05
Iter: 426 loss: 4.42391465e-05
Iter: 427 loss: 4.42721139e-05
Iter: 428 loss: 4.42343371e-05
Iter: 429 loss: 4.42223245e-05
Iter: 430 loss: 4.4333312e-05
Iter: 431 loss: 4.4221757e-05
Iter: 432 loss: 4.4212e-05
Iter: 433 loss: 4.42696801e-05
Iter: 434 loss: 4.42107703e-05
Iter: 435 loss: 4.42034943e-05
Iter: 436 loss: 4.42057717e-05
Iter: 437 loss: 4.41983138e-05
Iter: 438 loss: 4.41889788e-05
Iter: 439 loss: 4.42228666e-05
Iter: 440 loss: 4.41866578e-05
Iter: 441 loss: 4.41777811e-05
Iter: 442 loss: 4.41852753e-05
Iter: 443 loss: 4.41723532e-05
Iter: 444 loss: 4.41628144e-05
Iter: 445 loss: 4.41787088e-05
Iter: 446 loss: 4.41585835e-05
Iter: 447 loss: 4.41480515e-05
Iter: 448 loss: 4.41745942e-05
Iter: 449 loss: 4.41442935e-05
Iter: 450 loss: 4.4133878e-05
Iter: 451 loss: 4.41614029e-05
Iter: 452 loss: 4.41303891e-05
Iter: 453 loss: 4.41201046e-05
Iter: 454 loss: 4.41468947e-05
Iter: 455 loss: 4.41165685e-05
Iter: 456 loss: 4.4106826e-05
Iter: 457 loss: 4.41392112e-05
Iter: 458 loss: 4.4104152e-05
Iter: 459 loss: 4.40946678e-05
Iter: 460 loss: 4.41264056e-05
Iter: 461 loss: 4.40920776e-05
Iter: 462 loss: 4.40836739e-05
Iter: 463 loss: 4.41123557e-05
Iter: 464 loss: 4.40814329e-05
Iter: 465 loss: 4.40748263e-05
Iter: 466 loss: 4.41724187e-05
Iter: 467 loss: 4.40748663e-05
Iter: 468 loss: 4.40697331e-05
Iter: 469 loss: 4.40705408e-05
Iter: 470 loss: 4.40657823e-05
Iter: 471 loss: 4.40599433e-05
Iter: 472 loss: 4.40750737e-05
Iter: 473 loss: 4.40580079e-05
Iter: 474 loss: 4.4051525e-05
Iter: 475 loss: 4.40637159e-05
Iter: 476 loss: 4.40487e-05
Iter: 477 loss: 4.40426229e-05
Iter: 478 loss: 4.40486911e-05
Iter: 479 loss: 4.40392141e-05
Iter: 480 loss: 4.40322547e-05
Iter: 481 loss: 4.40541844e-05
Iter: 482 loss: 4.40303193e-05
Iter: 483 loss: 4.40237272e-05
Iter: 484 loss: 4.40380172e-05
Iter: 485 loss: 4.40212898e-05
Iter: 486 loss: 4.40141339e-05
Iter: 487 loss: 4.40269578e-05
Iter: 488 loss: 4.40109434e-05
Iter: 489 loss: 4.40040676e-05
Iter: 490 loss: 4.40281656e-05
Iter: 491 loss: 4.40023141e-05
Iter: 492 loss: 4.39960313e-05
Iter: 493 loss: 4.40280201e-05
Iter: 494 loss: 4.39949872e-05
Iter: 495 loss: 4.39895921e-05
Iter: 496 loss: 4.39983633e-05
Iter: 497 loss: 4.39871401e-05
Iter: 498 loss: 4.39826545e-05
Iter: 499 loss: 4.39826799e-05
Iter: 500 loss: 4.39787837e-05
Iter: 501 loss: 4.39835676e-05
Iter: 502 loss: 4.39768555e-05
Iter: 503 loss: 4.39731302e-05
Iter: 504 loss: 4.39773066e-05
Iter: 505 loss: 4.39712094e-05
Iter: 506 loss: 4.39667747e-05
Iter: 507 loss: 4.39813302e-05
Iter: 508 loss: 4.3965545e-05
Iter: 509 loss: 4.39615142e-05
Iter: 510 loss: 4.39652358e-05
Iter: 511 loss: 4.39591531e-05
Iter: 512 loss: 4.39546566e-05
Iter: 513 loss: 4.39626492e-05
Iter: 514 loss: 4.39526812e-05
Iter: 515 loss: 4.39478499e-05
Iter: 516 loss: 4.3964108e-05
Iter: 517 loss: 4.3946653e-05
Iter: 518 loss: 4.394196e-05
Iter: 519 loss: 4.39494106e-05
Iter: 520 loss: 4.39398973e-05
Iter: 521 loss: 4.39349242e-05
Iter: 522 loss: 4.39499199e-05
Iter: 523 loss: 4.39335854e-05
Iter: 524 loss: 4.39290598e-05
Iter: 525 loss: 4.3948352e-05
Iter: 526 loss: 4.39282157e-05
Iter: 527 loss: 4.39241849e-05
Iter: 528 loss: 4.39343494e-05
Iter: 529 loss: 4.39228206e-05
Iter: 530 loss: 4.39195428e-05
Iter: 531 loss: 4.39453361e-05
Iter: 532 loss: 4.3919259e-05
Iter: 533 loss: 4.39160976e-05
Iter: 534 loss: 4.39335417e-05
Iter: 535 loss: 4.39156393e-05
Iter: 536 loss: 4.39134965e-05
Iter: 537 loss: 4.39137802e-05
Iter: 538 loss: 4.39119576e-05
Iter: 539 loss: 4.39092219e-05
Iter: 540 loss: 4.39176292e-05
Iter: 541 loss: 4.39084652e-05
Iter: 542 loss: 4.39057112e-05
Iter: 543 loss: 4.3911914e-05
Iter: 544 loss: 4.39046307e-05
Iter: 545 loss: 4.39020041e-05
Iter: 546 loss: 4.39036048e-05
Iter: 547 loss: 4.39001669e-05
Iter: 548 loss: 4.38971074e-05
Iter: 549 loss: 4.39044597e-05
Iter: 550 loss: 4.3895976e-05
Iter: 551 loss: 4.38926072e-05
Iter: 552 loss: 4.39023788e-05
Iter: 553 loss: 4.38915886e-05
Iter: 554 loss: 4.38885108e-05
Iter: 555 loss: 4.38985735e-05
Iter: 556 loss: 4.38876814e-05
Iter: 557 loss: 4.38846655e-05
Iter: 558 loss: 4.38943e-05
Iter: 559 loss: 4.38838324e-05
Iter: 560 loss: 4.38811694e-05
Iter: 561 loss: 4.3885695e-05
Iter: 562 loss: 4.38799398e-05
Iter: 563 loss: 4.38773386e-05
Iter: 564 loss: 4.38960415e-05
Iter: 565 loss: 4.38771385e-05
Iter: 566 loss: 4.38751886e-05
Iter: 567 loss: 4.39001851e-05
Iter: 568 loss: 4.38751413e-05
Iter: 569 loss: 4.38737698e-05
Iter: 570 loss: 4.38729694e-05
Iter: 571 loss: 4.38724674e-05
Iter: 572 loss: 4.38706e-05
Iter: 573 loss: 4.38758434e-05
Iter: 574 loss: 4.38699681e-05
Iter: 575 loss: 4.386816e-05
Iter: 576 loss: 4.38736643e-05
Iter: 577 loss: 4.38676507e-05
Iter: 578 loss: 4.38657298e-05
Iter: 579 loss: 4.38682582e-05
Iter: 580 loss: 4.38646603e-05
Iter: 581 loss: 4.38628958e-05
Iter: 582 loss: 4.38644565e-05
Iter: 583 loss: 4.38616407e-05
Iter: 584 loss: 4.38594325e-05
Iter: 585 loss: 4.3866763e-05
Iter: 586 loss: 4.38587886e-05
Iter: 587 loss: 4.38565694e-05
Iter: 588 loss: 4.3862834e-05
Iter: 589 loss: 4.385594e-05
Iter: 590 loss: 4.38539937e-05
Iter: 591 loss: 4.38647221e-05
Iter: 592 loss: 4.38537681e-05
Iter: 593 loss: 4.38521492e-05
Iter: 594 loss: 4.38531097e-05
Iter: 595 loss: 4.38510142e-05
Iter: 596 loss: 4.38491552e-05
Iter: 597 loss: 4.38600036e-05
Iter: 598 loss: 4.38488569e-05
Iter: 599 loss: 4.38476818e-05
Iter: 600 loss: 4.38665375e-05
Iter: 601 loss: 4.38476709e-05
Iter: 602 loss: 4.38466159e-05
Iter: 603 loss: 4.3846856e-05
Iter: 604 loss: 4.38459028e-05
Iter: 605 loss: 4.38446477e-05
Iter: 606 loss: 4.38458701e-05
Iter: 607 loss: 4.3843982e-05
Iter: 608 loss: 4.38426105e-05
Iter: 609 loss: 4.38479619e-05
Iter: 610 loss: 4.38423e-05
Iter: 611 loss: 4.38410316e-05
Iter: 612 loss: 4.38436036e-05
Iter: 613 loss: 4.3840475e-05
Iter: 614 loss: 4.38391362e-05
Iter: 615 loss: 4.38399657e-05
Iter: 616 loss: 4.38381612e-05
Iter: 617 loss: 4.38367169e-05
Iter: 618 loss: 4.38426723e-05
Iter: 619 loss: 4.38363677e-05
Iter: 620 loss: 4.38349743e-05
Iter: 621 loss: 4.38379211e-05
Iter: 622 loss: 4.38345196e-05
Iter: 623 loss: 4.38331153e-05
Iter: 624 loss: 4.3836626e-05
Iter: 625 loss: 4.38326751e-05
Iter: 626 loss: 4.38311945e-05
Iter: 627 loss: 4.38358547e-05
Iter: 628 loss: 4.38306961e-05
Iter: 629 loss: 4.38294483e-05
Iter: 630 loss: 4.38329807e-05
Iter: 631 loss: 4.38290335e-05
Iter: 632 loss: 4.38280877e-05
Iter: 633 loss: 4.38281168e-05
Iter: 634 loss: 4.38272327e-05
Iter: 635 loss: 4.38290444e-05
Iter: 636 loss: 4.38270181e-05
Iter: 637 loss: 4.3826265e-05
Iter: 638 loss: 4.38259558e-05
Iter: 639 loss: 4.38255629e-05
Iter: 640 loss: 4.38245479e-05
Iter: 641 loss: 4.38285642e-05
Iter: 642 loss: 4.38243078e-05
Iter: 643 loss: 4.38233874e-05
Iter: 644 loss: 4.38258721e-05
Iter: 645 loss: 4.38230709e-05
Iter: 646 loss: 4.38221032e-05
Iter: 647 loss: 4.38231764e-05
Iter: 648 loss: 4.38215793e-05
Iter: 649 loss: 4.38206407e-05
Iter: 650 loss: 4.3822467e-05
Iter: 651 loss: 4.38202442e-05
Iter: 652 loss: 4.38192328e-05
Iter: 653 loss: 4.38237184e-05
Iter: 654 loss: 4.38190546e-05
Iter: 655 loss: 4.38180723e-05
Iter: 656 loss: 4.38197603e-05
Iter: 657 loss: 4.38176976e-05
Iter: 658 loss: 4.38168499e-05
Iter: 659 loss: 4.38197821e-05
Iter: 660 loss: 4.38165407e-05
Iter: 661 loss: 4.3815613e-05
Iter: 662 loss: 4.38176467e-05
Iter: 663 loss: 4.38153147e-05
Iter: 664 loss: 4.38145544e-05
Iter: 665 loss: 4.38219322e-05
Iter: 666 loss: 4.3814638e-05
Iter: 667 loss: 4.38138886e-05
Iter: 668 loss: 4.38180105e-05
Iter: 669 loss: 4.38138813e-05
Iter: 670 loss: 4.38135103e-05
Iter: 671 loss: 4.38132e-05
Iter: 672 loss: 4.38130301e-05
Iter: 673 loss: 4.38123679e-05
Iter: 674 loss: 4.38135321e-05
Iter: 675 loss: 4.3812106e-05
Iter: 676 loss: 4.38114294e-05
Iter: 677 loss: 4.38153547e-05
Iter: 678 loss: 4.38113893e-05
Iter: 679 loss: 4.381084e-05
Iter: 680 loss: 4.38111019e-05
Iter: 681 loss: 4.38104471e-05
Iter: 682 loss: 4.38098e-05
Iter: 683 loss: 4.38110656e-05
Iter: 684 loss: 4.38095085e-05
Iter: 685 loss: 4.38088209e-05
Iter: 686 loss: 4.38108691e-05
Iter: 687 loss: 4.38086427e-05
Iter: 688 loss: 4.38079805e-05
Iter: 689 loss: 4.38097231e-05
Iter: 690 loss: 4.38077113e-05
Iter: 691 loss: 4.38070347e-05
Iter: 692 loss: 4.38084535e-05
Iter: 693 loss: 4.38068564e-05
Iter: 694 loss: 4.38062052e-05
Iter: 695 loss: 4.3808468e-05
Iter: 696 loss: 4.38060342e-05
Iter: 697 loss: 4.38055613e-05
Iter: 698 loss: 4.38085699e-05
Iter: 699 loss: 4.38054631e-05
Iter: 700 loss: 4.3805052e-05
Iter: 701 loss: 4.38102e-05
Iter: 702 loss: 4.38050956e-05
Iter: 703 loss: 4.38046955e-05
Iter: 704 loss: 4.38045536e-05
Iter: 705 loss: 4.38043753e-05
Iter: 706 loss: 4.38039606e-05
Iter: 707 loss: 4.38045608e-05
Iter: 708 loss: 4.38038187e-05
Iter: 709 loss: 4.38033567e-05
Iter: 710 loss: 4.3805936e-05
Iter: 711 loss: 4.38032221e-05
Iter: 712 loss: 4.38028146e-05
Iter: 713 loss: 4.38034331e-05
Iter: 714 loss: 4.38026764e-05
Iter: 715 loss: 4.38021962e-05
Iter: 716 loss: 4.38023853e-05
Iter: 717 loss: 4.38019342e-05
Iter: 718 loss: 4.38013558e-05
Iter: 719 loss: 4.38032876e-05
Iter: 720 loss: 4.3801283e-05
Iter: 721 loss: 4.38007628e-05
Iter: 722 loss: 4.38022034e-05
Iter: 723 loss: 4.38005882e-05
Iter: 724 loss: 4.38001116e-05
Iter: 725 loss: 4.38013813e-05
Iter: 726 loss: 4.38000134e-05
Iter: 727 loss: 4.37995295e-05
Iter: 728 loss: 4.38003408e-05
Iter: 729 loss: 4.37993585e-05
Iter: 730 loss: 4.37989474e-05
Iter: 731 loss: 4.38009229e-05
Iter: 732 loss: 4.37988347e-05
Iter: 733 loss: 4.379858e-05
Iter: 734 loss: 4.37986382e-05
Iter: 735 loss: 4.37983399e-05
Iter: 736 loss: 4.37984054e-05
Iter: 737 loss: 4.37981143e-05
Iter: 738 loss: 4.37978088e-05
Iter: 739 loss: 4.37976923e-05
Iter: 740 loss: 4.37975941e-05
Iter: 741 loss: 4.37972121e-05
Iter: 742 loss: 4.37999151e-05
Iter: 743 loss: 4.37971466e-05
Iter: 744 loss: 4.37967828e-05
Iter: 745 loss: 4.37974813e-05
Iter: 746 loss: 4.37967392e-05
Iter: 747 loss: 4.37964e-05
Iter: 748 loss: 4.37967501e-05
Iter: 749 loss: 4.37962735e-05
Iter: 750 loss: 4.37958843e-05
Iter: 751 loss: 4.37965682e-05
Iter: 752 loss: 4.37957096e-05
Iter: 753 loss: 4.37953531e-05
Iter: 754 loss: 4.37968847e-05
Iter: 755 loss: 4.37952913e-05
Iter: 756 loss: 4.37950403e-05
Iter: 757 loss: 4.3795284e-05
Iter: 758 loss: 4.37948183e-05
Iter: 759 loss: 4.37945346e-05
Iter: 760 loss: 4.37958952e-05
Iter: 761 loss: 4.37943454e-05
Iter: 762 loss: 4.37940689e-05
Iter: 763 loss: 4.37948256e-05
Iter: 764 loss: 4.37939598e-05
Iter: 765 loss: 4.37936978e-05
Iter: 766 loss: 4.37937342e-05
Iter: 767 loss: 4.3793465e-05
Iter: 768 loss: 4.37938652e-05
Iter: 769 loss: 4.37934068e-05
Iter: 770 loss: 4.37932467e-05
Iter: 771 loss: 4.37930939e-05
Iter: 772 loss: 4.37930357e-05
Iter: 773 loss: 4.37927665e-05
Iter: 774 loss: 4.37937961e-05
Iter: 775 loss: 4.37927301e-05
Iter: 776 loss: 4.37925846e-05
Iter: 777 loss: 4.37933122e-05
Iter: 778 loss: 4.37924682e-05
Iter: 779 loss: 4.37922499e-05
Iter: 780 loss: 4.37925155e-05
Iter: 781 loss: 4.3792119e-05
Iter: 782 loss: 4.37919298e-05
Iter: 783 loss: 4.37922317e-05
Iter: 784 loss: 4.37918061e-05
Iter: 785 loss: 4.3791606e-05
Iter: 786 loss: 4.37924027e-05
Iter: 787 loss: 4.37915733e-05
Iter: 788 loss: 4.37912822e-05
Iter: 789 loss: 4.37918316e-05
Iter: 790 loss: 4.37911585e-05
Iter: 791 loss: 4.37909839e-05
Iter: 792 loss: 4.37913477e-05
Iter: 793 loss: 4.37907547e-05
Iter: 794 loss: 4.37906056e-05
Iter: 795 loss: 4.37918316e-05
Iter: 796 loss: 4.3790471e-05
Iter: 797 loss: 4.37903727e-05
Iter: 798 loss: 4.37917042e-05
Iter: 799 loss: 4.37903655e-05
Iter: 800 loss: 4.37901326e-05
Iter: 801 loss: 4.3791224e-05
Iter: 802 loss: 4.37901108e-05
Iter: 803 loss: 4.379e-05
Iter: 804 loss: 4.37898561e-05
Iter: 805 loss: 4.37898198e-05
Iter: 806 loss: 4.37896742e-05
Iter: 807 loss: 4.37901763e-05
Iter: 808 loss: 4.37896815e-05
Iter: 809 loss: 4.37893978e-05
Iter: 810 loss: 4.37903327e-05
Iter: 811 loss: 4.37894196e-05
Iter: 812 loss: 4.37892741e-05
Iter: 813 loss: 4.3789456e-05
Iter: 814 loss: 4.37892086e-05
Iter: 815 loss: 4.37891e-05
Iter: 816 loss: 4.37892304e-05
Iter: 817 loss: 4.37888739e-05
Iter: 818 loss: 4.37887575e-05
Iter: 819 loss: 4.37892159e-05
Iter: 820 loss: 4.37886774e-05
Iter: 821 loss: 4.37885283e-05
Iter: 822 loss: 4.37892049e-05
Iter: 823 loss: 4.37884955e-05
Iter: 824 loss: 4.37882954e-05
Iter: 825 loss: 4.37885465e-05
Iter: 826 loss: 4.37881972e-05
Iter: 827 loss: 4.37880371e-05
Iter: 828 loss: 4.37885137e-05
Iter: 829 loss: 4.37879316e-05
Iter: 830 loss: 4.37878443e-05
Iter: 831 loss: 4.37890048e-05
Iter: 832 loss: 4.3787848e-05
Iter: 833 loss: 4.37877352e-05
Iter: 834 loss: 4.37891649e-05
Iter: 835 loss: 4.37876733e-05
Iter: 836 loss: 4.37875715e-05
Iter: 837 loss: 4.3787506e-05
Iter: 838 loss: 4.3787586e-05
Iter: 839 loss: 4.37873932e-05
Iter: 840 loss: 4.37875642e-05
Iter: 841 loss: 4.37872804e-05
Iter: 842 loss: 4.37872404e-05
Iter: 843 loss: 4.37878916e-05
Iter: 844 loss: 4.37871713e-05
Iter: 845 loss: 4.37870804e-05
Iter: 846 loss: 4.37872513e-05
Iter: 847 loss: 4.37870876e-05
Iter: 848 loss: 4.37868475e-05
Iter: 849 loss: 4.37869967e-05
Iter: 850 loss: 4.37868912e-05
Iter: 851 loss: 4.37867711e-05
Iter: 852 loss: 4.37872295e-05
Iter: 853 loss: 4.37867e-05
Iter: 854 loss: 4.37865747e-05
Iter: 855 loss: 4.37869421e-05
Iter: 856 loss: 4.37865638e-05
Iter: 857 loss: 4.37864437e-05
Iter: 858 loss: 4.37867056e-05
Iter: 859 loss: 4.37863637e-05
Iter: 860 loss: 4.37861818e-05
Iter: 861 loss: 4.37866074e-05
Iter: 862 loss: 4.37861927e-05
Iter: 863 loss: 4.3786069e-05
Iter: 864 loss: 4.37865383e-05
Iter: 865 loss: 4.3786109e-05
Iter: 866 loss: 4.37860217e-05
Iter: 867 loss: 4.3786e-05
Iter: 868 loss: 4.37860217e-05
Iter: 869 loss: 4.37859271e-05
Iter: 870 loss: 4.37859453e-05
Iter: 871 loss: 4.37858471e-05
Iter: 872 loss: 4.37858907e-05
Iter: 873 loss: 4.37857743e-05
Iter: 874 loss: 4.37856907e-05
Iter: 875 loss: 4.37860144e-05
Iter: 876 loss: 4.37856e-05
Iter: 877 loss: 4.3785556e-05
Iter: 878 loss: 4.37859708e-05
Iter: 879 loss: 4.37855851e-05
Iter: 880 loss: 4.3785476e-05
Iter: 881 loss: 4.37856215e-05
Iter: 882 loss: 4.37854396e-05
Iter: 883 loss: 4.37854105e-05
Iter: 884 loss: 4.3785556e-05
Iter: 885 loss: 4.37853087e-05
Iter: 886 loss: 4.37852905e-05
Iter: 887 loss: 4.37855379e-05
Iter: 888 loss: 4.37852032e-05
Iter: 889 loss: 4.37851777e-05
Iter: 890 loss: 4.37854142e-05
Iter: 891 loss: 4.37850395e-05
Iter: 892 loss: 4.37849958e-05
Iter: 893 loss: 4.37851631e-05
Iter: 894 loss: 4.37850977e-05
Iter: 895 loss: 4.37850322e-05
Iter: 896 loss: 4.3785e-05
Iter: 897 loss: 4.37849885e-05
Iter: 898 loss: 4.37850686e-05
Iter: 899 loss: 4.37850831e-05
Iter: 900 loss: 4.37850322e-05
Iter: 901 loss: 4.37850285e-05
Iter: 902 loss: 4.37850467e-05
Iter: 903 loss: 4.37850358e-05
Iter: 904 loss: 4.37850758e-05
Iter: 905 loss: 4.37851049e-05
Iter: 906 loss: 4.37850467e-05
Iter: 907 loss: 4.37850686e-05
Iter: 908 loss: 4.37851e-05
Iter: 909 loss: 4.37850831e-05
Iter: 910 loss: 4.37851049e-05
Iter: 911 loss: 4.37851e-05
Iter: 912 loss: 4.37850904e-05
Iter: 913 loss: 4.37850831e-05
Iter: 914 loss: 4.37850867e-05
Iter: 915 loss: 4.37850831e-05
Iter: 916 loss: 4.37850831e-05
Iter: 917 loss: 4.37850831e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6
+ date
Tue Oct 27 15:16:17 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2175dd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2175ec730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2176931e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2176e6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2176e61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217635a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2176e60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217578a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2175782f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2175787b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2174c60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2174e5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217487a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2174bd268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2174b4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217405d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff21741fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217467b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2173fad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff21741fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217371ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217371268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2173710d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2172db9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2172dbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2172db950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2172a7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217249d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217271488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2172121e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff21721b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2171d72f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2171db598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217186ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff2171be2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff217169f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0309350397
Iter: 2 loss: 0.0226044953
Iter: 3 loss: 3080.81055
Iter: 4 loss: 0.0226044655
Iter: 5 loss: 0.0189886782
Iter: 6 loss: 0.0207092296
Iter: 7 loss: 0.0160639
Iter: 8 loss: 0.0120434761
Iter: 9 loss: 0.212298349
Iter: 10 loss: 0.0120345661
Iter: 11 loss: 0.0102207912
Iter: 12 loss: 0.0102187432
Iter: 13 loss: 0.00914972275
Iter: 14 loss: 0.00949431676
Iter: 15 loss: 0.00834962539
Iter: 16 loss: 0.00690694293
Iter: 17 loss: 0.0552778207
Iter: 18 loss: 0.00684925634
Iter: 19 loss: 0.00561243575
Iter: 20 loss: 0.00559989177
Iter: 21 loss: 0.00455500511
Iter: 22 loss: 0.0266190916
Iter: 23 loss: 0.00452125305
Iter: 24 loss: 0.00399044249
Iter: 25 loss: 0.00393641274
Iter: 26 loss: 0.00365969911
Iter: 27 loss: 0.00540299807
Iter: 28 loss: 0.00361024775
Iter: 29 loss: 0.00334436353
Iter: 30 loss: 0.00372694014
Iter: 31 loss: 0.00319449813
Iter: 32 loss: 0.00281346031
Iter: 33 loss: 0.0039815614
Iter: 34 loss: 0.00270499
Iter: 35 loss: 0.00246885163
Iter: 36 loss: 0.00304169068
Iter: 37 loss: 0.00236720406
Iter: 38 loss: 0.00212702923
Iter: 39 loss: 0.00318351295
Iter: 40 loss: 0.00207055314
Iter: 41 loss: 0.00185831683
Iter: 42 loss: 0.00300285965
Iter: 43 loss: 0.00182540447
Iter: 44 loss: 0.00165521365
Iter: 45 loss: 0.00227953261
Iter: 46 loss: 0.00160790805
Iter: 47 loss: 0.00148649747
Iter: 48 loss: 0.00244194106
Iter: 49 loss: 0.00147922838
Iter: 50 loss: 0.00137258205
Iter: 51 loss: 0.00176987541
Iter: 52 loss: 0.00134126039
Iter: 53 loss: 0.00124902558
Iter: 54 loss: 0.00156458351
Iter: 55 loss: 0.00122360815
Iter: 56 loss: 0.0011373444
Iter: 57 loss: 0.00175644225
Iter: 58 loss: 0.00112864585
Iter: 59 loss: 0.00106990535
Iter: 60 loss: 0.00177959888
Iter: 61 loss: 0.00106964097
Iter: 62 loss: 0.00101828715
Iter: 63 loss: 0.00142005528
Iter: 64 loss: 0.00101291563
Iter: 65 loss: 0.000979347504
Iter: 66 loss: 0.000980846933
Iter: 67 loss: 0.00095286034
Iter: 68 loss: 0.00089266838
Iter: 69 loss: 0.0011691543
Iter: 70 loss: 0.000879978121
Iter: 71 loss: 0.000832057325
Iter: 72 loss: 0.00113667687
Iter: 73 loss: 0.000827295
Iter: 74 loss: 0.000800208887
Iter: 75 loss: 0.000776354515
Iter: 76 loss: 0.000769045495
Iter: 77 loss: 0.000735110603
Iter: 78 loss: 0.00077410927
Iter: 79 loss: 0.000716966693
Iter: 80 loss: 0.000683964696
Iter: 81 loss: 0.000848567637
Iter: 82 loss: 0.000678500626
Iter: 83 loss: 0.000650406408
Iter: 84 loss: 0.000690481393
Iter: 85 loss: 0.000636427314
Iter: 86 loss: 0.000608569884
Iter: 87 loss: 0.000669339555
Iter: 88 loss: 0.000597754261
Iter: 89 loss: 0.000567812705
Iter: 90 loss: 0.000806383439
Iter: 91 loss: 0.000565789582
Iter: 92 loss: 0.000543709379
Iter: 93 loss: 0.000611291267
Iter: 94 loss: 0.000537376909
Iter: 95 loss: 0.000522798684
Iter: 96 loss: 0.000522794668
Iter: 97 loss: 0.000509495032
Iter: 98 loss: 0.000514558225
Iter: 99 loss: 0.00050036388
Iter: 100 loss: 0.000483997108
Iter: 101 loss: 0.000485850556
Iter: 102 loss: 0.000471390435
Iter: 103 loss: 0.000451858243
Iter: 104 loss: 0.000552882382
Iter: 105 loss: 0.000448745792
Iter: 106 loss: 0.000432949339
Iter: 107 loss: 0.000514380343
Iter: 108 loss: 0.00043015409
Iter: 109 loss: 0.000416527124
Iter: 110 loss: 0.000479940121
Iter: 111 loss: 0.000414083508
Iter: 112 loss: 0.000401342404
Iter: 113 loss: 0.000399133365
Iter: 114 loss: 0.000390344794
Iter: 115 loss: 0.000375968724
Iter: 116 loss: 0.000410874025
Iter: 117 loss: 0.000370575668
Iter: 118 loss: 0.000355154596
Iter: 119 loss: 0.000427904917
Iter: 120 loss: 0.000352356117
Iter: 121 loss: 0.000338693731
Iter: 122 loss: 0.000380334532
Iter: 123 loss: 0.000334520475
Iter: 124 loss: 0.000323606131
Iter: 125 loss: 0.000331799965
Iter: 126 loss: 0.000316939579
Iter: 127 loss: 0.000308016315
Iter: 128 loss: 0.000307878538
Iter: 129 loss: 0.000300169515
Iter: 130 loss: 0.000339635531
Iter: 131 loss: 0.00029904861
Iter: 132 loss: 0.00029257359
Iter: 133 loss: 0.00029115309
Iter: 134 loss: 0.000286864117
Iter: 135 loss: 0.00028145095
Iter: 136 loss: 0.000277339772
Iter: 137 loss: 0.000275593164
Iter: 138 loss: 0.000265957759
Iter: 139 loss: 0.000299843057
Iter: 140 loss: 0.000263416063
Iter: 141 loss: 0.000255309598
Iter: 142 loss: 0.000268279458
Iter: 143 loss: 0.00025151833
Iter: 144 loss: 0.000242366179
Iter: 145 loss: 0.000288952724
Iter: 146 loss: 0.000240845635
Iter: 147 loss: 0.000233973362
Iter: 148 loss: 0.000275924802
Iter: 149 loss: 0.00023318555
Iter: 150 loss: 0.000227317825
Iter: 151 loss: 0.000253821549
Iter: 152 loss: 0.000226117729
Iter: 153 loss: 0.000221492926
Iter: 154 loss: 0.000222837029
Iter: 155 loss: 0.000218173154
Iter: 156 loss: 0.000212272484
Iter: 157 loss: 0.00025541638
Iter: 158 loss: 0.000211771083
Iter: 159 loss: 0.000206662124
Iter: 160 loss: 0.000213733671
Iter: 161 loss: 0.000204161392
Iter: 162 loss: 0.000200592971
Iter: 163 loss: 0.000200532202
Iter: 164 loss: 0.000197913279
Iter: 165 loss: 0.000197664893
Iter: 166 loss: 0.000195754576
Iter: 167 loss: 0.000191761224
Iter: 168 loss: 0.000197498652
Iter: 169 loss: 0.000189806975
Iter: 170 loss: 0.000185732264
Iter: 171 loss: 0.000190385443
Iter: 172 loss: 0.000183561147
Iter: 173 loss: 0.000178917864
Iter: 174 loss: 0.000194208886
Iter: 175 loss: 0.000177610113
Iter: 176 loss: 0.000173083186
Iter: 177 loss: 0.000173877634
Iter: 178 loss: 0.000169683582
Iter: 179 loss: 0.000164719793
Iter: 180 loss: 0.000188374543
Iter: 181 loss: 0.000163808218
Iter: 182 loss: 0.000160891417
Iter: 183 loss: 0.000160736789
Iter: 184 loss: 0.000158126408
Iter: 185 loss: 0.00015752131
Iter: 186 loss: 0.000155831629
Iter: 187 loss: 0.000152927096
Iter: 188 loss: 0.000152791094
Iter: 189 loss: 0.000150559645
Iter: 190 loss: 0.000146943057
Iter: 191 loss: 0.00018207595
Iter: 192 loss: 0.000146797131
Iter: 193 loss: 0.000144676524
Iter: 194 loss: 0.000165660735
Iter: 195 loss: 0.000144616206
Iter: 196 loss: 0.000142760808
Iter: 197 loss: 0.000146234321
Iter: 198 loss: 0.000141957542
Iter: 199 loss: 0.000140276956
Iter: 200 loss: 0.00013947468
Iter: 201 loss: 0.000138659845
Iter: 202 loss: 0.000135985742
Iter: 203 loss: 0.000141958531
Iter: 204 loss: 0.000134956805
Iter: 205 loss: 0.000132032
Iter: 206 loss: 0.000138573261
Iter: 207 loss: 0.000130916596
Iter: 208 loss: 0.000128231914
Iter: 209 loss: 0.000137533032
Iter: 210 loss: 0.000127512423
Iter: 211 loss: 0.000124913888
Iter: 212 loss: 0.000128008891
Iter: 213 loss: 0.000123536956
Iter: 214 loss: 0.00012074082
Iter: 215 loss: 0.000139958516
Iter: 216 loss: 0.000120452481
Iter: 217 loss: 0.000118302225
Iter: 218 loss: 0.000141554279
Iter: 219 loss: 0.000118258329
Iter: 220 loss: 0.000116702628
Iter: 221 loss: 0.000114556155
Iter: 222 loss: 0.000114459006
Iter: 223 loss: 0.000111972295
Iter: 224 loss: 0.000123351085
Iter: 225 loss: 0.000111501548
Iter: 226 loss: 0.000109835339
Iter: 227 loss: 0.000129408145
Iter: 228 loss: 0.000109804867
Iter: 229 loss: 0.000108427295
Iter: 230 loss: 0.000116669886
Iter: 231 loss: 0.000108260538
Iter: 232 loss: 0.000107201537
Iter: 233 loss: 0.000106381223
Iter: 234 loss: 0.000106043779
Iter: 235 loss: 0.000104334526
Iter: 236 loss: 0.000105358049
Iter: 237 loss: 0.000103232582
Iter: 238 loss: 0.00010140524
Iter: 239 loss: 0.000112411079
Iter: 240 loss: 0.000101173253
Iter: 241 loss: 9.96268136e-05
Iter: 242 loss: 0.000100479927
Iter: 243 loss: 9.86113591e-05
Iter: 244 loss: 9.68153e-05
Iter: 245 loss: 0.000103688268
Iter: 246 loss: 9.6384465e-05
Iter: 247 loss: 9.46919099e-05
Iter: 248 loss: 0.0001020528
Iter: 249 loss: 9.43495761e-05
Iter: 250 loss: 9.3167313e-05
Iter: 251 loss: 0.000103229904
Iter: 252 loss: 9.30950555e-05
Iter: 253 loss: 9.19778104e-05
Iter: 254 loss: 9.29690141e-05
Iter: 255 loss: 9.13239128e-05
Iter: 256 loss: 9.02040192e-05
Iter: 257 loss: 9.11254319e-05
Iter: 258 loss: 8.95334379e-05
Iter: 259 loss: 8.84785e-05
Iter: 260 loss: 9.96508e-05
Iter: 261 loss: 8.84546607e-05
Iter: 262 loss: 8.76390477e-05
Iter: 263 loss: 9.52153496e-05
Iter: 264 loss: 8.76019258e-05
Iter: 265 loss: 8.69503783e-05
Iter: 266 loss: 8.65673719e-05
Iter: 267 loss: 8.62938468e-05
Iter: 268 loss: 8.53841921e-05
Iter: 269 loss: 8.71735247e-05
Iter: 270 loss: 8.50072247e-05
Iter: 271 loss: 8.41168876e-05
Iter: 272 loss: 8.62637899e-05
Iter: 273 loss: 8.37964e-05
Iter: 274 loss: 8.28902557e-05
Iter: 275 loss: 8.58661369e-05
Iter: 276 loss: 8.26365e-05
Iter: 277 loss: 8.18472e-05
Iter: 278 loss: 8.24479721e-05
Iter: 279 loss: 8.13663355e-05
Iter: 280 loss: 8.0434329e-05
Iter: 281 loss: 8.52462e-05
Iter: 282 loss: 8.02826471e-05
Iter: 283 loss: 7.94400185e-05
Iter: 284 loss: 8.43020243e-05
Iter: 285 loss: 7.93296e-05
Iter: 286 loss: 7.86085438e-05
Iter: 287 loss: 8.17989057e-05
Iter: 288 loss: 7.84629592e-05
Iter: 289 loss: 7.7941877e-05
Iter: 290 loss: 7.72620115e-05
Iter: 291 loss: 7.72181811e-05
Iter: 292 loss: 7.62852651e-05
Iter: 293 loss: 8.14225859e-05
Iter: 294 loss: 7.6147262e-05
Iter: 295 loss: 7.57759844e-05
Iter: 296 loss: 7.56851514e-05
Iter: 297 loss: 7.53309432e-05
Iter: 298 loss: 7.48954189e-05
Iter: 299 loss: 7.48561288e-05
Iter: 300 loss: 7.4257965e-05
Iter: 301 loss: 7.51545158e-05
Iter: 302 loss: 7.39726529e-05
Iter: 303 loss: 7.33598572e-05
Iter: 304 loss: 7.41491385e-05
Iter: 305 loss: 7.30453321e-05
Iter: 306 loss: 7.23428166e-05
Iter: 307 loss: 7.52347914e-05
Iter: 308 loss: 7.21901597e-05
Iter: 309 loss: 7.15695205e-05
Iter: 310 loss: 7.23244229e-05
Iter: 311 loss: 7.12445326e-05
Iter: 312 loss: 7.05214261e-05
Iter: 313 loss: 7.25160498e-05
Iter: 314 loss: 7.02869947e-05
Iter: 315 loss: 6.97011856e-05
Iter: 316 loss: 7.35510257e-05
Iter: 317 loss: 6.96382194e-05
Iter: 318 loss: 6.90855086e-05
Iter: 319 loss: 7.2194016e-05
Iter: 320 loss: 6.90097077e-05
Iter: 321 loss: 6.85670821e-05
Iter: 322 loss: 6.86791e-05
Iter: 323 loss: 6.82436366e-05
Iter: 324 loss: 6.76966738e-05
Iter: 325 loss: 6.79718214e-05
Iter: 326 loss: 6.73317845e-05
Iter: 327 loss: 6.69037181e-05
Iter: 328 loss: 6.6894223e-05
Iter: 329 loss: 6.64510153e-05
Iter: 330 loss: 6.70181907e-05
Iter: 331 loss: 6.6224442e-05
Iter: 332 loss: 6.58231875e-05
Iter: 333 loss: 6.59362922e-05
Iter: 334 loss: 6.55331387e-05
Iter: 335 loss: 6.50310612e-05
Iter: 336 loss: 6.58134086e-05
Iter: 337 loss: 6.4795182e-05
Iter: 338 loss: 6.42028899e-05
Iter: 339 loss: 6.547058e-05
Iter: 340 loss: 6.39701466e-05
Iter: 341 loss: 6.33837335e-05
Iter: 342 loss: 6.52323652e-05
Iter: 343 loss: 6.32139e-05
Iter: 344 loss: 6.26645342e-05
Iter: 345 loss: 6.42617088e-05
Iter: 346 loss: 6.24929962e-05
Iter: 347 loss: 6.20218125e-05
Iter: 348 loss: 6.29653077e-05
Iter: 349 loss: 6.18300837e-05
Iter: 350 loss: 6.13676384e-05
Iter: 351 loss: 6.74539e-05
Iter: 352 loss: 6.13644443e-05
Iter: 353 loss: 6.10235e-05
Iter: 354 loss: 6.11788e-05
Iter: 355 loss: 6.07924267e-05
Iter: 356 loss: 6.03867084e-05
Iter: 357 loss: 6.08836672e-05
Iter: 358 loss: 6.01741776e-05
Iter: 359 loss: 5.97802e-05
Iter: 360 loss: 6.19895218e-05
Iter: 361 loss: 5.97256658e-05
Iter: 362 loss: 5.93285113e-05
Iter: 363 loss: 6.25375105e-05
Iter: 364 loss: 5.93018158e-05
Iter: 365 loss: 5.90605887e-05
Iter: 366 loss: 5.87990908e-05
Iter: 367 loss: 5.87588511e-05
Iter: 368 loss: 5.83733381e-05
Iter: 369 loss: 5.9711605e-05
Iter: 370 loss: 5.8272235e-05
Iter: 371 loss: 5.79199586e-05
Iter: 372 loss: 5.85885064e-05
Iter: 373 loss: 5.77711689e-05
Iter: 374 loss: 5.74081678e-05
Iter: 375 loss: 5.85200505e-05
Iter: 376 loss: 5.730052e-05
Iter: 377 loss: 5.69576696e-05
Iter: 378 loss: 5.77877763e-05
Iter: 379 loss: 5.68346404e-05
Iter: 380 loss: 5.64884213e-05
Iter: 381 loss: 5.7133966e-05
Iter: 382 loss: 5.63406356e-05
Iter: 383 loss: 5.60531153e-05
Iter: 384 loss: 5.98122388e-05
Iter: 385 loss: 5.60515764e-05
Iter: 386 loss: 5.57949097e-05
Iter: 387 loss: 5.61479828e-05
Iter: 388 loss: 5.56668092e-05
Iter: 389 loss: 5.54390499e-05
Iter: 390 loss: 5.57070234e-05
Iter: 391 loss: 5.53182326e-05
Iter: 392 loss: 5.50553777e-05
Iter: 393 loss: 5.56413215e-05
Iter: 394 loss: 5.49546894e-05
Iter: 395 loss: 5.48013522e-05
Iter: 396 loss: 5.47804193e-05
Iter: 397 loss: 5.46590891e-05
Iter: 398 loss: 5.44394134e-05
Iter: 399 loss: 5.97977632e-05
Iter: 400 loss: 5.44393952e-05
Iter: 401 loss: 5.41962872e-05
Iter: 402 loss: 5.46298106e-05
Iter: 403 loss: 5.40899273e-05
Iter: 404 loss: 5.38258682e-05
Iter: 405 loss: 5.48783355e-05
Iter: 406 loss: 5.37660453e-05
Iter: 407 loss: 5.35564686e-05
Iter: 408 loss: 5.3923759e-05
Iter: 409 loss: 5.34638857e-05
Iter: 410 loss: 5.32199156e-05
Iter: 411 loss: 5.40299479e-05
Iter: 412 loss: 5.31526748e-05
Iter: 413 loss: 5.29331082e-05
Iter: 414 loss: 5.31976912e-05
Iter: 415 loss: 5.28176497e-05
Iter: 416 loss: 5.25998184e-05
Iter: 417 loss: 5.41639456e-05
Iter: 418 loss: 5.25805081e-05
Iter: 419 loss: 5.23929e-05
Iter: 420 loss: 5.3598058e-05
Iter: 421 loss: 5.23726158e-05
Iter: 422 loss: 5.22166338e-05
Iter: 423 loss: 5.2096e-05
Iter: 424 loss: 5.20463509e-05
Iter: 425 loss: 5.18330125e-05
Iter: 426 loss: 5.2761774e-05
Iter: 427 loss: 5.17899025e-05
Iter: 428 loss: 5.16443324e-05
Iter: 429 loss: 5.16443106e-05
Iter: 430 loss: 5.15070715e-05
Iter: 431 loss: 5.1447023e-05
Iter: 432 loss: 5.13770574e-05
Iter: 433 loss: 5.12163606e-05
Iter: 434 loss: 5.11377075e-05
Iter: 435 loss: 5.10605532e-05
Iter: 436 loss: 5.08235571e-05
Iter: 437 loss: 5.22894916e-05
Iter: 438 loss: 5.07955046e-05
Iter: 439 loss: 5.0602408e-05
Iter: 440 loss: 5.06858487e-05
Iter: 441 loss: 5.04704221e-05
Iter: 442 loss: 5.02267467e-05
Iter: 443 loss: 5.14307394e-05
Iter: 444 loss: 5.01848263e-05
Iter: 445 loss: 4.99826e-05
Iter: 446 loss: 5.0305498e-05
Iter: 447 loss: 4.9888491e-05
Iter: 448 loss: 4.96820649e-05
Iter: 449 loss: 5.05365606e-05
Iter: 450 loss: 4.96377652e-05
Iter: 451 loss: 4.94666892e-05
Iter: 452 loss: 5.11693506e-05
Iter: 453 loss: 4.94609267e-05
Iter: 454 loss: 4.93081461e-05
Iter: 455 loss: 4.92369873e-05
Iter: 456 loss: 4.91618084e-05
Iter: 457 loss: 4.89671802e-05
Iter: 458 loss: 4.94143314e-05
Iter: 459 loss: 4.88944643e-05
Iter: 460 loss: 4.8744776e-05
Iter: 461 loss: 5.10879181e-05
Iter: 462 loss: 4.87448415e-05
Iter: 463 loss: 4.86021963e-05
Iter: 464 loss: 4.87999e-05
Iter: 465 loss: 4.85310156e-05
Iter: 466 loss: 4.83989206e-05
Iter: 467 loss: 4.8237147e-05
Iter: 468 loss: 4.82223186e-05
Iter: 469 loss: 4.80125636e-05
Iter: 470 loss: 4.92939653e-05
Iter: 471 loss: 4.79869341e-05
Iter: 472 loss: 4.78176e-05
Iter: 473 loss: 4.82016e-05
Iter: 474 loss: 4.77539252e-05
Iter: 475 loss: 4.75655834e-05
Iter: 476 loss: 4.77788344e-05
Iter: 477 loss: 4.74642e-05
Iter: 478 loss: 4.72575048e-05
Iter: 479 loss: 4.81970201e-05
Iter: 480 loss: 4.72177526e-05
Iter: 481 loss: 4.70270825e-05
Iter: 482 loss: 4.72696483e-05
Iter: 483 loss: 4.69288279e-05
Iter: 484 loss: 4.67683385e-05
Iter: 485 loss: 4.89246413e-05
Iter: 486 loss: 4.67676437e-05
Iter: 487 loss: 4.66179808e-05
Iter: 488 loss: 4.67690552e-05
Iter: 489 loss: 4.65336743e-05
Iter: 490 loss: 4.63854667e-05
Iter: 491 loss: 4.65325e-05
Iter: 492 loss: 4.63018332e-05
Iter: 493 loss: 4.61714153e-05
Iter: 494 loss: 4.73269465e-05
Iter: 495 loss: 4.61645759e-05
Iter: 496 loss: 4.60332376e-05
Iter: 497 loss: 4.66246e-05
Iter: 498 loss: 4.60078845e-05
Iter: 499 loss: 4.59068178e-05
Iter: 500 loss: 4.57710194e-05
Iter: 501 loss: 4.57638089e-05
Iter: 502 loss: 4.55918562e-05
Iter: 503 loss: 4.60261e-05
Iter: 504 loss: 4.55319823e-05
Iter: 505 loss: 4.53729881e-05
Iter: 506 loss: 4.61000673e-05
Iter: 507 loss: 4.53426619e-05
Iter: 508 loss: 4.51918168e-05
Iter: 509 loss: 4.54020774e-05
Iter: 510 loss: 4.51170126e-05
Iter: 511 loss: 4.4961751e-05
Iter: 512 loss: 4.54374e-05
Iter: 513 loss: 4.49156505e-05
Iter: 514 loss: 4.47608181e-05
Iter: 515 loss: 4.52248e-05
Iter: 516 loss: 4.47140737e-05
Iter: 517 loss: 4.45728147e-05
Iter: 518 loss: 4.50558327e-05
Iter: 519 loss: 4.45350306e-05
Iter: 520 loss: 4.44038742e-05
Iter: 521 loss: 4.57292845e-05
Iter: 522 loss: 4.43998797e-05
Iter: 523 loss: 4.43178942e-05
Iter: 524 loss: 4.42343044e-05
Iter: 525 loss: 4.42181408e-05
Iter: 526 loss: 4.40933945e-05
Iter: 527 loss: 4.47883285e-05
Iter: 528 loss: 4.40758376e-05
Iter: 529 loss: 4.39814467e-05
Iter: 530 loss: 4.53965768e-05
Iter: 531 loss: 4.39813412e-05
Iter: 532 loss: 4.39174e-05
Iter: 533 loss: 4.38029092e-05
Iter: 534 loss: 4.66128877e-05
Iter: 535 loss: 4.38028583e-05
Iter: 536 loss: 4.36781775e-05
Iter: 537 loss: 4.40074364e-05
Iter: 538 loss: 4.36360569e-05
Iter: 539 loss: 4.35130823e-05
Iter: 540 loss: 4.3788219e-05
Iter: 541 loss: 4.34665053e-05
Iter: 542 loss: 4.33395544e-05
Iter: 543 loss: 4.39646028e-05
Iter: 544 loss: 4.33177629e-05
Iter: 545 loss: 4.3214277e-05
Iter: 546 loss: 4.3233169e-05
Iter: 547 loss: 4.3137e-05
Iter: 548 loss: 4.299793e-05
Iter: 549 loss: 4.37468916e-05
Iter: 550 loss: 4.29770153e-05
Iter: 551 loss: 4.28654457e-05
Iter: 552 loss: 4.3186632e-05
Iter: 553 loss: 4.28305721e-05
Iter: 554 loss: 4.27399282e-05
Iter: 555 loss: 4.38235293e-05
Iter: 556 loss: 4.27386549e-05
Iter: 557 loss: 4.2663185e-05
Iter: 558 loss: 4.26093065e-05
Iter: 559 loss: 4.25829494e-05
Iter: 560 loss: 4.24815807e-05
Iter: 561 loss: 4.27779378e-05
Iter: 562 loss: 4.24499704e-05
Iter: 563 loss: 4.23859929e-05
Iter: 564 loss: 4.23818346e-05
Iter: 565 loss: 4.23293823e-05
Iter: 566 loss: 4.22483718e-05
Iter: 567 loss: 4.22471676e-05
Iter: 568 loss: 4.21524237e-05
Iter: 569 loss: 4.22614103e-05
Iter: 570 loss: 4.21016557e-05
Iter: 571 loss: 4.19974458e-05
Iter: 572 loss: 4.22944468e-05
Iter: 573 loss: 4.19644821e-05
Iter: 574 loss: 4.18627606e-05
Iter: 575 loss: 4.23102865e-05
Iter: 576 loss: 4.18423733e-05
Iter: 577 loss: 4.17494812e-05
Iter: 578 loss: 4.18251766e-05
Iter: 579 loss: 4.16939074e-05
Iter: 580 loss: 4.15759423e-05
Iter: 581 loss: 4.19195858e-05
Iter: 582 loss: 4.15393588e-05
Iter: 583 loss: 4.14352471e-05
Iter: 584 loss: 4.18962409e-05
Iter: 585 loss: 4.14145143e-05
Iter: 586 loss: 4.13241796e-05
Iter: 587 loss: 4.18973978e-05
Iter: 588 loss: 4.13141606e-05
Iter: 589 loss: 4.12307963e-05
Iter: 590 loss: 4.14514179e-05
Iter: 591 loss: 4.12028021e-05
Iter: 592 loss: 4.11332221e-05
Iter: 593 loss: 4.10725843e-05
Iter: 594 loss: 4.1054e-05
Iter: 595 loss: 4.10105313e-05
Iter: 596 loss: 4.09937275e-05
Iter: 597 loss: 4.09429085e-05
Iter: 598 loss: 4.09015593e-05
Iter: 599 loss: 4.08865235e-05
Iter: 600 loss: 4.08126507e-05
Iter: 601 loss: 4.08227861e-05
Iter: 602 loss: 4.07563639e-05
Iter: 603 loss: 4.06616e-05
Iter: 604 loss: 4.0894487e-05
Iter: 605 loss: 4.06279651e-05
Iter: 606 loss: 4.05282044e-05
Iter: 607 loss: 4.09339082e-05
Iter: 608 loss: 4.05062492e-05
Iter: 609 loss: 4.04176462e-05
Iter: 610 loss: 4.06008185e-05
Iter: 611 loss: 4.03824379e-05
Iter: 612 loss: 4.02825208e-05
Iter: 613 loss: 4.04232487e-05
Iter: 614 loss: 4.02334117e-05
Iter: 615 loss: 4.01269863e-05
Iter: 616 loss: 4.05829924e-05
Iter: 617 loss: 4.01050493e-05
Iter: 618 loss: 4.00127901e-05
Iter: 619 loss: 4.05891369e-05
Iter: 620 loss: 4.00018616e-05
Iter: 621 loss: 3.99249075e-05
Iter: 622 loss: 4.03176964e-05
Iter: 623 loss: 3.99124547e-05
Iter: 624 loss: 3.98545235e-05
Iter: 625 loss: 3.98202283e-05
Iter: 626 loss: 3.97959e-05
Iter: 627 loss: 3.97385447e-05
Iter: 628 loss: 3.97384865e-05
Iter: 629 loss: 3.96783144e-05
Iter: 630 loss: 3.97005642e-05
Iter: 631 loss: 3.96362302e-05
Iter: 632 loss: 3.95797615e-05
Iter: 633 loss: 3.95886673e-05
Iter: 634 loss: 3.95370953e-05
Iter: 635 loss: 3.94631352e-05
Iter: 636 loss: 3.95878305e-05
Iter: 637 loss: 3.94297313e-05
Iter: 638 loss: 3.93500159e-05
Iter: 639 loss: 3.96516734e-05
Iter: 640 loss: 3.93307819e-05
Iter: 641 loss: 3.92532893e-05
Iter: 642 loss: 3.94553426e-05
Iter: 643 loss: 3.92268848e-05
Iter: 644 loss: 3.9150138e-05
Iter: 645 loss: 3.92993825e-05
Iter: 646 loss: 3.91183676e-05
Iter: 647 loss: 3.90368732e-05
Iter: 648 loss: 3.92267248e-05
Iter: 649 loss: 3.9006627e-05
Iter: 650 loss: 3.89279958e-05
Iter: 651 loss: 3.9472965e-05
Iter: 652 loss: 3.89206689e-05
Iter: 653 loss: 3.88605768e-05
Iter: 654 loss: 3.9258688e-05
Iter: 655 loss: 3.8854203e-05
Iter: 656 loss: 3.88088192e-05
Iter: 657 loss: 3.88015724e-05
Iter: 658 loss: 3.8770333e-05
Iter: 659 loss: 3.87150722e-05
Iter: 660 loss: 3.90006826e-05
Iter: 661 loss: 3.87060427e-05
Iter: 662 loss: 3.86446627e-05
Iter: 663 loss: 3.89839697e-05
Iter: 664 loss: 3.86358151e-05
Iter: 665 loss: 3.85986459e-05
Iter: 666 loss: 3.85431813e-05
Iter: 667 loss: 3.85419335e-05
Iter: 668 loss: 3.84761843e-05
Iter: 669 loss: 3.86910942e-05
Iter: 670 loss: 3.84578707e-05
Iter: 671 loss: 3.83931765e-05
Iter: 672 loss: 3.85465792e-05
Iter: 673 loss: 3.83695806e-05
Iter: 674 loss: 3.83050574e-05
Iter: 675 loss: 3.85383973e-05
Iter: 676 loss: 3.82888102e-05
Iter: 677 loss: 3.82244143e-05
Iter: 678 loss: 3.83627339e-05
Iter: 679 loss: 3.81992286e-05
Iter: 680 loss: 3.81404352e-05
Iter: 681 loss: 3.82433645e-05
Iter: 682 loss: 3.81145364e-05
Iter: 683 loss: 3.80467754e-05
Iter: 684 loss: 3.84092709e-05
Iter: 685 loss: 3.80364545e-05
Iter: 686 loss: 3.79895719e-05
Iter: 687 loss: 3.84799678e-05
Iter: 688 loss: 3.79883677e-05
Iter: 689 loss: 3.79516205e-05
Iter: 690 loss: 3.79325793e-05
Iter: 691 loss: 3.79157354e-05
Iter: 692 loss: 3.78649129e-05
Iter: 693 loss: 3.8047e-05
Iter: 694 loss: 3.78521072e-05
Iter: 695 loss: 3.780724e-05
Iter: 696 loss: 3.83770312e-05
Iter: 697 loss: 3.78068798e-05
Iter: 698 loss: 3.77779434e-05
Iter: 699 loss: 3.77232936e-05
Iter: 700 loss: 3.89195848e-05
Iter: 701 loss: 3.77230353e-05
Iter: 702 loss: 3.76707831e-05
Iter: 703 loss: 3.7847e-05
Iter: 704 loss: 3.76567259e-05
Iter: 705 loss: 3.76000389e-05
Iter: 706 loss: 3.77165707e-05
Iter: 707 loss: 3.75771415e-05
Iter: 708 loss: 3.75237e-05
Iter: 709 loss: 3.77254837e-05
Iter: 710 loss: 3.7510843e-05
Iter: 711 loss: 3.74559531e-05
Iter: 712 loss: 3.75854579e-05
Iter: 713 loss: 3.74358278e-05
Iter: 714 loss: 3.73867369e-05
Iter: 715 loss: 3.74838055e-05
Iter: 716 loss: 3.73665243e-05
Iter: 717 loss: 3.73120347e-05
Iter: 718 loss: 3.75558448e-05
Iter: 719 loss: 3.73014336e-05
Iter: 720 loss: 3.72607938e-05
Iter: 721 loss: 3.7671216e-05
Iter: 722 loss: 3.72594659e-05
Iter: 723 loss: 3.72268623e-05
Iter: 724 loss: 3.7236121e-05
Iter: 725 loss: 3.7203361e-05
Iter: 726 loss: 3.71626447e-05
Iter: 727 loss: 3.72371869e-05
Iter: 728 loss: 3.71451097e-05
Iter: 729 loss: 3.71134374e-05
Iter: 730 loss: 3.71128699e-05
Iter: 731 loss: 3.70895432e-05
Iter: 732 loss: 3.70424459e-05
Iter: 733 loss: 3.79157609e-05
Iter: 734 loss: 3.70418202e-05
Iter: 735 loss: 3.69958434e-05
Iter: 736 loss: 3.71244168e-05
Iter: 737 loss: 3.69811823e-05
Iter: 738 loss: 3.69359768e-05
Iter: 739 loss: 3.70764028e-05
Iter: 740 loss: 3.69227128e-05
Iter: 741 loss: 3.68788824e-05
Iter: 742 loss: 3.69936424e-05
Iter: 743 loss: 3.68640758e-05
Iter: 744 loss: 3.68192123e-05
Iter: 745 loss: 3.695751e-05
Iter: 746 loss: 3.68059191e-05
Iter: 747 loss: 3.6761845e-05
Iter: 748 loss: 3.68416e-05
Iter: 749 loss: 3.67427201e-05
Iter: 750 loss: 3.66968816e-05
Iter: 751 loss: 3.68230467e-05
Iter: 752 loss: 3.66820241e-05
Iter: 753 loss: 3.6642894e-05
Iter: 754 loss: 3.71205351e-05
Iter: 755 loss: 3.66425302e-05
Iter: 756 loss: 3.66140921e-05
Iter: 757 loss: 3.66620043e-05
Iter: 758 loss: 3.66012027e-05
Iter: 759 loss: 3.65707201e-05
Iter: 760 loss: 3.65852975e-05
Iter: 761 loss: 3.65503656e-05
Iter: 762 loss: 3.65311207e-05
Iter: 763 loss: 3.65288797e-05
Iter: 764 loss: 3.65113119e-05
Iter: 765 loss: 3.64795706e-05
Iter: 766 loss: 3.72425893e-05
Iter: 767 loss: 3.64795451e-05
Iter: 768 loss: 3.6444435e-05
Iter: 769 loss: 3.64905572e-05
Iter: 770 loss: 3.64265434e-05
Iter: 771 loss: 3.63893414e-05
Iter: 772 loss: 3.65113483e-05
Iter: 773 loss: 3.63790532e-05
Iter: 774 loss: 3.63421568e-05
Iter: 775 loss: 3.64672524e-05
Iter: 776 loss: 3.6332196e-05
Iter: 777 loss: 3.62985957e-05
Iter: 778 loss: 3.63780055e-05
Iter: 779 loss: 3.62862738e-05
Iter: 780 loss: 3.62509745e-05
Iter: 781 loss: 3.63716754e-05
Iter: 782 loss: 3.6241694e-05
Iter: 783 loss: 3.62109713e-05
Iter: 784 loss: 3.62535393e-05
Iter: 785 loss: 3.61957573e-05
Iter: 786 loss: 3.61656275e-05
Iter: 787 loss: 3.65163651e-05
Iter: 788 loss: 3.61650964e-05
Iter: 789 loss: 3.61411585e-05
Iter: 790 loss: 3.61970706e-05
Iter: 791 loss: 3.61323182e-05
Iter: 792 loss: 3.61091516e-05
Iter: 793 loss: 3.61314196e-05
Iter: 794 loss: 3.60960694e-05
Iter: 795 loss: 3.60781305e-05
Iter: 796 loss: 3.60782069e-05
Iter: 797 loss: 3.60605482e-05
Iter: 798 loss: 3.60397207e-05
Iter: 799 loss: 3.60375052e-05
Iter: 800 loss: 3.60122212e-05
Iter: 801 loss: 3.60293561e-05
Iter: 802 loss: 3.5996396e-05
Iter: 803 loss: 3.59685582e-05
Iter: 804 loss: 3.60724225e-05
Iter: 805 loss: 3.59616461e-05
Iter: 806 loss: 3.59355254e-05
Iter: 807 loss: 3.60044396e-05
Iter: 808 loss: 3.59266487e-05
Iter: 809 loss: 3.58992256e-05
Iter: 810 loss: 3.59741316e-05
Iter: 811 loss: 3.58901307e-05
Iter: 812 loss: 3.58639918e-05
Iter: 813 loss: 3.59466649e-05
Iter: 814 loss: 3.58564939e-05
Iter: 815 loss: 3.58297184e-05
Iter: 816 loss: 3.58630932e-05
Iter: 817 loss: 3.58159377e-05
Iter: 818 loss: 3.57926328e-05
Iter: 819 loss: 3.60591439e-05
Iter: 820 loss: 3.57922036e-05
Iter: 821 loss: 3.5772533e-05
Iter: 822 loss: 3.58268589e-05
Iter: 823 loss: 3.57659956e-05
Iter: 824 loss: 3.57474382e-05
Iter: 825 loss: 3.57648314e-05
Iter: 826 loss: 3.57367353e-05
Iter: 827 loss: 3.57195095e-05
Iter: 828 loss: 3.5887344e-05
Iter: 829 loss: 3.57188619e-05
Iter: 830 loss: 3.57009e-05
Iter: 831 loss: 3.57156823e-05
Iter: 832 loss: 3.56901764e-05
Iter: 833 loss: 3.56734672e-05
Iter: 834 loss: 3.56582532e-05
Iter: 835 loss: 3.56541495e-05
Iter: 836 loss: 3.56290584e-05
Iter: 837 loss: 3.57157478e-05
Iter: 838 loss: 3.56224919e-05
Iter: 839 loss: 3.55981974e-05
Iter: 840 loss: 3.56896417e-05
Iter: 841 loss: 3.55922821e-05
Iter: 842 loss: 3.55701413e-05
Iter: 843 loss: 3.56121236e-05
Iter: 844 loss: 3.55607772e-05
Iter: 845 loss: 3.55348493e-05
Iter: 846 loss: 3.56114215e-05
Iter: 847 loss: 3.5526813e-05
Iter: 848 loss: 3.55024531e-05
Iter: 849 loss: 3.55566517e-05
Iter: 850 loss: 3.54932126e-05
Iter: 851 loss: 3.54716904e-05
Iter: 852 loss: 3.56245837e-05
Iter: 853 loss: 3.54697586e-05
Iter: 854 loss: 3.54523581e-05
Iter: 855 loss: 3.55537341e-05
Iter: 856 loss: 3.54501099e-05
Iter: 857 loss: 3.54351578e-05
Iter: 858 loss: 3.54322037e-05
Iter: 859 loss: 3.54223303e-05
Iter: 860 loss: 3.54058611e-05
Iter: 861 loss: 3.55688499e-05
Iter: 862 loss: 3.54053336e-05
Iter: 863 loss: 3.53902724e-05
Iter: 864 loss: 3.54386248e-05
Iter: 865 loss: 3.5386005e-05
Iter: 866 loss: 3.53735704e-05
Iter: 867 loss: 3.53525429e-05
Iter: 868 loss: 3.53524156e-05
Iter: 869 loss: 3.53303039e-05
Iter: 870 loss: 3.5397381e-05
Iter: 871 loss: 3.53236464e-05
Iter: 872 loss: 3.53007308e-05
Iter: 873 loss: 3.54136355e-05
Iter: 874 loss: 3.52969801e-05
Iter: 875 loss: 3.52783609e-05
Iter: 876 loss: 3.53045471e-05
Iter: 877 loss: 3.52693969e-05
Iter: 878 loss: 3.52459574e-05
Iter: 879 loss: 3.5322184e-05
Iter: 880 loss: 3.52393035e-05
Iter: 881 loss: 3.52189163e-05
Iter: 882 loss: 3.52654606e-05
Iter: 883 loss: 3.52113e-05
Iter: 884 loss: 3.51912458e-05
Iter: 885 loss: 3.52941424e-05
Iter: 886 loss: 3.51879789e-05
Iter: 887 loss: 3.51727431e-05
Iter: 888 loss: 3.53107607e-05
Iter: 889 loss: 3.51720337e-05
Iter: 890 loss: 3.51597e-05
Iter: 891 loss: 3.51555573e-05
Iter: 892 loss: 3.51485323e-05
Iter: 893 loss: 3.51342023e-05
Iter: 894 loss: 3.52456336e-05
Iter: 895 loss: 3.513314e-05
Iter: 896 loss: 3.5120469e-05
Iter: 897 loss: 3.51900308e-05
Iter: 898 loss: 3.51186609e-05
Iter: 899 loss: 3.51086201e-05
Iter: 900 loss: 3.50906412e-05
Iter: 901 loss: 3.552423e-05
Iter: 902 loss: 3.50905721e-05
Iter: 903 loss: 3.50729315e-05
Iter: 904 loss: 3.51151102e-05
Iter: 905 loss: 3.50666669e-05
Iter: 906 loss: 3.50468545e-05
Iter: 907 loss: 3.51286508e-05
Iter: 908 loss: 3.5042518e-05
Iter: 909 loss: 3.50257033e-05
Iter: 910 loss: 3.50696e-05
Iter: 911 loss: 3.50199334e-05
Iter: 912 loss: 3.50016853e-05
Iter: 913 loss: 3.50486516e-05
Iter: 914 loss: 3.49954789e-05
Iter: 915 loss: 3.49778238e-05
Iter: 916 loss: 3.50312876e-05
Iter: 917 loss: 3.49725524e-05
Iter: 918 loss: 3.49565671e-05
Iter: 919 loss: 3.50116679e-05
Iter: 920 loss: 3.49522852e-05
Iter: 921 loss: 3.49401707e-05
Iter: 922 loss: 3.50943301e-05
Iter: 923 loss: 3.49400507e-05
Iter: 924 loss: 3.49308757e-05
Iter: 925 loss: 3.4929275e-05
Iter: 926 loss: 3.4923054e-05
Iter: 927 loss: 3.49105831e-05
Iter: 928 loss: 3.49557231e-05
Iter: 929 loss: 3.49075308e-05
Iter: 930 loss: 3.4896384e-05
Iter: 931 loss: 3.50133923e-05
Iter: 932 loss: 3.48961e-05
Iter: 933 loss: 3.48888207e-05
Iter: 934 loss: 3.4876135e-05
Iter: 935 loss: 3.48761932e-05
Iter: 936 loss: 3.48623726e-05
Iter: 937 loss: 3.48893154e-05
Iter: 938 loss: 3.48566136e-05
Iter: 939 loss: 3.48414615e-05
Iter: 940 loss: 3.48858e-05
Iter: 941 loss: 3.48367539e-05
Iter: 942 loss: 3.48227077e-05
Iter: 943 loss: 3.4897108e-05
Iter: 944 loss: 3.48205394e-05
Iter: 945 loss: 3.48079666e-05
Iter: 946 loss: 3.48126378e-05
Iter: 947 loss: 3.47991045e-05
Iter: 948 loss: 3.47830428e-05
Iter: 949 loss: 3.48855174e-05
Iter: 950 loss: 3.47812056e-05
Iter: 951 loss: 3.47691e-05
Iter: 952 loss: 3.47854875e-05
Iter: 953 loss: 3.47630739e-05
Iter: 954 loss: 3.47524256e-05
Iter: 955 loss: 3.49139773e-05
Iter: 956 loss: 3.47524328e-05
Iter: 957 loss: 3.47447531e-05
Iter: 958 loss: 3.47486639e-05
Iter: 959 loss: 3.47396781e-05
Iter: 960 loss: 3.47301066e-05
Iter: 961 loss: 3.47511086e-05
Iter: 962 loss: 3.47264613e-05
Iter: 963 loss: 3.47185087e-05
Iter: 964 loss: 3.47185924e-05
Iter: 965 loss: 3.4713441e-05
Iter: 966 loss: 3.47040077e-05
Iter: 967 loss: 3.49176262e-05
Iter: 968 loss: 3.47039531e-05
Iter: 969 loss: 3.4693272e-05
Iter: 970 loss: 3.47111782e-05
Iter: 971 loss: 3.46885863e-05
Iter: 972 loss: 3.46771958e-05
Iter: 973 loss: 3.46986199e-05
Iter: 974 loss: 3.46724555e-05
Iter: 975 loss: 3.46602865e-05
Iter: 976 loss: 3.47364039e-05
Iter: 977 loss: 3.46588422e-05
Iter: 978 loss: 3.4648514e-05
Iter: 979 loss: 3.46520101e-05
Iter: 980 loss: 3.4641107e-05
Iter: 981 loss: 3.46278757e-05
Iter: 982 loss: 3.47077948e-05
Iter: 983 loss: 3.46262532e-05
Iter: 984 loss: 3.46157576e-05
Iter: 985 loss: 3.46280503e-05
Iter: 986 loss: 3.46102788e-05
Iter: 987 loss: 3.46015659e-05
Iter: 988 loss: 3.46015731e-05
Iter: 989 loss: 3.45951412e-05
Iter: 990 loss: 3.45998415e-05
Iter: 991 loss: 3.45911903e-05
Iter: 992 loss: 3.45835215e-05
Iter: 993 loss: 3.45914232e-05
Iter: 994 loss: 3.45792287e-05
Iter: 995 loss: 3.4572713e-05
Iter: 996 loss: 3.45727167e-05
Iter: 997 loss: 3.45679364e-05
Iter: 998 loss: 3.45608896e-05
Iter: 999 loss: 3.45607841e-05
Iter: 1000 loss: 3.45524495e-05
Iter: 1001 loss: 3.45564476e-05
Iter: 1002 loss: 3.45469e-05
Iter: 1003 loss: 3.45361186e-05
Iter: 1004 loss: 3.45604931e-05
Iter: 1005 loss: 3.45321096e-05
Iter: 1006 loss: 3.45211083e-05
Iter: 1007 loss: 3.45868466e-05
Iter: 1008 loss: 3.45198205e-05
Iter: 1009 loss: 3.45104309e-05
Iter: 1010 loss: 3.45213084e-05
Iter: 1011 loss: 3.45054214e-05
Iter: 1012 loss: 3.44946493e-05
Iter: 1013 loss: 3.45368608e-05
Iter: 1014 loss: 3.44922519e-05
Iter: 1015 loss: 3.44825748e-05
Iter: 1016 loss: 3.45043445e-05
Iter: 1017 loss: 3.44788386e-05
Iter: 1018 loss: 3.44708133e-05
Iter: 1019 loss: 3.45554581e-05
Iter: 1020 loss: 3.44706423e-05
Iter: 1021 loss: 3.44637592e-05
Iter: 1022 loss: 3.44789e-05
Iter: 1023 loss: 3.44611035e-05
Iter: 1024 loss: 3.4454486e-05
Iter: 1025 loss: 3.44577129e-05
Iter: 1026 loss: 3.44499749e-05
Iter: 1027 loss: 3.4443452e-05
Iter: 1028 loss: 3.44434338e-05
Iter: 1029 loss: 3.44381697e-05
Iter: 1030 loss: 3.44349537e-05
Iter: 1031 loss: 3.44329092e-05
Iter: 1032 loss: 3.44263317e-05
Iter: 1033 loss: 3.44231448e-05
Iter: 1034 loss: 3.44198452e-05
Iter: 1035 loss: 3.44097862e-05
Iter: 1036 loss: 3.4440498e-05
Iter: 1037 loss: 3.44067e-05
Iter: 1038 loss: 3.4397257e-05
Iter: 1039 loss: 3.44438304e-05
Iter: 1040 loss: 3.43957e-05
Iter: 1041 loss: 3.43871943e-05
Iter: 1042 loss: 3.44054315e-05
Iter: 1043 loss: 3.43839747e-05
Iter: 1044 loss: 3.43747088e-05
Iter: 1045 loss: 3.43945539e-05
Iter: 1046 loss: 3.43711e-05
Iter: 1047 loss: 3.43612628e-05
Iter: 1048 loss: 3.43936772e-05
Iter: 1049 loss: 3.43587162e-05
Iter: 1050 loss: 3.43506908e-05
Iter: 1051 loss: 3.44068685e-05
Iter: 1052 loss: 3.4349956e-05
Iter: 1053 loss: 3.4343233e-05
Iter: 1054 loss: 3.4376837e-05
Iter: 1055 loss: 3.43420907e-05
Iter: 1056 loss: 3.43366592e-05
Iter: 1057 loss: 3.43354841e-05
Iter: 1058 loss: 3.43320826e-05
Iter: 1059 loss: 3.43267675e-05
Iter: 1060 loss: 3.4326793e-05
Iter: 1061 loss: 3.43225e-05
Iter: 1062 loss: 3.43216198e-05
Iter: 1063 loss: 3.43188876e-05
Iter: 1064 loss: 3.43133215e-05
Iter: 1065 loss: 3.43086504e-05
Iter: 1066 loss: 3.43071079e-05
Iter: 1067 loss: 3.42986532e-05
Iter: 1068 loss: 3.43211068e-05
Iter: 1069 loss: 3.42959538e-05
Iter: 1070 loss: 3.42877102e-05
Iter: 1071 loss: 3.43352331e-05
Iter: 1072 loss: 3.4286717e-05
Iter: 1073 loss: 3.42796302e-05
Iter: 1074 loss: 3.42897729e-05
Iter: 1075 loss: 3.42761668e-05
Iter: 1076 loss: 3.42677631e-05
Iter: 1077 loss: 3.42975618e-05
Iter: 1078 loss: 3.4265573e-05
Iter: 1079 loss: 3.42584244e-05
Iter: 1080 loss: 3.42757121e-05
Iter: 1081 loss: 3.42557905e-05
Iter: 1082 loss: 3.42486783e-05
Iter: 1083 loss: 3.42936037e-05
Iter: 1084 loss: 3.42478779e-05
Iter: 1085 loss: 3.42426501e-05
Iter: 1086 loss: 3.42825551e-05
Iter: 1087 loss: 3.42421699e-05
Iter: 1088 loss: 3.42381027e-05
Iter: 1089 loss: 3.4235316e-05
Iter: 1090 loss: 3.42337917e-05
Iter: 1091 loss: 3.42295862e-05
Iter: 1092 loss: 3.42295243e-05
Iter: 1093 loss: 3.42260428e-05
Iter: 1094 loss: 3.42257772e-05
Iter: 1095 loss: 3.42231069e-05
Iter: 1096 loss: 3.42183812e-05
Iter: 1097 loss: 3.42140156e-05
Iter: 1098 loss: 3.42128697e-05
Iter: 1099 loss: 3.42057683e-05
Iter: 1100 loss: 3.42246203e-05
Iter: 1101 loss: 3.42033563e-05
Iter: 1102 loss: 3.41965497e-05
Iter: 1103 loss: 3.42350031e-05
Iter: 1104 loss: 3.41955347e-05
Iter: 1105 loss: 3.41896521e-05
Iter: 1106 loss: 3.42007042e-05
Iter: 1107 loss: 3.41872e-05
Iter: 1108 loss: 3.41804043e-05
Iter: 1109 loss: 3.42009735e-05
Iter: 1110 loss: 3.41783e-05
Iter: 1111 loss: 3.41723135e-05
Iter: 1112 loss: 3.41889317e-05
Iter: 1113 loss: 3.41703271e-05
Iter: 1114 loss: 3.41643572e-05
Iter: 1115 loss: 3.41958221e-05
Iter: 1116 loss: 3.41634623e-05
Iter: 1117 loss: 3.41591513e-05
Iter: 1118 loss: 3.41969608e-05
Iter: 1119 loss: 3.41589293e-05
Iter: 1120 loss: 3.41555096e-05
Iter: 1121 loss: 3.41536579e-05
Iter: 1122 loss: 3.41522027e-05
Iter: 1123 loss: 3.41483392e-05
Iter: 1124 loss: 3.42019484e-05
Iter: 1125 loss: 3.41483537e-05
Iter: 1126 loss: 3.41449595e-05
Iter: 1127 loss: 3.41470077e-05
Iter: 1128 loss: 3.4142824e-05
Iter: 1129 loss: 3.41389386e-05
Iter: 1130 loss: 3.41342311e-05
Iter: 1131 loss: 3.41338491e-05
Iter: 1132 loss: 3.41274717e-05
Iter: 1133 loss: 3.41478699e-05
Iter: 1134 loss: 3.41256346e-05
Iter: 1135 loss: 3.411957e-05
Iter: 1136 loss: 3.41398918e-05
Iter: 1137 loss: 3.41179693e-05
Iter: 1138 loss: 3.41123086e-05
Iter: 1139 loss: 3.41369414e-05
Iter: 1140 loss: 3.41111372e-05
Iter: 1141 loss: 3.41056402e-05
Iter: 1142 loss: 3.41119776e-05
Iter: 1143 loss: 3.4102748e-05
Iter: 1144 loss: 3.40968472e-05
Iter: 1145 loss: 3.4124565e-05
Iter: 1146 loss: 3.40956758e-05
Iter: 1147 loss: 3.40905644e-05
Iter: 1148 loss: 3.41080849e-05
Iter: 1149 loss: 3.40891129e-05
Iter: 1150 loss: 3.40847619e-05
Iter: 1151 loss: 3.41306149e-05
Iter: 1152 loss: 3.40847764e-05
Iter: 1153 loss: 3.40817496e-05
Iter: 1154 loss: 3.4081022e-05
Iter: 1155 loss: 3.40789848e-05
Iter: 1156 loss: 3.40752449e-05
Iter: 1157 loss: 3.41038758e-05
Iter: 1158 loss: 3.40748484e-05
Iter: 1159 loss: 3.40711813e-05
Iter: 1160 loss: 3.40805818e-05
Iter: 1161 loss: 3.40699917e-05
Iter: 1162 loss: 3.4066903e-05
Iter: 1163 loss: 3.4062643e-05
Iter: 1164 loss: 3.4062472e-05
Iter: 1165 loss: 3.40568949e-05
Iter: 1166 loss: 3.40761617e-05
Iter: 1167 loss: 3.40554179e-05
Iter: 1168 loss: 3.40504848e-05
Iter: 1169 loss: 3.40586157e-05
Iter: 1170 loss: 3.40482657e-05
Iter: 1171 loss: 3.40429178e-05
Iter: 1172 loss: 3.40767183e-05
Iter: 1173 loss: 3.40423176e-05
Iter: 1174 loss: 3.4037359e-05
Iter: 1175 loss: 3.40395527e-05
Iter: 1176 loss: 3.40339611e-05
Iter: 1177 loss: 3.40282277e-05
Iter: 1178 loss: 3.40626284e-05
Iter: 1179 loss: 3.40273946e-05
Iter: 1180 loss: 3.40228871e-05
Iter: 1181 loss: 3.40362021e-05
Iter: 1182 loss: 3.40213664e-05
Iter: 1183 loss: 3.40175902e-05
Iter: 1184 loss: 3.40642036e-05
Iter: 1185 loss: 3.40174956e-05
Iter: 1186 loss: 3.40146762e-05
Iter: 1187 loss: 3.40155675e-05
Iter: 1188 loss: 3.40127117e-05
Iter: 1189 loss: 3.40095357e-05
Iter: 1190 loss: 3.40261395e-05
Iter: 1191 loss: 3.40090846e-05
Iter: 1192 loss: 3.40058104e-05
Iter: 1193 loss: 3.40177503e-05
Iter: 1194 loss: 3.40051338e-05
Iter: 1195 loss: 3.40026309e-05
Iter: 1196 loss: 3.39987018e-05
Iter: 1197 loss: 3.39987e-05
Iter: 1198 loss: 3.39940671e-05
Iter: 1199 loss: 3.40093247e-05
Iter: 1200 loss: 3.39927719e-05
Iter: 1201 loss: 3.39882754e-05
Iter: 1202 loss: 3.39943326e-05
Iter: 1203 loss: 3.39861072e-05
Iter: 1204 loss: 3.39811813e-05
Iter: 1205 loss: 3.4009583e-05
Iter: 1206 loss: 3.39806174e-05
Iter: 1207 loss: 3.39757898e-05
Iter: 1208 loss: 3.3981858e-05
Iter: 1209 loss: 3.39732578e-05
Iter: 1210 loss: 3.39687431e-05
Iter: 1211 loss: 3.39896e-05
Iter: 1212 loss: 3.3967739e-05
Iter: 1213 loss: 3.39635808e-05
Iter: 1214 loss: 3.39777107e-05
Iter: 1215 loss: 3.3962453e-05
Iter: 1216 loss: 3.39593062e-05
Iter: 1217 loss: 3.39965518e-05
Iter: 1218 loss: 3.39593062e-05
Iter: 1219 loss: 3.39568978e-05
Iter: 1220 loss: 3.39576764e-05
Iter: 1221 loss: 3.39550861e-05
Iter: 1222 loss: 3.39523613e-05
Iter: 1223 loss: 3.39657308e-05
Iter: 1224 loss: 3.3951932e-05
Iter: 1225 loss: 3.39492835e-05
Iter: 1226 loss: 3.39616126e-05
Iter: 1227 loss: 3.39488543e-05
Iter: 1228 loss: 3.39467151e-05
Iter: 1229 loss: 3.39430881e-05
Iter: 1230 loss: 3.39430335e-05
Iter: 1231 loss: 3.39391045e-05
Iter: 1232 loss: 3.39523831e-05
Iter: 1233 loss: 3.39379694e-05
Iter: 1234 loss: 3.3934055e-05
Iter: 1235 loss: 3.39390681e-05
Iter: 1236 loss: 3.39320068e-05
Iter: 1237 loss: 3.39278704e-05
Iter: 1238 loss: 3.39507678e-05
Iter: 1239 loss: 3.39271792e-05
Iter: 1240 loss: 3.39230173e-05
Iter: 1241 loss: 3.39311955e-05
Iter: 1242 loss: 3.39212929e-05
Iter: 1243 loss: 3.39175276e-05
Iter: 1244 loss: 3.39291728e-05
Iter: 1245 loss: 3.39163e-05
Iter: 1246 loss: 3.39123217e-05
Iter: 1247 loss: 3.39255712e-05
Iter: 1248 loss: 3.39111248e-05
Iter: 1249 loss: 3.39082762e-05
Iter: 1250 loss: 3.39432081e-05
Iter: 1251 loss: 3.3908269e-05
Iter: 1252 loss: 3.39059479e-05
Iter: 1253 loss: 3.39081598e-05
Iter: 1254 loss: 3.39045073e-05
Iter: 1255 loss: 3.39021208e-05
Iter: 1256 loss: 3.39094258e-05
Iter: 1257 loss: 3.39012877e-05
Iter: 1258 loss: 3.3898752e-05
Iter: 1259 loss: 3.39143153e-05
Iter: 1260 loss: 3.38984537e-05
Iter: 1261 loss: 3.38965e-05
Iter: 1262 loss: 3.38935279e-05
Iter: 1263 loss: 3.38935024e-05
Iter: 1264 loss: 3.38899445e-05
Iter: 1265 loss: 3.3899636e-05
Iter: 1266 loss: 3.38887403e-05
Iter: 1267 loss: 3.3885357e-05
Iter: 1268 loss: 3.38894461e-05
Iter: 1269 loss: 3.38836107e-05
Iter: 1270 loss: 3.38796308e-05
Iter: 1271 loss: 3.38997379e-05
Iter: 1272 loss: 3.38789614e-05
Iter: 1273 loss: 3.38753634e-05
Iter: 1274 loss: 3.38832e-05
Iter: 1275 loss: 3.38737809e-05
Iter: 1276 loss: 3.38699792e-05
Iter: 1277 loss: 3.38829668e-05
Iter: 1278 loss: 3.38690443e-05
Iter: 1279 loss: 3.38656173e-05
Iter: 1280 loss: 3.38747268e-05
Iter: 1281 loss: 3.38645405e-05
Iter: 1282 loss: 3.38613681e-05
Iter: 1283 loss: 3.3890261e-05
Iter: 1284 loss: 3.38611862e-05
Iter: 1285 loss: 3.38589816e-05
Iter: 1286 loss: 3.38667232e-05
Iter: 1287 loss: 3.3858425e-05
Iter: 1288 loss: 3.38565515e-05
Iter: 1289 loss: 3.38580285e-05
Iter: 1290 loss: 3.38554455e-05
Iter: 1291 loss: 3.38530626e-05
Iter: 1292 loss: 3.38733298e-05
Iter: 1293 loss: 3.38528444e-05
Iter: 1294 loss: 3.385132e-05
Iter: 1295 loss: 3.38489772e-05
Iter: 1296 loss: 3.38488389e-05
Iter: 1297 loss: 3.38459649e-05
Iter: 1298 loss: 3.38511309e-05
Iter: 1299 loss: 3.38444952e-05
Iter: 1300 loss: 3.38416285e-05
Iter: 1301 loss: 3.38451064e-05
Iter: 1302 loss: 3.38399841e-05
Iter: 1303 loss: 3.38362697e-05
Iter: 1304 loss: 3.38555401e-05
Iter: 1305 loss: 3.38357277e-05
Iter: 1306 loss: 3.38325954e-05
Iter: 1307 loss: 3.38411337e-05
Iter: 1308 loss: 3.38316204e-05
Iter: 1309 loss: 3.38284954e-05
Iter: 1310 loss: 3.38383143e-05
Iter: 1311 loss: 3.3827484e-05
Iter: 1312 loss: 3.38247701e-05
Iter: 1313 loss: 3.38321843e-05
Iter: 1314 loss: 3.38238242e-05
Iter: 1315 loss: 3.3821274e-05
Iter: 1316 loss: 3.38449609e-05
Iter: 1317 loss: 3.38210339e-05
Iter: 1318 loss: 3.38191712e-05
Iter: 1319 loss: 3.38271784e-05
Iter: 1320 loss: 3.38188765e-05
Iter: 1321 loss: 3.3817294e-05
Iter: 1322 loss: 3.38174941e-05
Iter: 1323 loss: 3.38162718e-05
Iter: 1324 loss: 3.38142308e-05
Iter: 1325 loss: 3.38357495e-05
Iter: 1326 loss: 3.38142418e-05
Iter: 1327 loss: 3.38128557e-05
Iter: 1328 loss: 3.38110258e-05
Iter: 1329 loss: 3.38109821e-05
Iter: 1330 loss: 3.38085192e-05
Iter: 1331 loss: 3.38123282e-05
Iter: 1332 loss: 3.38073769e-05
Iter: 1333 loss: 3.3804783e-05
Iter: 1334 loss: 3.38080754e-05
Iter: 1335 loss: 3.38034952e-05
Iter: 1336 loss: 3.38006284e-05
Iter: 1337 loss: 3.38176214e-05
Iter: 1338 loss: 3.38002e-05
Iter: 1339 loss: 3.37978418e-05
Iter: 1340 loss: 3.38031023e-05
Iter: 1341 loss: 3.3796834e-05
Iter: 1342 loss: 3.37942402e-05
Iter: 1343 loss: 3.38023528e-05
Iter: 1344 loss: 3.3793418e-05
Iter: 1345 loss: 3.3790915e-05
Iter: 1346 loss: 3.37978709e-05
Iter: 1347 loss: 3.37901874e-05
Iter: 1348 loss: 3.37881e-05
Iter: 1349 loss: 3.38089776e-05
Iter: 1350 loss: 3.37880192e-05
Iter: 1351 loss: 3.37865e-05
Iter: 1352 loss: 3.37922065e-05
Iter: 1353 loss: 3.37861638e-05
Iter: 1354 loss: 3.37848141e-05
Iter: 1355 loss: 3.37852834e-05
Iter: 1356 loss: 3.37838792e-05
Iter: 1357 loss: 3.37824385e-05
Iter: 1358 loss: 3.38016544e-05
Iter: 1359 loss: 3.37823221e-05
Iter: 1360 loss: 3.37812817e-05
Iter: 1361 loss: 3.37795573e-05
Iter: 1362 loss: 3.3779459e-05
Iter: 1363 loss: 3.37775091e-05
Iter: 1364 loss: 3.37812417e-05
Iter: 1365 loss: 3.37766505e-05
Iter: 1366 loss: 3.37746642e-05
Iter: 1367 loss: 3.37756792e-05
Iter: 1368 loss: 3.37731253e-05
Iter: 1369 loss: 3.37706224e-05
Iter: 1370 loss: 3.37862039e-05
Iter: 1371 loss: 3.37703314e-05
Iter: 1372 loss: 3.3768054e-05
Iter: 1373 loss: 3.3772998e-05
Iter: 1374 loss: 3.37670972e-05
Iter: 1375 loss: 3.37646088e-05
Iter: 1376 loss: 3.37723977e-05
Iter: 1377 loss: 3.37639613e-05
Iter: 1378 loss: 3.37618039e-05
Iter: 1379 loss: 3.37681195e-05
Iter: 1380 loss: 3.3761e-05
Iter: 1381 loss: 3.37592537e-05
Iter: 1382 loss: 3.37774363e-05
Iter: 1383 loss: 3.37592428e-05
Iter: 1384 loss: 3.37578858e-05
Iter: 1385 loss: 3.37627425e-05
Iter: 1386 loss: 3.37575075e-05
Iter: 1387 loss: 3.37563033e-05
Iter: 1388 loss: 3.3756598e-05
Iter: 1389 loss: 3.37553756e-05
Iter: 1390 loss: 3.37539714e-05
Iter: 1391 loss: 3.37712227e-05
Iter: 1392 loss: 3.37539641e-05
Iter: 1393 loss: 3.37529127e-05
Iter: 1394 loss: 3.37516467e-05
Iter: 1395 loss: 3.37514612e-05
Iter: 1396 loss: 3.37497258e-05
Iter: 1397 loss: 3.3751181e-05
Iter: 1398 loss: 3.37486599e-05
Iter: 1399 loss: 3.37465681e-05
Iter: 1400 loss: 3.37498459e-05
Iter: 1401 loss: 3.37454949e-05
Iter: 1402 loss: 3.37431411e-05
Iter: 1403 loss: 3.37527454e-05
Iter: 1404 loss: 3.37426172e-05
Iter: 1405 loss: 3.37403872e-05
Iter: 1406 loss: 3.37473975e-05
Iter: 1407 loss: 3.3739725e-05
Iter: 1408 loss: 3.3737444e-05
Iter: 1409 loss: 3.3743494e-05
Iter: 1410 loss: 3.37366364e-05
Iter: 1411 loss: 3.37346319e-05
Iter: 1412 loss: 3.37418023e-05
Iter: 1413 loss: 3.37341808e-05
Iter: 1414 loss: 3.37323836e-05
Iter: 1415 loss: 3.37436577e-05
Iter: 1416 loss: 3.37321326e-05
Iter: 1417 loss: 3.37308265e-05
Iter: 1418 loss: 3.37393431e-05
Iter: 1419 loss: 3.37306737e-05
Iter: 1420 loss: 3.37295205e-05
Iter: 1421 loss: 3.37295642e-05
Iter: 1422 loss: 3.37286692e-05
Iter: 1423 loss: 3.37274068e-05
Iter: 1424 loss: 3.37407073e-05
Iter: 1425 loss: 3.37272868e-05
Iter: 1426 loss: 3.37261445e-05
Iter: 1427 loss: 3.37256643e-05
Iter: 1428 loss: 3.37251586e-05
Iter: 1429 loss: 3.37236779e-05
Iter: 1430 loss: 3.37232195e-05
Iter: 1431 loss: 3.37224119e-05
Iter: 1432 loss: 3.37203055e-05
Iter: 1433 loss: 3.37270758e-05
Iter: 1434 loss: 3.37197416e-05
Iter: 1435 loss: 3.37176243e-05
Iter: 1436 loss: 3.37219462e-05
Iter: 1437 loss: 3.37168676e-05
Iter: 1438 loss: 3.37148522e-05
Iter: 1439 loss: 3.37247511e-05
Iter: 1440 loss: 3.3714492e-05
Iter: 1441 loss: 3.37123893e-05
Iter: 1442 loss: 3.37164529e-05
Iter: 1443 loss: 3.37116071e-05
Iter: 1444 loss: 3.37098609e-05
Iter: 1445 loss: 3.37165693e-05
Iter: 1446 loss: 3.37094025e-05
Iter: 1447 loss: 3.37078236e-05
Iter: 1448 loss: 3.37173406e-05
Iter: 1449 loss: 3.3707649e-05
Iter: 1450 loss: 3.37064121e-05
Iter: 1451 loss: 3.37156889e-05
Iter: 1452 loss: 3.37063466e-05
Iter: 1453 loss: 3.37054735e-05
Iter: 1454 loss: 3.37051424e-05
Iter: 1455 loss: 3.3704644e-05
Iter: 1456 loss: 3.3703418e-05
Iter: 1457 loss: 3.37167367e-05
Iter: 1458 loss: 3.37034653e-05
Iter: 1459 loss: 3.3702614e-05
Iter: 1460 loss: 3.37023157e-05
Iter: 1461 loss: 3.37017227e-05
Iter: 1462 loss: 3.37005622e-05
Iter: 1463 loss: 3.36999292e-05
Iter: 1464 loss: 3.36993471e-05
Iter: 1465 loss: 3.36976955e-05
Iter: 1466 loss: 3.37027122e-05
Iter: 1467 loss: 3.36971279e-05
Iter: 1468 loss: 3.36952653e-05
Iter: 1469 loss: 3.37005695e-05
Iter: 1470 loss: 3.36947633e-05
Iter: 1471 loss: 3.36930534e-05
Iter: 1472 loss: 3.36993035e-05
Iter: 1473 loss: 3.36928679e-05
Iter: 1474 loss: 3.36910416e-05
Iter: 1475 loss: 3.36959274e-05
Iter: 1476 loss: 3.36905287e-05
Iter: 1477 loss: 3.36891389e-05
Iter: 1478 loss: 3.36925623e-05
Iter: 1479 loss: 3.36886478e-05
Iter: 1480 loss: 3.36873418e-05
Iter: 1481 loss: 3.36980884e-05
Iter: 1482 loss: 3.3687269e-05
Iter: 1483 loss: 3.36863231e-05
Iter: 1484 loss: 3.36926569e-05
Iter: 1485 loss: 3.3686294e-05
Iter: 1486 loss: 3.36856101e-05
Iter: 1487 loss: 3.36855155e-05
Iter: 1488 loss: 3.36849735e-05
Iter: 1489 loss: 3.36841767e-05
Iter: 1490 loss: 3.36932571e-05
Iter: 1491 loss: 3.36841404e-05
Iter: 1492 loss: 3.36834346e-05
Iter: 1493 loss: 3.36831326e-05
Iter: 1494 loss: 3.36828307e-05
Iter: 1495 loss: 3.36817538e-05
Iter: 1496 loss: 3.36816374e-05
Iter: 1497 loss: 3.36808953e-05
Iter: 1498 loss: 3.36796074e-05
Iter: 1499 loss: 3.3682576e-05
Iter: 1500 loss: 3.36791345e-05
Iter: 1501 loss: 3.36775702e-05
Iter: 1502 loss: 3.36827179e-05
Iter: 1503 loss: 3.36772719e-05
Iter: 1504 loss: 3.36759476e-05
Iter: 1505 loss: 3.36790799e-05
Iter: 1506 loss: 3.36754529e-05
Iter: 1507 loss: 3.36740268e-05
Iter: 1508 loss: 3.36813209e-05
Iter: 1509 loss: 3.36737721e-05
Iter: 1510 loss: 3.3672728e-05
Iter: 1511 loss: 3.36736848e-05
Iter: 1512 loss: 3.36721569e-05
Iter: 1513 loss: 3.36709272e-05
Iter: 1514 loss: 3.36825397e-05
Iter: 1515 loss: 3.36709854e-05
Iter: 1516 loss: 3.36702469e-05
Iter: 1517 loss: 3.36751145e-05
Iter: 1518 loss: 3.36701669e-05
Iter: 1519 loss: 3.36695557e-05
Iter: 1520 loss: 3.36695484e-05
Iter: 1521 loss: 3.36690064e-05
Iter: 1522 loss: 3.3668417e-05
Iter: 1523 loss: 3.36745579e-05
Iter: 1524 loss: 3.36683916e-05
Iter: 1525 loss: 3.36677695e-05
Iter: 1526 loss: 3.36673293e-05
Iter: 1527 loss: 3.3667111e-05
Iter: 1528 loss: 3.36661906e-05
Iter: 1529 loss: 3.36663579e-05
Iter: 1530 loss: 3.36655175e-05
Iter: 1531 loss: 3.36643316e-05
Iter: 1532 loss: 3.36662e-05
Iter: 1533 loss: 3.36638732e-05
Iter: 1534 loss: 3.36625089e-05
Iter: 1535 loss: 3.36672965e-05
Iter: 1536 loss: 3.36621706e-05
Iter: 1537 loss: 3.366085e-05
Iter: 1538 loss: 3.36638186e-05
Iter: 1539 loss: 3.36603916e-05
Iter: 1540 loss: 3.3659082e-05
Iter: 1541 loss: 3.36665835e-05
Iter: 1542 loss: 3.36588746e-05
Iter: 1543 loss: 3.36579833e-05
Iter: 1544 loss: 3.36582671e-05
Iter: 1545 loss: 3.36571502e-05
Iter: 1546 loss: 3.36560079e-05
Iter: 1547 loss: 3.36685189e-05
Iter: 1548 loss: 3.3656e-05
Iter: 1549 loss: 3.36552694e-05
Iter: 1550 loss: 3.36605408e-05
Iter: 1551 loss: 3.36552221e-05
Iter: 1552 loss: 3.36545854e-05
Iter: 1553 loss: 3.36547455e-05
Iter: 1554 loss: 3.36540761e-05
Iter: 1555 loss: 3.36534358e-05
Iter: 1556 loss: 3.36593439e-05
Iter: 1557 loss: 3.36534067e-05
Iter: 1558 loss: 3.36526682e-05
Iter: 1559 loss: 3.36525045e-05
Iter: 1560 loss: 3.36521553e-05
Iter: 1561 loss: 3.36512239e-05
Iter: 1562 loss: 3.36512276e-05
Iter: 1563 loss: 3.36505545e-05
Iter: 1564 loss: 3.36494413e-05
Iter: 1565 loss: 3.3650882e-05
Iter: 1566 loss: 3.36488447e-05
Iter: 1567 loss: 3.36475205e-05
Iter: 1568 loss: 3.36525627e-05
Iter: 1569 loss: 3.3647193e-05
Iter: 1570 loss: 3.36459925e-05
Iter: 1571 loss: 3.36487465e-05
Iter: 1572 loss: 3.36454796e-05
Iter: 1573 loss: 3.36441917e-05
Iter: 1574 loss: 3.36515841e-05
Iter: 1575 loss: 3.36440025e-05
Iter: 1576 loss: 3.36429839e-05
Iter: 1577 loss: 3.36437042e-05
Iter: 1578 loss: 3.36422527e-05
Iter: 1579 loss: 3.36412086e-05
Iter: 1580 loss: 3.36521625e-05
Iter: 1581 loss: 3.36411686e-05
Iter: 1582 loss: 3.364035e-05
Iter: 1583 loss: 3.36454395e-05
Iter: 1584 loss: 3.36403682e-05
Iter: 1585 loss: 3.36395606e-05
Iter: 1586 loss: 3.364023e-05
Iter: 1587 loss: 3.36392804e-05
Iter: 1588 loss: 3.36385892e-05
Iter: 1589 loss: 3.36429584e-05
Iter: 1590 loss: 3.3638622e-05
Iter: 1591 loss: 3.36378798e-05
Iter: 1592 loss: 3.36380326e-05
Iter: 1593 loss: 3.36374142e-05
Iter: 1594 loss: 3.36367157e-05
Iter: 1595 loss: 3.36367157e-05
Iter: 1596 loss: 3.36361045e-05
Iter: 1597 loss: 3.36350422e-05
Iter: 1598 loss: 3.36361736e-05
Iter: 1599 loss: 3.36345947e-05
Iter: 1600 loss: 3.3633456e-05
Iter: 1601 loss: 3.36380908e-05
Iter: 1602 loss: 3.36331395e-05
Iter: 1603 loss: 3.36320263e-05
Iter: 1604 loss: 3.36340272e-05
Iter: 1605 loss: 3.36315425e-05
Iter: 1606 loss: 3.36304402e-05
Iter: 1607 loss: 3.36377198e-05
Iter: 1608 loss: 3.36301964e-05
Iter: 1609 loss: 3.36293524e-05
Iter: 1610 loss: 3.36301237e-05
Iter: 1611 loss: 3.36287667e-05
Iter: 1612 loss: 3.36278499e-05
Iter: 1613 loss: 3.36358789e-05
Iter: 1614 loss: 3.36277226e-05
Iter: 1615 loss: 3.36270132e-05
Iter: 1616 loss: 3.36319063e-05
Iter: 1617 loss: 3.36269841e-05
Iter: 1618 loss: 3.36263656e-05
Iter: 1619 loss: 3.36270241e-05
Iter: 1620 loss: 3.36260491e-05
Iter: 1621 loss: 3.36255071e-05
Iter: 1622 loss: 3.3628643e-05
Iter: 1623 loss: 3.36254452e-05
Iter: 1624 loss: 3.36248049e-05
Iter: 1625 loss: 3.36253215e-05
Iter: 1626 loss: 3.36245066e-05
Iter: 1627 loss: 3.36239173e-05
Iter: 1628 loss: 3.36236371e-05
Iter: 1629 loss: 3.36233315e-05
Iter: 1630 loss: 3.36224111e-05
Iter: 1631 loss: 3.362403e-05
Iter: 1632 loss: 3.36220037e-05
Iter: 1633 loss: 3.36210032e-05
Iter: 1634 loss: 3.36245648e-05
Iter: 1635 loss: 3.36207158e-05
Iter: 1636 loss: 3.36198827e-05
Iter: 1637 loss: 3.36215562e-05
Iter: 1638 loss: 3.36195e-05
Iter: 1639 loss: 3.36184894e-05
Iter: 1640 loss: 3.36244e-05
Iter: 1641 loss: 3.36182711e-05
Iter: 1642 loss: 3.36175799e-05
Iter: 1643 loss: 3.36185112e-05
Iter: 1644 loss: 3.36170924e-05
Iter: 1645 loss: 3.36161829e-05
Iter: 1646 loss: 3.36214725e-05
Iter: 1647 loss: 3.36161138e-05
Iter: 1648 loss: 3.3615408e-05
Iter: 1649 loss: 3.36207413e-05
Iter: 1650 loss: 3.36152589e-05
Iter: 1651 loss: 3.36147787e-05
Iter: 1652 loss: 3.36153898e-05
Iter: 1653 loss: 3.36145276e-05
Iter: 1654 loss: 3.36140511e-05
Iter: 1655 loss: 3.36166049e-05
Iter: 1656 loss: 3.36140147e-05
Iter: 1657 loss: 3.36134035e-05
Iter: 1658 loss: 3.36145895e-05
Iter: 1659 loss: 3.36132e-05
Iter: 1660 loss: 3.36127778e-05
Iter: 1661 loss: 3.3612163e-05
Iter: 1662 loss: 3.36120393e-05
Iter: 1663 loss: 3.36111661e-05
Iter: 1664 loss: 3.36138728e-05
Iter: 1665 loss: 3.36109151e-05
Iter: 1666 loss: 3.361e-05
Iter: 1667 loss: 3.36118537e-05
Iter: 1668 loss: 3.36097837e-05
Iter: 1669 loss: 3.36088051e-05
Iter: 1670 loss: 3.3610675e-05
Iter: 1671 loss: 3.36084559e-05
Iter: 1672 loss: 3.36073281e-05
Iter: 1673 loss: 3.36134726e-05
Iter: 1674 loss: 3.36072299e-05
Iter: 1675 loss: 3.36063495e-05
Iter: 1676 loss: 3.36074518e-05
Iter: 1677 loss: 3.36060111e-05
Iter: 1678 loss: 3.36050944e-05
Iter: 1679 loss: 3.36099474e-05
Iter: 1680 loss: 3.36049379e-05
Iter: 1681 loss: 3.36043522e-05
Iter: 1682 loss: 3.36106677e-05
Iter: 1683 loss: 3.36042722e-05
Iter: 1684 loss: 3.36038647e-05
Iter: 1685 loss: 3.36043668e-05
Iter: 1686 loss: 3.360357e-05
Iter: 1687 loss: 3.36030316e-05
Iter: 1688 loss: 3.36049197e-05
Iter: 1689 loss: 3.36029516e-05
Iter: 1690 loss: 3.36024968e-05
Iter: 1691 loss: 3.36040284e-05
Iter: 1692 loss: 3.36022713e-05
Iter: 1693 loss: 3.36018202e-05
Iter: 1694 loss: 3.36011362e-05
Iter: 1695 loss: 3.36011508e-05
Iter: 1696 loss: 3.36002449e-05
Iter: 1697 loss: 3.36029116e-05
Iter: 1698 loss: 3.36e-05
Iter: 1699 loss: 3.35989971e-05
Iter: 1700 loss: 3.36010635e-05
Iter: 1701 loss: 3.35987061e-05
Iter: 1702 loss: 3.35978e-05
Iter: 1703 loss: 3.35995137e-05
Iter: 1704 loss: 3.35973091e-05
Iter: 1705 loss: 3.35963196e-05
Iter: 1706 loss: 3.36038138e-05
Iter: 1707 loss: 3.35962468e-05
Iter: 1708 loss: 3.35953955e-05
Iter: 1709 loss: 3.35961522e-05
Iter: 1710 loss: 3.35949881e-05
Iter: 1711 loss: 3.35941186e-05
Iter: 1712 loss: 3.36005105e-05
Iter: 1713 loss: 3.35940567e-05
Iter: 1714 loss: 3.35934528e-05
Iter: 1715 loss: 3.35976911e-05
Iter: 1716 loss: 3.3593431e-05
Iter: 1717 loss: 3.35929799e-05
Iter: 1718 loss: 3.35935765e-05
Iter: 1719 loss: 3.35927143e-05
Iter: 1720 loss: 3.35922232e-05
Iter: 1721 loss: 3.3593984e-05
Iter: 1722 loss: 3.35921322e-05
Iter: 1723 loss: 3.35915611e-05
Iter: 1724 loss: 3.35930526e-05
Iter: 1725 loss: 3.35914228e-05
Iter: 1726 loss: 3.3590848e-05
Iter: 1727 loss: 3.35903387e-05
Iter: 1728 loss: 3.35903023e-05
Iter: 1729 loss: 3.35895529e-05
Iter: 1730 loss: 3.35912118e-05
Iter: 1731 loss: 3.35891964e-05
Iter: 1732 loss: 3.35883524e-05
Iter: 1733 loss: 3.35904842e-05
Iter: 1734 loss: 3.35880613e-05
Iter: 1735 loss: 3.35870791e-05
Iter: 1736 loss: 3.35888399e-05
Iter: 1737 loss: 3.35866753e-05
Iter: 1738 loss: 3.35857476e-05
Iter: 1739 loss: 3.35931036e-05
Iter: 1740 loss: 3.35857403e-05
Iter: 1741 loss: 3.35850564e-05
Iter: 1742 loss: 3.35855366e-05
Iter: 1743 loss: 3.35845907e-05
Iter: 1744 loss: 3.35837867e-05
Iter: 1745 loss: 3.35901059e-05
Iter: 1746 loss: 3.3583703e-05
Iter: 1747 loss: 3.35831355e-05
Iter: 1748 loss: 3.35874865e-05
Iter: 1749 loss: 3.35832083e-05
Iter: 1750 loss: 3.35826662e-05
Iter: 1751 loss: 3.35834338e-05
Iter: 1752 loss: 3.35825098e-05
Iter: 1753 loss: 3.35820623e-05
Iter: 1754 loss: 3.35833065e-05
Iter: 1755 loss: 3.35819204e-05
Iter: 1756 loss: 3.35814766e-05
Iter: 1757 loss: 3.35834484e-05
Iter: 1758 loss: 3.35813711e-05
Iter: 1759 loss: 3.358096e-05
Iter: 1760 loss: 3.35804e-05
Iter: 1761 loss: 3.35804325e-05
Iter: 1762 loss: 3.35797376e-05
Iter: 1763 loss: 3.35813529e-05
Iter: 1764 loss: 3.35794757e-05
Iter: 1765 loss: 3.35787554e-05
Iter: 1766 loss: 3.35800687e-05
Iter: 1767 loss: 3.35784e-05
Iter: 1768 loss: 3.35776e-05
Iter: 1769 loss: 3.35803197e-05
Iter: 1770 loss: 3.35773657e-05
Iter: 1771 loss: 3.35765872e-05
Iter: 1772 loss: 3.35806617e-05
Iter: 1773 loss: 3.35766345e-05
Iter: 1774 loss: 3.35758523e-05
Iter: 1775 loss: 3.35768455e-05
Iter: 1776 loss: 3.35756667e-05
Iter: 1777 loss: 3.35748264e-05
Iter: 1778 loss: 3.35775949e-05
Iter: 1779 loss: 3.35747209e-05
Iter: 1780 loss: 3.35742807e-05
Iter: 1781 loss: 3.35809236e-05
Iter: 1782 loss: 3.35742916e-05
Iter: 1783 loss: 3.35739351e-05
Iter: 1784 loss: 3.3574157e-05
Iter: 1785 loss: 3.35737095e-05
Iter: 1786 loss: 3.35733093e-05
Iter: 1787 loss: 3.35742297e-05
Iter: 1788 loss: 3.35731493e-05
Iter: 1789 loss: 3.35727236e-05
Iter: 1790 loss: 3.35751538e-05
Iter: 1791 loss: 3.35727564e-05
Iter: 1792 loss: 3.35723744e-05
Iter: 1793 loss: 3.3571836e-05
Iter: 1794 loss: 3.35718505e-05
Iter: 1795 loss: 3.35712684e-05
Iter: 1796 loss: 3.35729128e-05
Iter: 1797 loss: 3.35710756e-05
Iter: 1798 loss: 3.3570388e-05
Iter: 1799 loss: 3.35713376e-05
Iter: 1800 loss: 3.35700825e-05
Iter: 1801 loss: 3.35694203e-05
Iter: 1802 loss: 3.35716868e-05
Iter: 1803 loss: 3.35692421e-05
Iter: 1804 loss: 3.35684927e-05
Iter: 1805 loss: 3.35714831e-05
Iter: 1806 loss: 3.35684e-05
Iter: 1807 loss: 3.35677178e-05
Iter: 1808 loss: 3.35691766e-05
Iter: 1809 loss: 3.35675722e-05
Iter: 1810 loss: 3.35668883e-05
Iter: 1811 loss: 3.35696459e-05
Iter: 1812 loss: 3.35668083e-05
Iter: 1813 loss: 3.35664081e-05
Iter: 1814 loss: 3.35713266e-05
Iter: 1815 loss: 3.35664299e-05
Iter: 1816 loss: 3.3566037e-05
Iter: 1817 loss: 3.35662735e-05
Iter: 1818 loss: 3.3565957e-05
Iter: 1819 loss: 3.35654768e-05
Iter: 1820 loss: 3.35668301e-05
Iter: 1821 loss: 3.35653967e-05
Iter: 1822 loss: 3.35650802e-05
Iter: 1823 loss: 3.35669756e-05
Iter: 1824 loss: 3.35649529e-05
Iter: 1825 loss: 3.356464e-05
Iter: 1826 loss: 3.35641525e-05
Iter: 1827 loss: 3.35641962e-05
Iter: 1828 loss: 3.35635341e-05
Iter: 1829 loss: 3.35651857e-05
Iter: 1830 loss: 3.35634322e-05
Iter: 1831 loss: 3.35628e-05
Iter: 1832 loss: 3.3563796e-05
Iter: 1833 loss: 3.35624718e-05
Iter: 1834 loss: 3.35618133e-05
Iter: 1835 loss: 3.35633958e-05
Iter: 1836 loss: 3.35616e-05
Iter: 1837 loss: 3.35609e-05
Iter: 1838 loss: 3.35645163e-05
Iter: 1839 loss: 3.35608347e-05
Iter: 1840 loss: 3.3560158e-05
Iter: 1841 loss: 3.35615805e-05
Iter: 1842 loss: 3.35599616e-05
Iter: 1843 loss: 3.35593359e-05
Iter: 1844 loss: 3.35615623e-05
Iter: 1845 loss: 3.35592922e-05
Iter: 1846 loss: 3.35588702e-05
Iter: 1847 loss: 3.35633158e-05
Iter: 1848 loss: 3.35588629e-05
Iter: 1849 loss: 3.35585e-05
Iter: 1850 loss: 3.35588702e-05
Iter: 1851 loss: 3.35583136e-05
Iter: 1852 loss: 3.35579753e-05
Iter: 1853 loss: 3.35592813e-05
Iter: 1854 loss: 3.3557837e-05
Iter: 1855 loss: 3.35575423e-05
Iter: 1856 loss: 3.35592304e-05
Iter: 1857 loss: 3.35573241e-05
Iter: 1858 loss: 3.35570658e-05
Iter: 1859 loss: 3.35566219e-05
Iter: 1860 loss: 3.35565564e-05
Iter: 1861 loss: 3.3556e-05
Iter: 1862 loss: 3.35575169e-05
Iter: 1863 loss: 3.35558398e-05
Iter: 1864 loss: 3.35551849e-05
Iter: 1865 loss: 3.35564255e-05
Iter: 1866 loss: 3.35549375e-05
Iter: 1867 loss: 3.35542645e-05
Iter: 1868 loss: 3.35559962e-05
Iter: 1869 loss: 3.35541e-05
Iter: 1870 loss: 3.35534642e-05
Iter: 1871 loss: 3.35560107e-05
Iter: 1872 loss: 3.35532386e-05
Iter: 1873 loss: 3.35526493e-05
Iter: 1874 loss: 3.35548e-05
Iter: 1875 loss: 3.35526129e-05
Iter: 1876 loss: 3.35519871e-05
Iter: 1877 loss: 3.35536606e-05
Iter: 1878 loss: 3.35518816e-05
Iter: 1879 loss: 3.3551376e-05
Iter: 1880 loss: 3.35559635e-05
Iter: 1881 loss: 3.35513905e-05
Iter: 1882 loss: 3.35510631e-05
Iter: 1883 loss: 3.35517143e-05
Iter: 1884 loss: 3.35508885e-05
Iter: 1885 loss: 3.3550532e-05
Iter: 1886 loss: 3.35514269e-05
Iter: 1887 loss: 3.35504e-05
Iter: 1888 loss: 3.35500699e-05
Iter: 1889 loss: 3.3551969e-05
Iter: 1890 loss: 3.35500372e-05
Iter: 1891 loss: 3.35497534e-05
Iter: 1892 loss: 3.35492841e-05
Iter: 1893 loss: 3.35492914e-05
Iter: 1894 loss: 3.35486875e-05
Iter: 1895 loss: 3.35507066e-05
Iter: 1896 loss: 3.35485674e-05
Iter: 1897 loss: 3.354808e-05
Iter: 1898 loss: 3.35486475e-05
Iter: 1899 loss: 3.35477671e-05
Iter: 1900 loss: 3.35471195e-05
Iter: 1901 loss: 3.35491e-05
Iter: 1902 loss: 3.35469813e-05
Iter: 1903 loss: 3.35463956e-05
Iter: 1904 loss: 3.35481272e-05
Iter: 1905 loss: 3.35461664e-05
Iter: 1906 loss: 3.35457371e-05
Iter: 1907 loss: 3.35484074e-05
Iter: 1908 loss: 3.35455697e-05
Iter: 1909 loss: 3.35450932e-05
Iter: 1910 loss: 3.35459663e-05
Iter: 1911 loss: 3.35448276e-05
Iter: 1912 loss: 3.3544442e-05
Iter: 1913 loss: 3.35498044e-05
Iter: 1914 loss: 3.35444711e-05
Iter: 1915 loss: 3.35442091e-05
Iter: 1916 loss: 3.35447912e-05
Iter: 1917 loss: 3.35441764e-05
Iter: 1918 loss: 3.35439036e-05
Iter: 1919 loss: 3.35444238e-05
Iter: 1920 loss: 3.35436453e-05
Iter: 1921 loss: 3.35434052e-05
Iter: 1922 loss: 3.35452096e-05
Iter: 1923 loss: 3.35433142e-05
Iter: 1924 loss: 3.35431396e-05
Iter: 1925 loss: 3.35427139e-05
Iter: 1926 loss: 3.35427321e-05
Iter: 1927 loss: 3.3542281e-05
Iter: 1928 loss: 3.35442455e-05
Iter: 1929 loss: 3.35421428e-05
Iter: 1930 loss: 3.35417863e-05
Iter: 1931 loss: 3.35419136e-05
Iter: 1932 loss: 3.35415752e-05
Iter: 1933 loss: 3.3541e-05
Iter: 1934 loss: 3.35431105e-05
Iter: 1935 loss: 3.35408695e-05
Iter: 1936 loss: 3.35404e-05
Iter: 1937 loss: 3.35417863e-05
Iter: 1938 loss: 3.35402146e-05
Iter: 1939 loss: 3.35397563e-05
Iter: 1940 loss: 3.35420555e-05
Iter: 1941 loss: 3.35397e-05
Iter: 1942 loss: 3.35391742e-05
Iter: 1943 loss: 3.35402874e-05
Iter: 1944 loss: 3.35390214e-05
Iter: 1945 loss: 3.35386831e-05
Iter: 1946 loss: 3.35416516e-05
Iter: 1947 loss: 3.35386903e-05
Iter: 1948 loss: 3.35384502e-05
Iter: 1949 loss: 3.35390869e-05
Iter: 1950 loss: 3.35382865e-05
Iter: 1951 loss: 3.35380973e-05
Iter: 1952 loss: 3.35387776e-05
Iter: 1953 loss: 3.35380173e-05
Iter: 1954 loss: 3.35377263e-05
Iter: 1955 loss: 3.35394107e-05
Iter: 1956 loss: 3.35377408e-05
Iter: 1957 loss: 3.35375225e-05
Iter: 1958 loss: 3.35371697e-05
Iter: 1959 loss: 3.3537126e-05
Iter: 1960 loss: 3.35368459e-05
Iter: 1961 loss: 3.35381446e-05
Iter: 1962 loss: 3.35367149e-05
Iter: 1963 loss: 3.35364e-05
Iter: 1964 loss: 3.35365039e-05
Iter: 1965 loss: 3.35361328e-05
Iter: 1966 loss: 3.35356526e-05
Iter: 1967 loss: 3.35370933e-05
Iter: 1968 loss: 3.35355e-05
Iter: 1969 loss: 3.35349905e-05
Iter: 1970 loss: 3.35365548e-05
Iter: 1971 loss: 3.35348341e-05
Iter: 1972 loss: 3.35342884e-05
Iter: 1973 loss: 3.35366858e-05
Iter: 1974 loss: 3.35342374e-05
Iter: 1975 loss: 3.35338154e-05
Iter: 1976 loss: 3.35349614e-05
Iter: 1977 loss: 3.35337427e-05
Iter: 1978 loss: 3.35332952e-05
Iter: 1979 loss: 3.35366931e-05
Iter: 1980 loss: 3.35333825e-05
Iter: 1981 loss: 3.35330442e-05
Iter: 1982 loss: 3.35339646e-05
Iter: 1983 loss: 3.35329642e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2
+ date
Tue Oct 27 15:41:58 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa275762f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa23396a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa233a6e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa233a6c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa233a6c488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa233990950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa20c0c37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa20c07b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa20c07b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa20c07b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f00990d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f00bcd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f005c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f0083598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f00a26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f00a2f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f004aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1f004ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1547a9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa154758b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15471cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15471c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15471c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15472a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15468d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15469fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15465fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15465fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa154627488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1545c41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1545bd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1545892f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa154591950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa15453bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa1545722f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa154510d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.064348571
Iter: 2 loss: 830.696777
Iter: 3 loss: 0.0643484145
Iter: 4 loss: 724.820801
Iter: 5 loss: 898.910461
Iter: 6 loss: 0.0643482953
Iter: 7 loss: 1435.35315
Iter: 8 loss: 0.0643482655
Iter: 9 loss: 0.0751064271
Iter: 10 loss: 0.052463077
Iter: 11 loss: 0.0512563661
Iter: 12 loss: 0.050817661
Iter: 13 loss: 0.0546956435
Iter: 14 loss: 0.0485716835
Iter: 15 loss: 0.0484506935
Iter: 16 loss: 0.04171497
Iter: 17 loss: 0.0413973518
Iter: 18 loss: 0.0347298644
Iter: 19 loss: 0.0340436921
Iter: 20 loss: 0.0279948097
Iter: 21 loss: 0.222973436
Iter: 22 loss: 0.0279702228
Iter: 23 loss: 0.0256890468
Iter: 24 loss: 0.0293508153
Iter: 25 loss: 0.025311619
Iter: 26 loss: 0.0239785984
Iter: 27 loss: 0.0374115631
Iter: 28 loss: 0.0238131359
Iter: 29 loss: 0.022314297
Iter: 30 loss: 0.0541082956
Iter: 31 loss: 0.0222304761
Iter: 32 loss: 0.0205096845
Iter: 33 loss: 0.0891426653
Iter: 34 loss: 0.0204891767
Iter: 35 loss: 0.0189311
Iter: 36 loss: 0.0284780581
Iter: 37 loss: 0.0187709108
Iter: 38 loss: 0.017855132
Iter: 39 loss: 0.0169654768
Iter: 40 loss: 0.0167357456
Iter: 41 loss: 0.015417492
Iter: 42 loss: 0.0194137786
Iter: 43 loss: 0.0148329306
Iter: 44 loss: 0.0136071052
Iter: 45 loss: 0.0518175848
Iter: 46 loss: 0.0135836639
Iter: 47 loss: 0.0123524526
Iter: 48 loss: 0.0191575009
Iter: 49 loss: 0.012109261
Iter: 50 loss: 0.0110796168
Iter: 51 loss: 0.0235254765
Iter: 52 loss: 0.0134130511
Iter: 53 loss: 0.0112423133
Iter: 54 loss: 0.0110678589
Iter: 55 loss: 0.0106431153
Iter: 56 loss: 0.0102015799
Iter: 57 loss: 0.0216964725
Iter: 58 loss: 0.0101851281
Iter: 59 loss: 0.00977436081
Iter: 60 loss: 0.0122624431
Iter: 61 loss: 0.00970798172
Iter: 62 loss: 0.00933451
Iter: 63 loss: 0.0101330848
Iter: 64 loss: 0.00920659117
Iter: 65 loss: 0.00896942243
Iter: 66 loss: 0.00994960777
Iter: 67 loss: 0.00890229922
Iter: 68 loss: 0.00856493786
Iter: 69 loss: 0.00960208569
Iter: 70 loss: 0.00845347717
Iter: 71 loss: 0.00807845686
Iter: 72 loss: 0.00946778618
Iter: 73 loss: 0.00798306055
Iter: 74 loss: 0.00762675144
Iter: 75 loss: 0.00913937949
Iter: 76 loss: 0.0075563835
Iter: 77 loss: 0.0072253691
Iter: 78 loss: 0.00773234
Iter: 79 loss: 0.00706955558
Iter: 80 loss: 0.0067442744
Iter: 81 loss: 0.0132663129
Iter: 82 loss: 0.00673812721
Iter: 83 loss: 0.00649724156
Iter: 84 loss: 0.00673494302
Iter: 85 loss: 0.00635940814
Iter: 86 loss: 0.00609687902
Iter: 87 loss: 0.00647233333
Iter: 88 loss: 0.00598032027
Iter: 89 loss: 0.00582686905
Iter: 90 loss: 0.00599034177
Iter: 91 loss: 0.00573402
Iter: 92 loss: 0.00558304368
Iter: 93 loss: 0.00561021175
Iter: 94 loss: 0.00546298083
Iter: 95 loss: 0.00516918302
Iter: 96 loss: 0.00589340553
Iter: 97 loss: 0.00506123248
Iter: 98 loss: 0.00483383471
Iter: 99 loss: 0.00574281113
Iter: 100 loss: 0.0047916458
Iter: 101 loss: 0.00462253112
Iter: 102 loss: 0.00695337914
Iter: 103 loss: 0.0046178475
Iter: 104 loss: 0.00448118057
Iter: 105 loss: 0.00490779756
Iter: 106 loss: 0.00444012787
Iter: 107 loss: 0.004287811
Iter: 108 loss: 0.00428699842
Iter: 109 loss: 0.00416402612
Iter: 110 loss: 0.00403137738
Iter: 111 loss: 0.00403092429
Iter: 112 loss: 0.00393013144
Iter: 113 loss: 0.00407605618
Iter: 114 loss: 0.00387881231
Iter: 115 loss: 0.0037860251
Iter: 116 loss: 0.00394956302
Iter: 117 loss: 0.0037486488
Iter: 118 loss: 0.00362000451
Iter: 119 loss: 0.00459382497
Iter: 120 loss: 0.00360399112
Iter: 121 loss: 0.00353567279
Iter: 122 loss: 0.0038281742
Iter: 123 loss: 0.00352454092
Iter: 124 loss: 0.0034434814
Iter: 125 loss: 0.00355425081
Iter: 126 loss: 0.00340073439
Iter: 127 loss: 0.00330862193
Iter: 128 loss: 0.00338123273
Iter: 129 loss: 0.00325285224
Iter: 130 loss: 0.00315438956
Iter: 131 loss: 0.00353883626
Iter: 132 loss: 0.00313063804
Iter: 133 loss: 0.00305237528
Iter: 134 loss: 0.00347614125
Iter: 135 loss: 0.00304175704
Iter: 136 loss: 0.00294825574
Iter: 137 loss: 0.00436289748
Iter: 138 loss: 0.00294704968
Iter: 139 loss: 0.00290392782
Iter: 140 loss: 0.00288498495
Iter: 141 loss: 0.00286280736
Iter: 142 loss: 0.00279200426
Iter: 143 loss: 0.0028219996
Iter: 144 loss: 0.0027423203
Iter: 145 loss: 0.00268090935
Iter: 146 loss: 0.00268089771
Iter: 147 loss: 0.00262546539
Iter: 148 loss: 0.00274128909
Iter: 149 loss: 0.0026017162
Iter: 150 loss: 0.00255767209
Iter: 151 loss: 0.00300376141
Iter: 152 loss: 0.00255711819
Iter: 153 loss: 0.00251917541
Iter: 154 loss: 0.00248520379
Iter: 155 loss: 0.00247480068
Iter: 156 loss: 0.0024216664
Iter: 157 loss: 0.00291046267
Iter: 158 loss: 0.00242029922
Iter: 159 loss: 0.00238162
Iter: 160 loss: 0.00237253355
Iter: 161 loss: 0.0023478833
Iter: 162 loss: 0.00228663837
Iter: 163 loss: 0.00233448297
Iter: 164 loss: 0.00224824646
Iter: 165 loss: 0.0021856511
Iter: 166 loss: 0.00262654386
Iter: 167 loss: 0.0021788762
Iter: 168 loss: 0.00214139884
Iter: 169 loss: 0.0024684486
Iter: 170 loss: 0.00213992526
Iter: 171 loss: 0.00211558747
Iter: 172 loss: 0.00207947847
Iter: 173 loss: 0.00207847473
Iter: 174 loss: 0.0020394
Iter: 175 loss: 0.00207118597
Iter: 176 loss: 0.0020159292
Iter: 177 loss: 0.00198276341
Iter: 178 loss: 0.00201055175
Iter: 179 loss: 0.00196228246
Iter: 180 loss: 0.00193117454
Iter: 181 loss: 0.00193017209
Iter: 182 loss: 0.00190890091
Iter: 183 loss: 0.00191719667
Iter: 184 loss: 0.00189336308
Iter: 185 loss: 0.00186952704
Iter: 186 loss: 0.00194582785
Iter: 187 loss: 0.001863271
Iter: 188 loss: 0.00184374489
Iter: 189 loss: 0.00184356479
Iter: 190 loss: 0.00182810368
Iter: 191 loss: 0.00179179409
Iter: 192 loss: 0.00194205216
Iter: 193 loss: 0.00178388262
Iter: 194 loss: 0.00174521084
Iter: 195 loss: 0.0018122883
Iter: 196 loss: 0.00172735075
Iter: 197 loss: 0.00169702631
Iter: 198 loss: 0.00173004239
Iter: 199 loss: 0.00168065878
Iter: 200 loss: 0.0016575316
Iter: 201 loss: 0.00180958421
Iter: 202 loss: 0.00165466184
Iter: 203 loss: 0.00163079496
Iter: 204 loss: 0.00171721634
Iter: 205 loss: 0.00162505568
Iter: 206 loss: 0.00160722213
Iter: 207 loss: 0.00159534905
Iter: 208 loss: 0.00158836856
Iter: 209 loss: 0.00156748714
Iter: 210 loss: 0.0015723356
Iter: 211 loss: 0.00155245839
Iter: 212 loss: 0.00153397047
Iter: 213 loss: 0.00154806592
Iter: 214 loss: 0.00152219925
Iter: 215 loss: 0.00150255533
Iter: 216 loss: 0.00154005259
Iter: 217 loss: 0.00149427378
Iter: 218 loss: 0.00147553
Iter: 219 loss: 0.00147070992
Iter: 220 loss: 0.00145873509
Iter: 221 loss: 0.00143668847
Iter: 222 loss: 0.00143667369
Iter: 223 loss: 0.00141721917
Iter: 224 loss: 0.00142152747
Iter: 225 loss: 0.00140274456
Iter: 226 loss: 0.00138188514
Iter: 227 loss: 0.00139309256
Iter: 228 loss: 0.00136840378
Iter: 229 loss: 0.00134980248
Iter: 230 loss: 0.0014436706
Iter: 231 loss: 0.00134674064
Iter: 232 loss: 0.00132865692
Iter: 233 loss: 0.00143881817
Iter: 234 loss: 0.00132653385
Iter: 235 loss: 0.00131314131
Iter: 236 loss: 0.00150852
Iter: 237 loss: 0.00131308136
Iter: 238 loss: 0.00130380969
Iter: 239 loss: 0.00129872351
Iter: 240 loss: 0.00129471044
Iter: 241 loss: 0.00128129858
Iter: 242 loss: 0.00133553299
Iter: 243 loss: 0.0012781166
Iter: 244 loss: 0.00126827974
Iter: 245 loss: 0.00136123819
Iter: 246 loss: 0.00126796565
Iter: 247 loss: 0.0012594104
Iter: 248 loss: 0.00126307388
Iter: 249 loss: 0.00125348475
Iter: 250 loss: 0.00124201435
Iter: 251 loss: 0.00123073696
Iter: 252 loss: 0.00122829888
Iter: 253 loss: 0.00121086184
Iter: 254 loss: 0.00133633567
Iter: 255 loss: 0.00120913726
Iter: 256 loss: 0.00119243935
Iter: 257 loss: 0.00127522
Iter: 258 loss: 0.00118972803
Iter: 259 loss: 0.001175532
Iter: 260 loss: 0.00117532513
Iter: 261 loss: 0.00116412365
Iter: 262 loss: 0.00114730443
Iter: 263 loss: 0.00119872391
Iter: 264 loss: 0.00114236842
Iter: 265 loss: 0.0011259988
Iter: 266 loss: 0.0012307982
Iter: 267 loss: 0.00112404395
Iter: 268 loss: 0.00111159426
Iter: 269 loss: 0.00122478022
Iter: 270 loss: 0.00111113617
Iter: 271 loss: 0.00110160327
Iter: 272 loss: 0.00110997946
Iter: 273 loss: 0.00109583512
Iter: 274 loss: 0.00108597032
Iter: 275 loss: 0.0010968711
Iter: 276 loss: 0.00108071801
Iter: 277 loss: 0.00107019232
Iter: 278 loss: 0.00109877181
Iter: 279 loss: 0.00106657716
Iter: 280 loss: 0.00105310243
Iter: 281 loss: 0.00107505417
Iter: 282 loss: 0.00104706618
Iter: 283 loss: 0.00103352952
Iter: 284 loss: 0.00102627138
Iter: 285 loss: 0.00102017
Iter: 286 loss: 0.00100374257
Iter: 287 loss: 0.00107094401
Iter: 288 loss: 0.0010003004
Iter: 289 loss: 0.000982499681
Iter: 290 loss: 0.00110337243
Iter: 291 loss: 0.00098046381
Iter: 292 loss: 0.000967743574
Iter: 293 loss: 0.000986515
Iter: 294 loss: 0.000961533631
Iter: 295 loss: 0.000948974572
Iter: 296 loss: 0.000954181131
Iter: 297 loss: 0.000940324157
Iter: 298 loss: 0.000924875902
Iter: 299 loss: 0.00100788334
Iter: 300 loss: 0.000922607083
Iter: 301 loss: 0.00091181288
Iter: 302 loss: 0.00091180118
Iter: 303 loss: 0.000904219283
Iter: 304 loss: 0.000927635585
Iter: 305 loss: 0.000902054773
Iter: 306 loss: 0.000895323697
Iter: 307 loss: 0.000896202517
Iter: 308 loss: 0.000890118361
Iter: 309 loss: 0.000882980588
Iter: 310 loss: 0.000927725108
Iter: 311 loss: 0.000882228138
Iter: 312 loss: 0.000875654281
Iter: 313 loss: 0.000880662818
Iter: 314 loss: 0.000871543656
Iter: 315 loss: 0.000864519156
Iter: 316 loss: 0.000863303489
Iter: 317 loss: 0.000858485524
Iter: 318 loss: 0.00084785372
Iter: 319 loss: 0.000845651259
Iter: 320 loss: 0.000838548
Iter: 321 loss: 0.000827556127
Iter: 322 loss: 0.000827187905
Iter: 323 loss: 0.000818899309
Iter: 324 loss: 0.000821944675
Iter: 325 loss: 0.000813045772
Iter: 326 loss: 0.00080324756
Iter: 327 loss: 0.000818291155
Iter: 328 loss: 0.000798625289
Iter: 329 loss: 0.000788551115
Iter: 330 loss: 0.000801551738
Iter: 331 loss: 0.000783297233
Iter: 332 loss: 0.000774538668
Iter: 333 loss: 0.000774288899
Iter: 334 loss: 0.000767832273
Iter: 335 loss: 0.000782284769
Iter: 336 loss: 0.000765268051
Iter: 337 loss: 0.000758996233
Iter: 338 loss: 0.000753024127
Iter: 339 loss: 0.000751613756
Iter: 340 loss: 0.000743479119
Iter: 341 loss: 0.000768106082
Iter: 342 loss: 0.000740963209
Iter: 343 loss: 0.00073184655
Iter: 344 loss: 0.000780977076
Iter: 345 loss: 0.000730565283
Iter: 346 loss: 0.000723149627
Iter: 347 loss: 0.000720188313
Iter: 348 loss: 0.000716165756
Iter: 349 loss: 0.000706471212
Iter: 350 loss: 0.000696845818
Iter: 351 loss: 0.00069481472
Iter: 352 loss: 0.0006850668
Iter: 353 loss: 0.000685043109
Iter: 354 loss: 0.000677713309
Iter: 355 loss: 0.000694540446
Iter: 356 loss: 0.000675021787
Iter: 357 loss: 0.000667649379
Iter: 358 loss: 0.000682419864
Iter: 359 loss: 0.000664569787
Iter: 360 loss: 0.000656363
Iter: 361 loss: 0.000662384497
Iter: 362 loss: 0.000651346287
Iter: 363 loss: 0.000644975575
Iter: 364 loss: 0.000644963351
Iter: 365 loss: 0.000640708604
Iter: 366 loss: 0.000654884963
Iter: 367 loss: 0.000639587874
Iter: 368 loss: 0.000634885801
Iter: 369 loss: 0.000636542216
Iter: 370 loss: 0.00063153822
Iter: 371 loss: 0.000626996218
Iter: 372 loss: 0.000631153642
Iter: 373 loss: 0.000624381821
Iter: 374 loss: 0.000619604194
Iter: 375 loss: 0.000659935293
Iter: 376 loss: 0.000619299
Iter: 377 loss: 0.000615093624
Iter: 378 loss: 0.000616272213
Iter: 379 loss: 0.000612065662
Iter: 380 loss: 0.00060560694
Iter: 381 loss: 0.00061310106
Iter: 382 loss: 0.000602120359
Iter: 383 loss: 0.000597776438
Iter: 384 loss: 0.000655639
Iter: 385 loss: 0.000597764447
Iter: 386 loss: 0.000594047538
Iter: 387 loss: 0.000594131358
Iter: 388 loss: 0.000591075048
Iter: 389 loss: 0.000585879723
Iter: 390 loss: 0.000591500197
Iter: 391 loss: 0.000583048968
Iter: 392 loss: 0.000576225226
Iter: 393 loss: 0.00060146
Iter: 394 loss: 0.000574484584
Iter: 395 loss: 0.000570148113
Iter: 396 loss: 0.000610603835
Iter: 397 loss: 0.000569983036
Iter: 398 loss: 0.000566028699
Iter: 399 loss: 0.000580608321
Iter: 400 loss: 0.00056500925
Iter: 401 loss: 0.000561052759
Iter: 402 loss: 0.000567831099
Iter: 403 loss: 0.000559298845
Iter: 404 loss: 0.000555451552
Iter: 405 loss: 0.0005568919
Iter: 406 loss: 0.000552748446
Iter: 407 loss: 0.000548335433
Iter: 408 loss: 0.00058407418
Iter: 409 loss: 0.000548074
Iter: 410 loss: 0.000544113864
Iter: 411 loss: 0.000546513766
Iter: 412 loss: 0.000541543064
Iter: 413 loss: 0.000537084881
Iter: 414 loss: 0.000537761836
Iter: 415 loss: 0.000533730839
Iter: 416 loss: 0.000529542624
Iter: 417 loss: 0.000546186697
Iter: 418 loss: 0.00052854541
Iter: 419 loss: 0.000524143688
Iter: 420 loss: 0.000529983197
Iter: 421 loss: 0.000521932612
Iter: 422 loss: 0.000516678498
Iter: 423 loss: 0.000526168616
Iter: 424 loss: 0.000514355372
Iter: 425 loss: 0.000508135767
Iter: 426 loss: 0.000543153903
Iter: 427 loss: 0.000507263525
Iter: 428 loss: 0.00050355983
Iter: 429 loss: 0.000531162485
Iter: 430 loss: 0.000503241434
Iter: 431 loss: 0.000500216847
Iter: 432 loss: 0.000513276784
Iter: 433 loss: 0.000499620044
Iter: 434 loss: 0.000496589812
Iter: 435 loss: 0.0004987219
Iter: 436 loss: 0.000494688749
Iter: 437 loss: 0.00049106474
Iter: 438 loss: 0.000489902508
Iter: 439 loss: 0.0004878
Iter: 440 loss: 0.000483751646
Iter: 441 loss: 0.00051897869
Iter: 442 loss: 0.000483511947
Iter: 443 loss: 0.000480340823
Iter: 444 loss: 0.000483518728
Iter: 445 loss: 0.000478566741
Iter: 446 loss: 0.00047438551
Iter: 447 loss: 0.000488836202
Iter: 448 loss: 0.000473245891
Iter: 449 loss: 0.000470455561
Iter: 450 loss: 0.000493139087
Iter: 451 loss: 0.000470290659
Iter: 452 loss: 0.000467697
Iter: 453 loss: 0.000466997706
Iter: 454 loss: 0.000465381832
Iter: 455 loss: 0.000461651187
Iter: 456 loss: 0.000462114287
Iter: 457 loss: 0.000458814466
Iter: 458 loss: 0.0004537325
Iter: 459 loss: 0.000488957739
Iter: 460 loss: 0.000453232671
Iter: 461 loss: 0.000450093852
Iter: 462 loss: 0.000480056566
Iter: 463 loss: 0.000449982617
Iter: 464 loss: 0.00044749782
Iter: 465 loss: 0.000458596711
Iter: 466 loss: 0.000446992723
Iter: 467 loss: 0.000444610749
Iter: 468 loss: 0.000448993262
Iter: 469 loss: 0.000443603669
Iter: 470 loss: 0.000441122684
Iter: 471 loss: 0.00044134364
Iter: 472 loss: 0.000439192459
Iter: 473 loss: 0.000436404865
Iter: 474 loss: 0.000453323417
Iter: 475 loss: 0.000436076254
Iter: 476 loss: 0.000433452748
Iter: 477 loss: 0.0004374907
Iter: 478 loss: 0.000432202505
Iter: 479 loss: 0.000429605308
Iter: 480 loss: 0.000435408147
Iter: 481 loss: 0.000428632164
Iter: 482 loss: 0.000426185346
Iter: 483 loss: 0.000433263049
Iter: 484 loss: 0.000425403909
Iter: 485 loss: 0.000422230863
Iter: 486 loss: 0.000427161634
Iter: 487 loss: 0.000420759461
Iter: 488 loss: 0.00041772009
Iter: 489 loss: 0.000417191535
Iter: 490 loss: 0.000415116257
Iter: 491 loss: 0.000411405286
Iter: 492 loss: 0.000440457748
Iter: 493 loss: 0.000411151676
Iter: 494 loss: 0.000408458756
Iter: 495 loss: 0.000421370671
Iter: 496 loss: 0.000407959567
Iter: 497 loss: 0.000405624567
Iter: 498 loss: 0.000422772689
Iter: 499 loss: 0.000405440835
Iter: 500 loss: 0.000403604325
Iter: 501 loss: 0.000405384053
Iter: 502 loss: 0.000402544916
Iter: 503 loss: 0.000400291756
Iter: 504 loss: 0.000401156896
Iter: 505 loss: 0.000398731441
Iter: 506 loss: 0.000396075979
Iter: 507 loss: 0.000407310436
Iter: 508 loss: 0.00039549754
Iter: 509 loss: 0.00039274653
Iter: 510 loss: 0.000395927462
Iter: 511 loss: 0.000391282927
Iter: 512 loss: 0.00038826745
Iter: 513 loss: 0.000394990726
Iter: 514 loss: 0.000387100794
Iter: 515 loss: 0.000384507875
Iter: 516 loss: 0.000398662873
Iter: 517 loss: 0.000384140119
Iter: 518 loss: 0.000381476595
Iter: 519 loss: 0.00038679241
Iter: 520 loss: 0.000380367157
Iter: 521 loss: 0.000377723685
Iter: 522 loss: 0.000376568816
Iter: 523 loss: 0.00037521316
Iter: 524 loss: 0.000371951028
Iter: 525 loss: 0.00040208851
Iter: 526 loss: 0.000371796923
Iter: 527 loss: 0.000369376736
Iter: 528 loss: 0.000380994345
Iter: 529 loss: 0.000368956593
Iter: 530 loss: 0.000366959895
Iter: 531 loss: 0.000381229445
Iter: 532 loss: 0.000366772525
Iter: 533 loss: 0.000365123036
Iter: 534 loss: 0.000367330445
Iter: 535 loss: 0.000364303036
Iter: 536 loss: 0.000362298422
Iter: 537 loss: 0.00036414605
Iter: 538 loss: 0.000361130049
Iter: 539 loss: 0.000358999881
Iter: 540 loss: 0.000366426917
Iter: 541 loss: 0.000358453632
Iter: 542 loss: 0.000356063
Iter: 543 loss: 0.000360901933
Iter: 544 loss: 0.00035508041
Iter: 545 loss: 0.000352913456
Iter: 546 loss: 0.000357207609
Iter: 547 loss: 0.000352030067
Iter: 548 loss: 0.000349953101
Iter: 549 loss: 0.000355983444
Iter: 550 loss: 0.00034929614
Iter: 551 loss: 0.000346995803
Iter: 552 loss: 0.0003553938
Iter: 553 loss: 0.000346434303
Iter: 554 loss: 0.000344548025
Iter: 555 loss: 0.000342791522
Iter: 556 loss: 0.000342344691
Iter: 557 loss: 0.000339603168
Iter: 558 loss: 0.000355558092
Iter: 559 loss: 0.000339251623
Iter: 560 loss: 0.000337059086
Iter: 561 loss: 0.000349681592
Iter: 562 loss: 0.000336753204
Iter: 563 loss: 0.00033513346
Iter: 564 loss: 0.00035118204
Iter: 565 loss: 0.000335084711
Iter: 566 loss: 0.000333854754
Iter: 567 loss: 0.000333523029
Iter: 568 loss: 0.000332757249
Iter: 569 loss: 0.000330855226
Iter: 570 loss: 0.000331353454
Iter: 571 loss: 0.00032947844
Iter: 572 loss: 0.000327411573
Iter: 573 loss: 0.000336937723
Iter: 574 loss: 0.000327009126
Iter: 575 loss: 0.000325063127
Iter: 576 loss: 0.000330143288
Iter: 577 loss: 0.000324407913
Iter: 578 loss: 0.00032245944
Iter: 579 loss: 0.000323532062
Iter: 580 loss: 0.000321173546
Iter: 581 loss: 0.000318684586
Iter: 582 loss: 0.000330632553
Iter: 583 loss: 0.000318249629
Iter: 584 loss: 0.00031596559
Iter: 585 loss: 0.000330385577
Iter: 586 loss: 0.000315693032
Iter: 587 loss: 0.000314079516
Iter: 588 loss: 0.000312216318
Iter: 589 loss: 0.00031199347
Iter: 590 loss: 0.00030936423
Iter: 591 loss: 0.000327366113
Iter: 592 loss: 0.000309097086
Iter: 593 loss: 0.000307027483
Iter: 594 loss: 0.00032108702
Iter: 595 loss: 0.000306833652
Iter: 596 loss: 0.000305444293
Iter: 597 loss: 0.000317914644
Iter: 598 loss: 0.00030537066
Iter: 599 loss: 0.000304165675
Iter: 600 loss: 0.000304958958
Iter: 601 loss: 0.000303409703
Iter: 602 loss: 0.00030177462
Iter: 603 loss: 0.000305041554
Iter: 604 loss: 0.000301099091
Iter: 605 loss: 0.0002995588
Iter: 606 loss: 0.000305432186
Iter: 607 loss: 0.00029920222
Iter: 608 loss: 0.000297679449
Iter: 609 loss: 0.000300507818
Iter: 610 loss: 0.000297022983
Iter: 611 loss: 0.000295559526
Iter: 612 loss: 0.000296152575
Iter: 613 loss: 0.000294553116
Iter: 614 loss: 0.000292595301
Iter: 615 loss: 0.000297861377
Iter: 616 loss: 0.000291937613
Iter: 617 loss: 0.000289986958
Iter: 618 loss: 0.000305218913
Iter: 619 loss: 0.000289856805
Iter: 620 loss: 0.000288558134
Iter: 621 loss: 0.000286596071
Iter: 622 loss: 0.00028655713
Iter: 623 loss: 0.000284364272
Iter: 624 loss: 0.00029288014
Iter: 625 loss: 0.000283862872
Iter: 626 loss: 0.000281784334
Iter: 627 loss: 0.000294674479
Iter: 628 loss: 0.000281526562
Iter: 629 loss: 0.000280147622
Iter: 630 loss: 0.000297341321
Iter: 631 loss: 0.000280137261
Iter: 632 loss: 0.00027906106
Iter: 633 loss: 0.000278660125
Iter: 634 loss: 0.00027806178
Iter: 635 loss: 0.000276609469
Iter: 636 loss: 0.000278812367
Iter: 637 loss: 0.000275924278
Iter: 638 loss: 0.000274627
Iter: 639 loss: 0.000276310224
Iter: 640 loss: 0.000273955811
Iter: 641 loss: 0.000272329315
Iter: 642 loss: 0.000276215258
Iter: 643 loss: 0.000271739787
Iter: 644 loss: 0.000269985641
Iter: 645 loss: 0.000272850506
Iter: 646 loss: 0.000269173877
Iter: 647 loss: 0.000267321535
Iter: 648 loss: 0.000274074089
Iter: 649 loss: 0.000266863208
Iter: 650 loss: 0.00026504026
Iter: 651 loss: 0.000278535765
Iter: 652 loss: 0.000264883449
Iter: 653 loss: 0.000263380643
Iter: 654 loss: 0.000261870737
Iter: 655 loss: 0.00026156989
Iter: 656 loss: 0.000259544759
Iter: 657 loss: 0.000273969024
Iter: 658 loss: 0.000259359775
Iter: 659 loss: 0.000257662381
Iter: 660 loss: 0.000263326
Iter: 661 loss: 0.000257204374
Iter: 662 loss: 0.000255677296
Iter: 663 loss: 0.000267578318
Iter: 664 loss: 0.000255556923
Iter: 665 loss: 0.000254201412
Iter: 666 loss: 0.000256406842
Iter: 667 loss: 0.000253582606
Iter: 668 loss: 0.000252269034
Iter: 669 loss: 0.000258252519
Iter: 670 loss: 0.000252011698
Iter: 671 loss: 0.000250908721
Iter: 672 loss: 0.000251842139
Iter: 673 loss: 0.000250261102
Iter: 674 loss: 0.000248734927
Iter: 675 loss: 0.00025289919
Iter: 676 loss: 0.000248230645
Iter: 677 loss: 0.000246929296
Iter: 678 loss: 0.000247873308
Iter: 679 loss: 0.000246129639
Iter: 680 loss: 0.000244577299
Iter: 681 loss: 0.000247941905
Iter: 682 loss: 0.000243967719
Iter: 683 loss: 0.000242350623
Iter: 684 loss: 0.000256659871
Iter: 685 loss: 0.000242275855
Iter: 686 loss: 0.000241068134
Iter: 687 loss: 0.000239858928
Iter: 688 loss: 0.00023961073
Iter: 689 loss: 0.000238047593
Iter: 690 loss: 0.000242196867
Iter: 691 loss: 0.000237523913
Iter: 692 loss: 0.000235843792
Iter: 693 loss: 0.000246208045
Iter: 694 loss: 0.000235635205
Iter: 695 loss: 0.000234481398
Iter: 696 loss: 0.000246872602
Iter: 697 loss: 0.000234457257
Iter: 698 loss: 0.000233497616
Iter: 699 loss: 0.000234019477
Iter: 700 loss: 0.000232863153
Iter: 701 loss: 0.000231865168
Iter: 702 loss: 0.000234217732
Iter: 703 loss: 0.000231503858
Iter: 704 loss: 0.000230563222
Iter: 705 loss: 0.000231511018
Iter: 706 loss: 0.000230031772
Iter: 707 loss: 0.000228869569
Iter: 708 loss: 0.00023155479
Iter: 709 loss: 0.000228438555
Iter: 710 loss: 0.000227157871
Iter: 711 loss: 0.000228017045
Iter: 712 loss: 0.000226348493
Iter: 713 loss: 0.000224712538
Iter: 714 loss: 0.000228558434
Iter: 715 loss: 0.000224117117
Iter: 716 loss: 0.000222573988
Iter: 717 loss: 0.000243067654
Iter: 718 loss: 0.000222562536
Iter: 719 loss: 0.000221413793
Iter: 720 loss: 0.000220468937
Iter: 721 loss: 0.000220136295
Iter: 722 loss: 0.000218599453
Iter: 723 loss: 0.000223040261
Iter: 724 loss: 0.000218115951
Iter: 725 loss: 0.000216667337
Iter: 726 loss: 0.000227462762
Iter: 727 loss: 0.000216556364
Iter: 728 loss: 0.000215549022
Iter: 729 loss: 0.000222529707
Iter: 730 loss: 0.000215447828
Iter: 731 loss: 0.000214465545
Iter: 732 loss: 0.000215721899
Iter: 733 loss: 0.000213963198
Iter: 734 loss: 0.000212986444
Iter: 735 loss: 0.00021751551
Iter: 736 loss: 0.000212797939
Iter: 737 loss: 0.000211958555
Iter: 738 loss: 0.000212611601
Iter: 739 loss: 0.000211450708
Iter: 740 loss: 0.000210321858
Iter: 741 loss: 0.000213623745
Iter: 742 loss: 0.000209969381
Iter: 743 loss: 0.000208871614
Iter: 744 loss: 0.00020870952
Iter: 745 loss: 0.000207943332
Iter: 746 loss: 0.000206392651
Iter: 747 loss: 0.000209998281
Iter: 748 loss: 0.000205809745
Iter: 749 loss: 0.000204582931
Iter: 750 loss: 0.000222457384
Iter: 751 loss: 0.00020458168
Iter: 752 loss: 0.000203676609
Iter: 753 loss: 0.00020280137
Iter: 754 loss: 0.000202600728
Iter: 755 loss: 0.000201359915
Iter: 756 loss: 0.000204603974
Iter: 757 loss: 0.000200940325
Iter: 758 loss: 0.000199753034
Iter: 759 loss: 0.000209083722
Iter: 760 loss: 0.000199663889
Iter: 761 loss: 0.000198807145
Iter: 762 loss: 0.000204661206
Iter: 763 loss: 0.000198727299
Iter: 764 loss: 0.000197892034
Iter: 765 loss: 0.000198833935
Iter: 766 loss: 0.000197437548
Iter: 767 loss: 0.000196661567
Iter: 768 loss: 0.00019867871
Iter: 769 loss: 0.000196399749
Iter: 770 loss: 0.000195628236
Iter: 771 loss: 0.000196808513
Iter: 772 loss: 0.000195261877
Iter: 773 loss: 0.000194359876
Iter: 774 loss: 0.000196507506
Iter: 775 loss: 0.000194033724
Iter: 776 loss: 0.000193040847
Iter: 777 loss: 0.000193962158
Iter: 778 loss: 0.000192466512
Iter: 779 loss: 0.000191378014
Iter: 780 loss: 0.000193864602
Iter: 781 loss: 0.000190975174
Iter: 782 loss: 0.000189992221
Iter: 783 loss: 0.000202259951
Iter: 784 loss: 0.000189980885
Iter: 785 loss: 0.000189133774
Iter: 786 loss: 0.000188704
Iter: 787 loss: 0.000188308448
Iter: 788 loss: 0.000187320577
Iter: 789 loss: 0.00018880979
Iter: 790 loss: 0.000186847145
Iter: 791 loss: 0.000185729674
Iter: 792 loss: 0.000192892185
Iter: 793 loss: 0.000185610581
Iter: 794 loss: 0.000184681907
Iter: 795 loss: 0.000190025617
Iter: 796 loss: 0.000184552307
Iter: 797 loss: 0.00018360914
Iter: 798 loss: 0.000186056073
Iter: 799 loss: 0.000183292243
Iter: 800 loss: 0.000182555683
Iter: 801 loss: 0.000185119367
Iter: 802 loss: 0.000182360294
Iter: 803 loss: 0.000181659198
Iter: 804 loss: 0.000182527321
Iter: 805 loss: 0.000181295909
Iter: 806 loss: 0.000180492163
Iter: 807 loss: 0.000182993113
Iter: 808 loss: 0.00018025536
Iter: 809 loss: 0.000179530412
Iter: 810 loss: 0.000179415714
Iter: 811 loss: 0.000178914735
Iter: 812 loss: 0.000177866023
Iter: 813 loss: 0.000179713534
Iter: 814 loss: 0.000177397975
Iter: 815 loss: 0.000176485817
Iter: 816 loss: 0.000189824088
Iter: 817 loss: 0.000176484857
Iter: 818 loss: 0.00017571947
Iter: 819 loss: 0.00017513278
Iter: 820 loss: 0.000174886023
Iter: 821 loss: 0.000173843699
Iter: 822 loss: 0.000175223104
Iter: 823 loss: 0.000173315304
Iter: 824 loss: 0.000172179905
Iter: 825 loss: 0.000181214898
Iter: 826 loss: 0.000172096989
Iter: 827 loss: 0.000171262102
Iter: 828 loss: 0.000176011279
Iter: 829 loss: 0.000171150226
Iter: 830 loss: 0.000170315514
Iter: 831 loss: 0.00017233711
Iter: 832 loss: 0.000170011524
Iter: 833 loss: 0.00016938927
Iter: 834 loss: 0.000170465748
Iter: 835 loss: 0.000169113657
Iter: 836 loss: 0.000168434519
Iter: 837 loss: 0.000169650739
Iter: 838 loss: 0.000168136481
Iter: 839 loss: 0.00016738128
Iter: 840 loss: 0.000169101288
Iter: 841 loss: 0.000167098464
Iter: 842 loss: 0.000166192985
Iter: 843 loss: 0.000167155522
Iter: 844 loss: 0.000165692356
Iter: 845 loss: 0.000164706798
Iter: 846 loss: 0.000166055484
Iter: 847 loss: 0.000164219528
Iter: 848 loss: 0.000163196673
Iter: 849 loss: 0.000173252512
Iter: 850 loss: 0.000163157136
Iter: 851 loss: 0.000162192853
Iter: 852 loss: 0.000162518438
Iter: 853 loss: 0.000161513395
Iter: 854 loss: 0.000160573778
Iter: 855 loss: 0.00016154084
Iter: 856 loss: 0.000160049298
Iter: 857 loss: 0.000159065297
Iter: 858 loss: 0.00016659
Iter: 859 loss: 0.000158994939
Iter: 860 loss: 0.00015822651
Iter: 861 loss: 0.000162725395
Iter: 862 loss: 0.000158123439
Iter: 863 loss: 0.000157398375
Iter: 864 loss: 0.000160147058
Iter: 865 loss: 0.00015722774
Iter: 866 loss: 0.000156680326
Iter: 867 loss: 0.000157595932
Iter: 868 loss: 0.000156431037
Iter: 869 loss: 0.000155766465
Iter: 870 loss: 0.000156976719
Iter: 871 loss: 0.000155480928
Iter: 872 loss: 0.000154783207
Iter: 873 loss: 0.000156573893
Iter: 874 loss: 0.000154540525
Iter: 875 loss: 0.000153846486
Iter: 876 loss: 0.000153547851
Iter: 877 loss: 0.000153191184
Iter: 878 loss: 0.000152123815
Iter: 879 loss: 0.000154048088
Iter: 880 loss: 0.000151655549
Iter: 881 loss: 0.000150769585
Iter: 882 loss: 0.000163416553
Iter: 883 loss: 0.000150768552
Iter: 884 loss: 0.000150005682
Iter: 885 loss: 0.000150359963
Iter: 886 loss: 0.000149486819
Iter: 887 loss: 0.000148753752
Iter: 888 loss: 0.00014883824
Iter: 889 loss: 0.000148191379
Iter: 890 loss: 0.000147318176
Iter: 891 loss: 0.000155590547
Iter: 892 loss: 0.000147280865
Iter: 893 loss: 0.000146687671
Iter: 894 loss: 0.000149418804
Iter: 895 loss: 0.000146577091
Iter: 896 loss: 0.000145972197
Iter: 897 loss: 0.000148153777
Iter: 898 loss: 0.000145816201
Iter: 899 loss: 0.000145373895
Iter: 900 loss: 0.000145563914
Iter: 901 loss: 0.000145072321
Iter: 902 loss: 0.000144439648
Iter: 903 loss: 0.000146162143
Iter: 904 loss: 0.000144229212
Iter: 905 loss: 0.000143599435
Iter: 906 loss: 0.000145205
Iter: 907 loss: 0.000143383309
Iter: 908 loss: 0.000142668636
Iter: 909 loss: 0.000143378653
Iter: 910 loss: 0.000142265184
Iter: 911 loss: 0.000141525263
Iter: 912 loss: 0.000142914505
Iter: 913 loss: 0.000141212018
Iter: 914 loss: 0.000140490985
Iter: 915 loss: 0.000146216451
Iter: 916 loss: 0.000140438875
Iter: 917 loss: 0.000139737182
Iter: 918 loss: 0.00014073975
Iter: 919 loss: 0.00013939527
Iter: 920 loss: 0.000138796371
Iter: 921 loss: 0.000139239826
Iter: 922 loss: 0.00013842815
Iter: 923 loss: 0.000137744224
Iter: 924 loss: 0.000141312717
Iter: 925 loss: 0.000137637588
Iter: 926 loss: 0.000137028866
Iter: 927 loss: 0.000140821328
Iter: 928 loss: 0.000136955554
Iter: 929 loss: 0.000136414848
Iter: 930 loss: 0.000139349606
Iter: 931 loss: 0.000136336894
Iter: 932 loss: 0.000135959039
Iter: 933 loss: 0.000136218558
Iter: 934 loss: 0.000135721755
Iter: 935 loss: 0.000135215058
Iter: 936 loss: 0.000135862429
Iter: 937 loss: 0.000134956237
Iter: 938 loss: 0.000134377842
Iter: 939 loss: 0.000136145391
Iter: 940 loss: 0.000134204747
Iter: 941 loss: 0.000133689537
Iter: 942 loss: 0.000134214933
Iter: 943 loss: 0.00013340154
Iter: 944 loss: 0.000132850138
Iter: 945 loss: 0.000133448513
Iter: 946 loss: 0.000132546949
Iter: 947 loss: 0.000131924986
Iter: 948 loss: 0.000136683273
Iter: 949 loss: 0.000131880312
Iter: 950 loss: 0.000131275156
Iter: 951 loss: 0.000132587273
Iter: 952 loss: 0.000131038352
Iter: 953 loss: 0.000130605331
Iter: 954 loss: 0.00013032899
Iter: 955 loss: 0.000130160159
Iter: 956 loss: 0.000129480686
Iter: 957 loss: 0.000134685921
Iter: 958 loss: 0.000129427935
Iter: 959 loss: 0.000128915475
Iter: 960 loss: 0.000131020875
Iter: 961 loss: 0.000128805492
Iter: 962 loss: 0.000128309694
Iter: 963 loss: 0.000130796572
Iter: 964 loss: 0.00012822471
Iter: 965 loss: 0.000127885884
Iter: 966 loss: 0.00012774409
Iter: 967 loss: 0.000127567851
Iter: 968 loss: 0.000126977582
Iter: 969 loss: 0.000129532433
Iter: 970 loss: 0.000126855157
Iter: 971 loss: 0.000126336614
Iter: 972 loss: 0.000128140571
Iter: 973 loss: 0.000126201849
Iter: 974 loss: 0.000125719089
Iter: 975 loss: 0.000125964463
Iter: 976 loss: 0.000125397069
Iter: 977 loss: 0.000124835657
Iter: 978 loss: 0.000125961378
Iter: 979 loss: 0.000124607555
Iter: 980 loss: 0.000124073747
Iter: 981 loss: 0.000128096115
Iter: 982 loss: 0.000124030368
Iter: 983 loss: 0.000123514707
Iter: 984 loss: 0.000124684186
Iter: 985 loss: 0.000123321777
Iter: 986 loss: 0.000122879341
Iter: 987 loss: 0.000122780242
Iter: 988 loss: 0.000122493555
Iter: 989 loss: 0.000121943667
Iter: 990 loss: 0.000125918916
Iter: 991 loss: 0.000121897108
Iter: 992 loss: 0.000121466728
Iter: 993 loss: 0.000124171624
Iter: 994 loss: 0.000121416022
Iter: 995 loss: 0.000121035082
Iter: 996 loss: 0.000123367063
Iter: 997 loss: 0.000120989942
Iter: 998 loss: 0.000120704863
Iter: 999 loss: 0.000120643017
Iter: 1000 loss: 0.000120456716
Iter: 1001 loss: 0.000120047393
Iter: 1002 loss: 0.000120995624
Iter: 1003 loss: 0.000119896366
Iter: 1004 loss: 0.000119495868
Iter: 1005 loss: 0.000120631033
Iter: 1006 loss: 0.000119367767
Iter: 1007 loss: 0.000118981108
Iter: 1008 loss: 0.000119261895
Iter: 1009 loss: 0.000118742391
Iter: 1010 loss: 0.000118304844
Iter: 1011 loss: 0.000119298056
Iter: 1012 loss: 0.000118139164
Iter: 1013 loss: 0.000117721465
Iter: 1014 loss: 0.000120123936
Iter: 1015 loss: 0.000117666197
Iter: 1016 loss: 0.000117230287
Iter: 1017 loss: 0.000118469252
Iter: 1018 loss: 0.000117091069
Iter: 1019 loss: 0.00011675623
Iter: 1020 loss: 0.00011654172
Iter: 1021 loss: 0.000116411495
Iter: 1022 loss: 0.000115986
Iter: 1023 loss: 0.000120831879
Iter: 1024 loss: 0.000115978342
Iter: 1025 loss: 0.000115685187
Iter: 1026 loss: 0.000116589188
Iter: 1027 loss: 0.000115599643
Iter: 1028 loss: 0.00011529497
Iter: 1029 loss: 0.000116908166
Iter: 1030 loss: 0.00011524748
Iter: 1031 loss: 0.000115033676
Iter: 1032 loss: 0.000114837436
Iter: 1033 loss: 0.000114785369
Iter: 1034 loss: 0.000114388182
Iter: 1035 loss: 0.000116897703
Iter: 1036 loss: 0.00011434286
Iter: 1037 loss: 0.000113996328
Iter: 1038 loss: 0.000115153394
Iter: 1039 loss: 0.000113902817
Iter: 1040 loss: 0.000113579481
Iter: 1041 loss: 0.000113693532
Iter: 1042 loss: 0.000113351976
Iter: 1043 loss: 0.000112977446
Iter: 1044 loss: 0.000113616145
Iter: 1045 loss: 0.000112810099
Iter: 1046 loss: 0.000112411682
Iter: 1047 loss: 0.000114606955
Iter: 1048 loss: 0.000112352165
Iter: 1049 loss: 0.000111930887
Iter: 1050 loss: 0.00011321911
Iter: 1051 loss: 0.000111806607
Iter: 1052 loss: 0.000111458037
Iter: 1053 loss: 0.000111328161
Iter: 1054 loss: 0.000111135625
Iter: 1055 loss: 0.000110740715
Iter: 1056 loss: 0.000113913571
Iter: 1057 loss: 0.000110714653
Iter: 1058 loss: 0.000110403023
Iter: 1059 loss: 0.000112342183
Iter: 1060 loss: 0.000110366069
Iter: 1061 loss: 0.000110088673
Iter: 1062 loss: 0.000111755842
Iter: 1063 loss: 0.000110054738
Iter: 1064 loss: 0.000109827735
Iter: 1065 loss: 0.000109658657
Iter: 1066 loss: 0.000109583125
Iter: 1067 loss: 0.000109242668
Iter: 1068 loss: 0.000110360503
Iter: 1069 loss: 0.000109148372
Iter: 1070 loss: 0.000108827473
Iter: 1071 loss: 0.000109744105
Iter: 1072 loss: 0.000108725173
Iter: 1073 loss: 0.00010840148
Iter: 1074 loss: 0.00010841871
Iter: 1075 loss: 0.000108147316
Iter: 1076 loss: 0.0001077138
Iter: 1077 loss: 0.000109013134
Iter: 1078 loss: 0.0001075818
Iter: 1079 loss: 0.000107190739
Iter: 1080 loss: 0.000108937966
Iter: 1081 loss: 0.000107115164
Iter: 1082 loss: 0.000106693638
Iter: 1083 loss: 0.00010833639
Iter: 1084 loss: 0.000106595289
Iter: 1085 loss: 0.000106275897
Iter: 1086 loss: 0.000105984385
Iter: 1087 loss: 0.000105906074
Iter: 1088 loss: 0.000105485444
Iter: 1089 loss: 0.000110354747
Iter: 1090 loss: 0.000105478553
Iter: 1091 loss: 0.000105198968
Iter: 1092 loss: 0.000106354251
Iter: 1093 loss: 0.000105138672
Iter: 1094 loss: 0.000104882354
Iter: 1095 loss: 0.000106493855
Iter: 1096 loss: 0.000104852195
Iter: 1097 loss: 0.000104662817
Iter: 1098 loss: 0.000104402046
Iter: 1099 loss: 0.000104390019
Iter: 1100 loss: 0.000103991108
Iter: 1101 loss: 0.000106364292
Iter: 1102 loss: 0.000103940278
Iter: 1103 loss: 0.000103572114
Iter: 1104 loss: 0.000104992359
Iter: 1105 loss: 0.0001034858
Iter: 1106 loss: 0.000103164479
Iter: 1107 loss: 0.000103310951
Iter: 1108 loss: 0.000102945982
Iter: 1109 loss: 0.000102589867
Iter: 1110 loss: 0.000103277132
Iter: 1111 loss: 0.000102441452
Iter: 1112 loss: 0.000102061502
Iter: 1113 loss: 0.000103730839
Iter: 1114 loss: 0.000101983031
Iter: 1115 loss: 0.000101583333
Iter: 1116 loss: 0.000103581886
Iter: 1117 loss: 0.000101516809
Iter: 1118 loss: 0.000101218931
Iter: 1119 loss: 0.000101065489
Iter: 1120 loss: 0.000100927144
Iter: 1121 loss: 0.000100588186
Iter: 1122 loss: 0.00010300547
Iter: 1123 loss: 0.000100558012
Iter: 1124 loss: 0.000100290388
Iter: 1125 loss: 0.000102239879
Iter: 1126 loss: 0.000100267309
Iter: 1127 loss: 0.000100050805
Iter: 1128 loss: 0.000101367099
Iter: 1129 loss: 0.00010002515
Iter: 1130 loss: 9.98355172e-05
Iter: 1131 loss: 9.95879891e-05
Iter: 1132 loss: 9.95722439e-05
Iter: 1133 loss: 9.92370769e-05
Iter: 1134 loss: 0.000100202844
Iter: 1135 loss: 9.91329871e-05
Iter: 1136 loss: 9.8793389e-05
Iter: 1137 loss: 0.00010014663
Iter: 1138 loss: 9.87158564e-05
Iter: 1139 loss: 9.84218714e-05
Iter: 1140 loss: 9.85554361e-05
Iter: 1141 loss: 9.82227648e-05
Iter: 1142 loss: 9.78758471e-05
Iter: 1143 loss: 9.89442196e-05
Iter: 1144 loss: 9.77729942e-05
Iter: 1145 loss: 9.74464419e-05
Iter: 1146 loss: 9.83818318e-05
Iter: 1147 loss: 9.7345066e-05
Iter: 1148 loss: 9.6981079e-05
Iter: 1149 loss: 9.91486e-05
Iter: 1150 loss: 9.69342e-05
Iter: 1151 loss: 9.66913e-05
Iter: 1152 loss: 9.64600258e-05
Iter: 1153 loss: 9.64050851e-05
Iter: 1154 loss: 9.60662e-05
Iter: 1155 loss: 9.92041605e-05
Iter: 1156 loss: 9.60521429e-05
Iter: 1157 loss: 9.57972079e-05
Iter: 1158 loss: 9.69845423e-05
Iter: 1159 loss: 9.57503071e-05
Iter: 1160 loss: 9.55233554e-05
Iter: 1161 loss: 9.68457316e-05
Iter: 1162 loss: 9.54926727e-05
Iter: 1163 loss: 9.53141862e-05
Iter: 1164 loss: 9.50451067e-05
Iter: 1165 loss: 9.50394606e-05
Iter: 1166 loss: 9.46616201e-05
Iter: 1167 loss: 9.72329944e-05
Iter: 1168 loss: 9.46237124e-05
Iter: 1169 loss: 9.42924e-05
Iter: 1170 loss: 9.56302611e-05
Iter: 1171 loss: 9.42192928e-05
Iter: 1172 loss: 9.39407037e-05
Iter: 1173 loss: 9.40224709e-05
Iter: 1174 loss: 9.3740251e-05
Iter: 1175 loss: 9.3440045e-05
Iter: 1176 loss: 9.40587852e-05
Iter: 1177 loss: 9.33198098e-05
Iter: 1178 loss: 9.29972084e-05
Iter: 1179 loss: 9.42960396e-05
Iter: 1180 loss: 9.29240196e-05
Iter: 1181 loss: 9.25916174e-05
Iter: 1182 loss: 9.45487627e-05
Iter: 1183 loss: 9.25492786e-05
Iter: 1184 loss: 9.2293616e-05
Iter: 1185 loss: 9.20551174e-05
Iter: 1186 loss: 9.1994727e-05
Iter: 1187 loss: 9.16493809e-05
Iter: 1188 loss: 9.34283e-05
Iter: 1189 loss: 9.15930723e-05
Iter: 1190 loss: 9.12993e-05
Iter: 1191 loss: 9.40857426e-05
Iter: 1192 loss: 9.12873656e-05
Iter: 1193 loss: 9.10669914e-05
Iter: 1194 loss: 9.22553882e-05
Iter: 1195 loss: 9.10342642e-05
Iter: 1196 loss: 9.08302463e-05
Iter: 1197 loss: 9.05969282e-05
Iter: 1198 loss: 9.05676134e-05
Iter: 1199 loss: 9.02490428e-05
Iter: 1200 loss: 9.11758107e-05
Iter: 1201 loss: 9.01505773e-05
Iter: 1202 loss: 8.9815192e-05
Iter: 1203 loss: 9.14611082e-05
Iter: 1204 loss: 8.97567224e-05
Iter: 1205 loss: 8.94806144e-05
Iter: 1206 loss: 8.95588673e-05
Iter: 1207 loss: 8.92818862e-05
Iter: 1208 loss: 8.89538933e-05
Iter: 1209 loss: 9.00115265e-05
Iter: 1210 loss: 8.88612267e-05
Iter: 1211 loss: 8.85426271e-05
Iter: 1212 loss: 8.91001764e-05
Iter: 1213 loss: 8.84031688e-05
Iter: 1214 loss: 8.80195221e-05
Iter: 1215 loss: 9.0897709e-05
Iter: 1216 loss: 8.79885411e-05
Iter: 1217 loss: 8.772414e-05
Iter: 1218 loss: 8.74180405e-05
Iter: 1219 loss: 8.73817771e-05
Iter: 1220 loss: 8.69756041e-05
Iter: 1221 loss: 8.98893486e-05
Iter: 1222 loss: 8.69404466e-05
Iter: 1223 loss: 8.6638e-05
Iter: 1224 loss: 8.91171803e-05
Iter: 1225 loss: 8.6619737e-05
Iter: 1226 loss: 8.64021058e-05
Iter: 1227 loss: 8.77607672e-05
Iter: 1228 loss: 8.63761888e-05
Iter: 1229 loss: 8.62048255e-05
Iter: 1230 loss: 8.59236752e-05
Iter: 1231 loss: 8.59223073e-05
Iter: 1232 loss: 8.55487742e-05
Iter: 1233 loss: 8.7801709e-05
Iter: 1234 loss: 8.55015387e-05
Iter: 1235 loss: 8.5168067e-05
Iter: 1236 loss: 8.69543583e-05
Iter: 1237 loss: 8.51180739e-05
Iter: 1238 loss: 8.48687196e-05
Iter: 1239 loss: 8.49113e-05
Iter: 1240 loss: 8.46809562e-05
Iter: 1241 loss: 8.4403684e-05
Iter: 1242 loss: 8.47360134e-05
Iter: 1243 loss: 8.4257772e-05
Iter: 1244 loss: 8.39066633e-05
Iter: 1245 loss: 8.51153163e-05
Iter: 1246 loss: 8.38120613e-05
Iter: 1247 loss: 8.34797538e-05
Iter: 1248 loss: 8.65841284e-05
Iter: 1249 loss: 8.34662205e-05
Iter: 1250 loss: 8.3236635e-05
Iter: 1251 loss: 8.29850542e-05
Iter: 1252 loss: 8.29474084e-05
Iter: 1253 loss: 8.26225223e-05
Iter: 1254 loss: 8.39932327e-05
Iter: 1255 loss: 8.25535681e-05
Iter: 1256 loss: 8.22907168e-05
Iter: 1257 loss: 8.56690385e-05
Iter: 1258 loss: 8.22883e-05
Iter: 1259 loss: 8.21038848e-05
Iter: 1260 loss: 8.30396093e-05
Iter: 1261 loss: 8.20742571e-05
Iter: 1262 loss: 8.18957487e-05
Iter: 1263 loss: 8.16485262e-05
Iter: 1264 loss: 8.16379179e-05
Iter: 1265 loss: 8.13516817e-05
Iter: 1266 loss: 8.2375278e-05
Iter: 1267 loss: 8.12786602e-05
Iter: 1268 loss: 8.10027705e-05
Iter: 1269 loss: 8.27363401e-05
Iter: 1270 loss: 8.09700869e-05
Iter: 1271 loss: 8.07466713e-05
Iter: 1272 loss: 8.07552278e-05
Iter: 1273 loss: 8.05704112e-05
Iter: 1274 loss: 8.02892755e-05
Iter: 1275 loss: 8.11088539e-05
Iter: 1276 loss: 8.02018476e-05
Iter: 1277 loss: 7.99341651e-05
Iter: 1278 loss: 8.05835953e-05
Iter: 1279 loss: 7.98390247e-05
Iter: 1280 loss: 7.95673623e-05
Iter: 1281 loss: 8.20005953e-05
Iter: 1282 loss: 7.95538945e-05
Iter: 1283 loss: 7.93563668e-05
Iter: 1284 loss: 7.91172642e-05
Iter: 1285 loss: 7.9093872e-05
Iter: 1286 loss: 7.87975732e-05
Iter: 1287 loss: 8.0498794e-05
Iter: 1288 loss: 7.87573954e-05
Iter: 1289 loss: 7.85180091e-05
Iter: 1290 loss: 8.04824886e-05
Iter: 1291 loss: 7.85033626e-05
Iter: 1292 loss: 7.83193e-05
Iter: 1293 loss: 7.94421212e-05
Iter: 1294 loss: 7.82964489e-05
Iter: 1295 loss: 7.8142868e-05
Iter: 1296 loss: 7.79033071e-05
Iter: 1297 loss: 7.79000111e-05
Iter: 1298 loss: 7.76095112e-05
Iter: 1299 loss: 7.94177176e-05
Iter: 1300 loss: 7.75749722e-05
Iter: 1301 loss: 7.73327411e-05
Iter: 1302 loss: 7.87902245e-05
Iter: 1303 loss: 7.73030624e-05
Iter: 1304 loss: 7.71130581e-05
Iter: 1305 loss: 7.71285195e-05
Iter: 1306 loss: 7.69652834e-05
Iter: 1307 loss: 7.67503e-05
Iter: 1308 loss: 7.69847829e-05
Iter: 1309 loss: 7.66330413e-05
Iter: 1310 loss: 7.63603894e-05
Iter: 1311 loss: 7.73343127e-05
Iter: 1312 loss: 7.62900236e-05
Iter: 1313 loss: 7.60561597e-05
Iter: 1314 loss: 7.85648153e-05
Iter: 1315 loss: 7.60508192e-05
Iter: 1316 loss: 7.58786045e-05
Iter: 1317 loss: 7.56619265e-05
Iter: 1318 loss: 7.56446098e-05
Iter: 1319 loss: 7.53825298e-05
Iter: 1320 loss: 7.61025149e-05
Iter: 1321 loss: 7.52971682e-05
Iter: 1322 loss: 7.5061289e-05
Iter: 1323 loss: 7.82163697e-05
Iter: 1324 loss: 7.5059892e-05
Iter: 1325 loss: 7.48954772e-05
Iter: 1326 loss: 7.58348906e-05
Iter: 1327 loss: 7.48735765e-05
Iter: 1328 loss: 7.47202794e-05
Iter: 1329 loss: 7.44886929e-05
Iter: 1330 loss: 7.44842619e-05
Iter: 1331 loss: 7.42299744e-05
Iter: 1332 loss: 7.52122869e-05
Iter: 1333 loss: 7.41705589e-05
Iter: 1334 loss: 7.39501484e-05
Iter: 1335 loss: 7.56886802e-05
Iter: 1336 loss: 7.39345705e-05
Iter: 1337 loss: 7.37613445e-05
Iter: 1338 loss: 7.3757481e-05
Iter: 1339 loss: 7.36215297e-05
Iter: 1340 loss: 7.33859051e-05
Iter: 1341 loss: 7.37102237e-05
Iter: 1342 loss: 7.32683e-05
Iter: 1343 loss: 7.29927124e-05
Iter: 1344 loss: 7.38977396e-05
Iter: 1345 loss: 7.29164894e-05
Iter: 1346 loss: 7.26996368e-05
Iter: 1347 loss: 7.54080393e-05
Iter: 1348 loss: 7.26973376e-05
Iter: 1349 loss: 7.25392165e-05
Iter: 1350 loss: 7.23293924e-05
Iter: 1351 loss: 7.2317067e-05
Iter: 1352 loss: 7.20546886e-05
Iter: 1353 loss: 7.31632827e-05
Iter: 1354 loss: 7.19993404e-05
Iter: 1355 loss: 7.17960284e-05
Iter: 1356 loss: 7.42695411e-05
Iter: 1357 loss: 7.17938674e-05
Iter: 1358 loss: 7.16520153e-05
Iter: 1359 loss: 7.25575519e-05
Iter: 1360 loss: 7.16362629e-05
Iter: 1361 loss: 7.15136412e-05
Iter: 1362 loss: 7.13233894e-05
Iter: 1363 loss: 7.13207846e-05
Iter: 1364 loss: 7.11034518e-05
Iter: 1365 loss: 7.23792182e-05
Iter: 1366 loss: 7.10746826e-05
Iter: 1367 loss: 7.0897222e-05
Iter: 1368 loss: 7.21308897e-05
Iter: 1369 loss: 7.08808366e-05
Iter: 1370 loss: 7.07389e-05
Iter: 1371 loss: 7.07399668e-05
Iter: 1372 loss: 7.0625465e-05
Iter: 1373 loss: 7.04509e-05
Iter: 1374 loss: 7.04928825e-05
Iter: 1375 loss: 7.03232217e-05
Iter: 1376 loss: 7.00821402e-05
Iter: 1377 loss: 7.1145434e-05
Iter: 1378 loss: 7.00333767e-05
Iter: 1379 loss: 6.98706208e-05
Iter: 1380 loss: 7.21166871e-05
Iter: 1381 loss: 6.98701406e-05
Iter: 1382 loss: 6.9747708e-05
Iter: 1383 loss: 6.96036586e-05
Iter: 1384 loss: 6.95879862e-05
Iter: 1385 loss: 6.93988914e-05
Iter: 1386 loss: 6.96509305e-05
Iter: 1387 loss: 6.93037582e-05
Iter: 1388 loss: 6.9126414e-05
Iter: 1389 loss: 6.91267924e-05
Iter: 1390 loss: 6.90117595e-05
Iter: 1391 loss: 6.9731861e-05
Iter: 1392 loss: 6.89987282e-05
Iter: 1393 loss: 6.88893488e-05
Iter: 1394 loss: 6.86954227e-05
Iter: 1395 loss: 6.86955755e-05
Iter: 1396 loss: 6.84873376e-05
Iter: 1397 loss: 6.9323316e-05
Iter: 1398 loss: 6.84404513e-05
Iter: 1399 loss: 6.82685204e-05
Iter: 1400 loss: 6.97487e-05
Iter: 1401 loss: 6.82588143e-05
Iter: 1402 loss: 6.81214151e-05
Iter: 1403 loss: 6.81532329e-05
Iter: 1404 loss: 6.80202793e-05
Iter: 1405 loss: 6.78422075e-05
Iter: 1406 loss: 6.79387158e-05
Iter: 1407 loss: 6.77250282e-05
Iter: 1408 loss: 6.74952535e-05
Iter: 1409 loss: 6.85344858e-05
Iter: 1410 loss: 6.74513212e-05
Iter: 1411 loss: 6.72991591e-05
Iter: 1412 loss: 6.91628957e-05
Iter: 1413 loss: 6.72972383e-05
Iter: 1414 loss: 6.71785674e-05
Iter: 1415 loss: 6.70261943e-05
Iter: 1416 loss: 6.7015375e-05
Iter: 1417 loss: 6.68085413e-05
Iter: 1418 loss: 6.73551112e-05
Iter: 1419 loss: 6.67387721e-05
Iter: 1420 loss: 6.65687694e-05
Iter: 1421 loss: 6.91068271e-05
Iter: 1422 loss: 6.65686675e-05
Iter: 1423 loss: 6.64514446e-05
Iter: 1424 loss: 6.71140879e-05
Iter: 1425 loss: 6.64347535e-05
Iter: 1426 loss: 6.63235624e-05
Iter: 1427 loss: 6.61560553e-05
Iter: 1428 loss: 6.61526574e-05
Iter: 1429 loss: 6.59705402e-05
Iter: 1430 loss: 6.70665249e-05
Iter: 1431 loss: 6.59476646e-05
Iter: 1432 loss: 6.5805827e-05
Iter: 1433 loss: 6.69684377e-05
Iter: 1434 loss: 6.57969e-05
Iter: 1435 loss: 6.56808334e-05
Iter: 1436 loss: 6.57014461e-05
Iter: 1437 loss: 6.55938784e-05
Iter: 1438 loss: 6.54545584e-05
Iter: 1439 loss: 6.54413379e-05
Iter: 1440 loss: 6.53389288e-05
Iter: 1441 loss: 6.51378723e-05
Iter: 1442 loss: 6.61686063e-05
Iter: 1443 loss: 6.51049777e-05
Iter: 1444 loss: 6.49697176e-05
Iter: 1445 loss: 6.65153275e-05
Iter: 1446 loss: 6.49673821e-05
Iter: 1447 loss: 6.48541e-05
Iter: 1448 loss: 6.47529232e-05
Iter: 1449 loss: 6.47239649e-05
Iter: 1450 loss: 6.45601e-05
Iter: 1451 loss: 6.46944827e-05
Iter: 1452 loss: 6.44620595e-05
Iter: 1453 loss: 6.43171079e-05
Iter: 1454 loss: 6.43146705e-05
Iter: 1455 loss: 6.42170198e-05
Iter: 1456 loss: 6.48214555e-05
Iter: 1457 loss: 6.42054656e-05
Iter: 1458 loss: 6.41137449e-05
Iter: 1459 loss: 6.39673162e-05
Iter: 1460 loss: 6.39660211e-05
Iter: 1461 loss: 6.38199926e-05
Iter: 1462 loss: 6.43103413e-05
Iter: 1463 loss: 6.3780295e-05
Iter: 1464 loss: 6.36505138e-05
Iter: 1465 loss: 6.46678e-05
Iter: 1466 loss: 6.36413606e-05
Iter: 1467 loss: 6.3524596e-05
Iter: 1468 loss: 6.35748947e-05
Iter: 1469 loss: 6.34451135e-05
Iter: 1470 loss: 6.32996e-05
Iter: 1471 loss: 6.3301879e-05
Iter: 1472 loss: 6.31834e-05
Iter: 1473 loss: 6.29855786e-05
Iter: 1474 loss: 6.40368817e-05
Iter: 1475 loss: 6.29558708e-05
Iter: 1476 loss: 6.28174676e-05
Iter: 1477 loss: 6.41361548e-05
Iter: 1478 loss: 6.28118214e-05
Iter: 1479 loss: 6.26916e-05
Iter: 1480 loss: 6.26062174e-05
Iter: 1481 loss: 6.25638786e-05
Iter: 1482 loss: 6.24032182e-05
Iter: 1483 loss: 6.26628171e-05
Iter: 1484 loss: 6.23288361e-05
Iter: 1485 loss: 6.22004154e-05
Iter: 1486 loss: 6.21998e-05
Iter: 1487 loss: 6.2108229e-05
Iter: 1488 loss: 6.26546826e-05
Iter: 1489 loss: 6.20964929e-05
Iter: 1490 loss: 6.20101564e-05
Iter: 1491 loss: 6.1896535e-05
Iter: 1492 loss: 6.18894046e-05
Iter: 1493 loss: 6.1762e-05
Iter: 1494 loss: 6.23093365e-05
Iter: 1495 loss: 6.1735278e-05
Iter: 1496 loss: 6.16241596e-05
Iter: 1497 loss: 6.23883388e-05
Iter: 1498 loss: 6.16136895e-05
Iter: 1499 loss: 6.15096505e-05
Iter: 1500 loss: 6.15698955e-05
Iter: 1501 loss: 6.14421224e-05
Iter: 1502 loss: 6.13275333e-05
Iter: 1503 loss: 6.13086158e-05
Iter: 1504 loss: 6.12298318e-05
Iter: 1505 loss: 6.10735951e-05
Iter: 1506 loss: 6.20009e-05
Iter: 1507 loss: 6.10534044e-05
Iter: 1508 loss: 6.09440467e-05
Iter: 1509 loss: 6.19282e-05
Iter: 1510 loss: 6.09389535e-05
Iter: 1511 loss: 6.08419941e-05
Iter: 1512 loss: 6.08207629e-05
Iter: 1513 loss: 6.07577167e-05
Iter: 1514 loss: 6.06494832e-05
Iter: 1515 loss: 6.07015572e-05
Iter: 1516 loss: 6.05765599e-05
Iter: 1517 loss: 6.04725574e-05
Iter: 1518 loss: 6.04725428e-05
Iter: 1519 loss: 6.03985391e-05
Iter: 1520 loss: 6.08772098e-05
Iter: 1521 loss: 6.03905428e-05
Iter: 1522 loss: 6.03221597e-05
Iter: 1523 loss: 6.02420623e-05
Iter: 1524 loss: 6.02329965e-05
Iter: 1525 loss: 6.01448373e-05
Iter: 1526 loss: 6.03238623e-05
Iter: 1527 loss: 6.01094143e-05
Iter: 1528 loss: 6.00145977e-05
Iter: 1529 loss: 6.06222202e-05
Iter: 1530 loss: 6.00042476e-05
Iter: 1531 loss: 5.99098312e-05
Iter: 1532 loss: 6.00363e-05
Iter: 1533 loss: 5.98622501e-05
Iter: 1534 loss: 5.97678045e-05
Iter: 1535 loss: 5.97668513e-05
Iter: 1536 loss: 5.96916179e-05
Iter: 1537 loss: 5.95711972e-05
Iter: 1538 loss: 6.02216169e-05
Iter: 1539 loss: 5.95536512e-05
Iter: 1540 loss: 5.94625271e-05
Iter: 1541 loss: 6.01255088e-05
Iter: 1542 loss: 5.94546691e-05
Iter: 1543 loss: 5.93658333e-05
Iter: 1544 loss: 5.93596487e-05
Iter: 1545 loss: 5.92931428e-05
Iter: 1546 loss: 5.91880089e-05
Iter: 1547 loss: 5.92565229e-05
Iter: 1548 loss: 5.91219214e-05
Iter: 1549 loss: 5.90297423e-05
Iter: 1550 loss: 5.90294731e-05
Iter: 1551 loss: 5.89618176e-05
Iter: 1552 loss: 5.94098965e-05
Iter: 1553 loss: 5.89544907e-05
Iter: 1554 loss: 5.88928488e-05
Iter: 1555 loss: 5.88238763e-05
Iter: 1556 loss: 5.88143484e-05
Iter: 1557 loss: 5.87283357e-05
Iter: 1558 loss: 5.89213e-05
Iter: 1559 loss: 5.8695834e-05
Iter: 1560 loss: 5.86078313e-05
Iter: 1561 loss: 5.91215939e-05
Iter: 1562 loss: 5.85964081e-05
Iter: 1563 loss: 5.85087364e-05
Iter: 1564 loss: 5.86582319e-05
Iter: 1565 loss: 5.84694681e-05
Iter: 1566 loss: 5.83870133e-05
Iter: 1567 loss: 5.83695546e-05
Iter: 1568 loss: 5.83152105e-05
Iter: 1569 loss: 5.82093526e-05
Iter: 1570 loss: 5.88848852e-05
Iter: 1571 loss: 5.81976383e-05
Iter: 1572 loss: 5.81172244e-05
Iter: 1573 loss: 5.86192327e-05
Iter: 1574 loss: 5.8108104e-05
Iter: 1575 loss: 5.80270062e-05
Iter: 1576 loss: 5.80463238e-05
Iter: 1577 loss: 5.7967598e-05
Iter: 1578 loss: 5.78836698e-05
Iter: 1579 loss: 5.78990657e-05
Iter: 1580 loss: 5.78207764e-05
Iter: 1581 loss: 5.77407045e-05
Iter: 1582 loss: 5.77407736e-05
Iter: 1583 loss: 5.7679641e-05
Iter: 1584 loss: 5.81334643e-05
Iter: 1585 loss: 5.76744824e-05
Iter: 1586 loss: 5.76210587e-05
Iter: 1587 loss: 5.75679478e-05
Iter: 1588 loss: 5.75568083e-05
Iter: 1589 loss: 5.7488367e-05
Iter: 1590 loss: 5.7561072e-05
Iter: 1591 loss: 5.74505975e-05
Iter: 1592 loss: 5.73678699e-05
Iter: 1593 loss: 5.79000916e-05
Iter: 1594 loss: 5.73585712e-05
Iter: 1595 loss: 5.72772333e-05
Iter: 1596 loss: 5.74580044e-05
Iter: 1597 loss: 5.72458375e-05
Iter: 1598 loss: 5.71737874e-05
Iter: 1599 loss: 5.71558412e-05
Iter: 1600 loss: 5.71102719e-05
Iter: 1601 loss: 5.70206284e-05
Iter: 1602 loss: 5.749501e-05
Iter: 1603 loss: 5.70065604e-05
Iter: 1604 loss: 5.69326112e-05
Iter: 1605 loss: 5.74153273e-05
Iter: 1606 loss: 5.69247932e-05
Iter: 1607 loss: 5.68519099e-05
Iter: 1608 loss: 5.68845717e-05
Iter: 1609 loss: 5.68023897e-05
Iter: 1610 loss: 5.6724708e-05
Iter: 1611 loss: 5.67190582e-05
Iter: 1612 loss: 5.66608287e-05
Iter: 1613 loss: 5.65755981e-05
Iter: 1614 loss: 5.76430975e-05
Iter: 1615 loss: 5.65745577e-05
Iter: 1616 loss: 5.65070368e-05
Iter: 1617 loss: 5.7155652e-05
Iter: 1618 loss: 5.65041591e-05
Iter: 1619 loss: 5.64494658e-05
Iter: 1620 loss: 5.64049915e-05
Iter: 1621 loss: 5.63887e-05
Iter: 1622 loss: 5.6318604e-05
Iter: 1623 loss: 5.63918147e-05
Iter: 1624 loss: 5.6279503e-05
Iter: 1625 loss: 5.61964407e-05
Iter: 1626 loss: 5.67080569e-05
Iter: 1627 loss: 5.61862907e-05
Iter: 1628 loss: 5.61031738e-05
Iter: 1629 loss: 5.63375143e-05
Iter: 1630 loss: 5.60768167e-05
Iter: 1631 loss: 5.60097615e-05
Iter: 1632 loss: 5.59909968e-05
Iter: 1633 loss: 5.59501714e-05
Iter: 1634 loss: 5.586935e-05
Iter: 1635 loss: 5.62852656e-05
Iter: 1636 loss: 5.58563406e-05
Iter: 1637 loss: 5.57855856e-05
Iter: 1638 loss: 5.61404449e-05
Iter: 1639 loss: 5.57737112e-05
Iter: 1640 loss: 5.56954728e-05
Iter: 1641 loss: 5.57595631e-05
Iter: 1642 loss: 5.56485174e-05
Iter: 1643 loss: 5.55724364e-05
Iter: 1644 loss: 5.55613442e-05
Iter: 1645 loss: 5.55081424e-05
Iter: 1646 loss: 5.54200342e-05
Iter: 1647 loss: 5.62393179e-05
Iter: 1648 loss: 5.54164508e-05
Iter: 1649 loss: 5.53458121e-05
Iter: 1650 loss: 5.61311172e-05
Iter: 1651 loss: 5.53446407e-05
Iter: 1652 loss: 5.5289478e-05
Iter: 1653 loss: 5.52586062e-05
Iter: 1654 loss: 5.52345082e-05
Iter: 1655 loss: 5.51752091e-05
Iter: 1656 loss: 5.51815647e-05
Iter: 1657 loss: 5.51294361e-05
Iter: 1658 loss: 5.50516634e-05
Iter: 1659 loss: 5.5507644e-05
Iter: 1660 loss: 5.50413133e-05
Iter: 1661 loss: 5.49640536e-05
Iter: 1662 loss: 5.5236731e-05
Iter: 1663 loss: 5.494383e-05
Iter: 1664 loss: 5.48796343e-05
Iter: 1665 loss: 5.48826902e-05
Iter: 1666 loss: 5.48290482e-05
Iter: 1667 loss: 5.47584386e-05
Iter: 1668 loss: 5.50645418e-05
Iter: 1669 loss: 5.47440432e-05
Iter: 1670 loss: 5.46762349e-05
Iter: 1671 loss: 5.50043042e-05
Iter: 1672 loss: 5.46640877e-05
Iter: 1673 loss: 5.45922521e-05
Iter: 1674 loss: 5.46939373e-05
Iter: 1675 loss: 5.45568437e-05
Iter: 1676 loss: 5.44912218e-05
Iter: 1677 loss: 5.44973955e-05
Iter: 1678 loss: 5.44404429e-05
Iter: 1679 loss: 5.43702481e-05
Iter: 1680 loss: 5.48749413e-05
Iter: 1681 loss: 5.43641145e-05
Iter: 1682 loss: 5.43075257e-05
Iter: 1683 loss: 5.50898767e-05
Iter: 1684 loss: 5.43072892e-05
Iter: 1685 loss: 5.42627713e-05
Iter: 1686 loss: 5.42472662e-05
Iter: 1687 loss: 5.42217022e-05
Iter: 1688 loss: 5.41705e-05
Iter: 1689 loss: 5.41515292e-05
Iter: 1690 loss: 5.41229274e-05
Iter: 1691 loss: 5.40520959e-05
Iter: 1692 loss: 5.46118863e-05
Iter: 1693 loss: 5.40472647e-05
Iter: 1694 loss: 5.39845e-05
Iter: 1695 loss: 5.41834e-05
Iter: 1696 loss: 5.39663e-05
Iter: 1697 loss: 5.39095417e-05
Iter: 1698 loss: 5.38873683e-05
Iter: 1699 loss: 5.38564054e-05
Iter: 1700 loss: 5.37854503e-05
Iter: 1701 loss: 5.40796573e-05
Iter: 1702 loss: 5.37702435e-05
Iter: 1703 loss: 5.37078049e-05
Iter: 1704 loss: 5.41417539e-05
Iter: 1705 loss: 5.37018568e-05
Iter: 1706 loss: 5.3644304e-05
Iter: 1707 loss: 5.37378291e-05
Iter: 1708 loss: 5.36177577e-05
Iter: 1709 loss: 5.35608597e-05
Iter: 1710 loss: 5.35282488e-05
Iter: 1711 loss: 5.3503838e-05
Iter: 1712 loss: 5.34306164e-05
Iter: 1713 loss: 5.38869717e-05
Iter: 1714 loss: 5.34220708e-05
Iter: 1715 loss: 5.33688835e-05
Iter: 1716 loss: 5.3368738e-05
Iter: 1717 loss: 5.33281964e-05
Iter: 1718 loss: 5.33055536e-05
Iter: 1719 loss: 5.32875165e-05
Iter: 1720 loss: 5.32334452e-05
Iter: 1721 loss: 5.31776423e-05
Iter: 1722 loss: 5.31673722e-05
Iter: 1723 loss: 5.30929792e-05
Iter: 1724 loss: 5.3963995e-05
Iter: 1725 loss: 5.30919533e-05
Iter: 1726 loss: 5.30349971e-05
Iter: 1727 loss: 5.32368576e-05
Iter: 1728 loss: 5.30203797e-05
Iter: 1729 loss: 5.29664903e-05
Iter: 1730 loss: 5.29564059e-05
Iter: 1731 loss: 5.29201752e-05
Iter: 1732 loss: 5.28522396e-05
Iter: 1733 loss: 5.30722282e-05
Iter: 1734 loss: 5.28332239e-05
Iter: 1735 loss: 5.27720149e-05
Iter: 1736 loss: 5.33088678e-05
Iter: 1737 loss: 5.27690281e-05
Iter: 1738 loss: 5.27169395e-05
Iter: 1739 loss: 5.280388e-05
Iter: 1740 loss: 5.26937438e-05
Iter: 1741 loss: 5.26372532e-05
Iter: 1742 loss: 5.25923278e-05
Iter: 1743 loss: 5.25751311e-05
Iter: 1744 loss: 5.24958741e-05
Iter: 1745 loss: 5.28735691e-05
Iter: 1746 loss: 5.24815332e-05
Iter: 1747 loss: 5.2437048e-05
Iter: 1748 loss: 5.24314091e-05
Iter: 1749 loss: 5.23937379e-05
Iter: 1750 loss: 5.23855633e-05
Iter: 1751 loss: 5.23610724e-05
Iter: 1752 loss: 5.23123817e-05
Iter: 1753 loss: 5.22598493e-05
Iter: 1754 loss: 5.22515438e-05
Iter: 1755 loss: 5.21925504e-05
Iter: 1756 loss: 5.30782963e-05
Iter: 1757 loss: 5.21926522e-05
Iter: 1758 loss: 5.21498623e-05
Iter: 1759 loss: 5.22646369e-05
Iter: 1760 loss: 5.21357797e-05
Iter: 1761 loss: 5.20929207e-05
Iter: 1762 loss: 5.20689173e-05
Iter: 1763 loss: 5.20499452e-05
Iter: 1764 loss: 5.19876339e-05
Iter: 1765 loss: 5.21101101e-05
Iter: 1766 loss: 5.1962088e-05
Iter: 1767 loss: 5.19013847e-05
Iter: 1768 loss: 5.25034338e-05
Iter: 1769 loss: 5.18993402e-05
Iter: 1770 loss: 5.18477245e-05
Iter: 1771 loss: 5.19287787e-05
Iter: 1772 loss: 5.18234592e-05
Iter: 1773 loss: 5.17676199e-05
Iter: 1774 loss: 5.17331464e-05
Iter: 1775 loss: 5.17104854e-05
Iter: 1776 loss: 5.16380605e-05
Iter: 1777 loss: 5.188863e-05
Iter: 1778 loss: 5.16188957e-05
Iter: 1779 loss: 5.15796492e-05
Iter: 1780 loss: 5.15742722e-05
Iter: 1781 loss: 5.15390602e-05
Iter: 1782 loss: 5.15354404e-05
Iter: 1783 loss: 5.15098218e-05
Iter: 1784 loss: 5.14674539e-05
Iter: 1785 loss: 5.14240783e-05
Iter: 1786 loss: 5.14158492e-05
Iter: 1787 loss: 5.13644809e-05
Iter: 1788 loss: 5.19802379e-05
Iter: 1789 loss: 5.13640043e-05
Iter: 1790 loss: 5.13195264e-05
Iter: 1791 loss: 5.14046624e-05
Iter: 1792 loss: 5.13011837e-05
Iter: 1793 loss: 5.12476836e-05
Iter: 1794 loss: 5.12614679e-05
Iter: 1795 loss: 5.12089609e-05
Iter: 1796 loss: 5.11486724e-05
Iter: 1797 loss: 5.12653096e-05
Iter: 1798 loss: 5.11234502e-05
Iter: 1799 loss: 5.10630125e-05
Iter: 1800 loss: 5.16130349e-05
Iter: 1801 loss: 5.10600839e-05
Iter: 1802 loss: 5.10075843e-05
Iter: 1803 loss: 5.11125581e-05
Iter: 1804 loss: 5.09863021e-05
Iter: 1805 loss: 5.09339879e-05
Iter: 1806 loss: 5.09549645e-05
Iter: 1807 loss: 5.08977973e-05
Iter: 1808 loss: 5.08446028e-05
Iter: 1809 loss: 5.09284582e-05
Iter: 1810 loss: 5.08199446e-05
Iter: 1811 loss: 5.07878722e-05
Iter: 1812 loss: 5.07811274e-05
Iter: 1813 loss: 5.07472796e-05
Iter: 1814 loss: 5.07573204e-05
Iter: 1815 loss: 5.07230034e-05
Iter: 1816 loss: 5.06835859e-05
Iter: 1817 loss: 5.06427386e-05
Iter: 1818 loss: 5.06353463e-05
Iter: 1819 loss: 5.05823919e-05
Iter: 1820 loss: 5.10236969e-05
Iter: 1821 loss: 5.05791832e-05
Iter: 1822 loss: 5.05294738e-05
Iter: 1823 loss: 5.06183096e-05
Iter: 1824 loss: 5.05074713e-05
Iter: 1825 loss: 5.04510353e-05
Iter: 1826 loss: 5.05126372e-05
Iter: 1827 loss: 5.04202981e-05
Iter: 1828 loss: 5.03693591e-05
Iter: 1829 loss: 5.04291529e-05
Iter: 1830 loss: 5.03419906e-05
Iter: 1831 loss: 5.02884468e-05
Iter: 1832 loss: 5.07652949e-05
Iter: 1833 loss: 5.02856565e-05
Iter: 1834 loss: 5.02382427e-05
Iter: 1835 loss: 5.03503688e-05
Iter: 1836 loss: 5.02207258e-05
Iter: 1837 loss: 5.01750692e-05
Iter: 1838 loss: 5.01849172e-05
Iter: 1839 loss: 5.01411851e-05
Iter: 1840 loss: 5.0086288e-05
Iter: 1841 loss: 5.01109316e-05
Iter: 1842 loss: 5.00490278e-05
Iter: 1843 loss: 5.00137467e-05
Iter: 1844 loss: 5.00052083e-05
Iter: 1845 loss: 4.99657253e-05
Iter: 1846 loss: 4.99846064e-05
Iter: 1847 loss: 4.99391026e-05
Iter: 1848 loss: 4.98957888e-05
Iter: 1849 loss: 4.98429436e-05
Iter: 1850 loss: 4.98380905e-05
Iter: 1851 loss: 4.97748842e-05
Iter: 1852 loss: 5.02023904e-05
Iter: 1853 loss: 4.97684705e-05
Iter: 1854 loss: 4.97083856e-05
Iter: 1855 loss: 4.9898732e-05
Iter: 1856 loss: 4.96910943e-05
Iter: 1857 loss: 4.9634491e-05
Iter: 1858 loss: 4.97387882e-05
Iter: 1859 loss: 4.96101857e-05
Iter: 1860 loss: 4.95603235e-05
Iter: 1861 loss: 4.95924542e-05
Iter: 1862 loss: 4.95286513e-05
Iter: 1863 loss: 4.94724227e-05
Iter: 1864 loss: 4.99487905e-05
Iter: 1865 loss: 4.94694577e-05
Iter: 1866 loss: 4.94204942e-05
Iter: 1867 loss: 4.95358108e-05
Iter: 1868 loss: 4.940289e-05
Iter: 1869 loss: 4.93534499e-05
Iter: 1870 loss: 4.93552143e-05
Iter: 1871 loss: 4.93144253e-05
Iter: 1872 loss: 4.92523868e-05
Iter: 1873 loss: 4.93166954e-05
Iter: 1874 loss: 4.92177933e-05
Iter: 1875 loss: 4.91888677e-05
Iter: 1876 loss: 4.91784958e-05
Iter: 1877 loss: 4.91423561e-05
Iter: 1878 loss: 4.91804785e-05
Iter: 1879 loss: 4.91221217e-05
Iter: 1880 loss: 4.90849307e-05
Iter: 1881 loss: 4.9041726e-05
Iter: 1882 loss: 4.90366874e-05
Iter: 1883 loss: 4.89829981e-05
Iter: 1884 loss: 4.92695326e-05
Iter: 1885 loss: 4.89751037e-05
Iter: 1886 loss: 4.89218874e-05
Iter: 1887 loss: 4.91423743e-05
Iter: 1888 loss: 4.89100785e-05
Iter: 1889 loss: 4.88656515e-05
Iter: 1890 loss: 4.89382437e-05
Iter: 1891 loss: 4.88450023e-05
Iter: 1892 loss: 4.88026781e-05
Iter: 1893 loss: 4.8814094e-05
Iter: 1894 loss: 4.87719153e-05
Iter: 1895 loss: 4.87222169e-05
Iter: 1896 loss: 4.91517894e-05
Iter: 1897 loss: 4.87195612e-05
Iter: 1898 loss: 4.86746649e-05
Iter: 1899 loss: 4.88067926e-05
Iter: 1900 loss: 4.86607096e-05
Iter: 1901 loss: 4.86186691e-05
Iter: 1902 loss: 4.86263e-05
Iter: 1903 loss: 4.85869095e-05
Iter: 1904 loss: 4.85346281e-05
Iter: 1905 loss: 4.85704622e-05
Iter: 1906 loss: 4.85021e-05
Iter: 1907 loss: 4.84722259e-05
Iter: 1908 loss: 4.84663178e-05
Iter: 1909 loss: 4.84321536e-05
Iter: 1910 loss: 4.84942284e-05
Iter: 1911 loss: 4.84170814e-05
Iter: 1912 loss: 4.83857439e-05
Iter: 1913 loss: 4.83477634e-05
Iter: 1914 loss: 4.83440599e-05
Iter: 1915 loss: 4.82941832e-05
Iter: 1916 loss: 4.84454795e-05
Iter: 1917 loss: 4.82792311e-05
Iter: 1918 loss: 4.82220785e-05
Iter: 1919 loss: 4.85413439e-05
Iter: 1920 loss: 4.82138348e-05
Iter: 1921 loss: 4.8171536e-05
Iter: 1922 loss: 4.82433315e-05
Iter: 1923 loss: 4.81522657e-05
Iter: 1924 loss: 4.81104653e-05
Iter: 1925 loss: 4.81168972e-05
Iter: 1926 loss: 4.80787348e-05
Iter: 1927 loss: 4.80269882e-05
Iter: 1928 loss: 4.84171906e-05
Iter: 1929 loss: 4.80229137e-05
Iter: 1930 loss: 4.79746304e-05
Iter: 1931 loss: 4.81351817e-05
Iter: 1932 loss: 4.79615519e-05
Iter: 1933 loss: 4.79185474e-05
Iter: 1934 loss: 4.79202936e-05
Iter: 1935 loss: 4.78847251e-05
Iter: 1936 loss: 4.78296097e-05
Iter: 1937 loss: 4.78703e-05
Iter: 1938 loss: 4.7795751e-05
Iter: 1939 loss: 4.77576468e-05
Iter: 1940 loss: 4.77554931e-05
Iter: 1941 loss: 4.77156245e-05
Iter: 1942 loss: 4.78305883e-05
Iter: 1943 loss: 4.77031354e-05
Iter: 1944 loss: 4.76717141e-05
Iter: 1945 loss: 4.76337045e-05
Iter: 1946 loss: 4.76298446e-05
Iter: 1947 loss: 4.75793713e-05
Iter: 1948 loss: 4.76608038e-05
Iter: 1949 loss: 4.75562301e-05
Iter: 1950 loss: 4.74987137e-05
Iter: 1951 loss: 4.8023714e-05
Iter: 1952 loss: 4.74962799e-05
Iter: 1953 loss: 4.74577719e-05
Iter: 1954 loss: 4.74963381e-05
Iter: 1955 loss: 4.74361223e-05
Iter: 1956 loss: 4.73915279e-05
Iter: 1957 loss: 4.74215e-05
Iter: 1958 loss: 4.73638502e-05
Iter: 1959 loss: 4.73151231e-05
Iter: 1960 loss: 4.75985617e-05
Iter: 1961 loss: 4.73087566e-05
Iter: 1962 loss: 4.72613974e-05
Iter: 1963 loss: 4.74627377e-05
Iter: 1964 loss: 4.7251604e-05
Iter: 1965 loss: 4.72119791e-05
Iter: 1966 loss: 4.72139072e-05
Iter: 1967 loss: 4.71809253e-05
Iter: 1968 loss: 4.71313033e-05
Iter: 1969 loss: 4.71845051e-05
Iter: 1970 loss: 4.71039675e-05
Iter: 1971 loss: 4.70640189e-05
Iter: 1972 loss: 4.76672576e-05
Iter: 1973 loss: 4.70642262e-05
Iter: 1974 loss: 4.70236882e-05
Iter: 1975 loss: 4.7205649e-05
Iter: 1976 loss: 4.70156629e-05
Iter: 1977 loss: 4.69867482e-05
Iter: 1978 loss: 4.69588776e-05
Iter: 1979 loss: 4.69524748e-05
Iter: 1980 loss: 4.69111474e-05
Iter: 1981 loss: 4.69625484e-05
Iter: 1982 loss: 4.68895e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4
+ date
Tue Oct 27 16:07:39 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b8a184620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b8a197730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b483d81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b8a14a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b8a14a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b483ec950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b483928c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b48376400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b20118f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b4835e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b200d20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b200fbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b20096a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b200bb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b200bc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b2000fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b2002fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b200bb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b00443d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b2002f400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b003afea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b003af268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b003af0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b003279d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b00327d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b00327950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b002eeae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b00290c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b002b9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b002581e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b00251620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b0021d2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b0022a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b001cfae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b002062f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2b001a5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.31313464
Iter: 2 loss: 7605.69385
Iter: 3 loss: 0.312981427
Iter: 4 loss: 2330.7207
Iter: 5 loss: 0.312765718
Iter: 6 loss: 4167.29443
Iter: 7 loss: 0.312744141
Iter: 8 loss: 3389.02222
Iter: 9 loss: 0.311205566
Iter: 10 loss: 1608.69067
Iter: 11 loss: 935.297302
Iter: 12 loss: 0.311199784
Iter: 13 loss: 304.725769
Iter: 14 loss: 0.31119594
Iter: 15 loss: 287.614227
Iter: 16 loss: 174.703491
Iter: 17 loss: 0.311185896
Iter: 18 loss: 150.559952
Iter: 19 loss: 0.271776676
Iter: 20 loss: 0.257219642
Iter: 21 loss: 0.260076702
Iter: 22 loss: 1.28901887
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8
+ date
Tue Oct 27 16:08:25 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd1a6682f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd1a678840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcd1a6b8268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4559730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4559488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf455e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf44887b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf44bf488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf44bf620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf44bf378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4469378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4429d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4403f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4403598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4417a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf434de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf435dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf43a7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf42c6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf435dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf42b9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf42b9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf42b9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4228510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4228bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf42286a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf41eeae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf41eeb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf41b7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4152268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf41b77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf41b7730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4126620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4152158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf4100378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fccf40abf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.114650562
Iter: 2 loss: 2.12136793
Iter: 3 loss: 2.05567074
Iter: 4 loss: 1.28950822
Iter: 5 loss: 1.27327073
Iter: 6 loss: 0.917621076
Iter: 7 loss: 0.905283809
Iter: 8 loss: 0.661337495
Iter: 9 loss: 0.647306144
Iter: 10 loss: 0.4627918
Iter: 11 loss: 0.446656615
Iter: 12 loss: 0.316592306
Iter: 13 loss: 0.301420599
Iter: 14 loss: 0.218818933
Iter: 15 loss: 0.206458822
Iter: 16 loss: 0.158760384
Iter: 17 loss: 0.150556207
Iter: 18 loss: 0.127150834
Iter: 19 loss: 0.123247355
Iter: 20 loss: 0.113432854
Iter: 21 loss: 0.111952543
Iter: 22 loss: 0.109652355
Iter: 23 loss: 0.10567072
Iter: 24 loss: 303.476898
Iter: 25 loss: 0.105670735
Iter: 26 loss: 0.108352982
Iter: 27 loss: 0.105323538
Iter: 28 loss: 0.104503855
Iter: 29 loss: 0.104505062
Iter: 30 loss: 0.0946961939
Iter: 31 loss: 961.00177
Iter: 32 loss: 0.0946943611
Iter: 33 loss: 0.171914116
Iter: 34 loss: 0.0946603864
Iter: 35 loss: 0.0945280343
Iter: 36 loss: 0.0922274441
Iter: 37 loss: 0.0891614333
Iter: 38 loss: 0.0891482234
Iter: 39 loss: 0.0872492939
Iter: 40 loss: 0.0873214
Iter: 41 loss: 0.0863492116
Iter: 42 loss: 0.0848589689
Iter: 43 loss: 0.08483015
Iter: 44 loss: 0.0833178163
Iter: 45 loss: 0.0793106109
Iter: 46 loss: 4140.2627
Iter: 47 loss: 0.0793106
Iter: 48 loss: 0.0774071366
Iter: 49 loss: 0.0742680207
Iter: 50 loss: 0.0712410212
Iter: 51 loss: 0.0869418085
Iter: 52 loss: 0.0706501827
Iter: 53 loss: 0.0671910495
Iter: 54 loss: 0.0701976
Iter: 55 loss: 0.0654837415
Iter: 56 loss: 0.0614246354
Iter: 57 loss: 0.0911289901
Iter: 58 loss: 0.0611208305
Iter: 59 loss: 0.0579242222
Iter: 60 loss: 0.271588624
Iter: 61 loss: 0.0579224266
Iter: 62 loss: 0.0557938032
Iter: 63 loss: 0.0613902323
Iter: 64 loss: 0.05515562
Iter: 65 loss: 0.0560655631
Iter: 66 loss: 0.0541702211
Iter: 67 loss: 0.0517209731
Iter: 68 loss: 0.0828808919
Iter: 69 loss: 0.0516951308
Iter: 70 loss: 0.0506442785
Iter: 71 loss: 0.0505133197
Iter: 72 loss: 0.0483930558
Iter: 73 loss: 0.0548003092
Iter: 74 loss: 0.048137594
Iter: 75 loss: 0.0462034084
Iter: 76 loss: 0.0610497221
Iter: 77 loss: 0.0460218117
Iter: 78 loss: 0.0439226925
Iter: 79 loss: 0.128149122
Iter: 80 loss: 0.043922
Iter: 81 loss: 0.0426537
Iter: 82 loss: 0.0416427329
Iter: 83 loss: 0.0413985215
Iter: 84 loss: 0.0396426693
Iter: 85 loss: 0.159454837
Iter: 86 loss: 0.0396264493
Iter: 87 loss: 0.0381781347
Iter: 88 loss: 0.0571296178
Iter: 89 loss: 0.0381711796
Iter: 90 loss: 0.0373029187
Iter: 91 loss: 0.0382442586
Iter: 92 loss: 0.0371086821
Iter: 93 loss: 0.0363074914
Iter: 94 loss: 0.0651963726
Iter: 95 loss: 0.0362854376
Iter: 96 loss: 0.03564661
Iter: 97 loss: 0.100299299
Iter: 98 loss: 0.0356457196
Iter: 99 loss: 0.0349008068
Iter: 100 loss: 0.0362211615
Iter: 101 loss: 0.0345371664
Iter: 102 loss: 0.0332279205
Iter: 103 loss: 0.0384584591
Iter: 104 loss: 0.0329127684
Iter: 105 loss: 0.0320655666
Iter: 106 loss: 0.0351175517
Iter: 107 loss: 0.0318647772
Iter: 108 loss: 0.0309557132
Iter: 109 loss: 0.0340039246
Iter: 110 loss: 0.0306592528
Iter: 111 loss: 0.0296816751
Iter: 112 loss: 0.0306366123
Iter: 113 loss: 0.0291564316
Iter: 114 loss: 0.0278216079
Iter: 115 loss: 0.0568569191
Iter: 116 loss: 0.0277928077
Iter: 117 loss: 0.0267617255
Iter: 118 loss: 0.0388398431
Iter: 119 loss: 0.026736727
Iter: 120 loss: 0.0258024372
Iter: 121 loss: 0.0312330462
Iter: 122 loss: 0.0256934296
Iter: 123 loss: 0.0249221846
Iter: 124 loss: 0.026835151
Iter: 125 loss: 0.0245886035
Iter: 126 loss: 0.0241264403
Iter: 127 loss: 0.024168903
Iter: 128 loss: 0.0237370189
Iter: 129 loss: 0.0234760586
Iter: 130 loss: 0.0233976245
Iter: 131 loss: 0.023006985
Iter: 132 loss: 0.0255084895
Iter: 133 loss: 0.0229328796
Iter: 134 loss: 0.0226293206
Iter: 135 loss: 0.0230728127
Iter: 136 loss: 0.0224676728
Iter: 137 loss: 0.0220587552
Iter: 138 loss: 0.0223895051
Iter: 139 loss: 0.0218284447
Iter: 140 loss: 0.0214559156
Iter: 141 loss: 0.0219506659
Iter: 142 loss: 0.0212356821
Iter: 143 loss: 0.0208068527
Iter: 144 loss: 0.0211336799
Iter: 145 loss: 0.0205200091
Iter: 146 loss: 0.0198165122
Iter: 147 loss: 0.0211311094
Iter: 148 loss: 0.0195220467
Iter: 149 loss: 0.0188913643
Iter: 150 loss: 0.024183372
Iter: 151 loss: 0.0188378915
Iter: 152 loss: 0.0183105599
Iter: 153 loss: 0.0200812947
Iter: 154 loss: 0.0181796309
Iter: 155 loss: 0.0177820604
Iter: 156 loss: 0.0204601791
Iter: 157 loss: 0.01774057
Iter: 158 loss: 0.017318828
Iter: 159 loss: 0.0172931105
Iter: 160 loss: 0.0170364454
Iter: 161 loss: 0.0174106937
Iter: 162 loss: 0.0169263054
Iter: 163 loss: 0.0166827478
Iter: 164 loss: 0.0188275073
Iter: 165 loss: 0.0166586787
Iter: 166 loss: 0.0165076051
Iter: 167 loss: 0.016649181
Iter: 168 loss: 0.0164237097
Iter: 169 loss: 0.0161525905
Iter: 170 loss: 0.0196579192
Iter: 171 loss: 0.0161424149
Iter: 172 loss: 0.0158501882
Iter: 173 loss: 0.0172491893
Iter: 174 loss: 0.0158142671
Iter: 175 loss: 0.0156437363
Iter: 176 loss: 0.0154170664
Iter: 177 loss: 0.0154029047
Iter: 178 loss: 0.015092981
Iter: 179 loss: 0.0148643982
Iter: 180 loss: 0.0147645986
Iter: 181 loss: 0.0143343015
Iter: 182 loss: 0.0181793608
Iter: 183 loss: 0.0143010337
Iter: 184 loss: 0.0139138177
Iter: 185 loss: 0.0164791085
Iter: 186 loss: 0.0138657121
Iter: 187 loss: 0.0136603303
Iter: 188 loss: 0.0159477368
Iter: 189 loss: 0.0136558153
Iter: 190 loss: 0.0134729072
Iter: 191 loss: 0.0134660546
Iter: 192 loss: 0.0133189075
Iter: 193 loss: 0.0134928897
Iter: 194 loss: 0.0131649729
Iter: 195 loss: 0.0130294301
Iter: 196 loss: 0.0141666979
Iter: 197 loss: 0.0130146407
Iter: 198 loss: 0.0129467594
Iter: 199 loss: 0.0127905151
Iter: 200 loss: 0.0152901262
Iter: 201 loss: 0.0127812922
Iter: 202 loss: 0.0125748161
Iter: 203 loss: 0.0131906215
Iter: 204 loss: 0.0125228949
Iter: 205 loss: 0.0124141071
Iter: 206 loss: 0.0123352967
Iter: 207 loss: 0.0123004038
Iter: 208 loss: 0.0120496582
Iter: 209 loss: 0.014297259
Iter: 210 loss: 0.0120362006
Iter: 211 loss: 0.0118819438
Iter: 212 loss: 0.0118224006
Iter: 213 loss: 0.0116214612
Iter: 214 loss: 0.0115954727
Iter: 215 loss: 0.0114549184
Iter: 216 loss: 0.0112168873
Iter: 217 loss: 0.0125716496
Iter: 218 loss: 0.0111802295
Iter: 219 loss: 0.011016475
Iter: 220 loss: 0.0112393834
Iter: 221 loss: 0.0109344795
Iter: 222 loss: 0.0107697044
Iter: 223 loss: 0.0110224877
Iter: 224 loss: 0.0106892549
Iter: 225 loss: 0.0105340369
Iter: 226 loss: 0.0111324955
Iter: 227 loss: 0.0105014462
Iter: 228 loss: 0.0104048867
Iter: 229 loss: 0.0113271456
Iter: 230 loss: 0.0103985686
Iter: 231 loss: 0.0103284959
Iter: 232 loss: 0.0103677325
Iter: 233 loss: 0.0102829728
Iter: 234 loss: 0.0101657519
Iter: 235 loss: 0.0104417559
Iter: 236 loss: 0.0101216268
Iter: 237 loss: 0.00997578166
Iter: 238 loss: 0.0106772333
Iter: 239 loss: 0.00995388813
Iter: 240 loss: 0.00988867693
Iter: 241 loss: 0.00994417071
Iter: 242 loss: 0.00984904449
Iter: 243 loss: 0.00976803619
Iter: 244 loss: 0.00958826765
Iter: 245 loss: 0.0120225456
Iter: 246 loss: 0.00957843661
Iter: 247 loss: 0.0094019575
Iter: 248 loss: 0.00940142758
Iter: 249 loss: 0.00928302668
Iter: 250 loss: 0.00945729576
Iter: 251 loss: 0.0092276372
Iter: 252 loss: 0.00908377208
Iter: 253 loss: 0.00982612371
Iter: 254 loss: 0.00906375796
Iter: 255 loss: 0.00897603389
Iter: 256 loss: 0.00950055942
Iter: 257 loss: 0.00896413624
Iter: 258 loss: 0.00891576521
Iter: 259 loss: 0.00894135237
Iter: 260 loss: 0.00888299197
Iter: 261 loss: 0.00882754195
Iter: 262 loss: 0.00932762772
Iter: 263 loss: 0.00882588513
Iter: 264 loss: 0.00877597928
Iter: 265 loss: 0.00892010517
Iter: 266 loss: 0.00875954702
Iter: 267 loss: 0.00870229
Iter: 268 loss: 0.00881557725
Iter: 269 loss: 0.00867924467
Iter: 270 loss: 0.00861128885
Iter: 271 loss: 0.00860962085
Iter: 272 loss: 0.00855114404
Iter: 273 loss: 0.00860706158
Iter: 274 loss: 0.00851882
Iter: 275 loss: 0.00846893
Iter: 276 loss: 0.00838772766
Iter: 277 loss: 0.00838702358
Iter: 278 loss: 0.0082821995
Iter: 279 loss: 0.00843854249
Iter: 280 loss: 0.00823385268
Iter: 281 loss: 0.00811600871
Iter: 282 loss: 0.00886700675
Iter: 283 loss: 0.00810411386
Iter: 284 loss: 0.00802152604
Iter: 285 loss: 0.00817186292
Iter: 286 loss: 0.00798490364
Iter: 287 loss: 0.00787396077
Iter: 288 loss: 0.007942155
Iter: 289 loss: 0.00780310435
Iter: 290 loss: 0.00771621149
Iter: 291 loss: 0.00805825181
Iter: 292 loss: 0.0076966472
Iter: 293 loss: 0.00764996139
Iter: 294 loss: 0.00764588872
Iter: 295 loss: 0.00760659808
Iter: 296 loss: 0.00766822323
Iter: 297 loss: 0.00758882
Iter: 298 loss: 0.00755296461
Iter: 299 loss: 0.00747282617
Iter: 300 loss: 0.00877784751
Iter: 301 loss: 0.00746902265
Iter: 302 loss: 0.00740369735
Iter: 303 loss: 0.00806839671
Iter: 304 loss: 0.0074024233
Iter: 305 loss: 0.00735161174
Iter: 306 loss: 0.00805008
Iter: 307 loss: 0.0073510455
Iter: 308 loss: 0.00731843803
Iter: 309 loss: 0.00735605601
Iter: 310 loss: 0.00730122952
Iter: 311 loss: 0.0072613
Iter: 312 loss: 0.00721201
Iter: 313 loss: 0.00720783556
Iter: 314 loss: 0.00712528033
Iter: 315 loss: 0.00721471105
Iter: 316 loss: 0.00707811909
Iter: 317 loss: 0.00700852228
Iter: 318 loss: 0.00817518868
Iter: 319 loss: 0.00700839097
Iter: 320 loss: 0.00695731677
Iter: 321 loss: 0.00688202074
Iter: 322 loss: 0.00688025774
Iter: 323 loss: 0.00681371894
Iter: 324 loss: 0.0069516
Iter: 325 loss: 0.006786732
Iter: 326 loss: 0.00671749469
Iter: 327 loss: 0.00719502661
Iter: 328 loss: 0.00670920126
Iter: 329 loss: 0.00666878652
Iter: 330 loss: 0.00666736905
Iter: 331 loss: 0.00664720125
Iter: 332 loss: 0.00659315893
Iter: 333 loss: 0.00698631443
Iter: 334 loss: 0.00658087386
Iter: 335 loss: 0.00650459342
Iter: 336 loss: 0.00654932903
Iter: 337 loss: 0.00645758444
Iter: 338 loss: 0.00640664808
Iter: 339 loss: 0.00640572794
Iter: 340 loss: 0.00637480943
Iter: 341 loss: 0.00637396239
Iter: 342 loss: 0.00635683816
Iter: 343 loss: 0.00635096524
Iter: 344 loss: 0.00634118821
Iter: 345 loss: 0.00629493129
Iter: 346 loss: 0.00623031
Iter: 347 loss: 0.00622768607
Iter: 348 loss: 0.00617420906
Iter: 349 loss: 0.00698250439
Iter: 350 loss: 0.00617404189
Iter: 351 loss: 0.00612495653
Iter: 352 loss: 0.00627320539
Iter: 353 loss: 0.00610894617
Iter: 354 loss: 0.00604892056
Iter: 355 loss: 0.006062428
Iter: 356 loss: 0.0060048392
Iter: 357 loss: 0.00594730303
Iter: 358 loss: 0.00643721595
Iter: 359 loss: 0.00594342407
Iter: 360 loss: 0.00589602394
Iter: 361 loss: 0.00588436332
Iter: 362 loss: 0.00585493259
Iter: 363 loss: 0.00583135523
Iter: 364 loss: 0.00582191069
Iter: 365 loss: 0.00577507727
Iter: 366 loss: 0.00590651296
Iter: 367 loss: 0.00575856213
Iter: 368 loss: 0.00572983176
Iter: 369 loss: 0.00572596723
Iter: 370 loss: 0.00570569653
Iter: 371 loss: 0.00566224847
Iter: 372 loss: 0.00564996433
Iter: 373 loss: 0.00562476274
Iter: 374 loss: 0.00558128534
Iter: 375 loss: 0.00557979196
Iter: 376 loss: 0.00554385735
Iter: 377 loss: 0.0059732222
Iter: 378 loss: 0.00554299075
Iter: 379 loss: 0.00552962301
Iter: 380 loss: 0.00549522229
Iter: 381 loss: 0.00580604188
Iter: 382 loss: 0.00548948
Iter: 383 loss: 0.00543897646
Iter: 384 loss: 0.00546229817
Iter: 385 loss: 0.00540517969
Iter: 386 loss: 0.00538362563
Iter: 387 loss: 0.00538648944
Iter: 388 loss: 0.00536705041
Iter: 389 loss: 0.0053438656
Iter: 390 loss: 0.00530140381
Iter: 391 loss: 0.00630684756
Iter: 392 loss: 0.00530137401
Iter: 393 loss: 0.00526137603
Iter: 394 loss: 0.00583977811
Iter: 395 loss: 0.00526117068
Iter: 396 loss: 0.00521692
Iter: 397 loss: 0.00527811749
Iter: 398 loss: 0.00519579602
Iter: 399 loss: 0.00516443234
Iter: 400 loss: 0.00534248445
Iter: 401 loss: 0.00515940599
Iter: 402 loss: 0.00512414891
Iter: 403 loss: 0.00557360891
Iter: 404 loss: 0.00512385089
Iter: 405 loss: 0.00508633535
Iter: 406 loss: 0.00519704074
Iter: 407 loss: 0.00507429
Iter: 408 loss: 0.00505057769
Iter: 409 loss: 0.00516336737
Iter: 410 loss: 0.00504683796
Iter: 411 loss: 0.00502799917
Iter: 412 loss: 0.00499774935
Iter: 413 loss: 0.0049974313
Iter: 414 loss: 0.00497523602
Iter: 415 loss: 0.00524706207
Iter: 416 loss: 0.00497507304
Iter: 417 loss: 0.00495615788
Iter: 418 loss: 0.00497234613
Iter: 419 loss: 0.00494483858
Iter: 420 loss: 0.00491192378
Iter: 421 loss: 0.00495556649
Iter: 422 loss: 0.00489536626
Iter: 423 loss: 0.00485877832
Iter: 424 loss: 0.00542500522
Iter: 425 loss: 0.00485874899
Iter: 426 loss: 0.00483721262
Iter: 427 loss: 0.00482923072
Iter: 428 loss: 0.00481749931
Iter: 429 loss: 0.00477692252
Iter: 430 loss: 0.00498783216
Iter: 431 loss: 0.00476969406
Iter: 432 loss: 0.00472863391
Iter: 433 loss: 0.00476337597
Iter: 434 loss: 0.00470471
Iter: 435 loss: 0.00464510499
Iter: 436 loss: 0.0050476878
Iter: 437 loss: 0.0046385061
Iter: 438 loss: 0.00459599588
Iter: 439 loss: 0.00482361624
Iter: 440 loss: 0.00458964147
Iter: 441 loss: 0.0045613437
Iter: 442 loss: 0.00473142928
Iter: 443 loss: 0.0045570787
Iter: 444 loss: 0.00451671565
Iter: 445 loss: 0.00464037899
Iter: 446 loss: 0.00450496795
Iter: 447 loss: 0.00447864458
Iter: 448 loss: 0.00450298609
Iter: 449 loss: 0.00446295831
Iter: 450 loss: 0.00443970272
Iter: 451 loss: 0.00469176099
Iter: 452 loss: 0.00443931436
Iter: 453 loss: 0.00441893563
Iter: 454 loss: 0.00443762355
Iter: 455 loss: 0.00440693507
Iter: 456 loss: 0.00438016141
Iter: 457 loss: 0.00435433863
Iter: 458 loss: 0.00434833951
Iter: 459 loss: 0.00430413056
Iter: 460 loss: 0.00482930709
Iter: 461 loss: 0.00430333335
Iter: 462 loss: 0.00427853037
Iter: 463 loss: 0.00438241661
Iter: 464 loss: 0.004273945
Iter: 465 loss: 0.00424614
Iter: 466 loss: 0.00424867216
Iter: 467 loss: 0.00422402564
Iter: 468 loss: 0.00419559889
Iter: 469 loss: 0.00425756816
Iter: 470 loss: 0.0041850619
Iter: 471 loss: 0.00416196883
Iter: 472 loss: 0.00421816111
Iter: 473 loss: 0.00415353104
Iter: 474 loss: 0.00413493766
Iter: 475 loss: 0.00413462892
Iter: 476 loss: 0.00412060693
Iter: 477 loss: 0.0041428688
Iter: 478 loss: 0.0041137645
Iter: 479 loss: 0.00410152785
Iter: 480 loss: 0.00408627465
Iter: 481 loss: 0.00408507232
Iter: 482 loss: 0.00406338647
Iter: 483 loss: 0.00405694684
Iter: 484 loss: 0.00404378632
Iter: 485 loss: 0.00404636655
Iter: 486 loss: 0.00402355101
Iter: 487 loss: 0.00400866196
Iter: 488 loss: 0.00398408528
Iter: 489 loss: 0.00398396049
Iter: 490 loss: 0.00396144
Iter: 491 loss: 0.00396694243
Iter: 492 loss: 0.00394522911
Iter: 493 loss: 0.0039325105
Iter: 494 loss: 0.0039207451
Iter: 495 loss: 0.00391765265
Iter: 496 loss: 0.00389692793
Iter: 497 loss: 0.00389549416
Iter: 498 loss: 0.00388003048
Iter: 499 loss: 0.00386132859
Iter: 500 loss: 0.00410342729
Iter: 501 loss: 0.0038612755
Iter: 502 loss: 0.0038454216
Iter: 503 loss: 0.00383135746
Iter: 504 loss: 0.00382705266
Iter: 505 loss: 0.00381157896
Iter: 506 loss: 0.00386140845
Iter: 507 loss: 0.00380750862
Iter: 508 loss: 0.00379723078
Iter: 509 loss: 0.00378078455
Iter: 510 loss: 0.00378065533
Iter: 511 loss: 0.00375463092
Iter: 512 loss: 0.00398280052
Iter: 513 loss: 0.00375330774
Iter: 514 loss: 0.00372905633
Iter: 515 loss: 0.00377015863
Iter: 516 loss: 0.00371837942
Iter: 517 loss: 0.00369328121
Iter: 518 loss: 0.0038443245
Iter: 519 loss: 0.0036905061
Iter: 520 loss: 0.00367439119
Iter: 521 loss: 0.00380858569
Iter: 522 loss: 0.00367329363
Iter: 523 loss: 0.00366141181
Iter: 524 loss: 0.00374244177
Iter: 525 loss: 0.00366033125
Iter: 526 loss: 0.00364750857
Iter: 527 loss: 0.00364943501
Iter: 528 loss: 0.00363779883
Iter: 529 loss: 0.00361631019
Iter: 530 loss: 0.00371163758
Iter: 531 loss: 0.00361222774
Iter: 532 loss: 0.00359711889
Iter: 533 loss: 0.00360323768
Iter: 534 loss: 0.00358679844
Iter: 535 loss: 0.0035634425
Iter: 536 loss: 0.00360554969
Iter: 537 loss: 0.00355270295
Iter: 538 loss: 0.00353876827
Iter: 539 loss: 0.00353613682
Iter: 540 loss: 0.003528364
Iter: 541 loss: 0.00351282442
Iter: 542 loss: 0.00383252301
Iter: 543 loss: 0.00351265119
Iter: 544 loss: 0.00349808158
Iter: 545 loss: 0.00347980624
Iter: 546 loss: 0.00347840902
Iter: 547 loss: 0.00345103932
Iter: 548 loss: 0.0034480663
Iter: 549 loss: 0.00342799257
Iter: 550 loss: 0.00341507653
Iter: 551 loss: 0.00346716703
Iter: 552 loss: 0.00341223716
Iter: 553 loss: 0.00340168551
Iter: 554 loss: 0.00340506481
Iter: 555 loss: 0.00339414575
Iter: 556 loss: 0.00338025088
Iter: 557 loss: 0.00349843921
Iter: 558 loss: 0.00337958
Iter: 559 loss: 0.00336098415
Iter: 560 loss: 0.0033864663
Iter: 561 loss: 0.00335149793
Iter: 562 loss: 0.00333506521
Iter: 563 loss: 0.00341939484
Iter: 564 loss: 0.0033324752
Iter: 565 loss: 0.00331808068
Iter: 566 loss: 0.00330175739
Iter: 567 loss: 0.00329962349
Iter: 568 loss: 0.00326857972
Iter: 569 loss: 0.00334636448
Iter: 570 loss: 0.003257256
Iter: 571 loss: 0.00323364371
Iter: 572 loss: 0.00337482663
Iter: 573 loss: 0.00323026348
Iter: 574 loss: 0.00322594587
Iter: 575 loss: 0.00321948715
Iter: 576 loss: 0.00321592111
Iter: 577 loss: 0.00320909638
Iter: 578 loss: 0.00336035481
Iter: 579 loss: 0.00320906378
Iter: 580 loss: 0.00319597498
Iter: 581 loss: 0.00318600237
Iter: 582 loss: 0.00318174157
Iter: 583 loss: 0.0031689941
Iter: 584 loss: 0.00316710444
Iter: 585 loss: 0.0031519325
Iter: 586 loss: 0.00316940853
Iter: 587 loss: 0.00314398133
Iter: 588 loss: 0.00312880077
Iter: 589 loss: 0.00312493858
Iter: 590 loss: 0.0031152661
Iter: 591 loss: 0.00309475465
Iter: 592 loss: 0.00313065154
Iter: 593 loss: 0.00308591942
Iter: 594 loss: 0.00306507037
Iter: 595 loss: 0.00312691508
Iter: 596 loss: 0.00305855297
Iter: 597 loss: 0.00304041756
Iter: 598 loss: 0.00312018255
Iter: 599 loss: 0.00303663104
Iter: 600 loss: 0.00301981973
Iter: 601 loss: 0.00302376016
Iter: 602 loss: 0.0030075137
Iter: 603 loss: 0.00299015
Iter: 604 loss: 0.00311253406
Iter: 605 loss: 0.00298848539
Iter: 606 loss: 0.00297704572
Iter: 607 loss: 0.00316349068
Iter: 608 loss: 0.00297703
Iter: 609 loss: 0.00296618929
Iter: 610 loss: 0.00297494885
Iter: 611 loss: 0.00295978645
Iter: 612 loss: 0.00295188
Iter: 613 loss: 0.00293173594
Iter: 614 loss: 0.00311460276
Iter: 615 loss: 0.00292855
Iter: 616 loss: 0.00290761795
Iter: 617 loss: 0.00308248797
Iter: 618 loss: 0.00290627265
Iter: 619 loss: 0.00289139128
Iter: 620 loss: 0.00291277282
Iter: 621 loss: 0.00288391
Iter: 622 loss: 0.00286813197
Iter: 623 loss: 0.00295930915
Iter: 624 loss: 0.002866189
Iter: 625 loss: 0.00285382057
Iter: 626 loss: 0.00304021477
Iter: 627 loss: 0.00285377586
Iter: 628 loss: 0.00284939166
Iter: 629 loss: 0.0028438475
Iter: 630 loss: 0.00284343166
Iter: 631 loss: 0.00283408491
Iter: 632 loss: 0.00282830955
Iter: 633 loss: 0.00282451883
Iter: 634 loss: 0.00280878902
Iter: 635 loss: 0.00287184073
Iter: 636 loss: 0.00280519668
Iter: 637 loss: 0.00279405387
Iter: 638 loss: 0.0028078761
Iter: 639 loss: 0.00278824149
Iter: 640 loss: 0.00277879694
Iter: 641 loss: 0.0029038277
Iter: 642 loss: 0.00277877459
Iter: 643 loss: 0.00276871352
Iter: 644 loss: 0.00281141186
Iter: 645 loss: 0.00276644179
Iter: 646 loss: 0.00275997212
Iter: 647 loss: 0.00274731847
Iter: 648 loss: 0.00299781235
Iter: 649 loss: 0.00274721184
Iter: 650 loss: 0.00272873044
Iter: 651 loss: 0.00276435819
Iter: 652 loss: 0.00272072852
Iter: 653 loss: 0.00270294631
Iter: 654 loss: 0.00269164797
Iter: 655 loss: 0.00268472987
Iter: 656 loss: 0.00266754697
Iter: 657 loss: 0.00293281255
Iter: 658 loss: 0.00266750949
Iter: 659 loss: 0.00266154041
Iter: 660 loss: 0.00266152574
Iter: 661 loss: 0.00265310332
Iter: 662 loss: 0.00266355509
Iter: 663 loss: 0.00264859805
Iter: 664 loss: 0.00264150416
Iter: 665 loss: 0.00263909018
Iter: 666 loss: 0.00263509504
Iter: 667 loss: 0.00262673199
Iter: 668 loss: 0.00261513656
Iter: 669 loss: 0.00261461898
Iter: 670 loss: 0.00260256371
Iter: 671 loss: 0.00265679974
Iter: 672 loss: 0.00260023819
Iter: 673 loss: 0.00258879922
Iter: 674 loss: 0.00261063199
Iter: 675 loss: 0.0025841468
Iter: 676 loss: 0.00257240934
Iter: 677 loss: 0.00257185474
Iter: 678 loss: 0.00256262207
Iter: 679 loss: 0.00256534433
Iter: 680 loss: 0.00255605299
Iter: 681 loss: 0.00254682265
Iter: 682 loss: 0.00255279336
Iter: 683 loss: 0.00254097
Iter: 684 loss: 0.0025323513
Iter: 685 loss: 0.00253081601
Iter: 686 loss: 0.00252499897
Iter: 687 loss: 0.00251017511
Iter: 688 loss: 0.0025501952
Iter: 689 loss: 0.00250516157
Iter: 690 loss: 0.00249452284
Iter: 691 loss: 0.00250378065
Iter: 692 loss: 0.00248812512
Iter: 693 loss: 0.00247869198
Iter: 694 loss: 0.00247676857
Iter: 695 loss: 0.00247188937
Iter: 696 loss: 0.00247670943
Iter: 697 loss: 0.00246905955
Iter: 698 loss: 0.00246486487
Iter: 699 loss: 0.00245678797
Iter: 700 loss: 0.00263043842
Iter: 701 loss: 0.00245675
Iter: 702 loss: 0.00244083814
Iter: 703 loss: 0.00245641265
Iter: 704 loss: 0.00243166718
Iter: 705 loss: 0.0024172191
Iter: 706 loss: 0.00241699838
Iter: 707 loss: 0.00240390142
Iter: 708 loss: 0.00240563042
Iter: 709 loss: 0.00239394116
Iter: 710 loss: 0.00237779063
Iter: 711 loss: 0.00245331647
Iter: 712 loss: 0.002374565
Iter: 713 loss: 0.00236079539
Iter: 714 loss: 0.00244465703
Iter: 715 loss: 0.00235927058
Iter: 716 loss: 0.00234805839
Iter: 717 loss: 0.00233520614
Iter: 718 loss: 0.00233364897
Iter: 719 loss: 0.00231173914
Iter: 720 loss: 0.00248027919
Iter: 721 loss: 0.0023100914
Iter: 722 loss: 0.00229647523
Iter: 723 loss: 0.00234690588
Iter: 724 loss: 0.00229305541
Iter: 725 loss: 0.00228739227
Iter: 726 loss: 0.00228531472
Iter: 727 loss: 0.00228032074
Iter: 728 loss: 0.00233476213
Iter: 729 loss: 0.00228016451
Iter: 730 loss: 0.00227744458
Iter: 731 loss: 0.00227019354
Iter: 732 loss: 0.00232030055
Iter: 733 loss: 0.00226857793
Iter: 734 loss: 0.00225395197
Iter: 735 loss: 0.00224304013
Iter: 736 loss: 0.00223820144
Iter: 737 loss: 0.00221968675
Iter: 738 loss: 0.00224097073
Iter: 739 loss: 0.00220957911
Iter: 740 loss: 0.00219064439
Iter: 741 loss: 0.0023836561
Iter: 742 loss: 0.00219011796
Iter: 743 loss: 0.00217627781
Iter: 744 loss: 0.00216263812
Iter: 745 loss: 0.00215977593
Iter: 746 loss: 0.00214035297
Iter: 747 loss: 0.00214028032
Iter: 748 loss: 0.00213011773
Iter: 749 loss: 0.00213748449
Iter: 750 loss: 0.00212389557
Iter: 751 loss: 0.00210769265
Iter: 752 loss: 0.00221052906
Iter: 753 loss: 0.00210568612
Iter: 754 loss: 0.00209614914
Iter: 755 loss: 0.00208437676
Iter: 756 loss: 0.00208337512
Iter: 757 loss: 0.00207626703
Iter: 758 loss: 0.00207626494
Iter: 759 loss: 0.00207148818
Iter: 760 loss: 0.00208346406
Iter: 761 loss: 0.00206988
Iter: 762 loss: 0.00206449814
Iter: 763 loss: 0.00206273794
Iter: 764 loss: 0.00205959706
Iter: 765 loss: 0.00205445522
Iter: 766 loss: 0.00204503722
Iter: 767 loss: 0.00228079082
Iter: 768 loss: 0.00204502442
Iter: 769 loss: 0.00203387323
Iter: 770 loss: 0.00210328633
Iter: 771 loss: 0.00203262316
Iter: 772 loss: 0.00202500261
Iter: 773 loss: 0.00207663793
Iter: 774 loss: 0.00202422892
Iter: 775 loss: 0.00201860256
Iter: 776 loss: 0.0020044921
Iter: 777 loss: 0.00213506538
Iter: 778 loss: 0.00200244109
Iter: 779 loss: 0.00199115044
Iter: 780 loss: 0.0019910594
Iter: 781 loss: 0.00197952799
Iter: 782 loss: 0.00200139219
Iter: 783 loss: 0.0019746325
Iter: 784 loss: 0.00195749942
Iter: 785 loss: 0.00196269341
Iter: 786 loss: 0.00194521539
Iter: 787 loss: 0.00193537679
Iter: 788 loss: 0.00198674807
Iter: 789 loss: 0.00193380611
Iter: 790 loss: 0.00193039398
Iter: 791 loss: 0.00192991551
Iter: 792 loss: 0.0019264454
Iter: 793 loss: 0.00194826233
Iter: 794 loss: 0.00192600209
Iter: 795 loss: 0.00192379928
Iter: 796 loss: 0.0019200535
Iter: 797 loss: 0.00192005234
Iter: 798 loss: 0.00191471248
Iter: 799 loss: 0.00191950682
Iter: 800 loss: 0.00191163737
Iter: 801 loss: 0.00190626201
Iter: 802 loss: 0.00190744083
Iter: 803 loss: 0.00190229691
Iter: 804 loss: 0.00189449475
Iter: 805 loss: 0.0019333153
Iter: 806 loss: 0.0018931306
Iter: 807 loss: 0.00188542646
Iter: 808 loss: 0.00187772932
Iter: 809 loss: 0.00187611557
Iter: 810 loss: 0.00186673668
Iter: 811 loss: 0.00200336031
Iter: 812 loss: 0.00186672877
Iter: 813 loss: 0.00185976562
Iter: 814 loss: 0.00185812148
Iter: 815 loss: 0.00185368466
Iter: 816 loss: 0.00184611685
Iter: 817 loss: 0.00186629547
Iter: 818 loss: 0.00184356782
Iter: 819 loss: 0.00183734437
Iter: 820 loss: 0.00190344523
Iter: 821 loss: 0.00183720596
Iter: 822 loss: 0.00183327566
Iter: 823 loss: 0.00183680991
Iter: 824 loss: 0.0018309626
Iter: 825 loss: 0.00184189
Iter: 826 loss: 0.00182903919
Iter: 827 loss: 0.00182820146
Iter: 828 loss: 0.00182597968
Iter: 829 loss: 0.00184278516
Iter: 830 loss: 0.00182550785
Iter: 831 loss: 0.00182236556
Iter: 832 loss: 0.00181667949
Iter: 833 loss: 0.00195511966
Iter: 834 loss: 0.00181667763
Iter: 835 loss: 0.00180797651
Iter: 836 loss: 0.00182780321
Iter: 837 loss: 0.00180464238
Iter: 838 loss: 0.00179770007
Iter: 839 loss: 0.00182405196
Iter: 840 loss: 0.00179602602
Iter: 841 loss: 0.00178965565
Iter: 842 loss: 0.00178196642
Iter: 843 loss: 0.00178120716
Iter: 844 loss: 0.00177206588
Iter: 845 loss: 0.00184824131
Iter: 846 loss: 0.00177144492
Iter: 847 loss: 0.0017647791
Iter: 848 loss: 0.00176029548
Iter: 849 loss: 0.0017578206
Iter: 850 loss: 0.00175199239
Iter: 851 loss: 0.00176292856
Iter: 852 loss: 0.00174955674
Iter: 853 loss: 0.00174395414
Iter: 854 loss: 0.00182266429
Iter: 855 loss: 0.00174392899
Iter: 856 loss: 0.00173868681
Iter: 857 loss: 0.00172639918
Iter: 858 loss: 0.00186827919
Iter: 859 loss: 0.00172535493
Iter: 860 loss: 0.00172370404
Iter: 861 loss: 0.00172091811
Iter: 862 loss: 0.00171567081
Iter: 863 loss: 0.00172943424
Iter: 864 loss: 0.00171399838
Iter: 865 loss: 0.00170997786
Iter: 866 loss: 0.00170526281
Iter: 867 loss: 0.00170473242
Iter: 868 loss: 0.00170003437
Iter: 869 loss: 0.00170583604
Iter: 870 loss: 0.00169760513
Iter: 871 loss: 0.00169079634
Iter: 872 loss: 0.00170566153
Iter: 873 loss: 0.00168815488
Iter: 874 loss: 0.00168244075
Iter: 875 loss: 0.00169436424
Iter: 876 loss: 0.00168014015
Iter: 877 loss: 0.00167474221
Iter: 878 loss: 0.00168794242
Iter: 879 loss: 0.00167280575
Iter: 880 loss: 0.00166701782
Iter: 881 loss: 0.00168415764
Iter: 882 loss: 0.00166526355
Iter: 883 loss: 0.00166101579
Iter: 884 loss: 0.00173001993
Iter: 885 loss: 0.00166102126
Iter: 886 loss: 0.00165723346
Iter: 887 loss: 0.00165542599
Iter: 888 loss: 0.00165359851
Iter: 889 loss: 0.00165079837
Iter: 890 loss: 0.00165071315
Iter: 891 loss: 0.0016481342
Iter: 892 loss: 0.00164185057
Iter: 893 loss: 0.00170560949
Iter: 894 loss: 0.00164113182
Iter: 895 loss: 0.00164439389
Iter: 896 loss: 0.00163751072
Iter: 897 loss: 0.00163677312
Iter: 898 loss: 0.00163706485
Iter: 899 loss: 0.00163626601
Iter: 900 loss: 0.00163355144
Iter: 901 loss: 0.00162872043
Iter: 902 loss: 0.00162872206
Iter: 903 loss: 0.00162014528
Iter: 904 loss: 0.00166417868
Iter: 905 loss: 0.00161877519
Iter: 906 loss: 0.00161356886
Iter: 907 loss: 0.00161655061
Iter: 908 loss: 0.00161015894
Iter: 909 loss: 0.00160480302
Iter: 910 loss: 0.00160300871
Iter: 911 loss: 0.00159993279
Iter: 912 loss: 0.00159517862
Iter: 913 loss: 0.00159037986
Iter: 914 loss: 0.00158942083
Iter: 915 loss: 0.00158386922
Iter: 916 loss: 0.00159759016
Iter: 917 loss: 0.00158190983
Iter: 918 loss: 0.00157577568
Iter: 919 loss: 0.00157196983
Iter: 920 loss: 0.00156953186
Iter: 921 loss: 0.00156272016
Iter: 922 loss: 0.00158460578
Iter: 923 loss: 0.00156074797
Iter: 924 loss: 0.00155713689
Iter: 925 loss: 0.00158903096
Iter: 926 loss: 0.00155697786
Iter: 927 loss: 0.00155389728
Iter: 928 loss: 0.00155388145
Iter: 929 loss: 0.0015513103
Iter: 930 loss: 0.00154673378
Iter: 931 loss: 0.00165668968
Iter: 932 loss: 0.00154673238
Iter: 933 loss: 0.00154306949
Iter: 934 loss: 0.00153390039
Iter: 935 loss: 0.00162191154
Iter: 936 loss: 0.00153262704
Iter: 937 loss: 0.00152948708
Iter: 938 loss: 0.00152689987
Iter: 939 loss: 0.00152215199
Iter: 940 loss: 0.00155841419
Iter: 941 loss: 0.00152176432
Iter: 942 loss: 0.00151801656
Iter: 943 loss: 0.00155334244
Iter: 944 loss: 0.00151788187
Iter: 945 loss: 0.00151450082
Iter: 946 loss: 0.00151142245
Iter: 947 loss: 0.00151058845
Iter: 948 loss: 0.0015054075
Iter: 949 loss: 0.00151159929
Iter: 950 loss: 0.00150269386
Iter: 951 loss: 0.00149794319
Iter: 952 loss: 0.00153045857
Iter: 953 loss: 0.00149749895
Iter: 954 loss: 0.00149278762
Iter: 955 loss: 0.00149311323
Iter: 956 loss: 0.0014891387
Iter: 957 loss: 0.00148341572
Iter: 958 loss: 0.00149932411
Iter: 959 loss: 0.00148156437
Iter: 960 loss: 0.00147335045
Iter: 961 loss: 0.00148259359
Iter: 962 loss: 0.00146890641
Iter: 963 loss: 0.00147655234
Iter: 964 loss: 0.00146661513
Iter: 965 loss: 0.00146456086
Iter: 966 loss: 0.0014595869
Iter: 967 loss: 0.00151654938
Iter: 968 loss: 0.00145906722
Iter: 969 loss: 0.00145417708
Iter: 970 loss: 0.00145836629
Iter: 971 loss: 0.00145127322
Iter: 972 loss: 0.00144569064
Iter: 973 loss: 0.00150334404
Iter: 974 loss: 0.00144555664
Iter: 975 loss: 0.00144260377
Iter: 976 loss: 0.00147625583
Iter: 977 loss: 0.00144254486
Iter: 978 loss: 0.00144079258
Iter: 979 loss: 0.00144609401
Iter: 980 loss: 0.00144027639
Iter: 981 loss: 0.0014386361
Iter: 982 loss: 0.00143489451
Iter: 983 loss: 0.0014833766
Iter: 984 loss: 0.00143464433
Iter: 985 loss: 0.00143081788
Iter: 986 loss: 0.00144852581
Iter: 987 loss: 0.00143010984
Iter: 988 loss: 0.00142669654
Iter: 989 loss: 0.00143457344
Iter: 990 loss: 0.00142541132
Iter: 991 loss: 0.00142305158
Iter: 992 loss: 0.00141939137
Iter: 993 loss: 0.00141934422
Iter: 994 loss: 0.00141697458
Iter: 995 loss: 0.0014156783
Iter: 996 loss: 0.00141461939
Iter: 997 loss: 0.0014125763
Iter: 998 loss: 0.00141107035
Iter: 999 loss: 0.00141039072
Iter: 1000 loss: 0.00140612596
Iter: 1001 loss: 0.00141784851
Iter: 1002 loss: 0.00140471163
Iter: 1003 loss: 0.00139897317
Iter: 1004 loss: 0.00141334138
Iter: 1005 loss: 0.00139700598
Iter: 1006 loss: 0.0013940332
Iter: 1007 loss: 0.00138941873
Iter: 1008 loss: 0.00138935237
Iter: 1009 loss: 0.00138551532
Iter: 1010 loss: 0.00138532778
Iter: 1011 loss: 0.00138205918
Iter: 1012 loss: 0.00139264273
Iter: 1013 loss: 0.00138113543
Iter: 1014 loss: 0.00137695391
Iter: 1015 loss: 0.00136689469
Iter: 1016 loss: 0.00147446222
Iter: 1017 loss: 0.00136582879
Iter: 1018 loss: 0.00135759683
Iter: 1019 loss: 0.00144566386
Iter: 1020 loss: 0.00135739904
Iter: 1021 loss: 0.00135123939
Iter: 1022 loss: 0.00135425199
Iter: 1023 loss: 0.0013471219
Iter: 1024 loss: 0.00133966503
Iter: 1025 loss: 0.00141976168
Iter: 1026 loss: 0.00133950927
Iter: 1027 loss: 0.00133920927
Iter: 1028 loss: 0.00133749098
Iter: 1029 loss: 0.00133672426
Iter: 1030 loss: 0.00133476965
Iter: 1031 loss: 0.00135149772
Iter: 1032 loss: 0.00133444346
Iter: 1033 loss: 0.00133085065
Iter: 1034 loss: 0.0013466801
Iter: 1035 loss: 0.00133011071
Iter: 1036 loss: 0.00132703048
Iter: 1037 loss: 0.00136119302
Iter: 1038 loss: 0.00132698216
Iter: 1039 loss: 0.00132526
Iter: 1040 loss: 0.00132037723
Iter: 1041 loss: 0.00134540373
Iter: 1042 loss: 0.00131875277
Iter: 1043 loss: 0.00131073222
Iter: 1044 loss: 0.0013342083
Iter: 1045 loss: 0.00130829599
Iter: 1046 loss: 0.00130200176
Iter: 1047 loss: 0.00130180549
Iter: 1048 loss: 0.0012982802
Iter: 1049 loss: 0.0012948201
Iter: 1050 loss: 0.00129407248
Iter: 1051 loss: 0.00128769013
Iter: 1052 loss: 0.00130166428
Iter: 1053 loss: 0.00128526194
Iter: 1054 loss: 0.00127990067
Iter: 1055 loss: 0.0012916805
Iter: 1056 loss: 0.00127781322
Iter: 1057 loss: 0.0012741402
Iter: 1058 loss: 0.00128245214
Iter: 1059 loss: 0.00127277453
Iter: 1060 loss: 0.00127365091
Iter: 1061 loss: 0.00127121038
Iter: 1062 loss: 0.00126991724
Iter: 1063 loss: 0.00126778451
Iter: 1064 loss: 0.0012677745
Iter: 1065 loss: 0.00126539357
Iter: 1066 loss: 0.00126115559
Iter: 1067 loss: 0.00126115431
Iter: 1068 loss: 0.00125771749
Iter: 1069 loss: 0.00128758582
Iter: 1070 loss: 0.00125755579
Iter: 1071 loss: 0.00125389453
Iter: 1072 loss: 0.0012622925
Iter: 1073 loss: 0.00125249417
Iter: 1074 loss: 0.00124938611
Iter: 1075 loss: 0.00124554569
Iter: 1076 loss: 0.00124520482
Iter: 1077 loss: 0.00124049967
Iter: 1078 loss: 0.00130297395
Iter: 1079 loss: 0.00124047336
Iter: 1080 loss: 0.00123585644
Iter: 1081 loss: 0.00124295824
Iter: 1082 loss: 0.00123363617
Iter: 1083 loss: 0.0012314599
Iter: 1084 loss: 0.0012320528
Iter: 1085 loss: 0.00122989551
Iter: 1086 loss: 0.00122743123
Iter: 1087 loss: 0.00122619839
Iter: 1088 loss: 0.00122503226
Iter: 1089 loss: 0.00122252409
Iter: 1090 loss: 0.00122348126
Iter: 1091 loss: 0.00122077414
Iter: 1092 loss: 0.00121790241
Iter: 1093 loss: 0.00121790066
Iter: 1094 loss: 0.00121535757
Iter: 1095 loss: 0.00122184
Iter: 1096 loss: 0.00121446513
Iter: 1097 loss: 0.00121256127
Iter: 1098 loss: 0.00121504767
Iter: 1099 loss: 0.00121159665
Iter: 1100 loss: 0.00120965927
Iter: 1101 loss: 0.00120967207
Iter: 1102 loss: 0.00120809779
Iter: 1103 loss: 0.00120531837
Iter: 1104 loss: 0.00123253139
Iter: 1105 loss: 0.00120522745
Iter: 1106 loss: 0.00120322139
Iter: 1107 loss: 0.00119839329
Iter: 1108 loss: 0.0012507661
Iter: 1109 loss: 0.00119788409
Iter: 1110 loss: 0.00119176577
Iter: 1111 loss: 0.00123535935
Iter: 1112 loss: 0.0011912114
Iter: 1113 loss: 0.00118842057
Iter: 1114 loss: 0.00122083724
Iter: 1115 loss: 0.0011883832
Iter: 1116 loss: 0.00118545233
Iter: 1117 loss: 0.00119220477
Iter: 1118 loss: 0.00118433335
Iter: 1119 loss: 0.00118208933
Iter: 1120 loss: 0.00118151389
Iter: 1121 loss: 0.001180102
Iter: 1122 loss: 0.00117706344
Iter: 1123 loss: 0.00119009789
Iter: 1124 loss: 0.00117640733
Iter: 1125 loss: 0.00117366598
Iter: 1126 loss: 0.00118262297
Iter: 1127 loss: 0.00117288274
Iter: 1128 loss: 0.00117076025
Iter: 1129 loss: 0.0011707549
Iter: 1130 loss: 0.00116899179
Iter: 1131 loss: 0.00116952346
Iter: 1132 loss: 0.00116772274
Iter: 1133 loss: 0.00116577849
Iter: 1134 loss: 0.00116444216
Iter: 1135 loss: 0.00116373552
Iter: 1136 loss: 0.00116030301
Iter: 1137 loss: 0.00117075944
Iter: 1138 loss: 0.00115925178
Iter: 1139 loss: 0.00115538784
Iter: 1140 loss: 0.00115518912
Iter: 1141 loss: 0.0011522338
Iter: 1142 loss: 0.00114720489
Iter: 1143 loss: 0.00115830544
Iter: 1144 loss: 0.001145293
Iter: 1145 loss: 0.00114160962
Iter: 1146 loss: 0.00118099153
Iter: 1147 loss: 0.00114150508
Iter: 1148 loss: 0.00113880797
Iter: 1149 loss: 0.00113879493
Iter: 1150 loss: 0.00113726477
Iter: 1151 loss: 0.00113408244
Iter: 1152 loss: 0.00118874467
Iter: 1153 loss: 0.00113401026
Iter: 1154 loss: 0.0011308355
Iter: 1155 loss: 0.00113450957
Iter: 1156 loss: 0.00112914981
Iter: 1157 loss: 0.00112501602
Iter: 1158 loss: 0.00113574159
Iter: 1159 loss: 0.00112361007
Iter: 1160 loss: 0.00112061377
Iter: 1161 loss: 0.00112059223
Iter: 1162 loss: 0.00111831538
Iter: 1163 loss: 0.00112521625
Iter: 1164 loss: 0.00111764646
Iter: 1165 loss: 0.001115405
Iter: 1166 loss: 0.00111408252
Iter: 1167 loss: 0.00111314
Iter: 1168 loss: 0.00111003127
Iter: 1169 loss: 0.00114569534
Iter: 1170 loss: 0.0011099882
Iter: 1171 loss: 0.00110711309
Iter: 1172 loss: 0.00110428222
Iter: 1173 loss: 0.00110366801
Iter: 1174 loss: 0.00109963655
Iter: 1175 loss: 0.00110353332
Iter: 1176 loss: 0.00109733769
Iter: 1177 loss: 0.00109307549
Iter: 1178 loss: 0.00109680986
Iter: 1179 loss: 0.0010905927
Iter: 1180 loss: 0.00108995114
Iter: 1181 loss: 0.00108782179
Iter: 1182 loss: 0.00108601514
Iter: 1183 loss: 0.00108290499
Iter: 1184 loss: 0.00108290266
Iter: 1185 loss: 0.00107867725
Iter: 1186 loss: 0.00108177809
Iter: 1187 loss: 0.00107607269
Iter: 1188 loss: 0.00107041257
Iter: 1189 loss: 0.00107791228
Iter: 1190 loss: 0.0010675845
Iter: 1191 loss: 0.00106479251
Iter: 1192 loss: 0.00106453255
Iter: 1193 loss: 0.00106132019
Iter: 1194 loss: 0.00106299983
Iter: 1195 loss: 0.00105914846
Iter: 1196 loss: 0.00105625601
Iter: 1197 loss: 0.00105439662
Iter: 1198 loss: 0.00105327356
Iter: 1199 loss: 0.0010505314
Iter: 1200 loss: 0.0010493563
Iter: 1201 loss: 0.0010479287
Iter: 1202 loss: 0.00104492949
Iter: 1203 loss: 0.00104333519
Iter: 1204 loss: 0.00104197976
Iter: 1205 loss: 0.00103732594
Iter: 1206 loss: 0.00104313542
Iter: 1207 loss: 0.00103489473
Iter: 1208 loss: 0.00103048631
Iter: 1209 loss: 0.00106298097
Iter: 1210 loss: 0.00103011355
Iter: 1211 loss: 0.00102707103
Iter: 1212 loss: 0.00104141841
Iter: 1213 loss: 0.00102649606
Iter: 1214 loss: 0.00102413958
Iter: 1215 loss: 0.0010362654
Iter: 1216 loss: 0.00102376135
Iter: 1217 loss: 0.00102208159
Iter: 1218 loss: 0.00101873977
Iter: 1219 loss: 0.00108603039
Iter: 1220 loss: 0.00101870322
Iter: 1221 loss: 0.00101609
Iter: 1222 loss: 0.00101489341
Iter: 1223 loss: 0.00101361016
Iter: 1224 loss: 0.00101057
Iter: 1225 loss: 0.00100455724
Iter: 1226 loss: 0.00112294755
Iter: 1227 loss: 0.00100450206
Iter: 1228 loss: 0.0010141047
Iter: 1229 loss: 0.00100249797
Iter: 1230 loss: 0.00100077456
Iter: 1231 loss: 0.00100023905
Iter: 1232 loss: 0.000999222742
Iter: 1233 loss: 0.000995929586
Iter: 1234 loss: 0.00100508693
Iter: 1235 loss: 0.000994839938
Iter: 1236 loss: 0.000991661102
Iter: 1237 loss: 0.000998282922
Iter: 1238 loss: 0.000990409288
Iter: 1239 loss: 0.000988574
Iter: 1240 loss: 0.000988680404
Iter: 1241 loss: 0.000987133128
Iter: 1242 loss: 0.000984740094
Iter: 1243 loss: 0.000983836828
Iter: 1244 loss: 0.000982530881
Iter: 1245 loss: 0.000978578464
Iter: 1246 loss: 0.00101298816
Iter: 1247 loss: 0.000978374504
Iter: 1248 loss: 0.000976438518
Iter: 1249 loss: 0.000978611642
Iter: 1250 loss: 0.000975388743
Iter: 1251 loss: 0.000974300725
Iter: 1252 loss: 0.000974097231
Iter: 1253 loss: 0.000973312301
Iter: 1254 loss: 0.00097455486
Iter: 1255 loss: 0.000972943031
Iter: 1256 loss: 0.000971558387
Iter: 1257 loss: 0.000969819201
Iter: 1258 loss: 0.000969678455
Iter: 1259 loss: 0.000967331696
Iter: 1260 loss: 0.000972115
Iter: 1261 loss: 0.000966371677
Iter: 1262 loss: 0.000965152
Iter: 1263 loss: 0.000964750187
Iter: 1264 loss: 0.000963775965
Iter: 1265 loss: 0.000961375132
Iter: 1266 loss: 0.000985793769
Iter: 1267 loss: 0.000961071579
Iter: 1268 loss: 0.000958896
Iter: 1269 loss: 0.000966415624
Iter: 1270 loss: 0.000958337449
Iter: 1271 loss: 0.000956019911
Iter: 1272 loss: 0.000954815827
Iter: 1273 loss: 0.000953733048
Iter: 1274 loss: 0.000949706533
Iter: 1275 loss: 0.000953961397
Iter: 1276 loss: 0.000947473221
Iter: 1277 loss: 0.000944157946
Iter: 1278 loss: 0.000947928173
Iter: 1279 loss: 0.000942371786
Iter: 1280 loss: 0.000939196267
Iter: 1281 loss: 0.000980435754
Iter: 1282 loss: 0.000939176884
Iter: 1283 loss: 0.000937528675
Iter: 1284 loss: 0.000949920854
Iter: 1285 loss: 0.000937394
Iter: 1286 loss: 0.000935746939
Iter: 1287 loss: 0.000945952546
Iter: 1288 loss: 0.000935558812
Iter: 1289 loss: 0.00093413383
Iter: 1290 loss: 0.000933034054
Iter: 1291 loss: 0.000932580326
Iter: 1292 loss: 0.00093049003
Iter: 1293 loss: 0.000931229733
Iter: 1294 loss: 0.000929019821
Iter: 1295 loss: 0.000929334783
Iter: 1296 loss: 0.000928199268
Iter: 1297 loss: 0.000927436107
Iter: 1298 loss: 0.000925743603
Iter: 1299 loss: 0.000949578593
Iter: 1300 loss: 0.00092565082
Iter: 1301 loss: 0.000923958607
Iter: 1302 loss: 0.000944433792
Iter: 1303 loss: 0.000923935615
Iter: 1304 loss: 0.000922335428
Iter: 1305 loss: 0.000922719482
Iter: 1306 loss: 0.000921166327
Iter: 1307 loss: 0.000920054154
Iter: 1308 loss: 0.000920116
Iter: 1309 loss: 0.000919173646
Iter: 1310 loss: 0.000918309321
Iter: 1311 loss: 0.000916833756
Iter: 1312 loss: 0.000916824443
Iter: 1313 loss: 0.000915199751
Iter: 1314 loss: 0.000912359683
Iter: 1315 loss: 0.00091235881
Iter: 1316 loss: 0.000910571194
Iter: 1317 loss: 0.000911013
Iter: 1318 loss: 0.000909262
Iter: 1319 loss: 0.000906517264
Iter: 1320 loss: 0.00092802773
Iter: 1321 loss: 0.000906311849
Iter: 1322 loss: 0.000903371954
Iter: 1323 loss: 0.00092221325
Iter: 1324 loss: 0.000903039356
Iter: 1325 loss: 0.00090135244
Iter: 1326 loss: 0.000919022597
Iter: 1327 loss: 0.000901307387
Iter: 1328 loss: 0.000899368082
Iter: 1329 loss: 0.000902031257
Iter: 1330 loss: 0.000898415106
Iter: 1331 loss: 0.000896770507
Iter: 1332 loss: 0.000896756421
Iter: 1333 loss: 0.000895934354
Iter: 1334 loss: 0.000894691853
Iter: 1335 loss: 0.000894667639
Iter: 1336 loss: 0.000892831595
Iter: 1337 loss: 0.000914031581
Iter: 1338 loss: 0.000892795273
Iter: 1339 loss: 0.00089175842
Iter: 1340 loss: 0.000895451172
Iter: 1341 loss: 0.000891495962
Iter: 1342 loss: 0.000890462543
Iter: 1343 loss: 0.000892978918
Iter: 1344 loss: 0.00089009339
Iter: 1345 loss: 0.000888759154
Iter: 1346 loss: 0.00088850793
Iter: 1347 loss: 0.000887617
Iter: 1348 loss: 0.000886230962
Iter: 1349 loss: 0.000882555498
Iter: 1350 loss: 0.00090870721
Iter: 1351 loss: 0.000881733489
Iter: 1352 loss: 0.000876782869
Iter: 1353 loss: 0.000874567893
Iter: 1354 loss: 0.000872042088
Iter: 1355 loss: 0.000869324605
Iter: 1356 loss: 0.000869215291
Iter: 1357 loss: 0.000867369119
Iter: 1358 loss: 0.000885461748
Iter: 1359 loss: 0.00086730154
Iter: 1360 loss: 0.000865768292
Iter: 1361 loss: 0.000863250752
Iter: 1362 loss: 0.000863237889
Iter: 1363 loss: 0.000862016
Iter: 1364 loss: 0.000861502951
Iter: 1365 loss: 0.000859763473
Iter: 1366 loss: 0.0008648769
Iter: 1367 loss: 0.000859235472
Iter: 1368 loss: 0.000857604202
Iter: 1369 loss: 0.000863837777
Iter: 1370 loss: 0.000857205596
Iter: 1371 loss: 0.00085584505
Iter: 1372 loss: 0.000860629661
Iter: 1373 loss: 0.000855497085
Iter: 1374 loss: 0.000854042
Iter: 1375 loss: 0.000856610481
Iter: 1376 loss: 0.000853398698
Iter: 1377 loss: 0.000851743913
Iter: 1378 loss: 0.000853510224
Iter: 1379 loss: 0.000850836746
Iter: 1380 loss: 0.000849327887
Iter: 1381 loss: 0.000846395793
Iter: 1382 loss: 0.000907324662
Iter: 1383 loss: 0.000846379146
Iter: 1384 loss: 0.000841500645
Iter: 1385 loss: 0.000842523703
Iter: 1386 loss: 0.000837863074
Iter: 1387 loss: 0.00083293044
Iter: 1388 loss: 0.000851684716
Iter: 1389 loss: 0.000831755053
Iter: 1390 loss: 0.00082806818
Iter: 1391 loss: 0.000866451242
Iter: 1392 loss: 0.000827964861
Iter: 1393 loss: 0.000825048599
Iter: 1394 loss: 0.000843127433
Iter: 1395 loss: 0.000824703078
Iter: 1396 loss: 0.000822564878
Iter: 1397 loss: 0.000829310098
Iter: 1398 loss: 0.000821941067
Iter: 1399 loss: 0.000819778594
Iter: 1400 loss: 0.000843068876
Iter: 1401 loss: 0.000819737441
Iter: 1402 loss: 0.000818426255
Iter: 1403 loss: 0.000820892281
Iter: 1404 loss: 0.000817862
Iter: 1405 loss: 0.000816602842
Iter: 1406 loss: 0.000824204064
Iter: 1407 loss: 0.000816449407
Iter: 1408 loss: 0.000815410051
Iter: 1409 loss: 0.000818870612
Iter: 1410 loss: 0.000815118721
Iter: 1411 loss: 0.000814139785
Iter: 1412 loss: 0.000816001382
Iter: 1413 loss: 0.000813722378
Iter: 1414 loss: 0.000812764512
Iter: 1415 loss: 0.000810127123
Iter: 1416 loss: 0.000825866417
Iter: 1417 loss: 0.000809395
Iter: 1418 loss: 0.000806325348
Iter: 1419 loss: 0.000828944845
Iter: 1420 loss: 0.000806069525
Iter: 1421 loss: 0.000803765841
Iter: 1422 loss: 0.00080613466
Iter: 1423 loss: 0.000802480499
Iter: 1424 loss: 0.000800244627
Iter: 1425 loss: 0.000800918031
Iter: 1426 loss: 0.000798637688
Iter: 1427 loss: 0.000796537031
Iter: 1428 loss: 0.000825727358
Iter: 1429 loss: 0.000796531443
Iter: 1430 loss: 0.000794748892
Iter: 1431 loss: 0.00080018607
Iter: 1432 loss: 0.000794214546
Iter: 1433 loss: 0.000793283456
Iter: 1434 loss: 0.000793169136
Iter: 1435 loss: 0.000792357372
Iter: 1436 loss: 0.000793977873
Iter: 1437 loss: 0.000792021747
Iter: 1438 loss: 0.000791236176
Iter: 1439 loss: 0.000793656684
Iter: 1440 loss: 0.00079101
Iter: 1441 loss: 0.000790377846
Iter: 1442 loss: 0.000795297907
Iter: 1443 loss: 0.000790332328
Iter: 1444 loss: 0.000789855898
Iter: 1445 loss: 0.000790107646
Iter: 1446 loss: 0.000789538608
Iter: 1447 loss: 0.000788820675
Iter: 1448 loss: 0.000786722056
Iter: 1449 loss: 0.000794783351
Iter: 1450 loss: 0.000785834622
Iter: 1451 loss: 0.000783370342
Iter: 1452 loss: 0.000798065856
Iter: 1453 loss: 0.000783056254
Iter: 1454 loss: 0.000780663686
Iter: 1455 loss: 0.00078634
Iter: 1456 loss: 0.000779793132
Iter: 1457 loss: 0.000777995796
Iter: 1458 loss: 0.000780368573
Iter: 1459 loss: 0.000777077919
Iter: 1460 loss: 0.000775424647
Iter: 1461 loss: 0.000787572935
Iter: 1462 loss: 0.000775288034
Iter: 1463 loss: 0.000773766602
Iter: 1464 loss: 0.000782486517
Iter: 1465 loss: 0.000773557229
Iter: 1466 loss: 0.000772649655
Iter: 1467 loss: 0.000780055
Iter: 1468 loss: 0.000772590283
Iter: 1469 loss: 0.000771687133
Iter: 1470 loss: 0.00077615527
Iter: 1471 loss: 0.000771530322
Iter: 1472 loss: 0.00077087403
Iter: 1473 loss: 0.000772432308
Iter: 1474 loss: 0.000770635
Iter: 1475 loss: 0.000770027866
Iter: 1476 loss: 0.000772330444
Iter: 1477 loss: 0.000769881415
Iter: 1478 loss: 0.000769232924
Iter: 1479 loss: 0.000769641483
Iter: 1480 loss: 0.000768820231
Iter: 1481 loss: 0.000767835882
Iter: 1482 loss: 0.000765559089
Iter: 1483 loss: 0.000794654
Iter: 1484 loss: 0.000765394652
Iter: 1485 loss: 0.000763537711
Iter: 1486 loss: 0.000768424827
Iter: 1487 loss: 0.000762909185
Iter: 1488 loss: 0.000760685885
Iter: 1489 loss: 0.000766525278
Iter: 1490 loss: 0.000759932969
Iter: 1491 loss: 0.000758094655
Iter: 1492 loss: 0.000765785
Iter: 1493 loss: 0.000757702393
Iter: 1494 loss: 0.000756188063
Iter: 1495 loss: 0.000764929398
Iter: 1496 loss: 0.0007559894
Iter: 1497 loss: 0.000754461216
Iter: 1498 loss: 0.000761761679
Iter: 1499 loss: 0.000754184672
Iter: 1500 loss: 0.000753248692
Iter: 1501 loss: 0.000758457405
Iter: 1502 loss: 0.000753114466
Iter: 1503 loss: 0.000752201362
Iter: 1504 loss: 0.000757567352
Iter: 1505 loss: 0.000752077089
Iter: 1506 loss: 0.000751419342
Iter: 1507 loss: 0.000752381166
Iter: 1508 loss: 0.00075110083
Iter: 1509 loss: 0.000750291161
Iter: 1510 loss: 0.000753051485
Iter: 1511 loss: 0.000750073232
Iter: 1512 loss: 0.000749132829
Iter: 1513 loss: 0.000749447849
Iter: 1514 loss: 0.000748469844
Iter: 1515 loss: 0.000746848644
Iter: 1516 loss: 0.000743880635
Iter: 1517 loss: 0.000814554282
Iter: 1518 loss: 0.000743878889
Iter: 1519 loss: 0.000741706404
Iter: 1520 loss: 0.000748002436
Iter: 1521 loss: 0.000741029158
Iter: 1522 loss: 0.000738722156
Iter: 1523 loss: 0.000742755714
Iter: 1524 loss: 0.000737710623
Iter: 1525 loss: 0.000735370966
Iter: 1526 loss: 0.000742244243
Iter: 1527 loss: 0.00073463947
Iter: 1528 loss: 0.000732373446
Iter: 1529 loss: 0.000740258256
Iter: 1530 loss: 0.000731781765
Iter: 1531 loss: 0.000729509629
Iter: 1532 loss: 0.000749538536
Iter: 1533 loss: 0.000729393796
Iter: 1534 loss: 0.00072835444
Iter: 1535 loss: 0.000736795948
Iter: 1536 loss: 0.00072829111
Iter: 1537 loss: 0.000727441569
Iter: 1538 loss: 0.000731022796
Iter: 1539 loss: 0.000727259438
Iter: 1540 loss: 0.000726554892
Iter: 1541 loss: 0.000726874277
Iter: 1542 loss: 0.000726082362
Iter: 1543 loss: 0.000725082704
Iter: 1544 loss: 0.000729156833
Iter: 1545 loss: 0.000724858721
Iter: 1546 loss: 0.000723828154
Iter: 1547 loss: 0.000725885795
Iter: 1548 loss: 0.000723406964
Iter: 1549 loss: 0.000722091296
Iter: 1550 loss: 0.000720663462
Iter: 1551 loss: 0.0007204414
Iter: 1552 loss: 0.000719078875
Iter: 1553 loss: 0.000720271899
Iter: 1554 loss: 0.000718275551
Iter: 1555 loss: 0.000716519542
Iter: 1556 loss: 0.000722952536
Iter: 1557 loss: 0.000716083334
Iter: 1558 loss: 0.000714936
Iter: 1559 loss: 0.000720413926
Iter: 1560 loss: 0.000714727095
Iter: 1561 loss: 0.000713724527
Iter: 1562 loss: 0.00071400078
Iter: 1563 loss: 0.000712998095
Iter: 1564 loss: 0.000711504486
Iter: 1565 loss: 0.000723454403
Iter: 1566 loss: 0.000711402623
Iter: 1567 loss: 0.000710626482
Iter: 1568 loss: 0.000719655771
Iter: 1569 loss: 0.000710616
Iter: 1570 loss: 0.000710022869
Iter: 1571 loss: 0.000712400884
Iter: 1572 loss: 0.000709888176
Iter: 1573 loss: 0.000709359185
Iter: 1574 loss: 0.00070984097
Iter: 1575 loss: 0.000709057786
Iter: 1576 loss: 0.000708411506
Iter: 1577 loss: 0.000710510474
Iter: 1578 loss: 0.000708229258
Iter: 1579 loss: 0.00070750271
Iter: 1580 loss: 0.000708904059
Iter: 1581 loss: 0.000707199215
Iter: 1582 loss: 0.000706348
Iter: 1583 loss: 0.000705388491
Iter: 1584 loss: 0.000705259386
Iter: 1585 loss: 0.000704195176
Iter: 1586 loss: 0.000703498372
Iter: 1587 loss: 0.000703090336
Iter: 1588 loss: 0.000701347
Iter: 1589 loss: 0.000710723689
Iter: 1590 loss: 0.000701086537
Iter: 1591 loss: 0.000699929311
Iter: 1592 loss: 0.000703229336
Iter: 1593 loss: 0.000699559227
Iter: 1594 loss: 0.000698190881
Iter: 1595 loss: 0.000698545133
Iter: 1596 loss: 0.000697191863
Iter: 1597 loss: 0.000695334631
Iter: 1598 loss: 0.000714550493
Iter: 1599 loss: 0.000695280149
Iter: 1600 loss: 0.000694260234
Iter: 1601 loss: 0.000703420839
Iter: 1602 loss: 0.000694212504
Iter: 1603 loss: 0.000693323789
Iter: 1604 loss: 0.000696694246
Iter: 1605 loss: 0.00069310196
Iter: 1606 loss: 0.000692322559
Iter: 1607 loss: 0.000693593058
Iter: 1608 loss: 0.000691966852
Iter: 1609 loss: 0.000691090361
Iter: 1610 loss: 0.000693508249
Iter: 1611 loss: 0.000690801942
Iter: 1612 loss: 0.000689825742
Iter: 1613 loss: 0.000693850103
Iter: 1614 loss: 0.000689613458
Iter: 1615 loss: 0.000688760425
Iter: 1616 loss: 0.000687933411
Iter: 1617 loss: 0.000687740452
Iter: 1618 loss: 0.00068662368
Iter: 1619 loss: 0.000685371284
Iter: 1620 loss: 0.000685202074
Iter: 1621 loss: 0.000683257
Iter: 1622 loss: 0.000693723734
Iter: 1623 loss: 0.000682967
Iter: 1624 loss: 0.000681600417
Iter: 1625 loss: 0.000685216859
Iter: 1626 loss: 0.000681139762
Iter: 1627 loss: 0.000679539284
Iter: 1628 loss: 0.000680414494
Iter: 1629 loss: 0.000678487762
Iter: 1630 loss: 0.000676636701
Iter: 1631 loss: 0.000697600481
Iter: 1632 loss: 0.000676599855
Iter: 1633 loss: 0.000675441348
Iter: 1634 loss: 0.00068267918
Iter: 1635 loss: 0.000675314
Iter: 1636 loss: 0.000674214563
Iter: 1637 loss: 0.000677713542
Iter: 1638 loss: 0.000673899427
Iter: 1639 loss: 0.000673084345
Iter: 1640 loss: 0.000674327603
Iter: 1641 loss: 0.000672702445
Iter: 1642 loss: 0.000671737478
Iter: 1643 loss: 0.000674857933
Iter: 1644 loss: 0.000671465939
Iter: 1645 loss: 0.00067052152
Iter: 1646 loss: 0.000676832278
Iter: 1647 loss: 0.000670430716
Iter: 1648 loss: 0.000669729139
Iter: 1649 loss: 0.000669301371
Iter: 1650 loss: 0.000669014174
Iter: 1651 loss: 0.000668163
Iter: 1652 loss: 0.000667055254
Iter: 1653 loss: 0.000666985
Iter: 1654 loss: 0.000665656757
Iter: 1655 loss: 0.000672218797
Iter: 1656 loss: 0.000665432308
Iter: 1657 loss: 0.000664408901
Iter: 1658 loss: 0.000668764696
Iter: 1659 loss: 0.000664191553
Iter: 1660 loss: 0.000663220533
Iter: 1661 loss: 0.000663948129
Iter: 1662 loss: 0.000662624661
Iter: 1663 loss: 0.000661678147
Iter: 1664 loss: 0.000670958369
Iter: 1665 loss: 0.000661639846
Iter: 1666 loss: 0.000660994672
Iter: 1667 loss: 0.000665379164
Iter: 1668 loss: 0.000660931692
Iter: 1669 loss: 0.000660313235
Iter: 1670 loss: 0.000663520768
Iter: 1671 loss: 0.000660212419
Iter: 1672 loss: 0.000659823068
Iter: 1673 loss: 0.000659953803
Iter: 1674 loss: 0.000659548154
Iter: 1675 loss: 0.0006589556
Iter: 1676 loss: 0.000661876635
Iter: 1677 loss: 0.000658851932
Iter: 1678 loss: 0.000658368168
Iter: 1679 loss: 0.000662547
Iter: 1680 loss: 0.000658343313
Iter: 1681 loss: 0.000657972647
Iter: 1682 loss: 0.00065769197
Iter: 1683 loss: 0.00065757375
Iter: 1684 loss: 0.000657054712
Iter: 1685 loss: 0.000656361633
Iter: 1686 loss: 0.000656323042
Iter: 1687 loss: 0.00065535435
Iter: 1688 loss: 0.000657196622
Iter: 1689 loss: 0.000654944
Iter: 1690 loss: 0.000653888448
Iter: 1691 loss: 0.000660619233
Iter: 1692 loss: 0.000653765048
Iter: 1693 loss: 0.00065271632
Iter: 1694 loss: 0.000653662195
Iter: 1695 loss: 0.00065210904
Iter: 1696 loss: 0.00065087137
Iter: 1697 loss: 0.000657284516
Iter: 1698 loss: 0.000650672417
Iter: 1699 loss: 0.00064949831
Iter: 1700 loss: 0.000652352232
Iter: 1701 loss: 0.000649080612
Iter: 1702 loss: 0.000647849054
Iter: 1703 loss: 0.000666144
Iter: 1704 loss: 0.00064785016
Iter: 1705 loss: 0.000647361856
Iter: 1706 loss: 0.000646663422
Iter: 1707 loss: 0.000646642
Iter: 1708 loss: 0.000645453343
Iter: 1709 loss: 0.000651784823
Iter: 1710 loss: 0.000645267428
Iter: 1711 loss: 0.000644478365
Iter: 1712 loss: 0.000651353446
Iter: 1713 loss: 0.000644437678
Iter: 1714 loss: 0.000643757172
Iter: 1715 loss: 0.000642894534
Iter: 1716 loss: 0.000642825617
Iter: 1717 loss: 0.0006417
Iter: 1718 loss: 0.000640528044
Iter: 1719 loss: 0.000640316459
Iter: 1720 loss: 0.0006385874
Iter: 1721 loss: 0.000639663718
Iter: 1722 loss: 0.000637481455
Iter: 1723 loss: 0.000635327306
Iter: 1724 loss: 0.000647886423
Iter: 1725 loss: 0.000635035
Iter: 1726 loss: 0.00063306489
Iter: 1727 loss: 0.000636695419
Iter: 1728 loss: 0.000632218784
Iter: 1729 loss: 0.000630015449
Iter: 1730 loss: 0.000646091765
Iter: 1731 loss: 0.000629821327
Iter: 1732 loss: 0.000628080452
Iter: 1733 loss: 0.000639107137
Iter: 1734 loss: 0.000627888599
Iter: 1735 loss: 0.000626800407
Iter: 1736 loss: 0.0006267922
Iter: 1737 loss: 0.000626346096
Iter: 1738 loss: 0.000625425717
Iter: 1739 loss: 0.000641225139
Iter: 1740 loss: 0.000625404413
Iter: 1741 loss: 0.000623950153
Iter: 1742 loss: 0.000635415781
Iter: 1743 loss: 0.000623845728
Iter: 1744 loss: 0.000623062
Iter: 1745 loss: 0.000623022032
Iter: 1746 loss: 0.000622501713
Iter: 1747 loss: 0.000621676212
Iter: 1748 loss: 0.000621672254
Iter: 1749 loss: 0.000620528765
Iter: 1750 loss: 0.000620351348
Iter: 1751 loss: 0.000619557337
Iter: 1752 loss: 0.000617965939
Iter: 1753 loss: 0.000617200043
Iter: 1754 loss: 0.000616429083
Iter: 1755 loss: 0.00061451958
Iter: 1756 loss: 0.000639667327
Iter: 1757 loss: 0.000614509918
Iter: 1758 loss: 0.000612949952
Iter: 1759 loss: 0.000614761258
Iter: 1760 loss: 0.000612119562
Iter: 1761 loss: 0.000610548304
Iter: 1762 loss: 0.000617109472
Iter: 1763 loss: 0.000610205519
Iter: 1764 loss: 0.000609075068
Iter: 1765 loss: 0.000617340906
Iter: 1766 loss: 0.000608979841
Iter: 1767 loss: 0.000608298113
Iter: 1768 loss: 0.00060829107
Iter: 1769 loss: 0.000607936061
Iter: 1770 loss: 0.000606854563
Iter: 1771 loss: 0.000609834678
Iter: 1772 loss: 0.00060628145
Iter: 1773 loss: 0.00060459238
Iter: 1774 loss: 0.000626786263
Iter: 1775 loss: 0.000604579633
Iter: 1776 loss: 0.000604541798
Iter: 1777 loss: 0.000604107
Iter: 1778 loss: 0.000603856752
Iter: 1779 loss: 0.000603201042
Iter: 1780 loss: 0.00060818356
Iter: 1781 loss: 0.000603071181
Iter: 1782 loss: 0.00060178875
Iter: 1783 loss: 0.000602535438
Iter: 1784 loss: 0.000600959174
Iter: 1785 loss: 0.00059930759
Iter: 1786 loss: 0.000602048589
Iter: 1787 loss: 0.000598555838
Iter: 1788 loss: 0.000597291277
Iter: 1789 loss: 0.000597611477
Iter: 1790 loss: 0.000596370257
Iter: 1791 loss: 0.000594648882
Iter: 1792 loss: 0.000616071047
Iter: 1793 loss: 0.000594629091
Iter: 1794 loss: 0.000593639677
Iter: 1795 loss: 0.000601766456
Iter: 1796 loss: 0.000593576813
Iter: 1797 loss: 0.00059322489
Iter: 1798 loss: 0.000595995225
Iter: 1799 loss: 0.000593200326
Iter: 1800 loss: 0.000592969416
Iter: 1801 loss: 0.000592964469
Iter: 1802 loss: 0.000592815923
Iter: 1803 loss: 0.000592511089
Iter: 1804 loss: 0.00059804949
Iter: 1805 loss: 0.000592506607
Iter: 1806 loss: 0.000592267257
Iter: 1807 loss: 0.000592079072
Iter: 1808 loss: 0.000592004508
Iter: 1809 loss: 0.000591625518
Iter: 1810 loss: 0.000593944336
Iter: 1811 loss: 0.000591582968
Iter: 1812 loss: 0.000591197284
Iter: 1813 loss: 0.000590813812
Iter: 1814 loss: 0.000590734475
Iter: 1815 loss: 0.000590165844
Iter: 1816 loss: 0.000588978874
Iter: 1817 loss: 0.000610083109
Iter: 1818 loss: 0.000588954194
Iter: 1819 loss: 0.000587507151
Iter: 1820 loss: 0.000588279101
Iter: 1821 loss: 0.000586551265
Iter: 1822 loss: 0.000585291302
Iter: 1823 loss: 0.000583338551
Iter: 1824 loss: 0.000583307
Iter: 1825 loss: 0.000581730914
Iter: 1826 loss: 0.000581729109
Iter: 1827 loss: 0.000581053086
Iter: 1828 loss: 0.000582133303
Iter: 1829 loss: 0.000580741558
Iter: 1830 loss: 0.000579988933
Iter: 1831 loss: 0.00058586488
Iter: 1832 loss: 0.00057993317
Iter: 1833 loss: 0.000579563
Iter: 1834 loss: 0.000579473
Iter: 1835 loss: 0.000579019426
Iter: 1836 loss: 0.000578718202
Iter: 1837 loss: 0.00057854777
Iter: 1838 loss: 0.000577754749
Iter: 1839 loss: 0.000577031053
Iter: 1840 loss: 0.000576835184
Iter: 1841 loss: 0.000576176855
Iter: 1842 loss: 0.000576014048
Iter: 1843 loss: 0.0005754382
Iter: 1844 loss: 0.000575415732
Iter: 1845 loss: 0.000574974692
Iter: 1846 loss: 0.000574202568
Iter: 1847 loss: 0.000572908146
Iter: 1848 loss: 0.000572903315
Iter: 1849 loss: 0.000571979966
Iter: 1850 loss: 0.0005815677
Iter: 1851 loss: 0.000571958197
Iter: 1852 loss: 0.000571338751
Iter: 1853 loss: 0.000570982287
Iter: 1854 loss: 0.000570719829
Iter: 1855 loss: 0.000569805619
Iter: 1856 loss: 0.000572184334
Iter: 1857 loss: 0.000569495547
Iter: 1858 loss: 0.000568696414
Iter: 1859 loss: 0.000576588092
Iter: 1860 loss: 0.000568669115
Iter: 1861 loss: 0.000567832962
Iter: 1862 loss: 0.000566223112
Iter: 1863 loss: 0.000599795254
Iter: 1864 loss: 0.000566213101
Iter: 1865 loss: 0.000566570554
Iter: 1866 loss: 0.000565426191
Iter: 1867 loss: 0.000564634567
Iter: 1868 loss: 0.000566572475
Iter: 1869 loss: 0.000564349699
Iter: 1870 loss: 0.000563817797
Iter: 1871 loss: 0.000563705165
Iter: 1872 loss: 0.000563352834
Iter: 1873 loss: 0.000563025
Iter: 1874 loss: 0.000563007547
Iter: 1875 loss: 0.00056267163
Iter: 1876 loss: 0.000562518602
Iter: 1877 loss: 0.000562351081
Iter: 1878 loss: 0.000561818422
Iter: 1879 loss: 0.000562053581
Iter: 1880 loss: 0.000561453344
Iter: 1881 loss: 0.000560934
Iter: 1882 loss: 0.000563496724
Iter: 1883 loss: 0.000560841057
Iter: 1884 loss: 0.000560239365
Iter: 1885 loss: 0.000559823238
Iter: 1886 loss: 0.000559605425
Iter: 1887 loss: 0.000558706757
Iter: 1888 loss: 0.000559010718
Iter: 1889 loss: 0.000558069441
Iter: 1890 loss: 0.000556997606
Iter: 1891 loss: 0.000560166198
Iter: 1892 loss: 0.000556670479
Iter: 1893 loss: 0.000555764476
Iter: 1894 loss: 0.000566188537
Iter: 1895 loss: 0.000555748644
Iter: 1896 loss: 0.000555313833
Iter: 1897 loss: 0.000558196334
Iter: 1898 loss: 0.000555271225
Iter: 1899 loss: 0.000554779137
Iter: 1900 loss: 0.000557053485
Iter: 1901 loss: 0.000554685597
Iter: 1902 loss: 0.000554358
Iter: 1903 loss: 0.000554203056
Iter: 1904 loss: 0.000554044207
Iter: 1905 loss: 0.000553695601
Iter: 1906 loss: 0.000556635
Iter: 1907 loss: 0.000553678
Iter: 1908 loss: 0.000553268532
Iter: 1909 loss: 0.000553371268
Iter: 1910 loss: 0.000552971847
Iter: 1911 loss: 0.000552518177
Iter: 1912 loss: 0.000552043377
Iter: 1913 loss: 0.000551958219
Iter: 1914 loss: 0.000551146863
Iter: 1915 loss: 0.000552117592
Iter: 1916 loss: 0.00055072
Iter: 1917 loss: 0.000549829507
Iter: 1918 loss: 0.00055572018
Iter: 1919 loss: 0.000549735851
Iter: 1920 loss: 0.000549266289
Iter: 1921 loss: 0.000548664422
Iter: 1922 loss: 0.000548623153
Iter: 1923 loss: 0.000547694683
Iter: 1924 loss: 0.000553419697
Iter: 1925 loss: 0.000547584
Iter: 1926 loss: 0.000547159347
Iter: 1927 loss: 0.000553682
Iter: 1928 loss: 0.000547158532
Iter: 1929 loss: 0.000546931231
Iter: 1930 loss: 0.000547684031
Iter: 1931 loss: 0.000546867203
Iter: 1932 loss: 0.000546588562
Iter: 1933 loss: 0.000548561628
Iter: 1934 loss: 0.000546563766
Iter: 1935 loss: 0.000546309049
Iter: 1936 loss: 0.000546159921
Iter: 1937 loss: 0.000546052586
Iter: 1938 loss: 0.000545712071
Iter: 1939 loss: 0.00054720859
Iter: 1940 loss: 0.000545647694
Iter: 1941 loss: 0.000545207935
Iter: 1942 loss: 0.000546025287
Iter: 1943 loss: 0.000545021845
Iter: 1944 loss: 0.000544690469
Iter: 1945 loss: 0.000544523937
Iter: 1946 loss: 0.000544369104
Iter: 1947 loss: 0.000543879345
Iter: 1948 loss: 0.000544201816
Iter: 1949 loss: 0.000543567468
Iter: 1950 loss: 0.000542986556
Iter: 1951 loss: 0.000546214171
Iter: 1952 loss: 0.000542901224
Iter: 1953 loss: 0.000542352791
Iter: 1954 loss: 0.000541239395
Iter: 1955 loss: 0.000561695313
Iter: 1956 loss: 0.0005412217
Iter: 1957 loss: 0.000539980887
Iter: 1958 loss: 0.000547444157
Iter: 1959 loss: 0.00053982751
Iter: 1960 loss: 0.000538888504
Iter: 1961 loss: 0.000546992058
Iter: 1962 loss: 0.000538835069
Iter: 1963 loss: 0.00053817837
Iter: 1964 loss: 0.000544547045
Iter: 1965 loss: 0.000538154389
Iter: 1966 loss: 0.000537707703
Iter: 1967 loss: 0.000542539521
Iter: 1968 loss: 0.000537696411
Iter: 1969 loss: 0.00053740351
Iter: 1970 loss: 0.000537472893
Iter: 1971 loss: 0.000537191052
Iter: 1972 loss: 0.000536859967
Iter: 1973 loss: 0.000537257874
Iter: 1974 loss: 0.000536684529
Iter: 1975 loss: 0.000536155188
Iter: 1976 loss: 0.000537966494
Iter: 1977 loss: 0.000536014035
Iter: 1978 loss: 0.000535632949
Iter: 1979 loss: 0.000535080733
Iter: 1980 loss: 0.000535065483
Iter: 1981 loss: 0.000534187711
Iter: 1982 loss: 0.00053583
Iter: 1983 loss: 0.000533815648
Iter: 1984 loss: 0.000532893231
Iter: 1985 loss: 0.00053881557
Iter: 1986 loss: 0.000532789854
Iter: 1987 loss: 0.000531932921
Iter: 1988 loss: 0.000530393212
Iter: 1989 loss: 0.000567731564
Iter: 1990 loss: 0.000530392746
Iter: 1991 loss: 0.000528725097
Iter: 1992 loss: 0.000536342675
Iter: 1993 loss: 0.000528402743
Iter: 1994 loss: 0.000527328812
Iter: 1995 loss: 0.000540579
Iter: 1996 loss: 0.000527318916
Iter: 1997 loss: 0.0005266933
Iter: 1998 loss: 0.000533760933
Iter: 1999 loss: 0.000526682183
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3
+ date
Tue Oct 27 16:34:20 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 0 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662487400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466249b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4687f5eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4687f01730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46624c1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46624c1a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4687f01268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662429840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662429510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46623da048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46623f80d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466239fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466233b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662371268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466236e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662385840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46622bcb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46622bcd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46622b1ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662258b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662228ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662228268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662228158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466218e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466218e598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46621a2c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662161d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466218e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662126488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46620bc1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46620be620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46620802f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4662093840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466203bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f46620702f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f466200fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.041539669
Iter: 2 loss: 2.69589972
Iter: 3 loss: 2.68700314
Iter: 4 loss: 1.91584468
Iter: 5 loss: 1.90878177
Iter: 6 loss: 1.40017927
Iter: 7 loss: 1.39324427
Iter: 8 loss: 1.02559388
Iter: 9 loss: 1.01790226
Iter: 10 loss: 0.741382778
Iter: 11 loss: 0.732201457
Iter: 12 loss: 0.515070438
Iter: 13 loss: 0.503095031
Iter: 14 loss: 0.330637306
Iter: 15 loss: 0.315738499
Iter: 16 loss: 0.188027591
Iter: 17 loss: 0.172555536
Iter: 18 loss: 0.0899517238
Iter: 19 loss: 0.0783682913
Iter: 20 loss: 0.03731253
Iter: 21 loss: 0.0328532197
Iter: 22 loss: 0.0289996304
Iter: 23 loss: 0.0180097111
Iter: 24 loss: 1834.24243
Iter: 25 loss: 0.0180096421
Iter: 26 loss: 0.0222826116
Iter: 27 loss: 0.0170153361
Iter: 28 loss: 0.0188981295
Iter: 29 loss: 0.0156254657
Iter: 30 loss: 0.0638207197
Iter: 31 loss: 0.0153868385
Iter: 32 loss: 0.0117671024
Iter: 33 loss: 0.0117684556
Iter: 34 loss: 0.0094700912
Iter: 35 loss: 0.01322712
Iter: 36 loss: 0.00899156183
Iter: 37 loss: 0.00852380507
Iter: 38 loss: 0.0288807787
Iter: 39 loss: 0.0085204076
Iter: 40 loss: 0.00817503
Iter: 41 loss: 0.0115791485
Iter: 42 loss: 0.00814621616
Iter: 43 loss: 0.00757623
Iter: 44 loss: 0.00725770602
Iter: 45 loss: 0.00701459963
Iter: 46 loss: 0.00622429047
Iter: 47 loss: 0.0106368111
Iter: 48 loss: 0.00618958659
Iter: 49 loss: 0.00583778275
Iter: 50 loss: 0.00543068396
Iter: 51 loss: 0.00536485482
Iter: 52 loss: 0.00502242753
Iter: 53 loss: 0.00507831294
Iter: 54 loss: 0.00479265116
Iter: 55 loss: 0.00443433132
Iter: 56 loss: 0.0044033872
Iter: 57 loss: 0.004170042
Iter: 58 loss: 0.00384593802
Iter: 59 loss: 0.00522734504
Iter: 60 loss: 0.00375835085
Iter: 61 loss: 0.00359275
Iter: 62 loss: 0.00382942962
Iter: 63 loss: 0.0035136221
Iter: 64 loss: 0.0032765849
Iter: 65 loss: 0.00464469381
Iter: 66 loss: 0.00323724607
Iter: 67 loss: 0.00304838782
Iter: 68 loss: 0.00388980983
Iter: 69 loss: 0.00301989447
Iter: 70 loss: 0.0029041837
Iter: 71 loss: 0.002822479
Iter: 72 loss: 0.00277749449
Iter: 73 loss: 0.00268731918
Iter: 74 loss: 0.00328289741
Iter: 75 loss: 0.00267918967
Iter: 76 loss: 0.00254723616
Iter: 77 loss: 0.00298390444
Iter: 78 loss: 0.00251470064
Iter: 79 loss: 0.00239354651
Iter: 80 loss: 0.0024004681
Iter: 81 loss: 0.00230008317
Iter: 82 loss: 0.00216999324
Iter: 83 loss: 0.00225546351
Iter: 84 loss: 0.00208849832
Iter: 85 loss: 0.00209540594
Iter: 86 loss: 0.00203165854
Iter: 87 loss: 0.00197268138
Iter: 88 loss: 0.00200771377
Iter: 89 loss: 0.00193234824
Iter: 90 loss: 0.00189377228
Iter: 91 loss: 0.00185085798
Iter: 92 loss: 0.00184521079
Iter: 93 loss: 0.00177300093
Iter: 94 loss: 0.00198504119
Iter: 95 loss: 0.00175062637
Iter: 96 loss: 0.00166369905
Iter: 97 loss: 0.00183678069
Iter: 98 loss: 0.00162940635
Iter: 99 loss: 0.00156349153
Iter: 100 loss: 0.00197382458
Iter: 101 loss: 0.00155803049
Iter: 102 loss: 0.00151315145
Iter: 103 loss: 0.00201371382
Iter: 104 loss: 0.00151157088
Iter: 105 loss: 0.00147808308
Iter: 106 loss: 0.0016529311
Iter: 107 loss: 0.00147357094
Iter: 108 loss: 0.00143680221
Iter: 109 loss: 0.001456636
Iter: 110 loss: 0.00141251599
Iter: 111 loss: 0.00137169112
Iter: 112 loss: 0.0013451844
Iter: 113 loss: 0.0013301929
Iter: 114 loss: 0.00127733871
Iter: 115 loss: 0.00165620656
Iter: 116 loss: 0.00127212098
Iter: 117 loss: 0.00122790202
Iter: 118 loss: 0.00136739062
Iter: 119 loss: 0.00121679029
Iter: 120 loss: 0.00118196046
Iter: 121 loss: 0.00156566594
Iter: 122 loss: 0.00118071074
Iter: 123 loss: 0.00116431457
Iter: 124 loss: 0.00114387926
Iter: 125 loss: 0.00114229787
Iter: 126 loss: 0.00111456821
Iter: 127 loss: 0.00110216986
Iter: 128 loss: 0.00108799944
Iter: 129 loss: 0.00105612539
Iter: 130 loss: 0.0010563652
Iter: 131 loss: 0.00103084813
Iter: 132 loss: 0.000997280702
Iter: 133 loss: 0.00104142434
Iter: 134 loss: 0.000980023062
Iter: 135 loss: 0.00094882655
Iter: 136 loss: 0.00109540485
Iter: 137 loss: 0.000943116378
Iter: 138 loss: 0.000923015643
Iter: 139 loss: 0.000996292103
Iter: 140 loss: 0.000917813217
Iter: 141 loss: 0.000902462692
Iter: 142 loss: 0.000909767346
Iter: 143 loss: 0.000892108481
Iter: 144 loss: 0.000872191857
Iter: 145 loss: 0.000906087866
Iter: 146 loss: 0.000863611232
Iter: 147 loss: 0.000848471071
Iter: 148 loss: 0.00087074918
Iter: 149 loss: 0.000840843422
Iter: 150 loss: 0.000833848
Iter: 151 loss: 0.000856947037
Iter: 152 loss: 0.000832058606
Iter: 153 loss: 0.000827538955
Iter: 154 loss: 0.000817404827
Iter: 155 loss: 0.000958779361
Iter: 156 loss: 0.00081684615
Iter: 157 loss: 0.000806438387
Iter: 158 loss: 0.00080855313
Iter: 159 loss: 0.00079869054
Iter: 160 loss: 0.000784910633
Iter: 161 loss: 0.00089032657
Iter: 162 loss: 0.00078398909
Iter: 163 loss: 0.000773241743
Iter: 164 loss: 0.000811088365
Iter: 165 loss: 0.000770334213
Iter: 166 loss: 0.000763071934
Iter: 167 loss: 0.000752677734
Iter: 168 loss: 0.000752333552
Iter: 169 loss: 0.000741833646
Iter: 170 loss: 0.00088688184
Iter: 171 loss: 0.000741802738
Iter: 172 loss: 0.000733193301
Iter: 173 loss: 0.000742179924
Iter: 174 loss: 0.000728612125
Iter: 175 loss: 0.000717267278
Iter: 176 loss: 0.000747423619
Iter: 177 loss: 0.000713381858
Iter: 178 loss: 0.000704987207
Iter: 179 loss: 0.000708674197
Iter: 180 loss: 0.00069929345
Iter: 181 loss: 0.000696032541
Iter: 182 loss: 0.000692878501
Iter: 183 loss: 0.000687698252
Iter: 184 loss: 0.000747671467
Iter: 185 loss: 0.000687652384
Iter: 186 loss: 0.000685354404
Iter: 187 loss: 0.000680349476
Iter: 188 loss: 0.000757652
Iter: 189 loss: 0.000680152443
Iter: 190 loss: 0.000673319213
Iter: 191 loss: 0.000669731
Iter: 192 loss: 0.000666619278
Iter: 193 loss: 0.000658706878
Iter: 194 loss: 0.000735195063
Iter: 195 loss: 0.000658446283
Iter: 196 loss: 0.000653237395
Iter: 197 loss: 0.000658503792
Iter: 198 loss: 0.000650255766
Iter: 199 loss: 0.000644765794
Iter: 200 loss: 0.000654791598
Iter: 201 loss: 0.00064243027
Iter: 202 loss: 0.000638108409
Iter: 203 loss: 0.000632980373
Iter: 204 loss: 0.000632443174
Iter: 205 loss: 0.000624344568
Iter: 206 loss: 0.000659238896
Iter: 207 loss: 0.000622708118
Iter: 208 loss: 0.000616092701
Iter: 209 loss: 0.000658213394
Iter: 210 loss: 0.000615315279
Iter: 211 loss: 0.000611929107
Iter: 212 loss: 0.000616698642
Iter: 213 loss: 0.000610288465
Iter: 214 loss: 0.000606531627
Iter: 215 loss: 0.000613009383
Iter: 216 loss: 0.000604864326
Iter: 217 loss: 0.000601692707
Iter: 218 loss: 0.000646830536
Iter: 219 loss: 0.000601692765
Iter: 220 loss: 0.000598472951
Iter: 221 loss: 0.00060145295
Iter: 222 loss: 0.000596580678
Iter: 223 loss: 0.000593914127
Iter: 224 loss: 0.000588053314
Iter: 225 loss: 0.000672839466
Iter: 226 loss: 0.000587785384
Iter: 227 loss: 0.000582055771
Iter: 228 loss: 0.000604949309
Iter: 229 loss: 0.000580788648
Iter: 230 loss: 0.000577226223
Iter: 231 loss: 0.000577195
Iter: 232 loss: 0.000573962869
Iter: 233 loss: 0.000581324741
Iter: 234 loss: 0.000572780904
Iter: 235 loss: 0.000569768425
Iter: 236 loss: 0.000569641415
Iter: 237 loss: 0.000567325449
Iter: 238 loss: 0.000563533744
Iter: 239 loss: 0.000562030473
Iter: 240 loss: 0.0005600148
Iter: 241 loss: 0.000555567
Iter: 242 loss: 0.000555564475
Iter: 243 loss: 0.000551993959
Iter: 244 loss: 0.000555229723
Iter: 245 loss: 0.000549948949
Iter: 246 loss: 0.00054545264
Iter: 247 loss: 0.000580942
Iter: 248 loss: 0.000545130577
Iter: 249 loss: 0.000542673108
Iter: 250 loss: 0.000538714288
Iter: 251 loss: 0.000538688619
Iter: 252 loss: 0.000538396242
Iter: 253 loss: 0.000536370615
Iter: 254 loss: 0.000534475956
Iter: 255 loss: 0.000531968079
Iter: 256 loss: 0.000531823782
Iter: 257 loss: 0.000528467237
Iter: 258 loss: 0.000526206451
Iter: 259 loss: 0.000524984032
Iter: 260 loss: 0.000521170441
Iter: 261 loss: 0.000528522651
Iter: 262 loss: 0.00051953987
Iter: 263 loss: 0.000516156084
Iter: 264 loss: 0.000516326283
Iter: 265 loss: 0.000513498439
Iter: 266 loss: 0.000509020465
Iter: 267 loss: 0.000532566337
Iter: 268 loss: 0.000508337456
Iter: 269 loss: 0.000505462813
Iter: 270 loss: 0.000500637339
Iter: 271 loss: 0.000500626164
Iter: 272 loss: 0.000497656933
Iter: 273 loss: 0.00049755146
Iter: 274 loss: 0.000495246961
Iter: 275 loss: 0.000495247
Iter: 276 loss: 0.000493907195
Iter: 277 loss: 0.00049510895
Iter: 278 loss: 0.000493135245
Iter: 279 loss: 0.000491640938
Iter: 280 loss: 0.000490451814
Iter: 281 loss: 0.000489996455
Iter: 282 loss: 0.000488348887
Iter: 283 loss: 0.000488349528
Iter: 284 loss: 0.000486805919
Iter: 285 loss: 0.000491520856
Iter: 286 loss: 0.00048633205
Iter: 287 loss: 0.000484796561
Iter: 288 loss: 0.000482835632
Iter: 289 loss: 0.000482695497
Iter: 290 loss: 0.000479967828
Iter: 291 loss: 0.000492252468
Iter: 292 loss: 0.000479428563
Iter: 293 loss: 0.000477666094
Iter: 294 loss: 0.000479572074
Iter: 295 loss: 0.000476714631
Iter: 296 loss: 0.000474077329
Iter: 297 loss: 0.000474153552
Iter: 298 loss: 0.000471992709
Iter: 299 loss: 0.000469176215
Iter: 300 loss: 0.00047196087
Iter: 301 loss: 0.000467593869
Iter: 302 loss: 0.000464670768
Iter: 303 loss: 0.000482189
Iter: 304 loss: 0.00046431442
Iter: 305 loss: 0.000461657939
Iter: 306 loss: 0.000488779799
Iter: 307 loss: 0.000461572781
Iter: 308 loss: 0.000460158684
Iter: 309 loss: 0.00046015007
Iter: 310 loss: 0.000459273811
Iter: 311 loss: 0.000457882561
Iter: 312 loss: 0.000457870396
Iter: 313 loss: 0.000456267211
Iter: 314 loss: 0.000460733136
Iter: 315 loss: 0.000455770292
Iter: 316 loss: 0.000454433321
Iter: 317 loss: 0.000466694852
Iter: 318 loss: 0.000454368826
Iter: 319 loss: 0.00045350875
Iter: 320 loss: 0.000453152141
Iter: 321 loss: 0.000452702778
Iter: 322 loss: 0.000451129279
Iter: 323 loss: 0.000452408916
Iter: 324 loss: 0.000450188847
Iter: 325 loss: 0.000448665
Iter: 326 loss: 0.000449824642
Iter: 327 loss: 0.00044774136
Iter: 328 loss: 0.000446202466
Iter: 329 loss: 0.000451976841
Iter: 330 loss: 0.000445823302
Iter: 331 loss: 0.000444075675
Iter: 332 loss: 0.000444487319
Iter: 333 loss: 0.000442791847
Iter: 334 loss: 0.000440909411
Iter: 335 loss: 0.000442975259
Iter: 336 loss: 0.000439892523
Iter: 337 loss: 0.000437099836
Iter: 338 loss: 0.000445967133
Iter: 339 loss: 0.000436301169
Iter: 340 loss: 0.000433881738
Iter: 341 loss: 0.000434953894
Iter: 342 loss: 0.000432241
Iter: 343 loss: 0.000430562883
Iter: 344 loss: 0.000430561893
Iter: 345 loss: 0.00042921718
Iter: 346 loss: 0.000434755522
Iter: 347 loss: 0.000428920204
Iter: 348 loss: 0.000428505678
Iter: 349 loss: 0.00042816269
Iter: 350 loss: 0.00042767034
Iter: 351 loss: 0.000426258834
Iter: 352 loss: 0.000432387751
Iter: 353 loss: 0.000425718783
Iter: 354 loss: 0.000424286729
Iter: 355 loss: 0.000423668534
Iter: 356 loss: 0.000422935816
Iter: 357 loss: 0.000421440782
Iter: 358 loss: 0.000431429391
Iter: 359 loss: 0.000421283941
Iter: 360 loss: 0.000420030381
Iter: 361 loss: 0.000421349716
Iter: 362 loss: 0.000419338176
Iter: 363 loss: 0.000418058422
Iter: 364 loss: 0.000416103692
Iter: 365 loss: 0.000416071765
Iter: 366 loss: 0.000414168346
Iter: 367 loss: 0.000425277191
Iter: 368 loss: 0.000413926376
Iter: 369 loss: 0.00041224662
Iter: 370 loss: 0.00041243239
Iter: 371 loss: 0.000410950597
Iter: 372 loss: 0.000409376691
Iter: 373 loss: 0.000413382222
Iter: 374 loss: 0.00040883632
Iter: 375 loss: 0.000407657324
Iter: 376 loss: 0.000406288949
Iter: 377 loss: 0.00040613045
Iter: 378 loss: 0.000404551451
Iter: 379 loss: 0.000409517321
Iter: 380 loss: 0.000404093298
Iter: 381 loss: 0.000403136073
Iter: 382 loss: 0.000401161378
Iter: 383 loss: 0.000435568596
Iter: 384 loss: 0.000401119469
Iter: 385 loss: 0.000399109616
Iter: 386 loss: 0.000411587
Iter: 387 loss: 0.00039887469
Iter: 388 loss: 0.00039803487
Iter: 389 loss: 0.000397881609
Iter: 390 loss: 0.000397029857
Iter: 391 loss: 0.000402541133
Iter: 392 loss: 0.000396942545
Iter: 393 loss: 0.00039651664
Iter: 394 loss: 0.000395313255
Iter: 395 loss: 0.000401218102
Iter: 396 loss: 0.000394901901
Iter: 397 loss: 0.000393576047
Iter: 398 loss: 0.000400825462
Iter: 399 loss: 0.000393381983
Iter: 400 loss: 0.000392146176
Iter: 401 loss: 0.000398112927
Iter: 402 loss: 0.000391925307
Iter: 403 loss: 0.000391143549
Iter: 404 loss: 0.000390370435
Iter: 405 loss: 0.000390205445
Iter: 406 loss: 0.00038874906
Iter: 407 loss: 0.000393553375
Iter: 408 loss: 0.000388348242
Iter: 409 loss: 0.000387423846
Iter: 410 loss: 0.000393351831
Iter: 411 loss: 0.000387320266
Iter: 412 loss: 0.000386494183
Iter: 413 loss: 0.00039020821
Iter: 414 loss: 0.000386335771
Iter: 415 loss: 0.000385577674
Iter: 416 loss: 0.000386341213
Iter: 417 loss: 0.000385150721
Iter: 418 loss: 0.000384260522
Iter: 419 loss: 0.000386291067
Iter: 420 loss: 0.00038392737
Iter: 421 loss: 0.000383057311
Iter: 422 loss: 0.000382861705
Iter: 423 loss: 0.00038229645
Iter: 424 loss: 0.000381247315
Iter: 425 loss: 0.00039241038
Iter: 426 loss: 0.000381224963
Iter: 427 loss: 0.000380306708
Iter: 428 loss: 0.000393086404
Iter: 429 loss: 0.000380303594
Iter: 430 loss: 0.000379926292
Iter: 431 loss: 0.000379073957
Iter: 432 loss: 0.000390566362
Iter: 433 loss: 0.000379023899
Iter: 434 loss: 0.000377895805
Iter: 435 loss: 0.000375991804
Iter: 436 loss: 0.000375988282
Iter: 437 loss: 0.000374689494
Iter: 438 loss: 0.000394480594
Iter: 439 loss: 0.000374689233
Iter: 440 loss: 0.000373386662
Iter: 441 loss: 0.000377989025
Iter: 442 loss: 0.000373055402
Iter: 443 loss: 0.000372179842
Iter: 444 loss: 0.000374231575
Iter: 445 loss: 0.000371856615
Iter: 446 loss: 0.000370705209
Iter: 447 loss: 0.000374911557
Iter: 448 loss: 0.000370423659
Iter: 449 loss: 0.000369474787
Iter: 450 loss: 0.000371720816
Iter: 451 loss: 0.000369125162
Iter: 452 loss: 0.000368062843
Iter: 453 loss: 0.000367695582
Iter: 454 loss: 0.000367092784
Iter: 455 loss: 0.000365874032
Iter: 456 loss: 0.000377742574
Iter: 457 loss: 0.00036582828
Iter: 458 loss: 0.000364999985
Iter: 459 loss: 0.000366270571
Iter: 460 loss: 0.000364611158
Iter: 461 loss: 0.000364753709
Iter: 462 loss: 0.000364287291
Iter: 463 loss: 0.000364000094
Iter: 464 loss: 0.000363130879
Iter: 465 loss: 0.000365483051
Iter: 466 loss: 0.000362663268
Iter: 467 loss: 0.000361477258
Iter: 468 loss: 0.000368682
Iter: 469 loss: 0.000361332437
Iter: 470 loss: 0.000360521779
Iter: 471 loss: 0.000359552505
Iter: 472 loss: 0.00035945361
Iter: 473 loss: 0.000358289253
Iter: 474 loss: 0.00036770213
Iter: 475 loss: 0.000358212448
Iter: 476 loss: 0.000357088808
Iter: 477 loss: 0.000359532278
Iter: 478 loss: 0.000356649456
Iter: 479 loss: 0.000355830649
Iter: 480 loss: 0.000355198019
Iter: 481 loss: 0.000354938704
Iter: 482 loss: 0.000354093121
Iter: 483 loss: 0.000360233942
Iter: 484 loss: 0.000354019227
Iter: 485 loss: 0.000353434094
Iter: 486 loss: 0.000352837407
Iter: 487 loss: 0.000352724863
Iter: 488 loss: 0.000351616764
Iter: 489 loss: 0.000358736608
Iter: 490 loss: 0.000351494877
Iter: 491 loss: 0.00035045
Iter: 492 loss: 0.0003621449
Iter: 493 loss: 0.000350432238
Iter: 494 loss: 0.000349986018
Iter: 495 loss: 0.000353396754
Iter: 496 loss: 0.000349951093
Iter: 497 loss: 0.000349394628
Iter: 498 loss: 0.000348665199
Iter: 499 loss: 0.000348620408
Iter: 500 loss: 0.000347836
Iter: 501 loss: 0.000347880938
Iter: 502 loss: 0.000347222289
Iter: 503 loss: 0.000346191926
Iter: 504 loss: 0.000347036868
Iter: 505 loss: 0.000345575274
Iter: 506 loss: 0.000344398577
Iter: 507 loss: 0.000348063186
Iter: 508 loss: 0.000344056869
Iter: 509 loss: 0.000343064021
Iter: 510 loss: 0.000350394897
Iter: 511 loss: 0.000342982
Iter: 512 loss: 0.000341993291
Iter: 513 loss: 0.000341953884
Iter: 514 loss: 0.000341191248
Iter: 515 loss: 0.00034033577
Iter: 516 loss: 0.000340335653
Iter: 517 loss: 0.000339642691
Iter: 518 loss: 0.000338863
Iter: 519 loss: 0.000338758546
Iter: 520 loss: 0.000337504141
Iter: 521 loss: 0.00033865677
Iter: 522 loss: 0.00033677998
Iter: 523 loss: 0.000335671
Iter: 524 loss: 0.000340238417
Iter: 525 loss: 0.000335431134
Iter: 526 loss: 0.00033538742
Iter: 527 loss: 0.000335040444
Iter: 528 loss: 0.000334634562
Iter: 529 loss: 0.000334373268
Iter: 530 loss: 0.000334217038
Iter: 531 loss: 0.000333637348
Iter: 532 loss: 0.000333657372
Iter: 533 loss: 0.000333177653
Iter: 534 loss: 0.000332403812
Iter: 535 loss: 0.000332423631
Iter: 536 loss: 0.000331791176
Iter: 537 loss: 0.000330853451
Iter: 538 loss: 0.000333670352
Iter: 539 loss: 0.000330573064
Iter: 540 loss: 0.000329503207
Iter: 541 loss: 0.000333191274
Iter: 542 loss: 0.000329220173
Iter: 543 loss: 0.000328399561
Iter: 544 loss: 0.00032769845
Iter: 545 loss: 0.00032747307
Iter: 546 loss: 0.00032685016
Iter: 547 loss: 0.000326684327
Iter: 548 loss: 0.000326139707
Iter: 549 loss: 0.000326891488
Iter: 550 loss: 0.000325870729
Iter: 551 loss: 0.000324945984
Iter: 552 loss: 0.000326049689
Iter: 553 loss: 0.000324457069
Iter: 554 loss: 0.000323805696
Iter: 555 loss: 0.000322871434
Iter: 556 loss: 0.000322841923
Iter: 557 loss: 0.000322709209
Iter: 558 loss: 0.000322382781
Iter: 559 loss: 0.000321986765
Iter: 560 loss: 0.000321365223
Iter: 561 loss: 0.000321358733
Iter: 562 loss: 0.000320507766
Iter: 563 loss: 0.000324910681
Iter: 564 loss: 0.000320368825
Iter: 565 loss: 0.00031971492
Iter: 566 loss: 0.000318970095
Iter: 567 loss: 0.000318878156
Iter: 568 loss: 0.000317848491
Iter: 569 loss: 0.000321565691
Iter: 570 loss: 0.000317586178
Iter: 571 loss: 0.000316766673
Iter: 572 loss: 0.000316891063
Iter: 573 loss: 0.000316146557
Iter: 574 loss: 0.000315117359
Iter: 575 loss: 0.000318300095
Iter: 576 loss: 0.000314817356
Iter: 577 loss: 0.000314160658
Iter: 578 loss: 0.000313044788
Iter: 579 loss: 0.000313043129
Iter: 580 loss: 0.000312526565
Iter: 581 loss: 0.00031227633
Iter: 582 loss: 0.000311556214
Iter: 583 loss: 0.000312042946
Iter: 584 loss: 0.000311099895
Iter: 585 loss: 0.000310618372
Iter: 586 loss: 0.000310847623
Iter: 587 loss: 0.000310296658
Iter: 588 loss: 0.000309780822
Iter: 589 loss: 0.000310022966
Iter: 590 loss: 0.00030943047
Iter: 591 loss: 0.000308858085
Iter: 592 loss: 0.000309714029
Iter: 593 loss: 0.000308587274
Iter: 594 loss: 0.000307856273
Iter: 595 loss: 0.000308349729
Iter: 596 loss: 0.000307394948
Iter: 597 loss: 0.000306678849
Iter: 598 loss: 0.000310547126
Iter: 599 loss: 0.00030657358
Iter: 600 loss: 0.000306009897
Iter: 601 loss: 0.000305832946
Iter: 602 loss: 0.00030550026
Iter: 603 loss: 0.000304537709
Iter: 604 loss: 0.000307387148
Iter: 605 loss: 0.00030424571
Iter: 606 loss: 0.00030335164
Iter: 607 loss: 0.000302488334
Iter: 608 loss: 0.000302291533
Iter: 609 loss: 0.000300963118
Iter: 610 loss: 0.000305155583
Iter: 611 loss: 0.000300582353
Iter: 612 loss: 0.000300172571
Iter: 613 loss: 0.000300030806
Iter: 614 loss: 0.0002995166
Iter: 615 loss: 0.000301403925
Iter: 616 loss: 0.000299391104
Iter: 617 loss: 0.000299002801
Iter: 618 loss: 0.000302066386
Iter: 619 loss: 0.000298975181
Iter: 620 loss: 0.000298715197
Iter: 621 loss: 0.000299461361
Iter: 622 loss: 0.000298634521
Iter: 623 loss: 0.000298391271
Iter: 624 loss: 0.000298069295
Iter: 625 loss: 0.000298050232
Iter: 626 loss: 0.000297508319
Iter: 627 loss: 0.000299024396
Iter: 628 loss: 0.000297335675
Iter: 629 loss: 0.000296925718
Iter: 630 loss: 0.000297945633
Iter: 631 loss: 0.000296780287
Iter: 632 loss: 0.000296295038
Iter: 633 loss: 0.000296666985
Iter: 634 loss: 0.000296001061
Iter: 635 loss: 0.000295399252
Iter: 636 loss: 0.000296073616
Iter: 637 loss: 0.000295073551
Iter: 638 loss: 0.000294317695
Iter: 639 loss: 0.000296961342
Iter: 640 loss: 0.000294120808
Iter: 641 loss: 0.000293329649
Iter: 642 loss: 0.000292575045
Iter: 643 loss: 0.00029239626
Iter: 644 loss: 0.000291282253
Iter: 645 loss: 0.000297431456
Iter: 646 loss: 0.000291120959
Iter: 647 loss: 0.000290914933
Iter: 648 loss: 0.000290692726
Iter: 649 loss: 0.000290317577
Iter: 650 loss: 0.000290866796
Iter: 651 loss: 0.000290137017
Iter: 652 loss: 0.000289750111
Iter: 653 loss: 0.00029179253
Iter: 654 loss: 0.00028968777
Iter: 655 loss: 0.000289385644
Iter: 656 loss: 0.000289142074
Iter: 657 loss: 0.000289051037
Iter: 658 loss: 0.000288559095
Iter: 659 loss: 0.000290039985
Iter: 660 loss: 0.000288409879
Iter: 661 loss: 0.000287941133
Iter: 662 loss: 0.000288420415
Iter: 663 loss: 0.000287680654
Iter: 664 loss: 0.0002870881
Iter: 665 loss: 0.000288073323
Iter: 666 loss: 0.000286819588
Iter: 667 loss: 0.000286293711
Iter: 668 loss: 0.000289315532
Iter: 669 loss: 0.000286224589
Iter: 670 loss: 0.000285709917
Iter: 671 loss: 0.000284884707
Iter: 672 loss: 0.000284877664
Iter: 673 loss: 0.00028377946
Iter: 674 loss: 0.000285651884
Iter: 675 loss: 0.000283286499
Iter: 676 loss: 0.000282315
Iter: 677 loss: 0.000297763967
Iter: 678 loss: 0.000282314024
Iter: 679 loss: 0.00028167048
Iter: 680 loss: 0.000282554305
Iter: 681 loss: 0.000281351386
Iter: 682 loss: 0.000281088578
Iter: 683 loss: 0.000280927459
Iter: 684 loss: 0.000280752196
Iter: 685 loss: 0.000280815759
Iter: 686 loss: 0.00028062964
Iter: 687 loss: 0.00028034547
Iter: 688 loss: 0.000280109409
Iter: 689 loss: 0.000280028413
Iter: 690 loss: 0.000279592059
Iter: 691 loss: 0.000281722285
Iter: 692 loss: 0.000279517262
Iter: 693 loss: 0.000279147469
Iter: 694 loss: 0.000279371394
Iter: 695 loss: 0.000278909109
Iter: 696 loss: 0.000278473
Iter: 697 loss: 0.000279423955
Iter: 698 loss: 0.000278304884
Iter: 699 loss: 0.000277857
Iter: 700 loss: 0.000278030406
Iter: 701 loss: 0.000277545361
Iter: 702 loss: 0.000276810606
Iter: 703 loss: 0.00027857942
Iter: 704 loss: 0.000276545965
Iter: 705 loss: 0.00027577643
Iter: 706 loss: 0.000275404309
Iter: 707 loss: 0.000275032537
Iter: 708 loss: 0.000274125574
Iter: 709 loss: 0.000280906388
Iter: 710 loss: 0.00027405002
Iter: 711 loss: 0.000273347541
Iter: 712 loss: 0.000278077147
Iter: 713 loss: 0.00027327516
Iter: 714 loss: 0.000273051177
Iter: 715 loss: 0.000272992416
Iter: 716 loss: 0.00027277472
Iter: 717 loss: 0.000272892736
Iter: 718 loss: 0.000272631936
Iter: 719 loss: 0.000272364123
Iter: 720 loss: 0.000272262463
Iter: 721 loss: 0.000272117148
Iter: 722 loss: 0.000271709112
Iter: 723 loss: 0.000272346166
Iter: 724 loss: 0.000271517929
Iter: 725 loss: 0.000271031
Iter: 726 loss: 0.00027329853
Iter: 727 loss: 0.000270942168
Iter: 728 loss: 0.000270611548
Iter: 729 loss: 0.000270586112
Iter: 730 loss: 0.000270339253
Iter: 731 loss: 0.000269755459
Iter: 732 loss: 0.000270388729
Iter: 733 loss: 0.000269437121
Iter: 734 loss: 0.000268855656
Iter: 735 loss: 0.000269548473
Iter: 736 loss: 0.000268547126
Iter: 737 loss: 0.000267658295
Iter: 738 loss: 0.000269575306
Iter: 739 loss: 0.00026731423
Iter: 740 loss: 0.000266432
Iter: 741 loss: 0.000266564894
Iter: 742 loss: 0.000265765033
Iter: 743 loss: 0.000264804781
Iter: 744 loss: 0.000270111253
Iter: 745 loss: 0.00026467006
Iter: 746 loss: 0.000264155038
Iter: 747 loss: 0.000264105911
Iter: 748 loss: 0.000263682858
Iter: 749 loss: 0.000265207374
Iter: 750 loss: 0.000263577356
Iter: 751 loss: 0.000263205642
Iter: 752 loss: 0.000262844143
Iter: 753 loss: 0.00026276274
Iter: 754 loss: 0.000262152724
Iter: 755 loss: 0.000262811838
Iter: 756 loss: 0.00026182062
Iter: 757 loss: 0.000261223526
Iter: 758 loss: 0.000265403971
Iter: 759 loss: 0.000261166802
Iter: 760 loss: 0.000260706496
Iter: 761 loss: 0.000260173401
Iter: 762 loss: 0.000260109286
Iter: 763 loss: 0.000259383407
Iter: 764 loss: 0.000268442876
Iter: 765 loss: 0.00025937648
Iter: 766 loss: 0.000258868473
Iter: 767 loss: 0.000258019165
Iter: 768 loss: 0.000258016691
Iter: 769 loss: 0.000257024309
Iter: 770 loss: 0.000264577626
Iter: 771 loss: 0.000256947562
Iter: 772 loss: 0.000256146945
Iter: 773 loss: 0.000255452615
Iter: 774 loss: 0.000255236693
Iter: 775 loss: 0.000254238956
Iter: 776 loss: 0.000262516
Iter: 777 loss: 0.00025417615
Iter: 778 loss: 0.000253900478
Iter: 779 loss: 0.000253735809
Iter: 780 loss: 0.000253427657
Iter: 781 loss: 0.000253222708
Iter: 782 loss: 0.000253106
Iter: 783 loss: 0.000252577796
Iter: 784 loss: 0.000253030768
Iter: 785 loss: 0.000252268481
Iter: 786 loss: 0.000251721445
Iter: 787 loss: 0.000254189188
Iter: 788 loss: 0.000251613528
Iter: 789 loss: 0.000251153018
Iter: 790 loss: 0.000253581355
Iter: 791 loss: 0.000251082558
Iter: 792 loss: 0.000250679121
Iter: 793 loss: 0.000250232843
Iter: 794 loss: 0.000250169571
Iter: 795 loss: 0.000249621808
Iter: 796 loss: 0.000254287617
Iter: 797 loss: 0.000249590026
Iter: 798 loss: 0.000249103119
Iter: 799 loss: 0.000248741038
Iter: 800 loss: 0.000248576776
Iter: 801 loss: 0.00024785829
Iter: 802 loss: 0.000251805875
Iter: 803 loss: 0.000247755437
Iter: 804 loss: 0.000246968935
Iter: 805 loss: 0.000247337797
Iter: 806 loss: 0.000246437965
Iter: 807 loss: 0.000245625561
Iter: 808 loss: 0.000245785108
Iter: 809 loss: 0.000245022238
Iter: 810 loss: 0.000244590308
Iter: 811 loss: 0.000244395429
Iter: 812 loss: 0.000243809161
Iter: 813 loss: 0.000246185635
Iter: 814 loss: 0.000243680886
Iter: 815 loss: 0.00024329251
Iter: 816 loss: 0.000242871232
Iter: 817 loss: 0.000242805691
Iter: 818 loss: 0.000242182374
Iter: 819 loss: 0.000243370625
Iter: 820 loss: 0.000241922564
Iter: 821 loss: 0.00024134267
Iter: 822 loss: 0.00024423498
Iter: 823 loss: 0.00024124312
Iter: 824 loss: 0.000240729642
Iter: 825 loss: 0.000240921843
Iter: 826 loss: 0.000240370558
Iter: 827 loss: 0.000239687331
Iter: 828 loss: 0.000240419264
Iter: 829 loss: 0.000239309345
Iter: 830 loss: 0.000238502282
Iter: 831 loss: 0.00024398361
Iter: 832 loss: 0.0002384236
Iter: 833 loss: 0.000237858156
Iter: 834 loss: 0.000237227199
Iter: 835 loss: 0.000237139393
Iter: 836 loss: 0.0002361433
Iter: 837 loss: 0.000245109084
Iter: 838 loss: 0.000236096734
Iter: 839 loss: 0.000235383777
Iter: 840 loss: 0.000235737127
Iter: 841 loss: 0.000234906329
Iter: 842 loss: 0.000234068168
Iter: 843 loss: 0.000237414264
Iter: 844 loss: 0.000233879924
Iter: 845 loss: 0.000233295796
Iter: 846 loss: 0.000233261264
Iter: 847 loss: 0.000233015511
Iter: 848 loss: 0.00023279569
Iter: 849 loss: 0.000232733626
Iter: 850 loss: 0.000232260092
Iter: 851 loss: 0.000231705984
Iter: 852 loss: 0.000231642436
Iter: 853 loss: 0.000231017213
Iter: 854 loss: 0.000231012353
Iter: 855 loss: 0.000230629492
Iter: 856 loss: 0.000230741251
Iter: 857 loss: 0.000230353427
Iter: 858 loss: 0.000229824247
Iter: 859 loss: 0.00022959098
Iter: 860 loss: 0.000229322628
Iter: 861 loss: 0.000228740508
Iter: 862 loss: 0.000232421939
Iter: 863 loss: 0.000228673161
Iter: 864 loss: 0.000228064877
Iter: 865 loss: 0.000228167934
Iter: 866 loss: 0.0002276093
Iter: 867 loss: 0.000227000026
Iter: 868 loss: 0.000228793782
Iter: 869 loss: 0.000226812204
Iter: 870 loss: 0.000226153992
Iter: 871 loss: 0.000228895195
Iter: 872 loss: 0.000226012548
Iter: 873 loss: 0.000225420794
Iter: 874 loss: 0.000227476587
Iter: 875 loss: 0.000225264579
Iter: 876 loss: 0.000225373573
Iter: 877 loss: 0.000225051554
Iter: 878 loss: 0.000224935357
Iter: 879 loss: 0.00022463224
Iter: 880 loss: 0.000226964461
Iter: 881 loss: 0.000224571151
Iter: 882 loss: 0.00022406
Iter: 883 loss: 0.00022372375
Iter: 884 loss: 0.000223529962
Iter: 885 loss: 0.000222998511
Iter: 886 loss: 0.000227804572
Iter: 887 loss: 0.000222973234
Iter: 888 loss: 0.000222455725
Iter: 889 loss: 0.000223230949
Iter: 890 loss: 0.000222208895
Iter: 891 loss: 0.00022171087
Iter: 892 loss: 0.000223535084
Iter: 893 loss: 0.000221586612
Iter: 894 loss: 0.000221127935
Iter: 895 loss: 0.000220769056
Iter: 896 loss: 0.000220627015
Iter: 897 loss: 0.000219863636
Iter: 898 loss: 0.000226080214
Iter: 899 loss: 0.000219813664
Iter: 900 loss: 0.000219268128
Iter: 901 loss: 0.000218791451
Iter: 902 loss: 0.000218646426
Iter: 903 loss: 0.000217855981
Iter: 904 loss: 0.000222138333
Iter: 905 loss: 0.000217737674
Iter: 906 loss: 0.000217120687
Iter: 907 loss: 0.000222155693
Iter: 908 loss: 0.000217082299
Iter: 909 loss: 0.000216839529
Iter: 910 loss: 0.000216814136
Iter: 911 loss: 0.00021654056
Iter: 912 loss: 0.000216300803
Iter: 913 loss: 0.000216229455
Iter: 914 loss: 0.000215901149
Iter: 915 loss: 0.000216555054
Iter: 916 loss: 0.00021576682
Iter: 917 loss: 0.000215410197
Iter: 918 loss: 0.000215234119
Iter: 919 loss: 0.000215063774
Iter: 920 loss: 0.000214638218
Iter: 921 loss: 0.000214636151
Iter: 922 loss: 0.00021436032
Iter: 923 loss: 0.000214124739
Iter: 924 loss: 0.000214049127
Iter: 925 loss: 0.000213619467
Iter: 926 loss: 0.000215209715
Iter: 927 loss: 0.000213513
Iter: 928 loss: 0.000213115331
Iter: 929 loss: 0.000213666877
Iter: 930 loss: 0.000212919491
Iter: 931 loss: 0.000212304221
Iter: 932 loss: 0.000213066975
Iter: 933 loss: 0.000211983381
Iter: 934 loss: 0.000211468563
Iter: 935 loss: 0.000211705294
Iter: 936 loss: 0.000211119201
Iter: 937 loss: 0.00021056892
Iter: 938 loss: 0.000215723834
Iter: 939 loss: 0.000210545288
Iter: 940 loss: 0.000210319704
Iter: 941 loss: 0.000210285929
Iter: 942 loss: 0.000210041078
Iter: 943 loss: 0.000210347862
Iter: 944 loss: 0.000209913254
Iter: 945 loss: 0.000209702353
Iter: 946 loss: 0.000209389327
Iter: 947 loss: 0.000209381455
Iter: 948 loss: 0.000208876823
Iter: 949 loss: 0.000209374208
Iter: 950 loss: 0.000208589569
Iter: 951 loss: 0.000208134676
Iter: 952 loss: 0.000213484498
Iter: 953 loss: 0.000208128738
Iter: 954 loss: 0.000207701436
Iter: 955 loss: 0.000207592122
Iter: 956 loss: 0.000207323697
Iter: 957 loss: 0.000206868935
Iter: 958 loss: 0.000207933816
Iter: 959 loss: 0.000206701399
Iter: 960 loss: 0.000206151934
Iter: 961 loss: 0.000206951547
Iter: 962 loss: 0.000205883553
Iter: 963 loss: 0.00020523899
Iter: 964 loss: 0.000207521138
Iter: 965 loss: 0.000205072865
Iter: 966 loss: 0.000204575888
Iter: 967 loss: 0.00020643945
Iter: 968 loss: 0.000204455078
Iter: 969 loss: 0.000204010721
Iter: 970 loss: 0.000203698728
Iter: 971 loss: 0.000203540054
Iter: 972 loss: 0.000203610194
Iter: 973 loss: 0.000203296455
Iter: 974 loss: 0.000203016549
Iter: 975 loss: 0.00020317614
Iter: 976 loss: 0.000202833326
Iter: 977 loss: 0.000202518553
Iter: 978 loss: 0.000202460593
Iter: 979 loss: 0.000202247349
Iter: 980 loss: 0.000201831121
Iter: 981 loss: 0.000202227355
Iter: 982 loss: 0.000201594361
Iter: 983 loss: 0.000201077011
Iter: 984 loss: 0.000203710952
Iter: 985 loss: 0.000200990864
Iter: 986 loss: 0.000200642549
Iter: 987 loss: 0.000203047122
Iter: 988 loss: 0.000200608949
Iter: 989 loss: 0.000200366238
Iter: 990 loss: 0.000199885544
Iter: 991 loss: 0.000209330872
Iter: 992 loss: 0.000199880553
Iter: 993 loss: 0.000199406932
Iter: 994 loss: 0.000203851494
Iter: 995 loss: 0.000199388072
Iter: 996 loss: 0.000198942696
Iter: 997 loss: 0.000199818314
Iter: 998 loss: 0.000198756927
Iter: 999 loss: 0.000198391528
Iter: 1000 loss: 0.000198903581
Iter: 1001 loss: 0.000198212219
Iter: 1002 loss: 0.000197726476
Iter: 1003 loss: 0.000198438269
Iter: 1004 loss: 0.000197491929
Iter: 1005 loss: 0.000197014786
Iter: 1006 loss: 0.000196889436
Iter: 1007 loss: 0.000196592882
Iter: 1008 loss: 0.00019719603
Iter: 1009 loss: 0.000196345631
Iter: 1010 loss: 0.000196095498
Iter: 1011 loss: 0.000195459201
Iter: 1012 loss: 0.000201009796
Iter: 1013 loss: 0.000195355271
Iter: 1014 loss: 0.000194829161
Iter: 1015 loss: 0.000196825917
Iter: 1016 loss: 0.000194702225
Iter: 1017 loss: 0.000194103544
Iter: 1018 loss: 0.000196988083
Iter: 1019 loss: 0.000193999062
Iter: 1020 loss: 0.000193608459
Iter: 1021 loss: 0.00019462622
Iter: 1022 loss: 0.000193473039
Iter: 1023 loss: 0.000193043175
Iter: 1024 loss: 0.000192536099
Iter: 1025 loss: 0.000192481035
Iter: 1026 loss: 0.000191933883
Iter: 1027 loss: 0.000195252302
Iter: 1028 loss: 0.000191866624
Iter: 1029 loss: 0.000191402185
Iter: 1030 loss: 0.000192392064
Iter: 1031 loss: 0.000191220315
Iter: 1032 loss: 0.000190790728
Iter: 1033 loss: 0.000192143285
Iter: 1034 loss: 0.000190664883
Iter: 1035 loss: 0.000190266233
Iter: 1036 loss: 0.000190248596
Iter: 1037 loss: 0.000189942162
Iter: 1038 loss: 0.000189490558
Iter: 1039 loss: 0.000189777609
Iter: 1040 loss: 0.000189202547
Iter: 1041 loss: 0.000188627659
Iter: 1042 loss: 0.0001908103
Iter: 1043 loss: 0.000188490521
Iter: 1044 loss: 0.000188159102
Iter: 1045 loss: 0.000188106409
Iter: 1046 loss: 0.000187895057
Iter: 1047 loss: 0.000187472062
Iter: 1048 loss: 0.00019559302
Iter: 1049 loss: 0.000187466911
Iter: 1050 loss: 0.000187099067
Iter: 1051 loss: 0.000188283346
Iter: 1052 loss: 0.000186993624
Iter: 1053 loss: 0.000186657067
Iter: 1054 loss: 0.000186646983
Iter: 1055 loss: 0.000186382837
Iter: 1056 loss: 0.000186804944
Iter: 1057 loss: 0.000186259917
Iter: 1058 loss: 0.00018606364
Iter: 1059 loss: 0.000185639423
Iter: 1060 loss: 0.000192261272
Iter: 1061 loss: 0.00018562426
Iter: 1062 loss: 0.00018511244
Iter: 1063 loss: 0.000188398175
Iter: 1064 loss: 0.000185054494
Iter: 1065 loss: 0.000184657227
Iter: 1066 loss: 0.000186886609
Iter: 1067 loss: 0.000184600984
Iter: 1068 loss: 0.000184227087
Iter: 1069 loss: 0.000184695484
Iter: 1070 loss: 0.000184032368
Iter: 1071 loss: 0.000183649376
Iter: 1072 loss: 0.000183828583
Iter: 1073 loss: 0.000183391967
Iter: 1074 loss: 0.000182924545
Iter: 1075 loss: 0.000183890705
Iter: 1076 loss: 0.000182736199
Iter: 1077 loss: 0.000182203177
Iter: 1078 loss: 0.000184647637
Iter: 1079 loss: 0.000182101299
Iter: 1080 loss: 0.000182099175
Iter: 1081 loss: 0.000181874406
Iter: 1082 loss: 0.00018179
Iter: 1083 loss: 0.00018154658
Iter: 1084 loss: 0.000182584088
Iter: 1085 loss: 0.000181451891
Iter: 1086 loss: 0.00018121989
Iter: 1087 loss: 0.000184838937
Iter: 1088 loss: 0.000181220355
Iter: 1089 loss: 0.000181100855
Iter: 1090 loss: 0.000181090829
Iter: 1091 loss: 0.00018099905
Iter: 1092 loss: 0.000180728
Iter: 1093 loss: 0.000181656724
Iter: 1094 loss: 0.000180603151
Iter: 1095 loss: 0.000180286748
Iter: 1096 loss: 0.000183270662
Iter: 1097 loss: 0.000180274146
Iter: 1098 loss: 0.000180052448
Iter: 1099 loss: 0.000180036339
Iter: 1100 loss: 0.000179869065
Iter: 1101 loss: 0.000179654759
Iter: 1102 loss: 0.000182018601
Iter: 1103 loss: 0.000179649913
Iter: 1104 loss: 0.000179478491
Iter: 1105 loss: 0.000179314608
Iter: 1106 loss: 0.000179276161
Iter: 1107 loss: 0.000179005932
Iter: 1108 loss: 0.000179103954
Iter: 1109 loss: 0.000178816772
Iter: 1110 loss: 0.000178567687
Iter: 1111 loss: 0.000178298302
Iter: 1112 loss: 0.000178256407
Iter: 1113 loss: 0.000177787268
Iter: 1114 loss: 0.000178031245
Iter: 1115 loss: 0.000177475886
Iter: 1116 loss: 0.000177590133
Iter: 1117 loss: 0.00017721676
Iter: 1118 loss: 0.000176997928
Iter: 1119 loss: 0.000176509726
Iter: 1120 loss: 0.000183279699
Iter: 1121 loss: 0.000176482674
Iter: 1122 loss: 0.000176029251
Iter: 1123 loss: 0.000181032316
Iter: 1124 loss: 0.000176019312
Iter: 1125 loss: 0.000175659748
Iter: 1126 loss: 0.000175585039
Iter: 1127 loss: 0.00017535004
Iter: 1128 loss: 0.000174855115
Iter: 1129 loss: 0.000174874716
Iter: 1130 loss: 0.000174464381
Iter: 1131 loss: 0.000173968787
Iter: 1132 loss: 0.000175062014
Iter: 1133 loss: 0.000173778477
Iter: 1134 loss: 0.000173230786
Iter: 1135 loss: 0.000176101807
Iter: 1136 loss: 0.000173143839
Iter: 1137 loss: 0.000172787404
Iter: 1138 loss: 0.00017494231
Iter: 1139 loss: 0.000172743021
Iter: 1140 loss: 0.000172400818
Iter: 1141 loss: 0.000172424101
Iter: 1142 loss: 0.000172133077
Iter: 1143 loss: 0.000171898733
Iter: 1144 loss: 0.000172732776
Iter: 1145 loss: 0.000171839463
Iter: 1146 loss: 0.000171551568
Iter: 1147 loss: 0.000171610242
Iter: 1148 loss: 0.000171337684
Iter: 1149 loss: 0.000171041131
Iter: 1150 loss: 0.000173352688
Iter: 1151 loss: 0.000171021209
Iter: 1152 loss: 0.000170789688
Iter: 1153 loss: 0.000173714769
Iter: 1154 loss: 0.000170787433
Iter: 1155 loss: 0.000170677115
Iter: 1156 loss: 0.000170708154
Iter: 1157 loss: 0.000170597923
Iter: 1158 loss: 0.000170411382
Iter: 1159 loss: 0.000170620158
Iter: 1160 loss: 0.000170309911
Iter: 1161 loss: 0.000170114421
Iter: 1162 loss: 0.000170278101
Iter: 1163 loss: 0.000169998
Iter: 1164 loss: 0.000169745384
Iter: 1165 loss: 0.000169457096
Iter: 1166 loss: 0.000169419989
Iter: 1167 loss: 0.000169126128
Iter: 1168 loss: 0.000169125968
Iter: 1169 loss: 0.000168888815
Iter: 1170 loss: 0.000169065243
Iter: 1171 loss: 0.000168742641
Iter: 1172 loss: 0.000168528131
Iter: 1173 loss: 0.000171531414
Iter: 1174 loss: 0.000168527447
Iter: 1175 loss: 0.00016838577
Iter: 1176 loss: 0.000168244267
Iter: 1177 loss: 0.00016821477
Iter: 1178 loss: 0.000168000726
Iter: 1179 loss: 0.000169507024
Iter: 1180 loss: 0.000167981125
Iter: 1181 loss: 0.000167820355
Iter: 1182 loss: 0.000168080354
Iter: 1183 loss: 0.000167745486
Iter: 1184 loss: 0.000167618127
Iter: 1185 loss: 0.000167615581
Iter: 1186 loss: 0.000167527294
Iter: 1187 loss: 0.000167422259
Iter: 1188 loss: 0.00016741117
Iter: 1189 loss: 0.000167239181
Iter: 1190 loss: 0.000168106111
Iter: 1191 loss: 0.000167210979
Iter: 1192 loss: 0.000167072896
Iter: 1193 loss: 0.000167027378
Iter: 1194 loss: 0.000166947473
Iter: 1195 loss: 0.000166710102
Iter: 1196 loss: 0.000166545011
Iter: 1197 loss: 0.000166459795
Iter: 1198 loss: 0.000166187179
Iter: 1199 loss: 0.000167236765
Iter: 1200 loss: 0.000166122831
Iter: 1201 loss: 0.00016581887
Iter: 1202 loss: 0.000166946833
Iter: 1203 loss: 0.000165744772
Iter: 1204 loss: 0.000165468489
Iter: 1205 loss: 0.000166348545
Iter: 1206 loss: 0.000165390316
Iter: 1207 loss: 0.000165073172
Iter: 1208 loss: 0.000166171609
Iter: 1209 loss: 0.000164990866
Iter: 1210 loss: 0.000164816956
Iter: 1211 loss: 0.000165376594
Iter: 1212 loss: 0.000164767465
Iter: 1213 loss: 0.00016456109
Iter: 1214 loss: 0.000164812664
Iter: 1215 loss: 0.000164453275
Iter: 1216 loss: 0.000164298064
Iter: 1217 loss: 0.000164291443
Iter: 1218 loss: 0.000164172088
Iter: 1219 loss: 0.000164147175
Iter: 1220 loss: 0.000164068653
Iter: 1221 loss: 0.00016392523
Iter: 1222 loss: 0.000164524317
Iter: 1223 loss: 0.000163894263
Iter: 1224 loss: 0.00016375324
Iter: 1225 loss: 0.000163612509
Iter: 1226 loss: 0.000163583027
Iter: 1227 loss: 0.000163335571
Iter: 1228 loss: 0.000163891178
Iter: 1229 loss: 0.000163242104
Iter: 1230 loss: 0.000163049655
Iter: 1231 loss: 0.000163053061
Iter: 1232 loss: 0.000162896235
Iter: 1233 loss: 0.000162620374
Iter: 1234 loss: 0.000164805213
Iter: 1235 loss: 0.000162601209
Iter: 1236 loss: 0.000162382
Iter: 1237 loss: 0.000162739831
Iter: 1238 loss: 0.000162281212
Iter: 1239 loss: 0.000162032593
Iter: 1240 loss: 0.000163145844
Iter: 1241 loss: 0.000161983829
Iter: 1242 loss: 0.000161835618
Iter: 1243 loss: 0.000162022916
Iter: 1244 loss: 0.000161759192
Iter: 1245 loss: 0.000161583157
Iter: 1246 loss: 0.000163084071
Iter: 1247 loss: 0.000161573727
Iter: 1248 loss: 0.000161474512
Iter: 1249 loss: 0.000161473959
Iter: 1250 loss: 0.000161392207
Iter: 1251 loss: 0.000161338394
Iter: 1252 loss: 0.000161306903
Iter: 1253 loss: 0.00016120408
Iter: 1254 loss: 0.000161742326
Iter: 1255 loss: 0.000161187694
Iter: 1256 loss: 0.000161089469
Iter: 1257 loss: 0.000161110656
Iter: 1258 loss: 0.000161016811
Iter: 1259 loss: 0.000160892814
Iter: 1260 loss: 0.000160957017
Iter: 1261 loss: 0.000160809781
Iter: 1262 loss: 0.000160645432
Iter: 1263 loss: 0.000160547759
Iter: 1264 loss: 0.000160478608
Iter: 1265 loss: 0.000160251453
Iter: 1266 loss: 0.00016270671
Iter: 1267 loss: 0.000160246331
Iter: 1268 loss: 0.000160061376
Iter: 1269 loss: 0.000160419266
Iter: 1270 loss: 0.000159984571
Iter: 1271 loss: 0.000159789
Iter: 1272 loss: 0.000161443182
Iter: 1273 loss: 0.000159778079
Iter: 1274 loss: 0.000159656338
Iter: 1275 loss: 0.000159609888
Iter: 1276 loss: 0.000159543095
Iter: 1277 loss: 0.000159393021
Iter: 1278 loss: 0.000160286567
Iter: 1279 loss: 0.000159373812
Iter: 1280 loss: 0.000159282557
Iter: 1281 loss: 0.00015928247
Iter: 1282 loss: 0.000159203191
Iter: 1283 loss: 0.000159215793
Iter: 1284 loss: 0.000159143499
Iter: 1285 loss: 0.000159066039
Iter: 1286 loss: 0.000159394942
Iter: 1287 loss: 0.000159050047
Iter: 1288 loss: 0.000158971816
Iter: 1289 loss: 0.000158910261
Iter: 1290 loss: 0.000158886061
Iter: 1291 loss: 0.000158748866
Iter: 1292 loss: 0.000158939831
Iter: 1293 loss: 0.000158681476
Iter: 1294 loss: 0.000158516486
Iter: 1295 loss: 0.000158383977
Iter: 1296 loss: 0.000158334675
Iter: 1297 loss: 0.000158128561
Iter: 1298 loss: 0.000160859912
Iter: 1299 loss: 0.000158127281
Iter: 1300 loss: 0.000157973205
Iter: 1301 loss: 0.000158250841
Iter: 1302 loss: 0.000157906077
Iter: 1303 loss: 0.00015776162
Iter: 1304 loss: 0.000159192103
Iter: 1305 loss: 0.000157756687
Iter: 1306 loss: 0.000157645321
Iter: 1307 loss: 0.000157555129
Iter: 1308 loss: 0.000157522445
Iter: 1309 loss: 0.000157368544
Iter: 1310 loss: 0.000158749375
Iter: 1311 loss: 0.000157361384
Iter: 1312 loss: 0.000157282731
Iter: 1313 loss: 0.000157281407
Iter: 1314 loss: 0.000157218019
Iter: 1315 loss: 0.000157252449
Iter: 1316 loss: 0.000157176692
Iter: 1317 loss: 0.000157110742
Iter: 1318 loss: 0.000157228496
Iter: 1319 loss: 0.000157082235
Iter: 1320 loss: 0.000156987051
Iter: 1321 loss: 0.000156950235
Iter: 1322 loss: 0.000156899
Iter: 1323 loss: 0.000156769864
Iter: 1324 loss: 0.000157045739
Iter: 1325 loss: 0.00015671883
Iter: 1326 loss: 0.0001565813
Iter: 1327 loss: 0.000156431066
Iter: 1328 loss: 0.000156408976
Iter: 1329 loss: 0.00015619726
Iter: 1330 loss: 0.000158034149
Iter: 1331 loss: 0.000156186259
Iter: 1332 loss: 0.000156003836
Iter: 1333 loss: 0.000156583323
Iter: 1334 loss: 0.000155951246
Iter: 1335 loss: 0.00015579813
Iter: 1336 loss: 0.000156976894
Iter: 1337 loss: 0.000155787013
Iter: 1338 loss: 0.000155654925
Iter: 1339 loss: 0.000155506801
Iter: 1340 loss: 0.000155487127
Iter: 1341 loss: 0.000155278147
Iter: 1342 loss: 0.000156710521
Iter: 1343 loss: 0.000155258662
Iter: 1344 loss: 0.000155141141
Iter: 1345 loss: 0.000155138667
Iter: 1346 loss: 0.000155041314
Iter: 1347 loss: 0.000155112517
Iter: 1348 loss: 0.000154981783
Iter: 1349 loss: 0.000154885551
Iter: 1350 loss: 0.000155020389
Iter: 1351 loss: 0.0001548375
Iter: 1352 loss: 0.000154696463
Iter: 1353 loss: 0.000154652429
Iter: 1354 loss: 0.000154569061
Iter: 1355 loss: 0.000154386144
Iter: 1356 loss: 0.000154737019
Iter: 1357 loss: 0.000154309251
Iter: 1358 loss: 0.000154101843
Iter: 1359 loss: 0.000154054
Iter: 1360 loss: 0.000153920613
Iter: 1361 loss: 0.000153705609
Iter: 1362 loss: 0.000155278278
Iter: 1363 loss: 0.000153687404
Iter: 1364 loss: 0.000153486893
Iter: 1365 loss: 0.000153993024
Iter: 1366 loss: 0.000153417466
Iter: 1367 loss: 0.000153234374
Iter: 1368 loss: 0.000154742913
Iter: 1369 loss: 0.000153222674
Iter: 1370 loss: 0.000153068846
Iter: 1371 loss: 0.000153047979
Iter: 1372 loss: 0.000152939567
Iter: 1373 loss: 0.000152765831
Iter: 1374 loss: 0.00015342189
Iter: 1375 loss: 0.000152724067
Iter: 1376 loss: 0.000152629116
Iter: 1377 loss: 0.000152619279
Iter: 1378 loss: 0.000152537395
Iter: 1379 loss: 0.000152625
Iter: 1380 loss: 0.000152492343
Iter: 1381 loss: 0.000152409979
Iter: 1382 loss: 0.000152510387
Iter: 1383 loss: 0.000152366585
Iter: 1384 loss: 0.000152243199
Iter: 1385 loss: 0.000152330424
Iter: 1386 loss: 0.000152166453
Iter: 1387 loss: 0.000152041757
Iter: 1388 loss: 0.000152162509
Iter: 1389 loss: 0.000151971151
Iter: 1390 loss: 0.000151811051
Iter: 1391 loss: 0.000151824788
Iter: 1392 loss: 0.000151687418
Iter: 1393 loss: 0.000151516637
Iter: 1394 loss: 0.000152129622
Iter: 1395 loss: 0.000151472661
Iter: 1396 loss: 0.000151298736
Iter: 1397 loss: 0.000152285123
Iter: 1398 loss: 0.000151273853
Iter: 1399 loss: 0.00015113363
Iter: 1400 loss: 0.000151859233
Iter: 1401 loss: 0.000151111337
Iter: 1402 loss: 0.000150967666
Iter: 1403 loss: 0.000150918699
Iter: 1404 loss: 0.000150836626
Iter: 1405 loss: 0.000150672611
Iter: 1406 loss: 0.000151189248
Iter: 1407 loss: 0.000150625099
Iter: 1408 loss: 0.000150531749
Iter: 1409 loss: 0.000150524371
Iter: 1410 loss: 0.00015043476
Iter: 1411 loss: 0.000150523236
Iter: 1412 loss: 0.000150384221
Iter: 1413 loss: 0.000150290696
Iter: 1414 loss: 0.000150293519
Iter: 1415 loss: 0.000150216074
Iter: 1416 loss: 0.00015005676
Iter: 1417 loss: 0.000150468
Iter: 1418 loss: 0.000150002816
Iter: 1419 loss: 0.000149879692
Iter: 1420 loss: 0.000149992586
Iter: 1421 loss: 0.000149809275
Iter: 1422 loss: 0.000149651256
Iter: 1423 loss: 0.00014967873
Iter: 1424 loss: 0.000149532396
Iter: 1425 loss: 0.000149363157
Iter: 1426 loss: 0.00014982796
Iter: 1427 loss: 0.000149308325
Iter: 1428 loss: 0.000149119689
Iter: 1429 loss: 0.000149955391
Iter: 1430 loss: 0.000149082378
Iter: 1431 loss: 0.000148910811
Iter: 1432 loss: 0.000149922591
Iter: 1433 loss: 0.000148888619
Iter: 1434 loss: 0.000148720457
Iter: 1435 loss: 0.000148831095
Iter: 1436 loss: 0.000148614869
Iter: 1437 loss: 0.000148451276
Iter: 1438 loss: 0.000148637962
Iter: 1439 loss: 0.000148364139
Iter: 1440 loss: 0.000148285151
Iter: 1441 loss: 0.000148264982
Iter: 1442 loss: 0.000148177613
Iter: 1443 loss: 0.000148276522
Iter: 1444 loss: 0.000148130173
Iter: 1445 loss: 0.000148036255
Iter: 1446 loss: 0.000148000807
Iter: 1447 loss: 0.000147949293
Iter: 1448 loss: 0.000147789338
Iter: 1449 loss: 0.00014849758
Iter: 1450 loss: 0.000147757964
Iter: 1451 loss: 0.000147656901
Iter: 1452 loss: 0.000147655257
Iter: 1453 loss: 0.000147575163
Iter: 1454 loss: 0.00014741451
Iter: 1455 loss: 0.000147525338
Iter: 1456 loss: 0.000147313971
Iter: 1457 loss: 0.00014714514
Iter: 1458 loss: 0.000147258354
Iter: 1459 loss: 0.000147039114
Iter: 1460 loss: 0.000146847568
Iter: 1461 loss: 0.000148922525
Iter: 1462 loss: 0.000146843304
Iter: 1463 loss: 0.000146706909
Iter: 1464 loss: 0.000147310217
Iter: 1465 loss: 0.000146679056
Iter: 1466 loss: 0.000146526902
Iter: 1467 loss: 0.000146679784
Iter: 1468 loss: 0.0001464417
Iter: 1469 loss: 0.000146301056
Iter: 1470 loss: 0.000146463877
Iter: 1471 loss: 0.000146226026
Iter: 1472 loss: 0.000146144885
Iter: 1473 loss: 0.000146138016
Iter: 1474 loss: 0.000146055594
Iter: 1475 loss: 0.000146224949
Iter: 1476 loss: 0.00014602227
Iter: 1477 loss: 0.0001459419
Iter: 1478 loss: 0.000145906393
Iter: 1479 loss: 0.000145865313
Iter: 1480 loss: 0.000145746468
Iter: 1481 loss: 0.000146483479
Iter: 1482 loss: 0.000145732338
Iter: 1483 loss: 0.000145656348
Iter: 1484 loss: 0.000145587444
Iter: 1485 loss: 0.000145568425
Iter: 1486 loss: 0.000145437167
Iter: 1487 loss: 0.000145707047
Iter: 1488 loss: 0.000145384285
Iter: 1489 loss: 0.00014526851
Iter: 1490 loss: 0.000145277329
Iter: 1491 loss: 0.00014517887
Iter: 1492 loss: 0.000145029306
Iter: 1493 loss: 0.00014601041
Iter: 1494 loss: 0.000145013822
Iter: 1495 loss: 0.000144878286
Iter: 1496 loss: 0.00014563599
Iter: 1497 loss: 0.00014486
Iter: 1498 loss: 0.00014474045
Iter: 1499 loss: 0.000144961828
Iter: 1500 loss: 0.000144689373
Iter: 1501 loss: 0.000144587364
Iter: 1502 loss: 0.000144566875
Iter: 1503 loss: 0.000144498568
Iter: 1504 loss: 0.000144378442
Iter: 1505 loss: 0.000145855418
Iter: 1506 loss: 0.000144376929
Iter: 1507 loss: 0.000144247
Iter: 1508 loss: 0.000144826714
Iter: 1509 loss: 0.000144221558
Iter: 1510 loss: 0.000144127378
Iter: 1511 loss: 0.00014402486
Iter: 1512 loss: 0.000144009973
Iter: 1513 loss: 0.000143856189
Iter: 1514 loss: 0.000145104015
Iter: 1515 loss: 0.000143846526
Iter: 1516 loss: 0.00014374395
Iter: 1517 loss: 0.000143638157
Iter: 1518 loss: 0.00014361841
Iter: 1519 loss: 0.000143436482
Iter: 1520 loss: 0.000144116813
Iter: 1521 loss: 0.00014339255
Iter: 1522 loss: 0.000143242345
Iter: 1523 loss: 0.000143146841
Iter: 1524 loss: 0.000143087353
Iter: 1525 loss: 0.000142861536
Iter: 1526 loss: 0.000144262871
Iter: 1527 loss: 0.000142835604
Iter: 1528 loss: 0.000142631325
Iter: 1529 loss: 0.000143781799
Iter: 1530 loss: 0.000142603094
Iter: 1531 loss: 0.00014243128
Iter: 1532 loss: 0.000143631478
Iter: 1533 loss: 0.000142414661
Iter: 1534 loss: 0.000142310615
Iter: 1535 loss: 0.000142190635
Iter: 1536 loss: 0.000142176155
Iter: 1537 loss: 0.00014204935
Iter: 1538 loss: 0.000143673809
Iter: 1539 loss: 0.0001420482
Iter: 1540 loss: 0.000141932178
Iter: 1541 loss: 0.000143009238
Iter: 1542 loss: 0.000141927216
Iter: 1543 loss: 0.000141857046
Iter: 1544 loss: 0.000141799639
Iter: 1545 loss: 0.00014177915
Iter: 1546 loss: 0.000141690834
Iter: 1547 loss: 0.000142344259
Iter: 1548 loss: 0.000141684242
Iter: 1549 loss: 0.000141614422
Iter: 1550 loss: 0.000141517463
Iter: 1551 loss: 0.000141514087
Iter: 1552 loss: 0.000141387558
Iter: 1553 loss: 0.000141928947
Iter: 1554 loss: 0.000141361088
Iter: 1555 loss: 0.000141245007
Iter: 1556 loss: 0.000141167693
Iter: 1557 loss: 0.000141124154
Iter: 1558 loss: 0.000140954988
Iter: 1559 loss: 0.000141724013
Iter: 1560 loss: 0.000140922726
Iter: 1561 loss: 0.000140772056
Iter: 1562 loss: 0.000141990255
Iter: 1563 loss: 0.000140762335
Iter: 1564 loss: 0.000140648568
Iter: 1565 loss: 0.000141301309
Iter: 1566 loss: 0.000140633565
Iter: 1567 loss: 0.000140524498
Iter: 1568 loss: 0.000140449862
Iter: 1569 loss: 0.000140410732
Iter: 1570 loss: 0.00014027115
Iter: 1571 loss: 0.000140416232
Iter: 1572 loss: 0.000140193675
Iter: 1573 loss: 0.000140114484
Iter: 1574 loss: 0.000140082397
Iter: 1575 loss: 0.000140014527
Iter: 1576 loss: 0.000139908225
Iter: 1577 loss: 0.000139906828
Iter: 1578 loss: 0.000139767042
Iter: 1579 loss: 0.00014027697
Iter: 1580 loss: 0.00013973219
Iter: 1581 loss: 0.00013959533
Iter: 1582 loss: 0.000139794749
Iter: 1583 loss: 0.000139528885
Iter: 1584 loss: 0.000139431882
Iter: 1585 loss: 0.000139564479
Iter: 1586 loss: 0.000139383221
Iter: 1587 loss: 0.000139252108
Iter: 1588 loss: 0.000139257623
Iter: 1589 loss: 0.000139148629
Iter: 1590 loss: 0.000139024341
Iter: 1591 loss: 0.000139424
Iter: 1592 loss: 0.000138989781
Iter: 1593 loss: 0.000138875213
Iter: 1594 loss: 0.000139757452
Iter: 1595 loss: 0.000138866773
Iter: 1596 loss: 0.000138782358
Iter: 1597 loss: 0.000139446434
Iter: 1598 loss: 0.000138776522
Iter: 1599 loss: 0.000138710398
Iter: 1600 loss: 0.000138668751
Iter: 1601 loss: 0.000138642557
Iter: 1602 loss: 0.000138551943
Iter: 1603 loss: 0.000138595817
Iter: 1604 loss: 0.000138490839
Iter: 1605 loss: 0.000138496587
Iter: 1606 loss: 0.000138442105
Iter: 1607 loss: 0.000138397969
Iter: 1608 loss: 0.000138340722
Iter: 1609 loss: 0.000138336836
Iter: 1610 loss: 0.000138259013
Iter: 1611 loss: 0.000138362637
Iter: 1612 loss: 0.000138219737
Iter: 1613 loss: 0.000138127973
Iter: 1614 loss: 0.000138474468
Iter: 1615 loss: 0.000138105737
Iter: 1616 loss: 0.000138041432
Iter: 1617 loss: 0.000137997573
Iter: 1618 loss: 0.000137973257
Iter: 1619 loss: 0.000137860334
Iter: 1620 loss: 0.000138203162
Iter: 1621 loss: 0.000137826719
Iter: 1622 loss: 0.000137713068
Iter: 1623 loss: 0.000137771087
Iter: 1624 loss: 0.000137637282
Iter: 1625 loss: 0.00013751314
Iter: 1626 loss: 0.000138058385
Iter: 1627 loss: 0.000137487586
Iter: 1628 loss: 0.000137372466
Iter: 1629 loss: 0.000138572927
Iter: 1630 loss: 0.000137369614
Iter: 1631 loss: 0.000137281837
Iter: 1632 loss: 0.00013755192
Iter: 1633 loss: 0.000137256284
Iter: 1634 loss: 0.0001371775
Iter: 1635 loss: 0.000137063864
Iter: 1636 loss: 0.000137060357
Iter: 1637 loss: 0.000137022522
Iter: 1638 loss: 0.000136997449
Iter: 1639 loss: 0.000136928022
Iter: 1640 loss: 0.000136962248
Iter: 1641 loss: 0.00013688163
Iter: 1642 loss: 0.00013680954
Iter: 1643 loss: 0.000136860937
Iter: 1644 loss: 0.000136764982
Iter: 1645 loss: 0.000136693576
Iter: 1646 loss: 0.000137281182
Iter: 1647 loss: 0.000136689137
Iter: 1648 loss: 0.000136635281
Iter: 1649 loss: 0.00013653739
Iter: 1650 loss: 0.000138874864
Iter: 1651 loss: 0.000136537405
Iter: 1652 loss: 0.000136429459
Iter: 1653 loss: 0.000136992516
Iter: 1654 loss: 0.000136412214
Iter: 1655 loss: 0.000136322313
Iter: 1656 loss: 0.000136343675
Iter: 1657 loss: 0.0001362568
Iter: 1658 loss: 0.000136119183
Iter: 1659 loss: 0.000136186733
Iter: 1660 loss: 0.000136027375
Iter: 1661 loss: 0.000135954557
Iter: 1662 loss: 0.000135935523
Iter: 1663 loss: 0.000135853697
Iter: 1664 loss: 0.000135809882
Iter: 1665 loss: 0.000135772018
Iter: 1666 loss: 0.000135623457
Iter: 1667 loss: 0.000135944298
Iter: 1668 loss: 0.000135565511
Iter: 1669 loss: 0.00013543744
Iter: 1670 loss: 0.00013583884
Iter: 1671 loss: 0.000135400827
Iter: 1672 loss: 0.000135268536
Iter: 1673 loss: 0.000137090698
Iter: 1674 loss: 0.000135268376
Iter: 1675 loss: 0.000135215625
Iter: 1676 loss: 0.000135137103
Iter: 1677 loss: 0.00013513508
Iter: 1678 loss: 0.000135024413
Iter: 1679 loss: 0.000135446258
Iter: 1680 loss: 0.000134997681
Iter: 1681 loss: 0.000134887494
Iter: 1682 loss: 0.000135102629
Iter: 1683 loss: 0.000134841684
Iter: 1684 loss: 0.000134737318
Iter: 1685 loss: 0.000134687158
Iter: 1686 loss: 0.000134636881
Iter: 1687 loss: 0.000134497212
Iter: 1688 loss: 0.000135241804
Iter: 1689 loss: 0.000134476053
Iter: 1690 loss: 0.000134335976
Iter: 1691 loss: 0.000134245085
Iter: 1692 loss: 0.000134190952
Iter: 1693 loss: 0.000134052098
Iter: 1694 loss: 0.000135746406
Iter: 1695 loss: 0.000134050511
Iter: 1696 loss: 0.00013391
Iter: 1697 loss: 0.000134542526
Iter: 1698 loss: 0.000133882364
Iter: 1699 loss: 0.000133788781
Iter: 1700 loss: 0.000133894791
Iter: 1701 loss: 0.000133738504
Iter: 1702 loss: 0.00013362235
Iter: 1703 loss: 0.000133778143
Iter: 1704 loss: 0.000133563386
Iter: 1705 loss: 0.000133515598
Iter: 1706 loss: 0.000133490787
Iter: 1707 loss: 0.000133455091
Iter: 1708 loss: 0.000133379421
Iter: 1709 loss: 0.000134635193
Iter: 1710 loss: 0.000133377616
Iter: 1711 loss: 0.000133280962
Iter: 1712 loss: 0.000133501628
Iter: 1713 loss: 0.000133245267
Iter: 1714 loss: 0.000133144466
Iter: 1715 loss: 0.0001335001
Iter: 1716 loss: 0.000133118272
Iter: 1717 loss: 0.000133026071
Iter: 1718 loss: 0.000133019
Iter: 1719 loss: 0.000132949775
Iter: 1720 loss: 0.000132832094
Iter: 1721 loss: 0.000133077527
Iter: 1722 loss: 0.000132785324
Iter: 1723 loss: 0.000132627174
Iter: 1724 loss: 0.000132835572
Iter: 1725 loss: 0.000132547299
Iter: 1726 loss: 0.000132402842
Iter: 1727 loss: 0.000132692105
Iter: 1728 loss: 0.000132344023
Iter: 1729 loss: 0.000132228015
Iter: 1730 loss: 0.000132225323
Iter: 1731 loss: 0.000132139598
Iter: 1732 loss: 0.000132066634
Iter: 1733 loss: 0.000132042624
Iter: 1734 loss: 0.000131920475
Iter: 1735 loss: 0.000132785688
Iter: 1736 loss: 0.000131909794
Iter: 1737 loss: 0.000131844921
Iter: 1738 loss: 0.000131843248
Iter: 1739 loss: 0.000131791559
Iter: 1740 loss: 0.000131707202
Iter: 1741 loss: 0.000131706824
Iter: 1742 loss: 0.000131619425
Iter: 1743 loss: 0.000131955749
Iter: 1744 loss: 0.000131599561
Iter: 1745 loss: 0.000131500798
Iter: 1746 loss: 0.000131633758
Iter: 1747 loss: 0.000131450914
Iter: 1748 loss: 0.000131347
Iter: 1749 loss: 0.000131524517
Iter: 1750 loss: 0.000131300752
Iter: 1751 loss: 0.000131185807
Iter: 1752 loss: 0.00013103793
Iter: 1753 loss: 0.000131028311
Iter: 1754 loss: 0.000130846413
Iter: 1755 loss: 0.000132184417
Iter: 1756 loss: 0.000130831555
Iter: 1757 loss: 0.000130661443
Iter: 1758 loss: 0.000131029941
Iter: 1759 loss: 0.000130595203
Iter: 1760 loss: 0.000130475877
Iter: 1761 loss: 0.00013156471
Iter: 1762 loss: 0.00013047
Iter: 1763 loss: 0.000130346016
Iter: 1764 loss: 0.000130443208
Iter: 1765 loss: 0.000130271132
Iter: 1766 loss: 0.000130155444
Iter: 1767 loss: 0.000130281129
Iter: 1768 loss: 0.000130091968
Iter: 1769 loss: 0.000130050801
Iter: 1770 loss: 0.000130009415
Iter: 1771 loss: 0.000129945984
Iter: 1772 loss: 0.00012991637
Iter: 1773 loss: 0.000129885448
Iter: 1774 loss: 0.000129814813
Iter: 1775 loss: 0.000129746593
Iter: 1776 loss: 0.000129731459
Iter: 1777 loss: 0.00012960106
Iter: 1778 loss: 0.000130313027
Iter: 1779 loss: 0.000129581575
Iter: 1780 loss: 0.000129489184
Iter: 1781 loss: 0.000129589
Iter: 1782 loss: 0.000129438384
Iter: 1783 loss: 0.000129304201
Iter: 1784 loss: 0.000129318767
Iter: 1785 loss: 0.0001292011
Iter: 1786 loss: 0.000129055115
Iter: 1787 loss: 0.000129452645
Iter: 1788 loss: 0.000129007196
Iter: 1789 loss: 0.000128868094
Iter: 1790 loss: 0.000129586755
Iter: 1791 loss: 0.000128845568
Iter: 1792 loss: 0.000128730651
Iter: 1793 loss: 0.000129420645
Iter: 1794 loss: 0.000128716405
Iter: 1795 loss: 0.000128605505
Iter: 1796 loss: 0.000129238048
Iter: 1797 loss: 0.000128590371
Iter: 1798 loss: 0.000128507294
Iter: 1799 loss: 0.000128423068
Iter: 1800 loss: 0.0001284069
Iter: 1801 loss: 0.000128371641
Iter: 1802 loss: 0.000128348052
Iter: 1803 loss: 0.000128295767
Iter: 1804 loss: 0.000128261294
Iter: 1805 loss: 0.00012824146
Iter: 1806 loss: 0.000128167783
Iter: 1807 loss: 0.000128158834
Iter: 1808 loss: 0.000128105778
Iter: 1809 loss: 0.000128020518
Iter: 1810 loss: 0.00012849523
Iter: 1811 loss: 0.000128008367
Iter: 1812 loss: 0.000127920677
Iter: 1813 loss: 0.00012788258
Iter: 1814 loss: 0.000127838081
Iter: 1815 loss: 0.000127728825
Iter: 1816 loss: 0.000128037238
Iter: 1817 loss: 0.000127693886
Iter: 1818 loss: 0.000127578372
Iter: 1819 loss: 0.000127928055
Iter: 1820 loss: 0.000127543623
Iter: 1821 loss: 0.000127435778
Iter: 1822 loss: 0.000127355364
Iter: 1823 loss: 0.000127320047
Iter: 1824 loss: 0.000127177729
Iter: 1825 loss: 0.000128695683
Iter: 1826 loss: 0.000127174251
Iter: 1827 loss: 0.000127037405
Iter: 1828 loss: 0.000127578664
Iter: 1829 loss: 0.000127006031
Iter: 1830 loss: 0.000126898842
Iter: 1831 loss: 0.00012747162
Iter: 1832 loss: 0.000126882369
Iter: 1833 loss: 0.000126826766
Iter: 1834 loss: 0.000127321022
Iter: 1835 loss: 0.000126824089
Iter: 1836 loss: 0.00012675942
Iter: 1837 loss: 0.000126812956
Iter: 1838 loss: 0.000126720828
Iter: 1839 loss: 0.00012666246
Iter: 1840 loss: 0.000126649975
Iter: 1841 loss: 0.000126611558
Iter: 1842 loss: 0.000126528612
Iter: 1843 loss: 0.000126776446
Iter: 1844 loss: 0.000126503146
Iter: 1845 loss: 0.000126420899
Iter: 1846 loss: 0.000126646308
Iter: 1847 loss: 0.000126393788
Iter: 1848 loss: 0.000126315019
Iter: 1849 loss: 0.00012623152
Iter: 1850 loss: 0.000126217492
Iter: 1851 loss: 0.00012608894
Iter: 1852 loss: 0.000126566869
Iter: 1853 loss: 0.000126057799
Iter: 1854 loss: 0.000125935097
Iter: 1855 loss: 0.00012638788
Iter: 1856 loss: 0.000125905382
Iter: 1857 loss: 0.000125773528
Iter: 1858 loss: 0.000125903738
Iter: 1859 loss: 0.000125699662
Iter: 1860 loss: 0.00012559157
Iter: 1861 loss: 0.000127256877
Iter: 1862 loss: 0.000125590988
Iter: 1863 loss: 0.000125492719
Iter: 1864 loss: 0.000125648934
Iter: 1865 loss: 0.000125446735
Iter: 1866 loss: 0.000125387058
Iter: 1867 loss: 0.000125864346
Iter: 1868 loss: 0.000125383376
Iter: 1869 loss: 0.000125313949
Iter: 1870 loss: 0.000125499064
Iter: 1871 loss: 0.000125291102
Iter: 1872 loss: 0.000125228718
Iter: 1873 loss: 0.000125163642
Iter: 1874 loss: 0.000125152044
Iter: 1875 loss: 0.000125074119
Iter: 1876 loss: 0.000125470018
Iter: 1877 loss: 0.000125061226
Iter: 1878 loss: 0.000124982325
Iter: 1879 loss: 0.000124987404
Iter: 1880 loss: 0.000124921033
Iter: 1881 loss: 0.000124815939
Iter: 1882 loss: 0.000125136125
Iter: 1883 loss: 0.000124784128
Iter: 1884 loss: 0.000124672806
Iter: 1885 loss: 0.000124572922
Iter: 1886 loss: 0.000124544502
Iter: 1887 loss: 0.000124371669
Iter: 1888 loss: 0.000124969825
Iter: 1889 loss: 0.000124325859
Iter: 1890 loss: 0.00012416541
Iter: 1891 loss: 0.000125198596
Iter: 1892 loss: 0.000124147613
Iter: 1893 loss: 0.000124013022
Iter: 1894 loss: 0.00012446208
Iter: 1895 loss: 0.00012397673
Iter: 1896 loss: 0.000123880891
Iter: 1897 loss: 0.000125331819
Iter: 1898 loss: 0.000123880614
Iter: 1899 loss: 0.000123821665
Iter: 1900 loss: 0.000123873455
Iter: 1901 loss: 0.000123786973
Iter: 1902 loss: 0.000123718695
Iter: 1903 loss: 0.000124700338
Iter: 1904 loss: 0.000123718637
Iter: 1905 loss: 0.000123677106
Iter: 1906 loss: 0.000123611244
Iter: 1907 loss: 0.000123611069
Iter: 1908 loss: 0.000123533609
Iter: 1909 loss: 0.000123824677
Iter: 1910 loss: 0.000123515187
Iter: 1911 loss: 0.000123445439
Iter: 1912 loss: 0.000123521517
Iter: 1913 loss: 0.000123407823
Iter: 1914 loss: 0.000123305392
Iter: 1915 loss: 0.000123300008
Iter: 1916 loss: 0.000123221907
Iter: 1917 loss: 0.000123103833
Iter: 1918 loss: 0.000123500649
Iter: 1919 loss: 0.000123071819
Iter: 1920 loss: 0.000122946309
Iter: 1921 loss: 0.000123163496
Iter: 1922 loss: 0.000122890109
Iter: 1923 loss: 0.00012277007
Iter: 1924 loss: 0.000122815181
Iter: 1925 loss: 0.000122686237
Iter: 1926 loss: 0.000122575904
Iter: 1927 loss: 0.000122575992
Iter: 1928 loss: 0.000122478566
Iter: 1929 loss: 0.000122966245
Iter: 1930 loss: 0.000122462399
Iter: 1931 loss: 0.000122398123
Iter: 1932 loss: 0.00012278826
Iter: 1933 loss: 0.000122390367
Iter: 1934 loss: 0.000122344456
Iter: 1935 loss: 0.00012273679
Iter: 1936 loss: 0.000122342346
Iter: 1937 loss: 0.000122303696
Iter: 1938 loss: 0.000122235026
Iter: 1939 loss: 0.000122235229
Iter: 1940 loss: 0.000122163736
Iter: 1941 loss: 0.000122365978
Iter: 1942 loss: 0.00012214134
Iter: 1943 loss: 0.0001220634
Iter: 1944 loss: 0.000122091034
Iter: 1945 loss: 0.000122008729
Iter: 1946 loss: 0.000121902245
Iter: 1947 loss: 0.000122420766
Iter: 1948 loss: 0.000121883248
Iter: 1949 loss: 0.000121806181
Iter: 1950 loss: 0.000121834571
Iter: 1951 loss: 0.000121752142
Iter: 1952 loss: 0.000121647427
Iter: 1953 loss: 0.000121905156
Iter: 1954 loss: 0.000121610858
Iter: 1955 loss: 0.000121503232
Iter: 1956 loss: 0.000121764722
Iter: 1957 loss: 0.000121464691
Iter: 1958 loss: 0.000121351477
Iter: 1959 loss: 0.000121476012
Iter: 1960 loss: 0.000121290752
Iter: 1961 loss: 0.000121187302
Iter: 1962 loss: 0.000122711179
Iter: 1963 loss: 0.000121187564
Iter: 1964 loss: 0.000121098026
Iter: 1965 loss: 0.000121740741
Iter: 1966 loss: 0.000121090212
Iter: 1967 loss: 0.000121045334
Iter: 1968 loss: 0.000121391546
Iter: 1969 loss: 0.000121041936
Iter: 1970 loss: 0.000120999219
Iter: 1971 loss: 0.000120959659
Iter: 1972 loss: 0.000120949328
Iter: 1973 loss: 0.000120875542
Iter: 1974 loss: 0.000120904217
Iter: 1975 loss: 0.000120823868
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/k4
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0
+ date
Tue Oct 27 17:00:00 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fc5fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f118fe402f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f118fe9ec80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fbc8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fbb91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fc03bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fc2b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fb97158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fb99b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fb59620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116faf50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fb06ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fabd598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fae5048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fae6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116faa1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fa2cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fa64950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fa07400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116fa08e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f9cd8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f9ea378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f96dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f933840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f94f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f959d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f91c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f8bb268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f8c2c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f883730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f8a81e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f82dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f8646a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f80c158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f80db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f116f7d1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00148066343
Iter: 2 loss: 0.00147303066
Iter: 3 loss: 0.00144486106
Iter: 4 loss: 0.00136124808
Iter: 5 loss: 0.00244118832
Iter: 6 loss: 0.00135477399
Iter: 7 loss: 0.00132079376
Iter: 8 loss: 0.0014470024
Iter: 9 loss: 0.00131243165
Iter: 10 loss: 0.00128655543
Iter: 11 loss: 0.0015247697
Iter: 12 loss: 0.00128546101
Iter: 13 loss: 0.00127511146
Iter: 14 loss: 0.00127393636
Iter: 15 loss: 0.00126647449
Iter: 16 loss: 0.00126109901
Iter: 17 loss: 0.00126085943
Iter: 18 loss: 0.00125673669
Iter: 19 loss: 0.00126696285
Iter: 20 loss: 0.00125528232
Iter: 21 loss: 0.0012531674
Iter: 22 loss: 0.00125654787
Iter: 23 loss: 0.00125218905
Iter: 24 loss: 0.00125125702
Iter: 25 loss: 0.00125116587
Iter: 26 loss: 0.00125053502
Iter: 27 loss: 0.00125080778
Iter: 28 loss: 0.00125010381
Iter: 29 loss: 0.00124967296
Iter: 30 loss: 0.00125053595
Iter: 31 loss: 0.00124949752
Iter: 32 loss: 0.00124926399
Iter: 33 loss: 0.00125045143
Iter: 34 loss: 0.00124922604
Iter: 35 loss: 0.001249152
Iter: 36 loss: 0.00124914967
Iter: 37 loss: 0.00124910474
Iter: 38 loss: 0.00124953128
Iter: 39 loss: 0.00124910241
Iter: 40 loss: 0.00124907889
Iter: 41 loss: 0.00124910101
Iter: 42 loss: 0.00124906492
Iter: 43 loss: 0.00124904863
Iter: 44 loss: 0.00124913454
Iter: 45 loss: 0.00124904595
Iter: 46 loss: 0.00124903815
Iter: 47 loss: 0.00124911463
Iter: 48 loss: 0.00124903861
Iter: 49 loss: 0.00124903384
Iter: 50 loss: 0.00124906912
Iter: 51 loss: 0.00124903303
Iter: 52 loss: 0.00124903093
Iter: 53 loss: 0.00124903116
Iter: 54 loss: 0.00124902953
Iter: 55 loss: 0.00124902767
Iter: 56 loss: 0.0012490279
Iter: 57 loss: 0.00124902697
Iter: 58 loss: 0.0012490293
Iter: 59 loss: 0.00124902674
Iter: 60 loss: 0.00124902627
Iter: 61 loss: 0.00124902709
Iter: 62 loss: 0.00124902558
Iter: 63 loss: 0.00124902581
Iter: 64 loss: 0.00124902534
Iter: 65 loss: 0.00124902523
Iter: 66 loss: 0.00124902581
Iter: 67 loss: 0.00124902534
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4
+ date
Tue Oct 27 17:00:38 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d43f4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d44178c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4357378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4396950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4396ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d43960d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d429d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d43002f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d429d510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4282620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d42829d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4244e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d41e9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d422a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d41a10d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4161ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4185488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d41bd268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d40dfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4185e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d40a8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d40d12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d40d1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4040d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d4040840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22d40408c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c0676ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c0676c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c063e400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c05e22f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c063e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c063e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c063e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c063ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c05daf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f22c04d2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0280101635
Iter: 2 loss: 0.0268763956
Iter: 3 loss: 0.022685498
Iter: 4 loss: 0.00920576
Iter: 5 loss: 0.189755112
Iter: 6 loss: 0.00768056512
Iter: 7 loss: 0.00286477152
Iter: 8 loss: 0.0829430521
Iter: 9 loss: 0.00286423578
Iter: 10 loss: 0.00225273916
Iter: 11 loss: 0.00195496948
Iter: 12 loss: 0.00168520468
Iter: 13 loss: 0.00225857389
Iter: 14 loss: 0.00157872122
Iter: 15 loss: 0.00145927607
Iter: 16 loss: 0.00258948514
Iter: 17 loss: 0.00145428278
Iter: 18 loss: 0.00139416871
Iter: 19 loss: 0.00200302806
Iter: 20 loss: 0.00139235181
Iter: 21 loss: 0.00136706512
Iter: 22 loss: 0.00141331623
Iter: 23 loss: 0.00135604385
Iter: 24 loss: 0.00133932265
Iter: 25 loss: 0.0015199607
Iter: 26 loss: 0.0013389443
Iter: 27 loss: 0.00132956449
Iter: 28 loss: 0.00134447613
Iter: 29 loss: 0.00132522429
Iter: 30 loss: 0.00131997443
Iter: 31 loss: 0.00132888462
Iter: 32 loss: 0.00131760072
Iter: 33 loss: 0.00131436845
Iter: 34 loss: 0.00134919258
Iter: 35 loss: 0.00131429383
Iter: 36 loss: 0.00131204328
Iter: 37 loss: 0.00131788314
Iter: 38 loss: 0.00131128007
Iter: 39 loss: 0.00130985
Iter: 40 loss: 0.00131292292
Iter: 41 loss: 0.00130929053
Iter: 42 loss: 0.00130845478
Iter: 43 loss: 0.00131160533
Iter: 44 loss: 0.0013082542
Iter: 45 loss: 0.00130778039
Iter: 46 loss: 0.00131160195
Iter: 47 loss: 0.00130774966
Iter: 48 loss: 0.00130749471
Iter: 49 loss: 0.0013097449
Iter: 50 loss: 0.00130748237
Iter: 51 loss: 0.00130732986
Iter: 52 loss: 0.00130786956
Iter: 53 loss: 0.00130729
Iter: 54 loss: 0.00130720076
Iter: 55 loss: 0.00130788481
Iter: 56 loss: 0.00130719366
Iter: 57 loss: 0.00130713522
Iter: 58 loss: 0.00130756292
Iter: 59 loss: 0.00130713033
Iter: 60 loss: 0.00130709633
Iter: 61 loss: 0.00130716502
Iter: 62 loss: 0.0013070819
Iter: 63 loss: 0.00130705652
Iter: 64 loss: 0.00130726595
Iter: 65 loss: 0.00130705535
Iter: 66 loss: 0.00130703882
Iter: 67 loss: 0.00130708492
Iter: 68 loss: 0.00130703347
Iter: 69 loss: 0.00130702299
Iter: 70 loss: 0.00130708329
Iter: 71 loss: 0.00130702183
Iter: 72 loss: 0.00130701484
Iter: 73 loss: 0.00130703079
Iter: 74 loss: 0.00130701181
Iter: 75 loss: 0.00130700727
Iter: 76 loss: 0.00130703254
Iter: 77 loss: 0.00130700646
Iter: 78 loss: 0.0013070039
Iter: 79 loss: 0.00130703079
Iter: 80 loss: 0.00130700378
Iter: 81 loss: 0.0013070018
Iter: 82 loss: 0.0013070046
Iter: 83 loss: 0.00130700134
Iter: 84 loss: 0.00130700029
Iter: 85 loss: 0.00130700786
Iter: 86 loss: 0.00130699924
Iter: 87 loss: 0.00130699913
Iter: 88 loss: 0.00130700262
Iter: 89 loss: 0.00130699901
Iter: 90 loss: 0.00130699831
Iter: 91 loss: 0.00130700041
Iter: 92 loss: 0.00130699854
Iter: 93 loss: 0.00130699831
Iter: 94 loss: 0.0013070011
Iter: 95 loss: 0.00130699854
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8
+ date
Tue Oct 27 17:01:24 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106a47e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106a798c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61069bd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61069f8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61069f8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61069f8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61069bd488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f610693aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f610693a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61068f4158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61068f4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61068f49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106850d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106878e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f610681bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61067c2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61067e7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f610681ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61067bdd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f610681b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f610670f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61067352f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106735268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61066a7048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61066a7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61066b2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106666a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61066500d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106636400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61065d82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106636840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106636950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61066362f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6106636a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61065d0f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f61064cb048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0206075907
Iter: 2 loss: 0.019651
Iter: 3 loss: 0.0162298866
Iter: 4 loss: 0.0141295483
Iter: 5 loss: 0.0113771185
Iter: 6 loss: 0.00636494579
Iter: 7 loss: 0.0846452415
Iter: 8 loss: 0.00605285866
Iter: 9 loss: 0.00290601747
Iter: 10 loss: 0.00287875626
Iter: 11 loss: 0.00224060472
Iter: 12 loss: 0.00627777912
Iter: 13 loss: 0.00213002693
Iter: 14 loss: 0.00190583873
Iter: 15 loss: 0.00190471206
Iter: 16 loss: 0.00175776077
Iter: 17 loss: 0.00195371639
Iter: 18 loss: 0.00168420991
Iter: 19 loss: 0.00158102298
Iter: 20 loss: 0.00187
Iter: 21 loss: 0.00154652889
Iter: 22 loss: 0.00148270978
Iter: 23 loss: 0.00187853817
Iter: 24 loss: 0.0014748344
Iter: 25 loss: 0.00143939489
Iter: 26 loss: 0.00167571905
Iter: 27 loss: 0.00143575668
Iter: 28 loss: 0.00141455466
Iter: 29 loss: 0.00148433517
Iter: 30 loss: 0.00140859617
Iter: 31 loss: 0.00139671355
Iter: 32 loss: 0.00145505276
Iter: 33 loss: 0.00139464729
Iter: 34 loss: 0.00138728705
Iter: 35 loss: 0.00142828876
Iter: 36 loss: 0.0013862435
Iter: 37 loss: 0.00138171297
Iter: 38 loss: 0.0014035647
Iter: 39 loss: 0.00138089899
Iter: 40 loss: 0.00137791596
Iter: 41 loss: 0.00139205041
Iter: 42 loss: 0.00137737859
Iter: 43 loss: 0.00137541862
Iter: 44 loss: 0.00138904294
Iter: 45 loss: 0.00137523224
Iter: 46 loss: 0.00137374061
Iter: 47 loss: 0.00137513631
Iter: 48 loss: 0.00137288589
Iter: 49 loss: 0.00137153768
Iter: 50 loss: 0.00137471699
Iter: 51 loss: 0.00137104513
Iter: 52 loss: 0.00136979739
Iter: 53 loss: 0.0013785155
Iter: 54 loss: 0.00136968086
Iter: 55 loss: 0.00136877177
Iter: 56 loss: 0.00137380266
Iter: 57 loss: 0.00136864174
Iter: 58 loss: 0.00136798574
Iter: 59 loss: 0.00136818993
Iter: 60 loss: 0.00136751705
Iter: 61 loss: 0.0013668976
Iter: 62 loss: 0.00136890449
Iter: 63 loss: 0.00136672286
Iter: 64 loss: 0.00136621576
Iter: 65 loss: 0.00136786129
Iter: 66 loss: 0.00136607361
Iter: 67 loss: 0.0013656721
Iter: 68 loss: 0.00136733707
Iter: 69 loss: 0.0013655856
Iter: 70 loss: 0.00136528886
Iter: 71 loss: 0.00136663648
Iter: 72 loss: 0.00136523216
Iter: 73 loss: 0.00136503438
Iter: 74 loss: 0.0013659196
Iter: 75 loss: 0.00136499538
Iter: 76 loss: 0.00136485836
Iter: 77 loss: 0.00136579457
Iter: 78 loss: 0.0013648452
Iter: 79 loss: 0.001364775
Iter: 80 loss: 0.00136477523
Iter: 81 loss: 0.00136472634
Iter: 82 loss: 0.00136471423
Iter: 83 loss: 0.00136468362
Iter: 84 loss: 0.00136463635
Iter: 85 loss: 0.00136489538
Iter: 86 loss: 0.00136463
Iter: 87 loss: 0.00136460061
Iter: 88 loss: 0.00136477011
Iter: 89 loss: 0.001364597
Iter: 90 loss: 0.00136457791
Iter: 91 loss: 0.00136475265
Iter: 92 loss: 0.0013645771
Iter: 93 loss: 0.00136456592
Iter: 94 loss: 0.00136456476
Iter: 95 loss: 0.00136455591
Iter: 96 loss: 0.0013645445
Iter: 97 loss: 0.00136459549
Iter: 98 loss: 0.00136454217
Iter: 99 loss: 0.00136453426
Iter: 100 loss: 0.00136455311
Iter: 101 loss: 0.00136453169
Iter: 102 loss: 0.00136452657
Iter: 103 loss: 0.00136456545
Iter: 104 loss: 0.00136452564
Iter: 105 loss: 0.00136452215
Iter: 106 loss: 0.00136454019
Iter: 107 loss: 0.0013645218
Iter: 108 loss: 0.00136451935
Iter: 109 loss: 0.00136452925
Iter: 110 loss: 0.00136451889
Iter: 111 loss: 0.00136451749
Iter: 112 loss: 0.00136452413
Iter: 113 loss: 0.00136451726
Iter: 114 loss: 0.00136451563
Iter: 115 loss: 0.0013645275
Iter: 116 loss: 0.00136451621
Iter: 117 loss: 0.00136451575
Iter: 118 loss: 0.00136451772
Iter: 119 loss: 0.00136451563
Iter: 120 loss: 0.0013645147
Iter: 121 loss: 0.00136451493
Iter: 122 loss: 0.0013645147
Iter: 123 loss: 0.00136451423
Iter: 124 loss: 0.00136451551
Iter: 125 loss: 0.001364514
Iter: 126 loss: 0.001364514
Iter: 127 loss: 0.00136451749
Iter: 128 loss: 0.00136451365
Iter: 129 loss: 0.00136451377
Iter: 130 loss: 0.00136451377
Iter: 131 loss: 0.00136451423
Iter: 132 loss: 0.00136451388
Iter: 133 loss: 0.00136451377
Iter: 134 loss: 0.001364514
Iter: 135 loss: 0.00136451388
Iter: 136 loss: 0.00136451377
Iter: 137 loss: 0.00136451377
Iter: 138 loss: 0.00136451295
Iter: 139 loss: 0.00136451353
Iter: 140 loss: 0.00136451353
Iter: 141 loss: 0.0013645133
Iter: 142 loss: 0.00136451353
Iter: 143 loss: 0.00136451307
Iter: 144 loss: 0.0013645133
Iter: 145 loss: 0.00136451353
Iter: 146 loss: 0.00136451295
Iter: 147 loss: 0.0013645133
Iter: 148 loss: 0.00136451342
Iter: 149 loss: 0.0013645133
Iter: 150 loss: 0.0013645133
Iter: 151 loss: 0.0013645133
Iter: 152 loss: 0.00136451318
Iter: 153 loss: 0.00136451342
Iter: 154 loss: 0.0013645133
Iter: 155 loss: 0.00136451353
Iter: 156 loss: 0.00136451307
Iter: 157 loss: 0.0013645133
Iter: 158 loss: 0.0013645133
Iter: 159 loss: 0.0013645133
Iter: 160 loss: 0.00136451342
Iter: 161 loss: 0.0013645133
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2
+ date
Tue Oct 27 17:02:25 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3115e92f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3115d77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd311591268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd311591488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd31150f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec5900d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec59ac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec548ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec505f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec5170d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec517950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec4dbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec4a8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec4a8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec4ca9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec3fce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec413ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec44d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec3eea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec413d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec368f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec368268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec368158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec2d8510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec2d8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec2d86a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec299ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec245d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec264378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec208268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec2647b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec264730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec1cf620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec208158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec1b6378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd2ec157f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0222555455
Iter: 2 loss: 0.0196992122
Iter: 3 loss: 0.012920849
Iter: 4 loss: 3484.72559
Iter: 5 loss: 0.0129208472
Iter: 6 loss: 0.00948579423
Iter: 7 loss: 0.164488062
Iter: 8 loss: 0.00946153887
Iter: 9 loss: 0.00581565546
Iter: 10 loss: 0.0691232234
Iter: 11 loss: 0.00574371824
Iter: 12 loss: 0.00373587548
Iter: 13 loss: 0.0160443
Iter: 14 loss: 0.00345114479
Iter: 15 loss: 0.00272707897
Iter: 16 loss: 0.00812570564
Iter: 17 loss: 0.00263333553
Iter: 18 loss: 0.00225200527
Iter: 19 loss: 0.010987903
Iter: 20 loss: 0.00225200318
Iter: 21 loss: 0.00205280492
Iter: 22 loss: 0.0023657775
Iter: 23 loss: 0.00195654156
Iter: 24 loss: 0.00182364043
Iter: 25 loss: 0.00243407488
Iter: 26 loss: 0.00179892313
Iter: 27 loss: 0.00172096759
Iter: 28 loss: 0.00190326222
Iter: 29 loss: 0.00169011019
Iter: 30 loss: 0.00161972037
Iter: 31 loss: 0.00175623933
Iter: 32 loss: 0.00159032049
Iter: 33 loss: 0.00153548771
Iter: 34 loss: 0.0017808266
Iter: 35 loss: 0.00152419636
Iter: 36 loss: 0.00148518395
Iter: 37 loss: 0.00163527345
Iter: 38 loss: 0.00147595059
Iter: 39 loss: 0.00144552614
Iter: 40 loss: 0.00154657895
Iter: 41 loss: 0.00143695134
Iter: 42 loss: 0.00141656
Iter: 43 loss: 0.00157220755
Iter: 44 loss: 0.0014149393
Iter: 45 loss: 0.00140187447
Iter: 46 loss: 0.00153674884
Iter: 47 loss: 0.00140153
Iter: 48 loss: 0.00139293389
Iter: 49 loss: 0.00143845915
Iter: 50 loss: 0.00139155029
Iter: 51 loss: 0.00138627947
Iter: 52 loss: 0.00139656139
Iter: 53 loss: 0.00138409145
Iter: 54 loss: 0.0013800587
Iter: 55 loss: 0.00141304906
Iter: 56 loss: 0.00137981051
Iter: 57 loss: 0.00137681188
Iter: 58 loss: 0.00138023519
Iter: 59 loss: 0.00137520046
Iter: 60 loss: 0.00137262337
Iter: 61 loss: 0.00137777743
Iter: 62 loss: 0.00137157214
Iter: 63 loss: 0.00136909692
Iter: 64 loss: 0.00137838139
Iter: 65 loss: 0.00136849494
Iter: 66 loss: 0.00136667909
Iter: 67 loss: 0.00138010737
Iter: 68 loss: 0.00136653311
Iter: 69 loss: 0.00136503519
Iter: 70 loss: 0.00136814674
Iter: 71 loss: 0.00136443414
Iter: 72 loss: 0.00136295403
Iter: 73 loss: 0.00136789354
Iter: 74 loss: 0.00136255217
Iter: 75 loss: 0.00136119418
Iter: 76 loss: 0.00136309152
Iter: 77 loss: 0.00136052095
Iter: 78 loss: 0.00135922898
Iter: 79 loss: 0.00136262295
Iter: 80 loss: 0.00135879
Iter: 81 loss: 0.00135774561
Iter: 82 loss: 0.00136877655
Iter: 83 loss: 0.00135771954
Iter: 84 loss: 0.00135680893
Iter: 85 loss: 0.00136089
Iter: 86 loss: 0.00135662942
Iter: 87 loss: 0.00135598658
Iter: 88 loss: 0.00135539682
Iter: 89 loss: 0.00135524175
Iter: 90 loss: 0.00135441357
Iter: 91 loss: 0.00136209221
Iter: 92 loss: 0.00135437865
Iter: 93 loss: 0.00135370134
Iter: 94 loss: 0.00135718507
Iter: 95 loss: 0.00135359075
Iter: 96 loss: 0.0013531018
Iter: 97 loss: 0.00135320716
Iter: 98 loss: 0.00135274115
Iter: 99 loss: 0.00135216629
Iter: 100 loss: 0.00135391974
Iter: 101 loss: 0.00135199516
Iter: 102 loss: 0.00135146326
Iter: 103 loss: 0.00135293789
Iter: 104 loss: 0.00135129131
Iter: 105 loss: 0.00135085394
Iter: 106 loss: 0.00135444093
Iter: 107 loss: 0.00135082635
Iter: 108 loss: 0.00135049992
Iter: 109 loss: 0.00135112251
Iter: 110 loss: 0.00135036418
Iter: 111 loss: 0.00135003345
Iter: 112 loss: 0.00135064765
Iter: 113 loss: 0.00134989165
Iter: 114 loss: 0.00134960096
Iter: 115 loss: 0.00135086267
Iter: 116 loss: 0.00134954089
Iter: 117 loss: 0.00134931575
Iter: 118 loss: 0.00134999247
Iter: 119 loss: 0.00134924718
Iter: 120 loss: 0.00134911458
Iter: 121 loss: 0.00134911016
Iter: 122 loss: 0.00134901993
Iter: 123 loss: 0.00134893437
Iter: 124 loss: 0.00134891435
Iter: 125 loss: 0.00134879118
Iter: 126 loss: 0.00134911365
Iter: 127 loss: 0.00134874927
Iter: 128 loss: 0.00134864415
Iter: 129 loss: 0.00134913786
Iter: 130 loss: 0.00134862401
Iter: 131 loss: 0.00134854391
Iter: 132 loss: 0.00134902657
Iter: 133 loss: 0.00134853413
Iter: 134 loss: 0.00134846778
Iter: 135 loss: 0.00134886103
Iter: 136 loss: 0.0013484587
Iter: 137 loss: 0.00134842
Iter: 138 loss: 0.00134846428
Iter: 139 loss: 0.00134839863
Iter: 140 loss: 0.00134836079
Iter: 141 loss: 0.0013484098
Iter: 142 loss: 0.00134834042
Iter: 143 loss: 0.00134830666
Iter: 144 loss: 0.00134859048
Iter: 145 loss: 0.00134830433
Iter: 146 loss: 0.00134827895
Iter: 147 loss: 0.00134839758
Iter: 148 loss: 0.00134827429
Iter: 149 loss: 0.00134825567
Iter: 150 loss: 0.00134828605
Iter: 151 loss: 0.0013482467
Iter: 152 loss: 0.00134823192
Iter: 153 loss: 0.00134832878
Iter: 154 loss: 0.00134823029
Iter: 155 loss: 0.00134821679
Iter: 156 loss: 0.00134829059
Iter: 157 loss: 0.00134821492
Iter: 158 loss: 0.00134820526
Iter: 159 loss: 0.00134821492
Iter: 160 loss: 0.00134820049
Iter: 161 loss: 0.00134819117
Iter: 162 loss: 0.00134820584
Iter: 163 loss: 0.00134818652
Iter: 164 loss: 0.00134817895
Iter: 165 loss: 0.00134821853
Iter: 166 loss: 0.00134817767
Iter: 167 loss: 0.00134817162
Iter: 168 loss: 0.00134820642
Iter: 169 loss: 0.00134817045
Iter: 170 loss: 0.00134816649
Iter: 171 loss: 0.00134820153
Iter: 172 loss: 0.0013481658
Iter: 173 loss: 0.00134816265
Iter: 174 loss: 0.00134816288
Iter: 175 loss: 0.00134816067
Iter: 176 loss: 0.00134815765
Iter: 177 loss: 0.00134816731
Iter: 178 loss: 0.0013481566
Iter: 179 loss: 0.00134815392
Iter: 180 loss: 0.00134816673
Iter: 181 loss: 0.00134815346
Iter: 182 loss: 0.00134815171
Iter: 183 loss: 0.00134816696
Iter: 184 loss: 0.00134815159
Iter: 185 loss: 0.00134814985
Iter: 186 loss: 0.00134815299
Iter: 187 loss: 0.00134814973
Iter: 188 loss: 0.00134814857
Iter: 189 loss: 0.00134815823
Iter: 190 loss: 0.00134814857
Iter: 191 loss: 0.00134814763
Iter: 192 loss: 0.00134814891
Iter: 193 loss: 0.00134814752
Iter: 194 loss: 0.00134814659
Iter: 195 loss: 0.00134814763
Iter: 196 loss: 0.00134814624
Iter: 197 loss: 0.00134814554
Iter: 198 loss: 0.00134814717
Iter: 199 loss: 0.00134814531
Iter: 200 loss: 0.00134814449
Iter: 201 loss: 0.00134814729
Iter: 202 loss: 0.00134814391
Iter: 203 loss: 0.00134814391
Iter: 204 loss: 0.00134815008
Iter: 205 loss: 0.00134814391
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6
+ date
Tue Oct 27 17:03:38 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4428f98d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4428f9d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4428ed8400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4428ee5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4428ee5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4428ee5ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4428ee5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4404750840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44047500d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44046e3bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4404706400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44046bcf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4404664bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440469e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440461cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44045dbea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44045fb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440469e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44046e3ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44045a5840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440451f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4404552b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44045521e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440449d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440449dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44044b0d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f440447fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4404464158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4404446488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44043ee2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44043f2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44043b5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44043d91e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44043ee1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44043d9620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f44042dfbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.032212574
Iter: 2 loss: 0.0203915443
Iter: 3 loss: 1005.49469
Iter: 4 loss: 0.0203915387
Iter: 5 loss: 0.0286212079
Iter: 6 loss: 0.0181624293
Iter: 7 loss: 0.0133865308
Iter: 8 loss: 0.0132499551
Iter: 9 loss: 0.0102348458
Iter: 10 loss: 0.026827991
Iter: 11 loss: 0.00960081723
Iter: 12 loss: 0.00716996379
Iter: 13 loss: 0.0195010491
Iter: 14 loss: 0.00683501177
Iter: 15 loss: 0.00584289711
Iter: 16 loss: 0.00521077495
Iter: 17 loss: 0.00482546445
Iter: 18 loss: 0.00364306918
Iter: 19 loss: 0.0165109932
Iter: 20 loss: 0.00350098382
Iter: 21 loss: 0.00299442676
Iter: 22 loss: 0.0175562575
Iter: 23 loss: 0.0029934363
Iter: 24 loss: 0.00268937647
Iter: 25 loss: 0.00324477209
Iter: 26 loss: 0.00255802623
Iter: 27 loss: 0.00236345734
Iter: 28 loss: 0.00268912502
Iter: 29 loss: 0.00227520196
Iter: 30 loss: 0.00207361416
Iter: 31 loss: 0.00266340631
Iter: 32 loss: 0.00200529303
Iter: 33 loss: 0.00188930845
Iter: 34 loss: 0.00252206391
Iter: 35 loss: 0.00187052379
Iter: 36 loss: 0.00179076067
Iter: 37 loss: 0.00204775343
Iter: 38 loss: 0.00176773849
Iter: 39 loss: 0.00171015807
Iter: 40 loss: 0.00224322057
Iter: 41 loss: 0.00170687272
Iter: 42 loss: 0.0016455747
Iter: 43 loss: 0.00223421911
Iter: 44 loss: 0.00164363417
Iter: 45 loss: 0.00160847791
Iter: 46 loss: 0.00182880263
Iter: 47 loss: 0.00160366343
Iter: 48 loss: 0.0015783736
Iter: 49 loss: 0.00161772093
Iter: 50 loss: 0.00156676874
Iter: 51 loss: 0.00153984316
Iter: 52 loss: 0.0015846059
Iter: 53 loss: 0.00152738148
Iter: 54 loss: 0.00150384114
Iter: 55 loss: 0.00156570459
Iter: 56 loss: 0.00149567367
Iter: 57 loss: 0.00146730151
Iter: 58 loss: 0.00153562799
Iter: 59 loss: 0.00145705615
Iter: 60 loss: 0.00143638067
Iter: 61 loss: 0.00179183157
Iter: 62 loss: 0.00143637904
Iter: 63 loss: 0.00142096053
Iter: 64 loss: 0.00143314456
Iter: 65 loss: 0.00141173974
Iter: 66 loss: 0.0013953388
Iter: 67 loss: 0.00143312314
Iter: 68 loss: 0.00138912862
Iter: 69 loss: 0.00137249823
Iter: 70 loss: 0.00137958955
Iter: 71 loss: 0.00136112783
Iter: 72 loss: 0.00134581863
Iter: 73 loss: 0.00151365798
Iter: 74 loss: 0.00134542189
Iter: 75 loss: 0.00133412075
Iter: 76 loss: 0.00135387853
Iter: 77 loss: 0.00132909976
Iter: 78 loss: 0.00131996593
Iter: 79 loss: 0.00144554512
Iter: 80 loss: 0.00131991017
Iter: 81 loss: 0.00131395634
Iter: 82 loss: 0.00135610462
Iter: 83 loss: 0.00131346576
Iter: 84 loss: 0.00130858505
Iter: 85 loss: 0.00131495064
Iter: 86 loss: 0.0013060614
Iter: 87 loss: 0.00130182924
Iter: 88 loss: 0.00129863352
Iter: 89 loss: 0.00129724771
Iter: 90 loss: 0.00129173964
Iter: 91 loss: 0.00132957019
Iter: 92 loss: 0.00129120261
Iter: 93 loss: 0.00128734834
Iter: 94 loss: 0.00129509368
Iter: 95 loss: 0.00128577254
Iter: 96 loss: 0.00128276809
Iter: 97 loss: 0.00130694057
Iter: 98 loss: 0.00128257961
Iter: 99 loss: 0.00127973442
Iter: 100 loss: 0.00129990897
Iter: 101 loss: 0.00127946876
Iter: 102 loss: 0.00127796561
Iter: 103 loss: 0.00127910334
Iter: 104 loss: 0.00127704965
Iter: 105 loss: 0.00127557945
Iter: 106 loss: 0.00127528259
Iter: 107 loss: 0.00127430772
Iter: 108 loss: 0.00127251307
Iter: 109 loss: 0.00128819176
Iter: 110 loss: 0.00127242086
Iter: 111 loss: 0.00127115776
Iter: 112 loss: 0.00127381855
Iter: 113 loss: 0.0012706595
Iter: 114 loss: 0.00126950338
Iter: 115 loss: 0.00127354579
Iter: 116 loss: 0.00126920384
Iter: 117 loss: 0.00126834842
Iter: 118 loss: 0.00127512449
Iter: 119 loss: 0.00126828859
Iter: 120 loss: 0.00126766576
Iter: 121 loss: 0.00127332075
Iter: 122 loss: 0.00126763841
Iter: 123 loss: 0.00126711011
Iter: 124 loss: 0.00126726099
Iter: 125 loss: 0.00126672897
Iter: 126 loss: 0.00126623735
Iter: 127 loss: 0.00126616925
Iter: 128 loss: 0.00126582291
Iter: 129 loss: 0.00126514793
Iter: 130 loss: 0.00126707216
Iter: 131 loss: 0.00126493385
Iter: 132 loss: 0.00126431871
Iter: 133 loss: 0.00126622082
Iter: 134 loss: 0.00126413768
Iter: 135 loss: 0.00126359914
Iter: 136 loss: 0.00126711628
Iter: 137 loss: 0.00126354222
Iter: 138 loss: 0.00126304687
Iter: 139 loss: 0.00126392196
Iter: 140 loss: 0.00126282964
Iter: 141 loss: 0.00126244733
Iter: 142 loss: 0.00126589485
Iter: 143 loss: 0.0012624294
Iter: 144 loss: 0.00126204139
Iter: 145 loss: 0.0012624762
Iter: 146 loss: 0.00126183126
Iter: 147 loss: 0.00126149075
Iter: 148 loss: 0.00126123335
Iter: 149 loss: 0.00126112229
Iter: 150 loss: 0.0012606
Iter: 151 loss: 0.00126410718
Iter: 152 loss: 0.00126054755
Iter: 153 loss: 0.00126018212
Iter: 154 loss: 0.00126030087
Iter: 155 loss: 0.00125992228
Iter: 156 loss: 0.00125978014
Iter: 157 loss: 0.00125970575
Iter: 158 loss: 0.00125950249
Iter: 159 loss: 0.0012594033
Iter: 160 loss: 0.00125930551
Iter: 161 loss: 0.00125904381
Iter: 162 loss: 0.00125909364
Iter: 163 loss: 0.00125884812
Iter: 164 loss: 0.00125848968
Iter: 165 loss: 0.00125983509
Iter: 166 loss: 0.0012584033
Iter: 167 loss: 0.00125809608
Iter: 168 loss: 0.00125876919
Iter: 169 loss: 0.00125797838
Iter: 170 loss: 0.00125766685
Iter: 171 loss: 0.00125835603
Iter: 172 loss: 0.0012575466
Iter: 173 loss: 0.0012572764
Iter: 174 loss: 0.00125893718
Iter: 175 loss: 0.00125724403
Iter: 176 loss: 0.00125699141
Iter: 177 loss: 0.00125807058
Iter: 178 loss: 0.00125693856
Iter: 179 loss: 0.00125677162
Iter: 180 loss: 0.00125822017
Iter: 181 loss: 0.001256763
Iter: 182 loss: 0.00125661981
Iter: 183 loss: 0.00125641539
Iter: 184 loss: 0.0012564084
Iter: 185 loss: 0.00125618384
Iter: 186 loss: 0.00125711877
Iter: 187 loss: 0.00125613657
Iter: 188 loss: 0.00125594321
Iter: 189 loss: 0.00125630677
Iter: 190 loss: 0.00125586032
Iter: 191 loss: 0.00125570898
Iter: 192 loss: 0.00125807745
Iter: 193 loss: 0.00125570875
Iter: 194 loss: 0.00125556008
Iter: 195 loss: 0.00125571759
Iter: 196 loss: 0.0012554779
Iter: 197 loss: 0.00125534018
Iter: 198 loss: 0.00125531445
Iter: 199 loss: 0.00125522155
Iter: 200 loss: 0.00125504716
Iter: 201 loss: 0.00125524774
Iter: 202 loss: 0.00125495275
Iter: 203 loss: 0.00125474588
Iter: 204 loss: 0.00125588733
Iter: 205 loss: 0.00125471607
Iter: 206 loss: 0.00125453691
Iter: 207 loss: 0.00125507859
Iter: 208 loss: 0.00125448313
Iter: 209 loss: 0.00125433411
Iter: 210 loss: 0.00125460769
Iter: 211 loss: 0.00125427009
Iter: 212 loss: 0.00125412398
Iter: 213 loss: 0.00125560141
Iter: 214 loss: 0.00125411875
Iter: 215 loss: 0.00125401467
Iter: 216 loss: 0.00125454715
Iter: 217 loss: 0.00125399837
Iter: 218 loss: 0.00125391094
Iter: 219 loss: 0.00125388522
Iter: 220 loss: 0.00125383283
Iter: 221 loss: 0.0012537099
Iter: 222 loss: 0.00125413202
Iter: 223 loss: 0.00125367765
Iter: 224 loss: 0.00125357124
Iter: 225 loss: 0.00125372957
Iter: 226 loss: 0.00125352025
Iter: 227 loss: 0.00125344598
Iter: 228 loss: 0.00125344552
Iter: 229 loss: 0.00125337043
Iter: 230 loss: 0.00125332735
Iter: 231 loss: 0.00125329557
Iter: 232 loss: 0.0012532156
Iter: 233 loss: 0.00125329068
Iter: 234 loss: 0.0012531695
Iter: 235 loss: 0.00125306495
Iter: 236 loss: 0.00125330559
Iter: 237 loss: 0.00125302561
Iter: 238 loss: 0.00125293806
Iter: 239 loss: 0.00125306577
Iter: 240 loss: 0.00125289615
Iter: 241 loss: 0.00125280791
Iter: 242 loss: 0.00125366519
Iter: 243 loss: 0.00125280453
Iter: 244 loss: 0.00125273981
Iter: 245 loss: 0.00125285843
Iter: 246 loss: 0.00125271198
Iter: 247 loss: 0.0012526561
Iter: 248 loss: 0.00125317182
Iter: 249 loss: 0.00125265378
Iter: 250 loss: 0.00125260535
Iter: 251 loss: 0.00125273096
Iter: 252 loss: 0.00125258812
Iter: 253 loss: 0.00125255
Iter: 254 loss: 0.00125257485
Iter: 255 loss: 0.00125252572
Iter: 256 loss: 0.00125247973
Iter: 257 loss: 0.0012526561
Iter: 258 loss: 0.00125246961
Iter: 259 loss: 0.00125243026
Iter: 260 loss: 0.00125252036
Iter: 261 loss: 0.00125241524
Iter: 262 loss: 0.00125239231
Iter: 263 loss: 0.00125239091
Iter: 264 loss: 0.00125237391
Iter: 265 loss: 0.00125233782
Iter: 266 loss: 0.0012529029
Iter: 267 loss: 0.00125233619
Iter: 268 loss: 0.00125230406
Iter: 269 loss: 0.00125249766
Iter: 270 loss: 0.00125230022
Iter: 271 loss: 0.00125227193
Iter: 272 loss: 0.00125229789
Iter: 273 loss: 0.00125225575
Iter: 274 loss: 0.00125222816
Iter: 275 loss: 0.00125233456
Iter: 276 loss: 0.00125222234
Iter: 277 loss: 0.00125220185
Iter: 278 loss: 0.00125236902
Iter: 279 loss: 0.00125220022
Iter: 280 loss: 0.00125218427
Iter: 281 loss: 0.00125223724
Iter: 282 loss: 0.00125218008
Iter: 283 loss: 0.00125216809
Iter: 284 loss: 0.00125229731
Iter: 285 loss: 0.00125216832
Iter: 286 loss: 0.00125215924
Iter: 287 loss: 0.00125216076
Iter: 288 loss: 0.00125215179
Iter: 289 loss: 0.00125214201
Iter: 290 loss: 0.00125216122
Iter: 291 loss: 0.00125213736
Iter: 292 loss: 0.0012521263
Iter: 293 loss: 0.0012521653
Iter: 294 loss: 0.00125212385
Iter: 295 loss: 0.00125211617
Iter: 296 loss: 0.00125218695
Iter: 297 loss: 0.00125211652
Iter: 298 loss: 0.00125211012
Iter: 299 loss: 0.00125213317
Iter: 300 loss: 0.00125210849
Iter: 301 loss: 0.00125210336
Iter: 302 loss: 0.00125209882
Iter: 303 loss: 0.00125209778
Iter: 304 loss: 0.00125209079
Iter: 305 loss: 0.00125210721
Iter: 306 loss: 0.00125208835
Iter: 307 loss: 0.00125208241
Iter: 308 loss: 0.00125211407
Iter: 309 loss: 0.0012520809
Iter: 310 loss: 0.00125207554
Iter: 311 loss: 0.00125208287
Iter: 312 loss: 0.0012520731
Iter: 313 loss: 0.00125206704
Iter: 314 loss: 0.00125210593
Iter: 315 loss: 0.00125206693
Iter: 316 loss: 0.00125206297
Iter: 317 loss: 0.00125208392
Iter: 318 loss: 0.00125206274
Iter: 319 loss: 0.00125205889
Iter: 320 loss: 0.00125207938
Iter: 321 loss: 0.00125205866
Iter: 322 loss: 0.00125205645
Iter: 323 loss: 0.00125205866
Iter: 324 loss: 0.00125205459
Iter: 325 loss: 0.00125205168
Iter: 326 loss: 0.0012520575
Iter: 327 loss: 0.00125205133
Iter: 328 loss: 0.00125204865
Iter: 329 loss: 0.00125205761
Iter: 330 loss: 0.00125204772
Iter: 331 loss: 0.00125204609
Iter: 332 loss: 0.00125206751
Iter: 333 loss: 0.00125204539
Iter: 334 loss: 0.00125204423
Iter: 335 loss: 0.00125204469
Iter: 336 loss: 0.00125204318
Iter: 337 loss: 0.00125204166
Iter: 338 loss: 0.0012520412
Iter: 339 loss: 0.0012520398
Iter: 340 loss: 0.00125203701
Iter: 341 loss: 0.00125204504
Iter: 342 loss: 0.00125203712
Iter: 343 loss: 0.00125203456
Iter: 344 loss: 0.0012520384
Iter: 345 loss: 0.00125203305
Iter: 346 loss: 0.00125203154
Iter: 347 loss: 0.0012520405
Iter: 348 loss: 0.0012520313
Iter: 349 loss: 0.00125202956
Iter: 350 loss: 0.00125204446
Iter: 351 loss: 0.00125203
Iter: 352 loss: 0.00125202886
Iter: 353 loss: 0.00125203433
Iter: 354 loss: 0.00125202839
Iter: 355 loss: 0.00125202769
Iter: 356 loss: 0.00125202944
Iter: 357 loss: 0.00125202618
Iter: 358 loss: 0.00125202583
Iter: 359 loss: 0.00125202793
Iter: 360 loss: 0.00125202537
Iter: 361 loss: 0.00125202455
Iter: 362 loss: 0.0012520263
Iter: 363 loss: 0.00125202443
Iter: 364 loss: 0.0012520235
Iter: 365 loss: 0.00125203026
Iter: 366 loss: 0.00125202374
Iter: 367 loss: 0.00125202269
Iter: 368 loss: 0.0012520249
Iter: 369 loss: 0.00125202234
Iter: 370 loss: 0.00125202234
Iter: 371 loss: 0.00125202315
Iter: 372 loss: 0.00125202222
Iter: 373 loss: 0.00125202141
Iter: 374 loss: 0.00125202141
Iter: 375 loss: 0.00125202071
Iter: 376 loss: 0.00125202024
Iter: 377 loss: 0.00125202234
Iter: 378 loss: 0.00125201978
Iter: 379 loss: 0.00125201908
Iter: 380 loss: 0.00125202
Iter: 381 loss: 0.00125201838
Iter: 382 loss: 0.00125201838
Iter: 383 loss: 0.00125202304
Iter: 384 loss: 0.00125201768
Iter: 385 loss: 0.00125201815
Iter: 386 loss: 0.00125202048
Iter: 387 loss: 0.00125201792
Iter: 388 loss: 0.00125201792
Iter: 389 loss: 0.0012520192
Iter: 390 loss: 0.00125201675
Iter: 391 loss: 0.00125201745
Iter: 392 loss: 0.00125201698
Iter: 393 loss: 0.00125201663
Iter: 394 loss: 0.0012520164
Iter: 395 loss: 0.00125201838
Iter: 396 loss: 0.0012520164
Iter: 397 loss: 0.00125201652
Iter: 398 loss: 0.00125201722
Iter: 399 loss: 0.00125201629
Iter: 400 loss: 0.00125201594
Iter: 401 loss: 0.00125201908
Iter: 402 loss: 0.00125201594
Iter: 403 loss: 0.00125201594
Iter: 404 loss: 0.0012520157
Iter: 405 loss: 0.00125201559
Iter: 406 loss: 0.00125201559
Iter: 407 loss: 0.00125201652
Iter: 408 loss: 0.00125201477
Iter: 409 loss: 0.00125201489
Iter: 410 loss: 0.00125201535
Iter: 411 loss: 0.00125201477
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2
+ date
Tue Oct 27 17:05:34 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fed0cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fed1d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1140abe268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1140a62950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1140a62488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fed40950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1140a62510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fec7e7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10feca4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10fec58048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d83730d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8392d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d83379d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8365598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d837b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d837bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d832aea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d832ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d82a3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d825bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8215ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8215268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8215158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8223158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8183598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8196c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8157d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8157bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d811f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d80bf1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d80be620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d80842f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d808d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d8034ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10d806b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f10c010fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0654585734
Iter: 2 loss: 3303.21387
Iter: 3 loss: 0.065458551
Iter: 4 loss: 1724.1593
Iter: 5 loss: 0.0654293448
Iter: 6 loss: 0.0503118187
Iter: 7 loss: 0.0563816391
Iter: 8 loss: 0.0426671244
Iter: 9 loss: 0.0412809178
Iter: 10 loss: 0.0935744643
Iter: 11 loss: 0.0412322357
Iter: 12 loss: 0.0435582437
Iter: 13 loss: 0.0389487147
Iter: 14 loss: 0.032506194
Iter: 15 loss: 397.496124
Iter: 16 loss: 0.0737457648
Iter: 17 loss: 0.0360367186
Iter: 18 loss: 0.0308260582
Iter: 19 loss: 0.0284237247
Iter: 20 loss: 0.023424916
Iter: 21 loss: 0.0233538095
Iter: 22 loss: 0.0187604129
Iter: 23 loss: 0.0540718026
Iter: 24 loss: 0.0183343198
Iter: 25 loss: 0.0170161538
Iter: 26 loss: 0.0192106217
Iter: 27 loss: 0.0166608281
Iter: 28 loss: 0.0157258809
Iter: 29 loss: 0.0170251206
Iter: 30 loss: 0.015172095
Iter: 31 loss: 0.0135102598
Iter: 32 loss: 0.0316254459
Iter: 33 loss: 0.0133601073
Iter: 34 loss: 0.0114648482
Iter: 35 loss: 0.0152713116
Iter: 36 loss: 0.0106018409
Iter: 37 loss: 0.00862772856
Iter: 38 loss: 0.0575562119
Iter: 39 loss: 0.00855062809
Iter: 40 loss: 0.00710204942
Iter: 41 loss: 0.558102
Iter: 42 loss: 0.00710189715
Iter: 43 loss: 0.00641283672
Iter: 44 loss: 0.0101455972
Iter: 45 loss: 0.0062931031
Iter: 46 loss: 0.00576560851
Iter: 47 loss: 0.0077280933
Iter: 48 loss: 0.00562836742
Iter: 49 loss: 0.00505064614
Iter: 50 loss: 0.00503677549
Iter: 51 loss: 0.00452113431
Iter: 52 loss: 0.0100879651
Iter: 53 loss: 0.00451087579
Iter: 54 loss: 0.0042852452
Iter: 55 loss: 0.00475101173
Iter: 56 loss: 0.00418275967
Iter: 57 loss: 0.00399208581
Iter: 58 loss: 0.00435278
Iter: 59 loss: 0.00391033
Iter: 60 loss: 0.00370404706
Iter: 61 loss: 0.00401061866
Iter: 62 loss: 0.00360412
Iter: 63 loss: 0.00340503571
Iter: 64 loss: 0.00551418634
Iter: 65 loss: 0.00339517556
Iter: 66 loss: 0.00320410565
Iter: 67 loss: 0.0040462506
Iter: 68 loss: 0.00316929165
Iter: 69 loss: 0.00295788562
Iter: 70 loss: 0.00317792455
Iter: 71 loss: 0.00283099012
Iter: 72 loss: 0.00263219047
Iter: 73 loss: 0.0035576
Iter: 74 loss: 0.00259286258
Iter: 75 loss: 0.00244287448
Iter: 76 loss: 0.00379998097
Iter: 77 loss: 0.00243479759
Iter: 78 loss: 0.00232567685
Iter: 79 loss: 0.00274456711
Iter: 80 loss: 0.00229963101
Iter: 81 loss: 0.00218339264
Iter: 82 loss: 0.00403570291
Iter: 83 loss: 0.00218234467
Iter: 84 loss: 0.00212929817
Iter: 85 loss: 0.00220783846
Iter: 86 loss: 0.00210447237
Iter: 87 loss: 0.00204508519
Iter: 88 loss: 0.00198745285
Iter: 89 loss: 0.00197373494
Iter: 90 loss: 0.0019094228
Iter: 91 loss: 0.0023799683
Iter: 92 loss: 0.00190439471
Iter: 93 loss: 0.00185096287
Iter: 94 loss: 0.00211706664
Iter: 95 loss: 0.00184109202
Iter: 96 loss: 0.00179680111
Iter: 97 loss: 0.00189875683
Iter: 98 loss: 0.0017802139
Iter: 99 loss: 0.00174402446
Iter: 100 loss: 0.0020122258
Iter: 101 loss: 0.00174142991
Iter: 102 loss: 0.00171223551
Iter: 103 loss: 0.00180750911
Iter: 104 loss: 0.0017034437
Iter: 105 loss: 0.00168430782
Iter: 106 loss: 0.00167070539
Iter: 107 loss: 0.00166401279
Iter: 108 loss: 0.00164148083
Iter: 109 loss: 0.001660084
Iter: 110 loss: 0.0016279018
Iter: 111 loss: 0.00160278461
Iter: 112 loss: 0.0017929048
Iter: 113 loss: 0.00160082302
Iter: 114 loss: 0.00158317969
Iter: 115 loss: 0.00159605138
Iter: 116 loss: 0.0015722391
Iter: 117 loss: 0.00155783712
Iter: 118 loss: 0.00162730506
Iter: 119 loss: 0.00155542884
Iter: 120 loss: 0.00154348952
Iter: 121 loss: 0.00167954178
Iter: 122 loss: 0.00154319254
Iter: 123 loss: 0.00153547665
Iter: 124 loss: 0.00152365305
Iter: 125 loss: 0.00152345933
Iter: 126 loss: 0.00150908856
Iter: 127 loss: 0.00164613465
Iter: 128 loss: 0.00150842615
Iter: 129 loss: 0.00149609637
Iter: 130 loss: 0.00152136758
Iter: 131 loss: 0.00149116851
Iter: 132 loss: 0.00148037262
Iter: 133 loss: 0.00147234765
Iter: 134 loss: 0.00146876241
Iter: 135 loss: 0.00146941771
Iter: 136 loss: 0.00146225514
Iter: 137 loss: 0.001456219
Iter: 138 loss: 0.00144819287
Iter: 139 loss: 0.00144774141
Iter: 140 loss: 0.00143932202
Iter: 141 loss: 0.00143521908
Iter: 142 loss: 0.00143112952
Iter: 143 loss: 0.00142251654
Iter: 144 loss: 0.0014258842
Iter: 145 loss: 0.0014165875
Iter: 146 loss: 0.00140814472
Iter: 147 loss: 0.00140276679
Iter: 148 loss: 0.00139942497
Iter: 149 loss: 0.00138861337
Iter: 150 loss: 0.00148356147
Iter: 151 loss: 0.00138810661
Iter: 152 loss: 0.00137932855
Iter: 153 loss: 0.00139397394
Iter: 154 loss: 0.00137532316
Iter: 155 loss: 0.00136721809
Iter: 156 loss: 0.00140077446
Iter: 157 loss: 0.00136552239
Iter: 158 loss: 0.00135885633
Iter: 159 loss: 0.00135519193
Iter: 160 loss: 0.00135222217
Iter: 161 loss: 0.00134375179
Iter: 162 loss: 0.00139213819
Iter: 163 loss: 0.00134264934
Iter: 164 loss: 0.00133432192
Iter: 165 loss: 0.00133991754
Iter: 166 loss: 0.00132904947
Iter: 167 loss: 0.00131920807
Iter: 168 loss: 0.00132664107
Iter: 169 loss: 0.00131312665
Iter: 170 loss: 0.00131296657
Iter: 171 loss: 0.00130842649
Iter: 172 loss: 0.00130439107
Iter: 173 loss: 0.00129787647
Iter: 174 loss: 0.00129782828
Iter: 175 loss: 0.00129226944
Iter: 176 loss: 0.00131061277
Iter: 177 loss: 0.00129075279
Iter: 178 loss: 0.00128518709
Iter: 179 loss: 0.00128547754
Iter: 180 loss: 0.00128079252
Iter: 181 loss: 0.00127401971
Iter: 182 loss: 0.001285078
Iter: 183 loss: 0.00127088639
Iter: 184 loss: 0.00126297935
Iter: 185 loss: 0.00130115845
Iter: 186 loss: 0.00126155105
Iter: 187 loss: 0.00125564774
Iter: 188 loss: 0.00132615364
Iter: 189 loss: 0.00125558372
Iter: 190 loss: 0.00125143328
Iter: 191 loss: 0.00124871731
Iter: 192 loss: 0.00124712544
Iter: 193 loss: 0.00124073
Iter: 194 loss: 0.00127422041
Iter: 195 loss: 0.00123974506
Iter: 196 loss: 0.00123350462
Iter: 197 loss: 0.00125045679
Iter: 198 loss: 0.00123141427
Iter: 199 loss: 0.00122650585
Iter: 200 loss: 0.00122733531
Iter: 201 loss: 0.00122281117
Iter: 202 loss: 0.0012157606
Iter: 203 loss: 0.00122815941
Iter: 204 loss: 0.00121266302
Iter: 205 loss: 0.00120931584
Iter: 206 loss: 0.0012085787
Iter: 207 loss: 0.0012049661
Iter: 208 loss: 0.0012076057
Iter: 209 loss: 0.00120275712
Iter: 210 loss: 0.00119964359
Iter: 211 loss: 0.00119818537
Iter: 212 loss: 0.0011966459
Iter: 213 loss: 0.00119124446
Iter: 214 loss: 0.00119679759
Iter: 215 loss: 0.00118824164
Iter: 216 loss: 0.00118275057
Iter: 217 loss: 0.00118084298
Iter: 218 loss: 0.00117772107
Iter: 219 loss: 0.00117361348
Iter: 220 loss: 0.00117340032
Iter: 221 loss: 0.00116934755
Iter: 222 loss: 0.00117975834
Iter: 223 loss: 0.00116792717
Iter: 224 loss: 0.00116427313
Iter: 225 loss: 0.00116209872
Iter: 226 loss: 0.00116058171
Iter: 227 loss: 0.00115711614
Iter: 228 loss: 0.0011977799
Iter: 229 loss: 0.00115706329
Iter: 230 loss: 0.00115405419
Iter: 231 loss: 0.00115661544
Iter: 232 loss: 0.00115228491
Iter: 233 loss: 0.00114928826
Iter: 234 loss: 0.00115266046
Iter: 235 loss: 0.0011476737
Iter: 236 loss: 0.0011445469
Iter: 237 loss: 0.0011753228
Iter: 238 loss: 0.00114442967
Iter: 239 loss: 0.00114292349
Iter: 240 loss: 0.00114287063
Iter: 241 loss: 0.00114184793
Iter: 242 loss: 0.00113957829
Iter: 243 loss: 0.0011723059
Iter: 244 loss: 0.00113946875
Iter: 245 loss: 0.00113701262
Iter: 246 loss: 0.00114660803
Iter: 247 loss: 0.0011364473
Iter: 248 loss: 0.00113430806
Iter: 249 loss: 0.00114350033
Iter: 250 loss: 0.00113386568
Iter: 251 loss: 0.00113232061
Iter: 252 loss: 0.00113437208
Iter: 253 loss: 0.00113154366
Iter: 254 loss: 0.00112977088
Iter: 255 loss: 0.00113141246
Iter: 256 loss: 0.0011287427
Iter: 257 loss: 0.00112748519
Iter: 258 loss: 0.00112737436
Iter: 259 loss: 0.0011264506
Iter: 260 loss: 0.00112530333
Iter: 261 loss: 0.00112520484
Iter: 262 loss: 0.0011235096
Iter: 263 loss: 0.00113065355
Iter: 264 loss: 0.00112315407
Iter: 265 loss: 0.00112204417
Iter: 266 loss: 0.00113417825
Iter: 267 loss: 0.00112202007
Iter: 268 loss: 0.00112122134
Iter: 269 loss: 0.00111978571
Iter: 270 loss: 0.00115478761
Iter: 271 loss: 0.00111978583
Iter: 272 loss: 0.00111892796
Iter: 273 loss: 0.0011189155
Iter: 274 loss: 0.00111779186
Iter: 275 loss: 0.00111964648
Iter: 276 loss: 0.00111727812
Iter: 277 loss: 0.0011166645
Iter: 278 loss: 0.0011164106
Iter: 279 loss: 0.00111608836
Iter: 280 loss: 0.00111521571
Iter: 281 loss: 0.00111623097
Iter: 282 loss: 0.00111474958
Iter: 283 loss: 0.00111378368
Iter: 284 loss: 0.00111661921
Iter: 285 loss: 0.00111348694
Iter: 286 loss: 0.00111256703
Iter: 287 loss: 0.00111711922
Iter: 288 loss: 0.00111240847
Iter: 289 loss: 0.00111168483
Iter: 290 loss: 0.00111800688
Iter: 291 loss: 0.00111164874
Iter: 292 loss: 0.00111118041
Iter: 293 loss: 0.00111364538
Iter: 294 loss: 0.00111110625
Iter: 295 loss: 0.00111065852
Iter: 296 loss: 0.00111032114
Iter: 297 loss: 0.00111017539
Iter: 298 loss: 0.00110956759
Iter: 299 loss: 0.00111126434
Iter: 300 loss: 0.00110937189
Iter: 301 loss: 0.00110883045
Iter: 302 loss: 0.00111270766
Iter: 303 loss: 0.00110878376
Iter: 304 loss: 0.00110834488
Iter: 305 loss: 0.00110849296
Iter: 306 loss: 0.00110803416
Iter: 307 loss: 0.00110753905
Iter: 308 loss: 0.00111061591
Iter: 309 loss: 0.00110748131
Iter: 310 loss: 0.00110715837
Iter: 311 loss: 0.00110715092
Iter: 312 loss: 0.00110700284
Iter: 313 loss: 0.00110657141
Iter: 314 loss: 0.00110828574
Iter: 315 loss: 0.00110639527
Iter: 316 loss: 0.00110589492
Iter: 317 loss: 0.00110941078
Iter: 318 loss: 0.00110584882
Iter: 319 loss: 0.0011054643
Iter: 320 loss: 0.00110567978
Iter: 321 loss: 0.001105214
Iter: 322 loss: 0.00110467069
Iter: 323 loss: 0.00110762496
Iter: 324 loss: 0.00110459072
Iter: 325 loss: 0.00110429991
Iter: 326 loss: 0.00110713835
Iter: 327 loss: 0.0011042892
Iter: 328 loss: 0.00110394554
Iter: 329 loss: 0.00110419455
Iter: 330 loss: 0.00110373332
Iter: 331 loss: 0.00110344053
Iter: 332 loss: 0.00110491272
Iter: 333 loss: 0.00110339175
Iter: 334 loss: 0.00110317417
Iter: 335 loss: 0.00110302516
Iter: 336 loss: 0.00110294507
Iter: 337 loss: 0.00110265124
Iter: 338 loss: 0.00110546662
Iter: 339 loss: 0.0011026396
Iter: 340 loss: 0.00110241352
Iter: 341 loss: 0.00110297208
Iter: 342 loss: 0.00110233296
Iter: 343 loss: 0.00110217393
Iter: 344 loss: 0.00110217254
Iter: 345 loss: 0.00110202213
Iter: 346 loss: 0.00110185472
Iter: 347 loss: 0.00110183121
Iter: 348 loss: 0.00110165903
Iter: 349 loss: 0.00110133388
Iter: 350 loss: 0.00110841496
Iter: 351 loss: 0.00110133272
Iter: 352 loss: 0.00110104703
Iter: 353 loss: 0.00110466196
Iter: 354 loss: 0.00110104459
Iter: 355 loss: 0.00110080547
Iter: 356 loss: 0.00110126683
Iter: 357 loss: 0.00110070524
Iter: 358 loss: 0.00110050954
Iter: 359 loss: 0.00110193819
Iter: 360 loss: 0.00110049371
Iter: 361 loss: 0.0011002915
Iter: 362 loss: 0.00110112689
Iter: 363 loss: 0.00110024901
Iter: 364 loss: 0.00110006449
Iter: 365 loss: 0.00110045064
Iter: 366 loss: 0.00109999161
Iter: 367 loss: 0.00109986705
Iter: 368 loss: 0.00109995203
Iter: 369 loss: 0.00109978858
Iter: 370 loss: 0.00109961769
Iter: 371 loss: 0.0011000681
Iter: 372 loss: 0.00109956
Iter: 373 loss: 0.0010994192
Iter: 374 loss: 0.00110021268
Iter: 375 loss: 0.00109939941
Iter: 376 loss: 0.00109927985
Iter: 377 loss: 0.00110007112
Iter: 378 loss: 0.00109926739
Iter: 379 loss: 0.0010991504
Iter: 380 loss: 0.0010996731
Iter: 381 loss: 0.00109912804
Iter: 382 loss: 0.00109904166
Iter: 383 loss: 0.00109886518
Iter: 384 loss: 0.00110199116
Iter: 385 loss: 0.00109886203
Iter: 386 loss: 0.00109867658
Iter: 387 loss: 0.00109884213
Iter: 388 loss: 0.00109856739
Iter: 389 loss: 0.00109835586
Iter: 390 loss: 0.00109898578
Iter: 391 loss: 0.00109829125
Iter: 392 loss: 0.00109813095
Iter: 393 loss: 0.00109982304
Iter: 394 loss: 0.00109812745
Iter: 395 loss: 0.00109800952
Iter: 396 loss: 0.00109873153
Iter: 397 loss: 0.00109799451
Iter: 398 loss: 0.00109787425
Iter: 399 loss: 0.00109823153
Iter: 400 loss: 0.00109783816
Iter: 401 loss: 0.00109773956
Iter: 402 loss: 0.00109773199
Iter: 403 loss: 0.00109765981
Iter: 404 loss: 0.00109751907
Iter: 405 loss: 0.00109775993
Iter: 406 loss: 0.00109745609
Iter: 407 loss: 0.0010973278
Iter: 408 loss: 0.00109813921
Iter: 409 loss: 0.00109731313
Iter: 410 loss: 0.00109720393
Iter: 411 loss: 0.00109753327
Iter: 412 loss: 0.00109717122
Iter: 413 loss: 0.00109706027
Iter: 414 loss: 0.00109831814
Iter: 415 loss: 0.00109705911
Iter: 416 loss: 0.00109699473
Iter: 417 loss: 0.00109697832
Iter: 418 loss: 0.00109693897
Iter: 419 loss: 0.00109684968
Iter: 420 loss: 0.00109666481
Iter: 421 loss: 0.00109988544
Iter: 422 loss: 0.00109666097
Iter: 423 loss: 0.00109650497
Iter: 424 loss: 0.001097976
Iter: 425 loss: 0.0010964981
Iter: 426 loss: 0.00109637179
Iter: 427 loss: 0.00109663745
Iter: 428 loss: 0.00109632174
Iter: 429 loss: 0.00109619589
Iter: 430 loss: 0.00109648681
Iter: 431 loss: 0.00109614944
Iter: 432 loss: 0.00109604513
Iter: 433 loss: 0.00109604374
Iter: 434 loss: 0.00109598017
Iter: 435 loss: 0.0010959541
Iter: 436 loss: 0.00109592057
Iter: 437 loss: 0.00109582627
Iter: 438 loss: 0.001095791
Iter: 439 loss: 0.00109573896
Iter: 440 loss: 0.00109559507
Iter: 441 loss: 0.00109651266
Iter: 442 loss: 0.00109557901
Iter: 443 loss: 0.00109549495
Iter: 444 loss: 0.00109582965
Iter: 445 loss: 0.00109547703
Iter: 446 loss: 0.00109538797
Iter: 447 loss: 0.00109615433
Iter: 448 loss: 0.00109538389
Iter: 449 loss: 0.00109530974
Iter: 450 loss: 0.00109537435
Iter: 451 loss: 0.00109526631
Iter: 452 loss: 0.00109519763
Iter: 453 loss: 0.001095079
Iter: 454 loss: 0.001095079
Iter: 455 loss: 0.00109494035
Iter: 456 loss: 0.0010959619
Iter: 457 loss: 0.00109492824
Iter: 458 loss: 0.00109483779
Iter: 459 loss: 0.00109481462
Iter: 460 loss: 0.00109475781
Iter: 461 loss: 0.0010946322
Iter: 462 loss: 0.00109520403
Iter: 463 loss: 0.00109460857
Iter: 464 loss: 0.00109452894
Iter: 465 loss: 0.00109548401
Iter: 466 loss: 0.00109452778
Iter: 467 loss: 0.0010944393
Iter: 468 loss: 0.00109457283
Iter: 469 loss: 0.00109439727
Iter: 470 loss: 0.0010943308
Iter: 471 loss: 0.00109427911
Iter: 472 loss: 0.00109425862
Iter: 473 loss: 0.0010941542
Iter: 474 loss: 0.00109490193
Iter: 475 loss: 0.00109414477
Iter: 476 loss: 0.00109406875
Iter: 477 loss: 0.00109418994
Iter: 478 loss: 0.00109403278
Iter: 479 loss: 0.00109398761
Iter: 480 loss: 0.00109398167
Iter: 481 loss: 0.00109394547
Iter: 482 loss: 0.00109399855
Iter: 483 loss: 0.00109392894
Iter: 484 loss: 0.00109389145
Iter: 485 loss: 0.00109382858
Iter: 486 loss: 0.00109382882
Iter: 487 loss: 0.00109374942
Iter: 488 loss: 0.00109398016
Iter: 489 loss: 0.00109372521
Iter: 490 loss: 0.00109365629
Iter: 491 loss: 0.00109373755
Iter: 492 loss: 0.00109362
Iter: 493 loss: 0.00109353417
Iter: 494 loss: 0.00109387527
Iter: 495 loss: 0.00109351403
Iter: 496 loss: 0.00109344965
Iter: 497 loss: 0.00109350285
Iter: 498 loss: 0.00109341124
Iter: 499 loss: 0.00109340553
Iter: 500 loss: 0.0010933741
Iter: 501 loss: 0.0010933507
Iter: 502 loss: 0.00109328469
Iter: 503 loss: 0.00109361892
Iter: 504 loss: 0.00109326211
Iter: 505 loss: 0.00109319808
Iter: 506 loss: 0.00109386491
Iter: 507 loss: 0.00109319645
Iter: 508 loss: 0.00109314639
Iter: 509 loss: 0.00109318702
Iter: 510 loss: 0.00109311589
Iter: 511 loss: 0.00109305524
Iter: 512 loss: 0.00109356863
Iter: 513 loss: 0.0010930514
Iter: 514 loss: 0.001093011
Iter: 515 loss: 0.0010935904
Iter: 516 loss: 0.00109301088
Iter: 517 loss: 0.00109299016
Iter: 518 loss: 0.00109295454
Iter: 519 loss: 0.00109380973
Iter: 520 loss: 0.001092955
Iter: 521 loss: 0.00109290425
Iter: 522 loss: 0.00109301077
Iter: 523 loss: 0.00109288399
Iter: 524 loss: 0.00109284
Iter: 525 loss: 0.00109277491
Iter: 526 loss: 0.00109277363
Iter: 527 loss: 0.00109272241
Iter: 528 loss: 0.00109271985
Iter: 529 loss: 0.00109268
Iter: 530 loss: 0.0010926344
Iter: 531 loss: 0.00109262846
Iter: 532 loss: 0.00109258643
Iter: 533 loss: 0.00109258515
Iter: 534 loss: 0.0010925422
Iter: 535 loss: 0.00109270762
Iter: 536 loss: 0.00109253125
Iter: 537 loss: 0.00109250552
Iter: 538 loss: 0.00109247048
Iter: 539 loss: 0.00109246792
Iter: 540 loss: 0.00109242136
Iter: 541 loss: 0.00109244918
Iter: 542 loss: 0.00109238969
Iter: 543 loss: 0.00109234022
Iter: 544 loss: 0.00109291566
Iter: 545 loss: 0.00109233882
Iter: 546 loss: 0.00109230436
Iter: 547 loss: 0.00109280087
Iter: 548 loss: 0.00109230448
Iter: 549 loss: 0.00109227456
Iter: 550 loss: 0.0010922451
Iter: 551 loss: 0.00109223858
Iter: 552 loss: 0.00109220366
Iter: 553 loss: 0.00109226699
Iter: 554 loss: 0.00109218806
Iter: 555 loss: 0.00109214766
Iter: 556 loss: 0.00109222753
Iter: 557 loss: 0.00109212939
Iter: 558 loss: 0.00109208806
Iter: 559 loss: 0.00109216606
Iter: 560 loss: 0.00109207
Iter: 561 loss: 0.00109202671
Iter: 562 loss: 0.00109204138
Iter: 563 loss: 0.00109199714
Iter: 564 loss: 0.00109194731
Iter: 565 loss: 0.00109223381
Iter: 566 loss: 0.00109194103
Iter: 567 loss: 0.00109189935
Iter: 568 loss: 0.00109222648
Iter: 569 loss: 0.00109189667
Iter: 570 loss: 0.00109185372
Iter: 571 loss: 0.00109199132
Iter: 572 loss: 0.00109184301
Iter: 573 loss: 0.00109181984
Iter: 574 loss: 0.00109180179
Iter: 575 loss: 0.00109179434
Iter: 576 loss: 0.00109174824
Iter: 577 loss: 0.0010917444
Iter: 578 loss: 0.00109170773
Iter: 579 loss: 0.0010916777
Iter: 580 loss: 0.00109167758
Iter: 581 loss: 0.00109163811
Iter: 582 loss: 0.00109168608
Iter: 583 loss: 0.00109161786
Iter: 584 loss: 0.00109158549
Iter: 585 loss: 0.00109157874
Iter: 586 loss: 0.00109155686
Iter: 587 loss: 0.00109151658
Iter: 588 loss: 0.00109165767
Iter: 589 loss: 0.0010915061
Iter: 590 loss: 0.00109146268
Iter: 591 loss: 0.00109150214
Iter: 592 loss: 0.00109143695
Iter: 593 loss: 0.00109139644
Iter: 594 loss: 0.00109165045
Iter: 595 loss: 0.00109139271
Iter: 596 loss: 0.00109135162
Iter: 597 loss: 0.00109133613
Iter: 598 loss: 0.0010913146
Iter: 599 loss: 0.00109126535
Iter: 600 loss: 0.00109134021
Iter: 601 loss: 0.00109124242
Iter: 602 loss: 0.00109121925
Iter: 603 loss: 0.00109120749
Iter: 604 loss: 0.00109118654
Iter: 605 loss: 0.00109114661
Iter: 606 loss: 0.00109205802
Iter: 607 loss: 0.00109114696
Iter: 608 loss: 0.00109109911
Iter: 609 loss: 0.00109112728
Iter: 610 loss: 0.00109106814
Iter: 611 loss: 0.00109101459
Iter: 612 loss: 0.00109115045
Iter: 613 loss: 0.00109099608
Iter: 614 loss: 0.00109097804
Iter: 615 loss: 0.00109096454
Iter: 616 loss: 0.00109094311
Iter: 617 loss: 0.00109090784
Iter: 618 loss: 0.00109090749
Iter: 619 loss: 0.00109086907
Iter: 620 loss: 0.00109085836
Iter: 621 loss: 0.00109083462
Iter: 622 loss: 0.00109078293
Iter: 623 loss: 0.00109117536
Iter: 624 loss: 0.0010907785
Iter: 625 loss: 0.00109073007
Iter: 626 loss: 0.00109077687
Iter: 627 loss: 0.00109070458
Iter: 628 loss: 0.00109065673
Iter: 629 loss: 0.00109079946
Iter: 630 loss: 0.00109064067
Iter: 631 loss: 0.00109059399
Iter: 632 loss: 0.00109069445
Iter: 633 loss: 0.00109057641
Iter: 634 loss: 0.00109053263
Iter: 635 loss: 0.00109090214
Iter: 636 loss: 0.00109052949
Iter: 637 loss: 0.00109050306
Iter: 638 loss: 0.00109076884
Iter: 639 loss: 0.00109050237
Iter: 640 loss: 0.00109047408
Iter: 641 loss: 0.00109042309
Iter: 642 loss: 0.0010915976
Iter: 643 loss: 0.00109042274
Iter: 644 loss: 0.00109038292
Iter: 645 loss: 0.00109050283
Iter: 646 loss: 0.00109037152
Iter: 647 loss: 0.00109033647
Iter: 648 loss: 0.00109060656
Iter: 649 loss: 0.00109033333
Iter: 650 loss: 0.00109029026
Iter: 651 loss: 0.0010904459
Iter: 652 loss: 0.00109027978
Iter: 653 loss: 0.00109026267
Iter: 654 loss: 0.00109022693
Iter: 655 loss: 0.00109083205
Iter: 656 loss: 0.00109022611
Iter: 657 loss: 0.00109018933
Iter: 658 loss: 0.0010905345
Iter: 659 loss: 0.001090187
Iter: 660 loss: 0.00109016104
Iter: 661 loss: 0.00109018083
Iter: 662 loss: 0.00109014451
Iter: 663 loss: 0.0010901005
Iter: 664 loss: 0.00109014718
Iter: 665 loss: 0.00109007501
Iter: 666 loss: 0.00109003868
Iter: 667 loss: 0.0010901629
Iter: 668 loss: 0.00109003007
Iter: 669 loss: 0.00108999386
Iter: 670 loss: 0.0010901296
Iter: 671 loss: 0.00108998583
Iter: 672 loss: 0.00108995719
Iter: 673 loss: 0.00109024555
Iter: 674 loss: 0.00108995615
Iter: 675 loss: 0.00108992984
Iter: 676 loss: 0.00108996988
Iter: 677 loss: 0.00108991703
Iter: 678 loss: 0.00108989095
Iter: 679 loss: 0.00108987535
Iter: 680 loss: 0.00108986325
Iter: 681 loss: 0.00108983088
Iter: 682 loss: 0.00108985696
Iter: 683 loss: 0.00108981109
Iter: 684 loss: 0.00108979875
Iter: 685 loss: 0.00108978653
Iter: 686 loss: 0.00108977617
Iter: 687 loss: 0.00108974788
Iter: 688 loss: 0.00108993461
Iter: 689 loss: 0.00108974054
Iter: 690 loss: 0.00108970539
Iter: 691 loss: 0.00108979747
Iter: 692 loss: 0.00108969305
Iter: 693 loss: 0.00108966092
Iter: 694 loss: 0.00108983926
Iter: 695 loss: 0.00108965533
Iter: 696 loss: 0.00108962331
Iter: 697 loss: 0.0010897
Iter: 698 loss: 0.00108961167
Iter: 699 loss: 0.00108958478
Iter: 700 loss: 0.00108964718
Iter: 701 loss: 0.00108957407
Iter: 702 loss: 0.00108954264
Iter: 703 loss: 0.00108956883
Iter: 704 loss: 0.00108952285
Iter: 705 loss: 0.00108949386
Iter: 706 loss: 0.00108984357
Iter: 707 loss: 0.00108949328
Iter: 708 loss: 0.00108946639
Iter: 709 loss: 0.00108958362
Iter: 710 loss: 0.00108946103
Iter: 711 loss: 0.00108944
Iter: 712 loss: 0.00108945661
Iter: 713 loss: 0.00108942727
Iter: 714 loss: 0.00108940597
Iter: 715 loss: 0.00108939246
Iter: 716 loss: 0.00108938385
Iter: 717 loss: 0.00108938012
Iter: 718 loss: 0.00108937104
Iter: 719 loss: 0.001089358
Iter: 720 loss: 0.00108934473
Iter: 721 loss: 0.00108934159
Iter: 722 loss: 0.00108932448
Iter: 723 loss: 0.00108928478
Iter: 724 loss: 0.00108984951
Iter: 725 loss: 0.00108928303
Iter: 726 loss: 0.00108926371
Iter: 727 loss: 0.00108926231
Iter: 728 loss: 0.00108924357
Iter: 729 loss: 0.00108925591
Iter: 730 loss: 0.00108923216
Iter: 731 loss: 0.00108921027
Iter: 732 loss: 0.00108933158
Iter: 733 loss: 0.00108920678
Iter: 734 loss: 0.00108918932
Iter: 735 loss: 0.00108918524
Iter: 736 loss: 0.00108917523
Iter: 737 loss: 0.00108915404
Iter: 738 loss: 0.00108935102
Iter: 739 loss: 0.00108915288
Iter: 740 loss: 0.00108913844
Iter: 741 loss: 0.00108931179
Iter: 742 loss: 0.00108913798
Iter: 743 loss: 0.00108912692
Iter: 744 loss: 0.00108911842
Iter: 745 loss: 0.0010891133
Iter: 746 loss: 0.00108909816
Iter: 747 loss: 0.00108914613
Iter: 748 loss: 0.00108909281
Iter: 749 loss: 0.00108908059
Iter: 750 loss: 0.00108911
Iter: 751 loss: 0.0010890757
Iter: 752 loss: 0.00108905835
Iter: 753 loss: 0.00108917686
Iter: 754 loss: 0.00108905521
Iter: 755 loss: 0.00108904787
Iter: 756 loss: 0.00108903053
Iter: 757 loss: 0.00108936173
Iter: 758 loss: 0.00108903088
Iter: 759 loss: 0.00108901365
Iter: 760 loss: 0.00108906534
Iter: 761 loss: 0.00108900899
Iter: 762 loss: 0.00108899316
Iter: 763 loss: 0.00108902249
Iter: 764 loss: 0.00108898734
Iter: 765 loss: 0.00108897197
Iter: 766 loss: 0.00108917058
Iter: 767 loss: 0.00108897267
Iter: 768 loss: 0.00108896312
Iter: 769 loss: 0.00108895591
Iter: 770 loss: 0.00108895346
Iter: 771 loss: 0.00108893798
Iter: 772 loss: 0.00108899118
Iter: 773 loss: 0.00108893518
Iter: 774 loss: 0.00108892424
Iter: 775 loss: 0.00108892436
Iter: 776 loss: 0.00108891528
Iter: 777 loss: 0.00108891912
Iter: 778 loss: 0.00108890957
Iter: 779 loss: 0.00108889921
Iter: 780 loss: 0.0010889119
Iter: 781 loss: 0.00108889374
Iter: 782 loss: 0.00108888315
Iter: 783 loss: 0.00108890818
Iter: 784 loss: 0.00108887977
Iter: 785 loss: 0.00108887127
Iter: 786 loss: 0.0010888715
Iter: 787 loss: 0.00108886627
Iter: 788 loss: 0.00108885719
Iter: 789 loss: 0.00108907
Iter: 790 loss: 0.00108885684
Iter: 791 loss: 0.00108884636
Iter: 792 loss: 0.00108883518
Iter: 793 loss: 0.00108883274
Iter: 794 loss: 0.0010888176
Iter: 795 loss: 0.00108895777
Iter: 796 loss: 0.00108881691
Iter: 797 loss: 0.00108880701
Iter: 798 loss: 0.00108886161
Iter: 799 loss: 0.00108880654
Iter: 800 loss: 0.00108879583
Iter: 801 loss: 0.0010888204
Iter: 802 loss: 0.00108879292
Iter: 803 loss: 0.00108878291
Iter: 804 loss: 0.00108877022
Iter: 805 loss: 0.00108877
Iter: 806 loss: 0.00108876615
Iter: 807 loss: 0.00108876242
Iter: 808 loss: 0.00108875614
Iter: 809 loss: 0.00108876487
Iter: 810 loss: 0.00108875276
Iter: 811 loss: 0.00108874566
Iter: 812 loss: 0.00108874927
Iter: 813 loss: 0.00108874089
Iter: 814 loss: 0.00108873448
Iter: 815 loss: 0.00108876778
Iter: 816 loss: 0.00108873425
Iter: 817 loss: 0.00108872959
Iter: 818 loss: 0.00108879502
Iter: 819 loss: 0.00108872913
Iter: 820 loss: 0.0010887261
Iter: 821 loss: 0.00108871819
Iter: 822 loss: 0.00108889665
Iter: 823 loss: 0.00108871842
Iter: 824 loss: 0.00108871155
Iter: 825 loss: 0.0010887119
Iter: 826 loss: 0.00108870561
Iter: 827 loss: 0.001088697
Iter: 828 loss: 0.00108872459
Iter: 829 loss: 0.00108869513
Iter: 830 loss: 0.00108868664
Iter: 831 loss: 0.00108871
Iter: 832 loss: 0.00108868373
Iter: 833 loss: 0.00108867674
Iter: 834 loss: 0.00108876126
Iter: 835 loss: 0.00108867697
Iter: 836 loss: 0.00108867127
Iter: 837 loss: 0.00108866254
Iter: 838 loss: 0.00108866277
Iter: 839 loss: 0.00108865486
Iter: 840 loss: 0.0010886552
Iter: 841 loss: 0.00108864962
Iter: 842 loss: 0.00108870154
Iter: 843 loss: 0.0010886502
Iter: 844 loss: 0.00108864554
Iter: 845 loss: 0.00108864263
Iter: 846 loss: 0.00108864147
Iter: 847 loss: 0.00108863553
Iter: 848 loss: 0.00108866009
Iter: 849 loss: 0.00108863425
Iter: 850 loss: 0.00108863087
Iter: 851 loss: 0.00108867721
Iter: 852 loss: 0.00108863111
Iter: 853 loss: 0.00108862715
Iter: 854 loss: 0.00108862261
Iter: 855 loss: 0.00108862156
Iter: 856 loss: 0.00108861714
Iter: 857 loss: 0.00108861993
Iter: 858 loss: 0.00108861353
Iter: 859 loss: 0.00108860782
Iter: 860 loss: 0.0010886048
Iter: 861 loss: 0.00108860165
Iter: 862 loss: 0.00108859467
Iter: 863 loss: 0.0010886665
Iter: 864 loss: 0.00108859432
Iter: 865 loss: 0.0010885892
Iter: 866 loss: 0.00108860957
Iter: 867 loss: 0.0010885878
Iter: 868 loss: 0.00108858256
Iter: 869 loss: 0.00108859409
Iter: 870 loss: 0.00108857895
Iter: 871 loss: 0.00108857523
Iter: 872 loss: 0.00108857919
Iter: 873 loss: 0.00108857232
Iter: 874 loss: 0.00108856848
Iter: 875 loss: 0.00108856871
Iter: 876 loss: 0.00108856498
Iter: 877 loss: 0.00108856242
Iter: 878 loss: 0.00108856091
Iter: 879 loss: 0.00108855683
Iter: 880 loss: 0.00108857523
Iter: 881 loss: 0.00108855474
Iter: 882 loss: 0.00108855218
Iter: 883 loss: 0.00108858128
Iter: 884 loss: 0.00108855241
Iter: 885 loss: 0.00108854868
Iter: 886 loss: 0.00108855311
Iter: 887 loss: 0.00108854705
Iter: 888 loss: 0.00108854345
Iter: 889 loss: 0.00108853844
Iter: 890 loss: 0.00108853914
Iter: 891 loss: 0.00108853343
Iter: 892 loss: 0.0010885396
Iter: 893 loss: 0.00108853064
Iter: 894 loss: 0.00108852633
Iter: 895 loss: 0.00108856428
Iter: 896 loss: 0.00108852459
Iter: 897 loss: 0.00108852
Iter: 898 loss: 0.00108852785
Iter: 899 loss: 0.00108851888
Iter: 900 loss: 0.00108851411
Iter: 901 loss: 0.00108855218
Iter: 902 loss: 0.00108851364
Iter: 903 loss: 0.00108851038
Iter: 904 loss: 0.00108851027
Iter: 905 loss: 0.00108850771
Iter: 906 loss: 0.00108850421
Iter: 907 loss: 0.0010885438
Iter: 908 loss: 0.00108850375
Iter: 909 loss: 0.0010885
Iter: 910 loss: 0.00108852144
Iter: 911 loss: 0.0010885
Iter: 912 loss: 0.00108849793
Iter: 913 loss: 0.0010884963
Iter: 914 loss: 0.00108849606
Iter: 915 loss: 0.00108849327
Iter: 916 loss: 0.00108852249
Iter: 917 loss: 0.00108849257
Iter: 918 loss: 0.00108849118
Iter: 919 loss: 0.00108850584
Iter: 920 loss: 0.00108849141
Iter: 921 loss: 0.00108848978
Iter: 922 loss: 0.00108848629
Iter: 923 loss: 0.00108855159
Iter: 924 loss: 0.00108848675
Iter: 925 loss: 0.00108848419
Iter: 926 loss: 0.00108848501
Iter: 927 loss: 0.00108848256
Iter: 928 loss: 0.0010884786
Iter: 929 loss: 0.00108848745
Iter: 930 loss: 0.00108847767
Iter: 931 loss: 0.00108847418
Iter: 932 loss: 0.00108850026
Iter: 933 loss: 0.00108847476
Iter: 934 loss: 0.00108847162
Iter: 935 loss: 0.00108847662
Iter: 936 loss: 0.00108847115
Iter: 937 loss: 0.00108846789
Iter: 938 loss: 0.00108848047
Iter: 939 loss: 0.00108846766
Iter: 940 loss: 0.00108846684
Iter: 941 loss: 0.00108846847
Iter: 942 loss: 0.00108846556
Iter: 943 loss: 0.00108846324
Iter: 944 loss: 0.00108846347
Iter: 945 loss: 0.0010884623
Iter: 946 loss: 0.00108846137
Iter: 947 loss: 0.00108846161
Iter: 948 loss: 0.00108845986
Iter: 949 loss: 0.00108846906
Iter: 950 loss: 0.00108845974
Iter: 951 loss: 0.00108845835
Iter: 952 loss: 0.00108846836
Iter: 953 loss: 0.00108845788
Iter: 954 loss: 0.00108845672
Iter: 955 loss: 0.00108845602
Iter: 956 loss: 0.0010884566
Iter: 957 loss: 0.00108845439
Iter: 958 loss: 0.00108845229
Iter: 959 loss: 0.00108845229
Iter: 960 loss: 0.0010884502
Iter: 961 loss: 0.00108846906
Iter: 962 loss: 0.00108845031
Iter: 963 loss: 0.00108844868
Iter: 964 loss: 0.00108845474
Iter: 965 loss: 0.0010884488
Iter: 966 loss: 0.00108844717
Iter: 967 loss: 0.00108845183
Iter: 968 loss: 0.00108844601
Iter: 969 loss: 0.00108844507
Iter: 970 loss: 0.00108845031
Iter: 971 loss: 0.00108844333
Iter: 972 loss: 0.00108844205
Iter: 973 loss: 0.00108844531
Iter: 974 loss: 0.00108844147
Iter: 975 loss: 0.0010884403
Iter: 976 loss: 0.00108845788
Iter: 977 loss: 0.00108844065
Iter: 978 loss: 0.00108844019
Iter: 979 loss: 0.00108843925
Iter: 980 loss: 0.00108843832
Iter: 981 loss: 0.00108843832
Iter: 982 loss: 0.00108844577
Iter: 983 loss: 0.00108843728
Iter: 984 loss: 0.00108843716
Iter: 985 loss: 0.0010884403
Iter: 986 loss: 0.00108843669
Iter: 987 loss: 0.00108843704
Iter: 988 loss: 0.0010884353
Iter: 989 loss: 0.00108843576
Iter: 990 loss: 0.0010884346
Iter: 991 loss: 0.0010884339
Iter: 992 loss: 0.00108843355
Iter: 993 loss: 0.00108843262
Iter: 994 loss: 0.00108843588
Iter: 995 loss: 0.0010884318
Iter: 996 loss: 0.00108843017
Iter: 997 loss: 0.00108843483
Iter: 998 loss: 0.00108842924
Iter: 999 loss: 0.00108842808
Iter: 1000 loss: 0.00108843693
Iter: 1001 loss: 0.00108842808
Iter: 1002 loss: 0.00108842633
Iter: 1003 loss: 0.00108843239
Iter: 1004 loss: 0.00108842703
Iter: 1005 loss: 0.00108842505
Iter: 1006 loss: 0.00108842622
Iter: 1007 loss: 0.00108842389
Iter: 1008 loss: 0.00108842435
Iter: 1009 loss: 0.001088424
Iter: 1010 loss: 0.00108842319
Iter: 1011 loss: 0.00108842331
Iter: 1012 loss: 0.00108842284
Iter: 1013 loss: 0.00108842144
Iter: 1014 loss: 0.00108842389
Iter: 1015 loss: 0.00108842109
Iter: 1016 loss: 0.00108842179
Iter: 1017 loss: 0.0010884247
Iter: 1018 loss: 0.00108842202
Iter: 1019 loss: 0.00108842063
Iter: 1020 loss: 0.00108841981
Iter: 1021 loss: 0.00108841993
Iter: 1022 loss: 0.00108841946
Iter: 1023 loss: 0.00108841923
Iter: 1024 loss: 0.00108841888
Iter: 1025 loss: 0.00108841807
Iter: 1026 loss: 0.00108841923
Iter: 1027 loss: 0.00108841667
Iter: 1028 loss: 0.00108841492
Iter: 1029 loss: 0.00108842179
Iter: 1030 loss: 0.00108841492
Iter: 1031 loss: 0.00108841364
Iter: 1032 loss: 0.00108841853
Iter: 1033 loss: 0.00108841341
Iter: 1034 loss: 0.00108841306
Iter: 1035 loss: 0.0010884176
Iter: 1036 loss: 0.00108841236
Iter: 1037 loss: 0.00108841062
Iter: 1038 loss: 0.00108841492
Iter: 1039 loss: 0.00108841085
Iter: 1040 loss: 0.0010884105
Iter: 1041 loss: 0.00108841748
Iter: 1042 loss: 0.0010884105
Iter: 1043 loss: 0.0010884091
Iter: 1044 loss: 0.00108841062
Iter: 1045 loss: 0.00108840922
Iter: 1046 loss: 0.0010884084
Iter: 1047 loss: 0.00108841038
Iter: 1048 loss: 0.00108840805
Iter: 1049 loss: 0.00108840759
Iter: 1050 loss: 0.00108841108
Iter: 1051 loss: 0.00108840794
Iter: 1052 loss: 0.00108840736
Iter: 1053 loss: 0.00108840642
Iter: 1054 loss: 0.00108840736
Iter: 1055 loss: 0.00108840573
Iter: 1056 loss: 0.00108840596
Iter: 1057 loss: 0.00108840596
Iter: 1058 loss: 0.00108840514
Iter: 1059 loss: 0.00108840433
Iter: 1060 loss: 0.00108840363
Iter: 1061 loss: 0.00108840247
Iter: 1062 loss: 0.00108840782
Iter: 1063 loss: 0.00108840247
Iter: 1064 loss: 0.00108840107
Iter: 1065 loss: 0.00108840712
Iter: 1066 loss: 0.0010884006
Iter: 1067 loss: 0.00108839991
Iter: 1068 loss: 0.0010884041
Iter: 1069 loss: 0.00108839944
Iter: 1070 loss: 0.00108839944
Iter: 1071 loss: 0.0010884013
Iter: 1072 loss: 0.00108839874
Iter: 1073 loss: 0.00108839851
Iter: 1074 loss: 0.00108840433
Iter: 1075 loss: 0.00108839851
Iter: 1076 loss: 0.00108839734
Iter: 1077 loss: 0.00108839932
Iter: 1078 loss: 0.00108839676
Iter: 1079 loss: 0.00108839758
Iter: 1080 loss: 0.00108839711
Iter: 1081 loss: 0.00108839606
Iter: 1082 loss: 0.00108839595
Iter: 1083 loss: 0.00108840177
Iter: 1084 loss: 0.00108839606
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4
+ date
Tue Oct 27 17:10:02 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f217bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f2174950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f20b52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f20c8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f20c8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f20c82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f20c8158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f203a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f203a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1fed1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1feda60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1f4de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1f4dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1f8ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1f07158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1f41d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1ee7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1f07f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1eb9d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1eb97b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1e06950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1e2eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1e2e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1d886a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1d88ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1da3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1d6aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1d52158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1d2e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1cd12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1cd6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1c99f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1cbf1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1cd11e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1cbf620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd1f1bc6bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.314335495
Iter: 2 loss: 14488.5801
Iter: 3 loss: 0.314334631
Iter: 4 loss: 13383.2539
Iter: 5 loss: 0.314321
Iter: 6 loss: 8546.04297
Iter: 7 loss: 1387.39062
Iter: 8 loss: 0.314251781
Iter: 9 loss: 1958.15979
Iter: 10 loss: 513.673035
Iter: 11 loss: 136.030884
Iter: 12 loss: 0.229859889
Iter: 13 loss: 0.215645537
Iter: 14 loss: 0.216445595
Iter: 15 loss: 0.207625821
Iter: 16 loss: 0.20761025
Iter: 17 loss: 638.155396
Iter: 18 loss: 0.201374441
Iter: 19 loss: 0.201714724
Iter: 20 loss: 223.969833
Iter: 21 loss: 296.163544
Iter: 22 loss: 0.652526438
Iter: 23 loss: 0.201580584
Iter: 24 loss: 0.215526044
Iter: 25 loss: 0.200571448
Iter: 26 loss: 0.282183826
Iter: 27 loss: 0.19955641
Iter: 28 loss: 0.177490264
Iter: 29 loss: 0.177339718
Iter: 30 loss: 0.175194427
Iter: 31 loss: 0.170770645
Iter: 32 loss: 0.156983733
Iter: 33 loss: 4.42136955
Iter: 34 loss: 0.156925842
Iter: 35 loss: 86.5876694
Iter: 36 loss: 0.156913966
Iter: 37 loss: 141.038589
Iter: 38 loss: 0.153410405
Iter: 39 loss: 0.134406283
Iter: 40 loss: 0.152293
Iter: 41 loss: 0.127355963
Iter: 42 loss: 0.126527503
Iter: 43 loss: 0.125423789
Iter: 44 loss: 0.125339523
Iter: 45 loss: 0.113090225
Iter: 46 loss: 0.434817493
Iter: 47 loss: 0.134232402
Iter: 48 loss: 0.117269181
Iter: 49 loss: 0.126932174
Iter: 50 loss: 0.113462739
Iter: 51 loss: 0.109674357
Iter: 52 loss: 0.109108582
Iter: 53 loss: 0.106998481
Iter: 54 loss: 0.116775803
Iter: 55 loss: 0.106541067
Iter: 56 loss: 0.103059128
Iter: 57 loss: 0.119448438
Iter: 58 loss: 0.102809265
Iter: 59 loss: 0.0995062366
Iter: 60 loss: 0.101057336
Iter: 61 loss: 0.0969405
Iter: 62 loss: 0.0933220312
Iter: 63 loss: 0.145878017
Iter: 64 loss: 0.0930224061
Iter: 65 loss: 0.0860182345
Iter: 66 loss: 32.3626976
Iter: 67 loss: 0.0860182345
Iter: 68 loss: 0.0825385898
Iter: 69 loss: 0.0819390714
Iter: 70 loss: 0.0869275853
Iter: 71 loss: 0.0798816159
Iter: 72 loss: 0.0781958103
Iter: 73 loss: 0.0779309
Iter: 74 loss: 0.0761921853
Iter: 75 loss: 0.0786659
Iter: 76 loss: 0.0751593933
Iter: 77 loss: 0.0719323307
Iter: 78 loss: 0.136924684
Iter: 79 loss: 0.071842514
Iter: 80 loss: 0.0707616434
Iter: 81 loss: 0.0703474879
Iter: 82 loss: 0.0691309869
Iter: 83 loss: 0.068808049
Iter: 84 loss: 0.066948086
Iter: 85 loss: 0.0963034
Iter: 86 loss: 0.0668682158
Iter: 87 loss: 0.0651129559
Iter: 88 loss: 0.0995470509
Iter: 89 loss: 0.0650575459
Iter: 90 loss: 0.0630096942
Iter: 91 loss: 0.0688266084
Iter: 92 loss: 0.0622906499
Iter: 93 loss: 0.0592570193
Iter: 94 loss: 0.0595106147
Iter: 95 loss: 0.0568139777
Iter: 96 loss: 0.0552660152
Iter: 97 loss: 0.0614375323
Iter: 98 loss: 0.054688409
Iter: 99 loss: 0.053198427
Iter: 100 loss: 0.0763012394
Iter: 101 loss: 0.0531703681
Iter: 102 loss: 0.051681079
Iter: 103 loss: 0.0551842302
Iter: 104 loss: 0.0511025786
Iter: 105 loss: 0.0499263853
Iter: 106 loss: 0.0499262847
Iter: 107 loss: 0.0494746193
Iter: 108 loss: 0.0506731309
Iter: 109 loss: 0.0492904149
Iter: 110 loss: 0.0489016734
Iter: 111 loss: 0.0504666418
Iter: 112 loss: 0.0487784818
Iter: 113 loss: 0.0482710525
Iter: 114 loss: 0.0488384403
Iter: 115 loss: 0.0479837433
Iter: 116 loss: 0.0470311977
Iter: 117 loss: 0.0483657569
Iter: 118 loss: 0.0465515107
Iter: 119 loss: 0.0459499881
Iter: 120 loss: 0.0460200161
Iter: 121 loss: 0.0454372689
Iter: 122 loss: 0.0448862165
Iter: 123 loss: 0.0456632
Iter: 124 loss: 0.0446204692
Iter: 125 loss: 0.0429173782
Iter: 126 loss: 0.0519544818
Iter: 127 loss: 0.0427020863
Iter: 128 loss: 0.0430392288
Iter: 129 loss: 0.0417899378
Iter: 130 loss: 0.0412722304
Iter: 131 loss: 0.0410031229
Iter: 132 loss: 0.0403385
Iter: 133 loss: 0.044990357
Iter: 134 loss: 0.0402970649
Iter: 135 loss: 0.040063031
Iter: 136 loss: 0.0414828807
Iter: 137 loss: 0.0400227085
Iter: 138 loss: 0.0399639755
Iter: 139 loss: 0.0400572
Iter: 140 loss: 0.0399357341
Iter: 141 loss: 0.0397932753
Iter: 142 loss: 0.0396318287
Iter: 143 loss: 0.0396123901
Iter: 144 loss: 0.0393087901
Iter: 145 loss: 0.0403248817
Iter: 146 loss: 0.0392324105
Iter: 147 loss: 0.0389763974
Iter: 148 loss: 0.0391836613
Iter: 149 loss: 0.0388099626
Iter: 150 loss: 0.0383279696
Iter: 151 loss: 0.0379257761
Iter: 152 loss: 0.0377830602
Iter: 153 loss: 0.0370693542
Iter: 154 loss: 0.0435135961
Iter: 155 loss: 0.0370343179
Iter: 156 loss: 0.036296349
Iter: 157 loss: 0.0394060053
Iter: 158 loss: 0.0361144207
Iter: 159 loss: 0.0355723202
Iter: 160 loss: 0.0355573744
Iter: 161 loss: 0.035131935
Iter: 162 loss: 0.0347758979
Iter: 163 loss: 0.0348083675
Iter: 164 loss: 0.0345173851
Iter: 165 loss: 0.0337928943
Iter: 166 loss: 0.0378513783
Iter: 167 loss: 0.0336408094
Iter: 168 loss: 0.0328866132
Iter: 169 loss: 0.0355601236
Iter: 170 loss: 0.0327040255
Iter: 171 loss: 0.0337035768
Iter: 172 loss: 0.0324978977
Iter: 173 loss: 0.0322596394
Iter: 174 loss: 0.0328166634
Iter: 175 loss: 0.0321629271
Iter: 176 loss: 0.0318488628
Iter: 177 loss: 0.0320279077
Iter: 178 loss: 0.0316585153
Iter: 179 loss: 0.0314551219
Iter: 180 loss: 0.0311369225
Iter: 181 loss: 0.0311298966
Iter: 182 loss: 0.0305683184
Iter: 183 loss: 0.0310706794
Iter: 184 loss: 0.030224096
Iter: 185 loss: 0.0299731214
Iter: 186 loss: 0.0299303606
Iter: 187 loss: 0.0296247751
Iter: 188 loss: 0.0296134483
Iter: 189 loss: 0.0293396525
Iter: 190 loss: 0.0304205976
Iter: 191 loss: 0.0292663798
Iter: 192 loss: 0.0289126523
Iter: 193 loss: 0.0282245278
Iter: 194 loss: 0.0458879396
Iter: 195 loss: 0.0282212812
Iter: 196 loss: 0.0275777616
Iter: 197 loss: 0.0314973071
Iter: 198 loss: 0.0274688769
Iter: 199 loss: 0.0271033123
Iter: 200 loss: 0.0270974655
Iter: 201 loss: 0.0269035362
Iter: 202 loss: 0.0277733132
Iter: 203 loss: 0.0268594883
Iter: 204 loss: 0.0267127
Iter: 205 loss: 0.0280409791
Iter: 206 loss: 0.0267088078
Iter: 207 loss: 0.0265430752
Iter: 208 loss: 0.0270224474
Iter: 209 loss: 0.0264842622
Iter: 210 loss: 0.0263305828
Iter: 211 loss: 0.0266400557
Iter: 212 loss: 0.0262717959
Iter: 213 loss: 0.0261639059
Iter: 214 loss: 0.0261399895
Iter: 215 loss: 0.0260685496
Iter: 216 loss: 0.0258360785
Iter: 217 loss: 0.0263447613
Iter: 218 loss: 0.025745932
Iter: 219 loss: 0.0256764181
Iter: 220 loss: 0.0255844891
Iter: 221 loss: 0.0254620463
Iter: 222 loss: 0.0253149271
Iter: 223 loss: 0.0252984315
Iter: 224 loss: 0.0250914283
Iter: 225 loss: 0.0250372291
Iter: 226 loss: 0.02490348
Iter: 227 loss: 0.0245101899
Iter: 228 loss: 0.0275516286
Iter: 229 loss: 0.0244777445
Iter: 230 loss: 0.0243111048
Iter: 231 loss: 0.0242781
Iter: 232 loss: 0.0241744705
Iter: 233 loss: 0.0241521988
Iter: 234 loss: 0.0240881518
Iter: 235 loss: 0.0240805168
Iter: 236 loss: 0.0240327455
Iter: 237 loss: 0.0239400789
Iter: 238 loss: 0.0238831565
Iter: 239 loss: 0.0238460451
Iter: 240 loss: 0.0237138495
Iter: 241 loss: 0.0236434229
Iter: 242 loss: 0.0235802643
Iter: 243 loss: 0.023413714
Iter: 244 loss: 0.0244583376
Iter: 245 loss: 0.0233931486
Iter: 246 loss: 0.023139324
Iter: 247 loss: 0.0245858189
Iter: 248 loss: 0.0230931677
Iter: 249 loss: 0.0229348894
Iter: 250 loss: 0.0234707631
Iter: 251 loss: 0.0228951275
Iter: 252 loss: 0.0226905216
Iter: 253 loss: 0.0224934109
Iter: 254 loss: 0.0224443376
Iter: 255 loss: 0.0221805759
Iter: 256 loss: 0.0226407796
Iter: 257 loss: 0.0220649168
Iter: 258 loss: 0.0218497571
Iter: 259 loss: 0.0222794116
Iter: 260 loss: 0.0217691511
Iter: 261 loss: 0.0215191357
Iter: 262 loss: 0.0217143595
Iter: 263 loss: 0.0213666335
Iter: 264 loss: 0.0211392343
Iter: 265 loss: 0.0218373574
Iter: 266 loss: 0.0210669637
Iter: 267 loss: 0.0209513493
Iter: 268 loss: 0.0209328253
Iter: 269 loss: 0.0208589602
Iter: 270 loss: 0.020974122
Iter: 271 loss: 0.0208243709
Iter: 272 loss: 0.020680353
Iter: 273 loss: 0.0206765141
Iter: 274 loss: 0.0205637664
Iter: 275 loss: 0.0203834474
Iter: 276 loss: 0.0203102529
Iter: 277 loss: 0.0202145241
Iter: 278 loss: 0.020150343
Iter: 279 loss: 0.0200703945
Iter: 280 loss: 0.0199413411
Iter: 281 loss: 0.01987179
Iter: 282 loss: 0.0198161956
Iter: 283 loss: 0.0196504518
Iter: 284 loss: 0.0194867831
Iter: 285 loss: 0.0194525495
Iter: 286 loss: 0.0192798879
Iter: 287 loss: 0.0199586432
Iter: 288 loss: 0.0192438737
Iter: 289 loss: 0.0191424973
Iter: 290 loss: 0.0188947134
Iter: 291 loss: 0.0217559058
Iter: 292 loss: 0.0188673828
Iter: 293 loss: 0.0186429676
Iter: 294 loss: 0.0192113742
Iter: 295 loss: 0.0185674168
Iter: 296 loss: 0.0184542798
Iter: 297 loss: 0.0184299778
Iter: 298 loss: 0.0183552895
Iter: 299 loss: 0.0182412565
Iter: 300 loss: 0.0183329619
Iter: 301 loss: 0.0181690641
Iter: 302 loss: 0.0181918908
Iter: 303 loss: 0.0180446655
Iter: 304 loss: 0.0179380067
Iter: 305 loss: 0.0181270745
Iter: 306 loss: 0.0178900398
Iter: 307 loss: 0.0177789889
Iter: 308 loss: 0.0180516429
Iter: 309 loss: 0.0177358072
Iter: 310 loss: 0.0176080577
Iter: 311 loss: 0.0176286865
Iter: 312 loss: 0.0175102688
Iter: 313 loss: 0.0173324291
Iter: 314 loss: 0.0173540451
Iter: 315 loss: 0.0171917863
Iter: 316 loss: 0.0171030089
Iter: 317 loss: 0.0170814581
Iter: 318 loss: 0.0169763286
Iter: 319 loss: 0.016773181
Iter: 320 loss: 0.0221078955
Iter: 321 loss: 0.0167725403
Iter: 322 loss: 0.0165734217
Iter: 323 loss: 0.0172056332
Iter: 324 loss: 0.0165136606
Iter: 325 loss: 0.0164660495
Iter: 326 loss: 0.0164134987
Iter: 327 loss: 0.0164055713
Iter: 328 loss: 0.0163117964
Iter: 329 loss: 0.016265031
Iter: 330 loss: 0.0162202958
Iter: 331 loss: 0.0160605665
Iter: 332 loss: 0.0161488093
Iter: 333 loss: 0.0159549117
Iter: 334 loss: 0.015959762
Iter: 335 loss: 0.0158907343
Iter: 336 loss: 0.0158405714
Iter: 337 loss: 0.0159866679
Iter: 338 loss: 0.0158249978
Iter: 339 loss: 0.0157663599
Iter: 340 loss: 0.0157005303
Iter: 341 loss: 0.0156921707
Iter: 342 loss: 0.0155463107
Iter: 343 loss: 0.0155577101
Iter: 344 loss: 0.0154310036
Iter: 345 loss: 0.0152796581
Iter: 346 loss: 0.0152762942
Iter: 347 loss: 0.015232211
Iter: 348 loss: 0.0153027717
Iter: 349 loss: 0.0152110225
Iter: 350 loss: 0.0151752317
Iter: 351 loss: 0.0150910486
Iter: 352 loss: 0.0159838777
Iter: 353 loss: 0.0150833037
Iter: 354 loss: 0.0150046628
Iter: 355 loss: 0.0150379166
Iter: 356 loss: 0.0149521027
Iter: 357 loss: 0.0148581564
Iter: 358 loss: 0.0148527957
Iter: 359 loss: 0.0147341043
Iter: 360 loss: 0.0150580816
Iter: 361 loss: 0.0146980481
Iter: 362 loss: 0.0146274557
Iter: 363 loss: 0.0144899497
Iter: 364 loss: 0.0179747213
Iter: 365 loss: 0.0144893378
Iter: 366 loss: 0.0143021224
Iter: 367 loss: 0.0162101593
Iter: 368 loss: 0.0142946076
Iter: 369 loss: 0.0142265409
Iter: 370 loss: 0.0141847711
Iter: 371 loss: 0.0141283609
Iter: 372 loss: 0.0140406759
Iter: 373 loss: 0.0140395286
Iter: 374 loss: 0.0139276097
Iter: 375 loss: 0.0140799172
Iter: 376 loss: 0.0138705168
Iter: 377 loss: 0.0137938857
Iter: 378 loss: 0.0138561837
Iter: 379 loss: 0.013747503
Iter: 380 loss: 0.0136592062
Iter: 381 loss: 0.0141181359
Iter: 382 loss: 0.0136453016
Iter: 383 loss: 0.013543834
Iter: 384 loss: 0.0136529338
Iter: 385 loss: 0.013489495
Iter: 386 loss: 0.0133675989
Iter: 387 loss: 0.0133649465
Iter: 388 loss: 0.0132384673
Iter: 389 loss: 0.0144414473
Iter: 390 loss: 0.0132342093
Iter: 391 loss: 0.0131682539
Iter: 392 loss: 0.0138424393
Iter: 393 loss: 0.0131653883
Iter: 394 loss: 0.0131158009
Iter: 395 loss: 0.0129779093
Iter: 396 loss: 0.0137285832
Iter: 397 loss: 0.012936187
Iter: 398 loss: 0.0127432104
Iter: 399 loss: 0.0148281138
Iter: 400 loss: 0.0127377613
Iter: 401 loss: 0.0126375966
Iter: 402 loss: 0.0135266101
Iter: 403 loss: 0.0126335705
Iter: 404 loss: 0.0125298109
Iter: 405 loss: 0.0137834158
Iter: 406 loss: 0.0125278644
Iter: 407 loss: 0.012489669
Iter: 408 loss: 0.012519924
Iter: 409 loss: 0.0124666747
Iter: 410 loss: 0.0124201309
Iter: 411 loss: 0.0123506906
Iter: 412 loss: 0.0123492293
Iter: 413 loss: 0.0122571494
Iter: 414 loss: 0.0128964381
Iter: 415 loss: 0.0122499298
Iter: 416 loss: 0.0121645369
Iter: 417 loss: 0.0121637648
Iter: 418 loss: 0.0120807551
Iter: 419 loss: 0.0125716608
Iter: 420 loss: 0.0120696891
Iter: 421 loss: 0.0120131988
Iter: 422 loss: 0.0121207386
Iter: 423 loss: 0.0119902119
Iter: 424 loss: 0.0119388597
Iter: 425 loss: 0.0121946894
Iter: 426 loss: 0.0119288983
Iter: 427 loss: 0.0118615273
Iter: 428 loss: 0.0117864162
Iter: 429 loss: 0.0117758131
Iter: 430 loss: 0.0116659403
Iter: 431 loss: 0.0116565879
Iter: 432 loss: 0.011571506
Iter: 433 loss: 0.0117927659
Iter: 434 loss: 0.011537957
Iter: 435 loss: 0.0115017109
Iter: 436 loss: 0.0117434049
Iter: 437 loss: 0.0114974249
Iter: 438 loss: 0.0114836479
Iter: 439 loss: 0.0114637483
Iter: 440 loss: 0.0114631355
Iter: 441 loss: 0.0114136338
Iter: 442 loss: 0.0113713546
Iter: 443 loss: 0.0113580972
Iter: 444 loss: 0.0112683894
Iter: 445 loss: 0.0122662205
Iter: 446 loss: 0.0112657379
Iter: 447 loss: 0.0111725889
Iter: 448 loss: 0.0118423495
Iter: 449 loss: 0.0111633502
Iter: 450 loss: 0.0110988747
Iter: 451 loss: 0.0118571725
Iter: 452 loss: 0.0110977935
Iter: 453 loss: 0.0110276965
Iter: 454 loss: 0.011384
Iter: 455 loss: 0.0110155521
Iter: 456 loss: 0.0109440722
Iter: 457 loss: 0.0108161597
Iter: 458 loss: 0.0142254736
Iter: 459 loss: 0.0108161326
Iter: 460 loss: 0.0106931068
Iter: 461 loss: 0.0106855892
Iter: 462 loss: 0.0105408262
Iter: 463 loss: 0.0107905716
Iter: 464 loss: 0.0104749631
Iter: 465 loss: 0.0103923827
Iter: 466 loss: 0.0105867228
Iter: 467 loss: 0.0103616072
Iter: 468 loss: 0.0110504664
Iter: 469 loss: 0.010346774
Iter: 470 loss: 0.0103359576
Iter: 471 loss: 0.0103146536
Iter: 472 loss: 0.0107187144
Iter: 473 loss: 0.0103144553
Iter: 474 loss: 0.0102486396
Iter: 475 loss: 0.010127984
Iter: 476 loss: 0.0129643781
Iter: 477 loss: 0.0101279281
Iter: 478 loss: 0.0101376604
Iter: 479 loss: 0.0100758392
Iter: 480 loss: 0.010034034
Iter: 481 loss: 0.0100617567
Iter: 482 loss: 0.0100084161
Iter: 483 loss: 0.00992701389
Iter: 484 loss: 0.0104422234
Iter: 485 loss: 0.00991774164
Iter: 486 loss: 0.00985057093
Iter: 487 loss: 0.0103575457
Iter: 488 loss: 0.00984425
Iter: 489 loss: 0.00982333533
Iter: 490 loss: 0.00976309739
Iter: 491 loss: 0.0100503126
Iter: 492 loss: 0.0097407829
Iter: 493 loss: 0.00968133
Iter: 494 loss: 0.00988602266
Iter: 495 loss: 0.00966635905
Iter: 496 loss: 0.00964230672
Iter: 497 loss: 0.00957023073
Iter: 498 loss: 0.00979347154
Iter: 499 loss: 0.00953431055
Iter: 500 loss: 0.00945695303
Iter: 501 loss: 0.00974630378
Iter: 502 loss: 0.00943828188
Iter: 503 loss: 0.00940728374
Iter: 504 loss: 0.00949514285
Iter: 505 loss: 0.00939705223
Iter: 506 loss: 0.00933423452
Iter: 507 loss: 0.00973506458
Iter: 508 loss: 0.00932808
Iter: 509 loss: 0.00928886421
Iter: 510 loss: 0.00922301
Iter: 511 loss: 0.00922282226
Iter: 512 loss: 0.00915129669
Iter: 513 loss: 0.00915744528
Iter: 514 loss: 0.00909620337
Iter: 515 loss: 0.009052529
Iter: 516 loss: 0.00900884625
Iter: 517 loss: 0.00899920147
Iter: 518 loss: 0.00896642357
Iter: 519 loss: 0.00896641519
Iter: 520 loss: 0.00894026086
Iter: 521 loss: 0.00890281517
Iter: 522 loss: 0.00889478438
Iter: 523 loss: 0.00886941701
Iter: 524 loss: 0.00883357693
Iter: 525 loss: 0.00882263109
Iter: 526 loss: 0.00878005289
Iter: 527 loss: 0.0087854052
Iter: 528 loss: 0.00874739885
Iter: 529 loss: 0.00870078895
Iter: 530 loss: 0.00871939
Iter: 531 loss: 0.00866862
Iter: 532 loss: 0.00858035125
Iter: 533 loss: 0.00861695781
Iter: 534 loss: 0.00851815287
Iter: 535 loss: 0.00854880176
Iter: 536 loss: 0.00848462246
Iter: 537 loss: 0.0084563382
Iter: 538 loss: 0.00862053
Iter: 539 loss: 0.0084521994
Iter: 540 loss: 0.008429721
Iter: 541 loss: 0.00841539
Iter: 542 loss: 0.00840682909
Iter: 543 loss: 0.00836434308
Iter: 544 loss: 0.00839488301
Iter: 545 loss: 0.00833762623
Iter: 546 loss: 0.00828209706
Iter: 547 loss: 0.00867636316
Iter: 548 loss: 0.00827776641
Iter: 549 loss: 0.00823217258
Iter: 550 loss: 0.00875705
Iter: 551 loss: 0.00823094789
Iter: 552 loss: 0.00820897892
Iter: 553 loss: 0.00817804225
Iter: 554 loss: 0.00817688741
Iter: 555 loss: 0.00815299526
Iter: 556 loss: 0.00821575522
Iter: 557 loss: 0.00814506
Iter: 558 loss: 0.0081234
Iter: 559 loss: 0.00809267536
Iter: 560 loss: 0.00809159316
Iter: 561 loss: 0.00803655665
Iter: 562 loss: 0.00835423451
Iter: 563 loss: 0.00802986231
Iter: 564 loss: 0.0079886727
Iter: 565 loss: 0.00798585359
Iter: 566 loss: 0.00795956049
Iter: 567 loss: 0.00796524808
Iter: 568 loss: 0.00793994404
Iter: 569 loss: 0.00790594704
Iter: 570 loss: 0.00783475488
Iter: 571 loss: 0.00909729674
Iter: 572 loss: 0.007833004
Iter: 573 loss: 0.00783410948
Iter: 574 loss: 0.00780350482
Iter: 575 loss: 0.00779199181
Iter: 576 loss: 0.00777357118
Iter: 577 loss: 0.00777344313
Iter: 578 loss: 0.00772677
Iter: 579 loss: 0.0077234488
Iter: 580 loss: 0.00776338484
Iter: 581 loss: 0.00770426495
Iter: 582 loss: 0.0076937112
Iter: 583 loss: 0.00771893561
Iter: 584 loss: 0.0076898858
Iter: 585 loss: 0.00767031405
Iter: 586 loss: 0.00764112314
Iter: 587 loss: 0.00764042605
Iter: 588 loss: 0.00758124748
Iter: 589 loss: 0.00808817334
Iter: 590 loss: 0.0075784456
Iter: 591 loss: 0.00756080169
Iter: 592 loss: 0.00752865896
Iter: 593 loss: 0.00838051736
Iter: 594 loss: 0.00752863893
Iter: 595 loss: 0.00750169577
Iter: 596 loss: 0.00753295654
Iter: 597 loss: 0.00748728123
Iter: 598 loss: 0.00747488765
Iter: 599 loss: 0.00744897593
Iter: 600 loss: 0.00786695629
Iter: 601 loss: 0.00744828768
Iter: 602 loss: 0.00739181275
Iter: 603 loss: 0.00793038122
Iter: 604 loss: 0.00738983369
Iter: 605 loss: 0.00731648691
Iter: 606 loss: 0.00795319863
Iter: 607 loss: 0.00731217
Iter: 608 loss: 0.0073150103
Iter: 609 loss: 0.00721862121
Iter: 610 loss: 0.00715923123
Iter: 611 loss: 0.00753476378
Iter: 612 loss: 0.00715205818
Iter: 613 loss: 0.00711931847
Iter: 614 loss: 0.0071241213
Iter: 615 loss: 0.0070942305
Iter: 616 loss: 0.00711313
Iter: 617 loss: 0.00707971491
Iter: 618 loss: 0.00706692878
Iter: 619 loss: 0.00704241963
Iter: 620 loss: 0.00753514
Iter: 621 loss: 0.0070422641
Iter: 622 loss: 0.00701577589
Iter: 623 loss: 0.00702067465
Iter: 624 loss: 0.00699568167
Iter: 625 loss: 0.0069765579
Iter: 626 loss: 0.00693915738
Iter: 627 loss: 0.00773417531
Iter: 628 loss: 0.00693890965
Iter: 629 loss: 0.00691892719
Iter: 630 loss: 0.00691611134
Iter: 631 loss: 0.00689363759
Iter: 632 loss: 0.00707065873
Iter: 633 loss: 0.00689187786
Iter: 634 loss: 0.00687447097
Iter: 635 loss: 0.00684365956
Iter: 636 loss: 0.00684367027
Iter: 637 loss: 0.0068063708
Iter: 638 loss: 0.006851668
Iter: 639 loss: 0.00678737136
Iter: 640 loss: 0.00674246391
Iter: 641 loss: 0.00679975515
Iter: 642 loss: 0.00671868585
Iter: 643 loss: 0.00665548816
Iter: 644 loss: 0.00670064148
Iter: 645 loss: 0.00661641546
Iter: 646 loss: 0.00653793
Iter: 647 loss: 0.00696805818
Iter: 648 loss: 0.00652638
Iter: 649 loss: 0.00648616301
Iter: 650 loss: 0.00680167321
Iter: 651 loss: 0.00648342539
Iter: 652 loss: 0.00645061303
Iter: 653 loss: 0.00645016925
Iter: 654 loss: 0.00641227514
Iter: 655 loss: 0.00686330721
Iter: 656 loss: 0.00641143508
Iter: 657 loss: 0.00640191324
Iter: 658 loss: 0.00636853231
Iter: 659 loss: 0.00631754752
Iter: 660 loss: 0.00631213374
Iter: 661 loss: 0.00644805096
Iter: 662 loss: 0.00628764834
Iter: 663 loss: 0.00623884
Iter: 664 loss: 0.00686333049
Iter: 665 loss: 0.00623814575
Iter: 666 loss: 0.00622568186
Iter: 667 loss: 0.00637520943
Iter: 668 loss: 0.00622556172
Iter: 669 loss: 0.00621712301
Iter: 670 loss: 0.00619332492
Iter: 671 loss: 0.00632220227
Iter: 672 loss: 0.00618564105
Iter: 673 loss: 0.00614729943
Iter: 674 loss: 0.00611597
Iter: 675 loss: 0.00610495452
Iter: 676 loss: 0.00605338812
Iter: 677 loss: 0.00627270062
Iter: 678 loss: 0.00604369026
Iter: 679 loss: 0.00600460358
Iter: 680 loss: 0.0059805382
Iter: 681 loss: 0.00596473087
Iter: 682 loss: 0.00593022862
Iter: 683 loss: 0.0060340045
Iter: 684 loss: 0.00591949094
Iter: 685 loss: 0.00589896552
Iter: 686 loss: 0.00621511275
Iter: 687 loss: 0.00589896925
Iter: 688 loss: 0.00587278279
Iter: 689 loss: 0.00591827
Iter: 690 loss: 0.0058608437
Iter: 691 loss: 0.00584927108
Iter: 692 loss: 0.00590972789
Iter: 693 loss: 0.00584749551
Iter: 694 loss: 0.00582762714
Iter: 695 loss: 0.00578625966
Iter: 696 loss: 0.00651400723
Iter: 697 loss: 0.00578533346
Iter: 698 loss: 0.00573916547
Iter: 699 loss: 0.00574603863
Iter: 700 loss: 0.00570400758
Iter: 701 loss: 0.00566876307
Iter: 702 loss: 0.00575663056
Iter: 703 loss: 0.00565560581
Iter: 704 loss: 0.00561777456
Iter: 705 loss: 0.00604792871
Iter: 706 loss: 0.00561703043
Iter: 707 loss: 0.00559366215
Iter: 708 loss: 0.00560401
Iter: 709 loss: 0.00557736307
Iter: 710 loss: 0.00554521941
Iter: 711 loss: 0.00567342062
Iter: 712 loss: 0.00553834811
Iter: 713 loss: 0.00550847966
Iter: 714 loss: 0.0055278372
Iter: 715 loss: 0.00548935495
Iter: 716 loss: 0.00546369515
Iter: 717 loss: 0.00551161
Iter: 718 loss: 0.00545295421
Iter: 719 loss: 0.00543925539
Iter: 720 loss: 0.00556250941
Iter: 721 loss: 0.00543850474
Iter: 722 loss: 0.00542885484
Iter: 723 loss: 0.00544243865
Iter: 724 loss: 0.00542420615
Iter: 725 loss: 0.00540940929
Iter: 726 loss: 0.00537479948
Iter: 727 loss: 0.00581394462
Iter: 728 loss: 0.00537210843
Iter: 729 loss: 0.00532027148
Iter: 730 loss: 0.00532857329
Iter: 731 loss: 0.00528108049
Iter: 732 loss: 0.00522142742
Iter: 733 loss: 0.00563619286
Iter: 734 loss: 0.00521524204
Iter: 735 loss: 0.00519658253
Iter: 736 loss: 0.00519577507
Iter: 737 loss: 0.00517731812
Iter: 738 loss: 0.00522788055
Iter: 739 loss: 0.00517090689
Iter: 740 loss: 0.0051585366
Iter: 741 loss: 0.00512764743
Iter: 742 loss: 0.00542313047
Iter: 743 loss: 0.00512339827
Iter: 744 loss: 0.0050894767
Iter: 745 loss: 0.00517746061
Iter: 746 loss: 0.00507753249
Iter: 747 loss: 0.00506427605
Iter: 748 loss: 0.00505269831
Iter: 749 loss: 0.00504909363
Iter: 750 loss: 0.00502722804
Iter: 751 loss: 0.00504428055
Iter: 752 loss: 0.00501380395
Iter: 753 loss: 0.00501261326
Iter: 754 loss: 0.00500262529
Iter: 755 loss: 0.00499689393
Iter: 756 loss: 0.00498719839
Iter: 757 loss: 0.004987197
Iter: 758 loss: 0.00497258687
Iter: 759 loss: 0.0049609486
Iter: 760 loss: 0.00495646149
Iter: 761 loss: 0.00494278222
Iter: 762 loss: 0.00490910793
Iter: 763 loss: 0.00526915304
Iter: 764 loss: 0.004905059
Iter: 765 loss: 0.00487115653
Iter: 766 loss: 0.00486952625
Iter: 767 loss: 0.00482969
Iter: 768 loss: 0.00482926378
Iter: 769 loss: 0.00480066659
Iter: 770 loss: 0.00481318636
Iter: 771 loss: 0.00478074513
Iter: 772 loss: 0.00475523388
Iter: 773 loss: 0.00476619648
Iter: 774 loss: 0.00473781768
Iter: 775 loss: 0.00505393231
Iter: 776 loss: 0.00472589396
Iter: 777 loss: 0.0047213356
Iter: 778 loss: 0.00471566943
Iter: 779 loss: 0.00471517
Iter: 780 loss: 0.00470605493
Iter: 781 loss: 0.00469722738
Iter: 782 loss: 0.00469528139
Iter: 783 loss: 0.00468422845
Iter: 784 loss: 0.0047393
Iter: 785 loss: 0.00468233228
Iter: 786 loss: 0.00467408169
Iter: 787 loss: 0.00467334874
Iter: 788 loss: 0.00466387533
Iter: 789 loss: 0.00466369791
Iter: 790 loss: 0.00465038698
Iter: 791 loss: 0.00462166872
Iter: 792 loss: 0.00510090776
Iter: 793 loss: 0.00462069083
Iter: 794 loss: 0.00459868833
Iter: 795 loss: 0.00467476435
Iter: 796 loss: 0.00459300261
Iter: 797 loss: 0.00457375264
Iter: 798 loss: 0.00453861617
Iter: 799 loss: 0.00531276967
Iter: 800 loss: 0.00453860546
Iter: 801 loss: 0.00452054478
Iter: 802 loss: 0.00451581506
Iter: 803 loss: 0.00449314853
Iter: 804 loss: 0.00450059306
Iter: 805 loss: 0.00447710045
Iter: 806 loss: 0.00446061511
Iter: 807 loss: 0.00450636912
Iter: 808 loss: 0.00445512217
Iter: 809 loss: 0.00444937171
Iter: 810 loss: 0.0044394685
Iter: 811 loss: 0.00443947455
Iter: 812 loss: 0.00441919267
Iter: 813 loss: 0.00465381425
Iter: 814 loss: 0.00441879872
Iter: 815 loss: 0.00440759212
Iter: 816 loss: 0.00441919407
Iter: 817 loss: 0.00440144539
Iter: 818 loss: 0.00438445434
Iter: 819 loss: 0.00436600205
Iter: 820 loss: 0.00436304603
Iter: 821 loss: 0.00434453739
Iter: 822 loss: 0.00442490075
Iter: 823 loss: 0.00434063608
Iter: 824 loss: 0.0043278574
Iter: 825 loss: 0.00436527561
Iter: 826 loss: 0.00432397332
Iter: 827 loss: 0.00431600446
Iter: 828 loss: 0.00429833028
Iter: 829 loss: 0.00456606783
Iter: 830 loss: 0.00429748092
Iter: 831 loss: 0.00427934621
Iter: 832 loss: 0.00428784452
Iter: 833 loss: 0.00426716171
Iter: 834 loss: 0.00425067823
Iter: 835 loss: 0.00427541556
Iter: 836 loss: 0.00424262555
Iter: 837 loss: 0.00423216866
Iter: 838 loss: 0.00421868358
Iter: 839 loss: 0.0042177
Iter: 840 loss: 0.00419861823
Iter: 841 loss: 0.00427988544
Iter: 842 loss: 0.00419442495
Iter: 843 loss: 0.00418030052
Iter: 844 loss: 0.00423043454
Iter: 845 loss: 0.00417670421
Iter: 846 loss: 0.00416816724
Iter: 847 loss: 0.00418785
Iter: 848 loss: 0.00416491088
Iter: 849 loss: 0.00415641768
Iter: 850 loss: 0.0041357493
Iter: 851 loss: 0.00435005454
Iter: 852 loss: 0.00413338467
Iter: 853 loss: 0.00411642715
Iter: 854 loss: 0.00415008
Iter: 855 loss: 0.00410953537
Iter: 856 loss: 0.00410072366
Iter: 857 loss: 0.00408345135
Iter: 858 loss: 0.00445281155
Iter: 859 loss: 0.00408332329
Iter: 860 loss: 0.00407407712
Iter: 861 loss: 0.00405784603
Iter: 862 loss: 0.00405782089
Iter: 863 loss: 0.00404777424
Iter: 864 loss: 0.00406829733
Iter: 865 loss: 0.00404361682
Iter: 866 loss: 0.00403784635
Iter: 867 loss: 0.00403021881
Iter: 868 loss: 0.00402977364
Iter: 869 loss: 0.00403394783
Iter: 870 loss: 0.00401857775
Iter: 871 loss: 0.00400798209
Iter: 872 loss: 0.00399186462
Iter: 873 loss: 0.00399159733
Iter: 874 loss: 0.00399350189
Iter: 875 loss: 0.00397802703
Iter: 876 loss: 0.00396687817
Iter: 877 loss: 0.00405143248
Iter: 878 loss: 0.00396594359
Iter: 879 loss: 0.00396426627
Iter: 880 loss: 0.0039620148
Iter: 881 loss: 0.00395970419
Iter: 882 loss: 0.00395474955
Iter: 883 loss: 0.00403202465
Iter: 884 loss: 0.00395455677
Iter: 885 loss: 0.00394087378
Iter: 886 loss: 0.00393245742
Iter: 887 loss: 0.00392693141
Iter: 888 loss: 0.00390979275
Iter: 889 loss: 0.00408793241
Iter: 890 loss: 0.00390935922
Iter: 891 loss: 0.00389876589
Iter: 892 loss: 0.00389869721
Iter: 893 loss: 0.00389170041
Iter: 894 loss: 0.00389417633
Iter: 895 loss: 0.00388683216
Iter: 896 loss: 0.00387514755
Iter: 897 loss: 0.00385347405
Iter: 898 loss: 0.00439096335
Iter: 899 loss: 0.00385345635
Iter: 900 loss: 0.00383656262
Iter: 901 loss: 0.00398157444
Iter: 902 loss: 0.00383574609
Iter: 903 loss: 0.00382350548
Iter: 904 loss: 0.00383633887
Iter: 905 loss: 0.0038167
Iter: 906 loss: 0.00380906463
Iter: 907 loss: 0.00379658164
Iter: 908 loss: 0.00379654299
Iter: 909 loss: 0.00378369121
Iter: 910 loss: 0.00377255026
Iter: 911 loss: 0.00376914162
Iter: 912 loss: 0.00375970453
Iter: 913 loss: 0.00376064
Iter: 914 loss: 0.00375245418
Iter: 915 loss: 0.00372440857
Iter: 916 loss: 0.00382887083
Iter: 917 loss: 0.00371731585
Iter: 918 loss: 0.00370153505
Iter: 919 loss: 0.0037096364
Iter: 920 loss: 0.00369103393
Iter: 921 loss: 0.00367340608
Iter: 922 loss: 0.00367283309
Iter: 923 loss: 0.00365909515
Iter: 924 loss: 0.00363534247
Iter: 925 loss: 0.00377186295
Iter: 926 loss: 0.00363200251
Iter: 927 loss: 0.00362306507
Iter: 928 loss: 0.00362125086
Iter: 929 loss: 0.0036137295
Iter: 930 loss: 0.00362178497
Iter: 931 loss: 0.00360965054
Iter: 932 loss: 0.0036043881
Iter: 933 loss: 0.00359152677
Iter: 934 loss: 0.00372682023
Iter: 935 loss: 0.00359002175
Iter: 936 loss: 0.00357182068
Iter: 937 loss: 0.00371625274
Iter: 938 loss: 0.0035704989
Iter: 939 loss: 0.00357894902
Iter: 940 loss: 0.00356609724
Iter: 941 loss: 0.0035634723
Iter: 942 loss: 0.00356357126
Iter: 943 loss: 0.00356139662
Iter: 944 loss: 0.00355767715
Iter: 945 loss: 0.00355648948
Iter: 946 loss: 0.00355063868
Iter: 947 loss: 0.00356586743
Iter: 948 loss: 0.00354865566
Iter: 949 loss: 0.00354720978
Iter: 950 loss: 0.00354519463
Iter: 951 loss: 0.00354510802
Iter: 952 loss: 0.0035409634
Iter: 953 loss: 0.00353098731
Iter: 954 loss: 0.00364275556
Iter: 955 loss: 0.0035299554
Iter: 956 loss: 0.00351433107
Iter: 957 loss: 0.00358803663
Iter: 958 loss: 0.00351140602
Iter: 959 loss: 0.00349987345
Iter: 960 loss: 0.00349125941
Iter: 961 loss: 0.00348740397
Iter: 962 loss: 0.00347248721
Iter: 963 loss: 0.00369597063
Iter: 964 loss: 0.00347245974
Iter: 965 loss: 0.00346496794
Iter: 966 loss: 0.00346486876
Iter: 967 loss: 0.00345654693
Iter: 968 loss: 0.00346085755
Iter: 969 loss: 0.00345106889
Iter: 970 loss: 0.00345306844
Iter: 971 loss: 0.00344287721
Iter: 972 loss: 0.0034363335
Iter: 973 loss: 0.00342806103
Iter: 974 loss: 0.00342740794
Iter: 975 loss: 0.00342084491
Iter: 976 loss: 0.00343899825
Iter: 977 loss: 0.00341871358
Iter: 978 loss: 0.00341448397
Iter: 979 loss: 0.00341411261
Iter: 980 loss: 0.00340809557
Iter: 981 loss: 0.00342968735
Iter: 982 loss: 0.0034066306
Iter: 983 loss: 0.00340335118
Iter: 984 loss: 0.00339816813
Iter: 985 loss: 0.00339811202
Iter: 986 loss: 0.00339138461
Iter: 987 loss: 0.00338540296
Iter: 988 loss: 0.00338364113
Iter: 989 loss: 0.00337461382
Iter: 990 loss: 0.00338731357
Iter: 991 loss: 0.00337018748
Iter: 992 loss: 0.00336076482
Iter: 993 loss: 0.00342595438
Iter: 994 loss: 0.00335990451
Iter: 995 loss: 0.00335151819
Iter: 996 loss: 0.00334716332
Iter: 997 loss: 0.00334326597
Iter: 998 loss: 0.0033254968
Iter: 999 loss: 0.0035126037
Iter: 1000 loss: 0.003325094
Iter: 1001 loss: 0.00332158455
Iter: 1002 loss: 0.00335798319
Iter: 1003 loss: 0.00332148
Iter: 1004 loss: 0.00331791863
Iter: 1005 loss: 0.00331992237
Iter: 1006 loss: 0.00331557891
Iter: 1007 loss: 0.00331250555
Iter: 1008 loss: 0.00330543448
Iter: 1009 loss: 0.00339991273
Iter: 1010 loss: 0.00330495788
Iter: 1011 loss: 0.0032970102
Iter: 1012 loss: 0.00331909629
Iter: 1013 loss: 0.00329447351
Iter: 1014 loss: 0.00328830397
Iter: 1015 loss: 0.00330003328
Iter: 1016 loss: 0.00328564434
Iter: 1017 loss: 0.00327768177
Iter: 1018 loss: 0.00327582913
Iter: 1019 loss: 0.00327071385
Iter: 1020 loss: 0.00326398225
Iter: 1021 loss: 0.00336421374
Iter: 1022 loss: 0.00326398225
Iter: 1023 loss: 0.00325909629
Iter: 1024 loss: 0.00324841565
Iter: 1025 loss: 0.0034110155
Iter: 1026 loss: 0.00324796163
Iter: 1027 loss: 0.0032401816
Iter: 1028 loss: 0.00326278084
Iter: 1029 loss: 0.0032377718
Iter: 1030 loss: 0.00323130912
Iter: 1031 loss: 0.00324128126
Iter: 1032 loss: 0.00322822318
Iter: 1033 loss: 0.00321506872
Iter: 1034 loss: 0.00323088537
Iter: 1035 loss: 0.003208193
Iter: 1036 loss: 0.00321911648
Iter: 1037 loss: 0.00320287724
Iter: 1038 loss: 0.00319829909
Iter: 1039 loss: 0.0032214676
Iter: 1040 loss: 0.00319754193
Iter: 1041 loss: 0.00319504412
Iter: 1042 loss: 0.00319095748
Iter: 1043 loss: 0.00319094164
Iter: 1044 loss: 0.00319072441
Iter: 1045 loss: 0.00318832044
Iter: 1046 loss: 0.00318655721
Iter: 1047 loss: 0.00318292202
Iter: 1048 loss: 0.00324869202
Iter: 1049 loss: 0.00318284519
Iter: 1050 loss: 0.00317667355
Iter: 1051 loss: 0.00316913519
Iter: 1052 loss: 0.00316842832
Iter: 1053 loss: 0.0031535672
Iter: 1054 loss: 0.00316067971
Iter: 1055 loss: 0.00314351148
Iter: 1056 loss: 0.00312119117
Iter: 1057 loss: 0.00321903732
Iter: 1058 loss: 0.00311655411
Iter: 1059 loss: 0.00309961103
Iter: 1060 loss: 0.0032487791
Iter: 1061 loss: 0.0030986541
Iter: 1062 loss: 0.00308247702
Iter: 1063 loss: 0.00307016
Iter: 1064 loss: 0.00306488108
Iter: 1065 loss: 0.00305816811
Iter: 1066 loss: 0.00305808336
Iter: 1067 loss: 0.00305609056
Iter: 1068 loss: 0.00305551803
Iter: 1069 loss: 0.0030543115
Iter: 1070 loss: 0.00305006513
Iter: 1071 loss: 0.0030779941
Iter: 1072 loss: 0.00304961973
Iter: 1073 loss: 0.00304702623
Iter: 1074 loss: 0.00305107352
Iter: 1075 loss: 0.00304580247
Iter: 1076 loss: 0.00304192072
Iter: 1077 loss: 0.00304328371
Iter: 1078 loss: 0.0030391945
Iter: 1079 loss: 0.00303786807
Iter: 1080 loss: 0.00303642335
Iter: 1081 loss: 0.00303342426
Iter: 1082 loss: 0.00303000398
Iter: 1083 loss: 0.00302955811
Iter: 1084 loss: 0.00302095152
Iter: 1085 loss: 0.00300923456
Iter: 1086 loss: 0.00300866785
Iter: 1087 loss: 0.0029897159
Iter: 1088 loss: 0.00301066786
Iter: 1089 loss: 0.00297925388
Iter: 1090 loss: 0.00296590128
Iter: 1091 loss: 0.00296538882
Iter: 1092 loss: 0.00296031055
Iter: 1093 loss: 0.00299847755
Iter: 1094 loss: 0.00295990147
Iter: 1095 loss: 0.0029562097
Iter: 1096 loss: 0.0029784115
Iter: 1097 loss: 0.00295575685
Iter: 1098 loss: 0.0029518865
Iter: 1099 loss: 0.00295047974
Iter: 1100 loss: 0.0029482937
Iter: 1101 loss: 0.00294272299
Iter: 1102 loss: 0.00301712938
Iter: 1103 loss: 0.00294268946
Iter: 1104 loss: 0.00294038886
Iter: 1105 loss: 0.00293497229
Iter: 1106 loss: 0.00299795298
Iter: 1107 loss: 0.0029344745
Iter: 1108 loss: 0.00292993756
Iter: 1109 loss: 0.00297113252
Iter: 1110 loss: 0.00292973034
Iter: 1111 loss: 0.00292724324
Iter: 1112 loss: 0.00294202892
Iter: 1113 loss: 0.00292690494
Iter: 1114 loss: 0.00292383088
Iter: 1115 loss: 0.00291632
Iter: 1116 loss: 0.002992325
Iter: 1117 loss: 0.00291540357
Iter: 1118 loss: 0.00290949619
Iter: 1119 loss: 0.00291004102
Iter: 1120 loss: 0.00290492643
Iter: 1121 loss: 0.00289692869
Iter: 1122 loss: 0.00295699295
Iter: 1123 loss: 0.00289632985
Iter: 1124 loss: 0.00289126788
Iter: 1125 loss: 0.00288938265
Iter: 1126 loss: 0.00288659
Iter: 1127 loss: 0.00288124476
Iter: 1128 loss: 0.00292104203
Iter: 1129 loss: 0.00288082031
Iter: 1130 loss: 0.00287829549
Iter: 1131 loss: 0.00287804054
Iter: 1132 loss: 0.00287627289
Iter: 1133 loss: 0.00288271485
Iter: 1134 loss: 0.00287581049
Iter: 1135 loss: 0.00287292665
Iter: 1136 loss: 0.00287399022
Iter: 1137 loss: 0.00287088729
Iter: 1138 loss: 0.00286828843
Iter: 1139 loss: 0.00286643347
Iter: 1140 loss: 0.00286550308
Iter: 1141 loss: 0.00286261505
Iter: 1142 loss: 0.00286393706
Iter: 1143 loss: 0.00286066881
Iter: 1144 loss: 0.002858839
Iter: 1145 loss: 0.00285315
Iter: 1146 loss: 0.00286447792
Iter: 1147 loss: 0.00284952926
Iter: 1148 loss: 0.0028438326
Iter: 1149 loss: 0.00284166494
Iter: 1150 loss: 0.00283856341
Iter: 1151 loss: 0.0028324239
Iter: 1152 loss: 0.00283628725
Iter: 1153 loss: 0.00282850279
Iter: 1154 loss: 0.00282465527
Iter: 1155 loss: 0.00284327148
Iter: 1156 loss: 0.00282399263
Iter: 1157 loss: 0.00282016373
Iter: 1158 loss: 0.00280834502
Iter: 1159 loss: 0.00283220178
Iter: 1160 loss: 0.00280096382
Iter: 1161 loss: 0.00278726616
Iter: 1162 loss: 0.00281122653
Iter: 1163 loss: 0.00278113689
Iter: 1164 loss: 0.00277096522
Iter: 1165 loss: 0.00280760624
Iter: 1166 loss: 0.00276834797
Iter: 1167 loss: 0.00276136911
Iter: 1168 loss: 0.00280309306
Iter: 1169 loss: 0.00276047271
Iter: 1170 loss: 0.00275289896
Iter: 1171 loss: 0.0027695
Iter: 1172 loss: 0.00274995575
Iter: 1173 loss: 0.00276235444
Iter: 1174 loss: 0.00274859508
Iter: 1175 loss: 0.00274785701
Iter: 1176 loss: 0.00274789263
Iter: 1177 loss: 0.00274727074
Iter: 1178 loss: 0.00274430122
Iter: 1179 loss: 0.00273838127
Iter: 1180 loss: 0.00284927292
Iter: 1181 loss: 0.00273830257
Iter: 1182 loss: 0.00275001535
Iter: 1183 loss: 0.00273608835
Iter: 1184 loss: 0.00273424294
Iter: 1185 loss: 0.0027323612
Iter: 1186 loss: 0.00273198355
Iter: 1187 loss: 0.0027275451
Iter: 1188 loss: 0.00272740563
Iter: 1189 loss: 0.00272290781
Iter: 1190 loss: 0.00273938
Iter: 1191 loss: 0.00272178743
Iter: 1192 loss: 0.0027197313
Iter: 1193 loss: 0.00271407655
Iter: 1194 loss: 0.00274653314
Iter: 1195 loss: 0.00271247048
Iter: 1196 loss: 0.00270690769
Iter: 1197 loss: 0.00271094218
Iter: 1198 loss: 0.00270347553
Iter: 1199 loss: 0.00269907247
Iter: 1200 loss: 0.00268951198
Iter: 1201 loss: 0.00283298013
Iter: 1202 loss: 0.00268913899
Iter: 1203 loss: 0.00268163905
Iter: 1204 loss: 0.00274750125
Iter: 1205 loss: 0.00268123811
Iter: 1206 loss: 0.00267590792
Iter: 1207 loss: 0.00273030321
Iter: 1208 loss: 0.00267573819
Iter: 1209 loss: 0.00267393375
Iter: 1210 loss: 0.00267226435
Iter: 1211 loss: 0.00267148344
Iter: 1212 loss: 0.00266898796
Iter: 1213 loss: 0.00267208484
Iter: 1214 loss: 0.00266709388
Iter: 1215 loss: 0.00266970391
Iter: 1216 loss: 0.00266467151
Iter: 1217 loss: 0.00266258069
Iter: 1218 loss: 0.00267028296
Iter: 1219 loss: 0.0026620673
Iter: 1220 loss: 0.00265844539
Iter: 1221 loss: 0.00265063532
Iter: 1222 loss: 0.00277360948
Iter: 1223 loss: 0.00265035732
Iter: 1224 loss: 0.00265295757
Iter: 1225 loss: 0.00264715101
Iter: 1226 loss: 0.00264437986
Iter: 1227 loss: 0.00264227437
Iter: 1228 loss: 0.0026413626
Iter: 1229 loss: 0.00263881264
Iter: 1230 loss: 0.00263327057
Iter: 1231 loss: 0.00271498365
Iter: 1232 loss: 0.00263304589
Iter: 1233 loss: 0.00262914225
Iter: 1234 loss: 0.00263335928
Iter: 1235 loss: 0.00262698182
Iter: 1236 loss: 0.00262543978
Iter: 1237 loss: 0.0026220656
Iter: 1238 loss: 0.00267115375
Iter: 1239 loss: 0.00262193428
Iter: 1240 loss: 0.00261697732
Iter: 1241 loss: 0.00261712587
Iter: 1242 loss: 0.00261304621
Iter: 1243 loss: 0.00260853535
Iter: 1244 loss: 0.00261605019
Iter: 1245 loss: 0.00260649342
Iter: 1246 loss: 0.00260013063
Iter: 1247 loss: 0.00262088538
Iter: 1248 loss: 0.0025983348
Iter: 1249 loss: 0.00259189121
Iter: 1250 loss: 0.0026383223
Iter: 1251 loss: 0.0025913422
Iter: 1252 loss: 0.00258999248
Iter: 1253 loss: 0.00258828653
Iter: 1254 loss: 0.00258815568
Iter: 1255 loss: 0.00258571
Iter: 1256 loss: 0.0025843964
Iter: 1257 loss: 0.00258330069
Iter: 1258 loss: 0.00257947762
Iter: 1259 loss: 0.00258060289
Iter: 1260 loss: 0.002576706
Iter: 1261 loss: 0.00257577933
Iter: 1262 loss: 0.00257370714
Iter: 1263 loss: 0.00257031457
Iter: 1264 loss: 0.00257456163
Iter: 1265 loss: 0.00256854715
Iter: 1266 loss: 0.00256500114
Iter: 1267 loss: 0.00257682661
Iter: 1268 loss: 0.00256405585
Iter: 1269 loss: 0.00256126514
Iter: 1270 loss: 0.00255413773
Iter: 1271 loss: 0.00261613401
Iter: 1272 loss: 0.00255297194
Iter: 1273 loss: 0.00254981592
Iter: 1274 loss: 0.00254570926
Iter: 1275 loss: 0.00253998023
Iter: 1276 loss: 0.00254957331
Iter: 1277 loss: 0.0025374
Iter: 1278 loss: 0.00253404467
Iter: 1279 loss: 0.00254228758
Iter: 1280 loss: 0.00253286608
Iter: 1281 loss: 0.00252944953
Iter: 1282 loss: 0.00253495364
Iter: 1283 loss: 0.00252786302
Iter: 1284 loss: 0.00252603507
Iter: 1285 loss: 0.00252330536
Iter: 1286 loss: 0.00252325274
Iter: 1287 loss: 0.00251896866
Iter: 1288 loss: 0.00251771719
Iter: 1289 loss: 0.00251512625
Iter: 1290 loss: 0.00251240283
Iter: 1291 loss: 0.00251968531
Iter: 1292 loss: 0.00251148967
Iter: 1293 loss: 0.0025104247
Iter: 1294 loss: 0.00250998978
Iter: 1295 loss: 0.0025084021
Iter: 1296 loss: 0.00251365663
Iter: 1297 loss: 0.00250797
Iter: 1298 loss: 0.00250604935
Iter: 1299 loss: 0.00250257505
Iter: 1300 loss: 0.00258722156
Iter: 1301 loss: 0.00250257878
Iter: 1302 loss: 0.0024992507
Iter: 1303 loss: 0.00249738502
Iter: 1304 loss: 0.00249594613
Iter: 1305 loss: 0.00248646364
Iter: 1306 loss: 0.00251096627
Iter: 1307 loss: 0.00248322915
Iter: 1308 loss: 0.00247513223
Iter: 1309 loss: 0.0025612039
Iter: 1310 loss: 0.0024749469
Iter: 1311 loss: 0.00247001415
Iter: 1312 loss: 0.00246976619
Iter: 1313 loss: 0.0024673515
Iter: 1314 loss: 0.00248179631
Iter: 1315 loss: 0.00246706232
Iter: 1316 loss: 0.00246534683
Iter: 1317 loss: 0.0024658218
Iter: 1318 loss: 0.00246409955
Iter: 1319 loss: 0.00246212166
Iter: 1320 loss: 0.00247267843
Iter: 1321 loss: 0.00246182759
Iter: 1322 loss: 0.0024607759
Iter: 1323 loss: 0.00245817611
Iter: 1324 loss: 0.00248380518
Iter: 1325 loss: 0.00245783641
Iter: 1326 loss: 0.00245304545
Iter: 1327 loss: 0.00245641079
Iter: 1328 loss: 0.00245005591
Iter: 1329 loss: 0.00244405773
Iter: 1330 loss: 0.00253058295
Iter: 1331 loss: 0.00244404655
Iter: 1332 loss: 0.00243999576
Iter: 1333 loss: 0.00249043806
Iter: 1334 loss: 0.00243994384
Iter: 1335 loss: 0.00243793754
Iter: 1336 loss: 0.00243197614
Iter: 1337 loss: 0.00245349272
Iter: 1338 loss: 0.00242925761
Iter: 1339 loss: 0.00242236489
Iter: 1340 loss: 0.00242548389
Iter: 1341 loss: 0.00241767894
Iter: 1342 loss: 0.00241304142
Iter: 1343 loss: 0.00241097622
Iter: 1344 loss: 0.00240862137
Iter: 1345 loss: 0.00240739528
Iter: 1346 loss: 0.00240696594
Iter: 1347 loss: 0.00240568584
Iter: 1348 loss: 0.00241604261
Iter: 1349 loss: 0.00240559317
Iter: 1350 loss: 0.00240448141
Iter: 1351 loss: 0.00240274542
Iter: 1352 loss: 0.00240272772
Iter: 1353 loss: 0.00240000756
Iter: 1354 loss: 0.00240000244
Iter: 1355 loss: 0.00239903294
Iter: 1356 loss: 0.0023992341
Iter: 1357 loss: 0.00239832187
Iter: 1358 loss: 0.00239560218
Iter: 1359 loss: 0.00238853204
Iter: 1360 loss: 0.00244518532
Iter: 1361 loss: 0.0023872233
Iter: 1362 loss: 0.00238014502
Iter: 1363 loss: 0.00239172252
Iter: 1364 loss: 0.00237689051
Iter: 1365 loss: 0.00237506465
Iter: 1366 loss: 0.00237346301
Iter: 1367 loss: 0.00237103784
Iter: 1368 loss: 0.00236457679
Iter: 1369 loss: 0.00241046213
Iter: 1370 loss: 0.00236313906
Iter: 1371 loss: 0.00235977676
Iter: 1372 loss: 0.00235601095
Iter: 1373 loss: 0.00235549174
Iter: 1374 loss: 0.00235182792
Iter: 1375 loss: 0.00237328629
Iter: 1376 loss: 0.00235134899
Iter: 1377 loss: 0.00234892778
Iter: 1378 loss: 0.00237529725
Iter: 1379 loss: 0.00234887679
Iter: 1380 loss: 0.00234677293
Iter: 1381 loss: 0.00235604541
Iter: 1382 loss: 0.0023463415
Iter: 1383 loss: 0.00234461622
Iter: 1384 loss: 0.00234413426
Iter: 1385 loss: 0.00234307628
Iter: 1386 loss: 0.00234569889
Iter: 1387 loss: 0.00234164693
Iter: 1388 loss: 0.00233929884
Iter: 1389 loss: 0.00234166021
Iter: 1390 loss: 0.00233798986
Iter: 1391 loss: 0.00233661477
Iter: 1392 loss: 0.00233350322
Iter: 1393 loss: 0.00237667677
Iter: 1394 loss: 0.00233332603
Iter: 1395 loss: 0.00233113533
Iter: 1396 loss: 0.00233212602
Iter: 1397 loss: 0.00232965127
Iter: 1398 loss: 0.00232777488
Iter: 1399 loss: 0.0023251751
Iter: 1400 loss: 0.00232506241
Iter: 1401 loss: 0.0023220724
Iter: 1402 loss: 0.00231791567
Iter: 1403 loss: 0.00231775176
Iter: 1404 loss: 0.00231138244
Iter: 1405 loss: 0.00235993601
Iter: 1406 loss: 0.00231091469
Iter: 1407 loss: 0.00230673677
Iter: 1408 loss: 0.00236381032
Iter: 1409 loss: 0.00230671791
Iter: 1410 loss: 0.0023040988
Iter: 1411 loss: 0.00229881913
Iter: 1412 loss: 0.00239933911
Iter: 1413 loss: 0.00229873369
Iter: 1414 loss: 0.00231436477
Iter: 1415 loss: 0.00229749852
Iter: 1416 loss: 0.00229655951
Iter: 1417 loss: 0.00229551527
Iter: 1418 loss: 0.00229536043
Iter: 1419 loss: 0.00229336834
Iter: 1420 loss: 0.00229109824
Iter: 1421 loss: 0.00229081581
Iter: 1422 loss: 0.00228727516
Iter: 1423 loss: 0.00228822138
Iter: 1424 loss: 0.0022847068
Iter: 1425 loss: 0.00227937382
Iter: 1426 loss: 0.00232486567
Iter: 1427 loss: 0.00227906206
Iter: 1428 loss: 0.00227671885
Iter: 1429 loss: 0.0022713528
Iter: 1430 loss: 0.00234125555
Iter: 1431 loss: 0.00227099448
Iter: 1432 loss: 0.00227367389
Iter: 1433 loss: 0.0022677239
Iter: 1434 loss: 0.00226611737
Iter: 1435 loss: 0.00226304913
Iter: 1436 loss: 0.00232806127
Iter: 1437 loss: 0.00226304447
Iter: 1438 loss: 0.00225759251
Iter: 1439 loss: 0.00225482695
Iter: 1440 loss: 0.00225225883
Iter: 1441 loss: 0.00224813074
Iter: 1442 loss: 0.00227429811
Iter: 1443 loss: 0.00224764273
Iter: 1444 loss: 0.00224398822
Iter: 1445 loss: 0.00224170252
Iter: 1446 loss: 0.00224025408
Iter: 1447 loss: 0.00223729783
Iter: 1448 loss: 0.00225212425
Iter: 1449 loss: 0.00223679468
Iter: 1450 loss: 0.00223524566
Iter: 1451 loss: 0.00224052509
Iter: 1452 loss: 0.00223483751
Iter: 1453 loss: 0.00223241351
Iter: 1454 loss: 0.00222915877
Iter: 1455 loss: 0.00222898135
Iter: 1456 loss: 0.00222644722
Iter: 1457 loss: 0.00223210035
Iter: 1458 loss: 0.00222549075
Iter: 1459 loss: 0.00222290284
Iter: 1460 loss: 0.00224704086
Iter: 1461 loss: 0.00222279318
Iter: 1462 loss: 0.00222076778
Iter: 1463 loss: 0.00221679639
Iter: 1464 loss: 0.00229845475
Iter: 1465 loss: 0.0022167752
Iter: 1466 loss: 0.00221973
Iter: 1467 loss: 0.00221436704
Iter: 1468 loss: 0.00221220683
Iter: 1469 loss: 0.00221201568
Iter: 1470 loss: 0.0022104294
Iter: 1471 loss: 0.00220742822
Iter: 1472 loss: 0.00220639724
Iter: 1473 loss: 0.00220469013
Iter: 1474 loss: 0.00220286427
Iter: 1475 loss: 0.00223113527
Iter: 1476 loss: 0.00220286241
Iter: 1477 loss: 0.00220074854
Iter: 1478 loss: 0.00220969692
Iter: 1479 loss: 0.00220030593
Iter: 1480 loss: 0.00219848705
Iter: 1481 loss: 0.00220035575
Iter: 1482 loss: 0.00219746819
Iter: 1483 loss: 0.00219688751
Iter: 1484 loss: 0.0021965187
Iter: 1485 loss: 0.00219592173
Iter: 1486 loss: 0.00219498877
Iter: 1487 loss: 0.00219498645
Iter: 1488 loss: 0.00219358108
Iter: 1489 loss: 0.00220236811
Iter: 1490 loss: 0.00219342276
Iter: 1491 loss: 0.00219186628
Iter: 1492 loss: 0.00220095
Iter: 1493 loss: 0.00219165976
Iter: 1494 loss: 0.00219025649
Iter: 1495 loss: 0.00218673144
Iter: 1496 loss: 0.00221983157
Iter: 1497 loss: 0.002186222
Iter: 1498 loss: 0.00218448
Iter: 1499 loss: 0.00218435586
Iter: 1500 loss: 0.00218269066
Iter: 1501 loss: 0.00218877988
Iter: 1502 loss: 0.00218227599
Iter: 1503 loss: 0.00218064548
Iter: 1504 loss: 0.00217744219
Iter: 1505 loss: 0.0022420655
Iter: 1506 loss: 0.00217742193
Iter: 1507 loss: 0.00217444403
Iter: 1508 loss: 0.0021938365
Iter: 1509 loss: 0.00217410503
Iter: 1510 loss: 0.00217154203
Iter: 1511 loss: 0.00219162647
Iter: 1512 loss: 0.00217137346
Iter: 1513 loss: 0.00216969266
Iter: 1514 loss: 0.00216959091
Iter: 1515 loss: 0.00216832431
Iter: 1516 loss: 0.00216770242
Iter: 1517 loss: 0.00216727727
Iter: 1518 loss: 0.00216624793
Iter: 1519 loss: 0.00216545258
Iter: 1520 loss: 0.0021651336
Iter: 1521 loss: 0.00216422696
Iter: 1522 loss: 0.00216337782
Iter: 1523 loss: 0.00216316059
Iter: 1524 loss: 0.00216159178
Iter: 1525 loss: 0.00217353809
Iter: 1526 loss: 0.00216147606
Iter: 1527 loss: 0.00216003414
Iter: 1528 loss: 0.00216011633
Iter: 1529 loss: 0.00215890375
Iter: 1530 loss: 0.0021569971
Iter: 1531 loss: 0.00217303191
Iter: 1532 loss: 0.00215688488
Iter: 1533 loss: 0.00215672422
Iter: 1534 loss: 0.00215601129
Iter: 1535 loss: 0.00215567113
Iter: 1536 loss: 0.00215462013
Iter: 1537 loss: 0.00215582061
Iter: 1538 loss: 0.00215379149
Iter: 1539 loss: 0.00215184852
Iter: 1540 loss: 0.00216739695
Iter: 1541 loss: 0.00215170905
Iter: 1542 loss: 0.00215016608
Iter: 1543 loss: 0.00215323432
Iter: 1544 loss: 0.00214953115
Iter: 1545 loss: 0.00214810483
Iter: 1546 loss: 0.00214551855
Iter: 1547 loss: 0.00220945454
Iter: 1548 loss: 0.00214552321
Iter: 1549 loss: 0.00214392645
Iter: 1550 loss: 0.00214860402
Iter: 1551 loss: 0.00214343471
Iter: 1552 loss: 0.00214246288
Iter: 1553 loss: 0.00214545755
Iter: 1554 loss: 0.0021421737
Iter: 1555 loss: 0.00214128732
Iter: 1556 loss: 0.00213963399
Iter: 1557 loss: 0.0021771756
Iter: 1558 loss: 0.00213962491
Iter: 1559 loss: 0.0021374654
Iter: 1560 loss: 0.00213496899
Iter: 1561 loss: 0.00213466515
Iter: 1562 loss: 0.00213243323
Iter: 1563 loss: 0.00215318287
Iter: 1564 loss: 0.0021323422
Iter: 1565 loss: 0.00212977803
Iter: 1566 loss: 0.00215495215
Iter: 1567 loss: 0.00212967978
Iter: 1568 loss: 0.00212633796
Iter: 1569 loss: 0.00212418591
Iter: 1570 loss: 0.00212288112
Iter: 1571 loss: 0.0021177209
Iter: 1572 loss: 0.00219789194
Iter: 1573 loss: 0.00211771694
Iter: 1574 loss: 0.00211482914
Iter: 1575 loss: 0.00211029779
Iter: 1576 loss: 0.00211024703
Iter: 1577 loss: 0.00211668713
Iter: 1578 loss: 0.00210870709
Iter: 1579 loss: 0.00210737297
Iter: 1580 loss: 0.00211284752
Iter: 1581 loss: 0.00210708077
Iter: 1582 loss: 0.00210638484
Iter: 1583 loss: 0.00210540858
Iter: 1584 loss: 0.00210536597
Iter: 1585 loss: 0.00210321485
Iter: 1586 loss: 0.00210203882
Iter: 1587 loss: 0.00210108142
Iter: 1588 loss: 0.00209950679
Iter: 1589 loss: 0.00210046954
Iter: 1590 loss: 0.0020984835
Iter: 1591 loss: 0.00209608441
Iter: 1592 loss: 0.00211158628
Iter: 1593 loss: 0.00209581899
Iter: 1594 loss: 0.00209345156
Iter: 1595 loss: 0.0021015727
Iter: 1596 loss: 0.00209282129
Iter: 1597 loss: 0.00209134514
Iter: 1598 loss: 0.00208940846
Iter: 1599 loss: 0.00208928878
Iter: 1600 loss: 0.00208561285
Iter: 1601 loss: 0.00209127413
Iter: 1602 loss: 0.00208386802
Iter: 1603 loss: 0.00208105659
Iter: 1604 loss: 0.00208709808
Iter: 1605 loss: 0.00207995111
Iter: 1606 loss: 0.0020827644
Iter: 1607 loss: 0.002079139
Iter: 1608 loss: 0.00207876018
Iter: 1609 loss: 0.00207760022
Iter: 1610 loss: 0.002079739
Iter: 1611 loss: 0.00207684468
Iter: 1612 loss: 0.00207548868
Iter: 1613 loss: 0.00208309386
Iter: 1614 loss: 0.00207530474
Iter: 1615 loss: 0.0020748449
Iter: 1616 loss: 0.00207502441
Iter: 1617 loss: 0.00207452103
Iter: 1618 loss: 0.00207357062
Iter: 1619 loss: 0.00207352964
Iter: 1620 loss: 0.00207280554
Iter: 1621 loss: 0.00207197
Iter: 1622 loss: 0.00207186909
Iter: 1623 loss: 0.00207038783
Iter: 1624 loss: 0.00206882553
Iter: 1625 loss: 0.00206856569
Iter: 1626 loss: 0.00206628419
Iter: 1627 loss: 0.00206753914
Iter: 1628 loss: 0.00206479058
Iter: 1629 loss: 0.00206186669
Iter: 1630 loss: 0.00207471335
Iter: 1631 loss: 0.00206128624
Iter: 1632 loss: 0.00205718074
Iter: 1633 loss: 0.0020563209
Iter: 1634 loss: 0.00205360749
Iter: 1635 loss: 0.00204939279
Iter: 1636 loss: 0.0020642702
Iter: 1637 loss: 0.0020483085
Iter: 1638 loss: 0.0020438449
Iter: 1639 loss: 0.00205359794
Iter: 1640 loss: 0.00204210728
Iter: 1641 loss: 0.00205107499
Iter: 1642 loss: 0.00204103487
Iter: 1643 loss: 0.00204046187
Iter: 1644 loss: 0.00204290263
Iter: 1645 loss: 0.00204034103
Iter: 1646 loss: 0.00203980948
Iter: 1647 loss: 0.00203814521
Iter: 1648 loss: 0.00204095151
Iter: 1649 loss: 0.0020370197
Iter: 1650 loss: 0.0020344723
Iter: 1651 loss: 0.00203321758
Iter: 1652 loss: 0.00203199
Iter: 1653 loss: 0.00203371514
Iter: 1654 loss: 0.00203103106
Iter: 1655 loss: 0.00202966016
Iter: 1656 loss: 0.00203036889
Iter: 1657 loss: 0.00202874653
Iter: 1658 loss: 0.00202762894
Iter: 1659 loss: 0.0020251458
Iter: 1660 loss: 0.0020606406
Iter: 1661 loss: 0.00202501845
Iter: 1662 loss: 0.0020222473
Iter: 1663 loss: 0.00201978814
Iter: 1664 loss: 0.00201905565
Iter: 1665 loss: 0.00201735366
Iter: 1666 loss: 0.00203924952
Iter: 1667 loss: 0.00201734249
Iter: 1668 loss: 0.00201585167
Iter: 1669 loss: 0.00202494022
Iter: 1670 loss: 0.00201567472
Iter: 1671 loss: 0.00201475574
Iter: 1672 loss: 0.00201337086
Iter: 1673 loss: 0.00201334059
Iter: 1674 loss: 0.00201129913
Iter: 1675 loss: 0.00201823795
Iter: 1676 loss: 0.00201075617
Iter: 1677 loss: 0.00201802026
Iter: 1678 loss: 0.00201027421
Iter: 1679 loss: 0.00201005465
Iter: 1680 loss: 0.00200941367
Iter: 1681 loss: 0.00201173476
Iter: 1682 loss: 0.0020091245
Iter: 1683 loss: 0.00200810097
Iter: 1684 loss: 0.00200815452
Iter: 1685 loss: 0.00200729212
Iter: 1686 loss: 0.00200558081
Iter: 1687 loss: 0.00200194702
Iter: 1688 loss: 0.00206195656
Iter: 1689 loss: 0.00200183503
Iter: 1690 loss: 0.00199956377
Iter: 1691 loss: 0.00199946715
Iter: 1692 loss: 0.0019976669
Iter: 1693 loss: 0.00200406439
Iter: 1694 loss: 0.00199721311
Iter: 1695 loss: 0.0019951514
Iter: 1696 loss: 0.00199464499
Iter: 1697 loss: 0.00199333276
Iter: 1698 loss: 0.00199026382
Iter: 1699 loss: 0.00198368356
Iter: 1700 loss: 0.00208659191
Iter: 1701 loss: 0.00198345864
Iter: 1702 loss: 0.00198150799
Iter: 1703 loss: 0.00198064535
Iter: 1704 loss: 0.00197965279
Iter: 1705 loss: 0.00197765836
Iter: 1706 loss: 0.00197550235
Iter: 1707 loss: 0.00197516428
Iter: 1708 loss: 0.00197412306
Iter: 1709 loss: 0.00197238568
Iter: 1710 loss: 0.00197238335
Iter: 1711 loss: 0.0019712504
Iter: 1712 loss: 0.001969198
Iter: 1713 loss: 0.00201921677
Iter: 1714 loss: 0.00196919311
Iter: 1715 loss: 0.00198487798
Iter: 1716 loss: 0.00196838682
Iter: 1717 loss: 0.0019675
Iter: 1718 loss: 0.00196651323
Iter: 1719 loss: 0.00196637213
Iter: 1720 loss: 0.00196485827
Iter: 1721 loss: 0.00196382776
Iter: 1722 loss: 0.00196326757
Iter: 1723 loss: 0.00196079118
Iter: 1724 loss: 0.00196544849
Iter: 1725 loss: 0.00195974926
Iter: 1726 loss: 0.00195770198
Iter: 1727 loss: 0.00198742468
Iter: 1728 loss: 0.00195769453
Iter: 1729 loss: 0.00195481302
Iter: 1730 loss: 0.00195080473
Iter: 1731 loss: 0.00195063394
Iter: 1732 loss: 0.00195077597
Iter: 1733 loss: 0.00194796629
Iter: 1734 loss: 0.00194715057
Iter: 1735 loss: 0.00195157214
Iter: 1736 loss: 0.00194702088
Iter: 1737 loss: 0.00194587943
Iter: 1738 loss: 0.00195359951
Iter: 1739 loss: 0.00194577
Iter: 1740 loss: 0.00194527931
Iter: 1741 loss: 0.00194526487
Iter: 1742 loss: 0.00194488675
Iter: 1743 loss: 0.00194423122
Iter: 1744 loss: 0.00194303528
Iter: 1745 loss: 0.001971049
Iter: 1746 loss: 0.00194303086
Iter: 1747 loss: 0.00194113923
Iter: 1748 loss: 0.0019442566
Iter: 1749 loss: 0.00194026832
Iter: 1750 loss: 0.00193832209
Iter: 1751 loss: 0.00193829183
Iter: 1752 loss: 0.00193591323
Iter: 1753 loss: 0.00193689379
Iter: 1754 loss: 0.00193428271
Iter: 1755 loss: 0.00193254149
Iter: 1756 loss: 0.00194356963
Iter: 1757 loss: 0.00193234347
Iter: 1758 loss: 0.00193080935
Iter: 1759 loss: 0.00192931551
Iter: 1760 loss: 0.00192898011
Iter: 1761 loss: 0.00192761049
Iter: 1762 loss: 0.0019335649
Iter: 1763 loss: 0.00192733761
Iter: 1764 loss: 0.00192538067
Iter: 1765 loss: 0.00192299439
Iter: 1766 loss: 0.00192277681
Iter: 1767 loss: 0.00192435144
Iter: 1768 loss: 0.00192139973
Iter: 1769 loss: 0.00192045409
Iter: 1770 loss: 0.00192816067
Iter: 1771 loss: 0.00192038924
Iter: 1772 loss: 0.00191972253
Iter: 1773 loss: 0.00192123884
Iter: 1774 loss: 0.00191947026
Iter: 1775 loss: 0.00191865501
Iter: 1776 loss: 0.00191620493
Iter: 1777 loss: 0.00192361511
Iter: 1778 loss: 0.00191497244
Iter: 1779 loss: 0.00191323017
Iter: 1780 loss: 0.00191381783
Iter: 1781 loss: 0.00191199977
Iter: 1782 loss: 0.00191042409
Iter: 1783 loss: 0.00190729939
Iter: 1784 loss: 0.00196670461
Iter: 1785 loss: 0.00190726365
Iter: 1786 loss: 0.00190665305
Iter: 1787 loss: 0.00190489821
Iter: 1788 loss: 0.00190318166
Iter: 1789 loss: 0.00190121168
Iter: 1790 loss: 0.00190096966
Iter: 1791 loss: 0.00189676229
Iter: 1792 loss: 0.00192100671
Iter: 1793 loss: 0.00189617719
Iter: 1794 loss: 0.00189236773
Iter: 1795 loss: 0.00190195488
Iter: 1796 loss: 0.00189104408
Iter: 1797 loss: 0.00188810087
Iter: 1798 loss: 0.00189004769
Iter: 1799 loss: 0.00188625348
Iter: 1800 loss: 0.00188713812
Iter: 1801 loss: 0.00188467687
Iter: 1802 loss: 0.00188382261
Iter: 1803 loss: 0.00188762113
Iter: 1804 loss: 0.00188365614
Iter: 1805 loss: 0.00188327325
Iter: 1806 loss: 0.00188215915
Iter: 1807 loss: 0.00188724534
Iter: 1808 loss: 0.00188176148
Iter: 1809 loss: 0.00187948789
Iter: 1810 loss: 0.00188248
Iter: 1811 loss: 0.00187833875
Iter: 1812 loss: 0.00187608809
Iter: 1813 loss: 0.00189304375
Iter: 1814 loss: 0.00187590811
Iter: 1815 loss: 0.00187290064
Iter: 1816 loss: 0.00188315019
Iter: 1817 loss: 0.00187210948
Iter: 1818 loss: 0.00187038654
Iter: 1819 loss: 0.00186751573
Iter: 1820 loss: 0.00186751515
Iter: 1821 loss: 0.00186356145
Iter: 1822 loss: 0.00186356669
Iter: 1823 loss: 0.0018617505
Iter: 1824 loss: 0.00186357333
Iter: 1825 loss: 0.00186071882
Iter: 1826 loss: 0.00185931334
Iter: 1827 loss: 0.00185787235
Iter: 1828 loss: 0.00185760017
Iter: 1829 loss: 0.00185505976
Iter: 1830 loss: 0.00185330561
Iter: 1831 loss: 0.0018523857
Iter: 1832 loss: 0.00185720448
Iter: 1833 loss: 0.001851885
Iter: 1834 loss: 0.00185154576
Iter: 1835 loss: 0.00185386557
Iter: 1836 loss: 0.00185151072
Iter: 1837 loss: 0.00185121933
Iter: 1838 loss: 0.00185018755
Iter: 1839 loss: 0.0018483703
Iter: 1840 loss: 0.00184829091
Iter: 1841 loss: 0.00184592977
Iter: 1842 loss: 0.00187594874
Iter: 1843 loss: 0.0018459144
Iter: 1844 loss: 0.00184412883
Iter: 1845 loss: 0.00184597529
Iter: 1846 loss: 0.0018431308
Iter: 1847 loss: 0.00184120936
Iter: 1848 loss: 0.00186185702
Iter: 1849 loss: 0.00184116943
Iter: 1850 loss: 0.00184046314
Iter: 1851 loss: 0.00183894567
Iter: 1852 loss: 0.00186245202
Iter: 1853 loss: 0.0018388906
Iter: 1854 loss: 0.00183747546
Iter: 1855 loss: 0.00183827453
Iter: 1856 loss: 0.00183655089
Iter: 1857 loss: 0.00183532899
Iter: 1858 loss: 0.00183951599
Iter: 1859 loss: 0.00183501211
Iter: 1860 loss: 0.00183350942
Iter: 1861 loss: 0.00183992088
Iter: 1862 loss: 0.00183319359
Iter: 1863 loss: 0.0018322547
Iter: 1864 loss: 0.00183008856
Iter: 1865 loss: 0.00185702951
Iter: 1866 loss: 0.00182992406
Iter: 1867 loss: 0.0018285499
Iter: 1868 loss: 0.0018284861
Iter: 1869 loss: 0.00182735804
Iter: 1870 loss: 0.00183973787
Iter: 1871 loss: 0.00182733289
Iter: 1872 loss: 0.00182690343
Iter: 1873 loss: 0.0018255075
Iter: 1874 loss: 0.00182641647
Iter: 1875 loss: 0.00182428746
Iter: 1876 loss: 0.00182239362
Iter: 1877 loss: 0.00184878381
Iter: 1878 loss: 0.00182239199
Iter: 1879 loss: 0.00182150421
Iter: 1880 loss: 0.00182126986
Iter: 1881 loss: 0.00182071957
Iter: 1882 loss: 0.00181982608
Iter: 1883 loss: 0.00182203972
Iter: 1884 loss: 0.0018195099
Iter: 1885 loss: 0.00181898661
Iter: 1886 loss: 0.00181855285
Iter: 1887 loss: 0.00181840558
Iter: 1888 loss: 0.00181708869
Iter: 1889 loss: 0.00181501813
Iter: 1890 loss: 0.00181499764
Iter: 1891 loss: 0.00181345711
Iter: 1892 loss: 0.00181587948
Iter: 1893 loss: 0.00181272696
Iter: 1894 loss: 0.00181187817
Iter: 1895 loss: 0.00181165105
Iter: 1896 loss: 0.00180994137
Iter: 1897 loss: 0.00180792669
Iter: 1898 loss: 0.00180770876
Iter: 1899 loss: 0.00180610444
Iter: 1900 loss: 0.00180610898
Iter: 1901 loss: 0.00180574
Iter: 1902 loss: 0.00180556066
Iter: 1903 loss: 0.0018052503
Iter: 1904 loss: 0.00180424505
Iter: 1905 loss: 0.00180446589
Iter: 1906 loss: 0.00180324318
Iter: 1907 loss: 0.00180182885
Iter: 1908 loss: 0.0018117812
Iter: 1909 loss: 0.00180169975
Iter: 1910 loss: 0.00180072803
Iter: 1911 loss: 0.00180623366
Iter: 1912 loss: 0.00180060021
Iter: 1913 loss: 0.00179999438
Iter: 1914 loss: 0.001799986
Iter: 1915 loss: 0.00179950893
Iter: 1916 loss: 0.0017981464
Iter: 1917 loss: 0.00180455064
Iter: 1918 loss: 0.0017976719
Iter: 1919 loss: 0.00179592578
Iter: 1920 loss: 0.00179353077
Iter: 1921 loss: 0.00179342204
Iter: 1922 loss: 0.0017912063
Iter: 1923 loss: 0.00179157546
Iter: 1924 loss: 0.00178954611
Iter: 1925 loss: 0.00178807
Iter: 1926 loss: 0.00178913795
Iter: 1927 loss: 0.00178715691
Iter: 1928 loss: 0.00178585586
Iter: 1929 loss: 0.00178845669
Iter: 1930 loss: 0.00178532465
Iter: 1931 loss: 0.00178397424
Iter: 1932 loss: 0.00178397028
Iter: 1933 loss: 0.00179044483
Iter: 1934 loss: 0.00178349204
Iter: 1935 loss: 0.00178325
Iter: 1936 loss: 0.00178243755
Iter: 1937 loss: 0.00178220752
Iter: 1938 loss: 0.00178150856
Iter: 1939 loss: 0.00178046303
Iter: 1940 loss: 0.00178041
Iter: 1941 loss: 0.00177982985
Iter: 1942 loss: 0.00178089016
Iter: 1943 loss: 0.0017795756
Iter: 1944 loss: 0.00177867408
Iter: 1945 loss: 0.00178021262
Iter: 1946 loss: 0.00177827035
Iter: 1947 loss: 0.00177777547
Iter: 1948 loss: 0.00177739712
Iter: 1949 loss: 0.00177724194
Iter: 1950 loss: 0.00177649013
Iter: 1951 loss: 0.00177507754
Iter: 1952 loss: 0.00180621771
Iter: 1953 loss: 0.00177507824
Iter: 1954 loss: 0.00177350338
Iter: 1955 loss: 0.00179214939
Iter: 1956 loss: 0.00177348813
Iter: 1957 loss: 0.0017724369
Iter: 1958 loss: 0.00177942542
Iter: 1959 loss: 0.00177233189
Iter: 1960 loss: 0.00177127658
Iter: 1961 loss: 0.00177193386
Iter: 1962 loss: 0.00177060382
Iter: 1963 loss: 0.00176903256
Iter: 1964 loss: 0.00179121923
Iter: 1965 loss: 0.00176902791
Iter: 1966 loss: 0.00176832557
Iter: 1967 loss: 0.00176811824
Iter: 1968 loss: 0.00176766748
Iter: 1969 loss: 0.00176667282
Iter: 1970 loss: 0.00178101496
Iter: 1971 loss: 0.00176663336
Iter: 1972 loss: 0.00176595221
Iter: 1973 loss: 0.00176587084
Iter: 1974 loss: 0.00176533964
Iter: 1975 loss: 0.00177228288
Iter: 1976 loss: 0.00176534033
Iter: 1977 loss: 0.00176500657
Iter: 1978 loss: 0.00176513032
Iter: 1979 loss: 0.00176477991
Iter: 1980 loss: 0.00176456559
Iter: 1981 loss: 0.00176456117
Iter: 1982 loss: 0.00176435011
Iter: 1983 loss: 0.00176386314
Iter: 1984 loss: 0.00176928483
Iter: 1985 loss: 0.00176380319
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8
+ date
Tue Oct 27 17:17:46 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f0098e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f00b6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f02161ff400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f00d5378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f00d5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f00d52f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f00d5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f003f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01f003f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01d00ac1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01d00ac7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01d007dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01d0017d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01287d60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01287d6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012877ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012879c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01287d6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0128776d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012879c510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01286c0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01286f2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01286f21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012863b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012863bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012865dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0128625ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01285fc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f01285e6488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012858f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0128592730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012855af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012856f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012858f1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f012856f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0128482bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.232477486
Iter: 2 loss: 23.1084862
Iter: 3 loss: 23.0798683
Iter: 4 loss: 12.7480669
Iter: 5 loss: 12.7393627
Iter: 6 loss: 7.93953753
Iter: 7 loss: 7.93431568
Iter: 8 loss: 5.1519804
Iter: 9 loss: 5.14819
Iter: 10 loss: 3.45786428
Iter: 11 loss: 3.45499802
Iter: 12 loss: 2.39714265
Iter: 13 loss: 2.39478064
Iter: 14 loss: 1.69918692
Iter: 15 loss: 1.69702208
Iter: 16 loss: 1.21793175
Iter: 17 loss: 1.2158
Iter: 18 loss: 0.872084
Iter: 19 loss: 0.869713604
Iter: 20 loss: 0.603678882
Iter: 21 loss: 0.600684881
Iter: 22 loss: 0.396506816
Iter: 23 loss: 0.393330395
Iter: 24 loss: 0.252328455
Iter: 25 loss: 0.24953936
Iter: 26 loss: 0.161801592
Iter: 27 loss: 0.159958
Iter: 28 loss: 0.157498553
Iter: 29 loss: 0.147623569
Iter: 30 loss: 0.100791514
Iter: 31 loss: 887.597473
Iter: 32 loss: 0.100791492
Iter: 33 loss: 2072.7771
Iter: 34 loss: 0.100791499
Iter: 35 loss: 552.758362
Iter: 36 loss: 0.100724399
Iter: 37 loss: 890.673767
Iter: 38 loss: 0.100722849
Iter: 39 loss: 0.0883619413
Iter: 40 loss: 0.0868820772
Iter: 41 loss: 0.0762825832
Iter: 42 loss: 0.0755453557
Iter: 43 loss: 0.0728978291
Iter: 44 loss: 0.0685675666
Iter: 45 loss: 0.0547203794
Iter: 46 loss: 31.9687424
Iter: 47 loss: 0.0547204167
Iter: 48 loss: 0.0541768484
Iter: 49 loss: 0.0513406433
Iter: 50 loss: 0.0473921895
Iter: 51 loss: 0.0572921596
Iter: 52 loss: 0.0448560677
Iter: 53 loss: 0.0432303399
Iter: 54 loss: 0.0424802527
Iter: 55 loss: 0.0395404696
Iter: 56 loss: 0.0388720185
Iter: 57 loss: 0.037253134
Iter: 58 loss: 0.0345956385
Iter: 59 loss: 0.0341187045
Iter: 60 loss: 0.0322990119
Iter: 61 loss: 0.0391516313
Iter: 62 loss: 0.03200268
Iter: 63 loss: 0.0289250724
Iter: 64 loss: 0.0353277773
Iter: 65 loss: 0.0273702703
Iter: 66 loss: 0.0255310461
Iter: 67 loss: 0.0245684832
Iter: 68 loss: 0.0194499791
Iter: 69 loss: 1064.73804
Iter: 70 loss: 0.0194499865
Iter: 71 loss: 0.0175186843
Iter: 72 loss: 0.0302108973
Iter: 73 loss: 0.0175134446
Iter: 74 loss: 0.016632285
Iter: 75 loss: 0.0165160317
Iter: 76 loss: 0.0159461219
Iter: 77 loss: 0.0149927791
Iter: 78 loss: 0.0149809625
Iter: 79 loss: 0.0137701565
Iter: 80 loss: 0.0244770497
Iter: 81 loss: 0.0136157423
Iter: 82 loss: 0.0125543019
Iter: 83 loss: 0.016064262
Iter: 84 loss: 0.0122026484
Iter: 85 loss: 0.01226201
Iter: 86 loss: 0.0114091132
Iter: 87 loss: 0.0108319754
Iter: 88 loss: 0.0117408857
Iter: 89 loss: 0.0105456058
Iter: 90 loss: 0.0100931767
Iter: 91 loss: 0.00997600891
Iter: 92 loss: 0.00969423354
Iter: 93 loss: 0.0090831276
Iter: 94 loss: 0.0131701492
Iter: 95 loss: 0.00901959836
Iter: 96 loss: 0.00858364
Iter: 97 loss: 0.0105059743
Iter: 98 loss: 0.00850610621
Iter: 99 loss: 0.008339772
Iter: 100 loss: 0.00831177458
Iter: 101 loss: 0.00805551931
Iter: 102 loss: 0.00816567894
Iter: 103 loss: 0.00788287446
Iter: 104 loss: 0.00744263129
Iter: 105 loss: 0.00810460839
Iter: 106 loss: 0.00723424368
Iter: 107 loss: 0.00690745609
Iter: 108 loss: 0.00897901598
Iter: 109 loss: 0.0068591414
Iter: 110 loss: 0.00663056644
Iter: 111 loss: 0.00731046405
Iter: 112 loss: 0.00655714422
Iter: 113 loss: 0.00637842575
Iter: 114 loss: 0.0063338792
Iter: 115 loss: 0.00622669142
Iter: 116 loss: 0.00600639684
Iter: 117 loss: 0.00636142958
Iter: 118 loss: 0.00590115041
Iter: 119 loss: 0.0056322189
Iter: 120 loss: 0.00602626102
Iter: 121 loss: 0.0055081537
Iter: 122 loss: 0.00521095889
Iter: 123 loss: 0.00702917576
Iter: 124 loss: 0.00518885721
Iter: 125 loss: 0.00502619427
Iter: 126 loss: 0.00561417919
Iter: 127 loss: 0.00497762
Iter: 128 loss: 0.00488553895
Iter: 129 loss: 0.00476224255
Iter: 130 loss: 0.00475620572
Iter: 131 loss: 0.00460699759
Iter: 132 loss: 0.00507291453
Iter: 133 loss: 0.00456727622
Iter: 134 loss: 0.00449284771
Iter: 135 loss: 0.00448296219
Iter: 136 loss: 0.00439513102
Iter: 137 loss: 0.00442951731
Iter: 138 loss: 0.00433306256
Iter: 139 loss: 0.00425182423
Iter: 140 loss: 0.00415986357
Iter: 141 loss: 0.0041506649
Iter: 142 loss: 0.0040212255
Iter: 143 loss: 0.00454137661
Iter: 144 loss: 0.00399283133
Iter: 145 loss: 0.00387704116
Iter: 146 loss: 0.00457885
Iter: 147 loss: 0.00386447273
Iter: 148 loss: 0.00376506103
Iter: 149 loss: 0.00374924019
Iter: 150 loss: 0.00367862917
Iter: 151 loss: 0.00359389395
Iter: 152 loss: 0.00357326586
Iter: 153 loss: 0.00352111063
Iter: 154 loss: 0.00346537749
Iter: 155 loss: 0.0034287353
Iter: 156 loss: 0.00340651534
Iter: 157 loss: 0.00332955923
Iter: 158 loss: 0.00340544758
Iter: 159 loss: 0.00328755332
Iter: 160 loss: 0.00320841954
Iter: 161 loss: 0.00341091212
Iter: 162 loss: 0.00318077393
Iter: 163 loss: 0.00307783158
Iter: 164 loss: 0.00314144325
Iter: 165 loss: 0.00301137031
Iter: 166 loss: 0.00291365897
Iter: 167 loss: 0.00408814847
Iter: 168 loss: 0.00291221682
Iter: 169 loss: 0.00283082435
Iter: 170 loss: 0.0035477255
Iter: 171 loss: 0.00282817567
Iter: 172 loss: 0.00278224377
Iter: 173 loss: 0.0028724107
Iter: 174 loss: 0.00276226061
Iter: 175 loss: 0.00273585273
Iter: 176 loss: 0.00267421
Iter: 177 loss: 0.00336089893
Iter: 178 loss: 0.00266896351
Iter: 179 loss: 0.00258370442
Iter: 180 loss: 0.00309790345
Iter: 181 loss: 0.00257370528
Iter: 182 loss: 0.00253443792
Iter: 183 loss: 0.00270713074
Iter: 184 loss: 0.00252675847
Iter: 185 loss: 0.00246537384
Iter: 186 loss: 0.002807301
Iter: 187 loss: 0.00245542917
Iter: 188 loss: 0.00240226602
Iter: 189 loss: 0.00250950782
Iter: 190 loss: 0.00238171988
Iter: 191 loss: 0.0023511271
Iter: 192 loss: 0.00240603462
Iter: 193 loss: 0.00233725295
Iter: 194 loss: 0.00230323174
Iter: 195 loss: 0.00236671185
Iter: 196 loss: 0.00228908751
Iter: 197 loss: 0.00224465737
Iter: 198 loss: 0.00229459791
Iter: 199 loss: 0.00222059153
Iter: 200 loss: 0.00217405288
Iter: 201 loss: 0.00222994038
Iter: 202 loss: 0.00215011882
Iter: 203 loss: 0.00210449053
Iter: 204 loss: 0.00252319034
Iter: 205 loss: 0.00210234104
Iter: 206 loss: 0.00208121911
Iter: 207 loss: 0.00227205455
Iter: 208 loss: 0.00208051177
Iter: 209 loss: 0.00207185582
Iter: 210 loss: 0.00204791594
Iter: 211 loss: 0.00217797025
Iter: 212 loss: 0.00204084092
Iter: 213 loss: 0.00200686906
Iter: 214 loss: 0.0020628653
Iter: 215 loss: 0.00199140888
Iter: 216 loss: 0.00196622242
Iter: 217 loss: 0.00208763173
Iter: 218 loss: 0.00196176837
Iter: 219 loss: 0.00194267184
Iter: 220 loss: 0.00202547666
Iter: 221 loss: 0.00193901919
Iter: 222 loss: 0.00192204514
Iter: 223 loss: 0.00207884843
Iter: 224 loss: 0.00192110357
Iter: 225 loss: 0.00191041431
Iter: 226 loss: 0.00192195
Iter: 227 loss: 0.0019046932
Iter: 228 loss: 0.0018937249
Iter: 229 loss: 0.00187409518
Iter: 230 loss: 0.00234923512
Iter: 231 loss: 0.00187409273
Iter: 232 loss: 0.00185700366
Iter: 233 loss: 0.00189522654
Iter: 234 loss: 0.00185057218
Iter: 235 loss: 0.00183413306
Iter: 236 loss: 0.00194659689
Iter: 237 loss: 0.00183245097
Iter: 238 loss: 0.0018212361
Iter: 239 loss: 0.00192614191
Iter: 240 loss: 0.00182083086
Iter: 241 loss: 0.00181209948
Iter: 242 loss: 0.0018571812
Iter: 243 loss: 0.00181066
Iter: 244 loss: 0.00180503214
Iter: 245 loss: 0.00179502938
Iter: 246 loss: 0.00179502903
Iter: 247 loss: 0.00178443734
Iter: 248 loss: 0.00178679428
Iter: 249 loss: 0.0017767176
Iter: 250 loss: 0.00176643464
Iter: 251 loss: 0.00178208668
Iter: 252 loss: 0.00176159537
Iter: 253 loss: 0.00174940424
Iter: 254 loss: 0.00183552736
Iter: 255 loss: 0.00174826873
Iter: 256 loss: 0.00174302247
Iter: 257 loss: 0.00174288033
Iter: 258 loss: 0.00173782767
Iter: 259 loss: 0.001752713
Iter: 260 loss: 0.00173622952
Iter: 261 loss: 0.00173195265
Iter: 262 loss: 0.00172678963
Iter: 263 loss: 0.00172628718
Iter: 264 loss: 0.00171921914
Iter: 265 loss: 0.00172256236
Iter: 266 loss: 0.00171444006
Iter: 267 loss: 0.00170549913
Iter: 268 loss: 0.00171157904
Iter: 269 loss: 0.00169990771
Iter: 270 loss: 0.00169181777
Iter: 271 loss: 0.0016918102
Iter: 272 loss: 0.00169041508
Iter: 273 loss: 0.00168946455
Iter: 274 loss: 0.0016872487
Iter: 275 loss: 0.00168073154
Iter: 276 loss: 0.00170506933
Iter: 277 loss: 0.00167789822
Iter: 278 loss: 0.00167355232
Iter: 279 loss: 0.00167230656
Iter: 280 loss: 0.00166968326
Iter: 281 loss: 0.00166565052
Iter: 282 loss: 0.00166044524
Iter: 283 loss: 0.00166008901
Iter: 284 loss: 0.00165478745
Iter: 285 loss: 0.0016480214
Iter: 286 loss: 0.00164753874
Iter: 287 loss: 0.00164294918
Iter: 288 loss: 0.00165931019
Iter: 289 loss: 0.00164174964
Iter: 290 loss: 0.00163948326
Iter: 291 loss: 0.00166634377
Iter: 292 loss: 0.00163945928
Iter: 293 loss: 0.00163655193
Iter: 294 loss: 0.00163109601
Iter: 295 loss: 0.00175112253
Iter: 296 loss: 0.00163108506
Iter: 297 loss: 0.00162644265
Iter: 298 loss: 0.00164862187
Iter: 299 loss: 0.00162560318
Iter: 300 loss: 0.00162086368
Iter: 301 loss: 0.00162497605
Iter: 302 loss: 0.00161805248
Iter: 303 loss: 0.00161444617
Iter: 304 loss: 0.00163474469
Iter: 305 loss: 0.00161396107
Iter: 306 loss: 0.00161146384
Iter: 307 loss: 0.00161052006
Iter: 308 loss: 0.00160914427
Iter: 309 loss: 0.00160649535
Iter: 310 loss: 0.00160646101
Iter: 311 loss: 0.00160410628
Iter: 312 loss: 0.0016014094
Iter: 313 loss: 0.00160107436
Iter: 314 loss: 0.00159752183
Iter: 315 loss: 0.00164565956
Iter: 316 loss: 0.00159750762
Iter: 317 loss: 0.00159475696
Iter: 318 loss: 0.00159406872
Iter: 319 loss: 0.00159231713
Iter: 320 loss: 0.00158924377
Iter: 321 loss: 0.00158892467
Iter: 322 loss: 0.00158668752
Iter: 323 loss: 0.00158356118
Iter: 324 loss: 0.00158501789
Iter: 325 loss: 0.00158142741
Iter: 326 loss: 0.00157660467
Iter: 327 loss: 0.00158486306
Iter: 328 loss: 0.00157445739
Iter: 329 loss: 0.00157004269
Iter: 330 loss: 0.00156803417
Iter: 331 loss: 0.00156581751
Iter: 332 loss: 0.00155842921
Iter: 333 loss: 0.00163853797
Iter: 334 loss: 0.00155827438
Iter: 335 loss: 0.00155272544
Iter: 336 loss: 0.00156815129
Iter: 337 loss: 0.00155088759
Iter: 338 loss: 0.00154668861
Iter: 339 loss: 0.00154665951
Iter: 340 loss: 0.00154452014
Iter: 341 loss: 0.00155825634
Iter: 342 loss: 0.00154427369
Iter: 343 loss: 0.00154214422
Iter: 344 loss: 0.0015432256
Iter: 345 loss: 0.0015407342
Iter: 346 loss: 0.00153814792
Iter: 347 loss: 0.00153773441
Iter: 348 loss: 0.0015359465
Iter: 349 loss: 0.00153238443
Iter: 350 loss: 0.0015735568
Iter: 351 loss: 0.00153233437
Iter: 352 loss: 0.00152998324
Iter: 353 loss: 0.00153620227
Iter: 354 loss: 0.00152918778
Iter: 355 loss: 0.00152698497
Iter: 356 loss: 0.00152493035
Iter: 357 loss: 0.00152441522
Iter: 358 loss: 0.00152067724
Iter: 359 loss: 0.00153466337
Iter: 360 loss: 0.00151975197
Iter: 361 loss: 0.0015165261
Iter: 362 loss: 0.00151219475
Iter: 363 loss: 0.00151196122
Iter: 364 loss: 0.00150613091
Iter: 365 loss: 0.00155051157
Iter: 366 loss: 0.0015056734
Iter: 367 loss: 0.00150030013
Iter: 368 loss: 0.0015149042
Iter: 369 loss: 0.00149858196
Iter: 370 loss: 0.00149506226
Iter: 371 loss: 0.00154107972
Iter: 372 loss: 0.00149503513
Iter: 373 loss: 0.00149286748
Iter: 374 loss: 0.00149094267
Iter: 375 loss: 0.00149039307
Iter: 376 loss: 0.00148533587
Iter: 377 loss: 0.00149780232
Iter: 378 loss: 0.00148351188
Iter: 379 loss: 0.00147922803
Iter: 380 loss: 0.0014769726
Iter: 381 loss: 0.00147501682
Iter: 382 loss: 0.00147149712
Iter: 383 loss: 0.00147105544
Iter: 384 loss: 0.00146833342
Iter: 385 loss: 0.00148306298
Iter: 386 loss: 0.00146793353
Iter: 387 loss: 0.00146547402
Iter: 388 loss: 0.00146300858
Iter: 389 loss: 0.00146250334
Iter: 390 loss: 0.0014586522
Iter: 391 loss: 0.00148115668
Iter: 392 loss: 0.00145816826
Iter: 393 loss: 0.00145490479
Iter: 394 loss: 0.00144898356
Iter: 395 loss: 0.00159201073
Iter: 396 loss: 0.00144897983
Iter: 397 loss: 0.00144302682
Iter: 398 loss: 0.00146992051
Iter: 399 loss: 0.00144190097
Iter: 400 loss: 0.00143698195
Iter: 401 loss: 0.00146123173
Iter: 402 loss: 0.00143609929
Iter: 403 loss: 0.00143245771
Iter: 404 loss: 0.00147251296
Iter: 405 loss: 0.00143239205
Iter: 406 loss: 0.00142929063
Iter: 407 loss: 0.00144130853
Iter: 408 loss: 0.00142854673
Iter: 409 loss: 0.00142561574
Iter: 410 loss: 0.00143551116
Iter: 411 loss: 0.00142482948
Iter: 412 loss: 0.0014213809
Iter: 413 loss: 0.00141873804
Iter: 414 loss: 0.00141762861
Iter: 415 loss: 0.00141396222
Iter: 416 loss: 0.00143938896
Iter: 417 loss: 0.0014136259
Iter: 418 loss: 0.00141039712
Iter: 419 loss: 0.00143167074
Iter: 420 loss: 0.00141004263
Iter: 421 loss: 0.00140771223
Iter: 422 loss: 0.00140393781
Iter: 423 loss: 0.00140391442
Iter: 424 loss: 0.0013991053
Iter: 425 loss: 0.00141625048
Iter: 426 loss: 0.00139784021
Iter: 427 loss: 0.00139287103
Iter: 428 loss: 0.00139171537
Iter: 429 loss: 0.00138852082
Iter: 430 loss: 0.00138290273
Iter: 431 loss: 0.00139179337
Iter: 432 loss: 0.00138026127
Iter: 433 loss: 0.00137442874
Iter: 434 loss: 0.0014024222
Iter: 435 loss: 0.00137342466
Iter: 436 loss: 0.00136889145
Iter: 437 loss: 0.0013688528
Iter: 438 loss: 0.00136616139
Iter: 439 loss: 0.00136657292
Iter: 440 loss: 0.0013641353
Iter: 441 loss: 0.00135994016
Iter: 442 loss: 0.00136741647
Iter: 443 loss: 0.0013580774
Iter: 444 loss: 0.00135431159
Iter: 445 loss: 0.00135536655
Iter: 446 loss: 0.00135159609
Iter: 447 loss: 0.00134789222
Iter: 448 loss: 0.00138180237
Iter: 449 loss: 0.00134771969
Iter: 450 loss: 0.00134476367
Iter: 451 loss: 0.00137703784
Iter: 452 loss: 0.00134470803
Iter: 453 loss: 0.0013421413
Iter: 454 loss: 0.00134145573
Iter: 455 loss: 0.00133986
Iter: 456 loss: 0.00133626151
Iter: 457 loss: 0.00134506426
Iter: 458 loss: 0.0013349941
Iter: 459 loss: 0.0013309432
Iter: 460 loss: 0.0013277916
Iter: 461 loss: 0.0013265037
Iter: 462 loss: 0.00132157328
Iter: 463 loss: 0.00133780041
Iter: 464 loss: 0.00132020283
Iter: 465 loss: 0.00131509872
Iter: 466 loss: 0.00132693979
Iter: 467 loss: 0.00131316436
Iter: 468 loss: 0.00130897295
Iter: 469 loss: 0.00130896876
Iter: 470 loss: 0.00130577176
Iter: 471 loss: 0.00132903235
Iter: 472 loss: 0.00130548375
Iter: 473 loss: 0.00130309339
Iter: 474 loss: 0.00131498044
Iter: 475 loss: 0.00130270072
Iter: 476 loss: 0.00130068
Iter: 477 loss: 0.00129912398
Iter: 478 loss: 0.00129847357
Iter: 479 loss: 0.00129577157
Iter: 480 loss: 0.00129566388
Iter: 481 loss: 0.00129357609
Iter: 482 loss: 0.00129031355
Iter: 483 loss: 0.00129031204
Iter: 484 loss: 0.00128803239
Iter: 485 loss: 0.00128725346
Iter: 486 loss: 0.00128595426
Iter: 487 loss: 0.00128231011
Iter: 488 loss: 0.00128353119
Iter: 489 loss: 0.00127970683
Iter: 490 loss: 0.00127489935
Iter: 491 loss: 0.00128297834
Iter: 492 loss: 0.00127273728
Iter: 493 loss: 0.0012685284
Iter: 494 loss: 0.00126691768
Iter: 495 loss: 0.00126461696
Iter: 496 loss: 0.00125738163
Iter: 497 loss: 0.00127481495
Iter: 498 loss: 0.00125478418
Iter: 499 loss: 0.00125184632
Iter: 500 loss: 0.00125086
Iter: 501 loss: 0.00124849402
Iter: 502 loss: 0.00125929108
Iter: 503 loss: 0.00124805525
Iter: 504 loss: 0.00124570378
Iter: 505 loss: 0.00124998065
Iter: 506 loss: 0.00124467281
Iter: 507 loss: 0.00124225905
Iter: 508 loss: 0.00124155288
Iter: 509 loss: 0.00124010444
Iter: 510 loss: 0.00123690232
Iter: 511 loss: 0.00124443113
Iter: 512 loss: 0.00123571919
Iter: 513 loss: 0.00123341149
Iter: 514 loss: 0.00123341277
Iter: 515 loss: 0.00123140612
Iter: 516 loss: 0.00123253325
Iter: 517 loss: 0.00123008632
Iter: 518 loss: 0.00122759468
Iter: 519 loss: 0.00122953905
Iter: 520 loss: 0.00122609455
Iter: 521 loss: 0.00122314505
Iter: 522 loss: 0.00122820749
Iter: 523 loss: 0.00122182094
Iter: 524 loss: 0.00121919019
Iter: 525 loss: 0.00121780811
Iter: 526 loss: 0.00121660682
Iter: 527 loss: 0.00121203822
Iter: 528 loss: 0.00123575656
Iter: 529 loss: 0.00121129456
Iter: 530 loss: 0.00120807975
Iter: 531 loss: 0.00123159192
Iter: 532 loss: 0.0012078213
Iter: 533 loss: 0.00120571384
Iter: 534 loss: 0.00120571384
Iter: 535 loss: 0.00120456528
Iter: 536 loss: 0.00120535959
Iter: 537 loss: 0.00120385084
Iter: 538 loss: 0.00120218948
Iter: 539 loss: 0.00120324863
Iter: 540 loss: 0.00120112463
Iter: 541 loss: 0.00119916536
Iter: 542 loss: 0.00119938073
Iter: 543 loss: 0.00119766104
Iter: 544 loss: 0.00119577185
Iter: 545 loss: 0.00119576289
Iter: 546 loss: 0.00119432178
Iter: 547 loss: 0.00119566382
Iter: 548 loss: 0.00119349465
Iter: 549 loss: 0.00119182328
Iter: 550 loss: 0.0011924688
Iter: 551 loss: 0.00119065575
Iter: 552 loss: 0.00118830684
Iter: 553 loss: 0.00119102723
Iter: 554 loss: 0.0011870591
Iter: 555 loss: 0.00118441961
Iter: 556 loss: 0.00118287292
Iter: 557 loss: 0.00118175475
Iter: 558 loss: 0.00117722084
Iter: 559 loss: 0.00118452311
Iter: 560 loss: 0.00117512979
Iter: 561 loss: 0.0011711577
Iter: 562 loss: 0.00122584542
Iter: 563 loss: 0.00117113499
Iter: 564 loss: 0.00116957724
Iter: 565 loss: 0.00116938457
Iter: 566 loss: 0.00116825686
Iter: 567 loss: 0.00116759096
Iter: 568 loss: 0.00116711471
Iter: 569 loss: 0.00116502575
Iter: 570 loss: 0.0011655211
Iter: 571 loss: 0.00116350013
Iter: 572 loss: 0.00116092525
Iter: 573 loss: 0.00116466929
Iter: 574 loss: 0.00115967321
Iter: 575 loss: 0.00115799624
Iter: 576 loss: 0.00115799252
Iter: 577 loss: 0.00115655758
Iter: 578 loss: 0.00115863886
Iter: 579 loss: 0.00115585921
Iter: 580 loss: 0.0011543415
Iter: 581 loss: 0.00115387328
Iter: 582 loss: 0.00115297537
Iter: 583 loss: 0.00115065766
Iter: 584 loss: 0.00115418667
Iter: 585 loss: 0.00114954636
Iter: 586 loss: 0.00114707323
Iter: 587 loss: 0.00114693074
Iter: 588 loss: 0.00114504667
Iter: 589 loss: 0.00114188401
Iter: 590 loss: 0.00116517046
Iter: 591 loss: 0.00114161544
Iter: 592 loss: 0.0011396663
Iter: 593 loss: 0.00115664792
Iter: 594 loss: 0.00113956747
Iter: 595 loss: 0.00113870297
Iter: 596 loss: 0.00113864604
Iter: 597 loss: 0.00113804126
Iter: 598 loss: 0.00113743101
Iter: 599 loss: 0.00113731017
Iter: 600 loss: 0.0011361012
Iter: 601 loss: 0.0011390642
Iter: 602 loss: 0.00113566325
Iter: 603 loss: 0.00113466277
Iter: 604 loss: 0.00113546057
Iter: 605 loss: 0.00113405869
Iter: 606 loss: 0.00113310106
Iter: 607 loss: 0.00114118936
Iter: 608 loss: 0.00113304518
Iter: 609 loss: 0.00113215623
Iter: 610 loss: 0.00113551808
Iter: 611 loss: 0.00113194226
Iter: 612 loss: 0.00113122724
Iter: 613 loss: 0.00113113096
Iter: 614 loss: 0.00113062316
Iter: 615 loss: 0.00112950453
Iter: 616 loss: 0.00113173923
Iter: 617 loss: 0.00112904841
Iter: 618 loss: 0.00112778181
Iter: 619 loss: 0.0011270328
Iter: 620 loss: 0.00112650183
Iter: 621 loss: 0.00112508552
Iter: 622 loss: 0.00113220233
Iter: 623 loss: 0.00112484931
Iter: 624 loss: 0.00112367957
Iter: 625 loss: 0.0011285448
Iter: 626 loss: 0.00112342718
Iter: 627 loss: 0.00112292205
Iter: 628 loss: 0.00112279307
Iter: 629 loss: 0.0011223068
Iter: 630 loss: 0.00112179085
Iter: 631 loss: 0.00112170423
Iter: 632 loss: 0.00112076511
Iter: 633 loss: 0.00112499914
Iter: 634 loss: 0.00112058641
Iter: 635 loss: 0.00111979735
Iter: 636 loss: 0.00112062227
Iter: 637 loss: 0.0011193594
Iter: 638 loss: 0.00111863157
Iter: 639 loss: 0.00112156908
Iter: 640 loss: 0.00111847313
Iter: 641 loss: 0.00111765717
Iter: 642 loss: 0.00112035708
Iter: 643 loss: 0.00111743249
Iter: 644 loss: 0.00111674261
Iter: 645 loss: 0.00111609534
Iter: 646 loss: 0.00111593434
Iter: 647 loss: 0.00111467612
Iter: 648 loss: 0.00111630093
Iter: 649 loss: 0.00111402781
Iter: 650 loss: 0.00111261976
Iter: 651 loss: 0.00111259008
Iter: 652 loss: 0.00111148378
Iter: 653 loss: 0.00110974966
Iter: 654 loss: 0.00111645448
Iter: 655 loss: 0.00110933883
Iter: 656 loss: 0.00110791903
Iter: 657 loss: 0.00112034008
Iter: 658 loss: 0.00110784569
Iter: 659 loss: 0.00110731658
Iter: 660 loss: 0.00110722939
Iter: 661 loss: 0.00110672344
Iter: 662 loss: 0.00110594835
Iter: 663 loss: 0.00110593764
Iter: 664 loss: 0.00110484404
Iter: 665 loss: 0.00110979611
Iter: 666 loss: 0.00110463274
Iter: 667 loss: 0.00110384985
Iter: 668 loss: 0.00110480725
Iter: 669 loss: 0.00110344274
Iter: 670 loss: 0.0011027141
Iter: 671 loss: 0.00110568292
Iter: 672 loss: 0.00110255391
Iter: 673 loss: 0.00110178569
Iter: 674 loss: 0.00110566267
Iter: 675 loss: 0.00110165845
Iter: 676 loss: 0.00110103562
Iter: 677 loss: 0.00110058812
Iter: 678 loss: 0.00110037229
Iter: 679 loss: 0.00109930278
Iter: 680 loss: 0.00110261911
Iter: 681 loss: 0.00109899323
Iter: 682 loss: 0.00109804119
Iter: 683 loss: 0.00109830231
Iter: 684 loss: 0.00109735481
Iter: 685 loss: 0.00109631941
Iter: 686 loss: 0.00109808717
Iter: 687 loss: 0.0010958605
Iter: 688 loss: 0.00109498703
Iter: 689 loss: 0.00110325741
Iter: 690 loss: 0.00109495257
Iter: 691 loss: 0.00109452847
Iter: 692 loss: 0.00109451136
Iter: 693 loss: 0.00109407352
Iter: 694 loss: 0.00109365687
Iter: 695 loss: 0.00109355722
Iter: 696 loss: 0.00109293405
Iter: 697 loss: 0.0010967179
Iter: 698 loss: 0.00109285966
Iter: 699 loss: 0.00109238899
Iter: 700 loss: 0.00109303766
Iter: 701 loss: 0.00109215733
Iter: 702 loss: 0.00109171425
Iter: 703 loss: 0.0010925628
Iter: 704 loss: 0.00109153136
Iter: 705 loss: 0.00109098013
Iter: 706 loss: 0.0010949322
Iter: 707 loss: 0.00109093264
Iter: 708 loss: 0.00109055534
Iter: 709 loss: 0.00109010935
Iter: 710 loss: 0.00109006325
Iter: 711 loss: 0.00108936056
Iter: 712 loss: 0.00109112589
Iter: 713 loss: 0.00108911062
Iter: 714 loss: 0.00108840922
Iter: 715 loss: 0.00108832633
Iter: 716 loss: 0.00108782202
Iter: 717 loss: 0.00108693726
Iter: 718 loss: 0.00108957582
Iter: 719 loss: 0.00108666799
Iter: 720 loss: 0.00108580117
Iter: 721 loss: 0.00108963205
Iter: 722 loss: 0.00108562829
Iter: 723 loss: 0.00108527811
Iter: 724 loss: 0.0010851773
Iter: 725 loss: 0.00108479161
Iter: 726 loss: 0.00108455587
Iter: 727 loss: 0.00108440313
Iter: 728 loss: 0.00108389009
Iter: 729 loss: 0.0010865049
Iter: 730 loss: 0.00108380697
Iter: 731 loss: 0.00108339952
Iter: 732 loss: 0.00108352117
Iter: 733 loss: 0.00108310732
Iter: 734 loss: 0.00108260568
Iter: 735 loss: 0.00108470081
Iter: 736 loss: 0.00108249695
Iter: 737 loss: 0.00108204433
Iter: 738 loss: 0.00108626368
Iter: 739 loss: 0.00108202791
Iter: 740 loss: 0.00108169916
Iter: 741 loss: 0.0010813917
Iter: 742 loss: 0.00108131592
Iter: 743 loss: 0.00108073978
Iter: 744 loss: 0.00108129438
Iter: 745 loss: 0.00108041347
Iter: 746 loss: 0.00107968319
Iter: 747 loss: 0.00108041975
Iter: 748 loss: 0.00107927283
Iter: 749 loss: 0.00107857282
Iter: 750 loss: 0.00107893988
Iter: 751 loss: 0.001078111
Iter: 752 loss: 0.00107723405
Iter: 753 loss: 0.00108428486
Iter: 754 loss: 0.00107717735
Iter: 755 loss: 0.00107673148
Iter: 756 loss: 0.00107672391
Iter: 757 loss: 0.00107627013
Iter: 758 loss: 0.00107642333
Iter: 759 loss: 0.00107595092
Iter: 760 loss: 0.00107550877
Iter: 761 loss: 0.00107742287
Iter: 762 loss: 0.00107542134
Iter: 763 loss: 0.00107499398
Iter: 764 loss: 0.00107551098
Iter: 765 loss: 0.00107477058
Iter: 766 loss: 0.00107437046
Iter: 767 loss: 0.00107498432
Iter: 768 loss: 0.00107418129
Iter: 769 loss: 0.00107374554
Iter: 770 loss: 0.00107809273
Iter: 771 loss: 0.0010737332
Iter: 772 loss: 0.00107342028
Iter: 773 loss: 0.00107306859
Iter: 774 loss: 0.00107302086
Iter: 775 loss: 0.00107247347
Iter: 776 loss: 0.00107446476
Iter: 777 loss: 0.00107233715
Iter: 778 loss: 0.00107184076
Iter: 779 loss: 0.00107189082
Iter: 780 loss: 0.00107146089
Iter: 781 loss: 0.0010708262
Iter: 782 loss: 0.00107130513
Iter: 783 loss: 0.0010704376
Iter: 784 loss: 0.00106978416
Iter: 785 loss: 0.00107404881
Iter: 786 loss: 0.00106971362
Iter: 787 loss: 0.00106943457
Iter: 788 loss: 0.00106938719
Iter: 789 loss: 0.00106907729
Iter: 790 loss: 0.00106925191
Iter: 791 loss: 0.00106887438
Iter: 792 loss: 0.00106860232
Iter: 793 loss: 0.00106939371
Iter: 794 loss: 0.00106851535
Iter: 795 loss: 0.00106824015
Iter: 796 loss: 0.00106835179
Iter: 797 loss: 0.00106805237
Iter: 798 loss: 0.00106771593
Iter: 799 loss: 0.00106887589
Iter: 800 loss: 0.00106762862
Iter: 801 loss: 0.00106734084
Iter: 802 loss: 0.00107040303
Iter: 803 loss: 0.00106733257
Iter: 804 loss: 0.0010671101
Iter: 805 loss: 0.00106691092
Iter: 806 loss: 0.00106685224
Iter: 807 loss: 0.00106650649
Iter: 808 loss: 0.00106709043
Iter: 809 loss: 0.00106634956
Iter: 810 loss: 0.00106594281
Iter: 811 loss: 0.00106649834
Iter: 812 loss: 0.00106574106
Iter: 813 loss: 0.00106535526
Iter: 814 loss: 0.00106540066
Iter: 815 loss: 0.0010650591
Iter: 816 loss: 0.00106456759
Iter: 817 loss: 0.00106788101
Iter: 818 loss: 0.00106452033
Iter: 819 loss: 0.00106425257
Iter: 820 loss: 0.00106424722
Iter: 821 loss: 0.00106398109
Iter: 822 loss: 0.00106461474
Iter: 823 loss: 0.00106388249
Iter: 824 loss: 0.00106368901
Iter: 825 loss: 0.00106392708
Iter: 826 loss: 0.00106358912
Iter: 827 loss: 0.00106330402
Iter: 828 loss: 0.00106353802
Iter: 829 loss: 0.00106313475
Iter: 830 loss: 0.0010628358
Iter: 831 loss: 0.00106362847
Iter: 832 loss: 0.00106273731
Iter: 833 loss: 0.00106247503
Iter: 834 loss: 0.00106511172
Iter: 835 loss: 0.00106246793
Iter: 836 loss: 0.00106227025
Iter: 837 loss: 0.00106207456
Iter: 838 loss: 0.00106203463
Iter: 839 loss: 0.00106172962
Iter: 840 loss: 0.00106247398
Iter: 841 loss: 0.00106161949
Iter: 842 loss: 0.00106131041
Iter: 843 loss: 0.00106167304
Iter: 844 loss: 0.00106114591
Iter: 845 loss: 0.00106079597
Iter: 846 loss: 0.00106077397
Iter: 847 loss: 0.00106050959
Iter: 848 loss: 0.00106004952
Iter: 849 loss: 0.00106224208
Iter: 850 loss: 0.00105996639
Iter: 851 loss: 0.00105971203
Iter: 852 loss: 0.00105969887
Iter: 853 loss: 0.00105944974
Iter: 854 loss: 0.00106014195
Iter: 855 loss: 0.00105936965
Iter: 856 loss: 0.00105919852
Iter: 857 loss: 0.00105929782
Iter: 858 loss: 0.00105908373
Iter: 859 loss: 0.00105882506
Iter: 860 loss: 0.00105923461
Iter: 861 loss: 0.00105870375
Iter: 862 loss: 0.00105844752
Iter: 863 loss: 0.0010592714
Iter: 864 loss: 0.00105837383
Iter: 865 loss: 0.00105815846
Iter: 866 loss: 0.00106018642
Iter: 867 loss: 0.00105815195
Iter: 868 loss: 0.00105798058
Iter: 869 loss: 0.00105794403
Iter: 870 loss: 0.00105783297
Iter: 871 loss: 0.00105763902
Iter: 872 loss: 0.00105787057
Iter: 873 loss: 0.00105753902
Iter: 874 loss: 0.00105730013
Iter: 875 loss: 0.00105744216
Iter: 876 loss: 0.00105714402
Iter: 877 loss: 0.00105684553
Iter: 878 loss: 0.00105683412
Iter: 879 loss: 0.00105660316
Iter: 880 loss: 0.00105622062
Iter: 881 loss: 0.00105834054
Iter: 882 loss: 0.00105616485
Iter: 883 loss: 0.00105595426
Iter: 884 loss: 0.00105594588
Iter: 885 loss: 0.00105575263
Iter: 886 loss: 0.00105658104
Iter: 887 loss: 0.00105570932
Iter: 888 loss: 0.00105559779
Iter: 889 loss: 0.00105551584
Iter: 890 loss: 0.00105547765
Iter: 891 loss: 0.00105524121
Iter: 892 loss: 0.00105579279
Iter: 893 loss: 0.00105515367
Iter: 894 loss: 0.00105495332
Iter: 895 loss: 0.00105571584
Iter: 896 loss: 0.00105490664
Iter: 897 loss: 0.00105475751
Iter: 898 loss: 0.00105623517
Iter: 899 loss: 0.00105475227
Iter: 900 loss: 0.00105464016
Iter: 901 loss: 0.00105461432
Iter: 902 loss: 0.0010545433
Iter: 903 loss: 0.00105440104
Iter: 904 loss: 0.00105454936
Iter: 905 loss: 0.00105432351
Iter: 906 loss: 0.00105412991
Iter: 907 loss: 0.00105426833
Iter: 908 loss: 0.00105401187
Iter: 909 loss: 0.00105377473
Iter: 910 loss: 0.00105386158
Iter: 911 loss: 0.00105360814
Iter: 912 loss: 0.0010533263
Iter: 913 loss: 0.00105408835
Iter: 914 loss: 0.00105323247
Iter: 915 loss: 0.001053093
Iter: 916 loss: 0.00105306378
Iter: 917 loss: 0.00105291524
Iter: 918 loss: 0.001053505
Iter: 919 loss: 0.00105288276
Iter: 920 loss: 0.00105277845
Iter: 921 loss: 0.00105267891
Iter: 922 loss: 0.001052654
Iter: 923 loss: 0.00105245912
Iter: 924 loss: 0.00105320208
Iter: 925 loss: 0.00105241162
Iter: 926 loss: 0.00105227274
Iter: 927 loss: 0.00105284341
Iter: 928 loss: 0.00105224177
Iter: 929 loss: 0.00105213257
Iter: 930 loss: 0.00105293177
Iter: 931 loss: 0.00105212489
Iter: 932 loss: 0.00105202233
Iter: 933 loss: 0.00105205586
Iter: 934 loss: 0.00105195167
Iter: 935 loss: 0.00105184107
Iter: 936 loss: 0.00105184026
Iter: 937 loss: 0.00105175516
Iter: 938 loss: 0.00105157564
Iter: 939 loss: 0.0010518257
Iter: 940 loss: 0.00105148705
Iter: 941 loss: 0.00105128542
Iter: 942 loss: 0.00105121627
Iter: 943 loss: 0.00105110032
Iter: 944 loss: 0.00105081277
Iter: 945 loss: 0.00105187227
Iter: 946 loss: 0.00105074176
Iter: 947 loss: 0.00105057447
Iter: 948 loss: 0.00105056877
Iter: 949 loss: 0.00105042115
Iter: 950 loss: 0.00105138693
Iter: 951 loss: 0.00105040625
Iter: 952 loss: 0.00105032814
Iter: 953 loss: 0.00105020287
Iter: 954 loss: 0.00105020148
Iter: 955 loss: 0.00105001032
Iter: 956 loss: 0.00105099846
Iter: 957 loss: 0.00104997889
Iter: 958 loss: 0.00104984955
Iter: 959 loss: 0.0010501442
Iter: 960 loss: 0.00104979821
Iter: 961 loss: 0.00104967854
Iter: 962 loss: 0.00105066807
Iter: 963 loss: 0.0010496683
Iter: 964 loss: 0.00104956643
Iter: 965 loss: 0.00104965735
Iter: 966 loss: 0.00104950834
Iter: 967 loss: 0.00104940229
Iter: 968 loss: 0.00104937505
Iter: 969 loss: 0.00104930927
Iter: 970 loss: 0.0010491187
Iter: 971 loss: 0.00104934629
Iter: 972 loss: 0.00104902079
Iter: 973 loss: 0.00104879483
Iter: 974 loss: 0.00104896468
Iter: 975 loss: 0.00104865618
Iter: 976 loss: 0.00104843057
Iter: 977 loss: 0.00104890042
Iter: 978 loss: 0.00104833744
Iter: 979 loss: 0.00104824256
Iter: 980 loss: 0.00104821124
Iter: 981 loss: 0.00104810973
Iter: 982 loss: 0.00104874326
Iter: 983 loss: 0.00104809785
Iter: 984 loss: 0.00104802451
Iter: 985 loss: 0.00104791624
Iter: 986 loss: 0.00104791485
Iter: 987 loss: 0.00104776397
Iter: 988 loss: 0.00104860181
Iter: 989 loss: 0.00104774325
Iter: 990 loss: 0.00104764162
Iter: 991 loss: 0.00104787888
Iter: 992 loss: 0.00104760332
Iter: 993 loss: 0.00104750879
Iter: 994 loss: 0.00104804407
Iter: 995 loss: 0.00104749564
Iter: 996 loss: 0.00104739959
Iter: 997 loss: 0.00104752253
Iter: 998 loss: 0.00104734814
Iter: 999 loss: 0.0010472599
Iter: 1000 loss: 0.00104717026
Iter: 1001 loss: 0.00104715163
Iter: 1002 loss: 0.00104696443
Iter: 1003 loss: 0.00104742381
Iter: 1004 loss: 0.00104689877
Iter: 1005 loss: 0.00104671787
Iter: 1006 loss: 0.0010468699
Iter: 1007 loss: 0.00104661088
Iter: 1008 loss: 0.00104643637
Iter: 1009 loss: 0.00104698795
Iter: 1010 loss: 0.00104638492
Iter: 1011 loss: 0.00104627572
Iter: 1012 loss: 0.00104627642
Iter: 1013 loss: 0.00104617805
Iter: 1014 loss: 0.00104690983
Iter: 1015 loss: 0.00104617164
Iter: 1016 loss: 0.00104610785
Iter: 1017 loss: 0.00104599097
Iter: 1018 loss: 0.00104842905
Iter: 1019 loss: 0.00104598864
Iter: 1020 loss: 0.00104583497
Iter: 1021 loss: 0.00104704965
Iter: 1022 loss: 0.00104582484
Iter: 1023 loss: 0.00104573229
Iter: 1024 loss: 0.00104581949
Iter: 1025 loss: 0.00104567758
Iter: 1026 loss: 0.00104557397
Iter: 1027 loss: 0.00104626839
Iter: 1028 loss: 0.00104556326
Iter: 1029 loss: 0.00104547106
Iter: 1030 loss: 0.00104559178
Iter: 1031 loss: 0.00104542181
Iter: 1032 loss: 0.00104532787
Iter: 1033 loss: 0.00104526826
Iter: 1034 loss: 0.00104522938
Iter: 1035 loss: 0.00104505569
Iter: 1036 loss: 0.00104573125
Iter: 1037 loss: 0.00104501517
Iter: 1038 loss: 0.00104487
Iter: 1039 loss: 0.0010450487
Iter: 1040 loss: 0.00104479096
Iter: 1041 loss: 0.00104466383
Iter: 1042 loss: 0.0010446806
Iter: 1043 loss: 0.00104456604
Iter: 1044 loss: 0.00104446081
Iter: 1045 loss: 0.00104445522
Iter: 1046 loss: 0.0010443686
Iter: 1047 loss: 0.00104500714
Iter: 1048 loss: 0.0010443629
Iter: 1049 loss: 0.00104429806
Iter: 1050 loss: 0.00104419026
Iter: 1051 loss: 0.00104418781
Iter: 1052 loss: 0.00104406103
Iter: 1053 loss: 0.00104502181
Iter: 1054 loss: 0.00104405219
Iter: 1055 loss: 0.00104396592
Iter: 1056 loss: 0.00104407733
Iter: 1057 loss: 0.00104392297
Iter: 1058 loss: 0.00104383356
Iter: 1059 loss: 0.00104446511
Iter: 1060 loss: 0.00104382611
Iter: 1061 loss: 0.00104374252
Iter: 1062 loss: 0.00104389247
Iter: 1063 loss: 0.0010437062
Iter: 1064 loss: 0.00104363775
Iter: 1065 loss: 0.00104353367
Iter: 1066 loss: 0.00104353041
Iter: 1067 loss: 0.00104338932
Iter: 1068 loss: 0.00104395358
Iter: 1069 loss: 0.00104335742
Iter: 1070 loss: 0.00104324636
Iter: 1071 loss: 0.00104341202
Iter: 1072 loss: 0.00104319141
Iter: 1073 loss: 0.00104307709
Iter: 1074 loss: 0.00104334299
Iter: 1075 loss: 0.00104303414
Iter: 1076 loss: 0.00104296021
Iter: 1077 loss: 0.00104295905
Iter: 1078 loss: 0.00104289828
Iter: 1079 loss: 0.00104331307
Iter: 1080 loss: 0.00104289199
Iter: 1081 loss: 0.00104284775
Iter: 1082 loss: 0.00104277756
Iter: 1083 loss: 0.00104277686
Iter: 1084 loss: 0.00104269199
Iter: 1085 loss: 0.00104361377
Iter: 1086 loss: 0.00104268896
Iter: 1087 loss: 0.00104263634
Iter: 1088 loss: 0.00104268244
Iter: 1089 loss: 0.00104260282
Iter: 1090 loss: 0.00104254438
Iter: 1091 loss: 0.00104287593
Iter: 1092 loss: 0.00104253413
Iter: 1093 loss: 0.00104247557
Iter: 1094 loss: 0.00104257651
Iter: 1095 loss: 0.00104244961
Iter: 1096 loss: 0.00104239641
Iter: 1097 loss: 0.00104232435
Iter: 1098 loss: 0.00104232016
Iter: 1099 loss: 0.00104221015
Iter: 1100 loss: 0.00104283437
Iter: 1101 loss: 0.00104219653
Iter: 1102 loss: 0.00104211364
Iter: 1103 loss: 0.00104221993
Iter: 1104 loss: 0.0010420708
Iter: 1105 loss: 0.00104199525
Iter: 1106 loss: 0.00104203948
Iter: 1107 loss: 0.00104194623
Iter: 1108 loss: 0.00104189664
Iter: 1109 loss: 0.00104189105
Iter: 1110 loss: 0.00104184542
Iter: 1111 loss: 0.00104213879
Iter: 1112 loss: 0.0010418403
Iter: 1113 loss: 0.00104180491
Iter: 1114 loss: 0.00104175275
Iter: 1115 loss: 0.00104175124
Iter: 1116 loss: 0.00104169431
Iter: 1117 loss: 0.00104227534
Iter: 1118 loss: 0.00104169338
Iter: 1119 loss: 0.00104165194
Iter: 1120 loss: 0.00104167685
Iter: 1121 loss: 0.00104162609
Iter: 1122 loss: 0.00104157813
Iter: 1123 loss: 0.00104181911
Iter: 1124 loss: 0.00104156858
Iter: 1125 loss: 0.00104152202
Iter: 1126 loss: 0.00104161934
Iter: 1127 loss: 0.00104150036
Iter: 1128 loss: 0.00104145904
Iter: 1129 loss: 0.00104139256
Iter: 1130 loss: 0.00104139
Iter: 1131 loss: 0.00104129908
Iter: 1132 loss: 0.00104199082
Iter: 1133 loss: 0.00104129431
Iter: 1134 loss: 0.00104122888
Iter: 1135 loss: 0.00104127161
Iter: 1136 loss: 0.00104118825
Iter: 1137 loss: 0.00104112236
Iter: 1138 loss: 0.00104117976
Iter: 1139 loss: 0.0010410836
Iter: 1140 loss: 0.00104103668
Iter: 1141 loss: 0.00104103773
Iter: 1142 loss: 0.00104100117
Iter: 1143 loss: 0.00104130723
Iter: 1144 loss: 0.001041
Iter: 1145 loss: 0.00104097184
Iter: 1146 loss: 0.00104092364
Iter: 1147 loss: 0.00104092294
Iter: 1148 loss: 0.001040868
Iter: 1149 loss: 0.00104150502
Iter: 1150 loss: 0.00104086741
Iter: 1151 loss: 0.00104082981
Iter: 1152 loss: 0.0010408829
Iter: 1153 loss: 0.00104081107
Iter: 1154 loss: 0.0010407716
Iter: 1155 loss: 0.00104094925
Iter: 1156 loss: 0.00104076485
Iter: 1157 loss: 0.00104072597
Iter: 1158 loss: 0.00104077579
Iter: 1159 loss: 0.00104070548
Iter: 1160 loss: 0.00104066427
Iter: 1161 loss: 0.00104061374
Iter: 1162 loss: 0.00104060781
Iter: 1163 loss: 0.00104053505
Iter: 1164 loss: 0.00104101805
Iter: 1165 loss: 0.00104052701
Iter: 1166 loss: 0.00104046531
Iter: 1167 loss: 0.00104061328
Iter: 1168 loss: 0.0010404468
Iter: 1169 loss: 0.00104040164
Iter: 1170 loss: 0.00104043132
Iter: 1171 loss: 0.00104037393
Iter: 1172 loss: 0.00104034017
Iter: 1173 loss: 0.00104087149
Iter: 1174 loss: 0.00104033842
Iter: 1175 loss: 0.00104031095
Iter: 1176 loss: 0.00104047358
Iter: 1177 loss: 0.00104030874
Iter: 1178 loss: 0.00104027824
Iter: 1179 loss: 0.00104023074
Iter: 1180 loss: 0.00104023074
Iter: 1181 loss: 0.00104018406
Iter: 1182 loss: 0.00104063167
Iter: 1183 loss: 0.00104017986
Iter: 1184 loss: 0.00104015006
Iter: 1185 loss: 0.00104020943
Iter: 1186 loss: 0.00104013481
Iter: 1187 loss: 0.00104010012
Iter: 1188 loss: 0.00104029733
Iter: 1189 loss: 0.00104009511
Iter: 1190 loss: 0.00104005798
Iter: 1191 loss: 0.00104010338
Iter: 1192 loss: 0.00104003993
Iter: 1193 loss: 0.00104000489
Iter: 1194 loss: 0.00103994436
Iter: 1195 loss: 0.00103994296
Iter: 1196 loss: 0.00103987707
Iter: 1197 loss: 0.00104024727
Iter: 1198 loss: 0.00103986706
Iter: 1199 loss: 0.00103981828
Iter: 1200 loss: 0.00104
Iter: 1201 loss: 0.00103980547
Iter: 1202 loss: 0.00103976321
Iter: 1203 loss: 0.0010398603
Iter: 1204 loss: 0.00103974645
Iter: 1205 loss: 0.00103971339
Iter: 1206 loss: 0.00103971281
Iter: 1207 loss: 0.00103968452
Iter: 1208 loss: 0.00103979558
Iter: 1209 loss: 0.00103967718
Iter: 1210 loss: 0.00103964226
Iter: 1211 loss: 0.00103960256
Iter: 1212 loss: 0.00103959721
Iter: 1213 loss: 0.00103955436
Iter: 1214 loss: 0.00104004727
Iter: 1215 loss: 0.00103955227
Iter: 1216 loss: 0.00103952107
Iter: 1217 loss: 0.00103956275
Iter: 1218 loss: 0.00103950477
Iter: 1219 loss: 0.00103946647
Iter: 1220 loss: 0.0010396021
Iter: 1221 loss: 0.00103945751
Iter: 1222 loss: 0.0010394163
Iter: 1223 loss: 0.00103948603
Iter: 1224 loss: 0.00103939686
Iter: 1225 loss: 0.00103935215
Iter: 1226 loss: 0.00103929883
Iter: 1227 loss: 0.00103929651
Iter: 1228 loss: 0.00103923329
Iter: 1229 loss: 0.00103975902
Iter: 1230 loss: 0.00103923073
Iter: 1231 loss: 0.00103918836
Iter: 1232 loss: 0.00103921827
Iter: 1233 loss: 0.00103916298
Iter: 1234 loss: 0.00103910803
Iter: 1235 loss: 0.00103916007
Iter: 1236 loss: 0.00103907729
Iter: 1237 loss: 0.00103903818
Iter: 1238 loss: 0.00103903515
Iter: 1239 loss: 0.00103900081
Iter: 1240 loss: 0.00103919208
Iter: 1241 loss: 0.00103899697
Iter: 1242 loss: 0.001038966
Iter: 1243 loss: 0.00103893224
Iter: 1244 loss: 0.00103892561
Iter: 1245 loss: 0.00103888102
Iter: 1246 loss: 0.0010393156
Iter: 1247 loss: 0.00103887974
Iter: 1248 loss: 0.00103884586
Iter: 1249 loss: 0.00103885331
Iter: 1250 loss: 0.00103881967
Iter: 1251 loss: 0.0010387731
Iter: 1252 loss: 0.00103898905
Iter: 1253 loss: 0.00103876425
Iter: 1254 loss: 0.00103872106
Iter: 1255 loss: 0.00103881652
Iter: 1256 loss: 0.00103870174
Iter: 1257 loss: 0.00103865867
Iter: 1258 loss: 0.00103862025
Iter: 1259 loss: 0.0010386114
Iter: 1260 loss: 0.00103855273
Iter: 1261 loss: 0.00103891222
Iter: 1262 loss: 0.00103854539
Iter: 1263 loss: 0.00103849056
Iter: 1264 loss: 0.00103843992
Iter: 1265 loss: 0.0010384284
Iter: 1266 loss: 0.00103832548
Iter: 1267 loss: 0.00103844935
Iter: 1268 loss: 0.00103827147
Iter: 1269 loss: 0.00103822362
Iter: 1270 loss: 0.00103821396
Iter: 1271 loss: 0.00103817158
Iter: 1272 loss: 0.00103841966
Iter: 1273 loss: 0.00103816623
Iter: 1274 loss: 0.00103812478
Iter: 1275 loss: 0.00103806972
Iter: 1276 loss: 0.00103806518
Iter: 1277 loss: 0.00103800022
Iter: 1278 loss: 0.00103866297
Iter: 1279 loss: 0.00103799836
Iter: 1280 loss: 0.00103794364
Iter: 1281 loss: 0.00103800138
Iter: 1282 loss: 0.00103791512
Iter: 1283 loss: 0.00103785761
Iter: 1284 loss: 0.00103814353
Iter: 1285 loss: 0.00103784993
Iter: 1286 loss: 0.00103779719
Iter: 1287 loss: 0.00103791407
Iter: 1288 loss: 0.00103777763
Iter: 1289 loss: 0.00103772827
Iter: 1290 loss: 0.00103765517
Iter: 1291 loss: 0.00103765167
Iter: 1292 loss: 0.00103755074
Iter: 1293 loss: 0.00103804306
Iter: 1294 loss: 0.00103753153
Iter: 1295 loss: 0.00103742303
Iter: 1296 loss: 0.00103741465
Iter: 1297 loss: 0.00103733526
Iter: 1298 loss: 0.00103720394
Iter: 1299 loss: 0.00103733852
Iter: 1300 loss: 0.00103713246
Iter: 1301 loss: 0.00103705737
Iter: 1302 loss: 0.00103705563
Iter: 1303 loss: 0.00103699602
Iter: 1304 loss: 0.00103729672
Iter: 1305 loss: 0.00103698624
Iter: 1306 loss: 0.00103692058
Iter: 1307 loss: 0.00103684654
Iter: 1308 loss: 0.00103683944
Iter: 1309 loss: 0.00103675865
Iter: 1310 loss: 0.00103768683
Iter: 1311 loss: 0.00103675853
Iter: 1312 loss: 0.00103670289
Iter: 1313 loss: 0.00103681581
Iter: 1314 loss: 0.00103668065
Iter: 1315 loss: 0.00103662757
Iter: 1316 loss: 0.00103684526
Iter: 1317 loss: 0.00103661651
Iter: 1318 loss: 0.0010365576
Iter: 1319 loss: 0.00103664154
Iter: 1320 loss: 0.00103653013
Iter: 1321 loss: 0.00103646668
Iter: 1322 loss: 0.001036364
Iter: 1323 loss: 0.00103636214
Iter: 1324 loss: 0.00103623979
Iter: 1325 loss: 0.00103699579
Iter: 1326 loss: 0.00103622372
Iter: 1327 loss: 0.00103611499
Iter: 1328 loss: 0.00103636435
Iter: 1329 loss: 0.0010360739
Iter: 1330 loss: 0.00103599
Iter: 1331 loss: 0.0010361129
Iter: 1332 loss: 0.00103594782
Iter: 1333 loss: 0.0010358867
Iter: 1334 loss: 0.00103588635
Iter: 1335 loss: 0.00103583722
Iter: 1336 loss: 0.0010360931
Iter: 1337 loss: 0.00103582954
Iter: 1338 loss: 0.00103578018
Iter: 1339 loss: 0.00103575585
Iter: 1340 loss: 0.00103573396
Iter: 1341 loss: 0.00103569007
Iter: 1342 loss: 0.00103634922
Iter: 1343 loss: 0.00103568914
Iter: 1344 loss: 0.00103565946
Iter: 1345 loss: 0.00103568763
Iter: 1346 loss: 0.0010356413
Iter: 1347 loss: 0.00103560323
Iter: 1348 loss: 0.00103572407
Iter: 1349 loss: 0.00103559275
Iter: 1350 loss: 0.00103554991
Iter: 1351 loss: 0.00103561115
Iter: 1352 loss: 0.00103552896
Iter: 1353 loss: 0.00103547797
Iter: 1354 loss: 0.00103542116
Iter: 1355 loss: 0.00103541487
Iter: 1356 loss: 0.00103535014
Iter: 1357 loss: 0.001036064
Iter: 1358 loss: 0.00103534677
Iter: 1359 loss: 0.00103530008
Iter: 1360 loss: 0.00103540637
Iter: 1361 loss: 0.0010352832
Iter: 1362 loss: 0.00103524583
Iter: 1363 loss: 0.00103523443
Iter: 1364 loss: 0.00103521231
Iter: 1365 loss: 0.00103517715
Iter: 1366 loss: 0.00103517552
Iter: 1367 loss: 0.00103515177
Iter: 1368 loss: 0.00103529869
Iter: 1369 loss: 0.00103514805
Iter: 1370 loss: 0.00103512546
Iter: 1371 loss: 0.00103511685
Iter: 1372 loss: 0.00103510579
Iter: 1373 loss: 0.00103508076
Iter: 1374 loss: 0.00103523221
Iter: 1375 loss: 0.00103507889
Iter: 1376 loss: 0.00103505387
Iter: 1377 loss: 0.0010350768
Iter: 1378 loss: 0.00103504094
Iter: 1379 loss: 0.00103501056
Iter: 1380 loss: 0.00103511964
Iter: 1381 loss: 0.00103500474
Iter: 1382 loss: 0.00103497226
Iter: 1383 loss: 0.00103506166
Iter: 1384 loss: 0.00103496108
Iter: 1385 loss: 0.00103493361
Iter: 1386 loss: 0.0010348988
Iter: 1387 loss: 0.00103489647
Iter: 1388 loss: 0.00103486027
Iter: 1389 loss: 0.00103511405
Iter: 1390 loss: 0.00103485771
Iter: 1391 loss: 0.00103482371
Iter: 1392 loss: 0.00103488821
Iter: 1393 loss: 0.00103480928
Iter: 1394 loss: 0.00103477691
Iter: 1395 loss: 0.00103483768
Iter: 1396 loss: 0.00103476178
Iter: 1397 loss: 0.00103473966
Iter: 1398 loss: 0.00103474036
Iter: 1399 loss: 0.00103472406
Iter: 1400 loss: 0.00103480963
Iter: 1401 loss: 0.00103472127
Iter: 1402 loss: 0.00103470485
Iter: 1403 loss: 0.00103468448
Iter: 1404 loss: 0.00103468332
Iter: 1405 loss: 0.00103465491
Iter: 1406 loss: 0.00103489542
Iter: 1407 loss: 0.00103465386
Iter: 1408 loss: 0.00103462883
Iter: 1409 loss: 0.00103466481
Iter: 1410 loss: 0.00103461673
Iter: 1411 loss: 0.00103459042
Iter: 1412 loss: 0.00103472383
Iter: 1413 loss: 0.00103458576
Iter: 1414 loss: 0.00103456096
Iter: 1415 loss: 0.00103462231
Iter: 1416 loss: 0.00103455316
Iter: 1417 loss: 0.00103452837
Iter: 1418 loss: 0.00103448948
Iter: 1419 loss: 0.00103538984
Iter: 1420 loss: 0.00103448937
Iter: 1421 loss: 0.00103444629
Iter: 1422 loss: 0.00103468704
Iter: 1423 loss: 0.00103443977
Iter: 1424 loss: 0.00103439926
Iter: 1425 loss: 0.00103453267
Iter: 1426 loss: 0.00103439041
Iter: 1427 loss: 0.00103435782
Iter: 1428 loss: 0.00103438529
Iter: 1429 loss: 0.00103434268
Iter: 1430 loss: 0.00103431393
Iter: 1431 loss: 0.00103431218
Iter: 1432 loss: 0.00103429041
Iter: 1433 loss: 0.00103435433
Iter: 1434 loss: 0.00103428308
Iter: 1435 loss: 0.00103425083
Iter: 1436 loss: 0.00103422743
Iter: 1437 loss: 0.00103421637
Iter: 1438 loss: 0.00103417924
Iter: 1439 loss: 0.00103451405
Iter: 1440 loss: 0.00103417831
Iter: 1441 loss: 0.00103414687
Iter: 1442 loss: 0.00103420077
Iter: 1443 loss: 0.00103413104
Iter: 1444 loss: 0.00103409891
Iter: 1445 loss: 0.00103421486
Iter: 1446 loss: 0.00103409099
Iter: 1447 loss: 0.00103406
Iter: 1448 loss: 0.00103415025
Iter: 1449 loss: 0.00103404804
Iter: 1450 loss: 0.00103401334
Iter: 1451 loss: 0.00103396538
Iter: 1452 loss: 0.0010339641
Iter: 1453 loss: 0.0010339095
Iter: 1454 loss: 0.00103434548
Iter: 1455 loss: 0.00103390648
Iter: 1456 loss: 0.00103386457
Iter: 1457 loss: 0.00103392813
Iter: 1458 loss: 0.00103384489
Iter: 1459 loss: 0.00103380228
Iter: 1460 loss: 0.00103379297
Iter: 1461 loss: 0.00103376352
Iter: 1462 loss: 0.00103371963
Iter: 1463 loss: 0.00103372009
Iter: 1464 loss: 0.00103368191
Iter: 1465 loss: 0.00103386585
Iter: 1466 loss: 0.00103367842
Iter: 1467 loss: 0.00103364093
Iter: 1468 loss: 0.00103361113
Iter: 1469 loss: 0.00103360228
Iter: 1470 loss: 0.00103356107
Iter: 1471 loss: 0.00103397202
Iter: 1472 loss: 0.00103355874
Iter: 1473 loss: 0.00103352312
Iter: 1474 loss: 0.00103358435
Iter: 1475 loss: 0.00103350845
Iter: 1476 loss: 0.00103347236
Iter: 1477 loss: 0.0010336088
Iter: 1478 loss: 0.00103346363
Iter: 1479 loss: 0.00103342906
Iter: 1480 loss: 0.00103351951
Iter: 1481 loss: 0.00103341555
Iter: 1482 loss: 0.00103338575
Iter: 1483 loss: 0.00103334535
Iter: 1484 loss: 0.00103334233
Iter: 1485 loss: 0.0010332939
Iter: 1486 loss: 0.00103358575
Iter: 1487 loss: 0.00103328703
Iter: 1488 loss: 0.00103324256
Iter: 1489 loss: 0.00103334989
Iter: 1490 loss: 0.00103322451
Iter: 1491 loss: 0.00103318482
Iter: 1492 loss: 0.00103319832
Iter: 1493 loss: 0.00103315408
Iter: 1494 loss: 0.0010331223
Iter: 1495 loss: 0.00103312242
Iter: 1496 loss: 0.00103309937
Iter: 1497 loss: 0.00103320251
Iter: 1498 loss: 0.0010330946
Iter: 1499 loss: 0.00103307189
Iter: 1500 loss: 0.00103305816
Iter: 1501 loss: 0.0010330478
Iter: 1502 loss: 0.00103302044
Iter: 1503 loss: 0.00103320833
Iter: 1504 loss: 0.00103301974
Iter: 1505 loss: 0.00103299483
Iter: 1506 loss: 0.00103304279
Iter: 1507 loss: 0.00103298761
Iter: 1508 loss: 0.00103296223
Iter: 1509 loss: 0.00103308458
Iter: 1510 loss: 0.00103295827
Iter: 1511 loss: 0.00103293802
Iter: 1512 loss: 0.00103299366
Iter: 1513 loss: 0.00103293033
Iter: 1514 loss: 0.0010329138
Iter: 1515 loss: 0.00103287853
Iter: 1516 loss: 0.00103366189
Iter: 1517 loss: 0.00103287969
Iter: 1518 loss: 0.00103284349
Iter: 1519 loss: 0.00103309611
Iter: 1520 loss: 0.00103284
Iter: 1521 loss: 0.00103280775
Iter: 1522 loss: 0.00103290426
Iter: 1523 loss: 0.00103280065
Iter: 1524 loss: 0.00103277608
Iter: 1525 loss: 0.00103283278
Iter: 1526 loss: 0.00103276782
Iter: 1527 loss: 0.00103275222
Iter: 1528 loss: 0.00103275292
Iter: 1529 loss: 0.00103274023
Iter: 1530 loss: 0.00103278516
Iter: 1531 loss: 0.00103273476
Iter: 1532 loss: 0.00103272323
Iter: 1533 loss: 0.00103271217
Iter: 1534 loss: 0.00103270705
Iter: 1535 loss: 0.00103269
Iter: 1536 loss: 0.00103280775
Iter: 1537 loss: 0.0010326897
Iter: 1538 loss: 0.0010326748
Iter: 1539 loss: 0.00103270914
Iter: 1540 loss: 0.00103266933
Iter: 1541 loss: 0.00103265303
Iter: 1542 loss: 0.00103271392
Iter: 1543 loss: 0.00103265059
Iter: 1544 loss: 0.00103263487
Iter: 1545 loss: 0.00103266607
Iter: 1546 loss: 0.00103262789
Iter: 1547 loss: 0.00103260926
Iter: 1548 loss: 0.00103258155
Iter: 1549 loss: 0.00103258225
Iter: 1550 loss: 0.00103255454
Iter: 1551 loss: 0.00103271799
Iter: 1552 loss: 0.00103255245
Iter: 1553 loss: 0.00103252952
Iter: 1554 loss: 0.00103259261
Iter: 1555 loss: 0.00103252288
Iter: 1556 loss: 0.00103250379
Iter: 1557 loss: 0.00103251589
Iter: 1558 loss: 0.00103249156
Iter: 1559 loss: 0.00103247608
Iter: 1560 loss: 0.00103247503
Iter: 1561 loss: 0.00103246234
Iter: 1562 loss: 0.00103248807
Iter: 1563 loss: 0.0010324578
Iter: 1564 loss: 0.00103244279
Iter: 1565 loss: 0.00103243825
Iter: 1566 loss: 0.00103242963
Iter: 1567 loss: 0.00103241042
Iter: 1568 loss: 0.00103248504
Iter: 1569 loss: 0.00103240716
Iter: 1570 loss: 0.00103238435
Iter: 1571 loss: 0.00103241135
Iter: 1572 loss: 0.00103237492
Iter: 1573 loss: 0.00103234791
Iter: 1574 loss: 0.00103242719
Iter: 1575 loss: 0.00103234011
Iter: 1576 loss: 0.00103231287
Iter: 1577 loss: 0.00103239762
Iter: 1578 loss: 0.00103230332
Iter: 1579 loss: 0.00103227689
Iter: 1580 loss: 0.00103224325
Iter: 1581 loss: 0.00103224139
Iter: 1582 loss: 0.00103220413
Iter: 1583 loss: 0.00103238039
Iter: 1584 loss: 0.00103219831
Iter: 1585 loss: 0.00103215734
Iter: 1586 loss: 0.00103217759
Iter: 1587 loss: 0.00103213103
Iter: 1588 loss: 0.00103207782
Iter: 1589 loss: 0.00103215582
Iter: 1590 loss: 0.00103205128
Iter: 1591 loss: 0.00103201729
Iter: 1592 loss: 0.00103201589
Iter: 1593 loss: 0.0010319869
Iter: 1594 loss: 0.00103212544
Iter: 1595 loss: 0.00103198166
Iter: 1596 loss: 0.00103195594
Iter: 1597 loss: 0.00103194127
Iter: 1598 loss: 0.00103192974
Iter: 1599 loss: 0.00103189098
Iter: 1600 loss: 0.00103200017
Iter: 1601 loss: 0.00103187934
Iter: 1602 loss: 0.00103182357
Iter: 1603 loss: 0.00103189296
Iter: 1604 loss: 0.00103179622
Iter: 1605 loss: 0.001031733
Iter: 1606 loss: 0.00103206444
Iter: 1607 loss: 0.00103172357
Iter: 1608 loss: 0.00103167316
Iter: 1609 loss: 0.0010318011
Iter: 1610 loss: 0.0010316564
Iter: 1611 loss: 0.00103160786
Iter: 1612 loss: 0.00103154022
Iter: 1613 loss: 0.00103153917
Iter: 1614 loss: 0.00103145279
Iter: 1615 loss: 0.0010317011
Iter: 1616 loss: 0.00103142695
Iter: 1617 loss: 0.00103131693
Iter: 1618 loss: 0.00103146746
Iter: 1619 loss: 0.00103126327
Iter: 1620 loss: 0.00103114743
Iter: 1621 loss: 0.00103128213
Iter: 1622 loss: 0.00103108515
Iter: 1623 loss: 0.00103102508
Iter: 1624 loss: 0.00103101274
Iter: 1625 loss: 0.00103096361
Iter: 1626 loss: 0.00103114813
Iter: 1627 loss: 0.00103095034
Iter: 1628 loss: 0.00103089924
Iter: 1629 loss: 0.00103084149
Iter: 1630 loss: 0.00103083323
Iter: 1631 loss: 0.00103074929
Iter: 1632 loss: 0.00103095744
Iter: 1633 loss: 0.00103072065
Iter: 1634 loss: 0.00103060249
Iter: 1635 loss: 0.00103096548
Iter: 1636 loss: 0.0010305671
Iter: 1637 loss: 0.00103046349
Iter: 1638 loss: 0.00103112718
Iter: 1639 loss: 0.00103045255
Iter: 1640 loss: 0.00103037548
Iter: 1641 loss: 0.00103057979
Iter: 1642 loss: 0.00103034824
Iter: 1643 loss: 0.0010302664
Iter: 1644 loss: 0.00103016978
Iter: 1645 loss: 0.00103016011
Iter: 1646 loss: 0.00103002321
Iter: 1647 loss: 0.00103038945
Iter: 1648 loss: 0.0010299813
Iter: 1649 loss: 0.00102981401
Iter: 1650 loss: 0.00103008526
Iter: 1651 loss: 0.00102973869
Iter: 1652 loss: 0.00102958526
Iter: 1653 loss: 0.00102973531
Iter: 1654 loss: 0.00102949725
Iter: 1655 loss: 0.00102941098
Iter: 1656 loss: 0.00102940341
Iter: 1657 loss: 0.00102933182
Iter: 1658 loss: 0.00102969189
Iter: 1659 loss: 0.00102932018
Iter: 1660 loss: 0.00102924835
Iter: 1661 loss: 0.0010291934
Iter: 1662 loss: 0.00102917023
Iter: 1663 loss: 0.00102907175
Iter: 1664 loss: 0.00102932961
Iter: 1665 loss: 0.00102904043
Iter: 1666 loss: 0.00102892518
Iter: 1667 loss: 0.00102929957
Iter: 1668 loss: 0.00102889165
Iter: 1669 loss: 0.00102879363
Iter: 1670 loss: 0.00102946558
Iter: 1671 loss: 0.00102878269
Iter: 1672 loss: 0.00102871202
Iter: 1673 loss: 0.00102889608
Iter: 1674 loss: 0.00102868723
Iter: 1675 loss: 0.001028614
Iter: 1676 loss: 0.00102853193
Iter: 1677 loss: 0.00102852331
Iter: 1678 loss: 0.00102841249
Iter: 1679 loss: 0.00102864509
Iter: 1680 loss: 0.00102836778
Iter: 1681 loss: 0.0010282232
Iter: 1682 loss: 0.00102860481
Iter: 1683 loss: 0.00102817384
Iter: 1684 loss: 0.00102805463
Iter: 1685 loss: 0.00102817838
Iter: 1686 loss: 0.0010279885
Iter: 1687 loss: 0.00102791982
Iter: 1688 loss: 0.00102791097
Iter: 1689 loss: 0.00102785346
Iter: 1690 loss: 0.00102816231
Iter: 1691 loss: 0.00102784648
Iter: 1692 loss: 0.00102779339
Iter: 1693 loss: 0.00102775451
Iter: 1694 loss: 0.00102773809
Iter: 1695 loss: 0.00102767278
Iter: 1696 loss: 0.00102780527
Iter: 1697 loss: 0.00102764484
Iter: 1698 loss: 0.00102756009
Iter: 1699 loss: 0.00102782471
Iter: 1700 loss: 0.00102753448
Iter: 1701 loss: 0.001027463
Iter: 1702 loss: 0.00102798571
Iter: 1703 loss: 0.00102745742
Iter: 1704 loss: 0.00102740224
Iter: 1705 loss: 0.00102754892
Iter: 1706 loss: 0.00102738605
Iter: 1707 loss: 0.00102733495
Iter: 1708 loss: 0.00102727523
Iter: 1709 loss: 0.00102726812
Iter: 1710 loss: 0.001027185
Iter: 1711 loss: 0.00102738244
Iter: 1712 loss: 0.00102715474
Iter: 1713 loss: 0.00102704787
Iter: 1714 loss: 0.00102734496
Iter: 1715 loss: 0.00102701481
Iter: 1716 loss: 0.00102692703
Iter: 1717 loss: 0.00102696021
Iter: 1718 loss: 0.00102686335
Iter: 1719 loss: 0.0010267999
Iter: 1720 loss: 0.00102679909
Iter: 1721 loss: 0.00102675182
Iter: 1722 loss: 0.00102707685
Iter: 1723 loss: 0.00102674693
Iter: 1724 loss: 0.00102670677
Iter: 1725 loss: 0.0010266829
Iter: 1726 loss: 0.00102666731
Iter: 1727 loss: 0.00102661375
Iter: 1728 loss: 0.00102671585
Iter: 1729 loss: 0.00102659315
Iter: 1730 loss: 0.00102652202
Iter: 1731 loss: 0.00102668302
Iter: 1732 loss: 0.00102649594
Iter: 1733 loss: 0.00102643459
Iter: 1734 loss: 0.00102693483
Iter: 1735 loss: 0.00102642947
Iter: 1736 loss: 0.0010263857
Iter: 1737 loss: 0.0010265063
Iter: 1738 loss: 0.00102637126
Iter: 1739 loss: 0.00102632679
Iter: 1740 loss: 0.00102626788
Iter: 1741 loss: 0.00102626416
Iter: 1742 loss: 0.00102619082
Iter: 1743 loss: 0.00102629862
Iter: 1744 loss: 0.00102615473
Iter: 1745 loss: 0.00102605368
Iter: 1746 loss: 0.00102634286
Iter: 1747 loss: 0.00102602202
Iter: 1748 loss: 0.00102592958
Iter: 1749 loss: 0.0010260141
Iter: 1750 loss: 0.00102587696
Iter: 1751 loss: 0.0010258262
Iter: 1752 loss: 0.0010258141
Iter: 1753 loss: 0.00102577428
Iter: 1754 loss: 0.00102600607
Iter: 1755 loss: 0.00102576846
Iter: 1756 loss: 0.00102573505
Iter: 1757 loss: 0.00102571049
Iter: 1758 loss: 0.00102569885
Iter: 1759 loss: 0.00102564855
Iter: 1760 loss: 0.00102571701
Iter: 1761 loss: 0.00102562446
Iter: 1762 loss: 0.0010255496
Iter: 1763 loss: 0.00102580921
Iter: 1764 loss: 0.00102552818
Iter: 1765 loss: 0.00102546916
Iter: 1766 loss: 0.00102586718
Iter: 1767 loss: 0.00102546369
Iter: 1768 loss: 0.00102542085
Iter: 1769 loss: 0.00102555472
Iter: 1770 loss: 0.00102540688
Iter: 1771 loss: 0.00102536054
Iter: 1772 loss: 0.00102530757
Iter: 1773 loss: 0.00102530152
Iter: 1774 loss: 0.00102522981
Iter: 1775 loss: 0.00102537917
Iter: 1776 loss: 0.00102519954
Iter: 1777 loss: 0.00102510862
Iter: 1778 loss: 0.001025317
Iter: 1779 loss: 0.00102507626
Iter: 1780 loss: 0.00102499709
Iter: 1781 loss: 0.00102504715
Iter: 1782 loss: 0.00102494506
Iter: 1783 loss: 0.0010249035
Iter: 1784 loss: 0.00102489511
Iter: 1785 loss: 0.00102485868
Iter: 1786 loss: 0.00102511747
Iter: 1787 loss: 0.00102485414
Iter: 1788 loss: 0.00102482561
Iter: 1789 loss: 0.00102479593
Iter: 1790 loss: 0.00102478848
Iter: 1791 loss: 0.00102473935
Iter: 1792 loss: 0.00102482678
Iter: 1793 loss: 0.00102471723
Iter: 1794 loss: 0.00102465018
Iter: 1795 loss: 0.00102487754
Iter: 1796 loss: 0.00102463341
Iter: 1797 loss: 0.00102458056
Iter: 1798 loss: 0.00102496136
Iter: 1799 loss: 0.00102457567
Iter: 1800 loss: 0.00102453877
Iter: 1801 loss: 0.00102462689
Iter: 1802 loss: 0.00102452573
Iter: 1803 loss: 0.00102448976
Iter: 1804 loss: 0.00102445262
Iter: 1805 loss: 0.00102444261
Iter: 1806 loss: 0.0010243858
Iter: 1807 loss: 0.00102447369
Iter: 1808 loss: 0.00102435937
Iter: 1809 loss: 0.00102427974
Iter: 1810 loss: 0.00102453784
Iter: 1811 loss: 0.00102425797
Iter: 1812 loss: 0.00102419604
Iter: 1813 loss: 0.00102418428
Iter: 1814 loss: 0.00102414261
Iter: 1815 loss: 0.00102409697
Iter: 1816 loss: 0.00102409278
Iter: 1817 loss: 0.00102405646
Iter: 1818 loss: 0.00102428102
Iter: 1819 loss: 0.00102405297
Iter: 1820 loss: 0.00102402177
Iter: 1821 loss: 0.00102399476
Iter: 1822 loss: 0.00102398952
Iter: 1823 loss: 0.00102394191
Iter: 1824 loss: 0.00102399988
Iter: 1825 loss: 0.00102391699
Iter: 1826 loss: 0.0010238532
Iter: 1827 loss: 0.00102413422
Iter: 1828 loss: 0.00102383876
Iter: 1829 loss: 0.00102379313
Iter: 1830 loss: 0.00102415227
Iter: 1831 loss: 0.00102378847
Iter: 1832 loss: 0.00102375797
Iter: 1833 loss: 0.00102384191
Iter: 1834 loss: 0.00102374679
Iter: 1835 loss: 0.00102371327
Iter: 1836 loss: 0.00102367066
Iter: 1837 loss: 0.00102366682
Iter: 1838 loss: 0.00102361199
Iter: 1839 loss: 0.00102369918
Iter: 1840 loss: 0.00102358439
Iter: 1841 loss: 0.00102351245
Iter: 1842 loss: 0.00102370023
Iter: 1843 loss: 0.00102348637
Iter: 1844 loss: 0.00102341198
Iter: 1845 loss: 0.00102345098
Iter: 1846 loss: 0.00102336472
Iter: 1847 loss: 0.00102332025
Iter: 1848 loss: 0.0010233135
Iter: 1849 loss: 0.00102327694
Iter: 1850 loss: 0.00102352584
Iter: 1851 loss: 0.00102327275
Iter: 1852 loss: 0.001023244
Iter: 1853 loss: 0.00102320849
Iter: 1854 loss: 0.0010232036
Iter: 1855 loss: 0.00102315273
Iter: 1856 loss: 0.0010232958
Iter: 1857 loss: 0.00102313689
Iter: 1858 loss: 0.00102307799
Iter: 1859 loss: 0.00102331617
Iter: 1860 loss: 0.00102306856
Iter: 1861 loss: 0.00102302409
Iter: 1862 loss: 0.00102336006
Iter: 1863 loss: 0.00102302106
Iter: 1864 loss: 0.00102299324
Iter: 1865 loss: 0.00102303969
Iter: 1866 loss: 0.00102298
Iter: 1867 loss: 0.00102294341
Iter: 1868 loss: 0.00102290965
Iter: 1869 loss: 0.0010229
Iter: 1870 loss: 0.0010228469
Iter: 1871 loss: 0.00102287624
Iter: 1872 loss: 0.00102281012
Iter: 1873 loss: 0.00102272432
Iter: 1874 loss: 0.00102305482
Iter: 1875 loss: 0.00102270395
Iter: 1876 loss: 0.00102263584
Iter: 1877 loss: 0.00102263631
Iter: 1878 loss: 0.00102257868
Iter: 1879 loss: 0.00102253095
Iter: 1880 loss: 0.00102252746
Iter: 1881 loss: 0.00102248881
Iter: 1882 loss: 0.00102274516
Iter: 1883 loss: 0.00102248439
Iter: 1884 loss: 0.00102245202
Iter: 1885 loss: 0.00102243689
Iter: 1886 loss: 0.00102241966
Iter: 1887 loss: 0.00102237868
Iter: 1888 loss: 0.00102244469
Iter: 1889 loss: 0.00102235994
Iter: 1890 loss: 0.00102230627
Iter: 1891 loss: 0.00102251302
Iter: 1892 loss: 0.00102229021
Iter: 1893 loss: 0.00102225202
Iter: 1894 loss: 0.00102254935
Iter: 1895 loss: 0.00102224725
Iter: 1896 loss: 0.00102221803
Iter: 1897 loss: 0.00102227228
Iter: 1898 loss: 0.00102220441
Iter: 1899 loss: 0.00102216972
Iter: 1900 loss: 0.00102212816
Iter: 1901 loss: 0.00102212175
Iter: 1902 loss: 0.00102206052
Iter: 1903 loss: 0.00102215051
Iter: 1904 loss: 0.00102203328
Iter: 1905 loss: 0.0010219519
Iter: 1906 loss: 0.0010221902
Iter: 1907 loss: 0.00102192804
Iter: 1908 loss: 0.00102185667
Iter: 1909 loss: 0.00102191197
Iter: 1910 loss: 0.00102181488
Iter: 1911 loss: 0.00102177344
Iter: 1912 loss: 0.00102176797
Iter: 1913 loss: 0.0010217349
Iter: 1914 loss: 0.0010219859
Iter: 1915 loss: 0.00102173188
Iter: 1916 loss: 0.00102170929
Iter: 1917 loss: 0.00102168298
Iter: 1918 loss: 0.00102167868
Iter: 1919 loss: 0.00102164224
Iter: 1920 loss: 0.00102171325
Iter: 1921 loss: 0.00102162512
Iter: 1922 loss: 0.0010215803
Iter: 1923 loss: 0.00102170277
Iter: 1924 loss: 0.00102156424
Iter: 1925 loss: 0.00102152838
Iter: 1926 loss: 0.00102188671
Iter: 1927 loss: 0.00102152664
Iter: 1928 loss: 0.00102150068
Iter: 1929 loss: 0.00102153886
Iter: 1930 loss: 0.00102148624
Iter: 1931 loss: 0.0010214526
Iter: 1932 loss: 0.00102142314
Iter: 1933 loss: 0.00102141453
Iter: 1934 loss: 0.00102136564
Iter: 1935 loss: 0.0010213824
Iter: 1936 loss: 0.00102133374
Iter: 1937 loss: 0.00102125912
Iter: 1938 loss: 0.00102158741
Iter: 1939 loss: 0.00102124386
Iter: 1940 loss: 0.0010211902
Iter: 1941 loss: 0.00102124526
Iter: 1942 loss: 0.00102115923
Iter: 1943 loss: 0.00102113083
Iter: 1944 loss: 0.00102112698
Iter: 1945 loss: 0.00102110323
Iter: 1946 loss: 0.00102126074
Iter: 1947 loss: 0.00102110044
Iter: 1948 loss: 0.00102107914
Iter: 1949 loss: 0.00102107099
Iter: 1950 loss: 0.00102105935
Iter: 1951 loss: 0.00102103071
Iter: 1952 loss: 0.00102109858
Iter: 1953 loss: 0.00102102174
Iter: 1954 loss: 0.00102098635
Iter: 1955 loss: 0.00102111476
Iter: 1956 loss: 0.00102097844
Iter: 1957 loss: 0.00102095399
Iter: 1958 loss: 0.00102110428
Iter: 1959 loss: 0.00102094992
Iter: 1960 loss: 0.00102092978
Iter: 1961 loss: 0.00102097203
Iter: 1962 loss: 0.00102092186
Iter: 1963 loss: 0.0010208959
Iter: 1964 loss: 0.00102087518
Iter: 1965 loss: 0.00102086854
Iter: 1966 loss: 0.00102083082
Iter: 1967 loss: 0.00102087343
Iter: 1968 loss: 0.00102080987
Iter: 1969 loss: 0.00102076295
Iter: 1970 loss: 0.00102092721
Iter: 1971 loss: 0.00102075213
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3
+ date
Tue Oct 27 17:25:28 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 0 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3be051c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3be0534840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3be04cf1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3be0445950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3be0445488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3be0449950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb820a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb81c8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb81ebea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb81937b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb8193b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb8161d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb812df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb812d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb8138d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb80f1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb808ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb80ca268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb8151158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3bb808a268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0227f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0227268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba02271e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0231158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0191730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0199a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0166ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0166d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba012a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba00c5268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba012a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba012a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba00988c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba00c5158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0077378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ba0025f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0406236574
Iter: 2 loss: 1.97856688
Iter: 3 loss: 1.93251622
Iter: 4 loss: 1.28110588
Iter: 5 loss: 1.24706578
Iter: 6 loss: 0.838569045
Iter: 7 loss: 0.807976604
Iter: 8 loss: 0.530200839
Iter: 9 loss: 0.498329192
Iter: 10 loss: 0.301006198
Iter: 11 loss: 0.267276824
Iter: 12 loss: 0.139031
Iter: 13 loss: 0.11265555
Iter: 14 loss: 0.0493588224
Iter: 15 loss: 0.038740173
Iter: 16 loss: 0.03050033
Iter: 17 loss: 0.0191563126
Iter: 18 loss: 0.018478509
Iter: 19 loss: 0.936310887
Iter: 20 loss: 0.0184292011
Iter: 21 loss: 0.0211259462
Iter: 22 loss: 0.0154179893
Iter: 23 loss: 0.0135800978
Iter: 24 loss: 0.0124123646
Iter: 25 loss: 0.0101850564
Iter: 26 loss: 0.0101779271
Iter: 27 loss: 0.00806128699
Iter: 28 loss: 0.00905002188
Iter: 29 loss: 0.00700814277
Iter: 30 loss: 0.00647948449
Iter: 31 loss: 0.00661998801
Iter: 32 loss: 0.00605633948
Iter: 33 loss: 0.00563415233
Iter: 34 loss: 0.00607342832
Iter: 35 loss: 0.00543057267
Iter: 36 loss: 0.00499297911
Iter: 37 loss: 0.00512720086
Iter: 38 loss: 0.0047077043
Iter: 39 loss: 0.00400222465
Iter: 40 loss: 0.00530520082
Iter: 41 loss: 0.00364668644
Iter: 42 loss: 0.00317218713
Iter: 43 loss: 0.00324630272
Iter: 44 loss: 0.00282755867
Iter: 45 loss: 0.00256802351
Iter: 46 loss: 0.0025116012
Iter: 47 loss: 0.00234167604
Iter: 48 loss: 0.00291152345
Iter: 49 loss: 0.00229631271
Iter: 50 loss: 0.00220285635
Iter: 51 loss: 0.0022160809
Iter: 52 loss: 0.00213236222
Iter: 53 loss: 0.00203857059
Iter: 54 loss: 0.00234267861
Iter: 55 loss: 0.00201396085
Iter: 56 loss: 0.0019312076
Iter: 57 loss: 0.0019586687
Iter: 58 loss: 0.00187594304
Iter: 59 loss: 0.00179959438
Iter: 60 loss: 0.0018279592
Iter: 61 loss: 0.00174663006
Iter: 62 loss: 0.00171834254
Iter: 63 loss: 0.00170668017
Iter: 64 loss: 0.00166871189
Iter: 65 loss: 0.00167312776
Iter: 66 loss: 0.00164037175
Iter: 67 loss: 0.0015944331
Iter: 68 loss: 0.0016000215
Iter: 69 loss: 0.0015595092
Iter: 70 loss: 0.00151653471
Iter: 71 loss: 0.00155714375
Iter: 72 loss: 0.00149244454
Iter: 73 loss: 0.001442248
Iter: 74 loss: 0.001595421
Iter: 75 loss: 0.00142727687
Iter: 76 loss: 0.00138443406
Iter: 77 loss: 0.00149610778
Iter: 78 loss: 0.00137091801
Iter: 79 loss: 0.00133278384
Iter: 80 loss: 0.00177034072
Iter: 81 loss: 0.00133203086
Iter: 82 loss: 0.0013058472
Iter: 83 loss: 0.00136622507
Iter: 84 loss: 0.00129654328
Iter: 85 loss: 0.00126874098
Iter: 86 loss: 0.00137306435
Iter: 87 loss: 0.00126216887
Iter: 88 loss: 0.00124324171
Iter: 89 loss: 0.00124363357
Iter: 90 loss: 0.00122829573
Iter: 91 loss: 0.00120719266
Iter: 92 loss: 0.00140094943
Iter: 93 loss: 0.00120637659
Iter: 94 loss: 0.00119385822
Iter: 95 loss: 0.00120697101
Iter: 96 loss: 0.0011869045
Iter: 97 loss: 0.00119850668
Iter: 98 loss: 0.00118192786
Iter: 99 loss: 0.00117826788
Iter: 100 loss: 0.0011703074
Iter: 101 loss: 0.0012876176
Iter: 102 loss: 0.00116997946
Iter: 103 loss: 0.00116056681
Iter: 104 loss: 0.00117913284
Iter: 105 loss: 0.00115669484
Iter: 106 loss: 0.00115028548
Iter: 107 loss: 0.00122349779
Iter: 108 loss: 0.00115016906
Iter: 109 loss: 0.00114315329
Iter: 110 loss: 0.00114796963
Iter: 111 loss: 0.0011387656
Iter: 112 loss: 0.00113295298
Iter: 113 loss: 0.00116156985
Iter: 114 loss: 0.00113195274
Iter: 115 loss: 0.00112695014
Iter: 116 loss: 0.00114100368
Iter: 117 loss: 0.00112536829
Iter: 118 loss: 0.00112170214
Iter: 119 loss: 0.0011434335
Iter: 120 loss: 0.00112121087
Iter: 121 loss: 0.0011188623
Iter: 122 loss: 0.00111488171
Iter: 123 loss: 0.0011148745
Iter: 124 loss: 0.00111192942
Iter: 125 loss: 0.00113140838
Iter: 126 loss: 0.00111162837
Iter: 127 loss: 0.00110979145
Iter: 128 loss: 0.00110959134
Iter: 129 loss: 0.0011082585
Iter: 130 loss: 0.00110991206
Iter: 131 loss: 0.00110756117
Iter: 132 loss: 0.00110699062
Iter: 133 loss: 0.00110648712
Iter: 134 loss: 0.00110633764
Iter: 135 loss: 0.00110539701
Iter: 136 loss: 0.00110565883
Iter: 137 loss: 0.00110471703
Iter: 138 loss: 0.00110360864
Iter: 139 loss: 0.00110317278
Iter: 140 loss: 0.00110257673
Iter: 141 loss: 0.00110108836
Iter: 142 loss: 0.00111868954
Iter: 143 loss: 0.00110106776
Iter: 144 loss: 0.00110001094
Iter: 145 loss: 0.00110076834
Iter: 146 loss: 0.00109935505
Iter: 147 loss: 0.00109844294
Iter: 148 loss: 0.00109920953
Iter: 149 loss: 0.00109790452
Iter: 150 loss: 0.00109716807
Iter: 151 loss: 0.00110099046
Iter: 152 loss: 0.0010970491
Iter: 153 loss: 0.00109658064
Iter: 154 loss: 0.00109632686
Iter: 155 loss: 0.00109611603
Iter: 156 loss: 0.00109545782
Iter: 157 loss: 0.00109711115
Iter: 158 loss: 0.00109522766
Iter: 159 loss: 0.00109460775
Iter: 160 loss: 0.00109643373
Iter: 161 loss: 0.001094418
Iter: 162 loss: 0.00109394756
Iter: 163 loss: 0.00109878054
Iter: 164 loss: 0.00109393219
Iter: 165 loss: 0.00109344407
Iter: 166 loss: 0.00109613047
Iter: 167 loss: 0.00109337503
Iter: 168 loss: 0.00109310925
Iter: 169 loss: 0.00109271647
Iter: 170 loss: 0.00109270716
Iter: 171 loss: 0.00109214592
Iter: 172 loss: 0.00109165988
Iter: 173 loss: 0.00109150819
Iter: 174 loss: 0.00109071832
Iter: 175 loss: 0.00109695108
Iter: 176 loss: 0.00109066349
Iter: 177 loss: 0.00109002774
Iter: 178 loss: 0.00109163951
Iter: 179 loss: 0.00108980783
Iter: 180 loss: 0.00108935614
Iter: 181 loss: 0.00109382509
Iter: 182 loss: 0.00108934147
Iter: 183 loss: 0.00108900957
Iter: 184 loss: 0.00108907314
Iter: 185 loss: 0.00108876452
Iter: 186 loss: 0.00108855066
Iter: 187 loss: 0.00108852284
Iter: 188 loss: 0.00108834682
Iter: 189 loss: 0.00108793797
Iter: 190 loss: 0.0010929578
Iter: 191 loss: 0.00108790735
Iter: 192 loss: 0.00108756125
Iter: 193 loss: 0.0010875595
Iter: 194 loss: 0.00108736765
Iter: 195 loss: 0.00108761096
Iter: 196 loss: 0.00108726858
Iter: 197 loss: 0.00108714635
Iter: 198 loss: 0.00108714006
Iter: 199 loss: 0.00108707033
Iter: 200 loss: 0.00108688883
Iter: 201 loss: 0.00108833448
Iter: 202 loss: 0.00108685542
Iter: 203 loss: 0.00108662143
Iter: 204 loss: 0.00108664832
Iter: 205 loss: 0.00108644133
Iter: 206 loss: 0.00108622713
Iter: 207 loss: 0.00108726195
Iter: 208 loss: 0.00108619011
Iter: 209 loss: 0.00108596624
Iter: 210 loss: 0.00108687975
Iter: 211 loss: 0.00108591747
Iter: 212 loss: 0.00108568161
Iter: 213 loss: 0.00108545448
Iter: 214 loss: 0.00108540209
Iter: 215 loss: 0.00108509976
Iter: 216 loss: 0.00108925579
Iter: 217 loss: 0.00108510023
Iter: 218 loss: 0.00108489208
Iter: 219 loss: 0.0010869141
Iter: 220 loss: 0.00108488381
Iter: 221 loss: 0.00108469243
Iter: 222 loss: 0.0010848277
Iter: 223 loss: 0.00108457438
Iter: 224 loss: 0.00108438928
Iter: 225 loss: 0.00108447194
Iter: 226 loss: 0.00108426274
Iter: 227 loss: 0.0010840405
Iter: 228 loss: 0.00108437659
Iter: 229 loss: 0.0010839334
Iter: 230 loss: 0.00108395517
Iter: 231 loss: 0.00108384807
Iter: 232 loss: 0.00108375563
Iter: 233 loss: 0.00108348881
Iter: 234 loss: 0.00108474609
Iter: 235 loss: 0.00108339428
Iter: 236 loss: 0.00108318194
Iter: 237 loss: 0.00108427461
Iter: 238 loss: 0.00108314748
Iter: 239 loss: 0.00108293
Iter: 240 loss: 0.00108280499
Iter: 241 loss: 0.00108271162
Iter: 242 loss: 0.00108240067
Iter: 243 loss: 0.00108409941
Iter: 244 loss: 0.00108235597
Iter: 245 loss: 0.00108206621
Iter: 246 loss: 0.00108209916
Iter: 247 loss: 0.00108184351
Iter: 248 loss: 0.00108158006
Iter: 249 loss: 0.00108564564
Iter: 250 loss: 0.00108158053
Iter: 251 loss: 0.0010814101
Iter: 252 loss: 0.00108161138
Iter: 253 loss: 0.00108132092
Iter: 254 loss: 0.00108123058
Iter: 255 loss: 0.00108120544
Iter: 256 loss: 0.00108112069
Iter: 257 loss: 0.00108098215
Iter: 258 loss: 0.00108098076
Iter: 259 loss: 0.00108086574
Iter: 260 loss: 0.00108083244
Iter: 261 loss: 0.00108076283
Iter: 262 loss: 0.0010806733
Iter: 263 loss: 0.00108127214
Iter: 264 loss: 0.00108066259
Iter: 265 loss: 0.00108058029
Iter: 266 loss: 0.00108053023
Iter: 267 loss: 0.00108049414
Iter: 268 loss: 0.00108035165
Iter: 269 loss: 0.00108041137
Iter: 270 loss: 0.00108025479
Iter: 271 loss: 0.00108010671
Iter: 272 loss: 0.00108056446
Iter: 273 loss: 0.00108006364
Iter: 274 loss: 0.00107992801
Iter: 275 loss: 0.00108002138
Iter: 276 loss: 0.00107984524
Iter: 277 loss: 0.00107965991
Iter: 278 loss: 0.00107997947
Iter: 279 loss: 0.00107957819
Iter: 280 loss: 0.00107941544
Iter: 281 loss: 0.00108128379
Iter: 282 loss: 0.00107941264
Iter: 283 loss: 0.00107928552
Iter: 284 loss: 0.00107959495
Iter: 285 loss: 0.00107924046
Iter: 286 loss: 0.00107913627
Iter: 287 loss: 0.00108015514
Iter: 288 loss: 0.00107913255
Iter: 289 loss: 0.00107904617
Iter: 290 loss: 0.00107947818
Iter: 291 loss: 0.00107903115
Iter: 292 loss: 0.00107896212
Iter: 293 loss: 0.00107905106
Iter: 294 loss: 0.0010789251
Iter: 295 loss: 0.00107885699
Iter: 296 loss: 0.00107930857
Iter: 297 loss: 0.00107885012
Iter: 298 loss: 0.00107878726
Iter: 299 loss: 0.00107875932
Iter: 300 loss: 0.00107872719
Iter: 301 loss: 0.00107863441
Iter: 302 loss: 0.00107869296
Iter: 303 loss: 0.0010785762
Iter: 304 loss: 0.00107847364
Iter: 305 loss: 0.00107869366
Iter: 306 loss: 0.00107843382
Iter: 307 loss: 0.00107831741
Iter: 308 loss: 0.00107830681
Iter: 309 loss: 0.00107822148
Iter: 310 loss: 0.00107806164
Iter: 311 loss: 0.00107864547
Iter: 312 loss: 0.00107802241
Iter: 313 loss: 0.00107786688
Iter: 314 loss: 0.00107856
Iter: 315 loss: 0.00107783545
Iter: 316 loss: 0.00107770413
Iter: 317 loss: 0.00107820577
Iter: 318 loss: 0.00107767247
Iter: 319 loss: 0.00107756234
Iter: 320 loss: 0.00107841543
Iter: 321 loss: 0.00107755396
Iter: 322 loss: 0.00107746944
Iter: 323 loss: 0.00107814954
Iter: 324 loss: 0.00107746385
Iter: 325 loss: 0.0010774
Iter: 326 loss: 0.00107748271
Iter: 327 loss: 0.00107736676
Iter: 328 loss: 0.00107730646
Iter: 329 loss: 0.00107770029
Iter: 330 loss: 0.00107730157
Iter: 331 loss: 0.00107724848
Iter: 332 loss: 0.00107727514
Iter: 333 loss: 0.00107721356
Iter: 334 loss: 0.00107715628
Iter: 335 loss: 0.00107715477
Iter: 336 loss: 0.00107710971
Iter: 337 loss: 0.00107702217
Iter: 338 loss: 0.00107707502
Iter: 339 loss: 0.00107696513
Iter: 340 loss: 0.00107686571
Iter: 341 loss: 0.00107714487
Iter: 342 loss: 0.00107683509
Iter: 343 loss: 0.00107674417
Iter: 344 loss: 0.00107693253
Iter: 345 loss: 0.00107670762
Iter: 346 loss: 0.00107661146
Iter: 347 loss: 0.00107705849
Iter: 348 loss: 0.00107659318
Iter: 349 loss: 0.00107650377
Iter: 350 loss: 0.0010766827
Iter: 351 loss: 0.0010764692
Iter: 352 loss: 0.00107638806
Iter: 353 loss: 0.00107710203
Iter: 354 loss: 0.00107638608
Iter: 355 loss: 0.00107632182
Iter: 356 loss: 0.00107684685
Iter: 357 loss: 0.00107631856
Iter: 358 loss: 0.00107627257
Iter: 359 loss: 0.00107640144
Iter: 360 loss: 0.00107625709
Iter: 361 loss: 0.00107622112
Iter: 362 loss: 0.00107634254
Iter: 363 loss: 0.00107621215
Iter: 364 loss: 0.00107617141
Iter: 365 loss: 0.001076199
Iter: 366 loss: 0.00107614638
Iter: 367 loss: 0.00107609783
Iter: 368 loss: 0.00107608817
Iter: 369 loss: 0.00107605616
Iter: 370 loss: 0.00107598724
Iter: 371 loss: 0.00107608712
Iter: 372 loss: 0.00107595464
Iter: 373 loss: 0.00107587571
Iter: 374 loss: 0.00107593788
Iter: 375 loss: 0.00107582705
Iter: 376 loss: 0.00107573916
Iter: 377 loss: 0.00107617024
Iter: 378 loss: 0.00107572274
Iter: 379 loss: 0.0010756508
Iter: 380 loss: 0.00107576873
Iter: 381 loss: 0.00107561762
Iter: 382 loss: 0.00107552973
Iter: 383 loss: 0.00107583648
Iter: 384 loss: 0.00107550772
Iter: 385 loss: 0.0010754317
Iter: 386 loss: 0.00107589143
Iter: 387 loss: 0.00107542169
Iter: 388 loss: 0.00107536814
Iter: 389 loss: 0.00107608852
Iter: 390 loss: 0.00107536861
Iter: 391 loss: 0.0010753267
Iter: 392 loss: 0.00107538886
Iter: 393 loss: 0.00107530702
Iter: 394 loss: 0.00107526127
Iter: 395 loss: 0.00107537291
Iter: 396 loss: 0.00107524544
Iter: 397 loss: 0.00107519072
Iter: 398 loss: 0.00107528071
Iter: 399 loss: 0.00107516593
Iter: 400 loss: 0.00107511028
Iter: 401 loss: 0.00107509713
Iter: 402 loss: 0.0010750622
Iter: 403 loss: 0.00107498956
Iter: 404 loss: 0.00107508653
Iter: 405 loss: 0.00107495394
Iter: 406 loss: 0.00107486255
Iter: 407 loss: 0.00107498909
Iter: 408 loss: 0.00107481843
Iter: 409 loss: 0.00107472856
Iter: 410 loss: 0.0010749636
Iter: 411 loss: 0.00107469666
Iter: 412 loss: 0.00107460143
Iter: 413 loss: 0.00107476721
Iter: 414 loss: 0.00107456022
Iter: 415 loss: 0.00107445242
Iter: 416 loss: 0.00107486825
Iter: 417 loss: 0.00107442774
Iter: 418 loss: 0.00107432646
Iter: 419 loss: 0.00107483321
Iter: 420 loss: 0.00107431109
Iter: 421 loss: 0.00107424858
Iter: 422 loss: 0.00107424974
Iter: 423 loss: 0.00107420329
Iter: 424 loss: 0.00107429409
Iter: 425 loss: 0.00107418327
Iter: 426 loss: 0.00107413798
Iter: 427 loss: 0.00107421586
Iter: 428 loss: 0.00107411563
Iter: 429 loss: 0.00107405661
Iter: 430 loss: 0.00107420399
Iter: 431 loss: 0.00107403495
Iter: 432 loss: 0.0010739771
Iter: 433 loss: 0.00107394694
Iter: 434 loss: 0.00107392203
Iter: 435 loss: 0.00107384135
Iter: 436 loss: 0.00107397081
Iter: 437 loss: 0.00107380259
Iter: 438 loss: 0.00107371155
Iter: 439 loss: 0.00107391318
Iter: 440 loss: 0.00107367733
Iter: 441 loss: 0.00107359118
Iter: 442 loss: 0.00107370829
Iter: 443 loss: 0.00107354787
Iter: 444 loss: 0.00107344589
Iter: 445 loss: 0.0010736963
Iter: 446 loss: 0.00107341085
Iter: 447 loss: 0.00107330957
Iter: 448 loss: 0.00107373472
Iter: 449 loss: 0.00107328768
Iter: 450 loss: 0.00107319793
Iter: 451 loss: 0.00107364124
Iter: 452 loss: 0.0010731814
Iter: 453 loss: 0.00107312389
Iter: 454 loss: 0.00107406743
Iter: 455 loss: 0.00107312365
Iter: 456 loss: 0.00107307662
Iter: 457 loss: 0.00107319665
Iter: 458 loss: 0.00107306044
Iter: 459 loss: 0.00107301865
Iter: 460 loss: 0.00107310223
Iter: 461 loss: 0.0010730013
Iter: 462 loss: 0.00107295415
Iter: 463 loss: 0.00107308768
Iter: 464 loss: 0.00107293949
Iter: 465 loss: 0.00107289164
Iter: 466 loss: 0.00107283657
Iter: 467 loss: 0.00107283029
Iter: 468 loss: 0.00107274158
Iter: 469 loss: 0.00107288174
Iter: 470 loss: 0.00107269932
Iter: 471 loss: 0.001072607
Iter: 472 loss: 0.00107291911
Iter: 473 loss: 0.00107258302
Iter: 474 loss: 0.00107249781
Iter: 475 loss: 0.00107250374
Iter: 476 loss: 0.00107243052
Iter: 477 loss: 0.00107230665
Iter: 478 loss: 0.00107274309
Iter: 479 loss: 0.0010722744
Iter: 480 loss: 0.00107217068
Iter: 481 loss: 0.00107261573
Iter: 482 loss: 0.00107215019
Iter: 483 loss: 0.00107205915
Iter: 484 loss: 0.00107255555
Iter: 485 loss: 0.00107204553
Iter: 486 loss: 0.00107198441
Iter: 487 loss: 0.00107280852
Iter: 488 loss: 0.00107198406
Iter: 489 loss: 0.00107193377
Iter: 490 loss: 0.00107208313
Iter: 491 loss: 0.00107191922
Iter: 492 loss: 0.00107187405
Iter: 493 loss: 0.00107193855
Iter: 494 loss: 0.00107185263
Iter: 495 loss: 0.00107179908
Iter: 496 loss: 0.00107195531
Iter: 497 loss: 0.00107178104
Iter: 498 loss: 0.0010717262
Iter: 499 loss: 0.00107166707
Iter: 500 loss: 0.0010716581
Iter: 501 loss: 0.00107155798
Iter: 502 loss: 0.00107171375
Iter: 503 loss: 0.00107151223
Iter: 504 loss: 0.00107141
Iter: 505 loss: 0.00107174111
Iter: 506 loss: 0.00107137929
Iter: 507 loss: 0.00107128709
Iter: 508 loss: 0.00107141887
Iter: 509 loss: 0.00107124238
Iter: 510 loss: 0.00107114203
Iter: 511 loss: 0.00107138115
Iter: 512 loss: 0.00107110501
Iter: 513 loss: 0.00107100187
Iter: 514 loss: 0.00107136369
Iter: 515 loss: 0.00107097486
Iter: 516 loss: 0.00107089151
Iter: 517 loss: 0.0010715368
Iter: 518 loss: 0.0010708865
Iter: 519 loss: 0.00107083085
Iter: 520 loss: 0.00107141712
Iter: 521 loss: 0.00107082876
Iter: 522 loss: 0.00107078033
Iter: 523 loss: 0.00107093528
Iter: 524 loss: 0.00107076694
Iter: 525 loss: 0.00107072189
Iter: 526 loss: 0.00107079465
Iter: 527 loss: 0.00107070187
Iter: 528 loss: 0.00107065088
Iter: 529 loss: 0.00107081956
Iter: 530 loss: 0.00107063749
Iter: 531 loss: 0.00107058836
Iter: 532 loss: 0.0010705539
Iter: 533 loss: 0.00107053632
Iter: 534 loss: 0.0010704645
Iter: 535 loss: 0.00107056717
Iter: 536 loss: 0.00107042911
Iter: 537 loss: 0.00107035181
Iter: 538 loss: 0.00107056438
Iter: 539 loss: 0.0010703255
Iter: 540 loss: 0.00107024866
Iter: 541 loss: 0.001070356
Iter: 542 loss: 0.00107021199
Iter: 543 loss: 0.00107012631
Iter: 544 loss: 0.00107028149
Iter: 545 loss: 0.00107008847
Iter: 546 loss: 0.0010699894
Iter: 547 loss: 0.00107024703
Iter: 548 loss: 0.00106995553
Iter: 549 loss: 0.00106986833
Iter: 550 loss: 0.00107060838
Iter: 551 loss: 0.00106986426
Iter: 552 loss: 0.00106980745
Iter: 553 loss: 0.00107039278
Iter: 554 loss: 0.00106980628
Iter: 555 loss: 0.00106975879
Iter: 556 loss: 0.00106993061
Iter: 557 loss: 0.00106974645
Iter: 558 loss: 0.00106970384
Iter: 559 loss: 0.00106976519
Iter: 560 loss: 0.00106968381
Iter: 561 loss: 0.00106963527
Iter: 562 loss: 0.00106981653
Iter: 563 loss: 0.00106962328
Iter: 564 loss: 0.00106957823
Iter: 565 loss: 0.00106955203
Iter: 566 loss: 0.00106953341
Iter: 567 loss: 0.00106946961
Iter: 568 loss: 0.00106953178
Iter: 569 loss: 0.00106943317
Iter: 570 loss: 0.00106935774
Iter: 571 loss: 0.00106953
Iter: 572 loss: 0.00106932921
Iter: 573 loss: 0.00106924854
Iter: 574 loss: 0.00106936228
Iter: 575 loss: 0.00106920872
Iter: 576 loss: 0.00106911408
Iter: 577 loss: 0.0010692568
Iter: 578 loss: 0.00106906868
Iter: 579 loss: 0.00106895866
Iter: 580 loss: 0.00106930884
Iter: 581 loss: 0.0010689277
Iter: 582 loss: 0.00106883468
Iter: 583 loss: 0.00106944633
Iter: 584 loss: 0.00106882537
Iter: 585 loss: 0.00106876006
Iter: 586 loss: 0.00106948195
Iter: 587 loss: 0.00106875808
Iter: 588 loss: 0.00106870383
Iter: 589 loss: 0.00106897228
Iter: 590 loss: 0.00106869487
Iter: 591 loss: 0.00106865237
Iter: 592 loss: 0.00106872
Iter: 593 loss: 0.00106863258
Iter: 594 loss: 0.00106858579
Iter: 595 loss: 0.00106874551
Iter: 596 loss: 0.00106857438
Iter: 597 loss: 0.00106852781
Iter: 598 loss: 0.00106849626
Iter: 599 loss: 0.00106847938
Iter: 600 loss: 0.00106841116
Iter: 601 loss: 0.0010684696
Iter: 602 loss: 0.00106837065
Iter: 603 loss: 0.00106829009
Iter: 604 loss: 0.00106848904
Iter: 605 loss: 0.00106826215
Iter: 606 loss: 0.00106817647
Iter: 607 loss: 0.00106829277
Iter: 608 loss: 0.00106813386
Iter: 609 loss: 0.00106803724
Iter: 610 loss: 0.00106822292
Iter: 611 loss: 0.00106799626
Iter: 612 loss: 0.00106789498
Iter: 613 loss: 0.00106821582
Iter: 614 loss: 0.00106786564
Iter: 615 loss: 0.00106777786
Iter: 616 loss: 0.00106831128
Iter: 617 loss: 0.00106776808
Iter: 618 loss: 0.00106770347
Iter: 619 loss: 0.00106835575
Iter: 620 loss: 0.00106770126
Iter: 621 loss: 0.00106764829
Iter: 622 loss: 0.00106794573
Iter: 623 loss: 0.00106764049
Iter: 624 loss: 0.00106759951
Iter: 625 loss: 0.00106764864
Iter: 626 loss: 0.00106757856
Iter: 627 loss: 0.0010675313
Iter: 628 loss: 0.00106771162
Iter: 629 loss: 0.00106751919
Iter: 630 loss: 0.0010674732
Iter: 631 loss: 0.00106745295
Iter: 632 loss: 0.00106742908
Iter: 633 loss: 0.00106736273
Iter: 634 loss: 0.00106739579
Iter: 635 loss: 0.00106732012
Iter: 636 loss: 0.00106723839
Iter: 637 loss: 0.00106743153
Iter: 638 loss: 0.00106720813
Iter: 639 loss: 0.00106712442
Iter: 640 loss: 0.00106729893
Iter: 641 loss: 0.00106709125
Iter: 642 loss: 0.00106700149
Iter: 643 loss: 0.00106710813
Iter: 644 loss: 0.0010669562
Iter: 645 loss: 0.00106685224
Iter: 646 loss: 0.00106722594
Iter: 647 loss: 0.00106682663
Iter: 648 loss: 0.00106674293
Iter: 649 loss: 0.00106718368
Iter: 650 loss: 0.00106672826
Iter: 651 loss: 0.00106666144
Iter: 652 loss: 0.00106727146
Iter: 653 loss: 0.00106665853
Iter: 654 loss: 0.0010666
Iter: 655 loss: 0.00106695481
Iter: 656 loss: 0.00106659229
Iter: 657 loss: 0.00106654828
Iter: 658 loss: 0.0010666016
Iter: 659 loss: 0.00106652454
Iter: 660 loss: 0.00106647541
Iter: 661 loss: 0.00106666679
Iter: 662 loss: 0.00106646435
Iter: 663 loss: 0.00106641557
Iter: 664 loss: 0.00106640707
Iter: 665 loss: 0.00106637389
Iter: 666 loss: 0.00106631173
Iter: 667 loss: 0.00106633734
Iter: 668 loss: 0.00106626842
Iter: 669 loss: 0.00106618856
Iter: 670 loss: 0.00106636854
Iter: 671 loss: 0.00106615829
Iter: 672 loss: 0.0010660775
Iter: 673 loss: 0.00106626609
Iter: 674 loss: 0.0010660477
Iter: 675 loss: 0.00106596458
Iter: 676 loss: 0.00106607738
Iter: 677 loss: 0.00106592488
Iter: 678 loss: 0.00106583233
Iter: 679 loss: 0.00106613024
Iter: 680 loss: 0.00106580555
Iter: 681 loss: 0.0010657243
Iter: 682 loss: 0.00106612244
Iter: 683 loss: 0.00106571
Iter: 684 loss: 0.00106564537
Iter: 685 loss: 0.00106627936
Iter: 686 loss: 0.00106564257
Iter: 687 loss: 0.00106559193
Iter: 688 loss: 0.00106600439
Iter: 689 loss: 0.00106558879
Iter: 690 loss: 0.00106555223
Iter: 691 loss: 0.00106558343
Iter: 692 loss: 0.00106553198
Iter: 693 loss: 0.00106548821
Iter: 694 loss: 0.00106564281
Iter: 695 loss: 0.0010654775
Iter: 696 loss: 0.00106543489
Iter: 697 loss: 0.00106543605
Iter: 698 loss: 0.00106540113
Iter: 699 loss: 0.00106534944
Iter: 700 loss: 0.00106536748
Iter: 701 loss: 0.00106531265
Iter: 702 loss: 0.00106524758
Iter: 703 loss: 0.00106538576
Iter: 704 loss: 0.00106522
Iter: 705 loss: 0.00106514641
Iter: 706 loss: 0.00106529566
Iter: 707 loss: 0.00106511835
Iter: 708 loss: 0.0010650428
Iter: 709 loss: 0.00106516329
Iter: 710 loss: 0.00106500904
Iter: 711 loss: 0.00106493244
Iter: 712 loss: 0.0010652279
Iter: 713 loss: 0.0010649137
Iter: 714 loss: 0.00106484652
Iter: 715 loss: 0.00106506213
Iter: 716 loss: 0.00106482639
Iter: 717 loss: 0.00106476538
Iter: 718 loss: 0.00106544048
Iter: 719 loss: 0.00106476387
Iter: 720 loss: 0.00106472033
Iter: 721 loss: 0.00106514036
Iter: 722 loss: 0.00106471905
Iter: 723 loss: 0.00106469053
Iter: 724 loss: 0.00106471661
Iter: 725 loss: 0.001064674
Iter: 726 loss: 0.00106463989
Iter: 727 loss: 0.0010647506
Iter: 728 loss: 0.00106463046
Iter: 729 loss: 0.00106459577
Iter: 730 loss: 0.0010645939
Iter: 731 loss: 0.0010645669
Iter: 732 loss: 0.0010645201
Iter: 733 loss: 0.00106453407
Iter: 734 loss: 0.00106448552
Iter: 735 loss: 0.00106442673
Iter: 736 loss: 0.00106457481
Iter: 737 loss: 0.00106440659
Iter: 738 loss: 0.00106434582
Iter: 739 loss: 0.00106445374
Iter: 740 loss: 0.00106431963
Iter: 741 loss: 0.00106425327
Iter: 742 loss: 0.00106436829
Iter: 743 loss: 0.001064223
Iter: 744 loss: 0.00106415781
Iter: 745 loss: 0.00106441241
Iter: 746 loss: 0.00106414268
Iter: 747 loss: 0.00106408342
Iter: 748 loss: 0.0010642868
Iter: 749 loss: 0.00106406747
Iter: 750 loss: 0.00106401753
Iter: 751 loss: 0.0010645279
Iter: 752 loss: 0.0010640166
Iter: 753 loss: 0.00106398098
Iter: 754 loss: 0.00106435455
Iter: 755 loss: 0.00106398016
Iter: 756 loss: 0.00106395595
Iter: 757 loss: 0.00106397737
Iter: 758 loss: 0.00106394291
Iter: 759 loss: 0.00106391381
Iter: 760 loss: 0.00106401206
Iter: 761 loss: 0.00106390659
Iter: 762 loss: 0.00106387772
Iter: 763 loss: 0.00106388214
Iter: 764 loss: 0.00106385513
Iter: 765 loss: 0.00106381869
Iter: 766 loss: 0.00106381904
Iter: 767 loss: 0.00106378947
Iter: 768 loss: 0.00106373965
Iter: 769 loss: 0.00106385164
Iter: 770 loss: 0.00106372137
Iter: 771 loss: 0.00106366817
Iter: 772 loss: 0.001063801
Iter: 773 loss: 0.00106365012
Iter: 774 loss: 0.00106359972
Iter: 775 loss: 0.00106367713
Iter: 776 loss: 0.00106357527
Iter: 777 loss: 0.00106352055
Iter: 778 loss: 0.00106368819
Iter: 779 loss: 0.00106350542
Iter: 780 loss: 0.00106345408
Iter: 781 loss: 0.00106364244
Iter: 782 loss: 0.00106344069
Iter: 783 loss: 0.00106340135
Iter: 784 loss: 0.00106387306
Iter: 785 loss: 0.00106339972
Iter: 786 loss: 0.00106337154
Iter: 787 loss: 0.00106365234
Iter: 788 loss: 0.00106337096
Iter: 789 loss: 0.00106334942
Iter: 790 loss: 0.0010633606
Iter: 791 loss: 0.0010633372
Iter: 792 loss: 0.00106331159
Iter: 793 loss: 0.00106339832
Iter: 794 loss: 0.0010633053
Iter: 795 loss: 0.00106328097
Iter: 796 loss: 0.00106329704
Iter: 797 loss: 0.00106326479
Iter: 798 loss: 0.00106323673
Iter: 799 loss: 0.00106323918
Iter: 800 loss: 0.00106321461
Iter: 801 loss: 0.00106317608
Iter: 802 loss: 0.00106324349
Iter: 803 loss: 0.00106315757
Iter: 804 loss: 0.00106311589
Iter: 805 loss: 0.00106322835
Iter: 806 loss: 0.00106309983
Iter: 807 loss: 0.00106305815
Iter: 808 loss: 0.00106313988
Iter: 809 loss: 0.00106304162
Iter: 810 loss: 0.00106299808
Iter: 811 loss: 0.00106307282
Iter: 812 loss: 0.00106297736
Iter: 813 loss: 0.00106292649
Iter: 814 loss: 0.00106315291
Iter: 815 loss: 0.00106291682
Iter: 816 loss: 0.0010628812
Iter: 817 loss: 0.00106330914
Iter: 818 loss: 0.00106288027
Iter: 819 loss: 0.00106285489
Iter: 820 loss: 0.00106310192
Iter: 821 loss: 0.00106285536
Iter: 822 loss: 0.0010628365
Iter: 823 loss: 0.00106284511
Iter: 824 loss: 0.00106282486
Iter: 825 loss: 0.00106280099
Iter: 826 loss: 0.00106287922
Iter: 827 loss: 0.00106279552
Iter: 828 loss: 0.001062772
Iter: 829 loss: 0.00106278691
Iter: 830 loss: 0.00106275803
Iter: 831 loss: 0.00106273149
Iter: 832 loss: 0.00106272777
Iter: 833 loss: 0.00106271007
Iter: 834 loss: 0.00106267317
Iter: 835 loss: 0.00106273824
Iter: 836 loss: 0.00106265792
Iter: 837 loss: 0.00106261612
Iter: 838 loss: 0.00106272753
Iter: 839 loss: 0.00106260192
Iter: 840 loss: 0.00106256269
Iter: 841 loss: 0.00106262905
Iter: 842 loss: 0.00106254383
Iter: 843 loss: 0.00106250145
Iter: 844 loss: 0.00106258807
Iter: 845 loss: 0.00106248213
Iter: 846 loss: 0.0010624358
Iter: 847 loss: 0.00106259435
Iter: 848 loss: 0.00106242392
Iter: 849 loss: 0.00106238551
Iter: 850 loss: 0.00106285606
Iter: 851 loss: 0.00106238481
Iter: 852 loss: 0.00106236083
Iter: 853 loss: 0.00106263312
Iter: 854 loss: 0.00106236013
Iter: 855 loss: 0.00106234255
Iter: 856 loss: 0.0010623585
Iter: 857 loss: 0.00106233172
Iter: 858 loss: 0.0010623117
Iter: 859 loss: 0.00106238015
Iter: 860 loss: 0.00106230634
Iter: 861 loss: 0.00106228399
Iter: 862 loss: 0.00106229517
Iter: 863 loss: 0.00106227107
Iter: 864 loss: 0.00106224488
Iter: 865 loss: 0.00106223766
Iter: 866 loss: 0.00106222229
Iter: 867 loss: 0.00106218515
Iter: 868 loss: 0.00106227875
Iter: 869 loss: 0.0010621734
Iter: 870 loss: 0.00106213754
Iter: 871 loss: 0.00106223451
Iter: 872 loss: 0.00106212427
Iter: 873 loss: 0.00106208702
Iter: 874 loss: 0.0010621415
Iter: 875 loss: 0.0010620699
Iter: 876 loss: 0.00106202904
Iter: 877 loss: 0.00106210471
Iter: 878 loss: 0.00106201193
Iter: 879 loss: 0.00106196594
Iter: 880 loss: 0.00106215372
Iter: 881 loss: 0.00106195535
Iter: 882 loss: 0.00106192112
Iter: 883 loss: 0.00106229552
Iter: 884 loss: 0.00106192124
Iter: 885 loss: 0.0010618961
Iter: 886 loss: 0.00106216245
Iter: 887 loss: 0.00106189691
Iter: 888 loss: 0.0010618791
Iter: 889 loss: 0.00106189493
Iter: 890 loss: 0.00106186827
Iter: 891 loss: 0.00106184953
Iter: 892 loss: 0.00106191402
Iter: 893 loss: 0.00106184324
Iter: 894 loss: 0.00106182415
Iter: 895 loss: 0.00106183533
Iter: 896 loss: 0.00106181006
Iter: 897 loss: 0.00106178748
Iter: 898 loss: 0.00106177758
Iter: 899 loss: 0.00106176501
Iter: 900 loss: 0.00106173032
Iter: 901 loss: 0.00106181542
Iter: 902 loss: 0.00106171728
Iter: 903 loss: 0.00106168259
Iter: 904 loss: 0.00106179249
Iter: 905 loss: 0.00106167258
Iter: 906 loss: 0.00106163952
Iter: 907 loss: 0.00106167863
Iter: 908 loss: 0.00106162205
Iter: 909 loss: 0.00106158271
Iter: 910 loss: 0.00106164347
Iter: 911 loss: 0.00106156396
Iter: 912 loss: 0.00106151821
Iter: 913 loss: 0.00106170354
Iter: 914 loss: 0.00106150832
Iter: 915 loss: 0.0010614763
Iter: 916 loss: 0.00106187235
Iter: 917 loss: 0.00106147584
Iter: 918 loss: 0.00106145232
Iter: 919 loss: 0.00106169307
Iter: 920 loss: 0.00106145325
Iter: 921 loss: 0.00106143521
Iter: 922 loss: 0.00106145034
Iter: 923 loss: 0.00106142438
Iter: 924 loss: 0.00106140727
Iter: 925 loss: 0.00106147
Iter: 926 loss: 0.0010614018
Iter: 927 loss: 0.00106138154
Iter: 928 loss: 0.00106139854
Iter: 929 loss: 0.00106137013
Iter: 930 loss: 0.00106134976
Iter: 931 loss: 0.00106133695
Iter: 932 loss: 0.00106132776
Iter: 933 loss: 0.001061294
Iter: 934 loss: 0.00106136734
Iter: 935 loss: 0.00106128142
Iter: 936 loss: 0.00106124696
Iter: 937 loss: 0.00106135104
Iter: 938 loss: 0.0010612359
Iter: 939 loss: 0.00106120238
Iter: 940 loss: 0.00106125826
Iter: 941 loss: 0.00106118573
Iter: 942 loss: 0.00106114894
Iter: 943 loss: 0.00106119365
Iter: 944 loss: 0.00106112799
Iter: 945 loss: 0.00106108433
Iter: 946 loss: 0.00106127339
Iter: 947 loss: 0.00106107444
Iter: 948 loss: 0.00106104324
Iter: 949 loss: 0.00106141448
Iter: 950 loss: 0.00106104254
Iter: 951 loss: 0.0010610217
Iter: 952 loss: 0.00106129446
Iter: 953 loss: 0.00106102298
Iter: 954 loss: 0.00106100715
Iter: 955 loss: 0.00106102135
Iter: 956 loss: 0.00106099946
Iter: 957 loss: 0.00106098375
Iter: 958 loss: 0.00106103648
Iter: 959 loss: 0.00106097898
Iter: 960 loss: 0.00106096244
Iter: 961 loss: 0.00106097246
Iter: 962 loss: 0.0010609529
Iter: 963 loss: 0.00106093241
Iter: 964 loss: 0.00106091844
Iter: 965 loss: 0.00106091157
Iter: 966 loss: 0.00106088084
Iter: 967 loss: 0.00106096757
Iter: 968 loss: 0.00106087036
Iter: 969 loss: 0.00106084056
Iter: 970 loss: 0.00106092135
Iter: 971 loss: 0.00106082915
Iter: 972 loss: 0.00106079783
Iter: 973 loss: 0.00106083439
Iter: 974 loss: 0.0010607799
Iter: 975 loss: 0.00106074102
Iter: 976 loss: 0.00106081413
Iter: 977 loss: 0.00106072566
Iter: 978 loss: 0.00106068607
Iter: 979 loss: 0.00106082088
Iter: 980 loss: 0.00106067467
Iter: 981 loss: 0.001060643
Iter: 982 loss: 0.0010609983
Iter: 983 loss: 0.00106064137
Iter: 984 loss: 0.00106062158
Iter: 985 loss: 0.00106091984
Iter: 986 loss: 0.00106062065
Iter: 987 loss: 0.00106060714
Iter: 988 loss: 0.00106062414
Iter: 989 loss: 0.00106060086
Iter: 990 loss: 0.00106058689
Iter: 991 loss: 0.00106063159
Iter: 992 loss: 0.00106058223
Iter: 993 loss: 0.00106056675
Iter: 994 loss: 0.00106057699
Iter: 995 loss: 0.0010605565
Iter: 996 loss: 0.00106053636
Iter: 997 loss: 0.001060521
Iter: 998 loss: 0.00106051529
Iter: 999 loss: 0.00106048642
Iter: 1000 loss: 0.00106057234
Iter: 1001 loss: 0.00106047769
Iter: 1002 loss: 0.00106045
Iter: 1003 loss: 0.00106051669
Iter: 1004 loss: 0.00106043951
Iter: 1005 loss: 0.00106040819
Iter: 1006 loss: 0.00106044917
Iter: 1007 loss: 0.00106039247
Iter: 1008 loss: 0.00106035627
Iter: 1009 loss: 0.0010604132
Iter: 1010 loss: 0.00106033869
Iter: 1011 loss: 0.00106030062
Iter: 1012 loss: 0.00106044253
Iter: 1013 loss: 0.0010602891
Iter: 1014 loss: 0.00106025918
Iter: 1015 loss: 0.00106056989
Iter: 1016 loss: 0.00106025836
Iter: 1017 loss: 0.00106023764
Iter: 1018 loss: 0.00106054579
Iter: 1019 loss: 0.00106023892
Iter: 1020 loss: 0.0010602246
Iter: 1021 loss: 0.0010602359
Iter: 1022 loss: 0.00106021541
Iter: 1023 loss: 0.00106020109
Iter: 1024 loss: 0.00106024859
Iter: 1025 loss: 0.00106019725
Iter: 1026 loss: 0.00106018176
Iter: 1027 loss: 0.00106019736
Iter: 1028 loss: 0.00106017035
Iter: 1029 loss: 0.00106015196
Iter: 1030 loss: 0.00106014195
Iter: 1031 loss: 0.00106013333
Iter: 1032 loss: 0.00106010609
Iter: 1033 loss: 0.00106016826
Iter: 1034 loss: 0.00106009434
Iter: 1035 loss: 0.00106006733
Iter: 1036 loss: 0.00106016
Iter: 1037 loss: 0.0010600579
Iter: 1038 loss: 0.00106003135
Iter: 1039 loss: 0.00106007466
Iter: 1040 loss: 0.00106001948
Iter: 1041 loss: 0.00105998782
Iter: 1042 loss: 0.00106001936
Iter: 1043 loss: 0.00105997012
Iter: 1044 loss: 0.00105993473
Iter: 1045 loss: 0.0010601012
Iter: 1046 loss: 0.00105992868
Iter: 1047 loss: 0.00105990283
Iter: 1048 loss: 0.00106013659
Iter: 1049 loss: 0.00105990295
Iter: 1050 loss: 0.00105988514
Iter: 1051 loss: 0.00106012973
Iter: 1052 loss: 0.00105988595
Iter: 1053 loss: 0.00105987245
Iter: 1054 loss: 0.00105988048
Iter: 1055 loss: 0.00105986523
Iter: 1056 loss: 0.00105985056
Iter: 1057 loss: 0.00105989678
Iter: 1058 loss: 0.00105984614
Iter: 1059 loss: 0.00105983135
Iter: 1060 loss: 0.00105985533
Iter: 1061 loss: 0.00105982518
Iter: 1062 loss: 0.00105980958
Iter: 1063 loss: 0.00105979841
Iter: 1064 loss: 0.00105979305
Iter: 1065 loss: 0.00105976884
Iter: 1066 loss: 0.0010598118
Iter: 1067 loss: 0.00105975685
Iter: 1068 loss: 0.00105973147
Iter: 1069 loss: 0.0010598232
Iter: 1070 loss: 0.00105972402
Iter: 1071 loss: 0.00105969899
Iter: 1072 loss: 0.001059748
Iter: 1073 loss: 0.00105968898
Iter: 1074 loss: 0.00105966278
Iter: 1075 loss: 0.00105969084
Iter: 1076 loss: 0.001059648
Iter: 1077 loss: 0.00105961668
Iter: 1078 loss: 0.00105974113
Iter: 1079 loss: 0.00105961156
Iter: 1080 loss: 0.00105958804
Iter: 1081 loss: 0.00105979107
Iter: 1082 loss: 0.00105958746
Iter: 1083 loss: 0.00105957326
Iter: 1084 loss: 0.00105957338
Iter: 1085 loss: 0.00105956313
Iter: 1086 loss: 0.00105957047
Iter: 1087 loss: 0.00105955673
Iter: 1088 loss: 0.00105954509
Iter: 1089 loss: 0.00105958106
Iter: 1090 loss: 0.00105954229
Iter: 1091 loss: 0.00105952984
Iter: 1092 loss: 0.00105954683
Iter: 1093 loss: 0.00105952309
Iter: 1094 loss: 0.00105950993
Iter: 1095 loss: 0.00105949899
Iter: 1096 loss: 0.00105949421
Iter: 1097 loss: 0.00105947373
Iter: 1098 loss: 0.00105951284
Iter: 1099 loss: 0.00105946464
Iter: 1100 loss: 0.00105944136
Iter: 1101 loss: 0.00105950539
Iter: 1102 loss: 0.00105943345
Iter: 1103 loss: 0.00105941133
Iter: 1104 loss: 0.00105945836
Iter: 1105 loss: 0.00105940097
Iter: 1106 loss: 0.0010593778
Iter: 1107 loss: 0.00105942041
Iter: 1108 loss: 0.00105936639
Iter: 1109 loss: 0.0010593409
Iter: 1110 loss: 0.00105941563
Iter: 1111 loss: 0.00105933263
Iter: 1112 loss: 0.00105931098
Iter: 1113 loss: 0.00105948013
Iter: 1114 loss: 0.0010593097
Iter: 1115 loss: 0.00105929503
Iter: 1116 loss: 0.00105929584
Iter: 1117 loss: 0.00105928618
Iter: 1118 loss: 0.00105929421
Iter: 1119 loss: 0.00105928059
Iter: 1120 loss: 0.00105927023
Iter: 1121 loss: 0.00105929549
Iter: 1122 loss: 0.00105926534
Iter: 1123 loss: 0.00105925521
Iter: 1124 loss: 0.00105927372
Iter: 1125 loss: 0.00105924788
Iter: 1126 loss: 0.001059236
Iter: 1127 loss: 0.00105922914
Iter: 1128 loss: 0.00105922285
Iter: 1129 loss: 0.00105920562
Iter: 1130 loss: 0.00105923507
Iter: 1131 loss: 0.00105919759
Iter: 1132 loss: 0.0010591785
Iter: 1133 loss: 0.00105923018
Iter: 1134 loss: 0.00105917279
Iter: 1135 loss: 0.00105915219
Iter: 1136 loss: 0.00105919456
Iter: 1137 loss: 0.00105914217
Iter: 1138 loss: 0.00105912099
Iter: 1139 loss: 0.00105915824
Iter: 1140 loss: 0.00105911179
Iter: 1141 loss: 0.00105909014
Iter: 1142 loss: 0.0010591523
Iter: 1143 loss: 0.00105908327
Iter: 1144 loss: 0.00105906255
Iter: 1145 loss: 0.00105919642
Iter: 1146 loss: 0.0010590615
Iter: 1147 loss: 0.00105904904
Iter: 1148 loss: 0.00105904834
Iter: 1149 loss: 0.00105903926
Iter: 1150 loss: 0.00105904718
Iter: 1151 loss: 0.00105903251
Iter: 1152 loss: 0.00105902273
Iter: 1153 loss: 0.00105904927
Iter: 1154 loss: 0.00105901889
Iter: 1155 loss: 0.0010590083
Iter: 1156 loss: 0.00105903391
Iter: 1157 loss: 0.00105900492
Iter: 1158 loss: 0.00105899433
Iter: 1159 loss: 0.00105899025
Iter: 1160 loss: 0.00105898443
Iter: 1161 loss: 0.00105897163
Iter: 1162 loss: 0.00105898769
Iter: 1163 loss: 0.00105896452
Iter: 1164 loss: 0.00105894834
Iter: 1165 loss: 0.00105898851
Iter: 1166 loss: 0.00105894147
Iter: 1167 loss: 0.00105892413
Iter: 1168 loss: 0.0010589622
Iter: 1169 loss: 0.00105891819
Iter: 1170 loss: 0.0010588998
Iter: 1171 loss: 0.00105893309
Iter: 1172 loss: 0.00105889235
Iter: 1173 loss: 0.00105887465
Iter: 1174 loss: 0.0010589218
Iter: 1175 loss: 0.00105886965
Iter: 1176 loss: 0.00105885207
Iter: 1177 loss: 0.00105894625
Iter: 1178 loss: 0.00105884857
Iter: 1179 loss: 0.00105884008
Iter: 1180 loss: 0.00105883926
Iter: 1181 loss: 0.00105883041
Iter: 1182 loss: 0.00105883682
Iter: 1183 loss: 0.00105882599
Iter: 1184 loss: 0.00105881854
Iter: 1185 loss: 0.00105883821
Iter: 1186 loss: 0.00105881412
Iter: 1187 loss: 0.0010588048
Iter: 1188 loss: 0.00105883076
Iter: 1189 loss: 0.00105880201
Iter: 1190 loss: 0.00105879491
Iter: 1191 loss: 0.00105879153
Iter: 1192 loss: 0.00105878769
Iter: 1193 loss: 0.00105877733
Iter: 1194 loss: 0.00105878792
Iter: 1195 loss: 0.00105877058
Iter: 1196 loss: 0.00105875637
Iter: 1197 loss: 0.00105878734
Iter: 1198 loss: 0.00105875148
Iter: 1199 loss: 0.00105873484
Iter: 1200 loss: 0.00105877651
Iter: 1201 loss: 0.00105872983
Iter: 1202 loss: 0.00105871633
Iter: 1203 loss: 0.00105875009
Iter: 1204 loss: 0.00105871074
Iter: 1205 loss: 0.001058697
Iter: 1206 loss: 0.00105871889
Iter: 1207 loss: 0.00105869037
Iter: 1208 loss: 0.00105867372
Iter: 1209 loss: 0.00105877547
Iter: 1210 loss: 0.00105867325
Iter: 1211 loss: 0.00105866592
Iter: 1212 loss: 0.00105866475
Iter: 1213 loss: 0.0010586601
Iter: 1214 loss: 0.00105866441
Iter: 1215 loss: 0.00105865533
Iter: 1216 loss: 0.00105864974
Iter: 1217 loss: 0.00105866278
Iter: 1218 loss: 0.00105864671
Iter: 1219 loss: 0.00105863949
Iter: 1220 loss: 0.00105865975
Iter: 1221 loss: 0.00105863775
Iter: 1222 loss: 0.00105863065
Iter: 1223 loss: 0.0010586296
Iter: 1224 loss: 0.00105862587
Iter: 1225 loss: 0.00105861621
Iter: 1226 loss: 0.00105862622
Iter: 1227 loss: 0.00105861155
Iter: 1228 loss: 0.00105859921
Iter: 1229 loss: 0.00105862599
Iter: 1230 loss: 0.00105859467
Iter: 1231 loss: 0.00105858315
Iter: 1232 loss: 0.00105861539
Iter: 1233 loss: 0.00105857803
Iter: 1234 loss: 0.00105856778
Iter: 1235 loss: 0.00105859258
Iter: 1236 loss: 0.00105856289
Iter: 1237 loss: 0.00105855113
Iter: 1238 loss: 0.00105857383
Iter: 1239 loss: 0.00105854613
Iter: 1240 loss: 0.00105853379
Iter: 1241 loss: 0.0010585956
Iter: 1242 loss: 0.00105853286
Iter: 1243 loss: 0.00105852657
Iter: 1244 loss: 0.00105852541
Iter: 1245 loss: 0.00105852075
Iter: 1246 loss: 0.00105852471
Iter: 1247 loss: 0.00105851807
Iter: 1248 loss: 0.00105851283
Iter: 1249 loss: 0.00105852343
Iter: 1250 loss: 0.00105851039
Iter: 1251 loss: 0.00105850527
Iter: 1252 loss: 0.00105852215
Iter: 1253 loss: 0.00105850282
Iter: 1254 loss: 0.0010584977
Iter: 1255 loss: 0.00105849304
Iter: 1256 loss: 0.00105849165
Iter: 1257 loss: 0.0010584828
Iter: 1258 loss: 0.00105849584
Iter: 1259 loss: 0.00105848024
Iter: 1260 loss: 0.00105846848
Iter: 1261 loss: 0.00105850655
Iter: 1262 loss: 0.00105846603
Iter: 1263 loss: 0.00105845626
Iter: 1264 loss: 0.00105847511
Iter: 1265 loss: 0.00105845253
Iter: 1266 loss: 0.0010584424
Iter: 1267 loss: 0.0010584608
Iter: 1268 loss: 0.00105843751
Iter: 1269 loss: 0.00105842762
Iter: 1270 loss: 0.00105845474
Iter: 1271 loss: 0.00105842459
Iter: 1272 loss: 0.00105841435
Iter: 1273 loss: 0.00105845917
Iter: 1274 loss: 0.00105841376
Iter: 1275 loss: 0.00105840876
Iter: 1276 loss: 0.00105840818
Iter: 1277 loss: 0.00105840364
Iter: 1278 loss: 0.00105840759
Iter: 1279 loss: 0.00105840119
Iter: 1280 loss: 0.00105839549
Iter: 1281 loss: 0.00105840759
Iter: 1282 loss: 0.00105839432
Iter: 1283 loss: 0.0010583892
Iter: 1284 loss: 0.00105840364
Iter: 1285 loss: 0.00105838757
Iter: 1286 loss: 0.00105838268
Iter: 1287 loss: 0.00105837744
Iter: 1288 loss: 0.00105837616
Iter: 1289 loss: 0.00105836918
Iter: 1290 loss: 0.00105837861
Iter: 1291 loss: 0.00105836336
Iter: 1292 loss: 0.00105835474
Iter: 1293 loss: 0.00105839642
Iter: 1294 loss: 0.00105835218
Iter: 1295 loss: 0.0010583438
Iter: 1296 loss: 0.00105836219
Iter: 1297 loss: 0.00105834054
Iter: 1298 loss: 0.00105833262
Iter: 1299 loss: 0.00105834403
Iter: 1300 loss: 0.00105832866
Iter: 1301 loss: 0.00105831912
Iter: 1302 loss: 0.00105834671
Iter: 1303 loss: 0.00105831632
Iter: 1304 loss: 0.00105830724
Iter: 1305 loss: 0.00105833681
Iter: 1306 loss: 0.00105830608
Iter: 1307 loss: 0.00105830096
Iter: 1308 loss: 0.0010583
Iter: 1309 loss: 0.00105829735
Iter: 1310 loss: 0.00105829805
Iter: 1311 loss: 0.00105829409
Iter: 1312 loss: 0.00105828769
Iter: 1313 loss: 0.00105829863
Iter: 1314 loss: 0.00105828652
Iter: 1315 loss: 0.00105828256
Iter: 1316 loss: 0.00105830166
Iter: 1317 loss: 0.00105828047
Iter: 1318 loss: 0.00105827581
Iter: 1319 loss: 0.00105827115
Iter: 1320 loss: 0.00105827046
Iter: 1321 loss: 0.00105826405
Iter: 1322 loss: 0.00105827511
Iter: 1323 loss: 0.00105826114
Iter: 1324 loss: 0.00105825264
Iter: 1325 loss: 0.00105828
Iter: 1326 loss: 0.00105825008
Iter: 1327 loss: 0.00105824193
Iter: 1328 loss: 0.00105825672
Iter: 1329 loss: 0.00105823926
Iter: 1330 loss: 0.00105823181
Iter: 1331 loss: 0.00105824845
Iter: 1332 loss: 0.00105822773
Iter: 1333 loss: 0.00105821923
Iter: 1334 loss: 0.00105823798
Iter: 1335 loss: 0.00105821714
Iter: 1336 loss: 0.00105820841
Iter: 1337 loss: 0.00105823448
Iter: 1338 loss: 0.00105820585
Iter: 1339 loss: 0.00105820433
Iter: 1340 loss: 0.00105820119
Iter: 1341 loss: 0.00105819828
Iter: 1342 loss: 0.00105819898
Iter: 1343 loss: 0.00105819618
Iter: 1344 loss: 0.00105819246
Iter: 1345 loss: 0.00105820072
Iter: 1346 loss: 0.00105819164
Iter: 1347 loss: 0.00105818617
Iter: 1348 loss: 0.00105820422
Iter: 1349 loss: 0.00105818547
Iter: 1350 loss: 0.00105818128
Iter: 1351 loss: 0.00105817756
Iter: 1352 loss: 0.00105817732
Iter: 1353 loss: 0.00105817162
Iter: 1354 loss: 0.00105818151
Iter: 1355 loss: 0.00105817057
Iter: 1356 loss: 0.00105816405
Iter: 1357 loss: 0.00105818175
Iter: 1358 loss: 0.00105816149
Iter: 1359 loss: 0.00105815637
Iter: 1360 loss: 0.00105816557
Iter: 1361 loss: 0.0010581516
Iter: 1362 loss: 0.00105814484
Iter: 1363 loss: 0.00105816335
Iter: 1364 loss: 0.00105814228
Iter: 1365 loss: 0.00105813507
Iter: 1366 loss: 0.00105815497
Iter: 1367 loss: 0.00105813402
Iter: 1368 loss: 0.00105812738
Iter: 1369 loss: 0.00105814287
Iter: 1370 loss: 0.00105812564
Iter: 1371 loss: 0.00105812366
Iter: 1372 loss: 0.00105812284
Iter: 1373 loss: 0.00105812051
Iter: 1374 loss: 0.00105812284
Iter: 1375 loss: 0.00105811819
Iter: 1376 loss: 0.00105811539
Iter: 1377 loss: 0.00105811981
Iter: 1378 loss: 0.00105811458
Iter: 1379 loss: 0.00105811
Iter: 1380 loss: 0.00105812424
Iter: 1381 loss: 0.00105811027
Iter: 1382 loss: 0.00105810724
Iter: 1383 loss: 0.00105810491
Iter: 1384 loss: 0.00105810422
Iter: 1385 loss: 0.00105810072
Iter: 1386 loss: 0.00105810631
Iter: 1387 loss: 0.00105809839
Iter: 1388 loss: 0.00105809444
Iter: 1389 loss: 0.00105810724
Iter: 1390 loss: 0.00105809362
Iter: 1391 loss: 0.00105808873
Iter: 1392 loss: 0.00105809444
Iter: 1393 loss: 0.00105808536
Iter: 1394 loss: 0.00105807942
Iter: 1395 loss: 0.00105809735
Iter: 1396 loss: 0.00105807954
Iter: 1397 loss: 0.00105807465
Iter: 1398 loss: 0.00105808931
Iter: 1399 loss: 0.00105807313
Iter: 1400 loss: 0.00105806929
Iter: 1401 loss: 0.00105807697
Iter: 1402 loss: 0.00105806754
Iter: 1403 loss: 0.0010580672
Iter: 1404 loss: 0.00105806557
Iter: 1405 loss: 0.00105806394
Iter: 1406 loss: 0.00105806673
Iter: 1407 loss: 0.00105806277
Iter: 1408 loss: 0.00105806126
Iter: 1409 loss: 0.00105806324
Iter: 1410 loss: 0.00105806044
Iter: 1411 loss: 0.00105805742
Iter: 1412 loss: 0.0010580672
Iter: 1413 loss: 0.00105805625
Iter: 1414 loss: 0.00105805579
Iter: 1415 loss: 0.00105805392
Iter: 1416 loss: 0.00105805323
Iter: 1417 loss: 0.0010580509
Iter: 1418 loss: 0.00105805136
Iter: 1419 loss: 0.00105804962
Iter: 1420 loss: 0.00105804647
Iter: 1421 loss: 0.00105805555
Iter: 1422 loss: 0.00105804577
Iter: 1423 loss: 0.00105804356
Iter: 1424 loss: 0.00105804834
Iter: 1425 loss: 0.00105804123
Iter: 1426 loss: 0.00105803809
Iter: 1427 loss: 0.00105804787
Iter: 1428 loss: 0.00105803763
Iter: 1429 loss: 0.00105803437
Iter: 1430 loss: 0.00105804508
Iter: 1431 loss: 0.00105803437
Iter: 1432 loss: 0.00105803227
Iter: 1433 loss: 0.00105803902
Iter: 1434 loss: 0.0010580318
Iter: 1435 loss: 0.00105802959
Iter: 1436 loss: 0.0010580516
Iter: 1437 loss: 0.00105802808
Iter: 1438 loss: 0.00105802645
Iter: 1439 loss: 0.00105803378
Iter: 1440 loss: 0.00105802878
Iter: 1441 loss: 0.00105802645
Iter: 1442 loss: 0.00105802773
Iter: 1443 loss: 0.00105802505
Iter: 1444 loss: 0.00105802401
Iter: 1445 loss: 0.0010580325
Iter: 1446 loss: 0.00105802342
Iter: 1447 loss: 0.00105802272
Iter: 1448 loss: 0.00105802179
Iter: 1449 loss: 0.00105802109
Iter: 1450 loss: 0.00105801981
Iter: 1451 loss: 0.00105801981
Iter: 1452 loss: 0.0010580197
Iter: 1453 loss: 0.00105801737
Iter: 1454 loss: 0.00105802098
Iter: 1455 loss: 0.00105801737
Iter: 1456 loss: 0.00105801458
Iter: 1457 loss: 0.0010580176
Iter: 1458 loss: 0.00105801353
Iter: 1459 loss: 0.00105801201
Iter: 1460 loss: 0.00105801772
Iter: 1461 loss: 0.00105801085
Iter: 1462 loss: 0.00105801038
Iter: 1463 loss: 0.00105801655
Iter: 1464 loss: 0.00105800957
Iter: 1465 loss: 0.00105800747
Iter: 1466 loss: 0.00105800945
Iter: 1467 loss: 0.00105800678
Iter: 1468 loss: 0.00105800596
Iter: 1469 loss: 0.00105801749
Iter: 1470 loss: 0.00105800619
Iter: 1471 loss: 0.00105800398
Iter: 1472 loss: 0.00105801201
Iter: 1473 loss: 0.00105800305
Iter: 1474 loss: 0.0010580034
Iter: 1475 loss: 0.00105800398
Iter: 1476 loss: 0.00105800189
Iter: 1477 loss: 0.00105800177
Iter: 1478 loss: 0.00105800712
Iter: 1479 loss: 0.00105800107
Iter: 1480 loss: 0.00105800014
Iter: 1481 loss: 0.001058002
Iter: 1482 loss: 0.00105799874
Iter: 1483 loss: 0.00105799886
Iter: 1484 loss: 0.00105799863
Iter: 1485 loss: 0.00105799816
Iter: 1486 loss: 0.00105799665
Iter: 1487 loss: 0.00105799898
Iter: 1488 loss: 0.00105799618
Iter: 1489 loss: 0.0010579949
Iter: 1490 loss: 0.00105799758
Iter: 1491 loss: 0.0010579942
Iter: 1492 loss: 0.00105799339
Iter: 1493 loss: 0.00105799688
Iter: 1494 loss: 0.00105799269
Iter: 1495 loss: 0.00105799106
Iter: 1496 loss: 0.00105799548
Iter: 1497 loss: 0.00105799059
Iter: 1498 loss: 0.00105798966
Iter: 1499 loss: 0.00105799269
Iter: 1500 loss: 0.00105798896
Iter: 1501 loss: 0.00105798873
Iter: 1502 loss: 0.00105799572
Iter: 1503 loss: 0.00105798792
Iter: 1504 loss: 0.0010579871
Iter: 1505 loss: 0.00105799816
Iter: 1506 loss: 0.00105798664
Iter: 1507 loss: 0.00105798594
Iter: 1508 loss: 0.00105798687
Iter: 1509 loss: 0.00105798501
Iter: 1510 loss: 0.00105798442
Iter: 1511 loss: 0.00105798861
Iter: 1512 loss: 0.00105798419
Iter: 1513 loss: 0.00105798396
Iter: 1514 loss: 0.00105798396
Iter: 1515 loss: 0.00105798384
Iter: 1516 loss: 0.00105798373
Iter: 1517 loss: 0.00105798244
Iter: 1518 loss: 0.00105798221
Iter: 1519 loss: 0.0010579807
Iter: 1520 loss: 0.00105798384
Iter: 1521 loss: 0.0010579821
Iter: 1522 loss: 0.00105798035
Iter: 1523 loss: 0.00105798244
Iter: 1524 loss: 0.00105797942
Iter: 1525 loss: 0.00105797814
Iter: 1526 loss: 0.00105798012
Iter: 1527 loss: 0.00105797849
Iter: 1528 loss: 0.00105797709
Iter: 1529 loss: 0.00105798012
Iter: 1530 loss: 0.00105797697
Iter: 1531 loss: 0.00105797464
Iter: 1532 loss: 0.00105797802
Iter: 1533 loss: 0.00105797476
Iter: 1534 loss: 0.00105797453
Iter: 1535 loss: 0.0010579793
Iter: 1536 loss: 0.00105797511
Iter: 1537 loss: 0.00105797383
Iter: 1538 loss: 0.0010579743
Iter: 1539 loss: 0.0010579729
Iter: 1540 loss: 0.00105797418
Iter: 1541 loss: 0.00105797313
Iter: 1542 loss: 0.0010579729
Iter: 1543 loss: 0.00105797453
Iter: 1544 loss: 0.0010579729
Iter: 1545 loss: 0.00105797162
Iter: 1546 loss: 0.00105797267
Iter: 1547 loss: 0.00105797243
Iter: 1548 loss: 0.00105797104
Iter: 1549 loss: 0.00105797104
Iter: 1550 loss: 0.00105797057
Iter: 1551 loss: 0.00105797045
Iter: 1552 loss: 0.00105797313
Iter: 1553 loss: 0.00105797
Iter: 1554 loss: 0.0010579701
Iter: 1555 loss: 0.00105797139
Iter: 1556 loss: 0.00105796859
Iter: 1557 loss: 0.00105796824
Iter: 1558 loss: 0.00105796906
Iter: 1559 loss: 0.00105796824
Iter: 1560 loss: 0.00105796754
Iter: 1561 loss: 0.00105796801
Iter: 1562 loss: 0.00105796638
Iter: 1563 loss: 0.00105796638
Iter: 1564 loss: 0.0010579701
Iter: 1565 loss: 0.00105796522
Iter: 1566 loss: 0.00105796556
Iter: 1567 loss: 0.00105796766
Iter: 1568 loss: 0.00105796405
Iter: 1569 loss: 0.00105796545
Iter: 1570 loss: 0.00105796452
Iter: 1571 loss: 0.00105796452
Iter: 1572 loss: 0.00105796463
Iter: 1573 loss: 0.00105796463
Iter: 1574 loss: 0.00105796405
Iter: 1575 loss: 0.00105796533
Iter: 1576 loss: 0.00105796382
Iter: 1577 loss: 0.00105796196
Iter: 1578 loss: 0.00105796393
Iter: 1579 loss: 0.00105796265
Iter: 1580 loss: 0.00105796219
Iter: 1581 loss: 0.00105796126
Iter: 1582 loss: 0.00105796056
Iter: 1583 loss: 0.00105796102
Iter: 1584 loss: 0.00105796265
Iter: 1585 loss: 0.00105796126
Iter: 1586 loss: 0.00105795963
Iter: 1587 loss: 0.00105796242
Iter: 1588 loss: 0.00105796056
Iter: 1589 loss: 0.00105796079
Iter: 1590 loss: 0.00105796102
Iter: 1591 loss: 0.00105795928
Iter: 1592 loss: 0.00105795916
Iter: 1593 loss: 0.00105795916
Iter: 1594 loss: 0.00105795765
Iter: 1595 loss: 0.00105795835
Iter: 1596 loss: 0.00105796102
Iter: 1597 loss: 0.00105795765
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/k3
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0
+ date
Tue Oct 27 17:31:47 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f007a3639d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f005804d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0058058bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f007a30f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f007a305158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f005807fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f00580a7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f005800e0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f005800cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057fd0598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057f6f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057f78a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057f35510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057f37f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057f6a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057f1e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057f1fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057ede8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057e7f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057e83d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057e45840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057e642f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057debd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057dad7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057dc9268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057dd2c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057d93730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057d391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057d44bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057cfa6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057d1f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057d20b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057cdd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057c7d0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057c88ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f0057c4d598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00448786654
Iter: 2 loss: 0.00447325222
Iter: 3 loss: 0.00442876527
Iter: 4 loss: 0.00454049092
Iter: 5 loss: 0.00440387335
Iter: 6 loss: 0.00438651396
Iter: 7 loss: 0.00438385922
Iter: 8 loss: 0.00438120682
Iter: 9 loss: 0.0043818932
Iter: 10 loss: 0.00437927712
Iter: 11 loss: 0.00437933
Iter: 12 loss: 0.00437888922
Iter: 13 loss: 0.0043787607
Iter: 14 loss: 0.0043788217
Iter: 15 loss: 0.00437867315
Iter: 16 loss: 0.00437866617
Iter: 17 loss: 0.00437866338
Iter: 18 loss: 0.00437865732
Iter: 19 loss: 0.00437868
Iter: 20 loss: 0.00437865825
Iter: 21 loss: 0.00437865639
Iter: 22 loss: 0.00437865779
Iter: 23 loss: 0.00437865593
Iter: 24 loss: 0.00437865546
Iter: 25 loss: 0.00437865639
Iter: 26 loss: 0.00437865732
Iter: 27 loss: 0.00437865686
Iter: 28 loss: 0.00437865686
Iter: 29 loss: 0.00437865686
Iter: 30 loss: 0.00437865639
Iter: 31 loss: 0.00437865593
Iter: 32 loss: 0.00437865593
Iter: 33 loss: 0.00437865499
Iter: 34 loss: 0.00437865593
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4
+ date
Tue Oct 27 17:32:10 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c2c037bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c2c05d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c5298f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c529e4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c529e4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c529e41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c100ae620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c1008c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c1008c0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c10020bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c100451e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc47dfd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc4780b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc47bc730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc4739e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc46fbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc471a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc47bc400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4c10020598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc471ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc463f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc46672f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc4667268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc45dbd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc45db840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc45db8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc45a4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc45a4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc456a400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc45082f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc456a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc456a950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc44d18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc45086a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc44d1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4bc4571378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0314603858
Iter: 2 loss: 0.0270230751
Iter: 3 loss: 0.013924621
Iter: 4 loss: 0.0559449792
Iter: 5 loss: 0.00730845891
Iter: 6 loss: 0.00628978666
Iter: 7 loss: 0.0059018787
Iter: 8 loss: 0.00538441679
Iter: 9 loss: 0.0118368762
Iter: 10 loss: 0.00537060434
Iter: 11 loss: 0.00525688101
Iter: 12 loss: 0.00561389048
Iter: 13 loss: 0.00522411847
Iter: 14 loss: 0.00520271156
Iter: 15 loss: 0.00519314921
Iter: 16 loss: 0.00518072769
Iter: 17 loss: 0.00520304404
Iter: 18 loss: 0.00517534791
Iter: 19 loss: 0.00517215114
Iter: 20 loss: 0.00517215161
Iter: 21 loss: 0.00517127477
Iter: 22 loss: 0.00517123
Iter: 23 loss: 0.00517107546
Iter: 24 loss: 0.00517146895
Iter: 25 loss: 0.00517102238
Iter: 26 loss: 0.00517098792
Iter: 27 loss: 0.00517098699
Iter: 28 loss: 0.00517097302
Iter: 29 loss: 0.00517109828
Iter: 30 loss: 0.00517097209
Iter: 31 loss: 0.00517097
Iter: 32 loss: 0.00517097488
Iter: 33 loss: 0.00517096883
Iter: 34 loss: 0.00517096929
Iter: 35 loss: 0.00517097395
Iter: 36 loss: 0.0051709679
Iter: 37 loss: 0.00517096743
Iter: 38 loss: 0.00517096836
Iter: 39 loss: 0.00517096696
Iter: 40 loss: 0.00517096836
Iter: 41 loss: 0.00517096836
Iter: 42 loss: 0.00517096836
Iter: 43 loss: 0.00517096743
Iter: 44 loss: 0.00517096836
Iter: 45 loss: 0.00517096743
Iter: 46 loss: 0.00517096743
Iter: 47 loss: 0.0051709679
Iter: 48 loss: 0.00517096696
Iter: 49 loss: 0.00517096696
Iter: 50 loss: 0.00517096743
Iter: 51 loss: 0.00517096743
Iter: 52 loss: 0.0051709679
Iter: 53 loss: 0.0051709679
Iter: 54 loss: 0.00517096743
Iter: 55 loss: 0.0051709679
Iter: 56 loss: 0.00517096743
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8
+ date
Tue Oct 27 17:32:37 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35849a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3584b0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3584e1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358414730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358414488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358423ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358414268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358381a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358381378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3583816a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35833d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3582f1d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3582c9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3582c9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3582d6a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35820ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35822bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3582c9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35820ba60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35822b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35817df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35817d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd35817d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3580e2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3580e2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3580e26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3580b7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3580b7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358079378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358018268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3580797b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358079730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd34010b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd358018158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd3400f1378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd34009ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0249554515
Iter: 2 loss: 0.0213224702
Iter: 3 loss: 0.013030218
Iter: 4 loss: 1.26998425
Iter: 5 loss: 0.0130209466
Iter: 6 loss: 0.00809294
Iter: 7 loss: 0.0417777449
Iter: 8 loss: 0.00746052573
Iter: 9 loss: 0.00649139378
Iter: 10 loss: 0.00639354717
Iter: 11 loss: 0.00624324661
Iter: 12 loss: 0.00718176924
Iter: 13 loss: 0.00622387603
Iter: 14 loss: 0.00613192283
Iter: 15 loss: 0.00631060312
Iter: 16 loss: 0.0060927486
Iter: 17 loss: 0.00602856465
Iter: 18 loss: 0.00635445677
Iter: 19 loss: 0.00601833221
Iter: 20 loss: 0.00599795487
Iter: 21 loss: 0.0061474056
Iter: 22 loss: 0.00599623
Iter: 23 loss: 0.00599102955
Iter: 24 loss: 0.00599092431
Iter: 25 loss: 0.00598935084
Iter: 26 loss: 0.00599276507
Iter: 27 loss: 0.00598874
Iter: 28 loss: 0.00598848751
Iter: 29 loss: 0.00599190081
Iter: 30 loss: 0.00598848518
Iter: 31 loss: 0.00598838879
Iter: 32 loss: 0.00598975
Iter: 33 loss: 0.00598838925
Iter: 34 loss: 0.00598836225
Iter: 35 loss: 0.00598839857
Iter: 36 loss: 0.00598834921
Iter: 37 loss: 0.00598834129
Iter: 38 loss: 0.00598839391
Iter: 39 loss: 0.00598833803
Iter: 40 loss: 0.0059883371
Iter: 41 loss: 0.00598835293
Iter: 42 loss: 0.00598833524
Iter: 43 loss: 0.00598833617
Iter: 44 loss: 0.00598833617
Iter: 45 loss: 0.00598833524
Iter: 46 loss: 0.0059883357
Iter: 47 loss: 0.00598833757
Iter: 48 loss: 0.00598833617
Iter: 49 loss: 0.00598833757
Iter: 50 loss: 0.00598833617
Iter: 51 loss: 0.00598833617
Iter: 52 loss: 0.00598833524
Iter: 53 loss: 0.00598833524
Iter: 54 loss: 0.0059883357
Iter: 55 loss: 0.00598833524
Iter: 56 loss: 0.00598833524
Iter: 57 loss: 0.00598833617
Iter: 58 loss: 0.00598833524
Iter: 59 loss: 0.00598833524
Iter: 60 loss: 0.0059883357
Iter: 61 loss: 0.00598833617
Iter: 62 loss: 0.00598833524
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2
+ date
Tue Oct 27 17:33:04 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi0.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d13fa7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d14067b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d1352268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d1443950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d14431e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d1367950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91d1443510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac3a37b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac3c7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac36f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac36f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac332d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac2d5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac307268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac304730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac251d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac26bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac307048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac243d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac26b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac1b6ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac1b6268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac1b60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac12f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac12fd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac12f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac0f2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac097c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac0c0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac0611e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac05a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac0272f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91ac02b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9190782ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f91907ba2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9190768f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0268220175
Iter: 2 loss: 0.0203335974
Iter: 3 loss: 0.0237992238
Iter: 4 loss: 0.0149856666
Iter: 5 loss: 0.0108262477
Iter: 6 loss: 0.224263206
Iter: 7 loss: 0.0108203767
Iter: 8 loss: 0.00790391304
Iter: 9 loss: 0.0238990746
Iter: 10 loss: 0.00742337387
Iter: 11 loss: 0.0067034252
Iter: 12 loss: 0.00798509642
Iter: 13 loss: 0.0063757496
Iter: 14 loss: 0.00619886769
Iter: 15 loss: 0.00878264
Iter: 16 loss: 0.00619795313
Iter: 17 loss: 0.00612328
Iter: 18 loss: 0.0065309857
Iter: 19 loss: 0.00611173548
Iter: 20 loss: 0.00603556866
Iter: 21 loss: 0.0060993107
Iter: 22 loss: 0.00599035
Iter: 23 loss: 0.00595244486
Iter: 24 loss: 0.00634318497
Iter: 25 loss: 0.00595137943
Iter: 26 loss: 0.00593907945
Iter: 27 loss: 0.00601504277
Iter: 28 loss: 0.00593759492
Iter: 29 loss: 0.00593316415
Iter: 30 loss: 0.00596295577
Iter: 31 loss: 0.00593272
Iter: 32 loss: 0.00593131594
Iter: 33 loss: 0.00594245968
Iter: 34 loss: 0.00593122048
Iter: 35 loss: 0.00593084423
Iter: 36 loss: 0.00593299
Iter: 37 loss: 0.00593079114
Iter: 38 loss: 0.00593064073
Iter: 39 loss: 0.00593240932
Iter: 40 loss: 0.00593064
Iter: 41 loss: 0.00593058346
Iter: 42 loss: 0.00593080604
Iter: 43 loss: 0.00593057275
Iter: 44 loss: 0.00593054574
Iter: 45 loss: 0.00593054621
Iter: 46 loss: 0.00593053456
Iter: 47 loss: 0.00593056763
Iter: 48 loss: 0.00593052711
Iter: 49 loss: 0.00593051966
Iter: 50 loss: 0.00593055971
Iter: 51 loss: 0.00593052
Iter: 52 loss: 0.0059305178
Iter: 53 loss: 0.00593053829
Iter: 54 loss: 0.0059305178
Iter: 55 loss: 0.00593051501
Iter: 56 loss: 0.00593053503
Iter: 57 loss: 0.00593051501
Iter: 58 loss: 0.00593051501
Iter: 59 loss: 0.00593051687
Iter: 60 loss: 0.00593051407
Iter: 61 loss: 0.00593051454
Iter: 62 loss: 0.0059305164
Iter: 63 loss: 0.00593051361
Iter: 64 loss: 0.00593051361
Iter: 65 loss: 0.00593051407
Iter: 66 loss: 0.00593051361
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6
+ date
Tue Oct 27 17:33:31 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2babce730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2babc2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa29420f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa294229730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa294229488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa29422fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa294229268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa29416eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa294124f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa29416e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa294138378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2940fdd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2940ccf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2940cc598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2940e4a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa29401be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa294032d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2940cc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280781a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2940322f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280772f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280772268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280772158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2806e1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2806e1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2806e16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2806a5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2806a5b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280672378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280612268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2806727b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280672730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa2805dd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa280612158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa28053e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fa28055ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.036240615
Iter: 2 loss: 0.0184895732
Iter: 3 loss: 2047.7605
Iter: 4 loss: 0.0184895657
Iter: 5 loss: 0.015234828
Iter: 6 loss: 0.014355463
Iter: 7 loss: 0.0111909006
Iter: 8 loss: 0.0182439014
Iter: 9 loss: 0.00973875448
Iter: 10 loss: 0.00705216732
Iter: 11 loss: 0.0274532083
Iter: 12 loss: 0.00683575869
Iter: 13 loss: 0.00623611268
Iter: 14 loss: 0.0065476317
Iter: 15 loss: 0.00580954226
Iter: 16 loss: 0.0055757286
Iter: 17 loss: 0.00876459107
Iter: 18 loss: 0.00557371881
Iter: 19 loss: 0.00548804365
Iter: 20 loss: 0.00599107891
Iter: 21 loss: 0.00547599606
Iter: 22 loss: 0.00540047372
Iter: 23 loss: 0.00554962
Iter: 24 loss: 0.00536897825
Iter: 25 loss: 0.00529097579
Iter: 26 loss: 0.00549395196
Iter: 27 loss: 0.00526441261
Iter: 28 loss: 0.00520293415
Iter: 29 loss: 0.00529187685
Iter: 30 loss: 0.00517208641
Iter: 31 loss: 0.00512636313
Iter: 32 loss: 0.00527724531
Iter: 33 loss: 0.00511376699
Iter: 34 loss: 0.00509384647
Iter: 35 loss: 0.00529951137
Iter: 36 loss: 0.00509333052
Iter: 37 loss: 0.00508782361
Iter: 38 loss: 0.00510771526
Iter: 39 loss: 0.00508641452
Iter: 40 loss: 0.00508378679
Iter: 41 loss: 0.00508818869
Iter: 42 loss: 0.00508260401
Iter: 43 loss: 0.00508146873
Iter: 44 loss: 0.00508892536
Iter: 45 loss: 0.00508134905
Iter: 46 loss: 0.00508080749
Iter: 47 loss: 0.00508428691
Iter: 48 loss: 0.00508074835
Iter: 49 loss: 0.00508049736
Iter: 50 loss: 0.00508076325
Iter: 51 loss: 0.00508036092
Iter: 52 loss: 0.0050802
Iter: 53 loss: 0.00508091971
Iter: 54 loss: 0.0050801686
Iter: 55 loss: 0.00508009037
Iter: 56 loss: 0.0050806622
Iter: 57 loss: 0.00508008525
Iter: 58 loss: 0.00508002937
Iter: 59 loss: 0.0050803409
Iter: 60 loss: 0.00508002099
Iter: 61 loss: 0.00507998746
Iter: 62 loss: 0.00508009875
Iter: 63 loss: 0.00507997815
Iter: 64 loss: 0.00507996045
Iter: 65 loss: 0.00508010387
Iter: 66 loss: 0.00507996045
Iter: 67 loss: 0.00507994834
Iter: 68 loss: 0.00507998653
Iter: 69 loss: 0.00507994462
Iter: 70 loss: 0.00507993717
Iter: 71 loss: 0.00507995579
Iter: 72 loss: 0.00507993344
Iter: 73 loss: 0.00507993065
Iter: 74 loss: 0.00507996976
Iter: 75 loss: 0.00507993065
Iter: 76 loss: 0.00507992879
Iter: 77 loss: 0.00507994648
Iter: 78 loss: 0.00507992925
Iter: 79 loss: 0.00507992785
Iter: 80 loss: 0.00507993763
Iter: 81 loss: 0.00507992692
Iter: 82 loss: 0.00507992646
Iter: 83 loss: 0.00507992692
Iter: 84 loss: 0.00507992599
Iter: 85 loss: 0.00507992413
Iter: 86 loss: 0.00507992692
Iter: 87 loss: 0.00507992506
Iter: 88 loss: 0.00507992459
Iter: 89 loss: 0.00507992739
Iter: 90 loss: 0.00507992459
Iter: 91 loss: 0.00507992459
Iter: 92 loss: 0.00507992599
Iter: 93 loss: 0.00507992459
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2
+ date
Tue Oct 27 17:34:01 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi1.6/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb46e22598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb46e438c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb205062f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb205187b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20518ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20518268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20518a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2046f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2048e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2041bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2043d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20399e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20399b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb203d67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb203d4ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20392ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20335e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2036fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb203d66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20335378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20257488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2026b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2026b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb201f50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb201f5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20200b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb201b5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb201b5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20186488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb201262f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb2012a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20186a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb200ed8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb201266a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb200ede18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb20070f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0690151379
Iter: 2 loss: 1773.19104
Iter: 3 loss: 0.0690131262
Iter: 4 loss: 0.0354182608
Iter: 5 loss: 0.0383106
Iter: 6 loss: 85.2690277
Iter: 7 loss: 0.0383104309
Iter: 8 loss: 0.087247327
Iter: 9 loss: 0.033811368
Iter: 10 loss: 0.0417642221
Iter: 11 loss: 0.0263806619
Iter: 12 loss: 0.0230495054
Iter: 13 loss: 0.0205345117
Iter: 14 loss: 0.0173278023
Iter: 15 loss: 0.0523818694
Iter: 16 loss: 0.0169813205
Iter: 17 loss: 0.0133293159
Iter: 18 loss: 0.0308591556
Iter: 19 loss: 0.0125767812
Iter: 20 loss: 0.0109794391
Iter: 21 loss: 0.0135750799
Iter: 22 loss: 0.0103819072
Iter: 23 loss: 0.00951443613
Iter: 24 loss: 0.00844328
Iter: 25 loss: 0.00830092654
Iter: 26 loss: 0.00747195724
Iter: 27 loss: 0.00892906822
Iter: 28 loss: 0.00709667848
Iter: 29 loss: 0.00596836768
Iter: 30 loss: 0.0162014775
Iter: 31 loss: 0.00589280482
Iter: 32 loss: 0.00540708564
Iter: 33 loss: 0.0125459302
Iter: 34 loss: 0.00540433265
Iter: 35 loss: 0.00516978558
Iter: 36 loss: 0.00527421199
Iter: 37 loss: 0.00499947555
Iter: 38 loss: 0.00487647718
Iter: 39 loss: 0.00527151767
Iter: 40 loss: 0.0048426846
Iter: 41 loss: 0.00476991
Iter: 42 loss: 0.00488494057
Iter: 43 loss: 0.0047343052
Iter: 44 loss: 0.00469550397
Iter: 45 loss: 0.00478742551
Iter: 46 loss: 0.00468116906
Iter: 47 loss: 0.00465013133
Iter: 48 loss: 0.00470253313
Iter: 49 loss: 0.00463599199
Iter: 50 loss: 0.00460352935
Iter: 51 loss: 0.00465465616
Iter: 52 loss: 0.00458822306
Iter: 53 loss: 0.00453812862
Iter: 54 loss: 0.00456138654
Iter: 55 loss: 0.00450359
Iter: 56 loss: 0.00443109497
Iter: 57 loss: 0.00464052428
Iter: 58 loss: 0.00440808199
Iter: 59 loss: 0.00435540825
Iter: 60 loss: 0.00494022202
Iter: 61 loss: 0.00435396563
Iter: 62 loss: 0.00433214102
Iter: 63 loss: 0.00435172115
Iter: 64 loss: 0.00431944802
Iter: 65 loss: 0.00429725274
Iter: 66 loss: 0.00432291534
Iter: 67 loss: 0.00428526103
Iter: 68 loss: 0.00427131075
Iter: 69 loss: 0.00438509602
Iter: 70 loss: 0.00427043159
Iter: 71 loss: 0.00426518545
Iter: 72 loss: 0.00426475238
Iter: 73 loss: 0.0042609619
Iter: 74 loss: 0.00426991424
Iter: 75 loss: 0.00425959378
Iter: 76 loss: 0.00425586384
Iter: 77 loss: 0.0042502
Iter: 78 loss: 0.00425009243
Iter: 79 loss: 0.00424440391
Iter: 80 loss: 0.00427326933
Iter: 81 loss: 0.00424347
Iter: 82 loss: 0.00424024556
Iter: 83 loss: 0.00425642
Iter: 84 loss: 0.00423970539
Iter: 85 loss: 0.00423780456
Iter: 86 loss: 0.00424560905
Iter: 87 loss: 0.00423738733
Iter: 88 loss: 0.00423597731
Iter: 89 loss: 0.00424356572
Iter: 90 loss: 0.0042357631
Iter: 91 loss: 0.00423497194
Iter: 92 loss: 0.00424373848
Iter: 93 loss: 0.00423495518
Iter: 94 loss: 0.00423440337
Iter: 95 loss: 0.00423602201
Iter: 96 loss: 0.00423423154
Iter: 97 loss: 0.00423378497
Iter: 98 loss: 0.00423559546
Iter: 99 loss: 0.00423368625
Iter: 100 loss: 0.00423342548
Iter: 101 loss: 0.00423376169
Iter: 102 loss: 0.00423329324
Iter: 103 loss: 0.00423320569
Iter: 104 loss: 0.00423317309
Iter: 105 loss: 0.00423307531
Iter: 106 loss: 0.00423325785
Iter: 107 loss: 0.00423303433
Iter: 108 loss: 0.00423294678
Iter: 109 loss: 0.00423301198
Iter: 110 loss: 0.00423289
Iter: 111 loss: 0.00423281081
Iter: 112 loss: 0.00423283037
Iter: 113 loss: 0.00423275074
Iter: 114 loss: 0.00423266226
Iter: 115 loss: 0.00423297
Iter: 116 loss: 0.00423263712
Iter: 117 loss: 0.00423255889
Iter: 118 loss: 0.00423282245
Iter: 119 loss: 0.00423253747
Iter: 120 loss: 0.00423247
Iter: 121 loss: 0.00423265528
Iter: 122 loss: 0.00423244806
Iter: 123 loss: 0.00423238799
Iter: 124 loss: 0.00423286
Iter: 125 loss: 0.0042323838
Iter: 126 loss: 0.00423234422
Iter: 127 loss: 0.00423260499
Iter: 128 loss: 0.00423233677
Iter: 129 loss: 0.00423230929
Iter: 130 loss: 0.0042323852
Iter: 131 loss: 0.00423229951
Iter: 132 loss: 0.00423227437
Iter: 133 loss: 0.00423229672
Iter: 134 loss: 0.0042322604
Iter: 135 loss: 0.00423224
Iter: 136 loss: 0.00423254119
Iter: 137 loss: 0.00423224038
Iter: 138 loss: 0.00423222687
Iter: 139 loss: 0.00423235819
Iter: 140 loss: 0.00423222594
Iter: 141 loss: 0.00423221802
Iter: 142 loss: 0.00423220731
Iter: 143 loss: 0.00423220498
Iter: 144 loss: 0.00423219055
Iter: 145 loss: 0.00423220359
Iter: 146 loss: 0.00423218124
Iter: 147 loss: 0.00423216633
Iter: 148 loss: 0.0042322
Iter: 149 loss: 0.00423216075
Iter: 150 loss: 0.00423214771
Iter: 151 loss: 0.00423220824
Iter: 152 loss: 0.00423214631
Iter: 153 loss: 0.00423213607
Iter: 154 loss: 0.00423216866
Iter: 155 loss: 0.00423213374
Iter: 156 loss: 0.00423212675
Iter: 157 loss: 0.00423218403
Iter: 158 loss: 0.00423212815
Iter: 159 loss: 0.00423212256
Iter: 160 loss: 0.0042321505
Iter: 161 loss: 0.00423212256
Iter: 162 loss: 0.00423212
Iter: 163 loss: 0.00423213
Iter: 164 loss: 0.00423211791
Iter: 165 loss: 0.00423211511
Iter: 166 loss: 0.00423211791
Iter: 167 loss: 0.00423211372
Iter: 168 loss: 0.00423211232
Iter: 169 loss: 0.00423213374
Iter: 170 loss: 0.00423211139
Iter: 171 loss: 0.00423211232
Iter: 172 loss: 0.00423212349
Iter: 173 loss: 0.00423211139
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4
+ date
Tue Oct 27 17:34:35 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c610fa840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c610e6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c610432f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c610567b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c61056ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c61056488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c6100c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60fef268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60fc5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60f54ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60f7e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60f35f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60ed7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60f16950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60e92ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60e55ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60e72d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60f16488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60f54510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60e72510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60d95950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60dbbb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60dbb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60d2db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60d2d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60d2d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60cde7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60c91d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60cbb488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60c642f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60c66730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60c27f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60c4c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60c641e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c60c4cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5c486edbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.316895574
Iter: 2 loss: 9959.69922
Iter: 3 loss: 1158.65833
Iter: 4 loss: 0.316895187
Iter: 5 loss: 771.323792
Iter: 6 loss: 402.941315
Iter: 7 loss: 0.316892922
Iter: 8 loss: 0.205787852
Iter: 9 loss: 0.295454502
Iter: 10 loss: 0.192695677
Iter: 11 loss: 0.179231644
Iter: 12 loss: 0.135588557
Iter: 13 loss: 0.133169532
Iter: 14 loss: 745.44635
Iter: 15 loss: 86.4532547
Iter: 16 loss: 65.0987549
Iter: 17 loss: 0.338344097
Iter: 18 loss: 0.157027096
Iter: 19 loss: 0.129970908
Iter: 20 loss: 0.117817745
Iter: 21 loss: 0.117717586
Iter: 22 loss: 0.106627494
Iter: 23 loss: 0.342470109
Iter: 24 loss: 0.106289521
Iter: 25 loss: 0.0916726
Iter: 26 loss: 0.132792413
Iter: 27 loss: 0.0874577761
Iter: 28 loss: 0.0810821652
Iter: 29 loss: 0.163719475
Iter: 30 loss: 0.0802780837
Iter: 31 loss: 0.0727046132
Iter: 32 loss: 1865.67529
Iter: 33 loss: 0.0727046281
Iter: 34 loss: 0.0684189871
Iter: 35 loss: 0.146783799
Iter: 36 loss: 0.0681710169
Iter: 37 loss: 0.064976424
Iter: 38 loss: 0.210080236
Iter: 39 loss: 0.0649747849
Iter: 40 loss: 0.0614706948
Iter: 41 loss: 0.06234961
Iter: 42 loss: 0.0593645871
Iter: 43 loss: 0.055251129
Iter: 44 loss: 0.124585852
Iter: 45 loss: 0.0550315566
Iter: 46 loss: 0.052558355
Iter: 47 loss: 0.11363472
Iter: 48 loss: 0.0525181815
Iter: 49 loss: 0.0508244261
Iter: 50 loss: 0.0537043959
Iter: 51 loss: 0.0500357226
Iter: 52 loss: 0.0465258732
Iter: 53 loss: 0.0768329576
Iter: 54 loss: 0.0463483632
Iter: 55 loss: 0.0442221
Iter: 56 loss: 0.04935316
Iter: 57 loss: 0.0435051695
Iter: 58 loss: 0.0424871072
Iter: 59 loss: 0.0449571535
Iter: 60 loss: 0.0420191512
Iter: 61 loss: 0.0412757136
Iter: 62 loss: 0.0452582613
Iter: 63 loss: 0.0411135927
Iter: 64 loss: 0.0399954841
Iter: 65 loss: 0.0395987704
Iter: 66 loss: 0.0390574969
Iter: 67 loss: 0.0369412526
Iter: 68 loss: 0.0413488299
Iter: 69 loss: 0.0361970961
Iter: 70 loss: 0.0345560163
Iter: 71 loss: 0.0441238247
Iter: 72 loss: 0.0342390947
Iter: 73 loss: 0.033649087
Iter: 74 loss: 0.0368215553
Iter: 75 loss: 0.0335279405
Iter: 76 loss: 0.0325677395
Iter: 77 loss: 0.0328678973
Iter: 78 loss: 0.0318419784
Iter: 79 loss: 0.0306767896
Iter: 80 loss: 0.0328435935
Iter: 81 loss: 0.0302100703
Iter: 82 loss: 0.0296585336
Iter: 83 loss: 0.0323523954
Iter: 84 loss: 0.0295347832
Iter: 85 loss: 0.0290030576
Iter: 86 loss: 0.0324214175
Iter: 87 loss: 0.0289312061
Iter: 88 loss: 0.0283378139
Iter: 89 loss: 0.0279060528
Iter: 90 loss: 0.0276942793
Iter: 91 loss: 0.0268882271
Iter: 92 loss: 0.0302797388
Iter: 93 loss: 0.0267527141
Iter: 94 loss: 0.0261518639
Iter: 95 loss: 0.0337613039
Iter: 96 loss: 0.0261262543
Iter: 97 loss: 0.0256468654
Iter: 98 loss: 0.0244834572
Iter: 99 loss: 0.0494919308
Iter: 100 loss: 0.0244152732
Iter: 101 loss: 0.0229208097
Iter: 102 loss: 0.032920219
Iter: 103 loss: 0.0227222536
Iter: 104 loss: 0.0215513259
Iter: 105 loss: 0.027250139
Iter: 106 loss: 0.0213187449
Iter: 107 loss: 0.0194694325
Iter: 108 loss: 0.0244459361
Iter: 109 loss: 0.0188180245
Iter: 110 loss: 0.0168661177
Iter: 111 loss: 0.0250197519
Iter: 112 loss: 0.0161789525
Iter: 113 loss: 0.0149058448
Iter: 114 loss: 0.0409605
Iter: 115 loss: 0.0148972096
Iter: 116 loss: 0.0140585
Iter: 117 loss: 0.0224140119
Iter: 118 loss: 0.0140108699
Iter: 119 loss: 0.0137249604
Iter: 120 loss: 0.0136506502
Iter: 121 loss: 0.0133014396
Iter: 122 loss: 0.0139116086
Iter: 123 loss: 0.0131554063
Iter: 124 loss: 0.0127189597
Iter: 125 loss: 0.0155287143
Iter: 126 loss: 0.0126463939
Iter: 127 loss: 0.0122022033
Iter: 128 loss: 0.0170085691
Iter: 129 loss: 0.0121948905
Iter: 130 loss: 0.0119391289
Iter: 131 loss: 0.0126620466
Iter: 132 loss: 0.011854386
Iter: 133 loss: 0.0114672752
Iter: 134 loss: 0.011095305
Iter: 135 loss: 0.0110046342
Iter: 136 loss: 0.0109121799
Iter: 137 loss: 0.0107670259
Iter: 138 loss: 0.0105817681
Iter: 139 loss: 0.013548498
Iter: 140 loss: 0.0105812289
Iter: 141 loss: 0.0105151068
Iter: 142 loss: 0.0103788264
Iter: 143 loss: 0.0127197243
Iter: 144 loss: 0.0103759374
Iter: 145 loss: 0.0101676295
Iter: 146 loss: 0.0129056629
Iter: 147 loss: 0.0101664513
Iter: 148 loss: 0.0099945711
Iter: 149 loss: 0.0100406762
Iter: 150 loss: 0.00986917224
Iter: 151 loss: 0.00975160301
Iter: 152 loss: 0.0097493967
Iter: 153 loss: 0.00962271169
Iter: 154 loss: 0.0109924451
Iter: 155 loss: 0.00961859524
Iter: 156 loss: 0.00956042763
Iter: 157 loss: 0.0095175039
Iter: 158 loss: 0.00949749909
Iter: 159 loss: 0.00948507711
Iter: 160 loss: 0.00945119467
Iter: 161 loss: 0.00938131474
Iter: 162 loss: 0.00971441
Iter: 163 loss: 0.00936712883
Iter: 164 loss: 0.00934123155
Iter: 165 loss: 0.00928362086
Iter: 166 loss: 0.0101787988
Iter: 167 loss: 0.00928088464
Iter: 168 loss: 0.00922288559
Iter: 169 loss: 0.0092119
Iter: 170 loss: 0.00917536207
Iter: 171 loss: 0.00917497836
Iter: 172 loss: 0.00915325806
Iter: 173 loss: 0.00910123531
Iter: 174 loss: 0.00975933764
Iter: 175 loss: 0.00909647
Iter: 176 loss: 0.0090514794
Iter: 177 loss: 0.00916284509
Iter: 178 loss: 0.00903503597
Iter: 179 loss: 0.00898256712
Iter: 180 loss: 0.00906806439
Iter: 181 loss: 0.00895891
Iter: 182 loss: 0.00892234687
Iter: 183 loss: 0.00940490142
Iter: 184 loss: 0.00892209634
Iter: 185 loss: 0.00889035314
Iter: 186 loss: 0.00898940675
Iter: 187 loss: 0.00888104178
Iter: 188 loss: 0.0088381134
Iter: 189 loss: 0.00886405632
Iter: 190 loss: 0.00881071202
Iter: 191 loss: 0.00876218174
Iter: 192 loss: 0.00899374858
Iter: 193 loss: 0.0087533379
Iter: 194 loss: 0.00876072608
Iter: 195 loss: 0.00872599
Iter: 196 loss: 0.00871934742
Iter: 197 loss: 0.00870082248
Iter: 198 loss: 0.00880794413
Iter: 199 loss: 0.00869527459
Iter: 200 loss: 0.00867605861
Iter: 201 loss: 0.00869284105
Iter: 202 loss: 0.00866487063
Iter: 203 loss: 0.00865552388
Iter: 204 loss: 0.00863216445
Iter: 205 loss: 0.00885462482
Iter: 206 loss: 0.00862891
Iter: 207 loss: 0.00860249065
Iter: 208 loss: 0.00861357711
Iter: 209 loss: 0.00858429726
Iter: 210 loss: 0.00857602246
Iter: 211 loss: 0.0086468691
Iter: 212 loss: 0.0085755093
Iter: 213 loss: 0.00856477581
Iter: 214 loss: 0.00859809108
Iter: 215 loss: 0.00856159069
Iter: 216 loss: 0.00854461454
Iter: 217 loss: 0.00854565296
Iter: 218 loss: 0.00853127148
Iter: 219 loss: 0.00851406716
Iter: 220 loss: 0.00852906052
Iter: 221 loss: 0.00850386452
Iter: 222 loss: 0.0084857475
Iter: 223 loss: 0.00877551
Iter: 224 loss: 0.00848575588
Iter: 225 loss: 0.00846939348
Iter: 226 loss: 0.00849002
Iter: 227 loss: 0.0084608607
Iter: 228 loss: 0.00845493656
Iter: 229 loss: 0.00845223479
Iter: 230 loss: 0.00844695233
Iter: 231 loss: 0.00848235562
Iter: 232 loss: 0.00844639912
Iter: 233 loss: 0.00844304822
Iter: 234 loss: 0.00844673906
Iter: 235 loss: 0.00844120048
Iter: 236 loss: 0.00843440462
Iter: 237 loss: 0.00842304528
Iter: 238 loss: 0.00842301
Iter: 239 loss: 0.00841545
Iter: 240 loss: 0.00846034382
Iter: 241 loss: 0.00841451064
Iter: 242 loss: 0.0084109176
Iter: 243 loss: 0.00843940675
Iter: 244 loss: 0.00841065124
Iter: 245 loss: 0.0084059136
Iter: 246 loss: 0.00839268696
Iter: 247 loss: 0.00846298411
Iter: 248 loss: 0.00838857051
Iter: 249 loss: 0.00838013832
Iter: 250 loss: 0.0084174471
Iter: 251 loss: 0.00837845
Iter: 252 loss: 0.00837261137
Iter: 253 loss: 0.00838964339
Iter: 254 loss: 0.008370772
Iter: 255 loss: 0.00836231839
Iter: 256 loss: 0.00837785937
Iter: 257 loss: 0.00835868716
Iter: 258 loss: 0.00835287571
Iter: 259 loss: 0.00835053436
Iter: 260 loss: 0.00834741537
Iter: 261 loss: 0.00833848864
Iter: 262 loss: 0.00833665766
Iter: 263 loss: 0.00833076611
Iter: 264 loss: 0.00832955167
Iter: 265 loss: 0.00832429528
Iter: 266 loss: 0.00831901468
Iter: 267 loss: 0.00831839163
Iter: 268 loss: 0.00831460394
Iter: 269 loss: 0.008310128
Iter: 270 loss: 0.00831012055
Iter: 271 loss: 0.00830797572
Iter: 272 loss: 0.0083066728
Iter: 273 loss: 0.00830581412
Iter: 274 loss: 0.00830338523
Iter: 275 loss: 0.00830338709
Iter: 276 loss: 0.0083013624
Iter: 277 loss: 0.00829910394
Iter: 278 loss: 0.00829879194
Iter: 279 loss: 0.00829498656
Iter: 280 loss: 0.0082896268
Iter: 281 loss: 0.00828942843
Iter: 282 loss: 0.00828370731
Iter: 283 loss: 0.00827520154
Iter: 284 loss: 0.00827502
Iter: 285 loss: 0.00826587714
Iter: 286 loss: 0.00836458616
Iter: 287 loss: 0.0082656648
Iter: 288 loss: 0.00825970247
Iter: 289 loss: 0.00826743804
Iter: 290 loss: 0.00825668685
Iter: 291 loss: 0.00825225934
Iter: 292 loss: 0.00825443305
Iter: 293 loss: 0.00824928563
Iter: 294 loss: 0.00824720692
Iter: 295 loss: 0.00824124552
Iter: 296 loss: 0.00826753397
Iter: 297 loss: 0.00823897868
Iter: 298 loss: 0.00823849719
Iter: 299 loss: 0.00823639892
Iter: 300 loss: 0.00823484268
Iter: 301 loss: 0.00823430065
Iter: 302 loss: 0.00823341
Iter: 303 loss: 0.00823055301
Iter: 304 loss: 0.00823045615
Iter: 305 loss: 0.0082283318
Iter: 306 loss: 0.0082282545
Iter: 307 loss: 0.00822695345
Iter: 308 loss: 0.00822356
Iter: 309 loss: 0.00825112686
Iter: 310 loss: 0.00822296
Iter: 311 loss: 0.00821799226
Iter: 312 loss: 0.00821913593
Iter: 313 loss: 0.00821434
Iter: 314 loss: 0.00820784178
Iter: 315 loss: 0.00820764527
Iter: 316 loss: 0.00820258819
Iter: 317 loss: 0.00819577463
Iter: 318 loss: 0.00821694173
Iter: 319 loss: 0.00819377881
Iter: 320 loss: 0.00818885677
Iter: 321 loss: 0.00820991583
Iter: 322 loss: 0.00818781834
Iter: 323 loss: 0.00818618573
Iter: 324 loss: 0.00818569213
Iter: 325 loss: 0.00818343647
Iter: 326 loss: 0.00817958079
Iter: 327 loss: 0.00817957148
Iter: 328 loss: 0.00817756727
Iter: 329 loss: 0.00817160588
Iter: 330 loss: 0.00818975
Iter: 331 loss: 0.00816865265
Iter: 332 loss: 0.00816532224
Iter: 333 loss: 0.00816393271
Iter: 334 loss: 0.0081599988
Iter: 335 loss: 0.00818339549
Iter: 336 loss: 0.00815949403
Iter: 337 loss: 0.00815648213
Iter: 338 loss: 0.00819490105
Iter: 339 loss: 0.00815645698
Iter: 340 loss: 0.00815369282
Iter: 341 loss: 0.00815479271
Iter: 342 loss: 0.00815176778
Iter: 343 loss: 0.00814924482
Iter: 344 loss: 0.00814760756
Iter: 345 loss: 0.00814662129
Iter: 346 loss: 0.00814259797
Iter: 347 loss: 0.00816254877
Iter: 348 loss: 0.00814189203
Iter: 349 loss: 0.00813927129
Iter: 350 loss: 0.00814093836
Iter: 351 loss: 0.0081375977
Iter: 352 loss: 0.00813288428
Iter: 353 loss: 0.0081367325
Iter: 354 loss: 0.00813004281
Iter: 355 loss: 0.00812777691
Iter: 356 loss: 0.00812721066
Iter: 357 loss: 0.00812502
Iter: 358 loss: 0.00812090654
Iter: 359 loss: 0.00821504183
Iter: 360 loss: 0.00812089816
Iter: 361 loss: 0.00811548624
Iter: 362 loss: 0.00811527204
Iter: 363 loss: 0.00811106898
Iter: 364 loss: 0.00810490362
Iter: 365 loss: 0.00812326837
Iter: 366 loss: 0.00810304284
Iter: 367 loss: 0.00809723418
Iter: 368 loss: 0.00818552077
Iter: 369 loss: 0.00809722673
Iter: 370 loss: 0.00809549075
Iter: 371 loss: 0.00809537619
Iter: 372 loss: 0.00809379108
Iter: 373 loss: 0.00809250586
Iter: 374 loss: 0.00809203181
Iter: 375 loss: 0.00808971189
Iter: 376 loss: 0.00808248669
Iter: 377 loss: 0.00809553266
Iter: 378 loss: 0.00807769783
Iter: 379 loss: 0.00807313062
Iter: 380 loss: 0.00807295181
Iter: 381 loss: 0.00806982256
Iter: 382 loss: 0.00806702301
Iter: 383 loss: 0.0080662407
Iter: 384 loss: 0.00806203298
Iter: 385 loss: 0.0080635827
Iter: 386 loss: 0.00805909839
Iter: 387 loss: 0.00805674121
Iter: 388 loss: 0.00806787331
Iter: 389 loss: 0.00805630162
Iter: 390 loss: 0.00805381406
Iter: 391 loss: 0.00805610232
Iter: 392 loss: 0.00805239752
Iter: 393 loss: 0.00804547779
Iter: 394 loss: 0.00806951523
Iter: 395 loss: 0.00804365613
Iter: 396 loss: 0.0080372449
Iter: 397 loss: 0.00806126278
Iter: 398 loss: 0.00803568494
Iter: 399 loss: 0.00803137757
Iter: 400 loss: 0.00805119611
Iter: 401 loss: 0.00803056452
Iter: 402 loss: 0.00803188048
Iter: 403 loss: 0.00802840386
Iter: 404 loss: 0.00802738499
Iter: 405 loss: 0.00802550651
Iter: 406 loss: 0.00806764
Iter: 407 loss: 0.00802550092
Iter: 408 loss: 0.00802254304
Iter: 409 loss: 0.00801811833
Iter: 410 loss: 0.0080180224
Iter: 411 loss: 0.00801374391
Iter: 412 loss: 0.00801340584
Iter: 413 loss: 0.00801021047
Iter: 414 loss: 0.00800461136
Iter: 415 loss: 0.00806368329
Iter: 416 loss: 0.00800446514
Iter: 417 loss: 0.00800001156
Iter: 418 loss: 0.00799605623
Iter: 419 loss: 0.00799490232
Iter: 420 loss: 0.00800401624
Iter: 421 loss: 0.00799435098
Iter: 422 loss: 0.0079939086
Iter: 423 loss: 0.00799274165
Iter: 424 loss: 0.0080020465
Iter: 425 loss: 0.00799252931
Iter: 426 loss: 0.0079909
Iter: 427 loss: 0.00799135
Iter: 428 loss: 0.00798973534
Iter: 429 loss: 0.0079890918
Iter: 430 loss: 0.00798734743
Iter: 431 loss: 0.00799836311
Iter: 432 loss: 0.00798689388
Iter: 433 loss: 0.00798530597
Iter: 434 loss: 0.00798407197
Iter: 435 loss: 0.00798357464
Iter: 436 loss: 0.00798130222
Iter: 437 loss: 0.00801674463
Iter: 438 loss: 0.00798130222
Iter: 439 loss: 0.00797995552
Iter: 440 loss: 0.00798822287
Iter: 441 loss: 0.00797977857
Iter: 442 loss: 0.00797878
Iter: 443 loss: 0.0079773441
Iter: 444 loss: 0.00797729474
Iter: 445 loss: 0.0079738088
Iter: 446 loss: 0.00798570551
Iter: 447 loss: 0.00797288213
Iter: 448 loss: 0.0079706125
Iter: 449 loss: 0.00797179155
Iter: 450 loss: 0.00796910562
Iter: 451 loss: 0.00796768907
Iter: 452 loss: 0.0079662567
Iter: 453 loss: 0.0079659652
Iter: 454 loss: 0.00796539709
Iter: 455 loss: 0.00796514563
Iter: 456 loss: 0.00796482526
Iter: 457 loss: 0.0079642171
Iter: 458 loss: 0.00797756389
Iter: 459 loss: 0.00796422362
Iter: 460 loss: 0.00796320103
Iter: 461 loss: 0.0079682013
Iter: 462 loss: 0.00796302594
Iter: 463 loss: 0.00796259195
Iter: 464 loss: 0.00796428509
Iter: 465 loss: 0.00796248764
Iter: 466 loss: 0.0079617193
Iter: 467 loss: 0.00796024222
Iter: 468 loss: 0.00799161475
Iter: 469 loss: 0.00796023849
Iter: 470 loss: 0.00795873627
Iter: 471 loss: 0.00797217712
Iter: 472 loss: 0.00795865431
Iter: 473 loss: 0.00795751
Iter: 474 loss: 0.00795666873
Iter: 475 loss: 0.00795628503
Iter: 476 loss: 0.00795392133
Iter: 477 loss: 0.00796389394
Iter: 478 loss: 0.00795342587
Iter: 479 loss: 0.00795242935
Iter: 480 loss: 0.00795135181
Iter: 481 loss: 0.00795118324
Iter: 482 loss: 0.0079493206
Iter: 483 loss: 0.00796199683
Iter: 484 loss: 0.00794913713
Iter: 485 loss: 0.00794796366
Iter: 486 loss: 0.00794643722
Iter: 487 loss: 0.00794632547
Iter: 488 loss: 0.00794736203
Iter: 489 loss: 0.00794574339
Iter: 490 loss: 0.00794547424
Iter: 491 loss: 0.00794512872
Iter: 492 loss: 0.00794509612
Iter: 493 loss: 0.00794497784
Iter: 494 loss: 0.00794473663
Iter: 495 loss: 0.00794438
Iter: 496 loss: 0.00794453733
Iter: 497 loss: 0.00794412382
Iter: 498 loss: 0.00794366188
Iter: 499 loss: 0.00794283859
Iter: 500 loss: 0.00796338916
Iter: 501 loss: 0.00794283673
Iter: 502 loss: 0.00794176105
Iter: 503 loss: 0.00795348547
Iter: 504 loss: 0.00794172846
Iter: 505 loss: 0.00794083159
Iter: 506 loss: 0.00794013124
Iter: 507 loss: 0.00793984
Iter: 508 loss: 0.00793898851
Iter: 509 loss: 0.00794672
Iter: 510 loss: 0.00793895
Iter: 511 loss: 0.00793784298
Iter: 512 loss: 0.00793901086
Iter: 513 loss: 0.0079372162
Iter: 514 loss: 0.00793648139
Iter: 515 loss: 0.00793768652
Iter: 516 loss: 0.00793614425
Iter: 517 loss: 0.00793554354
Iter: 518 loss: 0.00793900713
Iter: 519 loss: 0.00793546066
Iter: 520 loss: 0.0079355333
Iter: 521 loss: 0.00793517474
Iter: 522 loss: 0.00793503411
Iter: 523 loss: 0.00793476682
Iter: 524 loss: 0.00793972239
Iter: 525 loss: 0.00793475565
Iter: 526 loss: 0.00793455448
Iter: 527 loss: 0.00793691
Iter: 528 loss: 0.00793456566
Iter: 529 loss: 0.00793442596
Iter: 530 loss: 0.00793401059
Iter: 531 loss: 0.00793490373
Iter: 532 loss: 0.00793374702
Iter: 533 loss: 0.00793255307
Iter: 534 loss: 0.00793402083
Iter: 535 loss: 0.00793192443
Iter: 536 loss: 0.00793155096
Iter: 537 loss: 0.00793141499
Iter: 538 loss: 0.00793104433
Iter: 539 loss: 0.00793372188
Iter: 540 loss: 0.00793101
Iter: 541 loss: 0.00793079287
Iter: 542 loss: 0.00793035328
Iter: 543 loss: 0.00793849863
Iter: 544 loss: 0.00793035794
Iter: 545 loss: 0.0079298839
Iter: 546 loss: 0.00793330185
Iter: 547 loss: 0.00792982709
Iter: 548 loss: 0.00792959705
Iter: 549 loss: 0.00792957656
Iter: 550 loss: 0.00792940613
Iter: 551 loss: 0.00792920869
Iter: 552 loss: 0.0079291882
Iter: 553 loss: 0.00792909227
Iter: 554 loss: 0.00792905223
Iter: 555 loss: 0.00792894047
Iter: 556 loss: 0.00792957656
Iter: 557 loss: 0.00792893209
Iter: 558 loss: 0.00792889111
Iter: 559 loss: 0.00792884454
Iter: 560 loss: 0.00792883057
Iter: 561 loss: 0.00792871229
Iter: 562 loss: 0.00792841893
Iter: 563 loss: 0.00793233328
Iter: 564 loss: 0.0079284152
Iter: 565 loss: 0.00792823639
Iter: 566 loss: 0.00792853907
Iter: 567 loss: 0.00792815
Iter: 568 loss: 0.00792794116
Iter: 569 loss: 0.00792797655
Iter: 570 loss: 0.0079277819
Iter: 571 loss: 0.00792756584
Iter: 572 loss: 0.0079288967
Iter: 573 loss: 0.00792753883
Iter: 574 loss: 0.00792729
Iter: 575 loss: 0.00792767759
Iter: 576 loss: 0.00792717375
Iter: 577 loss: 0.00792696
Iter: 578 loss: 0.00792653114
Iter: 579 loss: 0.00793404505
Iter: 580 loss: 0.00792653486
Iter: 581 loss: 0.00792607479
Iter: 582 loss: 0.00792607199
Iter: 583 loss: 0.00792584103
Iter: 584 loss: 0.00792582892
Iter: 585 loss: 0.0079257451
Iter: 586 loss: 0.00792563334
Iter: 587 loss: 0.00792564172
Iter: 588 loss: 0.00792585593
Iter: 589 loss: 0.00792559423
Iter: 590 loss: 0.00792554114
Iter: 591 loss: 0.00792573
Iter: 592 loss: 0.00792553835
Iter: 593 loss: 0.00792549551
Iter: 594 loss: 0.00792542472
Iter: 595 loss: 0.00792595651
Iter: 596 loss: 0.00792539772
Iter: 597 loss: 0.00792533
Iter: 598 loss: 0.00792525709
Iter: 599 loss: 0.00792524405
Iter: 600 loss: 0.00792510249
Iter: 601 loss: 0.0079255579
Iter: 602 loss: 0.00792506244
Iter: 603 loss: 0.00792494789
Iter: 604 loss: 0.00792489573
Iter: 605 loss: 0.00792484358
Iter: 606 loss: 0.00792482868
Iter: 607 loss: 0.00792476907
Iter: 608 loss: 0.00792472251
Iter: 609 loss: 0.00792455301
Iter: 610 loss: 0.00792533625
Iter: 611 loss: 0.00792450644
Iter: 612 loss: 0.00792433694
Iter: 613 loss: 0.00792504475
Iter: 614 loss: 0.00792429782
Iter: 615 loss: 0.00792425
Iter: 616 loss: 0.00792424381
Iter: 617 loss: 0.00792415254
Iter: 618 loss: 0.0079239551
Iter: 619 loss: 0.00792632531
Iter: 620 loss: 0.00792393461
Iter: 621 loss: 0.00792399794
Iter: 622 loss: 0.00792391412
Iter: 623 loss: 0.00792390853
Iter: 624 loss: 0.00792389736
Iter: 625 loss: 0.00792389456
Iter: 626 loss: 0.00792385358
Iter: 627 loss: 0.00792381726
Iter: 628 loss: 0.00792381167
Iter: 629 loss: 0.00792374928
Iter: 630 loss: 0.0079236934
Iter: 631 loss: 0.00792367
Iter: 632 loss: 0.00792361423
Iter: 633 loss: 0.00792388059
Iter: 634 loss: 0.00792359561
Iter: 635 loss: 0.00792355463
Iter: 636 loss: 0.00792366
Iter: 637 loss: 0.00792352669
Iter: 638 loss: 0.00792345591
Iter: 639 loss: 0.00792364776
Iter: 640 loss: 0.00792343356
Iter: 641 loss: 0.00792338
Iter: 642 loss: 0.00792374276
Iter: 643 loss: 0.00792337302
Iter: 644 loss: 0.00792332
Iter: 645 loss: 0.00792341866
Iter: 646 loss: 0.00792328734
Iter: 647 loss: 0.00792325754
Iter: 648 loss: 0.00792323146
Iter: 649 loss: 0.0079232147
Iter: 650 loss: 0.00792321563
Iter: 651 loss: 0.00792319514
Iter: 652 loss: 0.00792317651
Iter: 653 loss: 0.00792326685
Iter: 654 loss: 0.00792318396
Iter: 655 loss: 0.00792316254
Iter: 656 loss: 0.00792321
Iter: 657 loss: 0.00792315789
Iter: 658 loss: 0.00792313833
Iter: 659 loss: 0.00792311691
Iter: 660 loss: 0.0079231225
Iter: 661 loss: 0.0079231
Iter: 662 loss: 0.00792310387
Iter: 663 loss: 0.00792307593
Iter: 664 loss: 0.00792305917
Iter: 665 loss: 0.00792300701
Iter: 666 loss: 0.00792360678
Iter: 667 loss: 0.00792298652
Iter: 668 loss: 0.00792293064
Iter: 669 loss: 0.00792343449
Iter: 670 loss: 0.00792292319
Iter: 671 loss: 0.0079228878
Iter: 672 loss: 0.00792319328
Iter: 673 loss: 0.00792288594
Iter: 674 loss: 0.00792283937
Iter: 675 loss: 0.00792285055
Iter: 676 loss: 0.00792281702
Iter: 677 loss: 0.00792276859
Iter: 678 loss: 0.00792317465
Iter: 679 loss: 0.0079227658
Iter: 680 loss: 0.0079227332
Iter: 681 loss: 0.00792272575
Iter: 682 loss: 0.00792270899
Iter: 683 loss: 0.00792271458
Iter: 684 loss: 0.0079226885
Iter: 685 loss: 0.00792267174
Iter: 686 loss: 0.00792274158
Iter: 687 loss: 0.00792267546
Iter: 688 loss: 0.00792264938
Iter: 689 loss: 0.0079227034
Iter: 690 loss: 0.00792265125
Iter: 691 loss: 0.00792263355
Iter: 692 loss: 0.00792261586
Iter: 693 loss: 0.00792261399
Iter: 694 loss: 0.00792259
Iter: 695 loss: 0.00792257115
Iter: 696 loss: 0.00792256277
Iter: 697 loss: 0.00792253204
Iter: 698 loss: 0.00792249292
Iter: 699 loss: 0.0079224864
Iter: 700 loss: 0.00792246
Iter: 701 loss: 0.00792245287
Iter: 702 loss: 0.00792243145
Iter: 703 loss: 0.00792251807
Iter: 704 loss: 0.00792241096
Iter: 705 loss: 0.00792238489
Iter: 706 loss: 0.00792235322
Iter: 707 loss: 0.0079223495
Iter: 708 loss: 0.00792232715
Iter: 709 loss: 0.00792231597
Iter: 710 loss: 0.00792231411
Iter: 711 loss: 0.00792227685
Iter: 712 loss: 0.00792227
Iter: 713 loss: 0.00792230759
Iter: 714 loss: 0.00792225916
Iter: 715 loss: 0.00792225637
Iter: 716 loss: 0.00792239793
Iter: 717 loss: 0.00792226382
Iter: 718 loss: 0.00792225
Iter: 719 loss: 0.00792224333
Iter: 720 loss: 0.00792224146
Iter: 721 loss: 0.00792223401
Iter: 722 loss: 0.00792223215
Iter: 723 loss: 0.00792222377
Iter: 724 loss: 0.00792220607
Iter: 725 loss: 0.00792218745
Iter: 726 loss: 0.00792250875
Iter: 727 loss: 0.00792219117
Iter: 728 loss: 0.00792216696
Iter: 729 loss: 0.00792218745
Iter: 730 loss: 0.00792214088
Iter: 731 loss: 0.00792212412
Iter: 732 loss: 0.0079223495
Iter: 733 loss: 0.00792211667
Iter: 734 loss: 0.00792210642
Iter: 735 loss: 0.00792215671
Iter: 736 loss: 0.00792209245
Iter: 737 loss: 0.00792208128
Iter: 738 loss: 0.00792210177
Iter: 739 loss: 0.00792206079
Iter: 740 loss: 0.00792204682
Iter: 741 loss: 0.00792204868
Iter: 742 loss: 0.00792204402
Iter: 743 loss: 0.00792201608
Iter: 744 loss: 0.00792225171
Iter: 745 loss: 0.00792202
Iter: 746 loss: 0.00792200305
Iter: 747 loss: 0.00792213343
Iter: 748 loss: 0.00792199187
Iter: 749 loss: 0.00792198814
Iter: 750 loss: 0.00792198256
Iter: 751 loss: 0.00792197
Iter: 752 loss: 0.00792196579
Iter: 753 loss: 0.00792196579
Iter: 754 loss: 0.00792195182
Iter: 755 loss: 0.00792196766
Iter: 756 loss: 0.00792194158
Iter: 757 loss: 0.00792193413
Iter: 758 loss: 0.00792190433
Iter: 759 loss: 0.00792189129
Iter: 760 loss: 0.00792186148
Iter: 761 loss: 0.00792181771
Iter: 762 loss: 0.00792182051
Iter: 763 loss: 0.00792180095
Iter: 764 loss: 0.0079217758
Iter: 765 loss: 0.00792178139
Iter: 766 loss: 0.00792177
Iter: 767 loss: 0.00792176649
Iter: 768 loss: 0.00792175066
Iter: 769 loss: 0.00792175531
Iter: 770 loss: 0.00792175345
Iter: 771 loss: 0.00792173389
Iter: 772 loss: 0.00792173
Iter: 773 loss: 0.00792173389
Iter: 774 loss: 0.00792172365
Iter: 775 loss: 0.00792171806
Iter: 776 loss: 0.00792172085
Iter: 777 loss: 0.00792172
Iter: 778 loss: 0.00792170689
Iter: 779 loss: 0.00792193599
Iter: 780 loss: 0.00792169943
Iter: 781 loss: 0.00792169943
Iter: 782 loss: 0.00792170595
Iter: 783 loss: 0.00792170409
Iter: 784 loss: 0.00792169385
Iter: 785 loss: 0.00792169943
Iter: 786 loss: 0.00792169664
Iter: 787 loss: 0.00792168826
Iter: 788 loss: 0.00792168826
Iter: 789 loss: 0.00792168919
Iter: 790 loss: 0.00792169571
Iter: 791 loss: 0.00792167801
Iter: 792 loss: 0.00792168267
Iter: 793 loss: 0.00792167615
Iter: 794 loss: 0.00792167522
Iter: 795 loss: 0.00792166684
Iter: 796 loss: 0.00792169198
Iter: 797 loss: 0.00792165846
Iter: 798 loss: 0.00792165287
Iter: 799 loss: 0.00792167336
Iter: 800 loss: 0.00792165194
Iter: 801 loss: 0.0079216538
Iter: 802 loss: 0.00792166591
Iter: 803 loss: 0.00792165
Iter: 804 loss: 0.00792164356
Iter: 805 loss: 0.00792163797
Iter: 806 loss: 0.00792164542
Iter: 807 loss: 0.00792165
Iter: 808 loss: 0.00792164635
Iter: 809 loss: 0.00792164169
Iter: 810 loss: 0.00792163517
Iter: 811 loss: 0.00792173203
Iter: 812 loss: 0.00792164356
Iter: 813 loss: 0.00792163052
Iter: 814 loss: 0.00792163
Iter: 815 loss: 0.00792164914
Iter: 816 loss: 0.00792162865
Iter: 817 loss: 0.0079216212
Iter: 818 loss: 0.00792162213
Iter: 819 loss: 0.00792160258
Iter: 820 loss: 0.00792161189
Iter: 821 loss: 0.00792161375
Iter: 822 loss: 0.00792161468
Iter: 823 loss: 0.00792161562
Iter: 824 loss: 0.00792161375
Iter: 825 loss: 0.00792160537
Iter: 826 loss: 0.0079216063
Iter: 827 loss: 0.00792160444
Iter: 828 loss: 0.00792160165
Iter: 829 loss: 0.00792161375
Iter: 830 loss: 0.00792160816
Iter: 831 loss: 0.0079216063
Iter: 832 loss: 0.00792161468
Iter: 833 loss: 0.00792161282
Iter: 834 loss: 0.00792160444
Iter: 835 loss: 0.00792160444
Iter: 836 loss: 0.00792160444
Iter: 837 loss: 0.00792161562
Iter: 838 loss: 0.00792161655
Iter: 839 loss: 0.00792161562
Iter: 840 loss: 0.00792161562
Iter: 841 loss: 0.00792160444
Iter: 842 loss: 0.00792161562
Iter: 843 loss: 0.00792161562
Iter: 844 loss: 0.00792160444
Iter: 845 loss: 0.00792161562
Iter: 846 loss: 0.00792161562
Iter: 847 loss: 0.00792161562
Iter: 848 loss: 0.00792160444
Iter: 849 loss: 0.00792161562
Iter: 850 loss: 0.00792160258
Iter: 851 loss: 0.00792170875
Iter: 852 loss: 0.00792160071
Iter: 853 loss: 0.0079216
Iter: 854 loss: 0.00792158302
Iter: 855 loss: 0.00792160071
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8
+ date
Tue Oct 27 17:35:54 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f5ef730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f5fd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f696bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f60d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f60d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f60d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f60d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f585730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f5852f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f5361e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f536a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f5851e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f494bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f4c21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f454f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f40fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f432400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f4c2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f404d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f4548c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f3596a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f37bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f37b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f2d26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f2d2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f2f3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f2bcae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f293158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f280488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f21e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f224730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f1ecf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f2058c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f21e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fed0f205c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fecd649dbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.244079381
Iter: 2 loss: 28.3090935
Iter: 3 loss: 26.1671333
Iter: 4 loss: 7.56977654
Iter: 5 loss: 7.41053295
Iter: 6 loss: 3.94555449
Iter: 7 loss: 3.88419127
Iter: 8 loss: 2.23963451
Iter: 9 loss: 2.2059834
Iter: 10 loss: 1.31086087
Iter: 11 loss: 1.28869879
Iter: 12 loss: 0.767210364
Iter: 13 loss: 0.750941515
Iter: 14 loss: 0.430398971
Iter: 15 loss: 0.417286873
Iter: 16 loss: 0.221184045
Iter: 17 loss: 0.2121346
Iter: 18 loss: 0.201663285
Iter: 19 loss: 0.160032719
Iter: 20 loss: 19.1459084
Iter: 21 loss: 0.160020307
Iter: 22 loss: 0.0701804683
Iter: 23 loss: 0.0701785162
Iter: 24 loss: 526.800293
Iter: 25 loss: 617.457
Iter: 26 loss: 0.0701762885
Iter: 27 loss: 0.0924126953
Iter: 28 loss: 0.061841391
Iter: 29 loss: 0.0608122312
Iter: 30 loss: 0.0512058958
Iter: 31 loss: 0.043528
Iter: 32 loss: 0.0412447564
Iter: 33 loss: 0.0343310311
Iter: 34 loss: 0.11924202
Iter: 35 loss: 0.0339526497
Iter: 36 loss: 0.0285134
Iter: 37 loss: 0.0421690866
Iter: 38 loss: 0.0280020181
Iter: 39 loss: 0.024325259
Iter: 40 loss: 0.0438255221
Iter: 41 loss: 0.0232969467
Iter: 42 loss: 0.0220455322
Iter: 43 loss: 0.0246978533
Iter: 44 loss: 0.0214830618
Iter: 45 loss: 0.019453099
Iter: 46 loss: 0.0183011293
Iter: 47 loss: 0.0175906159
Iter: 48 loss: 0.0157016292
Iter: 49 loss: 0.0146658737
Iter: 50 loss: 0.0138864312
Iter: 51 loss: 0.0116671994
Iter: 52 loss: 0.0209182203
Iter: 53 loss: 0.0110823056
Iter: 54 loss: 0.0104448488
Iter: 55 loss: 0.0103995577
Iter: 56 loss: 0.00991374068
Iter: 57 loss: 0.0092788972
Iter: 58 loss: 0.0129784849
Iter: 59 loss: 0.00919626094
Iter: 60 loss: 0.00892838
Iter: 61 loss: 0.00973398425
Iter: 62 loss: 0.00885941
Iter: 63 loss: 0.00854711421
Iter: 64 loss: 0.00908123888
Iter: 65 loss: 0.00840473175
Iter: 66 loss: 0.00818148
Iter: 67 loss: 0.00855538528
Iter: 68 loss: 0.00808560476
Iter: 69 loss: 0.00788636226
Iter: 70 loss: 0.00893160049
Iter: 71 loss: 0.00786133669
Iter: 72 loss: 0.00775484042
Iter: 73 loss: 0.00800510403
Iter: 74 loss: 0.00771766901
Iter: 75 loss: 0.00761641096
Iter: 76 loss: 0.00766471308
Iter: 77 loss: 0.00754957646
Iter: 78 loss: 0.00755222794
Iter: 79 loss: 0.00751348725
Iter: 80 loss: 0.00749560259
Iter: 81 loss: 0.00748905307
Iter: 82 loss: 0.00747916847
Iter: 83 loss: 0.00744270626
Iter: 84 loss: 0.00743134599
Iter: 85 loss: 0.00741004
Iter: 86 loss: 0.00738507137
Iter: 87 loss: 0.00738353422
Iter: 88 loss: 0.00736923749
Iter: 89 loss: 0.00758552365
Iter: 90 loss: 0.00736922584
Iter: 91 loss: 0.00736153126
Iter: 92 loss: 0.0074076443
Iter: 93 loss: 0.00736059295
Iter: 94 loss: 0.00735530956
Iter: 95 loss: 0.00735793961
Iter: 96 loss: 0.00735179894
Iter: 97 loss: 0.0073463833
Iter: 98 loss: 0.0073897629
Iter: 99 loss: 0.00734602381
Iter: 100 loss: 0.0073424466
Iter: 101 loss: 0.0073485747
Iter: 102 loss: 0.00734085683
Iter: 103 loss: 0.0073368866
Iter: 104 loss: 0.00735874707
Iter: 105 loss: 0.00733630685
Iter: 106 loss: 0.0073335967
Iter: 107 loss: 0.00734220212
Iter: 108 loss: 0.00733281625
Iter: 109 loss: 0.00733150588
Iter: 110 loss: 0.00733139738
Iter: 111 loss: 0.00733008748
Iter: 112 loss: 0.00732745044
Iter: 113 loss: 0.00737684965
Iter: 114 loss: 0.00732741505
Iter: 115 loss: 0.00732449908
Iter: 116 loss: 0.00732022431
Iter: 117 loss: 0.00732010603
Iter: 118 loss: 0.00731455535
Iter: 119 loss: 0.00734496862
Iter: 120 loss: 0.00731373206
Iter: 121 loss: 0.00730916811
Iter: 122 loss: 0.00731753185
Iter: 123 loss: 0.00730719604
Iter: 124 loss: 0.00730150426
Iter: 125 loss: 0.0072992919
Iter: 126 loss: 0.00729619805
Iter: 127 loss: 0.00729099801
Iter: 128 loss: 0.00729092024
Iter: 129 loss: 0.00728654116
Iter: 130 loss: 0.00729105761
Iter: 131 loss: 0.0072841011
Iter: 132 loss: 0.00728001073
Iter: 133 loss: 0.00729116
Iter: 134 loss: 0.00727866217
Iter: 135 loss: 0.00727381138
Iter: 136 loss: 0.00729658455
Iter: 137 loss: 0.00727292197
Iter: 138 loss: 0.00726998458
Iter: 139 loss: 0.00729592796
Iter: 140 loss: 0.00726983137
Iter: 141 loss: 0.00726857409
Iter: 142 loss: 0.00726851495
Iter: 143 loss: 0.00726732239
Iter: 144 loss: 0.00726663135
Iter: 145 loss: 0.00726611819
Iter: 146 loss: 0.00726488233
Iter: 147 loss: 0.00726345973
Iter: 148 loss: 0.00726328325
Iter: 149 loss: 0.00726158777
Iter: 150 loss: 0.00726698432
Iter: 151 loss: 0.00726109929
Iter: 152 loss: 0.00725941639
Iter: 153 loss: 0.0072621638
Iter: 154 loss: 0.00725864572
Iter: 155 loss: 0.00725653861
Iter: 156 loss: 0.00725886226
Iter: 157 loss: 0.00725539681
Iter: 158 loss: 0.00725358818
Iter: 159 loss: 0.00725934189
Iter: 160 loss: 0.00725307129
Iter: 161 loss: 0.00725115184
Iter: 162 loss: 0.00726636872
Iter: 163 loss: 0.00725102099
Iter: 164 loss: 0.00724959094
Iter: 165 loss: 0.00724967849
Iter: 166 loss: 0.00724846916
Iter: 167 loss: 0.00724710152
Iter: 168 loss: 0.00724710245
Iter: 169 loss: 0.00724631362
Iter: 170 loss: 0.00725212414
Iter: 171 loss: 0.00724624936
Iter: 172 loss: 0.00724581163
Iter: 173 loss: 0.00725144893
Iter: 174 loss: 0.00724580837
Iter: 175 loss: 0.00724538742
Iter: 176 loss: 0.00724585494
Iter: 177 loss: 0.00724515971
Iter: 178 loss: 0.00724485936
Iter: 179 loss: 0.00724432524
Iter: 180 loss: 0.00724432804
Iter: 181 loss: 0.00724375434
Iter: 182 loss: 0.00724489801
Iter: 183 loss: 0.00724351918
Iter: 184 loss: 0.00724291243
Iter: 185 loss: 0.00724484
Iter: 186 loss: 0.00724273967
Iter: 187 loss: 0.0072422605
Iter: 188 loss: 0.00724499114
Iter: 189 loss: 0.0072421981
Iter: 190 loss: 0.00724184513
Iter: 191 loss: 0.00724171847
Iter: 192 loss: 0.00724152615
Iter: 193 loss: 0.00724127376
Iter: 194 loss: 0.00724124489
Iter: 195 loss: 0.00724106934
Iter: 196 loss: 0.00724116853
Iter: 197 loss: 0.0072409506
Iter: 198 loss: 0.00724074384
Iter: 199 loss: 0.00724125886
Iter: 200 loss: 0.00724067073
Iter: 201 loss: 0.00724051381
Iter: 202 loss: 0.00724051055
Iter: 203 loss: 0.00724041834
Iter: 204 loss: 0.00724118296
Iter: 205 loss: 0.00724041555
Iter: 206 loss: 0.00724031962
Iter: 207 loss: 0.00724047329
Iter: 208 loss: 0.00724027678
Iter: 209 loss: 0.00724019855
Iter: 210 loss: 0.00724006072
Iter: 211 loss: 0.00724005699
Iter: 212 loss: 0.00723991264
Iter: 213 loss: 0.00723994151
Iter: 214 loss: 0.00723979902
Iter: 215 loss: 0.00723962439
Iter: 216 loss: 0.00724110566
Iter: 217 loss: 0.00723961275
Iter: 218 loss: 0.00723949913
Iter: 219 loss: 0.00723966118
Iter: 220 loss: 0.00723944278
Iter: 221 loss: 0.00723930262
Iter: 222 loss: 0.00723956292
Iter: 223 loss: 0.00723924441
Iter: 224 loss: 0.00723913219
Iter: 225 loss: 0.00723979156
Iter: 226 loss: 0.00723912194
Iter: 227 loss: 0.00723903393
Iter: 228 loss: 0.00723956153
Iter: 229 loss: 0.00723902322
Iter: 230 loss: 0.00723896176
Iter: 231 loss: 0.00723897573
Iter: 232 loss: 0.0072389124
Iter: 233 loss: 0.00723888818
Iter: 234 loss: 0.00723888259
Iter: 235 loss: 0.00723885512
Iter: 236 loss: 0.00723904558
Iter: 237 loss: 0.00723885465
Iter: 238 loss: 0.00723882951
Iter: 239 loss: 0.00723888818
Iter: 240 loss: 0.007238816
Iter: 241 loss: 0.00723879552
Iter: 242 loss: 0.00723877
Iter: 243 loss: 0.00723876571
Iter: 244 loss: 0.00723873684
Iter: 245 loss: 0.00723872613
Iter: 246 loss: 0.00723870704
Iter: 247 loss: 0.00723867491
Iter: 248 loss: 0.00723897386
Iter: 249 loss: 0.00723867305
Iter: 250 loss: 0.00723864976
Iter: 251 loss: 0.00723868608
Iter: 252 loss: 0.00723863719
Iter: 253 loss: 0.00723861065
Iter: 254 loss: 0.00723868841
Iter: 255 loss: 0.00723859947
Iter: 256 loss: 0.00723857619
Iter: 257 loss: 0.00723862508
Iter: 258 loss: 0.00723856408
Iter: 259 loss: 0.00723854266
Iter: 260 loss: 0.00723876432
Iter: 261 loss: 0.00723854173
Iter: 262 loss: 0.00723853055
Iter: 263 loss: 0.00723855104
Iter: 264 loss: 0.0072385231
Iter: 265 loss: 0.00723850774
Iter: 266 loss: 0.00723855384
Iter: 267 loss: 0.00723850355
Iter: 268 loss: 0.00723849935
Iter: 269 loss: 0.00723849889
Iter: 270 loss: 0.0072384947
Iter: 271 loss: 0.00723850727
Iter: 272 loss: 0.00723849423
Iter: 273 loss: 0.00723849
Iter: 274 loss: 0.00723848492
Iter: 275 loss: 0.00723848213
Iter: 276 loss: 0.00723847467
Iter: 277 loss: 0.00723847747
Iter: 278 loss: 0.00723847
Iter: 279 loss: 0.00723846536
Iter: 280 loss: 0.0072384784
Iter: 281 loss: 0.00723846257
Iter: 282 loss: 0.00723845465
Iter: 283 loss: 0.00723852217
Iter: 284 loss: 0.00723845232
Iter: 285 loss: 0.0072384486
Iter: 286 loss: 0.00723844673
Iter: 287 loss: 0.00723844301
Iter: 288 loss: 0.00723843696
Iter: 289 loss: 0.00723850029
Iter: 290 loss: 0.00723843649
Iter: 291 loss: 0.00723842904
Iter: 292 loss: 0.0072384649
Iter: 293 loss: 0.0072384309
Iter: 294 loss: 0.00723843
Iter: 295 loss: 0.0072384309
Iter: 296 loss: 0.00723842764
Iter: 297 loss: 0.00723842252
Iter: 298 loss: 0.00723842252
Iter: 299 loss: 0.00723842112
Iter: 300 loss: 0.00723842531
Iter: 301 loss: 0.00723842112
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3
+ date
Tue Oct 27 17:36:36 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi2.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 0 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc122136a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc122141e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcc12261bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbec0a0620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbec0a0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbec0a00d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbec043598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbd00c2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbd00c2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbd006f158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbd006f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbd006f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c7c4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcbd0019a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c7f60d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c7b8ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c756e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c799268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c72eae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c7562f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c6ee6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c6a32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c6a31e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c613048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c6137b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c61dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c5d4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c5d4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c59d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c5412f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c59d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c59d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c59d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c59da60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c547f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb3c4b8048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0451761782
Iter: 2 loss: 1.40069342
Iter: 3 loss: 1.1620934
Iter: 4 loss: 0.630861044
Iter: 5 loss: 0.512227774
Iter: 6 loss: 0.255503029
Iter: 7 loss: 0.185038015
Iter: 8 loss: 0.0714161247
Iter: 9 loss: 0.0452285931
Iter: 10 loss: 0.0165042598
Iter: 11 loss: 0.0150611158
Iter: 12 loss: 0.0140117072
Iter: 13 loss: 0.0129199931
Iter: 14 loss: 0.012641836
Iter: 15 loss: 0.01161185
Iter: 16 loss: 0.00989710726
Iter: 17 loss: 0.00989232
Iter: 18 loss: 0.00871826429
Iter: 19 loss: 0.0171100162
Iter: 20 loss: 0.00870473869
Iter: 21 loss: 0.00857746
Iter: 22 loss: 0.00855330192
Iter: 23 loss: 0.00846482627
Iter: 24 loss: 0.00834518671
Iter: 25 loss: 0.00814086478
Iter: 26 loss: 0.00814069808
Iter: 27 loss: 0.00778238941
Iter: 28 loss: 0.00836009718
Iter: 29 loss: 0.0076207635
Iter: 30 loss: 0.00737637607
Iter: 31 loss: 0.00794601254
Iter: 32 loss: 0.00729272049
Iter: 33 loss: 0.00715436321
Iter: 34 loss: 0.00895009376
Iter: 35 loss: 0.00715354038
Iter: 36 loss: 0.00710572489
Iter: 37 loss: 0.00717040058
Iter: 38 loss: 0.00708192773
Iter: 39 loss: 0.00704027526
Iter: 40 loss: 0.00707011297
Iter: 41 loss: 0.00701503
Iter: 42 loss: 0.0069863731
Iter: 43 loss: 0.00726467278
Iter: 44 loss: 0.00698554842
Iter: 45 loss: 0.00697665662
Iter: 46 loss: 0.0070888279
Iter: 47 loss: 0.00697658537
Iter: 48 loss: 0.00697233807
Iter: 49 loss: 0.00697433762
Iter: 50 loss: 0.00696947612
Iter: 51 loss: 0.00696630543
Iter: 52 loss: 0.00698191719
Iter: 53 loss: 0.00696576945
Iter: 54 loss: 0.00696475
Iter: 55 loss: 0.00697125308
Iter: 56 loss: 0.0069646351
Iter: 57 loss: 0.00696445256
Iter: 58 loss: 0.00696435
Iter: 59 loss: 0.00696402974
Iter: 60 loss: 0.00696366
Iter: 61 loss: 0.00696361484
Iter: 62 loss: 0.0069631692
Iter: 63 loss: 0.0069624926
Iter: 64 loss: 0.00696247909
Iter: 65 loss: 0.00696171494
Iter: 66 loss: 0.00696560834
Iter: 67 loss: 0.00696159061
Iter: 68 loss: 0.00696097035
Iter: 69 loss: 0.00696348306
Iter: 70 loss: 0.00696083345
Iter: 71 loss: 0.00696034729
Iter: 72 loss: 0.00696262345
Iter: 73 loss: 0.00696025835
Iter: 74 loss: 0.00695981132
Iter: 75 loss: 0.00696060713
Iter: 76 loss: 0.00695961481
Iter: 77 loss: 0.00695921201
Iter: 78 loss: 0.00696048141
Iter: 79 loss: 0.00695909746
Iter: 80 loss: 0.00695876684
Iter: 81 loss: 0.00696058106
Iter: 82 loss: 0.00695872214
Iter: 83 loss: 0.00695845298
Iter: 84 loss: 0.00695820618
Iter: 85 loss: 0.00695814425
Iter: 86 loss: 0.00695784576
Iter: 87 loss: 0.00696167815
Iter: 88 loss: 0.00695784204
Iter: 89 loss: 0.00695779454
Iter: 90 loss: 0.0069577489
Iter: 91 loss: 0.00695765251
Iter: 92 loss: 0.00695780385
Iter: 93 loss: 0.00695760921
Iter: 94 loss: 0.00695752818
Iter: 95 loss: 0.00695738802
Iter: 96 loss: 0.00695738848
Iter: 97 loss: 0.00695722317
Iter: 98 loss: 0.00695731305
Iter: 99 loss: 0.00695711561
Iter: 100 loss: 0.00695693307
Iter: 101 loss: 0.0069577992
Iter: 102 loss: 0.00695690233
Iter: 103 loss: 0.00695678405
Iter: 104 loss: 0.00695755705
Iter: 105 loss: 0.00695677288
Iter: 106 loss: 0.00695668347
Iter: 107 loss: 0.0069570723
Iter: 108 loss: 0.00695666764
Iter: 109 loss: 0.00695660198
Iter: 110 loss: 0.00695678219
Iter: 111 loss: 0.00695658
Iter: 112 loss: 0.0069565326
Iter: 113 loss: 0.0069568865
Iter: 114 loss: 0.0069565312
Iter: 115 loss: 0.00695650373
Iter: 116 loss: 0.00695662899
Iter: 117 loss: 0.0069564986
Iter: 118 loss: 0.00695647858
Iter: 119 loss: 0.00695648696
Iter: 120 loss: 0.00695646182
Iter: 121 loss: 0.00695643947
Iter: 122 loss: 0.00695659081
Iter: 123 loss: 0.00695643667
Iter: 124 loss: 0.00695642876
Iter: 125 loss: 0.00695642736
Iter: 126 loss: 0.00695641898
Iter: 127 loss: 0.0069564213
Iter: 128 loss: 0.00695641
Iter: 129 loss: 0.00695640408
Iter: 130 loss: 0.00695638824
Iter: 131 loss: 0.00695655495
Iter: 132 loss: 0.00695638685
Iter: 133 loss: 0.00695636868
Iter: 134 loss: 0.00695650745
Iter: 135 loss: 0.00695636729
Iter: 136 loss: 0.00695636
Iter: 137 loss: 0.00695640035
Iter: 138 loss: 0.00695635751
Iter: 139 loss: 0.00695634913
Iter: 140 loss: 0.00695638778
Iter: 141 loss: 0.00695635052
Iter: 142 loss: 0.00695634447
Iter: 143 loss: 0.00695635797
Iter: 144 loss: 0.00695634214
Iter: 145 loss: 0.00695633888
Iter: 146 loss: 0.00695636496
Iter: 147 loss: 0.00695633749
Iter: 148 loss: 0.00695633283
Iter: 149 loss: 0.00695633795
Iter: 150 loss: 0.0069563305
Iter: 151 loss: 0.00695632957
Iter: 152 loss: 0.00695634494
Iter: 153 loss: 0.0069563305
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi0_phi3/k2
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0
+ date
Tue Oct 27 17:37:08 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240ccf1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240ccca730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240ccf1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cd73f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cd6c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cd6cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cc39620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cc05bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cc05b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cba69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cbbb2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cb4bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cb4be18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cb33730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cae3a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cab6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cac3268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cac3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240cac3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c9c8950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c9d8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c987f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c9b5ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c96bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c96b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c921840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c943ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c902620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c9021e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c8aa488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c858ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c817840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c81b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c840bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c7f8598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f240c789f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.000628332
Iter: 2 loss: 0.000625676941
Iter: 3 loss: 0.000615273602
Iter: 4 loss: 0.000568482152
Iter: 5 loss: 0.000465284509
Iter: 6 loss: 0.000465203193
Iter: 7 loss: 0.000375455071
Iter: 8 loss: 0.00129318424
Iter: 9 loss: 0.000372262788
Iter: 10 loss: 0.000325091853
Iter: 11 loss: 0.000351813884
Iter: 12 loss: 0.000294367608
Iter: 13 loss: 0.00025585707
Iter: 14 loss: 0.000759891118
Iter: 15 loss: 0.000255679624
Iter: 16 loss: 0.000226393968
Iter: 17 loss: 0.000249443692
Iter: 18 loss: 0.000208629761
Iter: 19 loss: 0.000183098426
Iter: 20 loss: 0.000221970535
Iter: 21 loss: 0.000170984829
Iter: 22 loss: 0.000154738373
Iter: 23 loss: 0.00015444099
Iter: 24 loss: 0.000141144032
Iter: 25 loss: 0.000142948236
Iter: 26 loss: 0.000131023902
Iter: 27 loss: 0.000118255557
Iter: 28 loss: 0.000130186061
Iter: 29 loss: 0.000110913599
Iter: 30 loss: 9.99848708e-05
Iter: 31 loss: 0.000193612126
Iter: 32 loss: 9.93795402e-05
Iter: 33 loss: 9.18188889e-05
Iter: 34 loss: 0.000176342379
Iter: 35 loss: 9.16754e-05
Iter: 36 loss: 8.7097018e-05
Iter: 37 loss: 8.3405117e-05
Iter: 38 loss: 8.2036524e-05
Iter: 39 loss: 7.66429293e-05
Iter: 40 loss: 9.75847142e-05
Iter: 41 loss: 7.53856293e-05
Iter: 42 loss: 7.17827e-05
Iter: 43 loss: 7.17780058e-05
Iter: 44 loss: 6.92028698e-05
Iter: 45 loss: 6.77612188e-05
Iter: 46 loss: 6.66370906e-05
Iter: 47 loss: 6.36223704e-05
Iter: 48 loss: 7.16182476e-05
Iter: 49 loss: 6.2611638e-05
Iter: 50 loss: 6.05253881e-05
Iter: 51 loss: 8.34908715e-05
Iter: 52 loss: 6.04837769e-05
Iter: 53 loss: 5.8786798e-05
Iter: 54 loss: 6.45422e-05
Iter: 55 loss: 5.83284418e-05
Iter: 56 loss: 5.70845841e-05
Iter: 57 loss: 5.89587471e-05
Iter: 58 loss: 5.64910551e-05
Iter: 59 loss: 5.53516438e-05
Iter: 60 loss: 6.72645838e-05
Iter: 61 loss: 5.5322249e-05
Iter: 62 loss: 5.4476448e-05
Iter: 63 loss: 5.43255737e-05
Iter: 64 loss: 5.37520864e-05
Iter: 65 loss: 5.28412602e-05
Iter: 66 loss: 5.60543886e-05
Iter: 67 loss: 5.26058357e-05
Iter: 68 loss: 5.18427405e-05
Iter: 69 loss: 6.07062866e-05
Iter: 70 loss: 5.18311972e-05
Iter: 71 loss: 5.13346204e-05
Iter: 72 loss: 5.09050624e-05
Iter: 73 loss: 5.07715e-05
Iter: 74 loss: 5.01326722e-05
Iter: 75 loss: 5.16897744e-05
Iter: 76 loss: 4.99044436e-05
Iter: 77 loss: 4.94419219e-05
Iter: 78 loss: 5.57434032e-05
Iter: 79 loss: 4.94401647e-05
Iter: 80 loss: 4.90363891e-05
Iter: 81 loss: 5.00972819e-05
Iter: 82 loss: 4.89002487e-05
Iter: 83 loss: 4.85885976e-05
Iter: 84 loss: 4.8582915e-05
Iter: 85 loss: 4.83376789e-05
Iter: 86 loss: 4.79694208e-05
Iter: 87 loss: 4.88790974e-05
Iter: 88 loss: 4.78392249e-05
Iter: 89 loss: 4.75319102e-05
Iter: 90 loss: 4.94118685e-05
Iter: 91 loss: 4.74949265e-05
Iter: 92 loss: 4.72624197e-05
Iter: 93 loss: 4.98980662e-05
Iter: 94 loss: 4.72581378e-05
Iter: 95 loss: 4.71043677e-05
Iter: 96 loss: 4.70129671e-05
Iter: 97 loss: 4.69489241e-05
Iter: 98 loss: 4.67785721e-05
Iter: 99 loss: 4.91857754e-05
Iter: 100 loss: 4.67782957e-05
Iter: 101 loss: 4.66428246e-05
Iter: 102 loss: 4.66201236e-05
Iter: 103 loss: 4.65275043e-05
Iter: 104 loss: 4.63743454e-05
Iter: 105 loss: 4.68844773e-05
Iter: 106 loss: 4.63324177e-05
Iter: 107 loss: 4.62014941e-05
Iter: 108 loss: 4.75570851e-05
Iter: 109 loss: 4.61978343e-05
Iter: 110 loss: 4.61062227e-05
Iter: 111 loss: 4.6021094e-05
Iter: 112 loss: 4.59993389e-05
Iter: 113 loss: 4.58739669e-05
Iter: 114 loss: 4.63424185e-05
Iter: 115 loss: 4.58433933e-05
Iter: 116 loss: 4.5749166e-05
Iter: 117 loss: 4.70483574e-05
Iter: 118 loss: 4.57488932e-05
Iter: 119 loss: 4.56767229e-05
Iter: 120 loss: 4.56188936e-05
Iter: 121 loss: 4.5597124e-05
Iter: 122 loss: 4.55055379e-05
Iter: 123 loss: 4.57807328e-05
Iter: 124 loss: 4.54779511e-05
Iter: 125 loss: 4.54081819e-05
Iter: 126 loss: 4.64769182e-05
Iter: 127 loss: 4.54081674e-05
Iter: 128 loss: 4.53536559e-05
Iter: 129 loss: 4.53289176e-05
Iter: 130 loss: 4.53015673e-05
Iter: 131 loss: 4.52339918e-05
Iter: 132 loss: 4.52980385e-05
Iter: 133 loss: 4.51954293e-05
Iter: 134 loss: 4.51230735e-05
Iter: 135 loss: 4.53883949e-05
Iter: 136 loss: 4.51051092e-05
Iter: 137 loss: 4.50550069e-05
Iter: 138 loss: 4.57357673e-05
Iter: 139 loss: 4.50548287e-05
Iter: 140 loss: 4.50103689e-05
Iter: 141 loss: 4.50787265e-05
Iter: 142 loss: 4.49892832e-05
Iter: 143 loss: 4.4950335e-05
Iter: 144 loss: 4.50344814e-05
Iter: 145 loss: 4.49352265e-05
Iter: 146 loss: 4.48917417e-05
Iter: 147 loss: 4.51158048e-05
Iter: 148 loss: 4.48846622e-05
Iter: 149 loss: 4.48517603e-05
Iter: 150 loss: 4.48393621e-05
Iter: 151 loss: 4.48213e-05
Iter: 152 loss: 4.47824568e-05
Iter: 153 loss: 4.50786792e-05
Iter: 154 loss: 4.47795392e-05
Iter: 155 loss: 4.47456841e-05
Iter: 156 loss: 4.49159488e-05
Iter: 157 loss: 4.47399834e-05
Iter: 158 loss: 4.47160164e-05
Iter: 159 loss: 4.46972044e-05
Iter: 160 loss: 4.46897902e-05
Iter: 161 loss: 4.46568447e-05
Iter: 162 loss: 4.47770144e-05
Iter: 163 loss: 4.46485283e-05
Iter: 164 loss: 4.46251215e-05
Iter: 165 loss: 4.46250415e-05
Iter: 166 loss: 4.46075283e-05
Iter: 167 loss: 4.45901169e-05
Iter: 168 loss: 4.45864425e-05
Iter: 169 loss: 4.45617879e-05
Iter: 170 loss: 4.45974401e-05
Iter: 171 loss: 4.45497681e-05
Iter: 172 loss: 4.45288169e-05
Iter: 173 loss: 4.4768567e-05
Iter: 174 loss: 4.4528475e-05
Iter: 175 loss: 4.45112455e-05
Iter: 176 loss: 4.45893456e-05
Iter: 177 loss: 4.45079168e-05
Iter: 178 loss: 4.44953403e-05
Iter: 179 loss: 4.44873331e-05
Iter: 180 loss: 4.44824618e-05
Iter: 181 loss: 4.44666148e-05
Iter: 182 loss: 4.45893529e-05
Iter: 183 loss: 4.4465527e-05
Iter: 184 loss: 4.44516263e-05
Iter: 185 loss: 4.4530243e-05
Iter: 186 loss: 4.44496436e-05
Iter: 187 loss: 4.44397701e-05
Iter: 188 loss: 4.44356047e-05
Iter: 189 loss: 4.44304751e-05
Iter: 190 loss: 4.44193283e-05
Iter: 191 loss: 4.45355508e-05
Iter: 192 loss: 4.44189645e-05
Iter: 193 loss: 4.44096877e-05
Iter: 194 loss: 4.44177495e-05
Iter: 195 loss: 4.44041616e-05
Iter: 196 loss: 4.43948811e-05
Iter: 197 loss: 4.44045763e-05
Iter: 198 loss: 4.43896861e-05
Iter: 199 loss: 4.43813187e-05
Iter: 200 loss: 4.44979e-05
Iter: 201 loss: 4.43812824e-05
Iter: 202 loss: 4.437405e-05
Iter: 203 loss: 4.43778918e-05
Iter: 204 loss: 4.43693098e-05
Iter: 205 loss: 4.43623285e-05
Iter: 206 loss: 4.43674726e-05
Iter: 207 loss: 4.43580066e-05
Iter: 208 loss: 4.43509562e-05
Iter: 209 loss: 4.44062971e-05
Iter: 210 loss: 4.43504978e-05
Iter: 211 loss: 4.43444405e-05
Iter: 212 loss: 4.43804456e-05
Iter: 213 loss: 4.43437602e-05
Iter: 214 loss: 4.43396057e-05
Iter: 215 loss: 4.43353783e-05
Iter: 216 loss: 4.43345853e-05
Iter: 217 loss: 4.43284771e-05
Iter: 218 loss: 4.43458084e-05
Iter: 219 loss: 4.43264726e-05
Iter: 220 loss: 4.43216777e-05
Iter: 221 loss: 4.43626705e-05
Iter: 222 loss: 4.43213867e-05
Iter: 223 loss: 4.43174213e-05
Iter: 224 loss: 4.4348446e-05
Iter: 225 loss: 4.43171666e-05
Iter: 226 loss: 4.43145327e-05
Iter: 227 loss: 4.43119789e-05
Iter: 228 loss: 4.43114332e-05
Iter: 229 loss: 4.43081e-05
Iter: 230 loss: 4.43366735e-05
Iter: 231 loss: 4.43079116e-05
Iter: 232 loss: 4.43049648e-05
Iter: 233 loss: 4.43142781e-05
Iter: 234 loss: 4.43040408e-05
Iter: 235 loss: 4.43017489e-05
Iter: 236 loss: 4.43027748e-05
Iter: 237 loss: 4.43001882e-05
Iter: 238 loss: 4.42979217e-05
Iter: 239 loss: 4.43274548e-05
Iter: 240 loss: 4.42979326e-05
Iter: 241 loss: 4.42960882e-05
Iter: 242 loss: 4.42970559e-05
Iter: 243 loss: 4.42949022e-05
Iter: 244 loss: 4.42930832e-05
Iter: 245 loss: 4.42947057e-05
Iter: 246 loss: 4.42919554e-05
Iter: 247 loss: 4.42903911e-05
Iter: 248 loss: 4.43131794e-05
Iter: 249 loss: 4.42904129e-05
Iter: 250 loss: 4.42890087e-05
Iter: 251 loss: 4.42901401e-05
Iter: 252 loss: 4.42882447e-05
Iter: 253 loss: 4.4287015e-05
Iter: 254 loss: 4.42873134e-05
Iter: 255 loss: 4.42861055e-05
Iter: 256 loss: 4.42850651e-05
Iter: 257 loss: 4.42850651e-05
Iter: 258 loss: 4.42842065e-05
Iter: 259 loss: 4.42843339e-05
Iter: 260 loss: 4.42834571e-05
Iter: 261 loss: 4.42825294e-05
Iter: 262 loss: 4.42830024e-05
Iter: 263 loss: 4.42817836e-05
Iter: 264 loss: 4.42809396e-05
Iter: 265 loss: 4.42885794e-05
Iter: 266 loss: 4.42807432e-05
Iter: 267 loss: 4.42800156e-05
Iter: 268 loss: 4.42867204e-05
Iter: 269 loss: 4.42800228e-05
Iter: 270 loss: 4.42795281e-05
Iter: 271 loss: 4.42789387e-05
Iter: 272 loss: 4.42788732e-05
Iter: 273 loss: 4.42781493e-05
Iter: 274 loss: 4.42812379e-05
Iter: 275 loss: 4.42779565e-05
Iter: 276 loss: 4.42773089e-05
Iter: 277 loss: 4.42834717e-05
Iter: 278 loss: 4.42773271e-05
Iter: 279 loss: 4.42769269e-05
Iter: 280 loss: 4.42770615e-05
Iter: 281 loss: 4.42765377e-05
Iter: 282 loss: 4.42761448e-05
Iter: 283 loss: 4.42780329e-05
Iter: 284 loss: 4.42759701e-05
Iter: 285 loss: 4.427561e-05
Iter: 286 loss: 4.42790952e-05
Iter: 287 loss: 4.4275559e-05
Iter: 288 loss: 4.42753153e-05
Iter: 289 loss: 4.4275148e-05
Iter: 290 loss: 4.42749952e-05
Iter: 291 loss: 4.42746095e-05
Iter: 292 loss: 4.42755045e-05
Iter: 293 loss: 4.42745368e-05
Iter: 294 loss: 4.42742094e-05
Iter: 295 loss: 4.42742603e-05
Iter: 296 loss: 4.42740311e-05
Iter: 297 loss: 4.42739838e-05
Iter: 298 loss: 4.42737874e-05
Iter: 299 loss: 4.42735763e-05
Iter: 300 loss: 4.42739038e-05
Iter: 301 loss: 4.42734417e-05
Iter: 302 loss: 4.42732344e-05
Iter: 303 loss: 4.42749624e-05
Iter: 304 loss: 4.42732817e-05
Iter: 305 loss: 4.42730816e-05
Iter: 306 loss: 4.4274675e-05
Iter: 307 loss: 4.42730088e-05
Iter: 308 loss: 4.42729579e-05
Iter: 309 loss: 4.42728197e-05
Iter: 310 loss: 4.42727687e-05
Iter: 311 loss: 4.42725759e-05
Iter: 312 loss: 4.42732489e-05
Iter: 313 loss: 4.42725723e-05
Iter: 314 loss: 4.42724813e-05
Iter: 315 loss: 4.42740711e-05
Iter: 316 loss: 4.42724486e-05
Iter: 317 loss: 4.42723249e-05
Iter: 318 loss: 4.42724086e-05
Iter: 319 loss: 4.42722812e-05
Iter: 320 loss: 4.42721721e-05
Iter: 321 loss: 4.42725068e-05
Iter: 322 loss: 4.42721503e-05
Iter: 323 loss: 4.42720884e-05
Iter: 324 loss: 4.42728051e-05
Iter: 325 loss: 4.42720302e-05
Iter: 326 loss: 4.42719902e-05
Iter: 327 loss: 4.42719065e-05
Iter: 328 loss: 4.4271892e-05
Iter: 329 loss: 4.4271932e-05
Iter: 330 loss: 4.42724522e-05
Iter: 331 loss: 4.42718956e-05
Iter: 332 loss: 4.42718228e-05
Iter: 333 loss: 4.42719611e-05
Iter: 334 loss: 4.42718301e-05
Iter: 335 loss: 4.42717428e-05
Iter: 336 loss: 4.42717e-05
Iter: 337 loss: 4.42716482e-05
Iter: 338 loss: 4.42716519e-05
Iter: 339 loss: 4.42719029e-05
Iter: 340 loss: 4.42716628e-05
Iter: 341 loss: 4.42715173e-05
Iter: 342 loss: 4.42720557e-05
Iter: 343 loss: 4.42714954e-05
Iter: 344 loss: 4.42715136e-05
Iter: 345 loss: 4.42714809e-05
Iter: 346 loss: 4.42715209e-05
Iter: 347 loss: 4.42714554e-05
Iter: 348 loss: 4.42716264e-05
Iter: 349 loss: 4.42713863e-05
Iter: 350 loss: 4.42714e-05
Iter: 351 loss: 4.42718374e-05
Iter: 352 loss: 4.42713972e-05
Iter: 353 loss: 4.42713354e-05
Iter: 354 loss: 4.42713426e-05
Iter: 355 loss: 4.42713172e-05
Iter: 356 loss: 4.42713281e-05
Iter: 357 loss: 4.42713936e-05
Iter: 358 loss: 4.42713354e-05
Iter: 359 loss: 4.42712917e-05
Iter: 360 loss: 4.42715245e-05
Iter: 361 loss: 4.42713208e-05
Iter: 362 loss: 4.42712262e-05
Iter: 363 loss: 4.42713208e-05
Iter: 364 loss: 4.42713317e-05
Iter: 365 loss: 4.42712553e-05
Iter: 366 loss: 4.42712226e-05
Iter: 367 loss: 4.42712335e-05
Iter: 368 loss: 4.42713135e-05
Iter: 369 loss: 4.42712553e-05
Iter: 370 loss: 4.42712189e-05
Iter: 371 loss: 4.42711971e-05
Iter: 372 loss: 4.4271248e-05
Iter: 373 loss: 4.42712735e-05
Iter: 374 loss: 4.42713e-05
Iter: 375 loss: 4.42713135e-05
Iter: 376 loss: 4.42712735e-05
Iter: 377 loss: 4.42713135e-05
Iter: 378 loss: 4.42712844e-05
Iter: 379 loss: 4.42712626e-05
Iter: 380 loss: 4.42712626e-05
Iter: 381 loss: 4.42712699e-05
Iter: 382 loss: 4.42712917e-05
Iter: 383 loss: 4.42712881e-05
Iter: 384 loss: 4.42712735e-05
Iter: 385 loss: 4.42712771e-05
Iter: 386 loss: 4.42712771e-05
Iter: 387 loss: 4.42712771e-05
Iter: 388 loss: 4.42712771e-05
Iter: 389 loss: 4.42712844e-05
Iter: 390 loss: 4.42712771e-05
Iter: 391 loss: 4.42712771e-05
Iter: 392 loss: 4.42712844e-05
Iter: 393 loss: 4.42712771e-05
Iter: 394 loss: 4.42712044e-05
Iter: 395 loss: 4.42711971e-05
Iter: 396 loss: 4.42711826e-05
Iter: 397 loss: 4.42711498e-05
Iter: 398 loss: 4.42712335e-05
Iter: 399 loss: 4.4271168e-05
Iter: 400 loss: 4.42711826e-05
Iter: 401 loss: 4.42711971e-05
Iter: 402 loss: 4.42711462e-05
Iter: 403 loss: 4.42711826e-05
Iter: 404 loss: 4.42711826e-05
Iter: 405 loss: 4.42710952e-05
Iter: 406 loss: 4.4271048e-05
Iter: 407 loss: 4.42711826e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4
+ date
Tue Oct 27 17:42:50 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5faec400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5fb47ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5fb62510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5fb62bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5fa14400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5fa14510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f9878c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f9bbae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f987048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f968378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f9187b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f8c98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f8dfd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f8856a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f8bb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f84bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f84b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f809510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f82b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f7f0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f784598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f79a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f76a7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f7037b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f7039d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f6c2378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f6d98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f699840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f6992f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f649158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f676d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f6762f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f676598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f5cf730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f58b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fae5f5ba620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0264610257
Iter: 2 loss: 0.0260440782
Iter: 3 loss: 0.0244302861
Iter: 4 loss: 0.0175972767
Iter: 5 loss: 0.0112253875
Iter: 6 loss: 0.00820556842
Iter: 7 loss: 0.00411551539
Iter: 8 loss: 0.00401595
Iter: 9 loss: 0.00231584883
Iter: 10 loss: 0.0146153886
Iter: 11 loss: 0.00202443032
Iter: 12 loss: 0.00128245784
Iter: 13 loss: 0.00524450699
Iter: 14 loss: 0.00114456739
Iter: 15 loss: 0.000760184252
Iter: 16 loss: 0.00545570627
Iter: 17 loss: 0.000755232759
Iter: 18 loss: 0.00055249373
Iter: 19 loss: 0.000551991456
Iter: 20 loss: 0.000460075767
Iter: 21 loss: 0.00050500338
Iter: 22 loss: 0.000398225529
Iter: 23 loss: 0.000313126511
Iter: 24 loss: 0.000981254503
Iter: 25 loss: 0.000306444912
Iter: 26 loss: 0.000255936233
Iter: 27 loss: 0.000358778692
Iter: 28 loss: 0.000235523476
Iter: 29 loss: 0.000198907554
Iter: 30 loss: 0.000322803564
Iter: 31 loss: 0.000189119397
Iter: 32 loss: 0.000162459852
Iter: 33 loss: 0.000362612074
Iter: 34 loss: 0.00016017587
Iter: 35 loss: 0.000142938734
Iter: 36 loss: 0.000187190628
Iter: 37 loss: 0.000137020586
Iter: 38 loss: 0.00012301885
Iter: 39 loss: 0.000191214349
Iter: 40 loss: 0.000120567158
Iter: 41 loss: 0.000109861983
Iter: 42 loss: 0.000169421808
Iter: 43 loss: 0.0001083022
Iter: 44 loss: 0.000100810648
Iter: 45 loss: 0.000138208619
Iter: 46 loss: 9.95759037e-05
Iter: 47 loss: 9.37257864e-05
Iter: 48 loss: 0.000110281202
Iter: 49 loss: 9.18511359e-05
Iter: 50 loss: 8.69063515e-05
Iter: 51 loss: 0.000101550831
Iter: 52 loss: 8.53900201e-05
Iter: 53 loss: 8.15462408e-05
Iter: 54 loss: 0.000102872349
Iter: 55 loss: 8.09973862e-05
Iter: 56 loss: 7.7796496e-05
Iter: 57 loss: 9.41979524e-05
Iter: 58 loss: 7.72725471e-05
Iter: 59 loss: 7.50181644e-05
Iter: 60 loss: 7.83650321e-05
Iter: 61 loss: 7.39315074e-05
Iter: 62 loss: 7.16509821e-05
Iter: 63 loss: 7.70384868e-05
Iter: 64 loss: 7.08184962e-05
Iter: 65 loss: 6.87922147e-05
Iter: 66 loss: 7.31352193e-05
Iter: 67 loss: 6.79997684e-05
Iter: 68 loss: 6.62258535e-05
Iter: 69 loss: 7.38079834e-05
Iter: 70 loss: 6.5856766e-05
Iter: 71 loss: 6.4359323e-05
Iter: 72 loss: 7.28484083e-05
Iter: 73 loss: 6.41537772e-05
Iter: 74 loss: 6.29907881e-05
Iter: 75 loss: 6.52663e-05
Iter: 76 loss: 6.250976e-05
Iter: 77 loss: 6.14426899e-05
Iter: 78 loss: 6.53182724e-05
Iter: 79 loss: 6.11725845e-05
Iter: 80 loss: 6.02693181e-05
Iter: 81 loss: 6.65903572e-05
Iter: 82 loss: 6.01874126e-05
Iter: 83 loss: 5.94727389e-05
Iter: 84 loss: 6.10666393e-05
Iter: 85 loss: 5.91998432e-05
Iter: 86 loss: 5.85441157e-05
Iter: 87 loss: 5.95731544e-05
Iter: 88 loss: 5.82373978e-05
Iter: 89 loss: 5.76464445e-05
Iter: 90 loss: 6.13215525e-05
Iter: 91 loss: 5.75772938e-05
Iter: 92 loss: 5.70866359e-05
Iter: 93 loss: 5.96225836e-05
Iter: 94 loss: 5.70077536e-05
Iter: 95 loss: 5.66237795e-05
Iter: 96 loss: 5.67098e-05
Iter: 97 loss: 5.63406793e-05
Iter: 98 loss: 5.58886786e-05
Iter: 99 loss: 5.75062659e-05
Iter: 100 loss: 5.57737148e-05
Iter: 101 loss: 5.5387547e-05
Iter: 102 loss: 5.62856803e-05
Iter: 103 loss: 5.52446072e-05
Iter: 104 loss: 5.48890384e-05
Iter: 105 loss: 5.6018067e-05
Iter: 106 loss: 5.47870586e-05
Iter: 107 loss: 5.44716531e-05
Iter: 108 loss: 5.59291875e-05
Iter: 109 loss: 5.44125869e-05
Iter: 110 loss: 5.41419577e-05
Iter: 111 loss: 5.49658107e-05
Iter: 112 loss: 5.40614274e-05
Iter: 113 loss: 5.38325476e-05
Iter: 114 loss: 5.47419695e-05
Iter: 115 loss: 5.37803535e-05
Iter: 116 loss: 5.35934378e-05
Iter: 117 loss: 5.46424963e-05
Iter: 118 loss: 5.35674e-05
Iter: 119 loss: 5.34083738e-05
Iter: 120 loss: 5.37987144e-05
Iter: 121 loss: 5.33517305e-05
Iter: 122 loss: 5.32118283e-05
Iter: 123 loss: 5.33627936e-05
Iter: 124 loss: 5.31352125e-05
Iter: 125 loss: 5.29956196e-05
Iter: 126 loss: 5.38957502e-05
Iter: 127 loss: 5.29804565e-05
Iter: 128 loss: 5.28636047e-05
Iter: 129 loss: 5.34255814e-05
Iter: 130 loss: 5.28427663e-05
Iter: 131 loss: 5.27508964e-05
Iter: 132 loss: 5.28243218e-05
Iter: 133 loss: 5.26954864e-05
Iter: 134 loss: 5.25973664e-05
Iter: 135 loss: 5.29075623e-05
Iter: 136 loss: 5.25691248e-05
Iter: 137 loss: 5.24778879e-05
Iter: 138 loss: 5.27494922e-05
Iter: 139 loss: 5.24502102e-05
Iter: 140 loss: 5.23711315e-05
Iter: 141 loss: 5.25189316e-05
Iter: 142 loss: 5.23376693e-05
Iter: 143 loss: 5.22628761e-05
Iter: 144 loss: 5.25814903e-05
Iter: 145 loss: 5.22473492e-05
Iter: 146 loss: 5.21806796e-05
Iter: 147 loss: 5.24348688e-05
Iter: 148 loss: 5.2164818e-05
Iter: 149 loss: 5.21108377e-05
Iter: 150 loss: 5.2200754e-05
Iter: 151 loss: 5.20863396e-05
Iter: 152 loss: 5.20416e-05
Iter: 153 loss: 5.26219737e-05
Iter: 154 loss: 5.20412432e-05
Iter: 155 loss: 5.20044814e-05
Iter: 156 loss: 5.20348585e-05
Iter: 157 loss: 5.19825262e-05
Iter: 158 loss: 5.1947929e-05
Iter: 159 loss: 5.20073881e-05
Iter: 160 loss: 5.19324021e-05
Iter: 161 loss: 5.18977322e-05
Iter: 162 loss: 5.21311085e-05
Iter: 163 loss: 5.18942361e-05
Iter: 164 loss: 5.1867e-05
Iter: 165 loss: 5.19864298e-05
Iter: 166 loss: 5.18616143e-05
Iter: 167 loss: 5.18381967e-05
Iter: 168 loss: 5.18629313e-05
Iter: 169 loss: 5.18253364e-05
Iter: 170 loss: 5.18019224e-05
Iter: 171 loss: 5.18615707e-05
Iter: 172 loss: 5.17938897e-05
Iter: 173 loss: 5.17708795e-05
Iter: 174 loss: 5.1839248e-05
Iter: 175 loss: 5.17638837e-05
Iter: 176 loss: 5.17434928e-05
Iter: 177 loss: 5.17893059e-05
Iter: 178 loss: 5.17357876e-05
Iter: 179 loss: 5.17168228e-05
Iter: 180 loss: 5.1771156e-05
Iter: 181 loss: 5.17108892e-05
Iter: 182 loss: 5.16942018e-05
Iter: 183 loss: 5.17960216e-05
Iter: 184 loss: 5.16922264e-05
Iter: 185 loss: 5.16788787e-05
Iter: 186 loss: 5.17081389e-05
Iter: 187 loss: 5.16738e-05
Iter: 188 loss: 5.16615764e-05
Iter: 189 loss: 5.17398075e-05
Iter: 190 loss: 5.16602486e-05
Iter: 191 loss: 5.16497821e-05
Iter: 192 loss: 5.16806176e-05
Iter: 193 loss: 5.16466171e-05
Iter: 194 loss: 5.1637624e-05
Iter: 195 loss: 5.16427208e-05
Iter: 196 loss: 5.16316941e-05
Iter: 197 loss: 5.16220243e-05
Iter: 198 loss: 5.16893488e-05
Iter: 199 loss: 5.16211221e-05
Iter: 200 loss: 5.1613617e-05
Iter: 201 loss: 5.16387627e-05
Iter: 202 loss: 5.16115251e-05
Iter: 203 loss: 5.16048021e-05
Iter: 204 loss: 5.16340187e-05
Iter: 205 loss: 5.16034052e-05
Iter: 206 loss: 5.15978318e-05
Iter: 207 loss: 5.159992e-05
Iter: 208 loss: 5.15939973e-05
Iter: 209 loss: 5.15875472e-05
Iter: 210 loss: 5.16033651e-05
Iter: 211 loss: 5.15852698e-05
Iter: 212 loss: 5.15793763e-05
Iter: 213 loss: 5.15966312e-05
Iter: 214 loss: 5.15775755e-05
Iter: 215 loss: 5.15720894e-05
Iter: 216 loss: 5.15874854e-05
Iter: 217 loss: 5.15703359e-05
Iter: 218 loss: 5.15654538e-05
Iter: 219 loss: 5.15877218e-05
Iter: 220 loss: 5.15645734e-05
Iter: 221 loss: 5.15605e-05
Iter: 222 loss: 5.15806787e-05
Iter: 223 loss: 5.15597822e-05
Iter: 224 loss: 5.15566462e-05
Iter: 225 loss: 5.15697138e-05
Iter: 226 loss: 5.15559223e-05
Iter: 227 loss: 5.15528445e-05
Iter: 228 loss: 5.15632491e-05
Iter: 229 loss: 5.15521388e-05
Iter: 230 loss: 5.1549483e-05
Iter: 231 loss: 5.15512365e-05
Iter: 232 loss: 5.15479041e-05
Iter: 233 loss: 5.15451284e-05
Iter: 234 loss: 5.15583743e-05
Iter: 235 loss: 5.15446081e-05
Iter: 236 loss: 5.15422653e-05
Iter: 237 loss: 5.15549e-05
Iter: 238 loss: 5.15418869e-05
Iter: 239 loss: 5.15399e-05
Iter: 240 loss: 5.15441752e-05
Iter: 241 loss: 5.15391512e-05
Iter: 242 loss: 5.15371066e-05
Iter: 243 loss: 5.15402753e-05
Iter: 244 loss: 5.15361389e-05
Iter: 245 loss: 5.15342072e-05
Iter: 246 loss: 5.15381107e-05
Iter: 247 loss: 5.15334032e-05
Iter: 248 loss: 5.15314714e-05
Iter: 249 loss: 5.15375832e-05
Iter: 250 loss: 5.15309039e-05
Iter: 251 loss: 5.15291322e-05
Iter: 252 loss: 5.15342326e-05
Iter: 253 loss: 5.15286629e-05
Iter: 254 loss: 5.15271167e-05
Iter: 255 loss: 5.15328e-05
Iter: 256 loss: 5.15266656e-05
Iter: 257 loss: 5.15253923e-05
Iter: 258 loss: 5.15323554e-05
Iter: 259 loss: 5.15251486e-05
Iter: 260 loss: 5.15240426e-05
Iter: 261 loss: 5.15266802e-05
Iter: 262 loss: 5.1523708e-05
Iter: 263 loss: 5.15227366e-05
Iter: 264 loss: 5.15302672e-05
Iter: 265 loss: 5.15227584e-05
Iter: 266 loss: 5.15218562e-05
Iter: 267 loss: 5.15220599e-05
Iter: 268 loss: 5.15212741e-05
Iter: 269 loss: 5.15203828e-05
Iter: 270 loss: 5.15221691e-05
Iter: 271 loss: 5.15200591e-05
Iter: 272 loss: 5.15192696e-05
Iter: 273 loss: 5.15262363e-05
Iter: 274 loss: 5.15193024e-05
Iter: 275 loss: 5.15186039e-05
Iter: 276 loss: 5.15202046e-05
Iter: 277 loss: 5.15183565e-05
Iter: 278 loss: 5.1517778e-05
Iter: 279 loss: 5.15188076e-05
Iter: 280 loss: 5.15176289e-05
Iter: 281 loss: 5.1517e-05
Iter: 282 loss: 5.15181418e-05
Iter: 283 loss: 5.15166903e-05
Iter: 284 loss: 5.15162574e-05
Iter: 285 loss: 5.15171778e-05
Iter: 286 loss: 5.15159518e-05
Iter: 287 loss: 5.15154607e-05
Iter: 288 loss: 5.1517316e-05
Iter: 289 loss: 5.15152969e-05
Iter: 290 loss: 5.15147185e-05
Iter: 291 loss: 5.15180946e-05
Iter: 292 loss: 5.15147549e-05
Iter: 293 loss: 5.15143693e-05
Iter: 294 loss: 5.15150168e-05
Iter: 295 loss: 5.15141219e-05
Iter: 296 loss: 5.15137217e-05
Iter: 297 loss: 5.15161846e-05
Iter: 298 loss: 5.15137799e-05
Iter: 299 loss: 5.15133142e-05
Iter: 300 loss: 5.15144602e-05
Iter: 301 loss: 5.15133506e-05
Iter: 302 loss: 5.15131796e-05
Iter: 303 loss: 5.15138563e-05
Iter: 304 loss: 5.15130523e-05
Iter: 305 loss: 5.1512834e-05
Iter: 306 loss: 5.15128631e-05
Iter: 307 loss: 5.15125794e-05
Iter: 308 loss: 5.15123465e-05
Iter: 309 loss: 5.15140418e-05
Iter: 310 loss: 5.15124339e-05
Iter: 311 loss: 5.15121064e-05
Iter: 312 loss: 5.15131251e-05
Iter: 313 loss: 5.15121865e-05
Iter: 314 loss: 5.15119464e-05
Iter: 315 loss: 5.15121865e-05
Iter: 316 loss: 5.15118882e-05
Iter: 317 loss: 5.15116917e-05
Iter: 318 loss: 5.15122192e-05
Iter: 319 loss: 5.15116262e-05
Iter: 320 loss: 5.15114953e-05
Iter: 321 loss: 5.15118409e-05
Iter: 322 loss: 5.1511397e-05
Iter: 323 loss: 5.15113534e-05
Iter: 324 loss: 5.15116626e-05
Iter: 325 loss: 5.15112151e-05
Iter: 326 loss: 5.15109605e-05
Iter: 327 loss: 5.1511659e-05
Iter: 328 loss: 5.15110369e-05
Iter: 329 loss: 5.15108914e-05
Iter: 330 loss: 5.15111569e-05
Iter: 331 loss: 5.15108477e-05
Iter: 332 loss: 5.15107713e-05
Iter: 333 loss: 5.15112e-05
Iter: 334 loss: 5.15107677e-05
Iter: 335 loss: 5.15106221e-05
Iter: 336 loss: 5.15110369e-05
Iter: 337 loss: 5.15105967e-05
Iter: 338 loss: 5.15105567e-05
Iter: 339 loss: 5.15110405e-05
Iter: 340 loss: 5.1510473e-05
Iter: 341 loss: 5.15104693e-05
Iter: 342 loss: 5.15103529e-05
Iter: 343 loss: 5.15104039e-05
Iter: 344 loss: 5.15103129e-05
Iter: 345 loss: 5.15105858e-05
Iter: 346 loss: 5.1510262e-05
Iter: 347 loss: 5.15102074e-05
Iter: 348 loss: 5.15111533e-05
Iter: 349 loss: 5.15102111e-05
Iter: 350 loss: 5.15102256e-05
Iter: 351 loss: 5.1510222e-05
Iter: 352 loss: 5.15100619e-05
Iter: 353 loss: 5.15100583e-05
Iter: 354 loss: 5.15102802e-05
Iter: 355 loss: 5.15100473e-05
Iter: 356 loss: 5.15100328e-05
Iter: 357 loss: 5.15102e-05
Iter: 358 loss: 5.15099964e-05
Iter: 359 loss: 5.15099455e-05
Iter: 360 loss: 5.15100619e-05
Iter: 361 loss: 5.15098691e-05
Iter: 362 loss: 5.15099164e-05
Iter: 363 loss: 5.15099637e-05
Iter: 364 loss: 5.15098764e-05
Iter: 365 loss: 5.15097672e-05
Iter: 366 loss: 5.15099418e-05
Iter: 367 loss: 5.15097709e-05
Iter: 368 loss: 5.15097272e-05
Iter: 369 loss: 5.1509789e-05
Iter: 370 loss: 5.15097418e-05
Iter: 371 loss: 5.15097054e-05
Iter: 372 loss: 5.15098873e-05
Iter: 373 loss: 5.15096508e-05
Iter: 374 loss: 5.15096581e-05
Iter: 375 loss: 5.15098145e-05
Iter: 376 loss: 5.15096835e-05
Iter: 377 loss: 5.15095926e-05
Iter: 378 loss: 5.15096981e-05
Iter: 379 loss: 5.15096472e-05
Iter: 380 loss: 5.15096144e-05
Iter: 381 loss: 5.15097308e-05
Iter: 382 loss: 5.15096217e-05
Iter: 383 loss: 5.15096108e-05
Iter: 384 loss: 5.15097563e-05
Iter: 385 loss: 5.15096253e-05
Iter: 386 loss: 5.15095235e-05
Iter: 387 loss: 5.15097199e-05
Iter: 388 loss: 5.15095489e-05
Iter: 389 loss: 5.15095089e-05
Iter: 390 loss: 5.15095599e-05
Iter: 391 loss: 5.15094143e-05
Iter: 392 loss: 5.15095453e-05
Iter: 393 loss: 5.15095198e-05
Iter: 394 loss: 5.15095235e-05
Iter: 395 loss: 5.15094944e-05
Iter: 396 loss: 5.15094798e-05
Iter: 397 loss: 5.15095417e-05
Iter: 398 loss: 5.15095162e-05
Iter: 399 loss: 5.15094471e-05
Iter: 400 loss: 5.15094471e-05
Iter: 401 loss: 5.15095271e-05
Iter: 402 loss: 5.15095053e-05
Iter: 403 loss: 5.15094616e-05
Iter: 404 loss: 5.15094871e-05
Iter: 405 loss: 5.1509458e-05
Iter: 406 loss: 5.15094907e-05
Iter: 407 loss: 5.15094653e-05
Iter: 408 loss: 5.15094871e-05
Iter: 409 loss: 5.15094616e-05
Iter: 410 loss: 5.15094798e-05
Iter: 411 loss: 5.15094653e-05
Iter: 412 loss: 5.15094798e-05
Iter: 413 loss: 5.15094798e-05
Iter: 414 loss: 5.15094653e-05
Iter: 415 loss: 5.15094798e-05
Iter: 416 loss: 5.15094653e-05
Iter: 417 loss: 5.15094653e-05
Iter: 418 loss: 5.15094653e-05
Iter: 419 loss: 5.15094798e-05
Iter: 420 loss: 5.15094653e-05
Iter: 421 loss: 5.15094798e-05
Iter: 422 loss: 5.15094653e-05
Iter: 423 loss: 5.15094798e-05
Iter: 424 loss: 5.15095198e-05
Iter: 425 loss: 5.15095344e-05
Iter: 426 loss: 5.15095307e-05
Iter: 427 loss: 5.15095198e-05
Iter: 428 loss: 5.15095453e-05
Iter: 429 loss: 5.15094471e-05
Iter: 430 loss: 5.15095053e-05
Iter: 431 loss: 5.15095e-05
Iter: 432 loss: 5.1509538e-05
Iter: 433 loss: 5.15095307e-05
Iter: 434 loss: 5.15095235e-05
Iter: 435 loss: 5.15095235e-05
Iter: 436 loss: 5.1509538e-05
Iter: 437 loss: 5.15095744e-05
Iter: 438 loss: 5.1509538e-05
Iter: 439 loss: 5.15095562e-05
Iter: 440 loss: 5.15095453e-05
Iter: 441 loss: 5.15095198e-05
Iter: 442 loss: 5.15095235e-05
Iter: 443 loss: 5.1509498e-05
Iter: 444 loss: 5.15095089e-05
Iter: 445 loss: 5.15095162e-05
Iter: 446 loss: 5.15095198e-05
Iter: 447 loss: 5.15095235e-05
Iter: 448 loss: 5.15095162e-05
Iter: 449 loss: 5.15095162e-05
Iter: 450 loss: 5.15095198e-05
Iter: 451 loss: 5.15095162e-05
Iter: 452 loss: 5.15095198e-05
Iter: 453 loss: 5.15095162e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8
+ date
Tue Oct 27 17:49:09 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac12ef400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac12ef6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac12f4d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac127b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac127b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac1293488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac1266f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac1216950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac1228488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac11bf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac1228730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac1146158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac119bb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac10f78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac10f7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac10c3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac10c3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac119bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac103f8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac103f2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac106b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac103f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac10108c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0fe4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0f81840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0f33598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0f6b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0ef79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0f116a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0eb3488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0f11840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0e9f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0ea82f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faac0e3ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa9518e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7faa9518e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0190161839
Iter: 2 loss: 0.0186457876
Iter: 3 loss: 0.0172361676
Iter: 4 loss: 0.0124334488
Iter: 5 loss: 11263.4688
Iter: 6 loss: 0.0124334488
Iter: 7 loss: 0.00800206512
Iter: 8 loss: 0.123988062
Iter: 9 loss: 0.00787228532
Iter: 10 loss: 0.00426472584
Iter: 11 loss: 0.081008479
Iter: 12 loss: 0.00425971206
Iter: 13 loss: 0.00260854815
Iter: 14 loss: 0.015805807
Iter: 15 loss: 0.00240160711
Iter: 16 loss: 0.00166812609
Iter: 17 loss: 0.00595522299
Iter: 18 loss: 0.00154161907
Iter: 19 loss: 0.00113440747
Iter: 20 loss: 0.00113440363
Iter: 21 loss: 0.000890459924
Iter: 22 loss: 0.0035526494
Iter: 23 loss: 0.000885729678
Iter: 24 loss: 0.000740943593
Iter: 25 loss: 0.000873276207
Iter: 26 loss: 0.000655772863
Iter: 27 loss: 0.000535826548
Iter: 28 loss: 0.00171721762
Iter: 29 loss: 0.00052850612
Iter: 30 loss: 0.000453381392
Iter: 31 loss: 0.000621030806
Iter: 32 loss: 0.000424654339
Iter: 33 loss: 0.000355753349
Iter: 34 loss: 0.00060895097
Iter: 35 loss: 0.00033720053
Iter: 36 loss: 0.000290686527
Iter: 37 loss: 0.00047993823
Iter: 38 loss: 0.000281123241
Iter: 39 loss: 0.000246332493
Iter: 40 loss: 0.000382239115
Iter: 41 loss: 0.000237541986
Iter: 42 loss: 0.000211662496
Iter: 43 loss: 0.000340487633
Iter: 44 loss: 0.000207185134
Iter: 45 loss: 0.000185730503
Iter: 46 loss: 0.00028422568
Iter: 47 loss: 0.000181595417
Iter: 48 loss: 0.000165941557
Iter: 49 loss: 0.000256776228
Iter: 50 loss: 0.000163990364
Iter: 51 loss: 0.000152670094
Iter: 52 loss: 0.000199880204
Iter: 53 loss: 0.000150154592
Iter: 54 loss: 0.000141245924
Iter: 55 loss: 0.000145647471
Iter: 56 loss: 0.000135286886
Iter: 57 loss: 0.000126319603
Iter: 58 loss: 0.000211729726
Iter: 59 loss: 0.000125934646
Iter: 60 loss: 0.000119263525
Iter: 61 loss: 0.000148737352
Iter: 62 loss: 0.000117924195
Iter: 63 loss: 0.000113256669
Iter: 64 loss: 0.000114689719
Iter: 65 loss: 0.000109925779
Iter: 66 loss: 0.000104885476
Iter: 67 loss: 0.000146537728
Iter: 68 loss: 0.000104551844
Iter: 69 loss: 0.000100655758
Iter: 70 loss: 0.000116771604
Iter: 71 loss: 9.98359e-05
Iter: 72 loss: 9.67702363e-05
Iter: 73 loss: 0.000101569218
Iter: 74 loss: 9.53186245e-05
Iter: 75 loss: 9.24534688e-05
Iter: 76 loss: 0.000102842554
Iter: 77 loss: 9.17441503e-05
Iter: 78 loss: 8.91366799e-05
Iter: 79 loss: 9.56193253e-05
Iter: 80 loss: 8.82108143e-05
Iter: 81 loss: 8.5983e-05
Iter: 82 loss: 9.25097338e-05
Iter: 83 loss: 8.52983503e-05
Iter: 84 loss: 8.32574e-05
Iter: 85 loss: 9.42949337e-05
Iter: 86 loss: 8.2946528e-05
Iter: 87 loss: 8.13355655e-05
Iter: 88 loss: 8.60013752e-05
Iter: 89 loss: 8.08357581e-05
Iter: 90 loss: 7.93813088e-05
Iter: 91 loss: 8.33562808e-05
Iter: 92 loss: 7.890079e-05
Iter: 93 loss: 7.76426168e-05
Iter: 94 loss: 8.37027474e-05
Iter: 95 loss: 7.74190776e-05
Iter: 96 loss: 7.62347772e-05
Iter: 97 loss: 7.98288384e-05
Iter: 98 loss: 7.58793758e-05
Iter: 99 loss: 7.48979946e-05
Iter: 100 loss: 7.56470545e-05
Iter: 101 loss: 7.42998236e-05
Iter: 102 loss: 7.33374909e-05
Iter: 103 loss: 7.98447436e-05
Iter: 104 loss: 7.32438566e-05
Iter: 105 loss: 7.24115525e-05
Iter: 106 loss: 7.60954e-05
Iter: 107 loss: 7.22433615e-05
Iter: 108 loss: 7.15482456e-05
Iter: 109 loss: 7.1777089e-05
Iter: 110 loss: 7.10564782e-05
Iter: 111 loss: 7.02635371e-05
Iter: 112 loss: 7.49097526e-05
Iter: 113 loss: 7.01589161e-05
Iter: 114 loss: 6.95208437e-05
Iter: 115 loss: 7.03861879e-05
Iter: 116 loss: 6.92022e-05
Iter: 117 loss: 6.8578338e-05
Iter: 118 loss: 7.09461747e-05
Iter: 119 loss: 6.84285915e-05
Iter: 120 loss: 6.78926153e-05
Iter: 121 loss: 7.07769723e-05
Iter: 122 loss: 6.78126089e-05
Iter: 123 loss: 6.73587492e-05
Iter: 124 loss: 6.81251331e-05
Iter: 125 loss: 6.71537418e-05
Iter: 126 loss: 6.67082568e-05
Iter: 127 loss: 6.83959588e-05
Iter: 128 loss: 6.66017659e-05
Iter: 129 loss: 6.620778e-05
Iter: 130 loss: 6.79462173e-05
Iter: 131 loss: 6.61290833e-05
Iter: 132 loss: 6.57652272e-05
Iter: 133 loss: 6.64897234e-05
Iter: 134 loss: 6.56162156e-05
Iter: 135 loss: 6.52832532e-05
Iter: 136 loss: 6.56016564e-05
Iter: 137 loss: 6.50932197e-05
Iter: 138 loss: 6.47596244e-05
Iter: 139 loss: 6.78605e-05
Iter: 140 loss: 6.47449488e-05
Iter: 141 loss: 6.4469139e-05
Iter: 142 loss: 6.51373703e-05
Iter: 143 loss: 6.4370528e-05
Iter: 144 loss: 6.41303195e-05
Iter: 145 loss: 6.4302425e-05
Iter: 146 loss: 6.39813879e-05
Iter: 147 loss: 6.36980476e-05
Iter: 148 loss: 6.50696893e-05
Iter: 149 loss: 6.36482582e-05
Iter: 150 loss: 6.34133758e-05
Iter: 151 loss: 6.38259226e-05
Iter: 152 loss: 6.33097079e-05
Iter: 153 loss: 6.30875e-05
Iter: 154 loss: 6.39654536e-05
Iter: 155 loss: 6.30370196e-05
Iter: 156 loss: 6.28373164e-05
Iter: 157 loss: 6.3766638e-05
Iter: 158 loss: 6.28002e-05
Iter: 159 loss: 6.26281253e-05
Iter: 160 loss: 6.29124e-05
Iter: 161 loss: 6.2549705e-05
Iter: 162 loss: 6.23851884e-05
Iter: 163 loss: 6.3164247e-05
Iter: 164 loss: 6.2355175e-05
Iter: 165 loss: 6.22104053e-05
Iter: 166 loss: 6.27830086e-05
Iter: 167 loss: 6.21772779e-05
Iter: 168 loss: 6.20477222e-05
Iter: 169 loss: 6.21286308e-05
Iter: 170 loss: 6.19649509e-05
Iter: 171 loss: 6.1834282e-05
Iter: 172 loss: 6.24651e-05
Iter: 173 loss: 6.18109916e-05
Iter: 174 loss: 6.1700317e-05
Iter: 175 loss: 6.22746156e-05
Iter: 176 loss: 6.16827747e-05
Iter: 177 loss: 6.15782192e-05
Iter: 178 loss: 6.17230908e-05
Iter: 179 loss: 6.15261233e-05
Iter: 180 loss: 6.14278106e-05
Iter: 181 loss: 6.15613535e-05
Iter: 182 loss: 6.13787051e-05
Iter: 183 loss: 6.12759541e-05
Iter: 184 loss: 6.18554186e-05
Iter: 185 loss: 6.12615913e-05
Iter: 186 loss: 6.11738069e-05
Iter: 187 loss: 6.12964795e-05
Iter: 188 loss: 6.11304422e-05
Iter: 189 loss: 6.10475254e-05
Iter: 190 loss: 6.14294113e-05
Iter: 191 loss: 6.10318639e-05
Iter: 192 loss: 6.0953902e-05
Iter: 193 loss: 6.12397271e-05
Iter: 194 loss: 6.09345589e-05
Iter: 195 loss: 6.08678783e-05
Iter: 196 loss: 6.09718845e-05
Iter: 197 loss: 6.0836559e-05
Iter: 198 loss: 6.07711409e-05
Iter: 199 loss: 6.12295698e-05
Iter: 200 loss: 6.07653e-05
Iter: 201 loss: 6.07090915e-05
Iter: 202 loss: 6.07613802e-05
Iter: 203 loss: 6.06768663e-05
Iter: 204 loss: 6.06168724e-05
Iter: 205 loss: 6.07532129e-05
Iter: 206 loss: 6.05943897e-05
Iter: 207 loss: 6.05370806e-05
Iter: 208 loss: 6.08028713e-05
Iter: 209 loss: 6.05265e-05
Iter: 210 loss: 6.04766683e-05
Iter: 211 loss: 6.0749986e-05
Iter: 212 loss: 6.04693523e-05
Iter: 213 loss: 6.0429069e-05
Iter: 214 loss: 6.04319684e-05
Iter: 215 loss: 6.03977314e-05
Iter: 216 loss: 6.03517765e-05
Iter: 217 loss: 6.05119531e-05
Iter: 218 loss: 6.03398585e-05
Iter: 219 loss: 6.02956534e-05
Iter: 220 loss: 6.04882043e-05
Iter: 221 loss: 6.02868022e-05
Iter: 222 loss: 6.02501968e-05
Iter: 223 loss: 6.03009612e-05
Iter: 224 loss: 6.02319597e-05
Iter: 225 loss: 6.019594e-05
Iter: 226 loss: 6.04340821e-05
Iter: 227 loss: 6.0192142e-05
Iter: 228 loss: 6.01602223e-05
Iter: 229 loss: 6.02060682e-05
Iter: 230 loss: 6.01446e-05
Iter: 231 loss: 6.01158827e-05
Iter: 232 loss: 6.02642249e-05
Iter: 233 loss: 6.01114371e-05
Iter: 234 loss: 6.00858402e-05
Iter: 235 loss: 6.0168255e-05
Iter: 236 loss: 6.00785461e-05
Iter: 237 loss: 6.00544445e-05
Iter: 238 loss: 6.00797539e-05
Iter: 239 loss: 6.00410567e-05
Iter: 240 loss: 6.00154162e-05
Iter: 241 loss: 6.0085531e-05
Iter: 242 loss: 6.00071362e-05
Iter: 243 loss: 5.99836749e-05
Iter: 244 loss: 6.01648062e-05
Iter: 245 loss: 5.99819432e-05
Iter: 246 loss: 5.99626583e-05
Iter: 247 loss: 5.99852137e-05
Iter: 248 loss: 5.99524428e-05
Iter: 249 loss: 5.99324703e-05
Iter: 250 loss: 5.99589621e-05
Iter: 251 loss: 5.99224113e-05
Iter: 252 loss: 5.99016676e-05
Iter: 253 loss: 5.99883351e-05
Iter: 254 loss: 5.98973056e-05
Iter: 255 loss: 5.98784463e-05
Iter: 256 loss: 5.99385057e-05
Iter: 257 loss: 5.98729494e-05
Iter: 258 loss: 5.98560873e-05
Iter: 259 loss: 5.99033301e-05
Iter: 260 loss: 5.98506267e-05
Iter: 261 loss: 5.98348961e-05
Iter: 262 loss: 5.99039377e-05
Iter: 263 loss: 5.98318074e-05
Iter: 264 loss: 5.98173756e-05
Iter: 265 loss: 5.98437109e-05
Iter: 266 loss: 5.98110346e-05
Iter: 267 loss: 5.9797072e-05
Iter: 268 loss: 5.9857859e-05
Iter: 269 loss: 5.97941253e-05
Iter: 270 loss: 5.97806793e-05
Iter: 271 loss: 5.98178376e-05
Iter: 272 loss: 5.97762846e-05
Iter: 273 loss: 5.97643811e-05
Iter: 274 loss: 5.97755861e-05
Iter: 275 loss: 5.97576436e-05
Iter: 276 loss: 5.97458857e-05
Iter: 277 loss: 5.9826536e-05
Iter: 278 loss: 5.97447688e-05
Iter: 279 loss: 5.97343169e-05
Iter: 280 loss: 5.97676808e-05
Iter: 281 loss: 5.9731261e-05
Iter: 282 loss: 5.97220933e-05
Iter: 283 loss: 5.9730748e-05
Iter: 284 loss: 5.97169783e-05
Iter: 285 loss: 5.97069848e-05
Iter: 286 loss: 5.97327235e-05
Iter: 287 loss: 5.97034596e-05
Iter: 288 loss: 5.96940554e-05
Iter: 289 loss: 5.97292637e-05
Iter: 290 loss: 5.96916143e-05
Iter: 291 loss: 5.96829341e-05
Iter: 292 loss: 5.97173675e-05
Iter: 293 loss: 5.96808968e-05
Iter: 294 loss: 5.96734499e-05
Iter: 295 loss: 5.96889877e-05
Iter: 296 loss: 5.96704413e-05
Iter: 297 loss: 5.96625869e-05
Iter: 298 loss: 5.96970858e-05
Iter: 299 loss: 5.96611717e-05
Iter: 300 loss: 5.96545724e-05
Iter: 301 loss: 5.96692917e-05
Iter: 302 loss: 5.96520549e-05
Iter: 303 loss: 5.96458704e-05
Iter: 304 loss: 5.96778409e-05
Iter: 305 loss: 5.96449645e-05
Iter: 306 loss: 5.96392783e-05
Iter: 307 loss: 5.96446152e-05
Iter: 308 loss: 5.96359605e-05
Iter: 309 loss: 5.96304817e-05
Iter: 310 loss: 5.96455247e-05
Iter: 311 loss: 5.96286336e-05
Iter: 312 loss: 5.96232348e-05
Iter: 313 loss: 5.96645332e-05
Iter: 314 loss: 5.96228419e-05
Iter: 315 loss: 5.96187601e-05
Iter: 316 loss: 5.96204081e-05
Iter: 317 loss: 5.96157734e-05
Iter: 318 loss: 5.96108221e-05
Iter: 319 loss: 5.96219834e-05
Iter: 320 loss: 5.96087921e-05
Iter: 321 loss: 5.96038226e-05
Iter: 322 loss: 5.96177415e-05
Iter: 323 loss: 5.96024438e-05
Iter: 324 loss: 5.95977217e-05
Iter: 325 loss: 5.96214159e-05
Iter: 326 loss: 5.95970596e-05
Iter: 327 loss: 5.9593116e-05
Iter: 328 loss: 5.96020109e-05
Iter: 329 loss: 5.9591679e-05
Iter: 330 loss: 5.95879465e-05
Iter: 331 loss: 5.96011159e-05
Iter: 332 loss: 5.95868696e-05
Iter: 333 loss: 5.95833553e-05
Iter: 334 loss: 5.95941638e-05
Iter: 335 loss: 5.95823294e-05
Iter: 336 loss: 5.95791e-05
Iter: 337 loss: 5.95888814e-05
Iter: 338 loss: 5.95782076e-05
Iter: 339 loss: 5.95749698e-05
Iter: 340 loss: 5.95854e-05
Iter: 341 loss: 5.95740894e-05
Iter: 342 loss: 5.95713318e-05
Iter: 343 loss: 5.95765741e-05
Iter: 344 loss: 5.95701822e-05
Iter: 345 loss: 5.95676029e-05
Iter: 346 loss: 5.95786441e-05
Iter: 347 loss: 5.95670717e-05
Iter: 348 loss: 5.9564416e-05
Iter: 349 loss: 5.95730307e-05
Iter: 350 loss: 5.95637284e-05
Iter: 351 loss: 5.95615638e-05
Iter: 352 loss: 5.95618039e-05
Iter: 353 loss: 5.95597739e-05
Iter: 354 loss: 5.95571364e-05
Iter: 355 loss: 5.95668862e-05
Iter: 356 loss: 5.95565143e-05
Iter: 357 loss: 5.9554e-05
Iter: 358 loss: 5.95651727e-05
Iter: 359 loss: 5.95535093e-05
Iter: 360 loss: 5.95514066e-05
Iter: 361 loss: 5.95572055e-05
Iter: 362 loss: 5.95507809e-05
Iter: 363 loss: 5.95485544e-05
Iter: 364 loss: 5.95545935e-05
Iter: 365 loss: 5.9548e-05
Iter: 366 loss: 5.95459278e-05
Iter: 367 loss: 5.95521924e-05
Iter: 368 loss: 5.95453967e-05
Iter: 369 loss: 5.95434685e-05
Iter: 370 loss: 5.95500824e-05
Iter: 371 loss: 5.95429883e-05
Iter: 372 loss: 5.95412748e-05
Iter: 373 loss: 5.95457022e-05
Iter: 374 loss: 5.954062e-05
Iter: 375 loss: 5.95390084e-05
Iter: 376 loss: 5.95449965e-05
Iter: 377 loss: 5.95386264e-05
Iter: 378 loss: 5.95370802e-05
Iter: 379 loss: 5.95391466e-05
Iter: 380 loss: 5.95364691e-05
Iter: 381 loss: 5.9534912e-05
Iter: 382 loss: 5.95464e-05
Iter: 383 loss: 5.95348793e-05
Iter: 384 loss: 5.95336642e-05
Iter: 385 loss: 5.95336351e-05
Iter: 386 loss: 5.95326601e-05
Iter: 387 loss: 5.95312522e-05
Iter: 388 loss: 5.95346974e-05
Iter: 389 loss: 5.95306628e-05
Iter: 390 loss: 5.95292731e-05
Iter: 391 loss: 5.95357487e-05
Iter: 392 loss: 5.95289821e-05
Iter: 393 loss: 5.95277561e-05
Iter: 394 loss: 5.95319216e-05
Iter: 395 loss: 5.95274505e-05
Iter: 396 loss: 5.95263773e-05
Iter: 397 loss: 5.95301317e-05
Iter: 398 loss: 5.95260208e-05
Iter: 399 loss: 5.95249585e-05
Iter: 400 loss: 5.9527636e-05
Iter: 401 loss: 5.95246529e-05
Iter: 402 loss: 5.95236525e-05
Iter: 403 loss: 5.95271777e-05
Iter: 404 loss: 5.9523285e-05
Iter: 405 loss: 5.95224265e-05
Iter: 406 loss: 5.95251258e-05
Iter: 407 loss: 5.95222627e-05
Iter: 408 loss: 5.95212077e-05
Iter: 409 loss: 5.95242127e-05
Iter: 410 loss: 5.95210586e-05
Iter: 411 loss: 5.95201891e-05
Iter: 412 loss: 5.95217e-05
Iter: 413 loss: 5.95198217e-05
Iter: 414 loss: 5.95190722e-05
Iter: 415 loss: 5.95231868e-05
Iter: 416 loss: 5.95188721e-05
Iter: 417 loss: 5.95182355e-05
Iter: 418 loss: 5.9519436e-05
Iter: 419 loss: 5.95178208e-05
Iter: 420 loss: 5.95171769e-05
Iter: 421 loss: 5.95177698e-05
Iter: 422 loss: 5.95167112e-05
Iter: 423 loss: 5.95159145e-05
Iter: 424 loss: 5.95190904e-05
Iter: 425 loss: 5.95157981e-05
Iter: 426 loss: 5.95150486e-05
Iter: 427 loss: 5.95180572e-05
Iter: 428 loss: 5.95149395e-05
Iter: 429 loss: 5.95143e-05
Iter: 430 loss: 5.95162783e-05
Iter: 431 loss: 5.95140882e-05
Iter: 432 loss: 5.95135389e-05
Iter: 433 loss: 5.95154343e-05
Iter: 434 loss: 5.95133351e-05
Iter: 435 loss: 5.95127785e-05
Iter: 436 loss: 5.95141319e-05
Iter: 437 loss: 5.95125966e-05
Iter: 438 loss: 5.95120509e-05
Iter: 439 loss: 5.9514e-05
Iter: 440 loss: 5.95119382e-05
Iter: 441 loss: 5.9511367e-05
Iter: 442 loss: 5.95127094e-05
Iter: 443 loss: 5.95111233e-05
Iter: 444 loss: 5.95107e-05
Iter: 445 loss: 5.95120837e-05
Iter: 446 loss: 5.9510483e-05
Iter: 447 loss: 5.95099773e-05
Iter: 448 loss: 5.95115234e-05
Iter: 449 loss: 5.95099082e-05
Iter: 450 loss: 5.95094862e-05
Iter: 451 loss: 5.95113524e-05
Iter: 452 loss: 5.9509428e-05
Iter: 453 loss: 5.95089659e-05
Iter: 454 loss: 5.95090132e-05
Iter: 455 loss: 5.9508704e-05
Iter: 456 loss: 5.95081729e-05
Iter: 457 loss: 5.95094862e-05
Iter: 458 loss: 5.95080382e-05
Iter: 459 loss: 5.9507649e-05
Iter: 460 loss: 5.95096499e-05
Iter: 461 loss: 5.95075326e-05
Iter: 462 loss: 5.95071906e-05
Iter: 463 loss: 5.95083948e-05
Iter: 464 loss: 5.95070378e-05
Iter: 465 loss: 5.95067031e-05
Iter: 466 loss: 5.95077145e-05
Iter: 467 loss: 5.95065649e-05
Iter: 468 loss: 5.95061938e-05
Iter: 469 loss: 5.95073325e-05
Iter: 470 loss: 5.95061319e-05
Iter: 471 loss: 5.95057791e-05
Iter: 472 loss: 5.95066958e-05
Iter: 473 loss: 5.95057718e-05
Iter: 474 loss: 5.95053898e-05
Iter: 475 loss: 5.95061938e-05
Iter: 476 loss: 5.9505328e-05
Iter: 477 loss: 5.95050442e-05
Iter: 478 loss: 5.95057281e-05
Iter: 479 loss: 5.95049423e-05
Iter: 480 loss: 5.9504644e-05
Iter: 481 loss: 5.95055026e-05
Iter: 482 loss: 5.95044658e-05
Iter: 483 loss: 5.95042729e-05
Iter: 484 loss: 5.95053789e-05
Iter: 485 loss: 5.95041856e-05
Iter: 486 loss: 5.95039382e-05
Iter: 487 loss: 5.95042438e-05
Iter: 488 loss: 5.95038182e-05
Iter: 489 loss: 5.95034944e-05
Iter: 490 loss: 5.95038728e-05
Iter: 491 loss: 5.95034035e-05
Iter: 492 loss: 5.9503087e-05
Iter: 493 loss: 5.95042438e-05
Iter: 494 loss: 5.95030142e-05
Iter: 495 loss: 5.95027086e-05
Iter: 496 loss: 5.9503891e-05
Iter: 497 loss: 5.95028032e-05
Iter: 498 loss: 5.95025485e-05
Iter: 499 loss: 5.95029451e-05
Iter: 500 loss: 5.95023303e-05
Iter: 501 loss: 5.95021847e-05
Iter: 502 loss: 5.95030651e-05
Iter: 503 loss: 5.95020938e-05
Iter: 504 loss: 5.95019e-05
Iter: 505 loss: 5.95023484e-05
Iter: 506 loss: 5.950181e-05
Iter: 507 loss: 5.95015808e-05
Iter: 508 loss: 5.95025485e-05
Iter: 509 loss: 5.95015699e-05
Iter: 510 loss: 5.95014208e-05
Iter: 511 loss: 5.95017627e-05
Iter: 512 loss: 5.95013262e-05
Iter: 513 loss: 5.95012025e-05
Iter: 514 loss: 5.95017082e-05
Iter: 515 loss: 5.95010897e-05
Iter: 516 loss: 5.95009515e-05
Iter: 517 loss: 5.95016681e-05
Iter: 518 loss: 5.95009151e-05
Iter: 519 loss: 5.95006895e-05
Iter: 520 loss: 5.9501006e-05
Iter: 521 loss: 5.9500635e-05
Iter: 522 loss: 5.95004931e-05
Iter: 523 loss: 5.9500715e-05
Iter: 524 loss: 5.95004531e-05
Iter: 525 loss: 5.95002748e-05
Iter: 526 loss: 5.95006568e-05
Iter: 527 loss: 5.95002348e-05
Iter: 528 loss: 5.95001547e-05
Iter: 529 loss: 5.95009551e-05
Iter: 530 loss: 5.95000893e-05
Iter: 531 loss: 5.94999328e-05
Iter: 532 loss: 5.95003221e-05
Iter: 533 loss: 5.94998564e-05
Iter: 534 loss: 5.94997036e-05
Iter: 535 loss: 5.95000747e-05
Iter: 536 loss: 5.94997146e-05
Iter: 537 loss: 5.94996e-05
Iter: 538 loss: 5.94999401e-05
Iter: 539 loss: 5.94995581e-05
Iter: 540 loss: 5.94994162e-05
Iter: 541 loss: 5.94998382e-05
Iter: 542 loss: 5.94994e-05
Iter: 543 loss: 5.9499238e-05
Iter: 544 loss: 5.94996964e-05
Iter: 545 loss: 5.94993326e-05
Iter: 546 loss: 5.9499238e-05
Iter: 547 loss: 5.94994417e-05
Iter: 548 loss: 5.94991543e-05
Iter: 549 loss: 5.94990488e-05
Iter: 550 loss: 5.94994781e-05
Iter: 551 loss: 5.94990634e-05
Iter: 552 loss: 5.94989579e-05
Iter: 553 loss: 5.9499187e-05
Iter: 554 loss: 5.94989469e-05
Iter: 555 loss: 5.94988269e-05
Iter: 556 loss: 5.94988924e-05
Iter: 557 loss: 5.94987832e-05
Iter: 558 loss: 5.94986559e-05
Iter: 559 loss: 5.94988742e-05
Iter: 560 loss: 5.94985977e-05
Iter: 561 loss: 5.9498514e-05
Iter: 562 loss: 5.94989688e-05
Iter: 563 loss: 5.9498554e-05
Iter: 564 loss: 5.94984776e-05
Iter: 565 loss: 5.94988742e-05
Iter: 566 loss: 5.94984449e-05
Iter: 567 loss: 5.94983067e-05
Iter: 568 loss: 5.9498514e-05
Iter: 569 loss: 5.94983139e-05
Iter: 570 loss: 5.9498343e-05
Iter: 571 loss: 5.9498605e-05
Iter: 572 loss: 5.94982412e-05
Iter: 573 loss: 5.94981939e-05
Iter: 574 loss: 5.94984e-05
Iter: 575 loss: 5.9498172e-05
Iter: 576 loss: 5.9498092e-05
Iter: 577 loss: 5.94982594e-05
Iter: 578 loss: 5.94980447e-05
Iter: 579 loss: 5.94980484e-05
Iter: 580 loss: 5.94982121e-05
Iter: 581 loss: 5.94980702e-05
Iter: 582 loss: 5.94979319e-05
Iter: 583 loss: 5.94980738e-05
Iter: 584 loss: 5.94979465e-05
Iter: 585 loss: 5.94979501e-05
Iter: 586 loss: 5.94981029e-05
Iter: 587 loss: 5.94978665e-05
Iter: 588 loss: 5.9497841e-05
Iter: 589 loss: 5.94978519e-05
Iter: 590 loss: 5.9497761e-05
Iter: 591 loss: 5.94977391e-05
Iter: 592 loss: 5.94978774e-05
Iter: 593 loss: 5.94976045e-05
Iter: 594 loss: 5.94976e-05
Iter: 595 loss: 5.94977682e-05
Iter: 596 loss: 5.94976082e-05
Iter: 597 loss: 5.94975e-05
Iter: 598 loss: 5.94979247e-05
Iter: 599 loss: 5.949755e-05
Iter: 600 loss: 5.94975281e-05
Iter: 601 loss: 5.94974881e-05
Iter: 602 loss: 5.94974954e-05
Iter: 603 loss: 5.94973681e-05
Iter: 604 loss: 5.94976045e-05
Iter: 605 loss: 5.94974044e-05
Iter: 606 loss: 5.94973571e-05
Iter: 607 loss: 5.94975e-05
Iter: 608 loss: 5.94974481e-05
Iter: 609 loss: 5.9497288e-05
Iter: 610 loss: 5.94974299e-05
Iter: 611 loss: 5.94973135e-05
Iter: 612 loss: 5.94972735e-05
Iter: 613 loss: 5.94974845e-05
Iter: 614 loss: 5.94973244e-05
Iter: 615 loss: 5.94972807e-05
Iter: 616 loss: 5.94973244e-05
Iter: 617 loss: 5.94973098e-05
Iter: 618 loss: 5.94972189e-05
Iter: 619 loss: 5.9497288e-05
Iter: 620 loss: 5.94971789e-05
Iter: 621 loss: 5.94971134e-05
Iter: 622 loss: 5.94971498e-05
Iter: 623 loss: 5.94971061e-05
Iter: 624 loss: 5.94970115e-05
Iter: 625 loss: 5.94971498e-05
Iter: 626 loss: 5.94970152e-05
Iter: 627 loss: 5.94970079e-05
Iter: 628 loss: 5.94970443e-05
Iter: 629 loss: 5.94969242e-05
Iter: 630 loss: 5.94969461e-05
Iter: 631 loss: 5.94971498e-05
Iter: 632 loss: 5.94969933e-05
Iter: 633 loss: 5.94969679e-05
Iter: 634 loss: 5.94969606e-05
Iter: 635 loss: 5.9497077e-05
Iter: 636 loss: 5.94969424e-05
Iter: 637 loss: 5.94969788e-05
Iter: 638 loss: 5.9496997e-05
Iter: 639 loss: 5.94969424e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2
+ date
Tue Oct 27 17:57:51 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8410730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59f06abae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59f06abbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59f0619a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c839cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c83b89d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8389b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c833aa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8350400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c82e3730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8350158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c82c4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c826a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c821fb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c821ff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c821f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c81f4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8205d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c81cf8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8205ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8183488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8134c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c80f27b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c8106f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c80a8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c80ade18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c808d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c802e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59c808d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59b0245ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59b0279a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59b0279bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59b02796a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59b02797b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59b018a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59b0196ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0204725284
Iter: 2 loss: 0.0191309899
Iter: 3 loss: 0.0149188749
Iter: 4 loss: 7780.92627
Iter: 5 loss: 0.0416428708
Iter: 6 loss: 0.0195917562
Iter: 7 loss: 0.0140912607
Iter: 8 loss: 0.0140730664
Iter: 9 loss: 0.0109553756
Iter: 10 loss: 0.0491869934
Iter: 11 loss: 0.0105983801
Iter: 12 loss: 0.00736534223
Iter: 13 loss: 0.0743334368
Iter: 14 loss: 0.00731588155
Iter: 15 loss: 0.00549761113
Iter: 16 loss: 0.0114637222
Iter: 17 loss: 0.00487079
Iter: 18 loss: 0.0034727375
Iter: 19 loss: 0.040146552
Iter: 20 loss: 0.00346121169
Iter: 21 loss: 0.00256547797
Iter: 22 loss: 1.41124129
Iter: 23 loss: 0.00256547751
Iter: 24 loss: 0.00207258668
Iter: 25 loss: 0.0045356378
Iter: 26 loss: 0.00198565633
Iter: 27 loss: 0.00171043584
Iter: 28 loss: 0.00325030903
Iter: 29 loss: 0.00165451015
Iter: 30 loss: 0.0013972267
Iter: 31 loss: 0.00396305183
Iter: 32 loss: 0.00139261829
Iter: 33 loss: 0.00124823162
Iter: 34 loss: 0.00140528858
Iter: 35 loss: 0.00116347708
Iter: 36 loss: 0.00103266793
Iter: 37 loss: 0.00144976773
Iter: 38 loss: 0.000994038535
Iter: 39 loss: 0.000881301647
Iter: 40 loss: 0.000990783796
Iter: 41 loss: 0.000815326
Iter: 42 loss: 0.000715712435
Iter: 43 loss: 0.00176316383
Iter: 44 loss: 0.000711411703
Iter: 45 loss: 0.000648553774
Iter: 46 loss: 0.000757280795
Iter: 47 loss: 0.00061990961
Iter: 48 loss: 0.000557875
Iter: 49 loss: 0.000719743257
Iter: 50 loss: 0.000536814157
Iter: 51 loss: 0.000484151096
Iter: 52 loss: 0.000780151109
Iter: 53 loss: 0.000476222369
Iter: 54 loss: 0.000439495227
Iter: 55 loss: 0.000488137681
Iter: 56 loss: 0.0004202493
Iter: 57 loss: 0.000382277358
Iter: 58 loss: 0.000465814781
Iter: 59 loss: 0.000367457164
Iter: 60 loss: 0.000338970218
Iter: 61 loss: 0.000571765355
Iter: 62 loss: 0.000337634207
Iter: 63 loss: 0.000316324644
Iter: 64 loss: 0.000419994525
Iter: 65 loss: 0.000312228512
Iter: 66 loss: 0.000293491728
Iter: 67 loss: 0.000351079361
Iter: 68 loss: 0.000288166339
Iter: 69 loss: 0.000270087272
Iter: 70 loss: 0.000405420666
Iter: 71 loss: 0.000268360716
Iter: 72 loss: 0.000254188082
Iter: 73 loss: 0.000255226827
Iter: 74 loss: 0.000243160088
Iter: 75 loss: 0.000227978162
Iter: 76 loss: 0.000303792098
Iter: 77 loss: 0.000225311524
Iter: 78 loss: 0.000212268613
Iter: 79 loss: 0.000235513
Iter: 80 loss: 0.000206527693
Iter: 81 loss: 0.000195160304
Iter: 82 loss: 0.000263769267
Iter: 83 loss: 0.000193683343
Iter: 84 loss: 0.000184007964
Iter: 85 loss: 0.00020444821
Iter: 86 loss: 0.000180199437
Iter: 87 loss: 0.000171834923
Iter: 88 loss: 0.000206552388
Iter: 89 loss: 0.000170015061
Iter: 90 loss: 0.000161524018
Iter: 91 loss: 0.000196322799
Iter: 92 loss: 0.000159597636
Iter: 93 loss: 0.000153519475
Iter: 94 loss: 0.000157192379
Iter: 95 loss: 0.000149585714
Iter: 96 loss: 0.000143263169
Iter: 97 loss: 0.000163108314
Iter: 98 loss: 0.000141449011
Iter: 99 loss: 0.000136549876
Iter: 100 loss: 0.000207081815
Iter: 101 loss: 0.000136530813
Iter: 102 loss: 0.000132801273
Iter: 103 loss: 0.000159600328
Iter: 104 loss: 0.000132509565
Iter: 105 loss: 0.000129890133
Iter: 106 loss: 0.000128163723
Iter: 107 loss: 0.00012716162
Iter: 108 loss: 0.000123612786
Iter: 109 loss: 0.000133089
Iter: 110 loss: 0.000122437224
Iter: 111 loss: 0.000119223609
Iter: 112 loss: 0.000123732432
Iter: 113 loss: 0.000117636009
Iter: 114 loss: 0.000114202667
Iter: 115 loss: 0.00013357398
Iter: 116 loss: 0.000113729984
Iter: 117 loss: 0.000110963359
Iter: 118 loss: 0.000118150412
Iter: 119 loss: 0.000110011868
Iter: 120 loss: 0.000107457126
Iter: 121 loss: 0.000112618465
Iter: 122 loss: 0.000106423424
Iter: 123 loss: 0.000103814695
Iter: 124 loss: 0.000119561795
Iter: 125 loss: 0.000103492064
Iter: 126 loss: 0.000101475816
Iter: 127 loss: 0.000105976163
Iter: 128 loss: 0.000100702229
Iter: 129 loss: 9.8683231e-05
Iter: 130 loss: 0.00010380106
Iter: 131 loss: 9.79824617e-05
Iter: 132 loss: 9.60077232e-05
Iter: 133 loss: 0.000101167971
Iter: 134 loss: 9.53388735e-05
Iter: 135 loss: 9.36958386e-05
Iter: 136 loss: 0.000106019208
Iter: 137 loss: 9.35560383e-05
Iter: 138 loss: 9.2188e-05
Iter: 139 loss: 0.000105189654
Iter: 140 loss: 9.21394458e-05
Iter: 141 loss: 9.13399344e-05
Iter: 142 loss: 9.00721061e-05
Iter: 143 loss: 9.00594605e-05
Iter: 144 loss: 8.85984191e-05
Iter: 145 loss: 9.03529144e-05
Iter: 146 loss: 8.78271603e-05
Iter: 147 loss: 8.64942704e-05
Iter: 148 loss: 9.94335e-05
Iter: 149 loss: 8.64446047e-05
Iter: 150 loss: 8.53008241e-05
Iter: 151 loss: 8.6525084e-05
Iter: 152 loss: 8.46717157e-05
Iter: 153 loss: 8.35504761e-05
Iter: 154 loss: 8.7055043e-05
Iter: 155 loss: 8.3222083e-05
Iter: 156 loss: 8.21058711e-05
Iter: 157 loss: 8.76583872e-05
Iter: 158 loss: 8.19181223e-05
Iter: 159 loss: 8.10472338e-05
Iter: 160 loss: 8.21939102e-05
Iter: 161 loss: 8.06056196e-05
Iter: 162 loss: 7.97304383e-05
Iter: 163 loss: 8.47655756e-05
Iter: 164 loss: 7.96105523e-05
Iter: 165 loss: 7.88280304e-05
Iter: 166 loss: 7.97718531e-05
Iter: 167 loss: 7.84162112e-05
Iter: 168 loss: 7.76387751e-05
Iter: 169 loss: 8.00357375e-05
Iter: 170 loss: 7.74105e-05
Iter: 171 loss: 7.69387261e-05
Iter: 172 loss: 7.69206817e-05
Iter: 173 loss: 7.64714059e-05
Iter: 174 loss: 7.63020143e-05
Iter: 175 loss: 7.60563562e-05
Iter: 176 loss: 7.55687652e-05
Iter: 177 loss: 7.57075322e-05
Iter: 178 loss: 7.52168271e-05
Iter: 179 loss: 7.46192891e-05
Iter: 180 loss: 7.59941686e-05
Iter: 181 loss: 7.43965793e-05
Iter: 182 loss: 7.3763018e-05
Iter: 183 loss: 7.70406332e-05
Iter: 184 loss: 7.36613947e-05
Iter: 185 loss: 7.31445107e-05
Iter: 186 loss: 7.46839869e-05
Iter: 187 loss: 7.2987983e-05
Iter: 188 loss: 7.24946294e-05
Iter: 189 loss: 7.3619085e-05
Iter: 190 loss: 7.23094e-05
Iter: 191 loss: 7.18452065e-05
Iter: 192 loss: 7.34090572e-05
Iter: 193 loss: 7.17192597e-05
Iter: 194 loss: 7.12353649e-05
Iter: 195 loss: 7.2109935e-05
Iter: 196 loss: 7.10250461e-05
Iter: 197 loss: 7.05626589e-05
Iter: 198 loss: 7.24399724e-05
Iter: 199 loss: 7.04595659e-05
Iter: 200 loss: 7.00472956e-05
Iter: 201 loss: 7.12050241e-05
Iter: 202 loss: 6.99159718e-05
Iter: 203 loss: 6.95063e-05
Iter: 204 loss: 7.02154139e-05
Iter: 205 loss: 6.93250477e-05
Iter: 206 loss: 6.9109e-05
Iter: 207 loss: 6.90658126e-05
Iter: 208 loss: 6.88593209e-05
Iter: 209 loss: 6.85042469e-05
Iter: 210 loss: 6.85038904e-05
Iter: 211 loss: 6.81468373e-05
Iter: 212 loss: 6.93599723e-05
Iter: 213 loss: 6.80507947e-05
Iter: 214 loss: 6.77151038e-05
Iter: 215 loss: 6.80040466e-05
Iter: 216 loss: 6.7517336e-05
Iter: 217 loss: 6.71434245e-05
Iter: 218 loss: 6.83100661e-05
Iter: 219 loss: 6.70344307e-05
Iter: 220 loss: 6.66808628e-05
Iter: 221 loss: 6.81214733e-05
Iter: 222 loss: 6.66027117e-05
Iter: 223 loss: 6.63046667e-05
Iter: 224 loss: 6.803016e-05
Iter: 225 loss: 6.62646926e-05
Iter: 226 loss: 6.59973302e-05
Iter: 227 loss: 6.64625913e-05
Iter: 228 loss: 6.5878914e-05
Iter: 229 loss: 6.56286138e-05
Iter: 230 loss: 6.58790887e-05
Iter: 231 loss: 6.54876567e-05
Iter: 232 loss: 6.51877563e-05
Iter: 233 loss: 6.68473585e-05
Iter: 234 loss: 6.51445298e-05
Iter: 235 loss: 6.48866626e-05
Iter: 236 loss: 6.52635063e-05
Iter: 237 loss: 6.47616762e-05
Iter: 238 loss: 6.45261462e-05
Iter: 239 loss: 6.58388744e-05
Iter: 240 loss: 6.44932443e-05
Iter: 241 loss: 6.43059611e-05
Iter: 242 loss: 6.71979651e-05
Iter: 243 loss: 6.43058593e-05
Iter: 244 loss: 6.41932857e-05
Iter: 245 loss: 6.39555365e-05
Iter: 246 loss: 6.78651049e-05
Iter: 247 loss: 6.39489e-05
Iter: 248 loss: 6.37028279e-05
Iter: 249 loss: 6.46682e-05
Iter: 250 loss: 6.36460463e-05
Iter: 251 loss: 6.34421303e-05
Iter: 252 loss: 6.36788609e-05
Iter: 253 loss: 6.33332311e-05
Iter: 254 loss: 6.31004586e-05
Iter: 255 loss: 6.41341176e-05
Iter: 256 loss: 6.30542854e-05
Iter: 257 loss: 6.2866493e-05
Iter: 258 loss: 6.39139616e-05
Iter: 259 loss: 6.28398411e-05
Iter: 260 loss: 6.26821129e-05
Iter: 261 loss: 6.31274088e-05
Iter: 262 loss: 6.26319525e-05
Iter: 263 loss: 6.24768363e-05
Iter: 264 loss: 6.29034621e-05
Iter: 265 loss: 6.24262393e-05
Iter: 266 loss: 6.22701191e-05
Iter: 267 loss: 6.28602e-05
Iter: 268 loss: 6.22327207e-05
Iter: 269 loss: 6.2100582e-05
Iter: 270 loss: 6.21929648e-05
Iter: 271 loss: 6.2018109e-05
Iter: 272 loss: 6.18666672e-05
Iter: 273 loss: 6.22106e-05
Iter: 274 loss: 6.18093763e-05
Iter: 275 loss: 6.17178739e-05
Iter: 276 loss: 6.17119586e-05
Iter: 277 loss: 6.16237958e-05
Iter: 278 loss: 6.17442056e-05
Iter: 279 loss: 6.15797617e-05
Iter: 280 loss: 6.14954697e-05
Iter: 281 loss: 6.14842065e-05
Iter: 282 loss: 6.14246528e-05
Iter: 283 loss: 6.1313709e-05
Iter: 284 loss: 6.13357333e-05
Iter: 285 loss: 6.12312651e-05
Iter: 286 loss: 6.10993811e-05
Iter: 287 loss: 6.17359765e-05
Iter: 288 loss: 6.10761417e-05
Iter: 289 loss: 6.09595518e-05
Iter: 290 loss: 6.14189e-05
Iter: 291 loss: 6.09329363e-05
Iter: 292 loss: 6.083271e-05
Iter: 293 loss: 6.09334384e-05
Iter: 294 loss: 6.07764086e-05
Iter: 295 loss: 6.06631838e-05
Iter: 296 loss: 6.1257022e-05
Iter: 297 loss: 6.06452959e-05
Iter: 298 loss: 6.0556551e-05
Iter: 299 loss: 6.09632807e-05
Iter: 300 loss: 6.05396235e-05
Iter: 301 loss: 6.04547931e-05
Iter: 302 loss: 6.07190814e-05
Iter: 303 loss: 6.04300512e-05
Iter: 304 loss: 6.03508815e-05
Iter: 305 loss: 6.0473616e-05
Iter: 306 loss: 6.0313665e-05
Iter: 307 loss: 6.02378022e-05
Iter: 308 loss: 6.04159613e-05
Iter: 309 loss: 6.0209888e-05
Iter: 310 loss: 6.0168637e-05
Iter: 311 loss: 6.01620704e-05
Iter: 312 loss: 6.01238935e-05
Iter: 313 loss: 6.00670573e-05
Iter: 314 loss: 6.00657841e-05
Iter: 315 loss: 6.00012427e-05
Iter: 316 loss: 6.00483836e-05
Iter: 317 loss: 5.99614068e-05
Iter: 318 loss: 5.98874212e-05
Iter: 319 loss: 6.02143955e-05
Iter: 320 loss: 5.98726692e-05
Iter: 321 loss: 5.98106271e-05
Iter: 322 loss: 5.99500199e-05
Iter: 323 loss: 5.97871185e-05
Iter: 324 loss: 5.97199323e-05
Iter: 325 loss: 5.98150873e-05
Iter: 326 loss: 5.96868631e-05
Iter: 327 loss: 5.96230457e-05
Iter: 328 loss: 5.98059341e-05
Iter: 329 loss: 5.96030841e-05
Iter: 330 loss: 5.95437596e-05
Iter: 331 loss: 5.99215855e-05
Iter: 332 loss: 5.95372148e-05
Iter: 333 loss: 5.94881858e-05
Iter: 334 loss: 5.96789359e-05
Iter: 335 loss: 5.94768e-05
Iter: 336 loss: 5.94334851e-05
Iter: 337 loss: 5.95790698e-05
Iter: 338 loss: 5.94217199e-05
Iter: 339 loss: 5.93820951e-05
Iter: 340 loss: 5.9472939e-05
Iter: 341 loss: 5.9367303e-05
Iter: 342 loss: 5.93281729e-05
Iter: 343 loss: 5.94887497e-05
Iter: 344 loss: 5.93197e-05
Iter: 345 loss: 5.92890356e-05
Iter: 346 loss: 5.97347898e-05
Iter: 347 loss: 5.92889046e-05
Iter: 348 loss: 5.92700162e-05
Iter: 349 loss: 5.92310025e-05
Iter: 350 loss: 5.99240084e-05
Iter: 351 loss: 5.92303113e-05
Iter: 352 loss: 5.91897879e-05
Iter: 353 loss: 5.93069781e-05
Iter: 354 loss: 5.91771131e-05
Iter: 355 loss: 5.91381613e-05
Iter: 356 loss: 5.92840806e-05
Iter: 357 loss: 5.91287426e-05
Iter: 358 loss: 5.90917371e-05
Iter: 359 loss: 5.91322496e-05
Iter: 360 loss: 5.90715936e-05
Iter: 361 loss: 5.90327581e-05
Iter: 362 loss: 5.91555508e-05
Iter: 363 loss: 5.9021575e-05
Iter: 364 loss: 5.89863484e-05
Iter: 365 loss: 5.91342796e-05
Iter: 366 loss: 5.89788e-05
Iter: 367 loss: 5.89469964e-05
Iter: 368 loss: 5.90578093e-05
Iter: 369 loss: 5.89385963e-05
Iter: 370 loss: 5.89121046e-05
Iter: 371 loss: 5.90224081e-05
Iter: 372 loss: 5.89064366e-05
Iter: 373 loss: 5.88804687e-05
Iter: 374 loss: 5.89667179e-05
Iter: 375 loss: 5.88733092e-05
Iter: 376 loss: 5.88508374e-05
Iter: 377 loss: 5.8938469e-05
Iter: 378 loss: 5.88456642e-05
Iter: 379 loss: 5.88280818e-05
Iter: 380 loss: 5.89753363e-05
Iter: 381 loss: 5.88270195e-05
Iter: 382 loss: 5.88097537e-05
Iter: 383 loss: 5.88326184e-05
Iter: 384 loss: 5.88010407e-05
Iter: 385 loss: 5.87858849e-05
Iter: 386 loss: 5.87769246e-05
Iter: 387 loss: 5.87706527e-05
Iter: 388 loss: 5.87483373e-05
Iter: 389 loss: 5.87845e-05
Iter: 390 loss: 5.87380782e-05
Iter: 391 loss: 5.87152354e-05
Iter: 392 loss: 5.87757895e-05
Iter: 393 loss: 5.87075847e-05
Iter: 394 loss: 5.86841052e-05
Iter: 395 loss: 5.87681352e-05
Iter: 396 loss: 5.86781498e-05
Iter: 397 loss: 5.86572278e-05
Iter: 398 loss: 5.87509e-05
Iter: 399 loss: 5.86531278e-05
Iter: 400 loss: 5.86347924e-05
Iter: 401 loss: 5.86655333e-05
Iter: 402 loss: 5.86265596e-05
Iter: 403 loss: 5.86086971e-05
Iter: 404 loss: 5.86668939e-05
Iter: 405 loss: 5.8603604e-05
Iter: 406 loss: 5.8586942e-05
Iter: 407 loss: 5.86585411e-05
Iter: 408 loss: 5.85834932e-05
Iter: 409 loss: 5.85699454e-05
Iter: 410 loss: 5.86608876e-05
Iter: 411 loss: 5.85686867e-05
Iter: 412 loss: 5.85574962e-05
Iter: 413 loss: 5.85818052e-05
Iter: 414 loss: 5.85531816e-05
Iter: 415 loss: 5.85409362e-05
Iter: 416 loss: 5.86433198e-05
Iter: 417 loss: 5.85401722e-05
Iter: 418 loss: 5.85318412e-05
Iter: 419 loss: 5.85289235e-05
Iter: 420 loss: 5.85243e-05
Iter: 421 loss: 5.85130765e-05
Iter: 422 loss: 5.85142916e-05
Iter: 423 loss: 5.85043199e-05
Iter: 424 loss: 5.84900263e-05
Iter: 425 loss: 5.85152593e-05
Iter: 426 loss: 5.8483678e-05
Iter: 427 loss: 5.84698319e-05
Iter: 428 loss: 5.8519603e-05
Iter: 429 loss: 5.84662266e-05
Iter: 430 loss: 5.84536101e-05
Iter: 431 loss: 5.85180132e-05
Iter: 432 loss: 5.84516165e-05
Iter: 433 loss: 5.84400223e-05
Iter: 434 loss: 5.84591835e-05
Iter: 435 loss: 5.84348236e-05
Iter: 436 loss: 5.84228255e-05
Iter: 437 loss: 5.84707159e-05
Iter: 438 loss: 5.84202062e-05
Iter: 439 loss: 5.8409998e-05
Iter: 440 loss: 5.84357113e-05
Iter: 441 loss: 5.84063891e-05
Iter: 442 loss: 5.8396512e-05
Iter: 443 loss: 5.84305162e-05
Iter: 444 loss: 5.83939473e-05
Iter: 445 loss: 5.83842702e-05
Iter: 446 loss: 5.84505906e-05
Iter: 447 loss: 5.83833571e-05
Iter: 448 loss: 5.83767178e-05
Iter: 449 loss: 5.84300069e-05
Iter: 450 loss: 5.83763613e-05
Iter: 451 loss: 5.83703695e-05
Iter: 452 loss: 5.83733854e-05
Iter: 453 loss: 5.83664587e-05
Iter: 454 loss: 5.83598085e-05
Iter: 455 loss: 5.83570654e-05
Iter: 456 loss: 5.83534784e-05
Iter: 457 loss: 5.83447254e-05
Iter: 458 loss: 5.83598921e-05
Iter: 459 loss: 5.83409201e-05
Iter: 460 loss: 5.83319925e-05
Iter: 461 loss: 5.83821311e-05
Iter: 462 loss: 5.83307701e-05
Iter: 463 loss: 5.83232613e-05
Iter: 464 loss: 5.8334339e-05
Iter: 465 loss: 5.83195433e-05
Iter: 466 loss: 5.83118162e-05
Iter: 467 loss: 5.83330766e-05
Iter: 468 loss: 5.8309306e-05
Iter: 469 loss: 5.83017427e-05
Iter: 470 loss: 5.83263245e-05
Iter: 471 loss: 5.82996145e-05
Iter: 472 loss: 5.8292324e-05
Iter: 473 loss: 5.8323647e-05
Iter: 474 loss: 5.82908142e-05
Iter: 475 loss: 5.82846151e-05
Iter: 476 loss: 5.82941939e-05
Iter: 477 loss: 5.82816501e-05
Iter: 478 loss: 5.82751709e-05
Iter: 479 loss: 5.83130241e-05
Iter: 480 loss: 5.82742941e-05
Iter: 481 loss: 5.82699395e-05
Iter: 482 loss: 5.83262881e-05
Iter: 483 loss: 5.82699104e-05
Iter: 484 loss: 5.82662251e-05
Iter: 485 loss: 5.82711655e-05
Iter: 486 loss: 5.82643879e-05
Iter: 487 loss: 5.82600442e-05
Iter: 488 loss: 5.82633256e-05
Iter: 489 loss: 5.82575267e-05
Iter: 490 loss: 5.82531866e-05
Iter: 491 loss: 5.82502944e-05
Iter: 492 loss: 5.82486718e-05
Iter: 493 loss: 5.82428147e-05
Iter: 494 loss: 5.82656758e-05
Iter: 495 loss: 5.82411813e-05
Iter: 496 loss: 5.82356588e-05
Iter: 497 loss: 5.82662324e-05
Iter: 498 loss: 5.82348694e-05
Iter: 499 loss: 5.82301946e-05
Iter: 500 loss: 5.82354078e-05
Iter: 501 loss: 5.82276116e-05
Iter: 502 loss: 5.82222674e-05
Iter: 503 loss: 5.82390931e-05
Iter: 504 loss: 5.8220794e-05
Iter: 505 loss: 5.82159628e-05
Iter: 506 loss: 5.82350294e-05
Iter: 507 loss: 5.82150096e-05
Iter: 508 loss: 5.82106295e-05
Iter: 509 loss: 5.82176108e-05
Iter: 510 loss: 5.82084467e-05
Iter: 511 loss: 5.82040375e-05
Iter: 512 loss: 5.82259236e-05
Iter: 513 loss: 5.82033354e-05
Iter: 514 loss: 5.81999666e-05
Iter: 515 loss: 5.82310749e-05
Iter: 516 loss: 5.81996937e-05
Iter: 517 loss: 5.81969e-05
Iter: 518 loss: 5.8212092e-05
Iter: 519 loss: 5.81965323e-05
Iter: 520 loss: 5.81942222e-05
Iter: 521 loss: 5.81942e-05
Iter: 522 loss: 5.81923196e-05
Iter: 523 loss: 5.81891072e-05
Iter: 524 loss: 5.81923705e-05
Iter: 525 loss: 5.81873137e-05
Iter: 526 loss: 5.81840141e-05
Iter: 527 loss: 5.81889617e-05
Iter: 528 loss: 5.81824715e-05
Iter: 529 loss: 5.81786735e-05
Iter: 530 loss: 5.81857166e-05
Iter: 531 loss: 5.81770546e-05
Iter: 532 loss: 5.81731365e-05
Iter: 533 loss: 5.81813329e-05
Iter: 534 loss: 5.8171765e-05
Iter: 535 loss: 5.81680433e-05
Iter: 536 loss: 5.8188878e-05
Iter: 537 loss: 5.81675486e-05
Iter: 538 loss: 5.81644927e-05
Iter: 539 loss: 5.81751046e-05
Iter: 540 loss: 5.81636268e-05
Iter: 541 loss: 5.8160811e-05
Iter: 542 loss: 5.81647255e-05
Iter: 543 loss: 5.81593849e-05
Iter: 544 loss: 5.81563e-05
Iter: 545 loss: 5.81643944e-05
Iter: 546 loss: 5.81552595e-05
Iter: 547 loss: 5.8152611e-05
Iter: 548 loss: 5.81719905e-05
Iter: 549 loss: 5.81523564e-05
Iter: 550 loss: 5.81504864e-05
Iter: 551 loss: 5.81760905e-05
Iter: 552 loss: 5.81505e-05
Iter: 553 loss: 5.81489803e-05
Iter: 554 loss: 5.81494278e-05
Iter: 555 loss: 5.81479071e-05
Iter: 556 loss: 5.814619e-05
Iter: 557 loss: 5.81478744e-05
Iter: 558 loss: 5.81451459e-05
Iter: 559 loss: 5.81430722e-05
Iter: 560 loss: 5.81448e-05
Iter: 561 loss: 5.81418826e-05
Iter: 562 loss: 5.81395434e-05
Iter: 563 loss: 5.81481763e-05
Iter: 564 loss: 5.81389577e-05
Iter: 565 loss: 5.81369313e-05
Iter: 566 loss: 5.81393506e-05
Iter: 567 loss: 5.813588e-05
Iter: 568 loss: 5.81335044e-05
Iter: 569 loss: 5.81400309e-05
Iter: 570 loss: 5.81327586e-05
Iter: 571 loss: 5.81306376e-05
Iter: 572 loss: 5.81395216e-05
Iter: 573 loss: 5.81302229e-05
Iter: 574 loss: 5.81282438e-05
Iter: 575 loss: 5.8133839e-05
Iter: 576 loss: 5.81275381e-05
Iter: 577 loss: 5.81256463e-05
Iter: 578 loss: 5.81298955e-05
Iter: 579 loss: 5.81248605e-05
Iter: 580 loss: 5.81229506e-05
Iter: 581 loss: 5.81317727e-05
Iter: 582 loss: 5.81225613e-05
Iter: 583 loss: 5.81212298e-05
Iter: 584 loss: 5.81334898e-05
Iter: 585 loss: 5.81212116e-05
Iter: 586 loss: 5.81198947e-05
Iter: 587 loss: 5.81244094e-05
Iter: 588 loss: 5.81195636e-05
Iter: 589 loss: 5.81184941e-05
Iter: 590 loss: 5.81184067e-05
Iter: 591 loss: 5.81177592e-05
Iter: 592 loss: 5.81164604e-05
Iter: 593 loss: 5.81204586e-05
Iter: 594 loss: 5.81159948e-05
Iter: 595 loss: 5.8114827e-05
Iter: 596 loss: 5.81150161e-05
Iter: 597 loss: 5.81138156e-05
Iter: 598 loss: 5.8112284e-05
Iter: 599 loss: 5.81153836e-05
Iter: 600 loss: 5.8111611e-05
Iter: 601 loss: 5.81101485e-05
Iter: 602 loss: 5.81171043e-05
Iter: 603 loss: 5.81097702e-05
Iter: 604 loss: 5.81084423e-05
Iter: 605 loss: 5.81122549e-05
Iter: 606 loss: 5.81079585e-05
Iter: 607 loss: 5.81064742e-05
Iter: 608 loss: 5.81099775e-05
Iter: 609 loss: 5.81059721e-05
Iter: 610 loss: 5.81046261e-05
Iter: 611 loss: 5.81073255e-05
Iter: 612 loss: 5.8104124e-05
Iter: 613 loss: 5.81027853e-05
Iter: 614 loss: 5.81101922e-05
Iter: 615 loss: 5.81026688e-05
Iter: 616 loss: 5.81015483e-05
Iter: 617 loss: 5.8105863e-05
Iter: 618 loss: 5.81012609e-05
Iter: 619 loss: 5.81005661e-05
Iter: 620 loss: 5.81004861e-05
Iter: 621 loss: 5.8099984e-05
Iter: 622 loss: 5.80993437e-05
Iter: 623 loss: 5.80992091e-05
Iter: 624 loss: 5.80983797e-05
Iter: 625 loss: 5.80997512e-05
Iter: 626 loss: 5.8097954e-05
Iter: 627 loss: 5.80969208e-05
Iter: 628 loss: 5.81008571e-05
Iter: 629 loss: 5.80968044e-05
Iter: 630 loss: 5.80958149e-05
Iter: 631 loss: 5.80959459e-05
Iter: 632 loss: 5.80952619e-05
Iter: 633 loss: 5.8094236e-05
Iter: 634 loss: 5.80972046e-05
Iter: 635 loss: 5.80938358e-05
Iter: 636 loss: 5.80930318e-05
Iter: 637 loss: 5.80963824e-05
Iter: 638 loss: 5.80926826e-05
Iter: 639 loss: 5.8091704e-05
Iter: 640 loss: 5.80950764e-05
Iter: 641 loss: 5.80915439e-05
Iter: 642 loss: 5.80906635e-05
Iter: 643 loss: 5.8092337e-05
Iter: 644 loss: 5.80903834e-05
Iter: 645 loss: 5.8089503e-05
Iter: 646 loss: 5.80929554e-05
Iter: 647 loss: 5.80892702e-05
Iter: 648 loss: 5.80884225e-05
Iter: 649 loss: 5.80898923e-05
Iter: 650 loss: 5.8088106e-05
Iter: 651 loss: 5.80876149e-05
Iter: 652 loss: 5.80875967e-05
Iter: 653 loss: 5.8087091e-05
Iter: 654 loss: 5.80872329e-05
Iter: 655 loss: 5.80866727e-05
Iter: 656 loss: 5.8086116e-05
Iter: 657 loss: 5.80865089e-05
Iter: 658 loss: 5.80858577e-05
Iter: 659 loss: 5.8085232e-05
Iter: 660 loss: 5.80877568e-05
Iter: 661 loss: 5.80850829e-05
Iter: 662 loss: 5.80844498e-05
Iter: 663 loss: 5.8084981e-05
Iter: 664 loss: 5.80841515e-05
Iter: 665 loss: 5.80834203e-05
Iter: 666 loss: 5.80857486e-05
Iter: 667 loss: 5.80833366e-05
Iter: 668 loss: 5.80827327e-05
Iter: 669 loss: 5.80838314e-05
Iter: 670 loss: 5.80824417e-05
Iter: 671 loss: 5.80818487e-05
Iter: 672 loss: 5.80826309e-05
Iter: 673 loss: 5.80814703e-05
Iter: 674 loss: 5.80807464e-05
Iter: 675 loss: 5.80835404e-05
Iter: 676 loss: 5.80806955e-05
Iter: 677 loss: 5.80801861e-05
Iter: 678 loss: 5.80828346e-05
Iter: 679 loss: 5.80800333e-05
Iter: 680 loss: 5.80795604e-05
Iter: 681 loss: 5.80807973e-05
Iter: 682 loss: 5.80793567e-05
Iter: 683 loss: 5.80788e-05
Iter: 684 loss: 5.8081343e-05
Iter: 685 loss: 5.80787855e-05
Iter: 686 loss: 5.80784472e-05
Iter: 687 loss: 5.80832275e-05
Iter: 688 loss: 5.80783853e-05
Iter: 689 loss: 5.8078138e-05
Iter: 690 loss: 5.80778251e-05
Iter: 691 loss: 5.80777487e-05
Iter: 692 loss: 5.80773703e-05
Iter: 693 loss: 5.80787091e-05
Iter: 694 loss: 5.8077203e-05
Iter: 695 loss: 5.80767555e-05
Iter: 696 loss: 5.80786145e-05
Iter: 697 loss: 5.80766209e-05
Iter: 698 loss: 5.80762644e-05
Iter: 699 loss: 5.80761916e-05
Iter: 700 loss: 5.80760243e-05
Iter: 701 loss: 5.8075555e-05
Iter: 702 loss: 5.80775595e-05
Iter: 703 loss: 5.80754349e-05
Iter: 704 loss: 5.80750566e-05
Iter: 705 loss: 5.80760207e-05
Iter: 706 loss: 5.80748092e-05
Iter: 707 loss: 5.80744927e-05
Iter: 708 loss: 5.8075515e-05
Iter: 709 loss: 5.80744309e-05
Iter: 710 loss: 5.80739979e-05
Iter: 711 loss: 5.8075264e-05
Iter: 712 loss: 5.80737687e-05
Iter: 713 loss: 5.80734049e-05
Iter: 714 loss: 5.80744054e-05
Iter: 715 loss: 5.80732449e-05
Iter: 716 loss: 5.80729684e-05
Iter: 717 loss: 5.80743e-05
Iter: 718 loss: 5.8072852e-05
Iter: 719 loss: 5.80726628e-05
Iter: 720 loss: 5.80726592e-05
Iter: 721 loss: 5.807251e-05
Iter: 722 loss: 5.80725136e-05
Iter: 723 loss: 5.80723645e-05
Iter: 724 loss: 5.80721062e-05
Iter: 725 loss: 5.80720953e-05
Iter: 726 loss: 5.80718261e-05
Iter: 727 loss: 5.80716041e-05
Iter: 728 loss: 5.80731175e-05
Iter: 729 loss: 5.80715423e-05
Iter: 730 loss: 5.80712731e-05
Iter: 731 loss: 5.80719097e-05
Iter: 732 loss: 5.80712222e-05
Iter: 733 loss: 5.80709238e-05
Iter: 734 loss: 5.8071244e-05
Iter: 735 loss: 5.80708511e-05
Iter: 736 loss: 5.80704655e-05
Iter: 737 loss: 5.80710548e-05
Iter: 738 loss: 5.80704364e-05
Iter: 739 loss: 5.80699925e-05
Iter: 740 loss: 5.8070862e-05
Iter: 741 loss: 5.80699743e-05
Iter: 742 loss: 5.80696797e-05
Iter: 743 loss: 5.80713531e-05
Iter: 744 loss: 5.80696433e-05
Iter: 745 loss: 5.80694796e-05
Iter: 746 loss: 5.8069767e-05
Iter: 747 loss: 5.80692868e-05
Iter: 748 loss: 5.80691194e-05
Iter: 749 loss: 5.80696324e-05
Iter: 750 loss: 5.80690394e-05
Iter: 751 loss: 5.80687592e-05
Iter: 752 loss: 5.80717788e-05
Iter: 753 loss: 5.80687265e-05
Iter: 754 loss: 5.80685592e-05
Iter: 755 loss: 5.80693631e-05
Iter: 756 loss: 5.8068581e-05
Iter: 757 loss: 5.806837e-05
Iter: 758 loss: 5.80683336e-05
Iter: 759 loss: 5.80682827e-05
Iter: 760 loss: 5.8068108e-05
Iter: 761 loss: 5.80685664e-05
Iter: 762 loss: 5.80679953e-05
Iter: 763 loss: 5.80677661e-05
Iter: 764 loss: 5.80686064e-05
Iter: 765 loss: 5.80677442e-05
Iter: 766 loss: 5.80675551e-05
Iter: 767 loss: 5.80680789e-05
Iter: 768 loss: 5.80675078e-05
Iter: 769 loss: 5.80673623e-05
Iter: 770 loss: 5.80674096e-05
Iter: 771 loss: 5.80671804e-05
Iter: 772 loss: 5.80669803e-05
Iter: 773 loss: 5.80675369e-05
Iter: 774 loss: 5.80668275e-05
Iter: 775 loss: 5.80667074e-05
Iter: 776 loss: 5.80674168e-05
Iter: 777 loss: 5.80667111e-05
Iter: 778 loss: 5.80665037e-05
Iter: 779 loss: 5.80670057e-05
Iter: 780 loss: 5.80663836e-05
Iter: 781 loss: 5.80662272e-05
Iter: 782 loss: 5.80667547e-05
Iter: 783 loss: 5.80661581e-05
Iter: 784 loss: 5.8066089e-05
Iter: 785 loss: 5.80669221e-05
Iter: 786 loss: 5.80660417e-05
Iter: 787 loss: 5.80659e-05
Iter: 788 loss: 5.80659e-05
Iter: 789 loss: 5.80658379e-05
Iter: 790 loss: 5.80656852e-05
Iter: 791 loss: 5.80656852e-05
Iter: 792 loss: 5.80655942e-05
Iter: 793 loss: 5.80654923e-05
Iter: 794 loss: 5.80654596e-05
Iter: 795 loss: 5.80653541e-05
Iter: 796 loss: 5.80664055e-05
Iter: 797 loss: 5.80654269e-05
Iter: 798 loss: 5.80651977e-05
Iter: 799 loss: 5.80655396e-05
Iter: 800 loss: 5.80650958e-05
Iter: 801 loss: 5.80649648e-05
Iter: 802 loss: 5.80652377e-05
Iter: 803 loss: 5.80649248e-05
Iter: 804 loss: 5.80648812e-05
Iter: 805 loss: 5.80651322e-05
Iter: 806 loss: 5.80647647e-05
Iter: 807 loss: 5.80646883e-05
Iter: 808 loss: 5.80650121e-05
Iter: 809 loss: 5.80645719e-05
Iter: 810 loss: 5.80644955e-05
Iter: 811 loss: 5.80646447e-05
Iter: 812 loss: 5.80643682e-05
Iter: 813 loss: 5.806423e-05
Iter: 814 loss: 5.80646483e-05
Iter: 815 loss: 5.80642954e-05
Iter: 816 loss: 5.80641063e-05
Iter: 817 loss: 5.80644846e-05
Iter: 818 loss: 5.80641172e-05
Iter: 819 loss: 5.80639207e-05
Iter: 820 loss: 5.80639753e-05
Iter: 821 loss: 5.80639353e-05
Iter: 822 loss: 5.80641863e-05
Iter: 823 loss: 5.8063888e-05
Iter: 824 loss: 5.80638443e-05
Iter: 825 loss: 5.80637643e-05
Iter: 826 loss: 5.80637279e-05
Iter: 827 loss: 5.80635897e-05
Iter: 828 loss: 5.80639644e-05
Iter: 829 loss: 5.80635569e-05
Iter: 830 loss: 5.80635788e-05
Iter: 831 loss: 5.80641063e-05
Iter: 832 loss: 5.80635024e-05
Iter: 833 loss: 5.80634187e-05
Iter: 834 loss: 5.80636333e-05
Iter: 835 loss: 5.80634842e-05
Iter: 836 loss: 5.80633823e-05
Iter: 837 loss: 5.80634223e-05
Iter: 838 loss: 5.80632477e-05
Iter: 839 loss: 5.80632e-05
Iter: 840 loss: 5.80633896e-05
Iter: 841 loss: 5.80631895e-05
Iter: 842 loss: 5.80631204e-05
Iter: 843 loss: 5.80634187e-05
Iter: 844 loss: 5.80630513e-05
Iter: 845 loss: 5.80629421e-05
Iter: 846 loss: 5.80631895e-05
Iter: 847 loss: 5.80628766e-05
Iter: 848 loss: 5.80627457e-05
Iter: 849 loss: 5.80630476e-05
Iter: 850 loss: 5.80628366e-05
Iter: 851 loss: 5.8062742e-05
Iter: 852 loss: 5.80630694e-05
Iter: 853 loss: 5.80627529e-05
Iter: 854 loss: 5.80626765e-05
Iter: 855 loss: 5.80627238e-05
Iter: 856 loss: 5.80625783e-05
Iter: 857 loss: 5.8062571e-05
Iter: 858 loss: 5.80626256e-05
Iter: 859 loss: 5.80625965e-05
Iter: 860 loss: 5.80625492e-05
Iter: 861 loss: 5.80625128e-05
Iter: 862 loss: 5.80625e-05
Iter: 863 loss: 5.80627639e-05
Iter: 864 loss: 5.80624037e-05
Iter: 865 loss: 5.80623237e-05
Iter: 866 loss: 5.80624619e-05
Iter: 867 loss: 5.80622946e-05
Iter: 868 loss: 5.80622582e-05
Iter: 869 loss: 5.80626111e-05
Iter: 870 loss: 5.80623237e-05
Iter: 871 loss: 5.8062149e-05
Iter: 872 loss: 5.80622291e-05
Iter: 873 loss: 5.80621308e-05
Iter: 874 loss: 5.80621199e-05
Iter: 875 loss: 5.80623309e-05
Iter: 876 loss: 5.80620908e-05
Iter: 877 loss: 5.80620363e-05
Iter: 878 loss: 5.80622909e-05
Iter: 879 loss: 5.80619562e-05
Iter: 880 loss: 5.80619708e-05
Iter: 881 loss: 5.80620544e-05
Iter: 882 loss: 5.80618616e-05
Iter: 883 loss: 5.80619671e-05
Iter: 884 loss: 5.80618616e-05
Iter: 885 loss: 5.80618689e-05
Iter: 886 loss: 5.80618289e-05
Iter: 887 loss: 5.80618653e-05
Iter: 888 loss: 5.80619e-05
Iter: 889 loss: 5.8061938e-05
Iter: 890 loss: 5.80619671e-05
Iter: 891 loss: 5.80619562e-05
Iter: 892 loss: 5.80619344e-05
Iter: 893 loss: 5.80618944e-05
Iter: 894 loss: 5.80619671e-05
Iter: 895 loss: 5.80619489e-05
Iter: 896 loss: 5.8061898e-05
Iter: 897 loss: 5.80619053e-05
Iter: 898 loss: 5.80619271e-05
Iter: 899 loss: 5.80619235e-05
Iter: 900 loss: 5.8061898e-05
Iter: 901 loss: 5.80619126e-05
Iter: 902 loss: 5.80619198e-05
Iter: 903 loss: 5.80619235e-05
Iter: 904 loss: 5.80619235e-05
Iter: 905 loss: 5.80619235e-05
Iter: 906 loss: 5.80619198e-05
Iter: 907 loss: 5.80619198e-05
Iter: 908 loss: 5.80619235e-05
Iter: 909 loss: 5.80618071e-05
Iter: 910 loss: 5.80624692e-05
Iter: 911 loss: 5.80618362e-05
Iter: 912 loss: 5.80616725e-05
Iter: 913 loss: 5.80617852e-05
Iter: 914 loss: 5.80617379e-05
Iter: 915 loss: 5.80618034e-05
Iter: 916 loss: 5.80616615e-05
Iter: 917 loss: 5.80616834e-05
Iter: 918 loss: 5.80616907e-05
Iter: 919 loss: 5.80616361e-05
Iter: 920 loss: 5.80616397e-05
Iter: 921 loss: 5.80616288e-05
Iter: 922 loss: 5.80615924e-05
Iter: 923 loss: 5.80614433e-05
Iter: 924 loss: 5.80618434e-05
Iter: 925 loss: 5.80615051e-05
Iter: 926 loss: 5.80614505e-05
Iter: 927 loss: 5.80616725e-05
Iter: 928 loss: 5.8061436e-05
Iter: 929 loss: 5.80613778e-05
Iter: 930 loss: 5.80615e-05
Iter: 931 loss: 5.80613669e-05
Iter: 932 loss: 5.80613741e-05
Iter: 933 loss: 5.80614651e-05
Iter: 934 loss: 5.80614396e-05
Iter: 935 loss: 5.8061476e-05
Iter: 936 loss: 5.80614105e-05
Iter: 937 loss: 5.80612505e-05
Iter: 938 loss: 5.80614578e-05
Iter: 939 loss: 5.80612832e-05
Iter: 940 loss: 5.80612468e-05
Iter: 941 loss: 5.80612905e-05
Iter: 942 loss: 5.80613269e-05
Iter: 943 loss: 5.80612104e-05
Iter: 944 loss: 5.80614651e-05
Iter: 945 loss: 5.80611777e-05
Iter: 946 loss: 5.80611668e-05
Iter: 947 loss: 5.80612432e-05
Iter: 948 loss: 5.80611522e-05
Iter: 949 loss: 5.80611741e-05
Iter: 950 loss: 5.80611741e-05
Iter: 951 loss: 5.80610504e-05
Iter: 952 loss: 5.80610758e-05
Iter: 953 loss: 5.80615524e-05
Iter: 954 loss: 5.80611595e-05
Iter: 955 loss: 5.80610686e-05
Iter: 956 loss: 5.80611959e-05
Iter: 957 loss: 5.80610213e-05
Iter: 958 loss: 5.80611377e-05
Iter: 959 loss: 5.80610067e-05
Iter: 960 loss: 5.80611086e-05
Iter: 961 loss: 5.80610431e-05
Iter: 962 loss: 5.8061054e-05
Iter: 963 loss: 5.80610613e-05
Iter: 964 loss: 5.80609521e-05
Iter: 965 loss: 5.8061054e-05
Iter: 966 loss: 5.8061054e-05
Iter: 967 loss: 5.80610431e-05
Iter: 968 loss: 5.80610649e-05
Iter: 969 loss: 5.80610686e-05
Iter: 970 loss: 5.80610977e-05
Iter: 971 loss: 5.80610867e-05
Iter: 972 loss: 5.80610831e-05
Iter: 973 loss: 5.8061054e-05
Iter: 974 loss: 5.80610576e-05
Iter: 975 loss: 5.80610649e-05
Iter: 976 loss: 5.80610758e-05
Iter: 977 loss: 5.80610831e-05
Iter: 978 loss: 5.80610722e-05
Iter: 979 loss: 5.80610795e-05
Iter: 980 loss: 5.80610795e-05
Iter: 981 loss: 5.80610831e-05
Iter: 982 loss: 5.80610795e-05
Iter: 983 loss: 5.80610831e-05
Iter: 984 loss: 5.8060923e-05
Iter: 985 loss: 5.80614651e-05
Iter: 986 loss: 5.80609776e-05
Iter: 987 loss: 5.80609812e-05
Iter: 988 loss: 5.8060923e-05
Iter: 989 loss: 5.80607957e-05
Iter: 990 loss: 5.80609776e-05
Iter: 991 loss: 5.80608903e-05
Iter: 992 loss: 5.80608539e-05
Iter: 993 loss: 5.80609085e-05
Iter: 994 loss: 5.80608612e-05
Iter: 995 loss: 5.80608867e-05
Iter: 996 loss: 5.80608e-05
Iter: 997 loss: 5.80608612e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6
+ date
Tue Oct 27 18:11:05 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42824138c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42c41ab620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f428240d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42824556a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42823a39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42823bbea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c307f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c2c39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c2ca488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c267840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c2c30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c267950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c267a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c1a3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c1da598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c1da400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c1856a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c185598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c0ed8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c11c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c0a3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c0b8840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c087840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c088a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f425c088d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4240098840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42400ca730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4240071840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42400717b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4240021400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4240021158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4240042ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f42400217b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41c0782d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41c078f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f41c07422f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0297906511
Iter: 2 loss: 0.0216587447
Iter: 3 loss: 1411.88257
Iter: 4 loss: 0.0216587391
Iter: 5 loss: 0.0180376135
Iter: 6 loss: 0.0361161232
Iter: 7 loss: 0.016819492
Iter: 8 loss: 0.0126776109
Iter: 9 loss: 0.0126510225
Iter: 10 loss: 0.010649126
Iter: 11 loss: 0.0267508496
Iter: 12 loss: 0.0104765818
Iter: 13 loss: 0.00943208486
Iter: 14 loss: 0.010722002
Iter: 15 loss: 0.00882271305
Iter: 16 loss: 0.00743097859
Iter: 17 loss: 0.0152367838
Iter: 18 loss: 0.00707678683
Iter: 19 loss: 0.00569451321
Iter: 20 loss: 0.00565698463
Iter: 21 loss: 0.00468202308
Iter: 22 loss: 0.0126072802
Iter: 23 loss: 0.00459343055
Iter: 24 loss: 0.00400514062
Iter: 25 loss: 0.00950201228
Iter: 26 loss: 0.00394132268
Iter: 27 loss: 0.00349758426
Iter: 28 loss: 0.00788502209
Iter: 29 loss: 0.00349037489
Iter: 30 loss: 0.00319747673
Iter: 31 loss: 0.00655463478
Iter: 32 loss: 0.0031679892
Iter: 33 loss: 0.00290868361
Iter: 34 loss: 0.00402694661
Iter: 35 loss: 0.00284231897
Iter: 36 loss: 0.00248826854
Iter: 37 loss: 0.00700323936
Iter: 38 loss: 0.00248432625
Iter: 39 loss: 0.00218029786
Iter: 40 loss: 0.00387073681
Iter: 41 loss: 0.00213307771
Iter: 42 loss: 0.0019307679
Iter: 43 loss: 0.00315026101
Iter: 44 loss: 0.00189662725
Iter: 45 loss: 0.00171854626
Iter: 46 loss: 0.00281096576
Iter: 47 loss: 0.00169193698
Iter: 48 loss: 0.00155862013
Iter: 49 loss: 0.00213184766
Iter: 50 loss: 0.0015269299
Iter: 51 loss: 0.00141734583
Iter: 52 loss: 0.00203896058
Iter: 53 loss: 0.00140386156
Iter: 54 loss: 0.00132182951
Iter: 55 loss: 0.00137154572
Iter: 56 loss: 0.00126817753
Iter: 57 loss: 0.00118442578
Iter: 58 loss: 0.00181258
Iter: 59 loss: 0.00117789162
Iter: 60 loss: 0.0011095556
Iter: 61 loss: 0.00154134911
Iter: 62 loss: 0.00109882222
Iter: 63 loss: 0.00105163606
Iter: 64 loss: 0.00128355774
Iter: 65 loss: 0.00104408525
Iter: 66 loss: 0.00100270193
Iter: 67 loss: 0.00102756498
Iter: 68 loss: 0.000975174131
Iter: 69 loss: 0.000910475035
Iter: 70 loss: 0.00113190105
Iter: 71 loss: 0.000892566692
Iter: 72 loss: 0.00084997504
Iter: 73 loss: 0.00116722379
Iter: 74 loss: 0.000845843926
Iter: 75 loss: 0.000806858181
Iter: 76 loss: 0.000835126906
Iter: 77 loss: 0.000782249204
Iter: 78 loss: 0.000738971867
Iter: 79 loss: 0.000845963252
Iter: 80 loss: 0.000723439443
Iter: 81 loss: 0.000684168888
Iter: 82 loss: 0.000880828
Iter: 83 loss: 0.000677606673
Iter: 84 loss: 0.000645231339
Iter: 85 loss: 0.000751760963
Iter: 86 loss: 0.000636052515
Iter: 87 loss: 0.000608170638
Iter: 88 loss: 0.000672060065
Iter: 89 loss: 0.000597294769
Iter: 90 loss: 0.000570251374
Iter: 91 loss: 0.000721223827
Iter: 92 loss: 0.000566877192
Iter: 93 loss: 0.000549069722
Iter: 94 loss: 0.000640856219
Iter: 95 loss: 0.000545826508
Iter: 96 loss: 0.000531496305
Iter: 97 loss: 0.000649011286
Iter: 98 loss: 0.000530779536
Iter: 99 loss: 0.000518102723
Iter: 100 loss: 0.00051310577
Iter: 101 loss: 0.000506178243
Iter: 102 loss: 0.000488838879
Iter: 103 loss: 0.000479805953
Iter: 104 loss: 0.0004718579
Iter: 105 loss: 0.000451692846
Iter: 106 loss: 0.000548059295
Iter: 107 loss: 0.000448038976
Iter: 108 loss: 0.000431512657
Iter: 109 loss: 0.000512400758
Iter: 110 loss: 0.000428668805
Iter: 111 loss: 0.000414512469
Iter: 112 loss: 0.000425741833
Iter: 113 loss: 0.000405915431
Iter: 114 loss: 0.000388635497
Iter: 115 loss: 0.000445738726
Iter: 116 loss: 0.000383817125
Iter: 117 loss: 0.000369479647
Iter: 118 loss: 0.000410895736
Iter: 119 loss: 0.000364906242
Iter: 120 loss: 0.000351407973
Iter: 121 loss: 0.000410550943
Iter: 122 loss: 0.000348618458
Iter: 123 loss: 0.00033738013
Iter: 124 loss: 0.000386304513
Iter: 125 loss: 0.000335028104
Iter: 126 loss: 0.000326391833
Iter: 127 loss: 0.000404061226
Iter: 128 loss: 0.000326066278
Iter: 129 loss: 0.000319620623
Iter: 130 loss: 0.000377496646
Iter: 131 loss: 0.000319233572
Iter: 132 loss: 0.000313921511
Iter: 133 loss: 0.000312864402
Iter: 134 loss: 0.000309371448
Iter: 135 loss: 0.000302083441
Iter: 136 loss: 0.000317446917
Iter: 137 loss: 0.000299170497
Iter: 138 loss: 0.000292312
Iter: 139 loss: 0.000291077129
Iter: 140 loss: 0.000286431401
Iter: 141 loss: 0.000278024265
Iter: 142 loss: 0.00033107528
Iter: 143 loss: 0.000277038984
Iter: 144 loss: 0.000270539662
Iter: 145 loss: 0.000280571228
Iter: 146 loss: 0.000267456635
Iter: 147 loss: 0.000260388129
Iter: 148 loss: 0.000284642068
Iter: 149 loss: 0.000258518
Iter: 150 loss: 0.000251638237
Iter: 151 loss: 0.000260574772
Iter: 152 loss: 0.000248122204
Iter: 153 loss: 0.000241450718
Iter: 154 loss: 0.00025318304
Iter: 155 loss: 0.00023849326
Iter: 156 loss: 0.000232424587
Iter: 157 loss: 0.000275584578
Iter: 158 loss: 0.000231879108
Iter: 159 loss: 0.000226709046
Iter: 160 loss: 0.000245077361
Iter: 161 loss: 0.000225318785
Iter: 162 loss: 0.000222621442
Iter: 163 loss: 0.000222155169
Iter: 164 loss: 0.000219816458
Iter: 165 loss: 0.000218673595
Iter: 166 loss: 0.000217531182
Iter: 167 loss: 0.00021396509
Iter: 168 loss: 0.00021340356
Iter: 169 loss: 0.000210936632
Iter: 170 loss: 0.000206615485
Iter: 171 loss: 0.000216211251
Iter: 172 loss: 0.00020494542
Iter: 173 loss: 0.000200273716
Iter: 174 loss: 0.00021036237
Iter: 175 loss: 0.000198469555
Iter: 176 loss: 0.0001940644
Iter: 177 loss: 0.000205507837
Iter: 178 loss: 0.000192561129
Iter: 179 loss: 0.000187874452
Iter: 180 loss: 0.000203833974
Iter: 181 loss: 0.000186605437
Iter: 182 loss: 0.000182274583
Iter: 183 loss: 0.000193742482
Iter: 184 loss: 0.000180817442
Iter: 185 loss: 0.000176217829
Iter: 186 loss: 0.000185286801
Iter: 187 loss: 0.000174322195
Iter: 188 loss: 0.000170236555
Iter: 189 loss: 0.000185925048
Iter: 190 loss: 0.00016925142
Iter: 191 loss: 0.000165004341
Iter: 192 loss: 0.000183920289
Iter: 193 loss: 0.000164176279
Iter: 194 loss: 0.000162479031
Iter: 195 loss: 0.000162248951
Iter: 196 loss: 0.000160584139
Iter: 197 loss: 0.000161572461
Iter: 198 loss: 0.000159520932
Iter: 199 loss: 0.000157413102
Iter: 200 loss: 0.000157509843
Iter: 201 loss: 0.000155749352
Iter: 202 loss: 0.00015317103
Iter: 203 loss: 0.000155486603
Iter: 204 loss: 0.000151668399
Iter: 205 loss: 0.00014834122
Iter: 206 loss: 0.000156548063
Iter: 207 loss: 0.000147149723
Iter: 208 loss: 0.000144198537
Iter: 209 loss: 0.000153902394
Iter: 210 loss: 0.000143370067
Iter: 211 loss: 0.000140794102
Iter: 212 loss: 0.000147720886
Iter: 213 loss: 0.00013993615
Iter: 214 loss: 0.000137357885
Iter: 215 loss: 0.000144827034
Iter: 216 loss: 0.000136552757
Iter: 217 loss: 0.00013400591
Iter: 218 loss: 0.000143036945
Iter: 219 loss: 0.000133347523
Iter: 220 loss: 0.000131114532
Iter: 221 loss: 0.000135471229
Iter: 222 loss: 0.00013018561
Iter: 223 loss: 0.000127733772
Iter: 224 loss: 0.000135258335
Iter: 225 loss: 0.000126997562
Iter: 226 loss: 0.000125763865
Iter: 227 loss: 0.000125622493
Iter: 228 loss: 0.000124503975
Iter: 229 loss: 0.000127723164
Iter: 230 loss: 0.000124143611
Iter: 231 loss: 0.000123144011
Iter: 232 loss: 0.000122239682
Iter: 233 loss: 0.000121990292
Iter: 234 loss: 0.000120335186
Iter: 235 loss: 0.000124948434
Iter: 236 loss: 0.000119796969
Iter: 237 loss: 0.000118142088
Iter: 238 loss: 0.000118964599
Iter: 239 loss: 0.000117036281
Iter: 240 loss: 0.000115131123
Iter: 241 loss: 0.000129024236
Iter: 242 loss: 0.000114969385
Iter: 243 loss: 0.000113604488
Iter: 244 loss: 0.00011401438
Iter: 245 loss: 0.000112625741
Iter: 246 loss: 0.000110887842
Iter: 247 loss: 0.000118967269
Iter: 248 loss: 0.000110561974
Iter: 249 loss: 0.000109150729
Iter: 250 loss: 0.000113539216
Iter: 251 loss: 0.000108736604
Iter: 252 loss: 0.000107378888
Iter: 253 loss: 0.000110794754
Iter: 254 loss: 0.000106901614
Iter: 255 loss: 0.000105494226
Iter: 256 loss: 0.000108925378
Iter: 257 loss: 0.000104992476
Iter: 258 loss: 0.000104175248
Iter: 259 loss: 0.000104154431
Iter: 260 loss: 0.000103382597
Iter: 261 loss: 0.000107863008
Iter: 262 loss: 0.000103284125
Iter: 263 loss: 0.000102710415
Iter: 264 loss: 0.000102084698
Iter: 265 loss: 0.000101989863
Iter: 266 loss: 0.000101098674
Iter: 267 loss: 0.00010283888
Iter: 268 loss: 0.000100730264
Iter: 269 loss: 9.97490715e-05
Iter: 270 loss: 0.000100534766
Iter: 271 loss: 9.91571869e-05
Iter: 272 loss: 9.81827179e-05
Iter: 273 loss: 0.000102685946
Iter: 274 loss: 9.79992765e-05
Iter: 275 loss: 9.7056356e-05
Iter: 276 loss: 9.94042e-05
Iter: 277 loss: 9.67231244e-05
Iter: 278 loss: 9.58392848e-05
Iter: 279 loss: 9.69508e-05
Iter: 280 loss: 9.53817944e-05
Iter: 281 loss: 9.43813575e-05
Iter: 282 loss: 9.96616436e-05
Iter: 283 loss: 9.42241604e-05
Iter: 284 loss: 9.3347342e-05
Iter: 285 loss: 9.41812468e-05
Iter: 286 loss: 9.28455702e-05
Iter: 287 loss: 9.18312871e-05
Iter: 288 loss: 9.62534832e-05
Iter: 289 loss: 9.16208664e-05
Iter: 290 loss: 9.08256e-05
Iter: 291 loss: 9.57225e-05
Iter: 292 loss: 9.07329086e-05
Iter: 293 loss: 9.01271269e-05
Iter: 294 loss: 9.97976e-05
Iter: 295 loss: 9.01267922e-05
Iter: 296 loss: 8.97565915e-05
Iter: 297 loss: 8.9384157e-05
Iter: 298 loss: 8.9309804e-05
Iter: 299 loss: 8.87075e-05
Iter: 300 loss: 8.92455064e-05
Iter: 301 loss: 8.83548e-05
Iter: 302 loss: 8.76359e-05
Iter: 303 loss: 9.01163876e-05
Iter: 304 loss: 8.74450197e-05
Iter: 305 loss: 8.67859053e-05
Iter: 306 loss: 8.71396333e-05
Iter: 307 loss: 8.63505702e-05
Iter: 308 loss: 8.55977123e-05
Iter: 309 loss: 8.98867074e-05
Iter: 310 loss: 8.54944665e-05
Iter: 311 loss: 8.47838091e-05
Iter: 312 loss: 8.53796591e-05
Iter: 313 loss: 8.43610833e-05
Iter: 314 loss: 8.36318868e-05
Iter: 315 loss: 8.64684698e-05
Iter: 316 loss: 8.34630773e-05
Iter: 317 loss: 8.27209442e-05
Iter: 318 loss: 8.47796036e-05
Iter: 319 loss: 8.24809758e-05
Iter: 320 loss: 8.17893451e-05
Iter: 321 loss: 8.3130537e-05
Iter: 322 loss: 8.15022795e-05
Iter: 323 loss: 8.08560144e-05
Iter: 324 loss: 8.53672682e-05
Iter: 325 loss: 8.0794809e-05
Iter: 326 loss: 8.05217496e-05
Iter: 327 loss: 8.04771e-05
Iter: 328 loss: 8.02412833e-05
Iter: 329 loss: 7.98830079e-05
Iter: 330 loss: 7.98764377e-05
Iter: 331 loss: 7.94165899e-05
Iter: 332 loss: 7.95563101e-05
Iter: 333 loss: 7.90875929e-05
Iter: 334 loss: 7.85224765e-05
Iter: 335 loss: 8.1115053e-05
Iter: 336 loss: 7.84148579e-05
Iter: 337 loss: 7.79491238e-05
Iter: 338 loss: 7.82469e-05
Iter: 339 loss: 7.76524103e-05
Iter: 340 loss: 7.71038613e-05
Iter: 341 loss: 7.94734806e-05
Iter: 342 loss: 7.69912294e-05
Iter: 343 loss: 7.65060104e-05
Iter: 344 loss: 7.77708337e-05
Iter: 345 loss: 7.63410644e-05
Iter: 346 loss: 7.58393144e-05
Iter: 347 loss: 7.68108875e-05
Iter: 348 loss: 7.56300287e-05
Iter: 349 loss: 7.51346961e-05
Iter: 350 loss: 7.63569551e-05
Iter: 351 loss: 7.49589381e-05
Iter: 352 loss: 7.44827776e-05
Iter: 353 loss: 7.70602855e-05
Iter: 354 loss: 7.44114877e-05
Iter: 355 loss: 7.40121177e-05
Iter: 356 loss: 7.45562284e-05
Iter: 357 loss: 7.38127928e-05
Iter: 358 loss: 7.37187947e-05
Iter: 359 loss: 7.36024376e-05
Iter: 360 loss: 7.34354908e-05
Iter: 361 loss: 7.33114e-05
Iter: 362 loss: 7.32560366e-05
Iter: 363 loss: 7.29984895e-05
Iter: 364 loss: 7.29066378e-05
Iter: 365 loss: 7.27618171e-05
Iter: 366 loss: 7.24294514e-05
Iter: 367 loss: 7.44691206e-05
Iter: 368 loss: 7.23896374e-05
Iter: 369 loss: 7.21145188e-05
Iter: 370 loss: 7.22049663e-05
Iter: 371 loss: 7.19190357e-05
Iter: 372 loss: 7.15991773e-05
Iter: 373 loss: 7.26513899e-05
Iter: 374 loss: 7.15102069e-05
Iter: 375 loss: 7.11773173e-05
Iter: 376 loss: 7.18628435e-05
Iter: 377 loss: 7.10439199e-05
Iter: 378 loss: 7.07035433e-05
Iter: 379 loss: 7.1842871e-05
Iter: 380 loss: 7.06106803e-05
Iter: 381 loss: 7.02851103e-05
Iter: 382 loss: 7.08032603e-05
Iter: 383 loss: 7.01337485e-05
Iter: 384 loss: 6.9788337e-05
Iter: 385 loss: 7.10847889e-05
Iter: 386 loss: 6.97047799e-05
Iter: 387 loss: 6.93961629e-05
Iter: 388 loss: 7.05213606e-05
Iter: 389 loss: 6.93188922e-05
Iter: 390 loss: 6.91651949e-05
Iter: 391 loss: 6.91574824e-05
Iter: 392 loss: 6.89829e-05
Iter: 393 loss: 6.90057568e-05
Iter: 394 loss: 6.88494183e-05
Iter: 395 loss: 6.86639396e-05
Iter: 396 loss: 6.86042476e-05
Iter: 397 loss: 6.84957486e-05
Iter: 398 loss: 6.82397076e-05
Iter: 399 loss: 6.90820962e-05
Iter: 400 loss: 6.81689125e-05
Iter: 401 loss: 6.79440418e-05
Iter: 402 loss: 6.86339699e-05
Iter: 403 loss: 6.78775541e-05
Iter: 404 loss: 6.76566196e-05
Iter: 405 loss: 6.77312e-05
Iter: 406 loss: 6.75003394e-05
Iter: 407 loss: 6.71962189e-05
Iter: 408 loss: 6.82825e-05
Iter: 409 loss: 6.71187881e-05
Iter: 410 loss: 6.68459179e-05
Iter: 411 loss: 6.76201307e-05
Iter: 412 loss: 6.67593704e-05
Iter: 413 loss: 6.64907129e-05
Iter: 414 loss: 6.71112648e-05
Iter: 415 loss: 6.63906685e-05
Iter: 416 loss: 6.60987062e-05
Iter: 417 loss: 6.66372507e-05
Iter: 418 loss: 6.59736615e-05
Iter: 419 loss: 6.56814373e-05
Iter: 420 loss: 6.67590648e-05
Iter: 421 loss: 6.56094635e-05
Iter: 422 loss: 6.53730094e-05
Iter: 423 loss: 6.7828274e-05
Iter: 424 loss: 6.53662e-05
Iter: 425 loss: 6.51482042e-05
Iter: 426 loss: 6.67111235e-05
Iter: 427 loss: 6.51298324e-05
Iter: 428 loss: 6.50017319e-05
Iter: 429 loss: 6.47832348e-05
Iter: 430 loss: 6.47830384e-05
Iter: 431 loss: 6.45595137e-05
Iter: 432 loss: 6.54650648e-05
Iter: 433 loss: 6.4509979e-05
Iter: 434 loss: 6.42919185e-05
Iter: 435 loss: 6.45795881e-05
Iter: 436 loss: 6.41814768e-05
Iter: 437 loss: 6.39427526e-05
Iter: 438 loss: 6.44856191e-05
Iter: 439 loss: 6.38531346e-05
Iter: 440 loss: 6.36032346e-05
Iter: 441 loss: 6.44704123e-05
Iter: 442 loss: 6.35372271e-05
Iter: 443 loss: 6.33269374e-05
Iter: 444 loss: 6.36354089e-05
Iter: 445 loss: 6.32252777e-05
Iter: 446 loss: 6.29691858e-05
Iter: 447 loss: 6.40007493e-05
Iter: 448 loss: 6.29118076e-05
Iter: 449 loss: 6.2698804e-05
Iter: 450 loss: 6.30456925e-05
Iter: 451 loss: 6.26010296e-05
Iter: 452 loss: 6.23587475e-05
Iter: 453 loss: 6.30082213e-05
Iter: 454 loss: 6.22780281e-05
Iter: 455 loss: 6.20723949e-05
Iter: 456 loss: 6.36210098e-05
Iter: 457 loss: 6.20566934e-05
Iter: 458 loss: 6.19018829e-05
Iter: 459 loss: 6.43106905e-05
Iter: 460 loss: 6.19018319e-05
Iter: 461 loss: 6.18107879e-05
Iter: 462 loss: 6.16769466e-05
Iter: 463 loss: 6.16734906e-05
Iter: 464 loss: 6.15165627e-05
Iter: 465 loss: 6.16117832e-05
Iter: 466 loss: 6.14156233e-05
Iter: 467 loss: 6.1226121e-05
Iter: 468 loss: 6.25284301e-05
Iter: 469 loss: 6.12081e-05
Iter: 470 loss: 6.10674178e-05
Iter: 471 loss: 6.0998249e-05
Iter: 472 loss: 6.09309609e-05
Iter: 473 loss: 6.07366528e-05
Iter: 474 loss: 6.22714e-05
Iter: 475 loss: 6.07233451e-05
Iter: 476 loss: 6.05773203e-05
Iter: 477 loss: 6.06049216e-05
Iter: 478 loss: 6.04683e-05
Iter: 479 loss: 6.02882646e-05
Iter: 480 loss: 6.13868251e-05
Iter: 481 loss: 6.02665059e-05
Iter: 482 loss: 6.01045831e-05
Iter: 483 loss: 6.02887667e-05
Iter: 484 loss: 6.001769e-05
Iter: 485 loss: 5.98439474e-05
Iter: 486 loss: 6.04152301e-05
Iter: 487 loss: 5.9796017e-05
Iter: 488 loss: 5.96437567e-05
Iter: 489 loss: 6.03371191e-05
Iter: 490 loss: 5.96144819e-05
Iter: 491 loss: 5.95293277e-05
Iter: 492 loss: 5.95193342e-05
Iter: 493 loss: 5.94507583e-05
Iter: 494 loss: 5.93359e-05
Iter: 495 loss: 5.93356817e-05
Iter: 496 loss: 5.92168763e-05
Iter: 497 loss: 5.93291625e-05
Iter: 498 loss: 5.91488497e-05
Iter: 499 loss: 5.90124509e-05
Iter: 500 loss: 5.959583e-05
Iter: 501 loss: 5.89840929e-05
Iter: 502 loss: 5.88531293e-05
Iter: 503 loss: 5.89721567e-05
Iter: 504 loss: 5.87771428e-05
Iter: 505 loss: 5.86341193e-05
Iter: 506 loss: 5.9162543e-05
Iter: 507 loss: 5.85989364e-05
Iter: 508 loss: 5.84660629e-05
Iter: 509 loss: 5.87775357e-05
Iter: 510 loss: 5.84173176e-05
Iter: 511 loss: 5.82695648e-05
Iter: 512 loss: 5.84476e-05
Iter: 513 loss: 5.81919085e-05
Iter: 514 loss: 5.80400447e-05
Iter: 515 loss: 5.89058327e-05
Iter: 516 loss: 5.80192136e-05
Iter: 517 loss: 5.78867875e-05
Iter: 518 loss: 5.80681153e-05
Iter: 519 loss: 5.78207801e-05
Iter: 520 loss: 5.76873936e-05
Iter: 521 loss: 5.80991473e-05
Iter: 522 loss: 5.76483981e-05
Iter: 523 loss: 5.75926279e-05
Iter: 524 loss: 5.75730082e-05
Iter: 525 loss: 5.75079248e-05
Iter: 526 loss: 5.74341248e-05
Iter: 527 loss: 5.74246114e-05
Iter: 528 loss: 5.73264042e-05
Iter: 529 loss: 5.73149518e-05
Iter: 530 loss: 5.72444042e-05
Iter: 531 loss: 5.71131532e-05
Iter: 532 loss: 5.75893064e-05
Iter: 533 loss: 5.70802513e-05
Iter: 534 loss: 5.69426593e-05
Iter: 535 loss: 5.72714562e-05
Iter: 536 loss: 5.68929099e-05
Iter: 537 loss: 5.67729585e-05
Iter: 538 loss: 5.69297808e-05
Iter: 539 loss: 5.6711895e-05
Iter: 540 loss: 5.65589944e-05
Iter: 541 loss: 5.70286e-05
Iter: 542 loss: 5.65138798e-05
Iter: 543 loss: 5.6383622e-05
Iter: 544 loss: 5.6754081e-05
Iter: 545 loss: 5.63424182e-05
Iter: 546 loss: 5.62125642e-05
Iter: 547 loss: 5.65576884e-05
Iter: 548 loss: 5.61691559e-05
Iter: 549 loss: 5.60394692e-05
Iter: 550 loss: 5.63354151e-05
Iter: 551 loss: 5.59907021e-05
Iter: 552 loss: 5.5854478e-05
Iter: 553 loss: 5.62364366e-05
Iter: 554 loss: 5.5810935e-05
Iter: 555 loss: 5.5765584e-05
Iter: 556 loss: 5.57502317e-05
Iter: 557 loss: 5.56842424e-05
Iter: 558 loss: 5.56378181e-05
Iter: 559 loss: 5.56143423e-05
Iter: 560 loss: 5.55334482e-05
Iter: 561 loss: 5.55546467e-05
Iter: 562 loss: 5.54745347e-05
Iter: 563 loss: 5.53645e-05
Iter: 564 loss: 5.54234866e-05
Iter: 565 loss: 5.529189e-05
Iter: 566 loss: 5.51649027e-05
Iter: 567 loss: 5.62214846e-05
Iter: 568 loss: 5.51573685e-05
Iter: 569 loss: 5.50658333e-05
Iter: 570 loss: 5.50441291e-05
Iter: 571 loss: 5.4985685e-05
Iter: 572 loss: 5.48588687e-05
Iter: 573 loss: 5.55196202e-05
Iter: 574 loss: 5.48390199e-05
Iter: 575 loss: 5.47330201e-05
Iter: 576 loss: 5.49208198e-05
Iter: 577 loss: 5.46866177e-05
Iter: 578 loss: 5.457714e-05
Iter: 579 loss: 5.49428623e-05
Iter: 580 loss: 5.45471339e-05
Iter: 581 loss: 5.44396426e-05
Iter: 582 loss: 5.46653901e-05
Iter: 583 loss: 5.439702e-05
Iter: 584 loss: 5.42911621e-05
Iter: 585 loss: 5.46696065e-05
Iter: 586 loss: 5.4264161e-05
Iter: 587 loss: 5.41918707e-05
Iter: 588 loss: 5.50284385e-05
Iter: 589 loss: 5.41906302e-05
Iter: 590 loss: 5.41162117e-05
Iter: 591 loss: 5.44665527e-05
Iter: 592 loss: 5.41028785e-05
Iter: 593 loss: 5.40574838e-05
Iter: 594 loss: 5.39837638e-05
Iter: 595 loss: 5.39832799e-05
Iter: 596 loss: 5.38977583e-05
Iter: 597 loss: 5.41375412e-05
Iter: 598 loss: 5.38703825e-05
Iter: 599 loss: 5.37861451e-05
Iter: 600 loss: 5.4067641e-05
Iter: 601 loss: 5.37631022e-05
Iter: 602 loss: 5.36850457e-05
Iter: 603 loss: 5.38565764e-05
Iter: 604 loss: 5.36551124e-05
Iter: 605 loss: 5.35686777e-05
Iter: 606 loss: 5.37442756e-05
Iter: 607 loss: 5.35334657e-05
Iter: 608 loss: 5.34544342e-05
Iter: 609 loss: 5.36640873e-05
Iter: 610 loss: 5.34279752e-05
Iter: 611 loss: 5.33458806e-05
Iter: 612 loss: 5.36163679e-05
Iter: 613 loss: 5.33232451e-05
Iter: 614 loss: 5.32432678e-05
Iter: 615 loss: 5.3345193e-05
Iter: 616 loss: 5.32021477e-05
Iter: 617 loss: 5.31089172e-05
Iter: 618 loss: 5.34644169e-05
Iter: 619 loss: 5.30867546e-05
Iter: 620 loss: 5.30229336e-05
Iter: 621 loss: 5.34729443e-05
Iter: 622 loss: 5.30172911e-05
Iter: 623 loss: 5.29631288e-05
Iter: 624 loss: 5.36571242e-05
Iter: 625 loss: 5.29627323e-05
Iter: 626 loss: 5.29270364e-05
Iter: 627 loss: 5.28603559e-05
Iter: 628 loss: 5.43473943e-05
Iter: 629 loss: 5.28601304e-05
Iter: 630 loss: 5.27929078e-05
Iter: 631 loss: 5.28951168e-05
Iter: 632 loss: 5.27609591e-05
Iter: 633 loss: 5.26860167e-05
Iter: 634 loss: 5.30920624e-05
Iter: 635 loss: 5.26750191e-05
Iter: 636 loss: 5.26139956e-05
Iter: 637 loss: 5.26679469e-05
Iter: 638 loss: 5.2578238e-05
Iter: 639 loss: 5.25060641e-05
Iter: 640 loss: 5.28428463e-05
Iter: 641 loss: 5.24927818e-05
Iter: 642 loss: 5.24281531e-05
Iter: 643 loss: 5.24328716e-05
Iter: 644 loss: 5.23779163e-05
Iter: 645 loss: 5.22969349e-05
Iter: 646 loss: 5.27436096e-05
Iter: 647 loss: 5.22851333e-05
Iter: 648 loss: 5.22128103e-05
Iter: 649 loss: 5.24079333e-05
Iter: 650 loss: 5.21888069e-05
Iter: 651 loss: 5.21230759e-05
Iter: 652 loss: 5.22044793e-05
Iter: 653 loss: 5.20889225e-05
Iter: 654 loss: 5.20138055e-05
Iter: 655 loss: 5.24300849e-05
Iter: 656 loss: 5.20030044e-05
Iter: 657 loss: 5.19706737e-05
Iter: 658 loss: 5.19637615e-05
Iter: 659 loss: 5.19338428e-05
Iter: 660 loss: 5.18750785e-05
Iter: 661 loss: 5.30413672e-05
Iter: 662 loss: 5.18746238e-05
Iter: 663 loss: 5.18208981e-05
Iter: 664 loss: 5.1901603e-05
Iter: 665 loss: 5.17953e-05
Iter: 666 loss: 5.17331755e-05
Iter: 667 loss: 5.18993402e-05
Iter: 668 loss: 5.17124136e-05
Iter: 669 loss: 5.16450345e-05
Iter: 670 loss: 5.18162633e-05
Iter: 671 loss: 5.16216423e-05
Iter: 672 loss: 5.15586398e-05
Iter: 673 loss: 5.17333319e-05
Iter: 674 loss: 5.15383144e-05
Iter: 675 loss: 5.14766e-05
Iter: 676 loss: 5.1663239e-05
Iter: 677 loss: 5.14581188e-05
Iter: 678 loss: 5.14021667e-05
Iter: 679 loss: 5.14338863e-05
Iter: 680 loss: 5.13655759e-05
Iter: 681 loss: 5.12952756e-05
Iter: 682 loss: 5.17329499e-05
Iter: 683 loss: 5.12870392e-05
Iter: 684 loss: 5.12314327e-05
Iter: 685 loss: 5.1326082e-05
Iter: 686 loss: 5.12067563e-05
Iter: 687 loss: 5.11499093e-05
Iter: 688 loss: 5.12989645e-05
Iter: 689 loss: 5.11308899e-05
Iter: 690 loss: 5.1109e-05
Iter: 691 loss: 5.10997488e-05
Iter: 692 loss: 5.10716382e-05
Iter: 693 loss: 5.10374157e-05
Iter: 694 loss: 5.10341197e-05
Iter: 695 loss: 5.09937963e-05
Iter: 696 loss: 5.09963502e-05
Iter: 697 loss: 5.09623023e-05
Iter: 698 loss: 5.09155943e-05
Iter: 699 loss: 5.11099315e-05
Iter: 700 loss: 5.09055026e-05
Iter: 701 loss: 5.08578451e-05
Iter: 702 loss: 5.09645579e-05
Iter: 703 loss: 5.08397934e-05
Iter: 704 loss: 5.0792376e-05
Iter: 705 loss: 5.08913909e-05
Iter: 706 loss: 5.07735494e-05
Iter: 707 loss: 5.07220648e-05
Iter: 708 loss: 5.08957601e-05
Iter: 709 loss: 5.07080113e-05
Iter: 710 loss: 5.0662813e-05
Iter: 711 loss: 5.06968936e-05
Iter: 712 loss: 5.0635048e-05
Iter: 713 loss: 5.05790231e-05
Iter: 714 loss: 5.08799676e-05
Iter: 715 loss: 5.05705611e-05
Iter: 716 loss: 5.05281496e-05
Iter: 717 loss: 5.06231299e-05
Iter: 718 loss: 5.05120552e-05
Iter: 719 loss: 5.04672789e-05
Iter: 720 loss: 5.06081196e-05
Iter: 721 loss: 5.04543386e-05
Iter: 722 loss: 5.04324198e-05
Iter: 723 loss: 5.04312484e-05
Iter: 724 loss: 5.04050076e-05
Iter: 725 loss: 5.03980045e-05
Iter: 726 loss: 5.03818e-05
Iter: 727 loss: 5.03552583e-05
Iter: 728 loss: 5.03498959e-05
Iter: 729 loss: 5.03322699e-05
Iter: 730 loss: 5.02952462e-05
Iter: 731 loss: 5.03494812e-05
Iter: 732 loss: 5.02774e-05
Iter: 733 loss: 5.0237184e-05
Iter: 734 loss: 5.04581112e-05
Iter: 735 loss: 5.02313451e-05
Iter: 736 loss: 5.01972e-05
Iter: 737 loss: 5.02460389e-05
Iter: 738 loss: 5.01804861e-05
Iter: 739 loss: 5.01432041e-05
Iter: 740 loss: 5.02858857e-05
Iter: 741 loss: 5.0134433e-05
Iter: 742 loss: 5.01013e-05
Iter: 743 loss: 5.01258401e-05
Iter: 744 loss: 5.00810784e-05
Iter: 745 loss: 5.0041217e-05
Iter: 746 loss: 5.02556213e-05
Iter: 747 loss: 5.00351925e-05
Iter: 748 loss: 5.00035676e-05
Iter: 749 loss: 5.00434617e-05
Iter: 750 loss: 4.99873568e-05
Iter: 751 loss: 4.99518828e-05
Iter: 752 loss: 5.01223039e-05
Iter: 753 loss: 4.99454327e-05
Iter: 754 loss: 4.99176786e-05
Iter: 755 loss: 5.00880233e-05
Iter: 756 loss: 4.99142625e-05
Iter: 757 loss: 4.98831432e-05
Iter: 758 loss: 5.00653841e-05
Iter: 759 loss: 4.9879076e-05
Iter: 760 loss: 4.98619447e-05
Iter: 761 loss: 4.98281443e-05
Iter: 762 loss: 5.04981363e-05
Iter: 763 loss: 4.98279296e-05
Iter: 764 loss: 4.97946603e-05
Iter: 765 loss: 4.9946153e-05
Iter: 766 loss: 4.97883302e-05
Iter: 767 loss: 4.97574292e-05
Iter: 768 loss: 4.98202426e-05
Iter: 769 loss: 4.97448709e-05
Iter: 770 loss: 4.97146102e-05
Iter: 771 loss: 4.98398622e-05
Iter: 772 loss: 4.97079345e-05
Iter: 773 loss: 4.96776047e-05
Iter: 774 loss: 4.97211367e-05
Iter: 775 loss: 4.96627326e-05
Iter: 776 loss: 4.9633687e-05
Iter: 777 loss: 4.97243527e-05
Iter: 778 loss: 4.96252214e-05
Iter: 779 loss: 4.95961722e-05
Iter: 780 loss: 4.96657667e-05
Iter: 781 loss: 4.9585673e-05
Iter: 782 loss: 4.95565619e-05
Iter: 783 loss: 4.96185748e-05
Iter: 784 loss: 4.95451459e-05
Iter: 785 loss: 4.95138083e-05
Iter: 786 loss: 4.96159846e-05
Iter: 787 loss: 4.95051499e-05
Iter: 788 loss: 4.94772976e-05
Iter: 789 loss: 4.96375724e-05
Iter: 790 loss: 4.94736814e-05
Iter: 791 loss: 4.94530759e-05
Iter: 792 loss: 4.94531414e-05
Iter: 793 loss: 4.9441107e-05
Iter: 794 loss: 4.94135093e-05
Iter: 795 loss: 4.97681394e-05
Iter: 796 loss: 4.94115884e-05
Iter: 797 loss: 4.93844163e-05
Iter: 798 loss: 4.94633e-05
Iter: 799 loss: 4.93760417e-05
Iter: 800 loss: 4.93490443e-05
Iter: 801 loss: 4.94533742e-05
Iter: 802 loss: 4.93427506e-05
Iter: 803 loss: 4.93177868e-05
Iter: 804 loss: 4.9365146e-05
Iter: 805 loss: 4.93071966e-05
Iter: 806 loss: 4.92811232e-05
Iter: 807 loss: 4.93892621e-05
Iter: 808 loss: 4.92756044e-05
Iter: 809 loss: 4.92507606e-05
Iter: 810 loss: 4.92625768e-05
Iter: 811 loss: 4.92339095e-05
Iter: 812 loss: 4.92076142e-05
Iter: 813 loss: 4.9363538e-05
Iter: 814 loss: 4.92043473e-05
Iter: 815 loss: 4.91803876e-05
Iter: 816 loss: 4.92099934e-05
Iter: 817 loss: 4.91680184e-05
Iter: 818 loss: 4.91424944e-05
Iter: 819 loss: 4.92093932e-05
Iter: 820 loss: 4.91339379e-05
Iter: 821 loss: 4.91093087e-05
Iter: 822 loss: 4.92884355e-05
Iter: 823 loss: 4.91072715e-05
Iter: 824 loss: 4.90983875e-05
Iter: 825 loss: 4.90963648e-05
Iter: 826 loss: 4.90887469e-05
Iter: 827 loss: 4.9068447e-05
Iter: 828 loss: 4.92283143e-05
Iter: 829 loss: 4.90647253e-05
Iter: 830 loss: 4.90431084e-05
Iter: 831 loss: 4.91147439e-05
Iter: 832 loss: 4.90370876e-05
Iter: 833 loss: 4.90173334e-05
Iter: 834 loss: 4.90727725e-05
Iter: 835 loss: 4.90111088e-05
Iter: 836 loss: 4.89901577e-05
Iter: 837 loss: 4.90471e-05
Iter: 838 loss: 4.89832892e-05
Iter: 839 loss: 4.89625891e-05
Iter: 840 loss: 4.9018603e-05
Iter: 841 loss: 4.89557096e-05
Iter: 842 loss: 4.8934955e-05
Iter: 843 loss: 4.89955273e-05
Iter: 844 loss: 4.89285303e-05
Iter: 845 loss: 4.89110425e-05
Iter: 846 loss: 4.8943275e-05
Iter: 847 loss: 4.89035592e-05
Iter: 848 loss: 4.88830337e-05
Iter: 849 loss: 4.89384765e-05
Iter: 850 loss: 4.88762707e-05
Iter: 851 loss: 4.88567821e-05
Iter: 852 loss: 4.89112826e-05
Iter: 853 loss: 4.88504375e-05
Iter: 854 loss: 4.88335063e-05
Iter: 855 loss: 4.89319282e-05
Iter: 856 loss: 4.88312835e-05
Iter: 857 loss: 4.8823953e-05
Iter: 858 loss: 4.88230908e-05
Iter: 859 loss: 4.88156365e-05
Iter: 860 loss: 4.88024598e-05
Iter: 861 loss: 4.91275205e-05
Iter: 862 loss: 4.88024962e-05
Iter: 863 loss: 4.8789032e-05
Iter: 864 loss: 4.87934376e-05
Iter: 865 loss: 4.87795514e-05
Iter: 866 loss: 4.87626094e-05
Iter: 867 loss: 4.88159858e-05
Iter: 868 loss: 4.87578473e-05
Iter: 869 loss: 4.87405923e-05
Iter: 870 loss: 4.87973302e-05
Iter: 871 loss: 4.8735732e-05
Iter: 872 loss: 4.87201978e-05
Iter: 873 loss: 4.87692232e-05
Iter: 874 loss: 4.87155958e-05
Iter: 875 loss: 4.8699847e-05
Iter: 876 loss: 4.8727823e-05
Iter: 877 loss: 4.86929021e-05
Iter: 878 loss: 4.86776808e-05
Iter: 879 loss: 4.87392208e-05
Iter: 880 loss: 4.86743447e-05
Iter: 881 loss: 4.86594909e-05
Iter: 882 loss: 4.8666785e-05
Iter: 883 loss: 4.86494537e-05
Iter: 884 loss: 4.86337158e-05
Iter: 885 loss: 4.87425168e-05
Iter: 886 loss: 4.86321878e-05
Iter: 887 loss: 4.86188765e-05
Iter: 888 loss: 4.8644335e-05
Iter: 889 loss: 4.86133358e-05
Iter: 890 loss: 4.86078134e-05
Iter: 891 loss: 4.86062454e-05
Iter: 892 loss: 4.85989949e-05
Iter: 893 loss: 4.85893215e-05
Iter: 894 loss: 4.85888049e-05
Iter: 895 loss: 4.85779674e-05
Iter: 896 loss: 4.85837845e-05
Iter: 897 loss: 4.85710225e-05
Iter: 898 loss: 4.85583514e-05
Iter: 899 loss: 4.85777782e-05
Iter: 900 loss: 4.8552487e-05
Iter: 901 loss: 4.85387864e-05
Iter: 902 loss: 4.86075e-05
Iter: 903 loss: 4.85364399e-05
Iter: 904 loss: 4.85242526e-05
Iter: 905 loss: 4.85503951e-05
Iter: 906 loss: 4.85194978e-05
Iter: 907 loss: 4.85066339e-05
Iter: 908 loss: 4.85390774e-05
Iter: 909 loss: 4.85022138e-05
Iter: 910 loss: 4.84897864e-05
Iter: 911 loss: 4.85229175e-05
Iter: 912 loss: 4.84855336e-05
Iter: 913 loss: 4.84719749e-05
Iter: 914 loss: 4.84870325e-05
Iter: 915 loss: 4.84645607e-05
Iter: 916 loss: 4.84498887e-05
Iter: 917 loss: 4.85111959e-05
Iter: 918 loss: 4.84467455e-05
Iter: 919 loss: 4.84352713e-05
Iter: 920 loss: 4.85012642e-05
Iter: 921 loss: 4.84337434e-05
Iter: 922 loss: 4.84260745e-05
Iter: 923 loss: 4.85073033e-05
Iter: 924 loss: 4.84259035e-05
Iter: 925 loss: 4.84171323e-05
Iter: 926 loss: 4.84266966e-05
Iter: 927 loss: 4.84124103e-05
Iter: 928 loss: 4.84061457e-05
Iter: 929 loss: 4.83991098e-05
Iter: 930 loss: 4.83981421e-05
Iter: 931 loss: 4.83871081e-05
Iter: 932 loss: 4.84156189e-05
Iter: 933 loss: 4.83834301e-05
Iter: 934 loss: 4.83733966e-05
Iter: 935 loss: 4.84002849e-05
Iter: 936 loss: 4.83702788e-05
Iter: 937 loss: 4.83591903e-05
Iter: 938 loss: 4.84028787e-05
Iter: 939 loss: 4.83567674e-05
Iter: 940 loss: 4.83473705e-05
Iter: 941 loss: 4.83639269e-05
Iter: 942 loss: 4.83433614e-05
Iter: 943 loss: 4.83331532e-05
Iter: 944 loss: 4.83620097e-05
Iter: 945 loss: 4.833001e-05
Iter: 946 loss: 4.83195035e-05
Iter: 947 loss: 4.83395816e-05
Iter: 948 loss: 4.83152799e-05
Iter: 949 loss: 4.83050426e-05
Iter: 950 loss: 4.83343e-05
Iter: 951 loss: 4.83019103e-05
Iter: 952 loss: 4.82926553e-05
Iter: 953 loss: 4.83364202e-05
Iter: 954 loss: 4.82908945e-05
Iter: 955 loss: 4.82838514e-05
Iter: 956 loss: 4.83456024e-05
Iter: 957 loss: 4.82835057e-05
Iter: 958 loss: 4.82763935e-05
Iter: 959 loss: 4.83092736e-05
Iter: 960 loss: 4.82750584e-05
Iter: 961 loss: 4.82709802e-05
Iter: 962 loss: 4.82632167e-05
Iter: 963 loss: 4.84374068e-05
Iter: 964 loss: 4.8263224e-05
Iter: 965 loss: 4.8253758e-05
Iter: 966 loss: 4.82734176e-05
Iter: 967 loss: 4.82501637e-05
Iter: 968 loss: 4.82410032e-05
Iter: 969 loss: 4.82791147e-05
Iter: 970 loss: 4.82390096e-05
Iter: 971 loss: 4.82307041e-05
Iter: 972 loss: 4.82557589e-05
Iter: 973 loss: 4.82280884e-05
Iter: 974 loss: 4.82200667e-05
Iter: 975 loss: 4.82464711e-05
Iter: 976 loss: 4.82177784e-05
Iter: 977 loss: 4.82102732e-05
Iter: 978 loss: 4.82171818e-05
Iter: 979 loss: 4.82058967e-05
Iter: 980 loss: 4.81969655e-05
Iter: 981 loss: 4.82459654e-05
Iter: 982 loss: 4.81955867e-05
Iter: 983 loss: 4.81884708e-05
Iter: 984 loss: 4.81904863e-05
Iter: 985 loss: 4.81833558e-05
Iter: 986 loss: 4.81747629e-05
Iter: 987 loss: 4.82335163e-05
Iter: 988 loss: 4.81740608e-05
Iter: 989 loss: 4.81678289e-05
Iter: 990 loss: 4.82051873e-05
Iter: 991 loss: 4.81671e-05
Iter: 992 loss: 4.81616844e-05
Iter: 993 loss: 4.82261967e-05
Iter: 994 loss: 4.8161608e-05
Iter: 995 loss: 4.81588431e-05
Iter: 996 loss: 4.8152513e-05
Iter: 997 loss: 4.8238926e-05
Iter: 998 loss: 4.81520183e-05
Iter: 999 loss: 4.81445022e-05
Iter: 1000 loss: 4.81602619e-05
Iter: 1001 loss: 4.81415227e-05
Iter: 1002 loss: 4.81344105e-05
Iter: 1003 loss: 4.81561365e-05
Iter: 1004 loss: 4.81323077e-05
Iter: 1005 loss: 4.81250318e-05
Iter: 1006 loss: 4.81547686e-05
Iter: 1007 loss: 4.8123562e-05
Iter: 1008 loss: 4.81174793e-05
Iter: 1009 loss: 4.81345778e-05
Iter: 1010 loss: 4.81155548e-05
Iter: 1011 loss: 4.81088828e-05
Iter: 1012 loss: 4.81150346e-05
Iter: 1013 loss: 4.81049392e-05
Iter: 1014 loss: 4.80974049e-05
Iter: 1015 loss: 4.81288043e-05
Iter: 1016 loss: 4.8095877e-05
Iter: 1017 loss: 4.80892922e-05
Iter: 1018 loss: 4.81052411e-05
Iter: 1019 loss: 4.8087084e-05
Iter: 1020 loss: 4.8080743e-05
Iter: 1021 loss: 4.80955714e-05
Iter: 1022 loss: 4.80783929e-05
Iter: 1023 loss: 4.80722811e-05
Iter: 1024 loss: 4.8116166e-05
Iter: 1025 loss: 4.80719464e-05
Iter: 1026 loss: 4.80678791e-05
Iter: 1027 loss: 4.80678427e-05
Iter: 1028 loss: 4.80651725e-05
Iter: 1029 loss: 4.80598828e-05
Iter: 1030 loss: 4.81578172e-05
Iter: 1031 loss: 4.80598064e-05
Iter: 1032 loss: 4.80541203e-05
Iter: 1033 loss: 4.80597082e-05
Iter: 1034 loss: 4.80508243e-05
Iter: 1035 loss: 4.80441704e-05
Iter: 1036 loss: 4.80632152e-05
Iter: 1037 loss: 4.80419403e-05
Iter: 1038 loss: 4.8035763e-05
Iter: 1039 loss: 4.80675444e-05
Iter: 1040 loss: 4.80348644e-05
Iter: 1041 loss: 4.80292802e-05
Iter: 1042 loss: 4.80408344e-05
Iter: 1043 loss: 4.80271556e-05
Iter: 1044 loss: 4.80214039e-05
Iter: 1045 loss: 4.80348208e-05
Iter: 1046 loss: 4.80192539e-05
Iter: 1047 loss: 4.80132767e-05
Iter: 1048 loss: 4.80302115e-05
Iter: 1049 loss: 4.80113049e-05
Iter: 1050 loss: 4.80059971e-05
Iter: 1051 loss: 4.80172203e-05
Iter: 1052 loss: 4.80038834e-05
Iter: 1053 loss: 4.79979e-05
Iter: 1054 loss: 4.80156705e-05
Iter: 1055 loss: 4.79960072e-05
Iter: 1056 loss: 4.79907903e-05
Iter: 1057 loss: 4.80149392e-05
Iter: 1058 loss: 4.79899099e-05
Iter: 1059 loss: 4.79870469e-05
Iter: 1060 loss: 4.79867449e-05
Iter: 1061 loss: 4.79844821e-05
Iter: 1062 loss: 4.79801201e-05
Iter: 1063 loss: 4.80658855e-05
Iter: 1064 loss: 4.79800838e-05
Iter: 1065 loss: 4.7975278e-05
Iter: 1066 loss: 4.79812734e-05
Iter: 1067 loss: 4.79729388e-05
Iter: 1068 loss: 4.79680857e-05
Iter: 1069 loss: 4.79761802e-05
Iter: 1070 loss: 4.7966e-05
Iter: 1071 loss: 4.79608934e-05
Iter: 1072 loss: 4.799218e-05
Iter: 1073 loss: 4.7960355e-05
Iter: 1074 loss: 4.79561422e-05
Iter: 1075 loss: 4.79625814e-05
Iter: 1076 loss: 4.79541959e-05
Iter: 1077 loss: 4.79492373e-05
Iter: 1078 loss: 4.7965259e-05
Iter: 1079 loss: 4.79479968e-05
Iter: 1080 loss: 4.79435839e-05
Iter: 1081 loss: 4.79514565e-05
Iter: 1082 loss: 4.79417649e-05
Iter: 1083 loss: 4.79367445e-05
Iter: 1084 loss: 4.79496048e-05
Iter: 1085 loss: 4.79350638e-05
Iter: 1086 loss: 4.79304945e-05
Iter: 1087 loss: 4.79439623e-05
Iter: 1088 loss: 4.79290575e-05
Iter: 1089 loss: 4.792455e-05
Iter: 1090 loss: 4.79437185e-05
Iter: 1091 loss: 4.79236842e-05
Iter: 1092 loss: 4.79219489e-05
Iter: 1093 loss: 4.79215523e-05
Iter: 1094 loss: 4.79196569e-05
Iter: 1095 loss: 4.79157425e-05
Iter: 1096 loss: 4.79890441e-05
Iter: 1097 loss: 4.79157898e-05
Iter: 1098 loss: 4.79121227e-05
Iter: 1099 loss: 4.79199807e-05
Iter: 1100 loss: 4.79106093e-05
Iter: 1101 loss: 4.79070441e-05
Iter: 1102 loss: 4.79071714e-05
Iter: 1103 loss: 4.79040973e-05
Iter: 1104 loss: 4.78995062e-05
Iter: 1105 loss: 4.79330774e-05
Iter: 1106 loss: 4.78991642e-05
Iter: 1107 loss: 4.78953225e-05
Iter: 1108 loss: 4.79025475e-05
Iter: 1109 loss: 4.78935908e-05
Iter: 1110 loss: 4.78896254e-05
Iter: 1111 loss: 4.79035589e-05
Iter: 1112 loss: 4.78886577e-05
Iter: 1113 loss: 4.78847214e-05
Iter: 1114 loss: 4.78911024e-05
Iter: 1115 loss: 4.78829461e-05
Iter: 1116 loss: 4.78786897e-05
Iter: 1117 loss: 4.7890273e-05
Iter: 1118 loss: 4.78774236e-05
Iter: 1119 loss: 4.78734146e-05
Iter: 1120 loss: 4.78853763e-05
Iter: 1121 loss: 4.78722941e-05
Iter: 1122 loss: 4.78684e-05
Iter: 1123 loss: 4.78815491e-05
Iter: 1124 loss: 4.78674556e-05
Iter: 1125 loss: 4.78656511e-05
Iter: 1126 loss: 4.78654656e-05
Iter: 1127 loss: 4.78636066e-05
Iter: 1128 loss: 4.78615293e-05
Iter: 1129 loss: 4.78612346e-05
Iter: 1130 loss: 4.78586735e-05
Iter: 1131 loss: 4.78589027e-05
Iter: 1132 loss: 4.78565416e-05
Iter: 1133 loss: 4.78528273e-05
Iter: 1134 loss: 4.78585243e-05
Iter: 1135 loss: 4.78510337e-05
Iter: 1136 loss: 4.78474722e-05
Iter: 1137 loss: 4.78634574e-05
Iter: 1138 loss: 4.78465736e-05
Iter: 1139 loss: 4.78430811e-05
Iter: 1140 loss: 4.78553848e-05
Iter: 1141 loss: 4.7842339e-05
Iter: 1142 loss: 4.78390466e-05
Iter: 1143 loss: 4.78452384e-05
Iter: 1144 loss: 4.78375223e-05
Iter: 1145 loss: 4.78341208e-05
Iter: 1146 loss: 4.78461625e-05
Iter: 1147 loss: 4.7833375e-05
Iter: 1148 loss: 4.78300935e-05
Iter: 1149 loss: 4.783447e-05
Iter: 1150 loss: 4.78283364e-05
Iter: 1151 loss: 4.78249458e-05
Iter: 1152 loss: 4.78366273e-05
Iter: 1153 loss: 4.78238871e-05
Iter: 1154 loss: 4.78206348e-05
Iter: 1155 loss: 4.78346556e-05
Iter: 1156 loss: 4.78198854e-05
Iter: 1157 loss: 4.78182264e-05
Iter: 1158 loss: 4.78180955e-05
Iter: 1159 loss: 4.78163565e-05
Iter: 1160 loss: 4.78151269e-05
Iter: 1161 loss: 4.78144357e-05
Iter: 1162 loss: 4.78121874e-05
Iter: 1163 loss: 4.78118745e-05
Iter: 1164 loss: 4.78103539e-05
Iter: 1165 loss: 4.78073234e-05
Iter: 1166 loss: 4.781194e-05
Iter: 1167 loss: 4.78059083e-05
Iter: 1168 loss: 4.78027905e-05
Iter: 1169 loss: 4.78140209e-05
Iter: 1170 loss: 4.78020884e-05
Iter: 1171 loss: 4.77990106e-05
Iter: 1172 loss: 4.78089823e-05
Iter: 1173 loss: 4.77981848e-05
Iter: 1174 loss: 4.77953508e-05
Iter: 1175 loss: 4.78049769e-05
Iter: 1176 loss: 4.77946523e-05
Iter: 1177 loss: 4.77919311e-05
Iter: 1178 loss: 4.77961476e-05
Iter: 1179 loss: 4.77906869e-05
Iter: 1180 loss: 4.77878893e-05
Iter: 1181 loss: 4.77969843e-05
Iter: 1182 loss: 4.77870635e-05
Iter: 1183 loss: 4.77839931e-05
Iter: 1184 loss: 4.77884969e-05
Iter: 1185 loss: 4.77827234e-05
Iter: 1186 loss: 4.77800204e-05
Iter: 1187 loss: 4.77970534e-05
Iter: 1188 loss: 4.77797585e-05
Iter: 1189 loss: 4.77777648e-05
Iter: 1190 loss: 4.77988e-05
Iter: 1191 loss: 4.77779686e-05
Iter: 1192 loss: 4.77760113e-05
Iter: 1193 loss: 4.77790527e-05
Iter: 1194 loss: 4.77750873e-05
Iter: 1195 loss: 4.77737085e-05
Iter: 1196 loss: 4.77719914e-05
Iter: 1197 loss: 4.77718713e-05
Iter: 1198 loss: 4.77691137e-05
Iter: 1199 loss: 4.77742251e-05
Iter: 1200 loss: 4.77680296e-05
Iter: 1201 loss: 4.77655594e-05
Iter: 1202 loss: 4.77730937e-05
Iter: 1203 loss: 4.77647518e-05
Iter: 1204 loss: 4.77622161e-05
Iter: 1205 loss: 4.77715366e-05
Iter: 1206 loss: 4.77616741e-05
Iter: 1207 loss: 4.7759364e-05
Iter: 1208 loss: 4.77656067e-05
Iter: 1209 loss: 4.77585127e-05
Iter: 1210 loss: 4.77560934e-05
Iter: 1211 loss: 4.77609938e-05
Iter: 1212 loss: 4.77550966e-05
Iter: 1213 loss: 4.77525973e-05
Iter: 1214 loss: 4.77606081e-05
Iter: 1215 loss: 4.77519643e-05
Iter: 1216 loss: 4.77495087e-05
Iter: 1217 loss: 4.7753565e-05
Iter: 1218 loss: 4.77486974e-05
Iter: 1219 loss: 4.77462454e-05
Iter: 1220 loss: 4.77563881e-05
Iter: 1221 loss: 4.77457397e-05
Iter: 1222 loss: 4.77441063e-05
Iter: 1223 loss: 4.77651229e-05
Iter: 1224 loss: 4.77440954e-05
Iter: 1225 loss: 4.77424692e-05
Iter: 1226 loss: 4.77476096e-05
Iter: 1227 loss: 4.77420035e-05
Iter: 1228 loss: 4.77408321e-05
Iter: 1229 loss: 4.77394678e-05
Iter: 1230 loss: 4.77392496e-05
Iter: 1231 loss: 4.77373469e-05
Iter: 1232 loss: 4.7740119e-05
Iter: 1233 loss: 4.77365e-05
Iter: 1234 loss: 4.77343419e-05
Iter: 1235 loss: 4.77410213e-05
Iter: 1236 loss: 4.77336835e-05
Iter: 1237 loss: 4.77316062e-05
Iter: 1238 loss: 4.77366775e-05
Iter: 1239 loss: 4.77307622e-05
Iter: 1240 loss: 4.77286339e-05
Iter: 1241 loss: 4.77396061e-05
Iter: 1242 loss: 4.77282083e-05
Iter: 1243 loss: 4.77264111e-05
Iter: 1244 loss: 4.77289723e-05
Iter: 1245 loss: 4.77255235e-05
Iter: 1246 loss: 4.77234498e-05
Iter: 1247 loss: 4.77296053e-05
Iter: 1248 loss: 4.77227659e-05
Iter: 1249 loss: 4.77208e-05
Iter: 1250 loss: 4.77245485e-05
Iter: 1251 loss: 4.77199355e-05
Iter: 1252 loss: 4.77178037e-05
Iter: 1253 loss: 4.77270041e-05
Iter: 1254 loss: 4.77174472e-05
Iter: 1255 loss: 4.77159592e-05
Iter: 1256 loss: 4.77282774e-05
Iter: 1257 loss: 4.7715861e-05
Iter: 1258 loss: 4.77144968e-05
Iter: 1259 loss: 4.77232934e-05
Iter: 1260 loss: 4.77142676e-05
Iter: 1261 loss: 4.77134236e-05
Iter: 1262 loss: 4.77119356e-05
Iter: 1263 loss: 4.77119174e-05
Iter: 1264 loss: 4.77101275e-05
Iter: 1265 loss: 4.77119465e-05
Iter: 1266 loss: 4.77091926e-05
Iter: 1267 loss: 4.77072972e-05
Iter: 1268 loss: 4.77144422e-05
Iter: 1269 loss: 4.77067806e-05
Iter: 1270 loss: 4.77049507e-05
Iter: 1271 loss: 4.77098365e-05
Iter: 1272 loss: 4.77043577e-05
Iter: 1273 loss: 4.77026588e-05
Iter: 1274 loss: 4.77084177e-05
Iter: 1275 loss: 4.77021131e-05
Iter: 1276 loss: 4.77002104e-05
Iter: 1277 loss: 4.77055473e-05
Iter: 1278 loss: 4.76997629e-05
Iter: 1279 loss: 4.76979621e-05
Iter: 1280 loss: 4.77008725e-05
Iter: 1281 loss: 4.76973219e-05
Iter: 1282 loss: 4.76953137e-05
Iter: 1283 loss: 4.77011781e-05
Iter: 1284 loss: 4.76948e-05
Iter: 1285 loss: 4.76929781e-05
Iter: 1286 loss: 4.76978e-05
Iter: 1287 loss: 4.76924979e-05
Iter: 1288 loss: 4.76910755e-05
Iter: 1289 loss: 4.77024805e-05
Iter: 1290 loss: 4.76908972e-05
Iter: 1291 loss: 4.76897803e-05
Iter: 1292 loss: 4.77046269e-05
Iter: 1293 loss: 4.76897621e-05
Iter: 1294 loss: 4.768902e-05
Iter: 1295 loss: 4.76876594e-05
Iter: 1296 loss: 4.77126523e-05
Iter: 1297 loss: 4.76876594e-05
Iter: 1298 loss: 4.76860223e-05
Iter: 1299 loss: 4.76888854e-05
Iter: 1300 loss: 4.76851346e-05
Iter: 1301 loss: 4.76835667e-05
Iter: 1302 loss: 4.76866517e-05
Iter: 1303 loss: 4.76828172e-05
Iter: 1304 loss: 4.76810019e-05
Iter: 1305 loss: 4.76893911e-05
Iter: 1306 loss: 4.76807545e-05
Iter: 1307 loss: 4.76790956e-05
Iter: 1308 loss: 4.76830755e-05
Iter: 1309 loss: 4.76786299e-05
Iter: 1310 loss: 4.76770947e-05
Iter: 1311 loss: 4.76828645e-05
Iter: 1312 loss: 4.76767236e-05
Iter: 1313 loss: 4.76751156e-05
Iter: 1314 loss: 4.76765854e-05
Iter: 1315 loss: 4.76743444e-05
Iter: 1316 loss: 4.7672529e-05
Iter: 1317 loss: 4.76787827e-05
Iter: 1318 loss: 4.76720925e-05
Iter: 1319 loss: 4.76704809e-05
Iter: 1320 loss: 4.76762143e-05
Iter: 1321 loss: 4.76702189e-05
Iter: 1322 loss: 4.76689092e-05
Iter: 1323 loss: 4.76745918e-05
Iter: 1324 loss: 4.76684218e-05
Iter: 1325 loss: 4.76675923e-05
Iter: 1326 loss: 4.76676141e-05
Iter: 1327 loss: 4.76670248e-05
Iter: 1328 loss: 4.76657951e-05
Iter: 1329 loss: 4.76915448e-05
Iter: 1330 loss: 4.76657915e-05
Iter: 1331 loss: 4.76644564e-05
Iter: 1332 loss: 4.76656e-05
Iter: 1333 loss: 4.76635505e-05
Iter: 1334 loss: 4.76621717e-05
Iter: 1335 loss: 4.76661226e-05
Iter: 1336 loss: 4.76615751e-05
Iter: 1337 loss: 4.76600544e-05
Iter: 1338 loss: 4.76643982e-05
Iter: 1339 loss: 4.76596106e-05
Iter: 1340 loss: 4.76582281e-05
Iter: 1341 loss: 4.76647219e-05
Iter: 1342 loss: 4.76578316e-05
Iter: 1343 loss: 4.76565328e-05
Iter: 1344 loss: 4.76589921e-05
Iter: 1345 loss: 4.76559981e-05
Iter: 1346 loss: 4.76545538e-05
Iter: 1347 loss: 4.76580353e-05
Iter: 1348 loss: 4.7653979e-05
Iter: 1349 loss: 4.76525638e-05
Iter: 1350 loss: 4.76564455e-05
Iter: 1351 loss: 4.76521564e-05
Iter: 1352 loss: 4.76509449e-05
Iter: 1353 loss: 4.76559726e-05
Iter: 1354 loss: 4.76506029e-05
Iter: 1355 loss: 4.76494206e-05
Iter: 1356 loss: 4.76527966e-05
Iter: 1357 loss: 4.76491041e-05
Iter: 1358 loss: 4.76484747e-05
Iter: 1359 loss: 4.76483692e-05
Iter: 1360 loss: 4.76478708e-05
Iter: 1361 loss: 4.76469068e-05
Iter: 1362 loss: 4.76652567e-05
Iter: 1363 loss: 4.76468085e-05
Iter: 1364 loss: 4.76457571e-05
Iter: 1365 loss: 4.76466848e-05
Iter: 1366 loss: 4.76450768e-05
Iter: 1367 loss: 4.76436617e-05
Iter: 1368 loss: 4.76456407e-05
Iter: 1369 loss: 4.76429414e-05
Iter: 1370 loss: 4.76415698e-05
Iter: 1371 loss: 4.76491368e-05
Iter: 1372 loss: 4.76413406e-05
Iter: 1373 loss: 4.7640202e-05
Iter: 1374 loss: 4.76434434e-05
Iter: 1375 loss: 4.76398345e-05
Iter: 1376 loss: 4.76385758e-05
Iter: 1377 loss: 4.76422356e-05
Iter: 1378 loss: 4.76381792e-05
Iter: 1379 loss: 4.76368223e-05
Iter: 1380 loss: 4.76387577e-05
Iter: 1381 loss: 4.76363e-05
Iter: 1382 loss: 4.76351233e-05
Iter: 1383 loss: 4.76401474e-05
Iter: 1384 loss: 4.76348287e-05
Iter: 1385 loss: 4.76337518e-05
Iter: 1386 loss: 4.76361e-05
Iter: 1387 loss: 4.76333262e-05
Iter: 1388 loss: 4.76321729e-05
Iter: 1389 loss: 4.76377791e-05
Iter: 1390 loss: 4.76320347e-05
Iter: 1391 loss: 4.76314817e-05
Iter: 1392 loss: 4.76315254e-05
Iter: 1393 loss: 4.76308778e-05
Iter: 1394 loss: 4.76300338e-05
Iter: 1395 loss: 4.76484602e-05
Iter: 1396 loss: 4.76299938e-05
Iter: 1397 loss: 4.76290152e-05
Iter: 1398 loss: 4.76301357e-05
Iter: 1399 loss: 4.76284258e-05
Iter: 1400 loss: 4.76273053e-05
Iter: 1401 loss: 4.76293353e-05
Iter: 1402 loss: 4.76268215e-05
Iter: 1403 loss: 4.76256755e-05
Iter: 1404 loss: 4.76299356e-05
Iter: 1405 loss: 4.76252826e-05
Iter: 1406 loss: 4.76242785e-05
Iter: 1407 loss: 4.76279929e-05
Iter: 1408 loss: 4.76241476e-05
Iter: 1409 loss: 4.7622998e-05
Iter: 1410 loss: 4.76255555e-05
Iter: 1411 loss: 4.76226924e-05
Iter: 1412 loss: 4.76215e-05
Iter: 1413 loss: 4.76242021e-05
Iter: 1414 loss: 4.7621128e-05
Iter: 1415 loss: 4.762e-05
Iter: 1416 loss: 4.76226705e-05
Iter: 1417 loss: 4.76195855e-05
Iter: 1418 loss: 4.76185742e-05
Iter: 1419 loss: 4.76221976e-05
Iter: 1420 loss: 4.76182577e-05
Iter: 1421 loss: 4.76173591e-05
Iter: 1422 loss: 4.76206333e-05
Iter: 1423 loss: 4.76170899e-05
Iter: 1424 loss: 4.76167297e-05
Iter: 1425 loss: 4.7616486e-05
Iter: 1426 loss: 4.76160349e-05
Iter: 1427 loss: 4.76152418e-05
Iter: 1428 loss: 4.76346177e-05
Iter: 1429 loss: 4.76152563e-05
Iter: 1430 loss: 4.76143396e-05
Iter: 1431 loss: 4.7615591e-05
Iter: 1432 loss: 4.76138594e-05
Iter: 1433 loss: 4.76128771e-05
Iter: 1434 loss: 4.76147834e-05
Iter: 1435 loss: 4.76126152e-05
Iter: 1436 loss: 4.76114801e-05
Iter: 1437 loss: 4.76141577e-05
Iter: 1438 loss: 4.76112145e-05
Iter: 1439 loss: 4.76103087e-05
Iter: 1440 loss: 4.76140631e-05
Iter: 1441 loss: 4.76099958e-05
Iter: 1442 loss: 4.76091627e-05
Iter: 1443 loss: 4.76116184e-05
Iter: 1444 loss: 4.76088426e-05
Iter: 1445 loss: 4.76079585e-05
Iter: 1446 loss: 4.76098e-05
Iter: 1447 loss: 4.76074965e-05
Iter: 1448 loss: 4.76065834e-05
Iter: 1449 loss: 4.76097048e-05
Iter: 1450 loss: 4.76063651e-05
Iter: 1451 loss: 4.76055538e-05
Iter: 1452 loss: 4.76072091e-05
Iter: 1453 loss: 4.76050882e-05
Iter: 1454 loss: 4.76041459e-05
Iter: 1455 loss: 4.76084351e-05
Iter: 1456 loss: 4.7604e-05
Iter: 1457 loss: 4.76035566e-05
Iter: 1458 loss: 4.76035493e-05
Iter: 1459 loss: 4.76029818e-05
Iter: 1460 loss: 4.76023706e-05
Iter: 1461 loss: 4.7602407e-05
Iter: 1462 loss: 4.76015921e-05
Iter: 1463 loss: 4.76025489e-05
Iter: 1464 loss: 4.76012574e-05
Iter: 1465 loss: 4.7600377e-05
Iter: 1466 loss: 4.76012356e-05
Iter: 1467 loss: 4.75999332e-05
Iter: 1468 loss: 4.759898e-05
Iter: 1469 loss: 4.76027635e-05
Iter: 1470 loss: 4.75987108e-05
Iter: 1471 loss: 4.75980742e-05
Iter: 1472 loss: 4.76004425e-05
Iter: 1473 loss: 4.75978e-05
Iter: 1474 loss: 4.75970082e-05
Iter: 1475 loss: 4.75992019e-05
Iter: 1476 loss: 4.75966808e-05
Iter: 1477 loss: 4.75957058e-05
Iter: 1478 loss: 4.75978886e-05
Iter: 1479 loss: 4.75953639e-05
Iter: 1480 loss: 4.75945562e-05
Iter: 1481 loss: 4.75974375e-05
Iter: 1482 loss: 4.75943816e-05
Iter: 1483 loss: 4.7593614e-05
Iter: 1484 loss: 4.75948254e-05
Iter: 1485 loss: 4.75931665e-05
Iter: 1486 loss: 4.75924026e-05
Iter: 1487 loss: 4.75957095e-05
Iter: 1488 loss: 4.75921115e-05
Iter: 1489 loss: 4.75916386e-05
Iter: 1490 loss: 4.75916167e-05
Iter: 1491 loss: 4.75911584e-05
Iter: 1492 loss: 4.75908892e-05
Iter: 1493 loss: 4.759066e-05
Iter: 1494 loss: 4.75899942e-05
Iter: 1495 loss: 4.75896e-05
Iter: 1496 loss: 4.75894849e-05
Iter: 1497 loss: 4.7588539e-05
Iter: 1498 loss: 4.75909219e-05
Iter: 1499 loss: 4.75881898e-05
Iter: 1500 loss: 4.75872876e-05
Iter: 1501 loss: 4.75898e-05
Iter: 1502 loss: 4.75870365e-05
Iter: 1503 loss: 4.75861088e-05
Iter: 1504 loss: 4.75884299e-05
Iter: 1505 loss: 4.75858506e-05
Iter: 1506 loss: 4.75850175e-05
Iter: 1507 loss: 4.75881607e-05
Iter: 1508 loss: 4.75847337e-05
Iter: 1509 loss: 4.7583846e-05
Iter: 1510 loss: 4.75862471e-05
Iter: 1511 loss: 4.75836096e-05
Iter: 1512 loss: 4.75828201e-05
Iter: 1513 loss: 4.75848137e-05
Iter: 1514 loss: 4.75825327e-05
Iter: 1515 loss: 4.75817142e-05
Iter: 1516 loss: 4.75830238e-05
Iter: 1517 loss: 4.75813504e-05
Iter: 1518 loss: 4.75804336e-05
Iter: 1519 loss: 4.75849447e-05
Iter: 1520 loss: 4.7580168e-05
Iter: 1521 loss: 4.75798261e-05
Iter: 1522 loss: 4.75797351e-05
Iter: 1523 loss: 4.75791785e-05
Iter: 1524 loss: 4.75792403e-05
Iter: 1525 loss: 4.75788838e-05
Iter: 1526 loss: 4.7578229e-05
Iter: 1527 loss: 4.75782035e-05
Iter: 1528 loss: 4.75777924e-05
Iter: 1529 loss: 4.75769921e-05
Iter: 1530 loss: 4.75779743e-05
Iter: 1531 loss: 4.75766574e-05
Iter: 1532 loss: 4.75756642e-05
Iter: 1533 loss: 4.75798188e-05
Iter: 1534 loss: 4.75755514e-05
Iter: 1535 loss: 4.75748129e-05
Iter: 1536 loss: 4.75756788e-05
Iter: 1537 loss: 4.7574511e-05
Iter: 1538 loss: 4.75736742e-05
Iter: 1539 loss: 4.75787419e-05
Iter: 1540 loss: 4.75735978e-05
Iter: 1541 loss: 4.75727211e-05
Iter: 1542 loss: 4.75741908e-05
Iter: 1543 loss: 4.75725174e-05
Iter: 1544 loss: 4.75718334e-05
Iter: 1545 loss: 4.75737e-05
Iter: 1546 loss: 4.75715497e-05
Iter: 1547 loss: 4.7570782e-05
Iter: 1548 loss: 4.75721972e-05
Iter: 1549 loss: 4.75705092e-05
Iter: 1550 loss: 4.75699053e-05
Iter: 1551 loss: 4.7573576e-05
Iter: 1552 loss: 4.75697416e-05
Iter: 1553 loss: 4.75693305e-05
Iter: 1554 loss: 4.75754423e-05
Iter: 1555 loss: 4.75693232e-05
Iter: 1556 loss: 4.75688903e-05
Iter: 1557 loss: 4.75693523e-05
Iter: 1558 loss: 4.75686393e-05
Iter: 1559 loss: 4.75682027e-05
Iter: 1560 loss: 4.75678462e-05
Iter: 1561 loss: 4.75676716e-05
Iter: 1562 loss: 4.75669367e-05
Iter: 1563 loss: 4.75686029e-05
Iter: 1564 loss: 4.75667293e-05
Iter: 1565 loss: 4.75661182e-05
Iter: 1566 loss: 4.75682536e-05
Iter: 1567 loss: 4.75659035e-05
Iter: 1568 loss: 4.75652414e-05
Iter: 1569 loss: 4.75663146e-05
Iter: 1570 loss: 4.75649285e-05
Iter: 1571 loss: 4.75641864e-05
Iter: 1572 loss: 4.75671113e-05
Iter: 1573 loss: 4.75641427e-05
Iter: 1574 loss: 4.75634588e-05
Iter: 1575 loss: 4.75659945e-05
Iter: 1576 loss: 4.75633497e-05
Iter: 1577 loss: 4.75627021e-05
Iter: 1578 loss: 4.75633242e-05
Iter: 1579 loss: 4.75625493e-05
Iter: 1580 loss: 4.75617126e-05
Iter: 1581 loss: 4.75638044e-05
Iter: 1582 loss: 4.75615961e-05
Iter: 1583 loss: 4.75610796e-05
Iter: 1584 loss: 4.75633715e-05
Iter: 1585 loss: 4.75609268e-05
Iter: 1586 loss: 4.75605593e-05
Iter: 1587 loss: 4.75652705e-05
Iter: 1588 loss: 4.75604938e-05
Iter: 1589 loss: 4.75600864e-05
Iter: 1590 loss: 4.75612251e-05
Iter: 1591 loss: 4.75600027e-05
Iter: 1592 loss: 4.75596753e-05
Iter: 1593 loss: 4.75590205e-05
Iter: 1594 loss: 4.75590932e-05
Iter: 1595 loss: 4.75585221e-05
Iter: 1596 loss: 4.75594607e-05
Iter: 1597 loss: 4.75581764e-05
Iter: 1598 loss: 4.75576162e-05
Iter: 1599 loss: 4.75605666e-05
Iter: 1600 loss: 4.75574234e-05
Iter: 1601 loss: 4.75569468e-05
Iter: 1602 loss: 4.7557478e-05
Iter: 1603 loss: 4.75565539e-05
Iter: 1604 loss: 4.75560119e-05
Iter: 1605 loss: 4.75587331e-05
Iter: 1606 loss: 4.75559136e-05
Iter: 1607 loss: 4.75552697e-05
Iter: 1608 loss: 4.75569759e-05
Iter: 1609 loss: 4.75551315e-05
Iter: 1610 loss: 4.75545094e-05
Iter: 1611 loss: 4.75561465e-05
Iter: 1612 loss: 4.75542765e-05
Iter: 1613 loss: 4.75537672e-05
Iter: 1614 loss: 4.75545094e-05
Iter: 1615 loss: 4.7553418e-05
Iter: 1616 loss: 4.75529669e-05
Iter: 1617 loss: 4.75562047e-05
Iter: 1618 loss: 4.75527413e-05
Iter: 1619 loss: 4.75522829e-05
Iter: 1620 loss: 4.75553607e-05
Iter: 1621 loss: 4.75522902e-05
Iter: 1622 loss: 4.75518464e-05
Iter: 1623 loss: 4.75548331e-05
Iter: 1624 loss: 4.75517372e-05
Iter: 1625 loss: 4.75515189e-05
Iter: 1626 loss: 4.75510533e-05
Iter: 1627 loss: 4.75617308e-05
Iter: 1628 loss: 4.75509514e-05
Iter: 1629 loss: 4.75503257e-05
Iter: 1630 loss: 4.75516499e-05
Iter: 1631 loss: 4.75501438e-05
Iter: 1632 loss: 4.75494744e-05
Iter: 1633 loss: 4.755181e-05
Iter: 1634 loss: 4.75494344e-05
Iter: 1635 loss: 4.75488087e-05
Iter: 1636 loss: 4.7549358e-05
Iter: 1637 loss: 4.75486e-05
Iter: 1638 loss: 4.75478264e-05
Iter: 1639 loss: 4.75502166e-05
Iter: 1640 loss: 4.75477136e-05
Iter: 1641 loss: 4.75469933e-05
Iter: 1642 loss: 4.75497909e-05
Iter: 1643 loss: 4.75468187e-05
Iter: 1644 loss: 4.7546393e-05
Iter: 1645 loss: 4.75475827e-05
Iter: 1646 loss: 4.75461857e-05
Iter: 1647 loss: 4.75456764e-05
Iter: 1648 loss: 4.7546484e-05
Iter: 1649 loss: 4.75453235e-05
Iter: 1650 loss: 4.75448e-05
Iter: 1651 loss: 4.7547459e-05
Iter: 1652 loss: 4.75446432e-05
Iter: 1653 loss: 4.75442757e-05
Iter: 1654 loss: 4.7547037e-05
Iter: 1655 loss: 4.75441739e-05
Iter: 1656 loss: 4.75436755e-05
Iter: 1657 loss: 4.75475535e-05
Iter: 1658 loss: 4.754361e-05
Iter: 1659 loss: 4.75434281e-05
Iter: 1660 loss: 4.7542937e-05
Iter: 1661 loss: 4.75528286e-05
Iter: 1662 loss: 4.7542926e-05
Iter: 1663 loss: 4.75423658e-05
Iter: 1664 loss: 4.75441047e-05
Iter: 1665 loss: 4.7542133e-05
Iter: 1666 loss: 4.75415218e-05
Iter: 1667 loss: 4.75432462e-05
Iter: 1668 loss: 4.75415509e-05
Iter: 1669 loss: 4.75408378e-05
Iter: 1670 loss: 4.75412089e-05
Iter: 1671 loss: 4.75406341e-05
Iter: 1672 loss: 4.75400266e-05
Iter: 1673 loss: 4.75436318e-05
Iter: 1674 loss: 4.75398556e-05
Iter: 1675 loss: 4.75393208e-05
Iter: 1676 loss: 4.75407942e-05
Iter: 1677 loss: 4.75392517e-05
Iter: 1678 loss: 4.75386842e-05
Iter: 1679 loss: 4.75399393e-05
Iter: 1680 loss: 4.75385496e-05
Iter: 1681 loss: 4.75380148e-05
Iter: 1682 loss: 4.75385859e-05
Iter: 1683 loss: 4.75377819e-05
Iter: 1684 loss: 4.75372e-05
Iter: 1685 loss: 4.75403e-05
Iter: 1686 loss: 4.75372362e-05
Iter: 1687 loss: 4.75367124e-05
Iter: 1688 loss: 4.75385059e-05
Iter: 1689 loss: 4.75367415e-05
Iter: 1690 loss: 4.7536174e-05
Iter: 1691 loss: 4.7536294e-05
Iter: 1692 loss: 4.75359775e-05
Iter: 1693 loss: 4.75356e-05
Iter: 1694 loss: 4.7542766e-05
Iter: 1695 loss: 4.75356246e-05
Iter: 1696 loss: 4.75351662e-05
Iter: 1697 loss: 4.75363086e-05
Iter: 1698 loss: 4.7535068e-05
Iter: 1699 loss: 4.75346205e-05
Iter: 1700 loss: 4.75350898e-05
Iter: 1701 loss: 4.75343732e-05
Iter: 1702 loss: 4.7533933e-05
Iter: 1703 loss: 4.75352026e-05
Iter: 1704 loss: 4.75338238e-05
Iter: 1705 loss: 4.75332054e-05
Iter: 1706 loss: 4.75346969e-05
Iter: 1707 loss: 4.75331144e-05
Iter: 1708 loss: 4.75326342e-05
Iter: 1709 loss: 4.75342822e-05
Iter: 1710 loss: 4.7532485e-05
Iter: 1711 loss: 4.75320776e-05
Iter: 1712 loss: 4.75335328e-05
Iter: 1713 loss: 4.75318411e-05
Iter: 1714 loss: 4.7531481e-05
Iter: 1715 loss: 4.75324123e-05
Iter: 1716 loss: 4.75312518e-05
Iter: 1717 loss: 4.75309062e-05
Iter: 1718 loss: 4.75320885e-05
Iter: 1719 loss: 4.75307679e-05
Iter: 1720 loss: 4.75304187e-05
Iter: 1721 loss: 4.75321576e-05
Iter: 1722 loss: 4.75303968e-05
Iter: 1723 loss: 4.75300512e-05
Iter: 1724 loss: 4.75299894e-05
Iter: 1725 loss: 4.75298948e-05
Iter: 1726 loss: 4.75294401e-05
Iter: 1727 loss: 4.7535148e-05
Iter: 1728 loss: 4.75295165e-05
Iter: 1729 loss: 4.75290981e-05
Iter: 1730 loss: 4.75299639e-05
Iter: 1731 loss: 4.75289125e-05
Iter: 1732 loss: 4.75284542e-05
Iter: 1733 loss: 4.75296401e-05
Iter: 1734 loss: 4.75283523e-05
Iter: 1735 loss: 4.75278757e-05
Iter: 1736 loss: 4.7529e-05
Iter: 1737 loss: 4.75277266e-05
Iter: 1738 loss: 4.75273519e-05
Iter: 1739 loss: 4.75287561e-05
Iter: 1740 loss: 4.75271736e-05
Iter: 1741 loss: 4.75268389e-05
Iter: 1742 loss: 4.75277266e-05
Iter: 1743 loss: 4.75266897e-05
Iter: 1744 loss: 4.75262423e-05
Iter: 1745 loss: 4.75281886e-05
Iter: 1746 loss: 4.75261768e-05
Iter: 1747 loss: 4.75258094e-05
Iter: 1748 loss: 4.75261841e-05
Iter: 1749 loss: 4.75255474e-05
Iter: 1750 loss: 4.752526e-05
Iter: 1751 loss: 4.75267916e-05
Iter: 1752 loss: 4.7525049e-05
Iter: 1753 loss: 4.75247325e-05
Iter: 1754 loss: 4.75260931e-05
Iter: 1755 loss: 4.75246925e-05
Iter: 1756 loss: 4.75244778e-05
Iter: 1757 loss: 4.75244415e-05
Iter: 1758 loss: 4.75243214e-05
Iter: 1759 loss: 4.75240158e-05
Iter: 1760 loss: 4.7531903e-05
Iter: 1761 loss: 4.75239503e-05
Iter: 1762 loss: 4.75236884e-05
Iter: 1763 loss: 4.75238558e-05
Iter: 1764 loss: 4.75234156e-05
Iter: 1765 loss: 4.75231172e-05
Iter: 1766 loss: 4.75244669e-05
Iter: 1767 loss: 4.75230554e-05
Iter: 1768 loss: 4.75227207e-05
Iter: 1769 loss: 4.75232227e-05
Iter: 1770 loss: 4.75224588e-05
Iter: 1771 loss: 4.75221459e-05
Iter: 1772 loss: 4.75233901e-05
Iter: 1773 loss: 4.75219567e-05
Iter: 1774 loss: 4.7521622e-05
Iter: 1775 loss: 4.75228808e-05
Iter: 1776 loss: 4.75215857e-05
Iter: 1777 loss: 4.75211709e-05
Iter: 1778 loss: 4.75219931e-05
Iter: 1779 loss: 4.7521e-05
Iter: 1780 loss: 4.75207416e-05
Iter: 1781 loss: 4.75215129e-05
Iter: 1782 loss: 4.75204215e-05
Iter: 1783 loss: 4.75200868e-05
Iter: 1784 loss: 4.75212655e-05
Iter: 1785 loss: 4.75199558e-05
Iter: 1786 loss: 4.75196539e-05
Iter: 1787 loss: 4.75214692e-05
Iter: 1788 loss: 4.75196575e-05
Iter: 1789 loss: 4.75194902e-05
Iter: 1790 loss: 4.75194538e-05
Iter: 1791 loss: 4.7519221e-05
Iter: 1792 loss: 4.75189809e-05
Iter: 1793 loss: 4.75190063e-05
Iter: 1794 loss: 4.7518668e-05
Iter: 1795 loss: 4.75189372e-05
Iter: 1796 loss: 4.75185807e-05
Iter: 1797 loss: 4.75181478e-05
Iter: 1798 loss: 4.75189736e-05
Iter: 1799 loss: 4.75180059e-05
Iter: 1800 loss: 4.7517744e-05
Iter: 1801 loss: 4.75187771e-05
Iter: 1802 loss: 4.75176457e-05
Iter: 1803 loss: 4.75172237e-05
Iter: 1804 loss: 4.75179368e-05
Iter: 1805 loss: 4.75171546e-05
Iter: 1806 loss: 4.75167471e-05
Iter: 1807 loss: 4.75182605e-05
Iter: 1808 loss: 4.75167544e-05
Iter: 1809 loss: 4.75163979e-05
Iter: 1810 loss: 4.75169873e-05
Iter: 1811 loss: 4.75162924e-05
Iter: 1812 loss: 4.75159504e-05
Iter: 1813 loss: 4.75168381e-05
Iter: 1814 loss: 4.75159104e-05
Iter: 1815 loss: 4.75155321e-05
Iter: 1816 loss: 4.75164e-05
Iter: 1817 loss: 4.75154666e-05
Iter: 1818 loss: 4.75152556e-05
Iter: 1819 loss: 4.75168272e-05
Iter: 1820 loss: 4.7515161e-05
Iter: 1821 loss: 4.75149536e-05
Iter: 1822 loss: 4.751499e-05
Iter: 1823 loss: 4.7514819e-05
Iter: 1824 loss: 4.75146298e-05
Iter: 1825 loss: 4.75145498e-05
Iter: 1826 loss: 4.75144479e-05
Iter: 1827 loss: 4.75142479e-05
Iter: 1828 loss: 4.75142515e-05
Iter: 1829 loss: 4.75138877e-05
Iter: 1830 loss: 4.75150664e-05
Iter: 1831 loss: 4.75138295e-05
Iter: 1832 loss: 4.75135894e-05
Iter: 1833 loss: 4.75142915e-05
Iter: 1834 loss: 4.75134511e-05
Iter: 1835 loss: 4.75130691e-05
Iter: 1836 loss: 4.75137349e-05
Iter: 1837 loss: 4.75129455e-05
Iter: 1838 loss: 4.75126799e-05
Iter: 1839 loss: 4.7514055e-05
Iter: 1840 loss: 4.75125926e-05
Iter: 1841 loss: 4.75123816e-05
Iter: 1842 loss: 4.75128218e-05
Iter: 1843 loss: 4.75122652e-05
Iter: 1844 loss: 4.75119705e-05
Iter: 1845 loss: 4.7512578e-05
Iter: 1846 loss: 4.75118504e-05
Iter: 1847 loss: 4.75114357e-05
Iter: 1848 loss: 4.75124616e-05
Iter: 1849 loss: 4.75114066e-05
Iter: 1850 loss: 4.75110901e-05
Iter: 1851 loss: 4.75123234e-05
Iter: 1852 loss: 4.75110864e-05
Iter: 1853 loss: 4.75109482e-05
Iter: 1854 loss: 4.75109737e-05
Iter: 1855 loss: 4.75107954e-05
Iter: 1856 loss: 4.75107e-05
Iter: 1857 loss: 4.75106026e-05
Iter: 1858 loss: 4.75104898e-05
Iter: 1859 loss: 4.75102861e-05
Iter: 1860 loss: 4.75103152e-05
Iter: 1861 loss: 4.75099587e-05
Iter: 1862 loss: 4.75108682e-05
Iter: 1863 loss: 4.75098641e-05
Iter: 1864 loss: 4.75095658e-05
Iter: 1865 loss: 4.7510388e-05
Iter: 1866 loss: 4.75095112e-05
Iter: 1867 loss: 4.75092165e-05
Iter: 1868 loss: 4.75095185e-05
Iter: 1869 loss: 4.75091074e-05
Iter: 1870 loss: 4.75088091e-05
Iter: 1871 loss: 4.75104825e-05
Iter: 1872 loss: 4.75087654e-05
Iter: 1873 loss: 4.75085108e-05
Iter: 1874 loss: 4.75088382e-05
Iter: 1875 loss: 4.75083434e-05
Iter: 1876 loss: 4.75080597e-05
Iter: 1877 loss: 4.75090419e-05
Iter: 1878 loss: 4.75080233e-05
Iter: 1879 loss: 4.75075904e-05
Iter: 1880 loss: 4.75081688e-05
Iter: 1881 loss: 4.75076085e-05
Iter: 1882 loss: 4.75072229e-05
Iter: 1883 loss: 4.75086563e-05
Iter: 1884 loss: 4.75072375e-05
Iter: 1885 loss: 4.75070374e-05
Iter: 1886 loss: 4.75091583e-05
Iter: 1887 loss: 4.75070265e-05
Iter: 1888 loss: 4.75068809e-05
Iter: 1889 loss: 4.75069755e-05
Iter: 1890 loss: 4.75067864e-05
Iter: 1891 loss: 4.75065644e-05
Iter: 1892 loss: 4.75063935e-05
Iter: 1893 loss: 4.75063862e-05
Iter: 1894 loss: 4.75060078e-05
Iter: 1895 loss: 4.75067282e-05
Iter: 1896 loss: 4.75059642e-05
Iter: 1897 loss: 4.75058187e-05
Iter: 1898 loss: 4.75065972e-05
Iter: 1899 loss: 4.75055858e-05
Iter: 1900 loss: 4.75054039e-05
Iter: 1901 loss: 4.75058478e-05
Iter: 1902 loss: 4.75053057e-05
Iter: 1903 loss: 4.75049746e-05
Iter: 1904 loss: 4.75061606e-05
Iter: 1905 loss: 4.75048691e-05
Iter: 1906 loss: 4.75046618e-05
Iter: 1907 loss: 4.75053821e-05
Iter: 1908 loss: 4.7504589e-05
Iter: 1909 loss: 4.75043489e-05
Iter: 1910 loss: 4.75048801e-05
Iter: 1911 loss: 4.75042689e-05
Iter: 1912 loss: 4.75039924e-05
Iter: 1913 loss: 4.75048037e-05
Iter: 1914 loss: 4.75038541e-05
Iter: 1915 loss: 4.75036177e-05
Iter: 1916 loss: 4.75047054e-05
Iter: 1917 loss: 4.75036431e-05
Iter: 1918 loss: 4.75033739e-05
Iter: 1919 loss: 4.75034249e-05
Iter: 1920 loss: 4.75033412e-05
Iter: 1921 loss: 4.75034467e-05
Iter: 1922 loss: 4.75032066e-05
Iter: 1923 loss: 4.75031047e-05
Iter: 1924 loss: 4.75029483e-05
Iter: 1925 loss: 4.75029e-05
Iter: 1926 loss: 4.75027846e-05
Iter: 1927 loss: 4.75031266e-05
Iter: 1928 loss: 4.75027045e-05
Iter: 1929 loss: 4.75024208e-05
Iter: 1930 loss: 4.75031411e-05
Iter: 1931 loss: 4.75023626e-05
Iter: 1932 loss: 4.7502057e-05
Iter: 1933 loss: 4.75026536e-05
Iter: 1934 loss: 4.75020424e-05
Iter: 1935 loss: 4.7501846e-05
Iter: 1936 loss: 4.75027409e-05
Iter: 1937 loss: 4.75017514e-05
Iter: 1938 loss: 4.7501635e-05
Iter: 1939 loss: 4.75021952e-05
Iter: 1940 loss: 4.75015368e-05
Iter: 1941 loss: 4.75013767e-05
Iter: 1942 loss: 4.75017259e-05
Iter: 1943 loss: 4.75011329e-05
Iter: 1944 loss: 4.7501082e-05
Iter: 1945 loss: 4.75016059e-05
Iter: 1946 loss: 4.75009838e-05
Iter: 1947 loss: 4.75007764e-05
Iter: 1948 loss: 4.75015368e-05
Iter: 1949 loss: 4.75007182e-05
Iter: 1950 loss: 4.7500529e-05
Iter: 1951 loss: 4.75006782e-05
Iter: 1952 loss: 4.75005072e-05
Iter: 1953 loss: 4.75007073e-05
Iter: 1954 loss: 4.75003471e-05
Iter: 1955 loss: 4.75002453e-05
Iter: 1956 loss: 4.7500238e-05
Iter: 1957 loss: 4.75001725e-05
Iter: 1958 loss: 4.74999797e-05
Iter: 1959 loss: 4.75000707e-05
Iter: 1960 loss: 4.74999179e-05
Iter: 1961 loss: 4.74996632e-05
Iter: 1962 loss: 4.75008383e-05
Iter: 1963 loss: 4.74996195e-05
Iter: 1964 loss: 4.74993358e-05
Iter: 1965 loss: 4.74995395e-05
Iter: 1966 loss: 4.7499303e-05
Iter: 1967 loss: 4.74991175e-05
Iter: 1968 loss: 4.74998742e-05
Iter: 1969 loss: 4.74990302e-05
Iter: 1970 loss: 4.74989101e-05
Iter: 1971 loss: 4.74992776e-05
Iter: 1972 loss: 4.749871e-05
Iter: 1973 loss: 4.74986227e-05
Iter: 1974 loss: 4.74992776e-05
Iter: 1975 loss: 4.74985172e-05
Iter: 1976 loss: 4.74983754e-05
Iter: 1977 loss: 4.749871e-05
Iter: 1978 loss: 4.74981862e-05
Iter: 1979 loss: 4.74980116e-05
Iter: 1980 loss: 4.74988701e-05
Iter: 1981 loss: 4.74980188e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2
+ date
Tue Oct 27 18:36:48 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb778c5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb779aa488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb779aabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb778fc048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb7785bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb7785bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77842b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb7782a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb778096a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb777b0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb777b0488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb7777a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb7772c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb7772c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77706b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb777062f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb777068c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77650840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb776502f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77650ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77644488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb776448c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb775b59d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77560840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77560400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb775897b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77544730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb774ed840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb774ed400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb77490488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb774901e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb774bd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb774bd620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb774bd730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb773da9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fcb773da2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0592974275
Iter: 2 loss: 1993.70459
Iter: 3 loss: 0.0592974164
Iter: 4 loss: 2351.27295
Iter: 5 loss: 1445.07275
Iter: 6 loss: 0.0592971593
Iter: 7 loss: 1891.14832
Iter: 8 loss: 0.0536295474
Iter: 9 loss: 0.0551257767
Iter: 10 loss: 0.0473036468
Iter: 11 loss: 0.0465705693
Iter: 12 loss: 3821.3064
Iter: 13 loss: 0.0505980328
Iter: 14 loss: 0.0450070128
Iter: 15 loss: 0.0387560055
Iter: 16 loss: 0.0387490056
Iter: 17 loss: 0.0347129032
Iter: 18 loss: 0.0344792157
Iter: 19 loss: 0.0280458145
Iter: 20 loss: 0.0896598548
Iter: 21 loss: 0.0277707539
Iter: 22 loss: 0.0263026729
Iter: 23 loss: 0.0249002893
Iter: 24 loss: 0.0247912854
Iter: 25 loss: 0.0233240724
Iter: 26 loss: 0.0522820652
Iter: 27 loss: 0.0232829191
Iter: 28 loss: 0.0217183121
Iter: 29 loss: 0.0314563364
Iter: 30 loss: 0.0213476904
Iter: 31 loss: 0.0195039157
Iter: 32 loss: 0.0477910712
Iter: 33 loss: 0.0193768553
Iter: 34 loss: 0.0177174211
Iter: 35 loss: 0.0387261957
Iter: 36 loss: 0.0176140945
Iter: 37 loss: 0.0162606984
Iter: 38 loss: 0.0310857072
Iter: 39 loss: 0.016135117
Iter: 40 loss: 0.0144906119
Iter: 41 loss: 0.0308726076
Iter: 42 loss: 0.0142913423
Iter: 43 loss: 0.0126640312
Iter: 44 loss: 0.0518135354
Iter: 45 loss: 0.0126341553
Iter: 46 loss: 0.0114266481
Iter: 47 loss: 0.183571905
Iter: 48 loss: 0.0114266155
Iter: 49 loss: 0.0105624069
Iter: 50 loss: 0.0169668049
Iter: 51 loss: 0.010457553
Iter: 52 loss: 0.0102037359
Iter: 53 loss: 0.0100663211
Iter: 54 loss: 0.00970638171
Iter: 55 loss: 0.0131178647
Iter: 56 loss: 0.00965545326
Iter: 57 loss: 0.00930754654
Iter: 58 loss: 0.0136984
Iter: 59 loss: 0.00927519333
Iter: 60 loss: 0.00895637739
Iter: 61 loss: 0.0101319272
Iter: 62 loss: 0.0088744536
Iter: 63 loss: 0.0085035786
Iter: 64 loss: 0.0110833347
Iter: 65 loss: 0.00847907551
Iter: 66 loss: 0.00799646229
Iter: 67 loss: 0.0194991417
Iter: 68 loss: 0.0079953419
Iter: 69 loss: 0.00768857636
Iter: 70 loss: 0.0102352155
Iter: 71 loss: 0.00768298
Iter: 72 loss: 0.00749630947
Iter: 73 loss: 0.00733157154
Iter: 74 loss: 0.00728327082
Iter: 75 loss: 0.00695579872
Iter: 76 loss: 0.00778908189
Iter: 77 loss: 0.00681452546
Iter: 78 loss: 0.00661237584
Iter: 79 loss: 0.00723958947
Iter: 80 loss: 0.00655044476
Iter: 81 loss: 0.00631589815
Iter: 82 loss: 0.00603472069
Iter: 83 loss: 0.0060052257
Iter: 84 loss: 0.00563611835
Iter: 85 loss: 0.00702196732
Iter: 86 loss: 0.00554192811
Iter: 87 loss: 0.00559590524
Iter: 88 loss: 0.00539896078
Iter: 89 loss: 0.00527426926
Iter: 90 loss: 0.00576684251
Iter: 91 loss: 0.00524703413
Iter: 92 loss: 0.00501938583
Iter: 93 loss: 0.00585667416
Iter: 94 loss: 0.0049564233
Iter: 95 loss: 0.00476453081
Iter: 96 loss: 0.00576269161
Iter: 97 loss: 0.0047418992
Iter: 98 loss: 0.00459032878
Iter: 99 loss: 0.00474019255
Iter: 100 loss: 0.00449830852
Iter: 101 loss: 0.00434932299
Iter: 102 loss: 0.00497919414
Iter: 103 loss: 0.00432576286
Iter: 104 loss: 0.00421165209
Iter: 105 loss: 0.00421732944
Iter: 106 loss: 0.00411487743
Iter: 107 loss: 0.00401774235
Iter: 108 loss: 0.00406416925
Iter: 109 loss: 0.00395429088
Iter: 110 loss: 0.00379163469
Iter: 111 loss: 0.00472669629
Iter: 112 loss: 0.00376600516
Iter: 113 loss: 0.00362211838
Iter: 114 loss: 0.00452325
Iter: 115 loss: 0.00360679394
Iter: 116 loss: 0.00352164288
Iter: 117 loss: 0.00359486858
Iter: 118 loss: 0.00346866902
Iter: 119 loss: 0.00337807951
Iter: 120 loss: 0.00338703115
Iter: 121 loss: 0.00330812018
Iter: 122 loss: 0.00320451846
Iter: 123 loss: 0.00435263477
Iter: 124 loss: 0.00320073171
Iter: 125 loss: 0.00312028313
Iter: 126 loss: 0.0041552675
Iter: 127 loss: 0.00311972387
Iter: 128 loss: 0.00306896842
Iter: 129 loss: 0.00300876191
Iter: 130 loss: 0.00300143356
Iter: 131 loss: 0.00293495
Iter: 132 loss: 0.00334736612
Iter: 133 loss: 0.00292873196
Iter: 134 loss: 0.00288533047
Iter: 135 loss: 0.00293916441
Iter: 136 loss: 0.00286230678
Iter: 137 loss: 0.00280943536
Iter: 138 loss: 0.00307866465
Iter: 139 loss: 0.00280231843
Iter: 140 loss: 0.00274939882
Iter: 141 loss: 0.002865894
Iter: 142 loss: 0.00272726
Iter: 143 loss: 0.00266046659
Iter: 144 loss: 0.00266301492
Iter: 145 loss: 0.00260813627
Iter: 146 loss: 0.00253003254
Iter: 147 loss: 0.00349080656
Iter: 148 loss: 0.0025280402
Iter: 149 loss: 0.00246972265
Iter: 150 loss: 0.00249774707
Iter: 151 loss: 0.00243150722
Iter: 152 loss: 0.00237362157
Iter: 153 loss: 0.00275218464
Iter: 154 loss: 0.00236602058
Iter: 155 loss: 0.0023245425
Iter: 156 loss: 0.00231368304
Iter: 157 loss: 0.00228745653
Iter: 158 loss: 0.0022238919
Iter: 159 loss: 0.00284133758
Iter: 160 loss: 0.00222084718
Iter: 161 loss: 0.00217626081
Iter: 162 loss: 0.00277808541
Iter: 163 loss: 0.00217618747
Iter: 164 loss: 0.00215300638
Iter: 165 loss: 0.00224215444
Iter: 166 loss: 0.0021467784
Iter: 167 loss: 0.00212214957
Iter: 168 loss: 0.0021393015
Iter: 169 loss: 0.00210699555
Iter: 170 loss: 0.00207857694
Iter: 171 loss: 0.00254958728
Iter: 172 loss: 0.00207846984
Iter: 173 loss: 0.00205822475
Iter: 174 loss: 0.00207446
Iter: 175 loss: 0.00204629824
Iter: 176 loss: 0.0020247777
Iter: 177 loss: 0.00198681047
Iter: 178 loss: 0.00198680349
Iter: 179 loss: 0.00195577345
Iter: 180 loss: 0.00197672774
Iter: 181 loss: 0.00193641498
Iter: 182 loss: 0.0018954043
Iter: 183 loss: 0.0019908566
Iter: 184 loss: 0.00187974307
Iter: 185 loss: 0.001852268
Iter: 186 loss: 0.00185121014
Iter: 187 loss: 0.00182711054
Iter: 188 loss: 0.00185251865
Iter: 189 loss: 0.00181303883
Iter: 190 loss: 0.0017863164
Iter: 191 loss: 0.00178540673
Iter: 192 loss: 0.00176512706
Iter: 193 loss: 0.00173563766
Iter: 194 loss: 0.00172727276
Iter: 195 loss: 0.00170871173
Iter: 196 loss: 0.00167688378
Iter: 197 loss: 0.00173091586
Iter: 198 loss: 0.00166269625
Iter: 199 loss: 0.00163142243
Iter: 200 loss: 0.00177231967
Iter: 201 loss: 0.00162475067
Iter: 202 loss: 0.00159949716
Iter: 203 loss: 0.0018063524
Iter: 204 loss: 0.00159838144
Iter: 205 loss: 0.00157661689
Iter: 206 loss: 0.0016913421
Iter: 207 loss: 0.0015729455
Iter: 208 loss: 0.00155567168
Iter: 209 loss: 0.00159412413
Iter: 210 loss: 0.00154941634
Iter: 211 loss: 0.00153332565
Iter: 212 loss: 0.00152877148
Iter: 213 loss: 0.00151868165
Iter: 214 loss: 0.00149895018
Iter: 215 loss: 0.00149089692
Iter: 216 loss: 0.00148051023
Iter: 217 loss: 0.00145892985
Iter: 218 loss: 0.00161214184
Iter: 219 loss: 0.00145639491
Iter: 220 loss: 0.00144133449
Iter: 221 loss: 0.00142122363
Iter: 222 loss: 0.00142006017
Iter: 223 loss: 0.00138996192
Iter: 224 loss: 0.00166973379
Iter: 225 loss: 0.00138853234
Iter: 226 loss: 0.00137046399
Iter: 227 loss: 0.00137021369
Iter: 228 loss: 0.00135793071
Iter: 229 loss: 0.00137098879
Iter: 230 loss: 0.00135103206
Iter: 231 loss: 0.00133442227
Iter: 232 loss: 0.00134849735
Iter: 233 loss: 0.0013246648
Iter: 234 loss: 0.00130319514
Iter: 235 loss: 0.00142034912
Iter: 236 loss: 0.00129951071
Iter: 237 loss: 0.00127464789
Iter: 238 loss: 0.00140103116
Iter: 239 loss: 0.00127097243
Iter: 240 loss: 0.00125751691
Iter: 241 loss: 0.00126098027
Iter: 242 loss: 0.00124755292
Iter: 243 loss: 0.00122764544
Iter: 244 loss: 0.0013430363
Iter: 245 loss: 0.00122532365
Iter: 246 loss: 0.0012082865
Iter: 247 loss: 0.0012412772
Iter: 248 loss: 0.00120091042
Iter: 249 loss: 0.00118179945
Iter: 250 loss: 0.00121176441
Iter: 251 loss: 0.00117288064
Iter: 252 loss: 0.00115720439
Iter: 253 loss: 0.00116949761
Iter: 254 loss: 0.00114758266
Iter: 255 loss: 0.00112447678
Iter: 256 loss: 0.00116249349
Iter: 257 loss: 0.00111372699
Iter: 258 loss: 0.00109070761
Iter: 259 loss: 0.00111405971
Iter: 260 loss: 0.00107756665
Iter: 261 loss: 0.00106258946
Iter: 262 loss: 0.00122360198
Iter: 263 loss: 0.00106235722
Iter: 264 loss: 0.00104539981
Iter: 265 loss: 0.00107109314
Iter: 266 loss: 0.00103723013
Iter: 267 loss: 0.0010215207
Iter: 268 loss: 0.00105960097
Iter: 269 loss: 0.00101582939
Iter: 270 loss: 0.00100547192
Iter: 271 loss: 0.00100547494
Iter: 272 loss: 0.000996273244
Iter: 273 loss: 0.001004196
Iter: 274 loss: 0.000990963541
Iter: 275 loss: 0.000984300161
Iter: 276 loss: 0.000976783806
Iter: 277 loss: 0.000975744857
Iter: 278 loss: 0.000964893319
Iter: 279 loss: 0.000963161
Iter: 280 loss: 0.000955663505
Iter: 281 loss: 0.000945679494
Iter: 282 loss: 0.000984584331
Iter: 283 loss: 0.000943170569
Iter: 284 loss: 0.000932162744
Iter: 285 loss: 0.000921538798
Iter: 286 loss: 0.000919069222
Iter: 287 loss: 0.000901228341
Iter: 288 loss: 0.000952732516
Iter: 289 loss: 0.000895788544
Iter: 290 loss: 0.000882629654
Iter: 291 loss: 0.00089649373
Iter: 292 loss: 0.000875374
Iter: 293 loss: 0.000861176173
Iter: 294 loss: 0.000933987147
Iter: 295 loss: 0.000858688436
Iter: 296 loss: 0.000845239148
Iter: 297 loss: 0.000859615684
Iter: 298 loss: 0.000837691594
Iter: 299 loss: 0.000824451388
Iter: 300 loss: 0.000903429813
Iter: 301 loss: 0.000822807429
Iter: 302 loss: 0.000811647857
Iter: 303 loss: 0.000828957127
Iter: 304 loss: 0.000806361495
Iter: 305 loss: 0.000806505
Iter: 306 loss: 0.000801351329
Iter: 307 loss: 0.000797709
Iter: 308 loss: 0.00079672935
Iter: 309 loss: 0.000794463791
Iter: 310 loss: 0.000784338277
Iter: 311 loss: 0.0007824559
Iter: 312 loss: 0.000775604916
Iter: 313 loss: 0.000778489222
Iter: 314 loss: 0.000768335303
Iter: 315 loss: 0.000763788
Iter: 316 loss: 0.000753227039
Iter: 317 loss: 0.000889956951
Iter: 318 loss: 0.000752441818
Iter: 319 loss: 0.000743110373
Iter: 320 loss: 0.000736963819
Iter: 321 loss: 0.000733434805
Iter: 322 loss: 0.000721303222
Iter: 323 loss: 0.000845540082
Iter: 324 loss: 0.000720957061
Iter: 325 loss: 0.000711284112
Iter: 326 loss: 0.000722670346
Iter: 327 loss: 0.000706038205
Iter: 328 loss: 0.000697700132
Iter: 329 loss: 0.000738855568
Iter: 330 loss: 0.000696251402
Iter: 331 loss: 0.000686878513
Iter: 332 loss: 0.000729748164
Iter: 333 loss: 0.000685202947
Iter: 334 loss: 0.000681241276
Iter: 335 loss: 0.000677377451
Iter: 336 loss: 0.000676487107
Iter: 337 loss: 0.000671960239
Iter: 338 loss: 0.000673125498
Iter: 339 loss: 0.00066872
Iter: 340 loss: 0.000662069477
Iter: 341 loss: 0.000710432883
Iter: 342 loss: 0.000661461963
Iter: 343 loss: 0.00065569143
Iter: 344 loss: 0.000664194289
Iter: 345 loss: 0.000652915041
Iter: 346 loss: 0.000646080822
Iter: 347 loss: 0.000643509557
Iter: 348 loss: 0.000639778329
Iter: 349 loss: 0.000634703785
Iter: 350 loss: 0.000634334749
Iter: 351 loss: 0.000628354261
Iter: 352 loss: 0.000629031623
Iter: 353 loss: 0.000623763772
Iter: 354 loss: 0.000617274432
Iter: 355 loss: 0.000646426925
Iter: 356 loss: 0.000616009
Iter: 357 loss: 0.000610423158
Iter: 358 loss: 0.000611462
Iter: 359 loss: 0.000606242684
Iter: 360 loss: 0.000598942745
Iter: 361 loss: 0.000662026112
Iter: 362 loss: 0.000598512357
Iter: 363 loss: 0.000593789038
Iter: 364 loss: 0.000613555661
Iter: 365 loss: 0.000592825236
Iter: 366 loss: 0.000589035568
Iter: 367 loss: 0.000589030329
Iter: 368 loss: 0.000586848066
Iter: 369 loss: 0.000586035778
Iter: 370 loss: 0.00058484904
Iter: 371 loss: 0.000581083703
Iter: 372 loss: 0.000582694891
Iter: 373 loss: 0.000578466337
Iter: 374 loss: 0.00057296193
Iter: 375 loss: 0.000569362659
Iter: 376 loss: 0.000567255658
Iter: 377 loss: 0.000558993197
Iter: 378 loss: 0.000586142414
Iter: 379 loss: 0.000556710525
Iter: 380 loss: 0.000550057099
Iter: 381 loss: 0.000566061935
Iter: 382 loss: 0.000547589152
Iter: 383 loss: 0.000543480506
Iter: 384 loss: 0.00054346
Iter: 385 loss: 0.000540133682
Iter: 386 loss: 0.000535839761
Iter: 387 loss: 0.000535537547
Iter: 388 loss: 0.000529910205
Iter: 389 loss: 0.000561894209
Iter: 390 loss: 0.000529119046
Iter: 391 loss: 0.000523991941
Iter: 392 loss: 0.000526834629
Iter: 393 loss: 0.000520592905
Iter: 394 loss: 0.000514848041
Iter: 395 loss: 0.000566132832
Iter: 396 loss: 0.000514589308
Iter: 397 loss: 0.000512240687
Iter: 398 loss: 0.00053223304
Iter: 399 loss: 0.000512089871
Iter: 400 loss: 0.000509862
Iter: 401 loss: 0.000512201746
Iter: 402 loss: 0.000508646888
Iter: 403 loss: 0.000505820615
Iter: 404 loss: 0.000505776377
Iter: 405 loss: 0.000503520423
Iter: 406 loss: 0.000499385758
Iter: 407 loss: 0.000504597323
Iter: 408 loss: 0.000497267582
Iter: 409 loss: 0.000493157189
Iter: 410 loss: 0.000499349786
Iter: 411 loss: 0.000491193146
Iter: 412 loss: 0.000486565288
Iter: 413 loss: 0.000487621146
Iter: 414 loss: 0.000483116164
Iter: 415 loss: 0.000478914357
Iter: 416 loss: 0.00054492295
Iter: 417 loss: 0.000478914124
Iter: 418 loss: 0.000475503301
Iter: 419 loss: 0.000478154281
Iter: 420 loss: 0.000473421416
Iter: 421 loss: 0.000469936931
Iter: 422 loss: 0.000470733328
Iter: 423 loss: 0.000467365724
Iter: 424 loss: 0.000462757627
Iter: 425 loss: 0.000486232981
Iter: 426 loss: 0.000461991818
Iter: 427 loss: 0.00045873021
Iter: 428 loss: 0.000508048222
Iter: 429 loss: 0.000458731374
Iter: 430 loss: 0.000456485723
Iter: 431 loss: 0.000458170107
Iter: 432 loss: 0.000455089932
Iter: 433 loss: 0.000452452106
Iter: 434 loss: 0.000470017869
Iter: 435 loss: 0.000452209613
Iter: 436 loss: 0.000450027524
Iter: 437 loss: 0.000446630351
Iter: 438 loss: 0.000446581544
Iter: 439 loss: 0.000442360295
Iter: 440 loss: 0.000460197829
Iter: 441 loss: 0.000441479409
Iter: 442 loss: 0.000438245246
Iter: 443 loss: 0.00043726369
Iter: 444 loss: 0.000435328373
Iter: 445 loss: 0.000430213695
Iter: 446 loss: 0.000437135983
Iter: 447 loss: 0.000427620631
Iter: 448 loss: 0.000424826459
Iter: 449 loss: 0.000424676458
Iter: 450 loss: 0.000422020385
Iter: 451 loss: 0.000423185818
Iter: 452 loss: 0.000420192722
Iter: 453 loss: 0.000416491384
Iter: 454 loss: 0.000415174232
Iter: 455 loss: 0.000413099682
Iter: 456 loss: 0.000407751213
Iter: 457 loss: 0.000423767313
Iter: 458 loss: 0.000406129519
Iter: 459 loss: 0.000403491664
Iter: 460 loss: 0.000403320766
Iter: 461 loss: 0.000401086698
Iter: 462 loss: 0.000414202281
Iter: 463 loss: 0.000400774705
Iter: 464 loss: 0.000399017124
Iter: 465 loss: 0.000402284903
Iter: 466 loss: 0.000398286327
Iter: 467 loss: 0.000395711599
Iter: 468 loss: 0.000394959759
Iter: 469 loss: 0.000393395079
Iter: 470 loss: 0.000390795642
Iter: 471 loss: 0.000400201738
Iter: 472 loss: 0.000390156521
Iter: 473 loss: 0.000387370761
Iter: 474 loss: 0.000385674823
Iter: 475 loss: 0.000384528073
Iter: 476 loss: 0.000380713434
Iter: 477 loss: 0.0003939702
Iter: 478 loss: 0.000379680831
Iter: 479 loss: 0.000376426207
Iter: 480 loss: 0.000385054736
Iter: 481 loss: 0.000375337462
Iter: 482 loss: 0.000371119619
Iter: 483 loss: 0.000411329762
Iter: 484 loss: 0.000370929
Iter: 485 loss: 0.000368585286
Iter: 486 loss: 0.000368263776
Iter: 487 loss: 0.000366620254
Iter: 488 loss: 0.000363788276
Iter: 489 loss: 0.000363867031
Iter: 490 loss: 0.000361537503
Iter: 491 loss: 0.000358538877
Iter: 492 loss: 0.000374681666
Iter: 493 loss: 0.000358102872
Iter: 494 loss: 0.000355763652
Iter: 495 loss: 0.000355756434
Iter: 496 loss: 0.000354028976
Iter: 497 loss: 0.000358562567
Iter: 498 loss: 0.000353456941
Iter: 499 loss: 0.000351612776
Iter: 500 loss: 0.000353975891
Iter: 501 loss: 0.000350656599
Iter: 502 loss: 0.000348862552
Iter: 503 loss: 0.00034788606
Iter: 504 loss: 0.000347092602
Iter: 505 loss: 0.000343768741
Iter: 506 loss: 0.000349058595
Iter: 507 loss: 0.000342212094
Iter: 508 loss: 0.000339243852
Iter: 509 loss: 0.000342495681
Iter: 510 loss: 0.000337610167
Iter: 511 loss: 0.00033404032
Iter: 512 loss: 0.000341741252
Iter: 513 loss: 0.000332654861
Iter: 514 loss: 0.000329972274
Iter: 515 loss: 0.000329963368
Iter: 516 loss: 0.000327734946
Iter: 517 loss: 0.000328194059
Iter: 518 loss: 0.000326084439
Iter: 519 loss: 0.000323931657
Iter: 520 loss: 0.000324817869
Iter: 521 loss: 0.000322433305
Iter: 522 loss: 0.00032028259
Iter: 523 loss: 0.000324367604
Iter: 524 loss: 0.000319379789
Iter: 525 loss: 0.000317587081
Iter: 526 loss: 0.00034234242
Iter: 527 loss: 0.000317577069
Iter: 528 loss: 0.000316133286
Iter: 529 loss: 0.000321252242
Iter: 530 loss: 0.000315768091
Iter: 531 loss: 0.00031420571
Iter: 532 loss: 0.000314989069
Iter: 533 loss: 0.000313152967
Iter: 534 loss: 0.000311335316
Iter: 535 loss: 0.000312850229
Iter: 536 loss: 0.00031025568
Iter: 537 loss: 0.000308156945
Iter: 538 loss: 0.000312236894
Iter: 539 loss: 0.000307278242
Iter: 540 loss: 0.000305021415
Iter: 541 loss: 0.000303881941
Iter: 542 loss: 0.000302816392
Iter: 543 loss: 0.000299916894
Iter: 544 loss: 0.000317278784
Iter: 545 loss: 0.000299551641
Iter: 546 loss: 0.00029738227
Iter: 547 loss: 0.000312216638
Iter: 548 loss: 0.00029715916
Iter: 549 loss: 0.000295095291
Iter: 550 loss: 0.000302436645
Iter: 551 loss: 0.000294573721
Iter: 552 loss: 0.000292763696
Iter: 553 loss: 0.000292657409
Iter: 554 loss: 0.000291271863
Iter: 555 loss: 0.00028946306
Iter: 556 loss: 0.000308232557
Iter: 557 loss: 0.000289413176
Iter: 558 loss: 0.000288340758
Iter: 559 loss: 0.000291410892
Iter: 560 loss: 0.000287997449
Iter: 561 loss: 0.000286774884
Iter: 562 loss: 0.000293570571
Iter: 563 loss: 0.00028660454
Iter: 564 loss: 0.00028545555
Iter: 565 loss: 0.000286103
Iter: 566 loss: 0.000284699054
Iter: 567 loss: 0.00028338618
Iter: 568 loss: 0.000284854788
Iter: 569 loss: 0.000282678026
Iter: 570 loss: 0.000281159242
Iter: 571 loss: 0.000282228051
Iter: 572 loss: 0.000280210457
Iter: 573 loss: 0.000278249208
Iter: 574 loss: 0.000278696418
Iter: 575 loss: 0.000276801758
Iter: 576 loss: 0.000274570368
Iter: 577 loss: 0.000281319313
Iter: 578 loss: 0.000273900863
Iter: 579 loss: 0.000271861732
Iter: 580 loss: 0.000287313625
Iter: 581 loss: 0.000271694968
Iter: 582 loss: 0.000269976794
Iter: 583 loss: 0.000278870692
Iter: 584 loss: 0.00026970543
Iter: 585 loss: 0.000268135394
Iter: 586 loss: 0.000267535914
Iter: 587 loss: 0.000266671384
Iter: 588 loss: 0.000264958304
Iter: 589 loss: 0.000285777613
Iter: 590 loss: 0.000264938077
Iter: 591 loss: 0.000263752852
Iter: 592 loss: 0.000266361923
Iter: 593 loss: 0.000263288559
Iter: 594 loss: 0.000262093614
Iter: 595 loss: 0.000271979021
Iter: 596 loss: 0.000262023183
Iter: 597 loss: 0.000261105481
Iter: 598 loss: 0.000261776906
Iter: 599 loss: 0.000260534143
Iter: 600 loss: 0.000259520195
Iter: 601 loss: 0.000260213623
Iter: 602 loss: 0.00025888806
Iter: 603 loss: 0.000257593958
Iter: 604 loss: 0.000257759821
Iter: 605 loss: 0.000256602769
Iter: 606 loss: 0.000254815095
Iter: 607 loss: 0.000256179745
Iter: 608 loss: 0.00025371954
Iter: 609 loss: 0.000251815276
Iter: 610 loss: 0.000256008323
Iter: 611 loss: 0.000251083
Iter: 612 loss: 0.00024933985
Iter: 613 loss: 0.000262307585
Iter: 614 loss: 0.000249192497
Iter: 615 loss: 0.000247794407
Iter: 616 loss: 0.000256999454
Iter: 617 loss: 0.000247649441
Iter: 618 loss: 0.000246419513
Iter: 619 loss: 0.000246647105
Iter: 620 loss: 0.000245495758
Iter: 621 loss: 0.000244222698
Iter: 622 loss: 0.000255043269
Iter: 623 loss: 0.000244151539
Iter: 624 loss: 0.000243077782
Iter: 625 loss: 0.000246518641
Iter: 626 loss: 0.000242764625
Iter: 627 loss: 0.000241884118
Iter: 628 loss: 0.000250690035
Iter: 629 loss: 0.000241857138
Iter: 630 loss: 0.000241209724
Iter: 631 loss: 0.000241604677
Iter: 632 loss: 0.000240790207
Iter: 633 loss: 0.000240019886
Iter: 634 loss: 0.000240546768
Iter: 635 loss: 0.000239539193
Iter: 636 loss: 0.000238530716
Iter: 637 loss: 0.000238845561
Iter: 638 loss: 0.000237808432
Iter: 639 loss: 0.000236493084
Iter: 640 loss: 0.000237647619
Iter: 641 loss: 0.000235719548
Iter: 642 loss: 0.000234248146
Iter: 643 loss: 0.000236474065
Iter: 644 loss: 0.000233546
Iter: 645 loss: 0.000232031118
Iter: 646 loss: 0.000241677975
Iter: 647 loss: 0.0002318552
Iter: 648 loss: 0.000230585574
Iter: 649 loss: 0.000238776265
Iter: 650 loss: 0.000230449543
Iter: 651 loss: 0.000229299781
Iter: 652 loss: 0.000230212638
Iter: 653 loss: 0.000228602
Iter: 654 loss: 0.000227531331
Iter: 655 loss: 0.00023416811
Iter: 656 loss: 0.000227407218
Iter: 657 loss: 0.000226449658
Iter: 658 loss: 0.000230246049
Iter: 659 loss: 0.000226225195
Iter: 660 loss: 0.000225484968
Iter: 661 loss: 0.000233006896
Iter: 662 loss: 0.000225464813
Iter: 663 loss: 0.000224890129
Iter: 664 loss: 0.000225135329
Iter: 665 loss: 0.000224494404
Iter: 666 loss: 0.000223744748
Iter: 667 loss: 0.000224074
Iter: 668 loss: 0.000223235402
Iter: 669 loss: 0.000222198461
Iter: 670 loss: 0.000222756076
Iter: 671 loss: 0.000221512106
Iter: 672 loss: 0.000220315633
Iter: 673 loss: 0.000222390678
Iter: 674 loss: 0.000219782669
Iter: 675 loss: 0.000218567089
Iter: 676 loss: 0.000219453374
Iter: 677 loss: 0.000217815759
Iter: 678 loss: 0.000216362387
Iter: 679 loss: 0.000223734649
Iter: 680 loss: 0.000216116983
Iter: 681 loss: 0.000214904489
Iter: 682 loss: 0.000224958625
Iter: 683 loss: 0.000214832689
Iter: 684 loss: 0.000213858468
Iter: 685 loss: 0.000215215259
Iter: 686 loss: 0.000213373132
Iter: 687 loss: 0.000212502695
Iter: 688 loss: 0.000216776592
Iter: 689 loss: 0.000212352868
Iter: 690 loss: 0.000211571256
Iter: 691 loss: 0.000215820415
Iter: 692 loss: 0.000211451887
Iter: 693 loss: 0.000210886807
Iter: 694 loss: 0.000216155589
Iter: 695 loss: 0.000210864266
Iter: 696 loss: 0.000210410624
Iter: 697 loss: 0.000210674305
Iter: 698 loss: 0.000210113882
Iter: 699 loss: 0.000209528342
Iter: 700 loss: 0.000209759251
Iter: 701 loss: 0.000209124308
Iter: 702 loss: 0.000208295125
Iter: 703 loss: 0.000208594953
Iter: 704 loss: 0.000207711768
Iter: 705 loss: 0.000206698285
Iter: 706 loss: 0.000208280369
Iter: 707 loss: 0.000206219964
Iter: 708 loss: 0.00020512905
Iter: 709 loss: 0.000206054072
Iter: 710 loss: 0.000204483367
Iter: 711 loss: 0.000203188334
Iter: 712 loss: 0.000207531368
Iter: 713 loss: 0.000202830881
Iter: 714 loss: 0.000201600807
Iter: 715 loss: 0.00021222682
Iter: 716 loss: 0.000201536866
Iter: 717 loss: 0.000200542621
Iter: 718 loss: 0.000201948162
Iter: 719 loss: 0.000200051538
Iter: 720 loss: 0.000199082831
Iter: 721 loss: 0.000202574272
Iter: 722 loss: 0.000198839567
Iter: 723 loss: 0.000198001784
Iter: 724 loss: 0.000206330209
Iter: 725 loss: 0.000197971982
Iter: 726 loss: 0.000197437039
Iter: 727 loss: 0.000201685965
Iter: 728 loss: 0.000197402696
Iter: 729 loss: 0.000196945854
Iter: 730 loss: 0.000197279413
Iter: 731 loss: 0.000196662237
Iter: 732 loss: 0.000196076173
Iter: 733 loss: 0.000196353765
Iter: 734 loss: 0.000195683708
Iter: 735 loss: 0.000194895634
Iter: 736 loss: 0.000195442233
Iter: 737 loss: 0.000194402062
Iter: 738 loss: 0.000193486907
Iter: 739 loss: 0.000194506822
Iter: 740 loss: 0.000192989
Iter: 741 loss: 0.000191869331
Iter: 742 loss: 0.00019280141
Iter: 743 loss: 0.000191203144
Iter: 744 loss: 0.000189961604
Iter: 745 loss: 0.0001942456
Iter: 746 loss: 0.000189628976
Iter: 747 loss: 0.00018855909
Iter: 748 loss: 0.000199513102
Iter: 749 loss: 0.000188529608
Iter: 750 loss: 0.000187676764
Iter: 751 loss: 0.000188914331
Iter: 752 loss: 0.00018726071
Iter: 753 loss: 0.000186378122
Iter: 754 loss: 0.000188016245
Iter: 755 loss: 0.000186002188
Iter: 756 loss: 0.000185258803
Iter: 757 loss: 0.000185259327
Iter: 758 loss: 0.000184803648
Iter: 759 loss: 0.000187780228
Iter: 760 loss: 0.000184756471
Iter: 761 loss: 0.000184345292
Iter: 762 loss: 0.000184862292
Iter: 763 loss: 0.000184131291
Iter: 764 loss: 0.000183632015
Iter: 765 loss: 0.000183789889
Iter: 766 loss: 0.000183279379
Iter: 767 loss: 0.000182616961
Iter: 768 loss: 0.000183323718
Iter: 769 loss: 0.000182251009
Iter: 770 loss: 0.000181489566
Iter: 771 loss: 0.000182118558
Iter: 772 loss: 0.000181034062
Iter: 773 loss: 0.000180031653
Iter: 774 loss: 0.000180957475
Iter: 775 loss: 0.000179454
Iter: 776 loss: 0.000178361966
Iter: 777 loss: 0.000181439915
Iter: 778 loss: 0.000178011251
Iter: 779 loss: 0.000177034031
Iter: 780 loss: 0.0001864777
Iter: 781 loss: 0.000177000155
Iter: 782 loss: 0.000176182395
Iter: 783 loss: 0.000177904891
Iter: 784 loss: 0.000175857087
Iter: 785 loss: 0.000175070862
Iter: 786 loss: 0.000175488531
Iter: 787 loss: 0.000174552406
Iter: 788 loss: 0.000173866778
Iter: 789 loss: 0.000173857421
Iter: 790 loss: 0.000173402135
Iter: 791 loss: 0.000175757101
Iter: 792 loss: 0.000173331282
Iter: 793 loss: 0.000172899847
Iter: 794 loss: 0.000173784734
Iter: 795 loss: 0.0001727239
Iter: 796 loss: 0.000172230328
Iter: 797 loss: 0.000172419153
Iter: 798 loss: 0.000171888561
Iter: 799 loss: 0.000171295032
Iter: 800 loss: 0.000171883526
Iter: 801 loss: 0.000170959131
Iter: 802 loss: 0.000170181884
Iter: 803 loss: 0.000170336032
Iter: 804 loss: 0.000169602572
Iter: 805 loss: 0.000168424769
Iter: 806 loss: 0.000170342915
Iter: 807 loss: 0.000167885402
Iter: 808 loss: 0.000166816637
Iter: 809 loss: 0.000170127605
Iter: 810 loss: 0.000166501268
Iter: 811 loss: 0.000165552774
Iter: 812 loss: 0.000172444765
Iter: 813 loss: 0.000165473539
Iter: 814 loss: 0.000164597557
Iter: 815 loss: 0.000167098304
Iter: 816 loss: 0.000164318757
Iter: 817 loss: 0.000163510034
Iter: 818 loss: 0.000163783363
Iter: 819 loss: 0.000162938421
Iter: 820 loss: 0.00016231669
Iter: 821 loss: 0.000162293873
Iter: 822 loss: 0.000161833712
Iter: 823 loss: 0.000163832839
Iter: 824 loss: 0.000161741511
Iter: 825 loss: 0.000161309421
Iter: 826 loss: 0.000162550685
Iter: 827 loss: 0.00016117176
Iter: 828 loss: 0.00016069776
Iter: 829 loss: 0.000161039992
Iter: 830 loss: 0.000160406475
Iter: 831 loss: 0.000159924311
Iter: 832 loss: 0.000160308526
Iter: 833 loss: 0.000159632589
Iter: 834 loss: 0.000158949639
Iter: 835 loss: 0.00015895284
Iter: 836 loss: 0.000158403622
Iter: 837 loss: 0.000157342933
Iter: 838 loss: 0.000159879739
Iter: 839 loss: 0.00015695882
Iter: 840 loss: 0.00015606315
Iter: 841 loss: 0.000158211755
Iter: 842 loss: 0.000155737478
Iter: 843 loss: 0.000154896654
Iter: 844 loss: 0.000159814299
Iter: 845 loss: 0.000154789232
Iter: 846 loss: 0.000153986781
Iter: 847 loss: 0.000156974667
Iter: 848 loss: 0.000153789297
Iter: 849 loss: 0.000153063389
Iter: 850 loss: 0.000153098343
Iter: 851 loss: 0.00015249342
Iter: 852 loss: 0.000151884829
Iter: 853 loss: 0.000151878194
Iter: 854 loss: 0.000151386776
Iter: 855 loss: 0.000153353089
Iter: 856 loss: 0.000151278044
Iter: 857 loss: 0.000150852895
Iter: 858 loss: 0.000152370121
Iter: 859 loss: 0.000150742766
Iter: 860 loss: 0.000150274805
Iter: 861 loss: 0.00015070611
Iter: 862 loss: 0.000150005391
Iter: 863 loss: 0.000149572064
Iter: 864 loss: 0.000149633692
Iter: 865 loss: 0.000149242958
Iter: 866 loss: 0.000148544612
Iter: 867 loss: 0.00014891653
Iter: 868 loss: 0.000148084044
Iter: 869 loss: 0.000147185987
Iter: 870 loss: 0.000150017382
Iter: 871 loss: 0.000146927239
Iter: 872 loss: 0.000146148202
Iter: 873 loss: 0.000147098865
Iter: 874 loss: 0.000145739337
Iter: 875 loss: 0.000144940394
Iter: 876 loss: 0.000150405322
Iter: 877 loss: 0.000144864956
Iter: 878 loss: 0.000144154517
Iter: 879 loss: 0.000147193263
Iter: 880 loss: 0.000144005782
Iter: 881 loss: 0.000143356447
Iter: 882 loss: 0.000143280282
Iter: 883 loss: 0.000142813835
Iter: 884 loss: 0.000142232937
Iter: 885 loss: 0.000142233155
Iter: 886 loss: 0.000141743949
Iter: 887 loss: 0.000144131365
Iter: 888 loss: 0.000141660828
Iter: 889 loss: 0.000141309167
Iter: 890 loss: 0.00014246002
Iter: 891 loss: 0.000141209661
Iter: 892 loss: 0.000140801771
Iter: 893 loss: 0.000141362281
Iter: 894 loss: 0.000140600197
Iter: 895 loss: 0.000140239863
Iter: 896 loss: 0.000139973214
Iter: 897 loss: 0.000139851691
Iter: 898 loss: 0.000139175492
Iter: 899 loss: 0.000140685283
Iter: 900 loss: 0.000138918898
Iter: 901 loss: 0.000138306961
Iter: 902 loss: 0.000140113363
Iter: 903 loss: 0.000138120493
Iter: 904 loss: 0.000137523515
Iter: 905 loss: 0.000137672119
Iter: 906 loss: 0.000137087918
Iter: 907 loss: 0.00013632272
Iter: 908 loss: 0.000140877441
Iter: 909 loss: 0.000136227987
Iter: 910 loss: 0.000135524504
Iter: 911 loss: 0.000138770396
Iter: 912 loss: 0.000135389579
Iter: 913 loss: 0.000134774542
Iter: 914 loss: 0.000135072565
Iter: 915 loss: 0.000134361879
Iter: 916 loss: 0.000133860187
Iter: 917 loss: 0.000140123098
Iter: 918 loss: 0.000133854774
Iter: 919 loss: 0.000133409427
Iter: 920 loss: 0.000135953946
Iter: 921 loss: 0.000133350841
Iter: 922 loss: 0.000133044639
Iter: 923 loss: 0.000133670881
Iter: 924 loss: 0.000132920046
Iter: 925 loss: 0.000132515532
Iter: 926 loss: 0.00013332536
Iter: 927 loss: 0.000132352434
Iter: 928 loss: 0.000132023037
Iter: 929 loss: 0.000131612964
Iter: 930 loss: 0.000131578869
Iter: 931 loss: 0.000130950415
Iter: 932 loss: 0.000133879774
Iter: 933 loss: 0.000130833185
Iter: 934 loss: 0.000130333035
Iter: 935 loss: 0.000130947825
Iter: 936 loss: 0.000130072774
Iter: 937 loss: 0.000129447144
Iter: 938 loss: 0.000129752
Iter: 939 loss: 0.000129026768
Iter: 940 loss: 0.000128338244
Iter: 941 loss: 0.000132990855
Iter: 942 loss: 0.000128271538
Iter: 943 loss: 0.000127629217
Iter: 944 loss: 0.000130254572
Iter: 945 loss: 0.000127486623
Iter: 946 loss: 0.000126899045
Iter: 947 loss: 0.000127494961
Iter: 948 loss: 0.000126570128
Iter: 949 loss: 0.000126084225
Iter: 950 loss: 0.000130202316
Iter: 951 loss: 0.000126055442
Iter: 952 loss: 0.000125611565
Iter: 953 loss: 0.000129830514
Iter: 954 loss: 0.000125595951
Iter: 955 loss: 0.000125331804
Iter: 956 loss: 0.000125658
Iter: 957 loss: 0.000125193284
Iter: 958 loss: 0.000124821818
Iter: 959 loss: 0.000125741324
Iter: 960 loss: 0.000124691913
Iter: 961 loss: 0.000124398051
Iter: 962 loss: 0.000123930164
Iter: 963 loss: 0.000123925653
Iter: 964 loss: 0.000123336242
Iter: 965 loss: 0.000126916901
Iter: 966 loss: 0.000123264035
Iter: 967 loss: 0.000122809259
Iter: 968 loss: 0.000123083373
Iter: 969 loss: 0.000122515485
Iter: 970 loss: 0.000121900055
Iter: 971 loss: 0.000122630649
Iter: 972 loss: 0.000121573576
Iter: 973 loss: 0.00012097774
Iter: 974 loss: 0.000124106809
Iter: 975 loss: 0.000120886587
Iter: 976 loss: 0.000120287397
Iter: 977 loss: 0.000122938553
Iter: 978 loss: 0.000120167133
Iter: 979 loss: 0.000119654673
Iter: 980 loss: 0.000120299635
Iter: 981 loss: 0.000119390395
Iter: 982 loss: 0.0001189061
Iter: 983 loss: 0.000120782424
Iter: 984 loss: 0.000118791686
Iter: 985 loss: 0.000118378877
Iter: 986 loss: 0.000118375647
Iter: 987 loss: 0.000118149721
Iter: 988 loss: 0.000118289187
Iter: 989 loss: 0.000118005024
Iter: 990 loss: 0.000117672505
Iter: 991 loss: 0.000118601689
Iter: 992 loss: 0.000117567281
Iter: 993 loss: 0.000117302101
Iter: 994 loss: 0.000116809
Iter: 995 loss: 0.000128044863
Iter: 996 loss: 0.000116807874
Iter: 997 loss: 0.000116293872
Iter: 998 loss: 0.00012067538
Iter: 999 loss: 0.000116265641
Iter: 1000 loss: 0.000115879637
Iter: 1001 loss: 0.000116032956
Iter: 1002 loss: 0.000115612907
Iter: 1003 loss: 0.000115095827
Iter: 1004 loss: 0.000115927891
Iter: 1005 loss: 0.000114855829
Iter: 1006 loss: 0.000114334427
Iter: 1007 loss: 0.000115959971
Iter: 1008 loss: 0.000114183669
Iter: 1009 loss: 0.000113624948
Iter: 1010 loss: 0.000117593518
Iter: 1011 loss: 0.000113574475
Iter: 1012 loss: 0.000113170187
Iter: 1013 loss: 0.000113517963
Iter: 1014 loss: 0.000112932335
Iter: 1015 loss: 0.000112447611
Iter: 1016 loss: 0.000112886351
Iter: 1017 loss: 0.000112164809
Iter: 1018 loss: 0.000111948793
Iter: 1019 loss: 0.000111818597
Iter: 1020 loss: 0.000111634508
Iter: 1021 loss: 0.000111709291
Iter: 1022 loss: 0.000111507703
Iter: 1023 loss: 0.000111243935
Iter: 1024 loss: 0.000111922534
Iter: 1025 loss: 0.000111155292
Iter: 1026 loss: 0.00011092241
Iter: 1027 loss: 0.00011043113
Iter: 1028 loss: 0.000118547461
Iter: 1029 loss: 0.000110417408
Iter: 1030 loss: 0.000109948895
Iter: 1031 loss: 0.000114646376
Iter: 1032 loss: 0.000109933804
Iter: 1033 loss: 0.000109571592
Iter: 1034 loss: 0.000109662316
Iter: 1035 loss: 0.000109307024
Iter: 1036 loss: 0.000108852691
Iter: 1037 loss: 0.000109696673
Iter: 1038 loss: 0.000108658642
Iter: 1039 loss: 0.000108205546
Iter: 1040 loss: 0.000109092667
Iter: 1041 loss: 0.000108019274
Iter: 1042 loss: 0.000107527732
Iter: 1043 loss: 0.000110970679
Iter: 1044 loss: 0.000107480737
Iter: 1045 loss: 0.000107131658
Iter: 1046 loss: 0.000107706408
Iter: 1047 loss: 0.00010697278
Iter: 1048 loss: 0.000106569118
Iter: 1049 loss: 0.000107055501
Iter: 1050 loss: 0.000106357053
Iter: 1051 loss: 0.000106384963
Iter: 1052 loss: 0.000106145788
Iter: 1053 loss: 0.000106014013
Iter: 1054 loss: 0.000106011685
Iter: 1055 loss: 0.000105907842
Iter: 1056 loss: 0.000105692045
Iter: 1057 loss: 0.000105981162
Iter: 1058 loss: 0.000105584004
Iter: 1059 loss: 0.000105368061
Iter: 1060 loss: 0.000104999162
Iter: 1061 loss: 0.000104998537
Iter: 1062 loss: 0.00010465354
Iter: 1063 loss: 0.000107776905
Iter: 1064 loss: 0.000104637882
Iter: 1065 loss: 0.000104323452
Iter: 1066 loss: 0.000103981467
Iter: 1067 loss: 0.000103929138
Iter: 1068 loss: 0.00010349261
Iter: 1069 loss: 0.0001064346
Iter: 1070 loss: 0.000103449383
Iter: 1071 loss: 0.00010315192
Iter: 1072 loss: 0.000103195591
Iter: 1073 loss: 0.000102927297
Iter: 1074 loss: 0.000102549719
Iter: 1075 loss: 0.000104308929
Iter: 1076 loss: 0.000102479171
Iter: 1077 loss: 0.000102174839
Iter: 1078 loss: 0.000102675556
Iter: 1079 loss: 0.000102036298
Iter: 1080 loss: 0.000101683858
Iter: 1081 loss: 0.00010165877
Iter: 1082 loss: 0.000101394136
Iter: 1083 loss: 0.000101411701
Iter: 1084 loss: 0.000101177924
Iter: 1085 loss: 0.000101006313
Iter: 1086 loss: 0.00010134773
Iter: 1087 loss: 0.000100935511
Iter: 1088 loss: 0.000100735197
Iter: 1089 loss: 0.000100946549
Iter: 1090 loss: 0.000100625264
Iter: 1091 loss: 0.000100425445
Iter: 1092 loss: 0.000100164587
Iter: 1093 loss: 0.000100147561
Iter: 1094 loss: 9.98315518e-05
Iter: 1095 loss: 0.000100861173
Iter: 1096 loss: 9.97436291e-05
Iter: 1097 loss: 9.93749054e-05
Iter: 1098 loss: 0.000100309604
Iter: 1099 loss: 9.92470814e-05
Iter: 1100 loss: 9.90339e-05
Iter: 1101 loss: 0.000100090881
Iter: 1102 loss: 9.89979599e-05
Iter: 1103 loss: 9.8767021e-05
Iter: 1104 loss: 9.86041e-05
Iter: 1105 loss: 9.85222068e-05
Iter: 1106 loss: 9.82771453e-05
Iter: 1107 loss: 9.874221e-05
Iter: 1108 loss: 9.81731e-05
Iter: 1109 loss: 9.78972457e-05
Iter: 1110 loss: 0.000101236248
Iter: 1111 loss: 9.78938042e-05
Iter: 1112 loss: 9.77284362e-05
Iter: 1113 loss: 9.75685398e-05
Iter: 1114 loss: 9.75324147e-05
Iter: 1115 loss: 9.71930131e-05
Iter: 1116 loss: 9.85396618e-05
Iter: 1117 loss: 9.71155823e-05
Iter: 1118 loss: 9.70888941e-05
Iter: 1119 loss: 9.69655084e-05
Iter: 1120 loss: 9.68874374e-05
Iter: 1121 loss: 9.67107771e-05
Iter: 1122 loss: 9.90843837e-05
Iter: 1123 loss: 9.6699514e-05
Iter: 1124 loss: 9.647e-05
Iter: 1125 loss: 9.66728694e-05
Iter: 1126 loss: 9.63360144e-05
Iter: 1127 loss: 9.61466576e-05
Iter: 1128 loss: 9.66331281e-05
Iter: 1129 loss: 9.60818143e-05
Iter: 1130 loss: 9.58789824e-05
Iter: 1131 loss: 9.68103268e-05
Iter: 1132 loss: 9.58409364e-05
Iter: 1133 loss: 9.56980075e-05
Iter: 1134 loss: 9.571e-05
Iter: 1135 loss: 9.55871146e-05
Iter: 1136 loss: 9.53554118e-05
Iter: 1137 loss: 9.58051824e-05
Iter: 1138 loss: 9.52594855e-05
Iter: 1139 loss: 9.50401154e-05
Iter: 1140 loss: 9.49835739e-05
Iter: 1141 loss: 9.4846735e-05
Iter: 1142 loss: 9.45654319e-05
Iter: 1143 loss: 9.67128071e-05
Iter: 1144 loss: 9.45439824e-05
Iter: 1145 loss: 9.42961342e-05
Iter: 1146 loss: 9.52605187e-05
Iter: 1147 loss: 9.42389743e-05
Iter: 1148 loss: 9.38525045e-05
Iter: 1149 loss: 9.3564282e-05
Iter: 1150 loss: 9.34360578e-05
Iter: 1151 loss: 9.43955674e-05
Iter: 1152 loss: 9.33442789e-05
Iter: 1153 loss: 9.32693511e-05
Iter: 1154 loss: 9.30597234e-05
Iter: 1155 loss: 9.4169307e-05
Iter: 1156 loss: 9.29931048e-05
Iter: 1157 loss: 9.26988e-05
Iter: 1158 loss: 9.29036687e-05
Iter: 1159 loss: 9.25158092e-05
Iter: 1160 loss: 9.22725885e-05
Iter: 1161 loss: 9.23717162e-05
Iter: 1162 loss: 9.21042956e-05
Iter: 1163 loss: 9.19195954e-05
Iter: 1164 loss: 9.45373e-05
Iter: 1165 loss: 9.19195e-05
Iter: 1166 loss: 9.18021324e-05
Iter: 1167 loss: 9.18266887e-05
Iter: 1168 loss: 9.17153375e-05
Iter: 1169 loss: 9.15565688e-05
Iter: 1170 loss: 9.16361823e-05
Iter: 1171 loss: 9.14508419e-05
Iter: 1172 loss: 9.12801042e-05
Iter: 1173 loss: 9.10969829e-05
Iter: 1174 loss: 9.10676245e-05
Iter: 1175 loss: 9.07079593e-05
Iter: 1176 loss: 9.16660938e-05
Iter: 1177 loss: 9.0587826e-05
Iter: 1178 loss: 9.01482272e-05
Iter: 1179 loss: 9.06668574e-05
Iter: 1180 loss: 8.99146107e-05
Iter: 1181 loss: 8.9672918e-05
Iter: 1182 loss: 9.12779287e-05
Iter: 1183 loss: 8.96486308e-05
Iter: 1184 loss: 8.9532783e-05
Iter: 1185 loss: 8.93878605e-05
Iter: 1186 loss: 8.93759425e-05
Iter: 1187 loss: 8.9254434e-05
Iter: 1188 loss: 8.92442913e-05
Iter: 1189 loss: 8.9154e-05
Iter: 1190 loss: 8.90273222e-05
Iter: 1191 loss: 8.90222218e-05
Iter: 1192 loss: 8.88224313e-05
Iter: 1193 loss: 8.88372e-05
Iter: 1194 loss: 8.86670678e-05
Iter: 1195 loss: 8.84391266e-05
Iter: 1196 loss: 8.89589e-05
Iter: 1197 loss: 8.83536122e-05
Iter: 1198 loss: 8.81039887e-05
Iter: 1199 loss: 8.95948178e-05
Iter: 1200 loss: 8.80726584e-05
Iter: 1201 loss: 8.79336e-05
Iter: 1202 loss: 8.83587418e-05
Iter: 1203 loss: 8.78924e-05
Iter: 1204 loss: 8.77022103e-05
Iter: 1205 loss: 8.75778787e-05
Iter: 1206 loss: 8.75053229e-05
Iter: 1207 loss: 8.72883757e-05
Iter: 1208 loss: 8.83664907e-05
Iter: 1209 loss: 8.72513483e-05
Iter: 1210 loss: 8.70187068e-05
Iter: 1211 loss: 8.70460426e-05
Iter: 1212 loss: 8.68401694e-05
Iter: 1213 loss: 8.65878101e-05
Iter: 1214 loss: 8.8572524e-05
Iter: 1215 loss: 8.6570537e-05
Iter: 1216 loss: 8.63889145e-05
Iter: 1217 loss: 8.89750736e-05
Iter: 1218 loss: 8.6388347e-05
Iter: 1219 loss: 8.62385714e-05
Iter: 1220 loss: 8.68994393e-05
Iter: 1221 loss: 8.62092129e-05
Iter: 1222 loss: 8.60501386e-05
Iter: 1223 loss: 8.58413187e-05
Iter: 1224 loss: 8.58284329e-05
Iter: 1225 loss: 8.55790277e-05
Iter: 1226 loss: 8.59536085e-05
Iter: 1227 loss: 8.54601531e-05
Iter: 1228 loss: 8.51486e-05
Iter: 1229 loss: 8.50402648e-05
Iter: 1230 loss: 8.48638665e-05
Iter: 1231 loss: 8.45906e-05
Iter: 1232 loss: 8.8570443e-05
Iter: 1233 loss: 8.45905379e-05
Iter: 1234 loss: 8.43685339e-05
Iter: 1235 loss: 8.41833607e-05
Iter: 1236 loss: 8.41202927e-05
Iter: 1237 loss: 8.3853316e-05
Iter: 1238 loss: 8.78035789e-05
Iter: 1239 loss: 8.38532287e-05
Iter: 1240 loss: 8.36637191e-05
Iter: 1241 loss: 8.34958e-05
Iter: 1242 loss: 8.34471357e-05
Iter: 1243 loss: 8.31858924e-05
Iter: 1244 loss: 8.47771735e-05
Iter: 1245 loss: 8.31541474e-05
Iter: 1246 loss: 8.29631754e-05
Iter: 1247 loss: 8.34517559e-05
Iter: 1248 loss: 8.28969642e-05
Iter: 1249 loss: 8.27372642e-05
Iter: 1250 loss: 8.45763425e-05
Iter: 1251 loss: 8.27346084e-05
Iter: 1252 loss: 8.26490868e-05
Iter: 1253 loss: 8.26379619e-05
Iter: 1254 loss: 8.25800453e-05
Iter: 1255 loss: 8.24749e-05
Iter: 1256 loss: 8.50315409e-05
Iter: 1257 loss: 8.24747694e-05
Iter: 1258 loss: 8.23486771e-05
Iter: 1259 loss: 8.23457231e-05
Iter: 1260 loss: 8.22467118e-05
Iter: 1261 loss: 8.20449422e-05
Iter: 1262 loss: 8.23973678e-05
Iter: 1263 loss: 8.19559136e-05
Iter: 1264 loss: 8.17763867e-05
Iter: 1265 loss: 8.24062226e-05
Iter: 1266 loss: 8.17299e-05
Iter: 1267 loss: 8.15714739e-05
Iter: 1268 loss: 8.20034184e-05
Iter: 1269 loss: 8.15194508e-05
Iter: 1270 loss: 8.13360239e-05
Iter: 1271 loss: 8.16096872e-05
Iter: 1272 loss: 8.1248545e-05
Iter: 1273 loss: 8.10499259e-05
Iter: 1274 loss: 8.20329369e-05
Iter: 1275 loss: 8.10161e-05
Iter: 1276 loss: 8.08457553e-05
Iter: 1277 loss: 8.13143124e-05
Iter: 1278 loss: 8.07907927e-05
Iter: 1279 loss: 8.06259195e-05
Iter: 1280 loss: 8.0421516e-05
Iter: 1281 loss: 8.04041338e-05
Iter: 1282 loss: 8.01526767e-05
Iter: 1283 loss: 8.12549115e-05
Iter: 1284 loss: 8.01027199e-05
Iter: 1285 loss: 8.02476861e-05
Iter: 1286 loss: 8.00316338e-05
Iter: 1287 loss: 7.99589616e-05
Iter: 1288 loss: 7.98638503e-05
Iter: 1289 loss: 7.98578476e-05
Iter: 1290 loss: 7.97420798e-05
Iter: 1291 loss: 7.95758097e-05
Iter: 1292 loss: 7.9570731e-05
Iter: 1293 loss: 7.94046209e-05
Iter: 1294 loss: 8.07215547e-05
Iter: 1295 loss: 7.93931831e-05
Iter: 1296 loss: 7.92836145e-05
Iter: 1297 loss: 7.93758372e-05
Iter: 1298 loss: 7.92187057e-05
Iter: 1299 loss: 7.90792838e-05
Iter: 1300 loss: 7.9443329e-05
Iter: 1301 loss: 7.90318954e-05
Iter: 1302 loss: 7.88938269e-05
Iter: 1303 loss: 7.90756e-05
Iter: 1304 loss: 7.88236139e-05
Iter: 1305 loss: 7.86621822e-05
Iter: 1306 loss: 7.97381072e-05
Iter: 1307 loss: 7.86459423e-05
Iter: 1308 loss: 7.85225493e-05
Iter: 1309 loss: 7.85678276e-05
Iter: 1310 loss: 7.8436191e-05
Iter: 1311 loss: 7.82540665e-05
Iter: 1312 loss: 7.96614331e-05
Iter: 1313 loss: 7.82405259e-05
Iter: 1314 loss: 7.81028648e-05
Iter: 1315 loss: 7.83159558e-05
Iter: 1316 loss: 7.80380215e-05
Iter: 1317 loss: 7.79583861e-05
Iter: 1318 loss: 7.90216873e-05
Iter: 1319 loss: 7.79582915e-05
Iter: 1320 loss: 7.78577887e-05
Iter: 1321 loss: 7.7955061e-05
Iter: 1322 loss: 7.7801189e-05
Iter: 1323 loss: 7.77043679e-05
Iter: 1324 loss: 7.76113884e-05
Iter: 1325 loss: 7.75899243e-05
Iter: 1326 loss: 7.74761356e-05
Iter: 1327 loss: 7.78475369e-05
Iter: 1328 loss: 7.74442669e-05
Iter: 1329 loss: 7.73321299e-05
Iter: 1330 loss: 7.73792e-05
Iter: 1331 loss: 7.72552448e-05
Iter: 1332 loss: 7.71147315e-05
Iter: 1333 loss: 7.78614049e-05
Iter: 1334 loss: 7.70930274e-05
Iter: 1335 loss: 7.69763e-05
Iter: 1336 loss: 7.69029575e-05
Iter: 1337 loss: 7.68566824e-05
Iter: 1338 loss: 7.67238453e-05
Iter: 1339 loss: 7.67238889e-05
Iter: 1340 loss: 7.66242811e-05
Iter: 1341 loss: 7.6571363e-05
Iter: 1342 loss: 7.65264776e-05
Iter: 1343 loss: 7.6375e-05
Iter: 1344 loss: 7.69270482e-05
Iter: 1345 loss: 7.63373537e-05
Iter: 1346 loss: 7.61913834e-05
Iter: 1347 loss: 7.70411934e-05
Iter: 1348 loss: 7.61718329e-05
Iter: 1349 loss: 7.61264528e-05
Iter: 1350 loss: 7.61209885e-05
Iter: 1351 loss: 7.60805488e-05
Iter: 1352 loss: 7.62186246e-05
Iter: 1353 loss: 7.6069744e-05
Iter: 1354 loss: 7.60320472e-05
Iter: 1355 loss: 7.59602553e-05
Iter: 1356 loss: 7.74830041e-05
Iter: 1357 loss: 7.59599498e-05
Iter: 1358 loss: 7.58745518e-05
Iter: 1359 loss: 7.60058538e-05
Iter: 1360 loss: 7.58343085e-05
Iter: 1361 loss: 7.5735923e-05
Iter: 1362 loss: 7.58365e-05
Iter: 1363 loss: 7.56809241e-05
Iter: 1364 loss: 7.55551882e-05
Iter: 1365 loss: 7.59454e-05
Iter: 1366 loss: 7.551827e-05
Iter: 1367 loss: 7.53724817e-05
Iter: 1368 loss: 7.54933935e-05
Iter: 1369 loss: 7.52853739e-05
Iter: 1370 loss: 7.51701882e-05
Iter: 1371 loss: 7.57509915e-05
Iter: 1372 loss: 7.51510743e-05
Iter: 1373 loss: 7.501855e-05
Iter: 1374 loss: 7.52629567e-05
Iter: 1375 loss: 7.49617539e-05
Iter: 1376 loss: 7.48353923e-05
Iter: 1377 loss: 7.494702e-05
Iter: 1378 loss: 7.47616868e-05
Iter: 1379 loss: 7.46155711e-05
Iter: 1380 loss: 7.54846187e-05
Iter: 1381 loss: 7.4596981e-05
Iter: 1382 loss: 7.45411962e-05
Iter: 1383 loss: 7.45363068e-05
Iter: 1384 loss: 7.44775607e-05
Iter: 1385 loss: 7.46651858e-05
Iter: 1386 loss: 7.44611898e-05
Iter: 1387 loss: 7.44033605e-05
Iter: 1388 loss: 7.43233395e-05
Iter: 1389 loss: 7.43200071e-05
Iter: 1390 loss: 7.42345292e-05
Iter: 1391 loss: 7.43742567e-05
Iter: 1392 loss: 7.41953845e-05
Iter: 1393 loss: 7.40867399e-05
Iter: 1394 loss: 7.40797841e-05
Iter: 1395 loss: 7.39978059e-05
Iter: 1396 loss: 7.38619565e-05
Iter: 1397 loss: 7.46713195e-05
Iter: 1398 loss: 7.38450472e-05
Iter: 1399 loss: 7.37200317e-05
Iter: 1400 loss: 7.3907373e-05
Iter: 1401 loss: 7.36602815e-05
Iter: 1402 loss: 7.35366048e-05
Iter: 1403 loss: 7.37043301e-05
Iter: 1404 loss: 7.34749265e-05
Iter: 1405 loss: 7.33629277e-05
Iter: 1406 loss: 7.45677899e-05
Iter: 1407 loss: 7.33602064e-05
Iter: 1408 loss: 7.32603294e-05
Iter: 1409 loss: 7.3138639e-05
Iter: 1410 loss: 7.31272157e-05
Iter: 1411 loss: 7.29855601e-05
Iter: 1412 loss: 7.41985932e-05
Iter: 1413 loss: 7.29779e-05
Iter: 1414 loss: 7.28898449e-05
Iter: 1415 loss: 7.38675808e-05
Iter: 1416 loss: 7.28883315e-05
Iter: 1417 loss: 7.28123268e-05
Iter: 1418 loss: 7.3498275e-05
Iter: 1419 loss: 7.28085288e-05
Iter: 1420 loss: 7.27669831e-05
Iter: 1421 loss: 7.27204315e-05
Iter: 1422 loss: 7.27139122e-05
Iter: 1423 loss: 7.26511935e-05
Iter: 1424 loss: 7.26544e-05
Iter: 1425 loss: 7.26021462e-05
Iter: 1426 loss: 7.25002465e-05
Iter: 1427 loss: 7.26776852e-05
Iter: 1428 loss: 7.24551501e-05
Iter: 1429 loss: 7.23534176e-05
Iter: 1430 loss: 7.26267172e-05
Iter: 1431 loss: 7.23201229e-05
Iter: 1432 loss: 7.22165132e-05
Iter: 1433 loss: 7.26197395e-05
Iter: 1434 loss: 7.21925244e-05
Iter: 1435 loss: 7.21015822e-05
Iter: 1436 loss: 7.20790704e-05
Iter: 1437 loss: 7.20214884e-05
Iter: 1438 loss: 7.19002928e-05
Iter: 1439 loss: 7.29184103e-05
Iter: 1440 loss: 7.18932424e-05
Iter: 1441 loss: 7.17898511e-05
Iter: 1442 loss: 7.20944809e-05
Iter: 1443 loss: 7.17578368e-05
Iter: 1444 loss: 7.16785071e-05
Iter: 1445 loss: 7.16645e-05
Iter: 1446 loss: 7.16106297e-05
Iter: 1447 loss: 7.1520386e-05
Iter: 1448 loss: 7.15202186e-05
Iter: 1449 loss: 7.14741182e-05
Iter: 1450 loss: 7.14711059e-05
Iter: 1451 loss: 7.14476919e-05
Iter: 1452 loss: 7.13987538e-05
Iter: 1453 loss: 7.22412078e-05
Iter: 1454 loss: 7.13975896e-05
Iter: 1455 loss: 7.13380723e-05
Iter: 1456 loss: 7.13057088e-05
Iter: 1457 loss: 7.12790279e-05
Iter: 1458 loss: 7.11841e-05
Iter: 1459 loss: 7.1463146e-05
Iter: 1460 loss: 7.11547327e-05
Iter: 1461 loss: 7.10688182e-05
Iter: 1462 loss: 7.12971e-05
Iter: 1463 loss: 7.10401218e-05
Iter: 1464 loss: 7.09614178e-05
Iter: 1465 loss: 7.13513364e-05
Iter: 1466 loss: 7.09482119e-05
Iter: 1467 loss: 7.08740045e-05
Iter: 1468 loss: 7.08232692e-05
Iter: 1469 loss: 7.07963118e-05
Iter: 1470 loss: 7.06771098e-05
Iter: 1471 loss: 7.12480105e-05
Iter: 1472 loss: 7.06557912e-05
Iter: 1473 loss: 7.05632265e-05
Iter: 1474 loss: 7.1086004e-05
Iter: 1475 loss: 7.05502e-05
Iter: 1476 loss: 7.0461756e-05
Iter: 1477 loss: 7.05210259e-05
Iter: 1478 loss: 7.04056511e-05
Iter: 1479 loss: 7.03269325e-05
Iter: 1480 loss: 7.08099469e-05
Iter: 1481 loss: 7.03173719e-05
Iter: 1482 loss: 7.02900434e-05
Iter: 1483 loss: 7.02764155e-05
Iter: 1484 loss: 7.02538746e-05
Iter: 1485 loss: 7.01924364e-05
Iter: 1486 loss: 7.05884886e-05
Iter: 1487 loss: 7.01771e-05
Iter: 1488 loss: 7.00882229e-05
Iter: 1489 loss: 7.027213e-05
Iter: 1490 loss: 7.00522723e-05
Iter: 1491 loss: 6.99749216e-05
Iter: 1492 loss: 7.02175894e-05
Iter: 1493 loss: 6.99523662e-05
Iter: 1494 loss: 6.98732692e-05
Iter: 1495 loss: 6.98858e-05
Iter: 1496 loss: 6.98135e-05
Iter: 1497 loss: 6.97106443e-05
Iter: 1498 loss: 7.04274134e-05
Iter: 1499 loss: 6.97013893e-05
Iter: 1500 loss: 6.96127536e-05
Iter: 1501 loss: 6.95551425e-05
Iter: 1502 loss: 6.95211638e-05
Iter: 1503 loss: 6.93850452e-05
Iter: 1504 loss: 7.01729e-05
Iter: 1505 loss: 6.93671172e-05
Iter: 1506 loss: 6.92636386e-05
Iter: 1507 loss: 6.96452335e-05
Iter: 1508 loss: 6.92383619e-05
Iter: 1509 loss: 6.91464e-05
Iter: 1510 loss: 6.95482522e-05
Iter: 1511 loss: 6.91277e-05
Iter: 1512 loss: 6.90532543e-05
Iter: 1513 loss: 6.91100504e-05
Iter: 1514 loss: 6.9007976e-05
Iter: 1515 loss: 6.90522938e-05
Iter: 1516 loss: 6.89738663e-05
Iter: 1517 loss: 6.89487351e-05
Iter: 1518 loss: 6.8881287e-05
Iter: 1519 loss: 6.93078837e-05
Iter: 1520 loss: 6.88638538e-05
Iter: 1521 loss: 6.87886059e-05
Iter: 1522 loss: 6.90059387e-05
Iter: 1523 loss: 6.87650536e-05
Iter: 1524 loss: 6.86946441e-05
Iter: 1525 loss: 6.88824221e-05
Iter: 1526 loss: 6.86707936e-05
Iter: 1527 loss: 6.85929699e-05
Iter: 1528 loss: 6.8633206e-05
Iter: 1529 loss: 6.85415216e-05
Iter: 1530 loss: 6.84461556e-05
Iter: 1531 loss: 6.89047301e-05
Iter: 1532 loss: 6.84294937e-05
Iter: 1533 loss: 6.83357721e-05
Iter: 1534 loss: 6.83995531e-05
Iter: 1535 loss: 6.82767568e-05
Iter: 1536 loss: 6.81747188e-05
Iter: 1537 loss: 6.85732157e-05
Iter: 1538 loss: 6.81509482e-05
Iter: 1539 loss: 6.80498633e-05
Iter: 1540 loss: 6.82584214e-05
Iter: 1541 loss: 6.80094672e-05
Iter: 1542 loss: 6.79138e-05
Iter: 1543 loss: 6.86902349e-05
Iter: 1544 loss: 6.79077202e-05
Iter: 1545 loss: 6.78367287e-05
Iter: 1546 loss: 6.78254437e-05
Iter: 1547 loss: 6.7776833e-05
Iter: 1548 loss: 6.78324577e-05
Iter: 1549 loss: 6.77447388e-05
Iter: 1550 loss: 6.77186181e-05
Iter: 1551 loss: 6.76555064e-05
Iter: 1552 loss: 6.83425242e-05
Iter: 1553 loss: 6.76487762e-05
Iter: 1554 loss: 6.75745905e-05
Iter: 1555 loss: 6.76854834e-05
Iter: 1556 loss: 6.75391639e-05
Iter: 1557 loss: 6.74666298e-05
Iter: 1558 loss: 6.78424476e-05
Iter: 1559 loss: 6.74552284e-05
Iter: 1560 loss: 6.73894101e-05
Iter: 1561 loss: 6.73628747e-05
Iter: 1562 loss: 6.7327841e-05
Iter: 1563 loss: 6.72382084e-05
Iter: 1564 loss: 6.76340278e-05
Iter: 1565 loss: 6.72205351e-05
Iter: 1566 loss: 6.71357484e-05
Iter: 1567 loss: 6.72244496e-05
Iter: 1568 loss: 6.7088884e-05
Iter: 1569 loss: 6.69954388e-05
Iter: 1570 loss: 6.72495662e-05
Iter: 1571 loss: 6.6965018e-05
Iter: 1572 loss: 6.6868568e-05
Iter: 1573 loss: 6.7153509e-05
Iter: 1574 loss: 6.6839e-05
Iter: 1575 loss: 6.67617714e-05
Iter: 1576 loss: 6.71671296e-05
Iter: 1577 loss: 6.67497443e-05
Iter: 1578 loss: 6.66775e-05
Iter: 1579 loss: 6.6705652e-05
Iter: 1580 loss: 6.66273409e-05
Iter: 1581 loss: 6.66316482e-05
Iter: 1582 loss: 6.65951811e-05
Iter: 1583 loss: 6.65551925e-05
Iter: 1584 loss: 6.6483226e-05
Iter: 1585 loss: 6.82182726e-05
Iter: 1586 loss: 6.64830877e-05
Iter: 1587 loss: 6.64174e-05
Iter: 1588 loss: 6.63675164e-05
Iter: 1589 loss: 6.63460596e-05
Iter: 1590 loss: 6.6249966e-05
Iter: 1591 loss: 6.66911292e-05
Iter: 1592 loss: 6.62317616e-05
Iter: 1593 loss: 6.61314625e-05
Iter: 1594 loss: 6.62716702e-05
Iter: 1595 loss: 6.60821388e-05
Iter: 1596 loss: 6.59972429e-05
Iter: 1597 loss: 6.64345425e-05
Iter: 1598 loss: 6.5983586e-05
Iter: 1599 loss: 6.5901957e-05
Iter: 1600 loss: 6.59404104e-05
Iter: 1601 loss: 6.58466452e-05
Iter: 1602 loss: 6.57416604e-05
Iter: 1603 loss: 6.59636207e-05
Iter: 1604 loss: 6.57000128e-05
Iter: 1605 loss: 6.55909535e-05
Iter: 1606 loss: 6.59812868e-05
Iter: 1607 loss: 6.5563363e-05
Iter: 1608 loss: 6.54799369e-05
Iter: 1609 loss: 6.60720398e-05
Iter: 1610 loss: 6.54725955e-05
Iter: 1611 loss: 6.53998213e-05
Iter: 1612 loss: 6.53693278e-05
Iter: 1613 loss: 6.5331209e-05
Iter: 1614 loss: 6.52846429e-05
Iter: 1615 loss: 6.52765957e-05
Iter: 1616 loss: 6.5205415e-05
Iter: 1617 loss: 6.5176966e-05
Iter: 1618 loss: 6.51387381e-05
Iter: 1619 loss: 6.50825386e-05
Iter: 1620 loss: 6.50400179e-05
Iter: 1621 loss: 6.50216098e-05
Iter: 1622 loss: 6.49411086e-05
Iter: 1623 loss: 6.50452785e-05
Iter: 1624 loss: 6.48998684e-05
Iter: 1625 loss: 6.47946435e-05
Iter: 1626 loss: 6.51364826e-05
Iter: 1627 loss: 6.47649067e-05
Iter: 1628 loss: 6.46884655e-05
Iter: 1629 loss: 6.49337e-05
Iter: 1630 loss: 6.46665285e-05
Iter: 1631 loss: 6.45795226e-05
Iter: 1632 loss: 6.47323e-05
Iter: 1633 loss: 6.45406617e-05
Iter: 1634 loss: 6.44546817e-05
Iter: 1635 loss: 6.46722619e-05
Iter: 1636 loss: 6.442421e-05
Iter: 1637 loss: 6.43413223e-05
Iter: 1638 loss: 6.46188855e-05
Iter: 1639 loss: 6.43188832e-05
Iter: 1640 loss: 6.42465166e-05
Iter: 1641 loss: 6.45513283e-05
Iter: 1642 loss: 6.42315863e-05
Iter: 1643 loss: 6.4152322e-05
Iter: 1644 loss: 6.42626546e-05
Iter: 1645 loss: 6.41130391e-05
Iter: 1646 loss: 6.40575454e-05
Iter: 1647 loss: 6.47001143e-05
Iter: 1648 loss: 6.40567159e-05
Iter: 1649 loss: 6.39926948e-05
Iter: 1650 loss: 6.42302039e-05
Iter: 1651 loss: 6.39768405e-05
Iter: 1652 loss: 6.39488644e-05
Iter: 1653 loss: 6.38844722e-05
Iter: 1654 loss: 6.47056222e-05
Iter: 1655 loss: 6.38800484e-05
Iter: 1656 loss: 6.37971316e-05
Iter: 1657 loss: 6.40302314e-05
Iter: 1658 loss: 6.37707053e-05
Iter: 1659 loss: 6.3692e-05
Iter: 1660 loss: 6.4235348e-05
Iter: 1661 loss: 6.3684347e-05
Iter: 1662 loss: 6.36326513e-05
Iter: 1663 loss: 6.36361e-05
Iter: 1664 loss: 6.35920733e-05
Iter: 1665 loss: 6.35170509e-05
Iter: 1666 loss: 6.38792771e-05
Iter: 1667 loss: 6.35040415e-05
Iter: 1668 loss: 6.34457756e-05
Iter: 1669 loss: 6.35254401e-05
Iter: 1670 loss: 6.34167809e-05
Iter: 1671 loss: 6.33368763e-05
Iter: 1672 loss: 6.3368956e-05
Iter: 1673 loss: 6.32816664e-05
Iter: 1674 loss: 6.31987859e-05
Iter: 1675 loss: 6.40259896e-05
Iter: 1676 loss: 6.31960575e-05
Iter: 1677 loss: 6.31272051e-05
Iter: 1678 loss: 6.32309821e-05
Iter: 1679 loss: 6.30941067e-05
Iter: 1680 loss: 6.30414579e-05
Iter: 1681 loss: 6.35935721e-05
Iter: 1682 loss: 6.30400391e-05
Iter: 1683 loss: 6.29921269e-05
Iter: 1684 loss: 6.35243196e-05
Iter: 1685 loss: 6.29913702e-05
Iter: 1686 loss: 6.29727729e-05
Iter: 1687 loss: 6.29193237e-05
Iter: 1688 loss: 6.31419098e-05
Iter: 1689 loss: 6.2897816e-05
Iter: 1690 loss: 6.28208873e-05
Iter: 1691 loss: 6.30309587e-05
Iter: 1692 loss: 6.27956324e-05
Iter: 1693 loss: 6.27181653e-05
Iter: 1694 loss: 6.32366937e-05
Iter: 1695 loss: 6.27106274e-05
Iter: 1696 loss: 6.26541e-05
Iter: 1697 loss: 6.26578e-05
Iter: 1698 loss: 6.26100227e-05
Iter: 1699 loss: 6.25230168e-05
Iter: 1700 loss: 6.27863774e-05
Iter: 1701 loss: 6.24968525e-05
Iter: 1702 loss: 6.24139648e-05
Iter: 1703 loss: 6.26094e-05
Iter: 1704 loss: 6.23837113e-05
Iter: 1705 loss: 6.22927546e-05
Iter: 1706 loss: 6.25035e-05
Iter: 1707 loss: 6.22591615e-05
Iter: 1708 loss: 6.21850922e-05
Iter: 1709 loss: 6.24302629e-05
Iter: 1710 loss: 6.21645813e-05
Iter: 1711 loss: 6.20759092e-05
Iter: 1712 loss: 6.24371314e-05
Iter: 1713 loss: 6.2056577e-05
Iter: 1714 loss: 6.20046922e-05
Iter: 1715 loss: 6.23078522e-05
Iter: 1716 loss: 6.19981583e-05
Iter: 1717 loss: 6.19552593e-05
Iter: 1718 loss: 6.1954961e-05
Iter: 1719 loss: 6.1934e-05
Iter: 1720 loss: 6.18731428e-05
Iter: 1721 loss: 6.21340514e-05
Iter: 1722 loss: 6.18498743e-05
Iter: 1723 loss: 6.17826299e-05
Iter: 1724 loss: 6.20740175e-05
Iter: 1725 loss: 6.17686455e-05
Iter: 1726 loss: 6.17085752e-05
Iter: 1727 loss: 6.20847713e-05
Iter: 1728 loss: 6.17014302e-05
Iter: 1729 loss: 6.16469624e-05
Iter: 1730 loss: 6.16214675e-05
Iter: 1731 loss: 6.15944e-05
Iter: 1732 loss: 6.15196404e-05
Iter: 1733 loss: 6.20361388e-05
Iter: 1734 loss: 6.15127065e-05
Iter: 1735 loss: 6.14523087e-05
Iter: 1736 loss: 6.14765449e-05
Iter: 1737 loss: 6.14106248e-05
Iter: 1738 loss: 6.13208249e-05
Iter: 1739 loss: 6.15479948e-05
Iter: 1740 loss: 6.1289451e-05
Iter: 1741 loss: 6.1210565e-05
Iter: 1742 loss: 6.1400453e-05
Iter: 1743 loss: 6.11820142e-05
Iter: 1744 loss: 6.1107683e-05
Iter: 1745 loss: 6.1834915e-05
Iter: 1746 loss: 6.11052092e-05
Iter: 1747 loss: 6.10579591e-05
Iter: 1748 loss: 6.11672876e-05
Iter: 1749 loss: 6.10404531e-05
Iter: 1750 loss: 6.10023308e-05
Iter: 1751 loss: 6.10005081e-05
Iter: 1752 loss: 6.09802228e-05
Iter: 1753 loss: 6.09252093e-05
Iter: 1754 loss: 6.12746662e-05
Iter: 1755 loss: 6.0911425e-05
Iter: 1756 loss: 6.08523e-05
Iter: 1757 loss: 6.08973496e-05
Iter: 1758 loss: 6.08164446e-05
Iter: 1759 loss: 6.0733164e-05
Iter: 1760 loss: 6.1168e-05
Iter: 1761 loss: 6.07199654e-05
Iter: 1762 loss: 6.06473477e-05
Iter: 1763 loss: 6.07055299e-05
Iter: 1764 loss: 6.06036483e-05
Iter: 1765 loss: 6.05131e-05
Iter: 1766 loss: 6.06118301e-05
Iter: 1767 loss: 6.04638044e-05
Iter: 1768 loss: 6.03464978e-05
Iter: 1769 loss: 6.06065696e-05
Iter: 1770 loss: 6.03017907e-05
Iter: 1771 loss: 6.01883439e-05
Iter: 1772 loss: 6.07481197e-05
Iter: 1773 loss: 6.01688625e-05
Iter: 1774 loss: 6.00842941e-05
Iter: 1775 loss: 6.01802458e-05
Iter: 1776 loss: 6.00388339e-05
Iter: 1777 loss: 5.99524392e-05
Iter: 1778 loss: 6.0825103e-05
Iter: 1779 loss: 5.99495797e-05
Iter: 1780 loss: 5.98933657e-05
Iter: 1781 loss: 6.01186948e-05
Iter: 1782 loss: 5.98806037e-05
Iter: 1783 loss: 5.98520637e-05
Iter: 1784 loss: 5.9846152e-05
Iter: 1785 loss: 5.98243241e-05
Iter: 1786 loss: 5.97655e-05
Iter: 1787 loss: 6.01468018e-05
Iter: 1788 loss: 5.97506951e-05
Iter: 1789 loss: 5.96930258e-05
Iter: 1790 loss: 5.97375038e-05
Iter: 1791 loss: 5.9658043e-05
Iter: 1792 loss: 5.95858473e-05
Iter: 1793 loss: 6.02203763e-05
Iter: 1794 loss: 5.95819802e-05
Iter: 1795 loss: 5.95229285e-05
Iter: 1796 loss: 5.9611044e-05
Iter: 1797 loss: 5.94945159e-05
Iter: 1798 loss: 5.94324774e-05
Iter: 1799 loss: 5.95083256e-05
Iter: 1800 loss: 5.93998848e-05
Iter: 1801 loss: 5.93263976e-05
Iter: 1802 loss: 5.94613666e-05
Iter: 1803 loss: 5.92946672e-05
Iter: 1804 loss: 5.92206e-05
Iter: 1805 loss: 5.96165701e-05
Iter: 1806 loss: 5.92091164e-05
Iter: 1807 loss: 5.91545177e-05
Iter: 1808 loss: 5.91991266e-05
Iter: 1809 loss: 5.91218231e-05
Iter: 1810 loss: 5.90625823e-05
Iter: 1811 loss: 5.94996091e-05
Iter: 1812 loss: 5.90576092e-05
Iter: 1813 loss: 5.90123127e-05
Iter: 1814 loss: 5.91423e-05
Iter: 1815 loss: 5.89982483e-05
Iter: 1816 loss: 5.89911906e-05
Iter: 1817 loss: 5.89762531e-05
Iter: 1818 loss: 5.89594274e-05
Iter: 1819 loss: 5.89151168e-05
Iter: 1820 loss: 5.92410979e-05
Iter: 1821 loss: 5.89058618e-05
Iter: 1822 loss: 5.88596085e-05
Iter: 1823 loss: 5.88080948e-05
Iter: 1824 loss: 5.88009134e-05
Iter: 1825 loss: 5.87341347e-05
Iter: 1826 loss: 5.96829559e-05
Iter: 1827 loss: 5.87339018e-05
Iter: 1828 loss: 5.8681504e-05
Iter: 1829 loss: 5.87607756e-05
Iter: 1830 loss: 5.86566348e-05
Iter: 1831 loss: 5.85959933e-05
Iter: 1832 loss: 5.86617389e-05
Iter: 1833 loss: 5.85627713e-05
Iter: 1834 loss: 5.84902e-05
Iter: 1835 loss: 5.85930829e-05
Iter: 1836 loss: 5.84549234e-05
Iter: 1837 loss: 5.83862311e-05
Iter: 1838 loss: 5.88734729e-05
Iter: 1839 loss: 5.83801702e-05
Iter: 1840 loss: 5.83238252e-05
Iter: 1841 loss: 5.8317557e-05
Iter: 1842 loss: 5.82769535e-05
Iter: 1843 loss: 5.82005487e-05
Iter: 1844 loss: 5.88157709e-05
Iter: 1845 loss: 5.81953936e-05
Iter: 1846 loss: 5.81351378e-05
Iter: 1847 loss: 5.8306905e-05
Iter: 1848 loss: 5.81163658e-05
Iter: 1849 loss: 5.80995547e-05
Iter: 1850 loss: 5.8087142e-05
Iter: 1851 loss: 5.80611486e-05
Iter: 1852 loss: 5.79984226e-05
Iter: 1853 loss: 5.8677786e-05
Iter: 1854 loss: 5.79918196e-05
Iter: 1855 loss: 5.79385051e-05
Iter: 1856 loss: 5.79368607e-05
Iter: 1857 loss: 5.78956242e-05
Iter: 1858 loss: 5.78288418e-05
Iter: 1859 loss: 5.81502318e-05
Iter: 1860 loss: 5.7817022e-05
Iter: 1861 loss: 5.77544524e-05
Iter: 1862 loss: 5.80814594e-05
Iter: 1863 loss: 5.77445244e-05
Iter: 1864 loss: 5.76971688e-05
Iter: 1865 loss: 5.77736064e-05
Iter: 1866 loss: 5.76755e-05
Iter: 1867 loss: 5.76191e-05
Iter: 1868 loss: 5.76088205e-05
Iter: 1869 loss: 5.75708764e-05
Iter: 1870 loss: 5.74960177e-05
Iter: 1871 loss: 5.80377273e-05
Iter: 1872 loss: 5.7489422e-05
Iter: 1873 loss: 5.74293626e-05
Iter: 1874 loss: 5.74233927e-05
Iter: 1875 loss: 5.73796497e-05
Iter: 1876 loss: 5.73099132e-05
Iter: 1877 loss: 5.80514752e-05
Iter: 1878 loss: 5.73080142e-05
Iter: 1879 loss: 5.72598328e-05
Iter: 1880 loss: 5.74097576e-05
Iter: 1881 loss: 5.72455901e-05
Iter: 1882 loss: 5.72264216e-05
Iter: 1883 loss: 5.7220248e-05
Iter: 1884 loss: 5.71928504e-05
Iter: 1885 loss: 5.71351629e-05
Iter: 1886 loss: 5.8075886e-05
Iter: 1887 loss: 5.71333076e-05
Iter: 1888 loss: 5.70895063e-05
Iter: 1889 loss: 5.70584671e-05
Iter: 1890 loss: 5.7043042e-05
Iter: 1891 loss: 5.69796794e-05
Iter: 1892 loss: 5.72806021e-05
Iter: 1893 loss: 5.69679505e-05
Iter: 1894 loss: 5.69026779e-05
Iter: 1895 loss: 5.7258334e-05
Iter: 1896 loss: 5.68931791e-05
Iter: 1897 loss: 5.68415198e-05
Iter: 1898 loss: 5.6941848e-05
Iter: 1899 loss: 5.68203832e-05
Iter: 1900 loss: 5.67618372e-05
Iter: 1901 loss: 5.67523784e-05
Iter: 1902 loss: 5.67120587e-05
Iter: 1903 loss: 5.66374e-05
Iter: 1904 loss: 5.71774326e-05
Iter: 1905 loss: 5.6631e-05
Iter: 1906 loss: 5.6564957e-05
Iter: 1907 loss: 5.65984737e-05
Iter: 1908 loss: 5.65207083e-05
Iter: 1909 loss: 5.64609327e-05
Iter: 1910 loss: 5.71832788e-05
Iter: 1911 loss: 5.64602e-05
Iter: 1912 loss: 5.64095353e-05
Iter: 1913 loss: 5.64837028e-05
Iter: 1914 loss: 5.63849353e-05
Iter: 1915 loss: 5.6359062e-05
Iter: 1916 loss: 5.63541362e-05
Iter: 1917 loss: 5.63232497e-05
Iter: 1918 loss: 5.62814566e-05
Iter: 1919 loss: 5.62792411e-05
Iter: 1920 loss: 5.62472051e-05
Iter: 1921 loss: 5.62021232e-05
Iter: 1922 loss: 5.62003661e-05
Iter: 1923 loss: 5.61417946e-05
Iter: 1924 loss: 5.62383248e-05
Iter: 1925 loss: 5.61150082e-05
Iter: 1926 loss: 5.60448316e-05
Iter: 1927 loss: 5.66044073e-05
Iter: 1928 loss: 5.60400949e-05
Iter: 1929 loss: 5.59912914e-05
Iter: 1930 loss: 5.60603e-05
Iter: 1931 loss: 5.59672117e-05
Iter: 1932 loss: 5.5902e-05
Iter: 1933 loss: 5.59583859e-05
Iter: 1934 loss: 5.58635547e-05
Iter: 1935 loss: 5.57931162e-05
Iter: 1936 loss: 5.60805383e-05
Iter: 1937 loss: 5.57776148e-05
Iter: 1938 loss: 5.57046224e-05
Iter: 1939 loss: 5.57826497e-05
Iter: 1940 loss: 5.56644518e-05
Iter: 1941 loss: 5.55992301e-05
Iter: 1942 loss: 5.6066041e-05
Iter: 1943 loss: 5.55938532e-05
Iter: 1944 loss: 5.55396036e-05
Iter: 1945 loss: 5.57718522e-05
Iter: 1946 loss: 5.55285224e-05
Iter: 1947 loss: 5.55019178e-05
Iter: 1948 loss: 5.54997532e-05
Iter: 1949 loss: 5.54725848e-05
Iter: 1950 loss: 5.54618418e-05
Iter: 1951 loss: 5.54471917e-05
Iter: 1952 loss: 5.54236831e-05
Iter: 1953 loss: 5.53621867e-05
Iter: 1954 loss: 5.5868346e-05
Iter: 1955 loss: 5.53513164e-05
Iter: 1956 loss: 5.52788e-05
Iter: 1957 loss: 5.56343584e-05
Iter: 1958 loss: 5.52659258e-05
Iter: 1959 loss: 5.52056372e-05
Iter: 1960 loss: 5.56792074e-05
Iter: 1961 loss: 5.5201439e-05
Iter: 1962 loss: 5.51553821e-05
Iter: 1963 loss: 5.52447e-05
Iter: 1964 loss: 5.51359881e-05
Iter: 1965 loss: 5.50848563e-05
Iter: 1966 loss: 5.51412886e-05
Iter: 1967 loss: 5.50568766e-05
Iter: 1968 loss: 5.5002849e-05
Iter: 1969 loss: 5.52154634e-05
Iter: 1970 loss: 5.49904507e-05
Iter: 1971 loss: 5.49346223e-05
Iter: 1972 loss: 5.49814649e-05
Iter: 1973 loss: 5.49013166e-05
Iter: 1974 loss: 5.48465978e-05
Iter: 1975 loss: 5.51587436e-05
Iter: 1976 loss: 5.48390308e-05
Iter: 1977 loss: 5.47879754e-05
Iter: 1978 loss: 5.50172153e-05
Iter: 1979 loss: 5.4778262e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4
+ date
Tue Oct 27 19:02:28 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe45a4a4730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe45a4f8f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe45a4f8d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4317cb1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4317cb400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe431782048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4317438c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe431776ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe431776598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe431713488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe4316d4950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c781bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c7931e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c737c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c76b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c76bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c6f8bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c7237b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c6edc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c6ae730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c63c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c63ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c6139d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c5c5730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c5c51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c575378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c575d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c54e268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c54e158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c4f3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c528ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c528e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c528bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c4f38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c43d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fe40c43d6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.233099908
Iter: 2 loss: 3165.6748
Iter: 3 loss: 0.23299785
Iter: 4 loss: 5552.72852
Iter: 5 loss: 12935.665
Iter: 6 loss: 0.2329842
Iter: 7 loss: 1797.04236
Iter: 8 loss: 0.232966155
Iter: 9 loss: 1749.73706
Iter: 10 loss: 0.232965112
Iter: 11 loss: 1887.85217
Iter: 12 loss: 0.232953429
Iter: 13 loss: 727.767883
Iter: 14 loss: 0.232949227
Iter: 15 loss: 562.536194
Iter: 16 loss: 504.952972
Iter: 17 loss: 0.179759532
Iter: 18 loss: 0.2142324
Iter: 19 loss: 0.192416936
Iter: 20 loss: 0.183640331
Iter: 21 loss: 0.460426629
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8
+ date
Tue Oct 27 19:03:16 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c44ba730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c44bf0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c44bfb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4503048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4457730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4484f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c43d4ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4409620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c438c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c43ac378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4361b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4321730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4329488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c42ce6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c43086a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4308598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4296620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4329400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4262bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4248730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c41cc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c41ee268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c41b9950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c415c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4167268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c410d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c410dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c40f08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c40f0b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c40a5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4055268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4078158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4080620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4017510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c40499d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd0c4049e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.110356793
Iter: 2 loss: 1.81869125
Iter: 3 loss: 1.80932593
Iter: 4 loss: 1.3066051
Iter: 5 loss: 1.29885077
Iter: 6 loss: 0.967211843
Iter: 7 loss: 0.959702611
Iter: 8 loss: 0.717026949
Iter: 9 loss: 0.707896352
Iter: 10 loss: 0.516466856
Iter: 11 loss: 0.505016804
Iter: 12 loss: 0.361955851
Iter: 13 loss: 0.350032657
Iter: 14 loss: 0.252965808
Iter: 15 loss: 0.242017701
Iter: 16 loss: 0.180247948
Iter: 17 loss: 0.17136392
Iter: 18 loss: 0.136352018
Iter: 19 loss: 0.130877614
Iter: 20 loss: 0.114337593
Iter: 21 loss: 0.111909375
Iter: 22 loss: 0.105305128
Iter: 23 loss: 0.104638666
Iter: 24 loss: 0.103843771
Iter: 25 loss: 0.102278404
Iter: 26 loss: 0.102262348
Iter: 27 loss: 0.101315632
Iter: 28 loss: 0.0983083844
Iter: 29 loss: 1133.17065
Iter: 30 loss: 0.0942671895
Iter: 31 loss: 0.0948064625
Iter: 32 loss: 236.84433
Iter: 33 loss: 524.379333
Iter: 34 loss: 0.0948064625
Iter: 35 loss: 0.540043592
Iter: 36 loss: 0.0947980285
Iter: 37 loss: 0.15379253
Iter: 38 loss: 0.0959975794
Iter: 39 loss: 0.0945034325
Iter: 40 loss: 0.0967268646
Iter: 41 loss: 0.0939213037
Iter: 42 loss: 0.0866357833
Iter: 43 loss: 541.072815
Iter: 44 loss: 0.270445853
Iter: 45 loss: 0.0936262
Iter: 46 loss: 0.0922744
Iter: 47 loss: 0.0867040083
Iter: 48 loss: 0.0865416899
Iter: 49 loss: 0.08493267
Iter: 50 loss: 0.083804965
Iter: 51 loss: 0.080804
Iter: 52 loss: 0.0807969347
Iter: 53 loss: 0.0795322359
Iter: 54 loss: 0.274315506
Iter: 55 loss: 0.079530634
Iter: 56 loss: 0.0785211623
Iter: 57 loss: 262.7612
Iter: 58 loss: 0.0785211474
Iter: 59 loss: 0.0770569146
Iter: 60 loss: 0.0757270679
Iter: 61 loss: 0.0753407776
Iter: 62 loss: 0.0712056533
Iter: 63 loss: 0.0821785331
Iter: 64 loss: 0.075070262
Iter: 65 loss: 0.0709946752
Iter: 66 loss: 0.0679840669
Iter: 67 loss: 0.0793012083
Iter: 68 loss: 0.0678542927
Iter: 69 loss: 0.0665484369
Iter: 70 loss: 0.064540185
Iter: 71 loss: 0.0645251274
Iter: 72 loss: 0.0626610145
Iter: 73 loss: 0.058393769
Iter: 74 loss: 2.25604343
Iter: 75 loss: 0.0583925098
Iter: 76 loss: 0.0551398844
Iter: 77 loss: 0.0551303774
Iter: 78 loss: 0.0538388304
Iter: 79 loss: 0.0527523682
Iter: 80 loss: 0.0525740683
Iter: 81 loss: 0.0507093742
Iter: 82 loss: 0.0506442338
Iter: 83 loss: 0.0482778028
Iter: 84 loss: 0.0634277612
Iter: 85 loss: 0.0481833741
Iter: 86 loss: 0.046535559
Iter: 87 loss: 0.0808984712
Iter: 88 loss: 0.0464971624
Iter: 89 loss: 0.0439474136
Iter: 90 loss: 0.071815677
Iter: 91 loss: 0.0437291861
Iter: 92 loss: 0.0419398248
Iter: 93 loss: 0.0419247039
Iter: 94 loss: 0.0400337204
Iter: 95 loss: 0.0514371619
Iter: 96 loss: 0.0397888385
Iter: 97 loss: 0.0382757783
Iter: 98 loss: 0.332693189
Iter: 99 loss: 0.0382704213
Iter: 100 loss: 0.0370155647
Iter: 101 loss: 0.0369971357
Iter: 102 loss: 0.0362111703
Iter: 103 loss: 0.0362088382
Iter: 104 loss: 0.0354535021
Iter: 105 loss: 0.0353394076
Iter: 106 loss: 0.0348128974
Iter: 107 loss: 0.0333677232
Iter: 108 loss: 0.0332330801
Iter: 109 loss: 0.0316883922
Iter: 110 loss: 0.0398545898
Iter: 111 loss: 0.0313791856
Iter: 112 loss: 0.0300930515
Iter: 113 loss: 0.033813633
Iter: 114 loss: 0.0296848174
Iter: 115 loss: 0.0284456424
Iter: 116 loss: 0.0284455512
Iter: 117 loss: 0.0271890201
Iter: 118 loss: 0.0282656737
Iter: 119 loss: 0.0264675282
Iter: 120 loss: 0.0257380158
Iter: 121 loss: 0.0256859586
Iter: 122 loss: 0.0252052825
Iter: 123 loss: 0.0267281123
Iter: 124 loss: 0.0250737108
Iter: 125 loss: 0.0243227091
Iter: 126 loss: 0.0241520479
Iter: 127 loss: 0.0237146169
Iter: 128 loss: 0.0229784884
Iter: 129 loss: 0.0261868797
Iter: 130 loss: 0.0227850489
Iter: 131 loss: 0.0223647114
Iter: 132 loss: 0.0223622471
Iter: 133 loss: 0.0218432266
Iter: 134 loss: 0.0353534
Iter: 135 loss: 0.0218411721
Iter: 136 loss: 0.0215001758
Iter: 137 loss: 0.0215640161
Iter: 138 loss: 0.0212593451
Iter: 139 loss: 0.0206380635
Iter: 140 loss: 0.0215685274
Iter: 141 loss: 0.0203215778
Iter: 142 loss: 0.0198892392
Iter: 143 loss: 0.0229763966
Iter: 144 loss: 0.0198649876
Iter: 145 loss: 0.0196195
Iter: 146 loss: 0.0194476023
Iter: 147 loss: 0.0193550736
Iter: 148 loss: 0.0189834405
Iter: 149 loss: 0.0189006608
Iter: 150 loss: 0.0186461918
Iter: 151 loss: 0.0180398729
Iter: 152 loss: 0.0212941915
Iter: 153 loss: 0.0179795288
Iter: 154 loss: 0.0177369267
Iter: 155 loss: 0.0174695179
Iter: 156 loss: 0.0172133073
Iter: 157 loss: 0.017298203
Iter: 158 loss: 0.017032288
Iter: 159 loss: 0.0165890269
Iter: 160 loss: 0.0163851827
Iter: 161 loss: 0.016156055
Iter: 162 loss: 0.0154521186
Iter: 163 loss: 0.0233997
Iter: 164 loss: 0.0154377371
Iter: 165 loss: 0.0150367469
Iter: 166 loss: 0.0173041821
Iter: 167 loss: 0.0149738509
Iter: 168 loss: 0.0146889519
Iter: 169 loss: 0.0152506027
Iter: 170 loss: 0.0145834126
Iter: 171 loss: 0.0145915709
Iter: 172 loss: 0.0144476537
Iter: 173 loss: 0.0143597759
Iter: 174 loss: 0.014664243
Iter: 175 loss: 0.0143401185
Iter: 176 loss: 0.0141681097
Iter: 177 loss: 0.0143048177
Iter: 178 loss: 0.0140620843
Iter: 179 loss: 0.0138246696
Iter: 180 loss: 0.015499969
Iter: 181 loss: 0.0138102937
Iter: 182 loss: 0.0136671243
Iter: 183 loss: 0.0134562198
Iter: 184 loss: 0.013451322
Iter: 185 loss: 0.0132052172
Iter: 186 loss: 0.0133647285
Iter: 187 loss: 0.0130449329
Iter: 188 loss: 0.0128628016
Iter: 189 loss: 0.0128187537
Iter: 190 loss: 0.0125164073
Iter: 191 loss: 0.0204827078
Iter: 192 loss: 0.0125161363
Iter: 193 loss: 0.0123555679
Iter: 194 loss: 0.0122263012
Iter: 195 loss: 0.0121808769
Iter: 196 loss: 0.0119574498
Iter: 197 loss: 0.0121342801
Iter: 198 loss: 0.0118155479
Iter: 199 loss: 0.0115645248
Iter: 200 loss: 0.012639652
Iter: 201 loss: 0.011504014
Iter: 202 loss: 0.0114624407
Iter: 203 loss: 0.0114171933
Iter: 204 loss: 0.011285184
Iter: 205 loss: 0.0114450548
Iter: 206 loss: 0.0112118917
Iter: 207 loss: 0.0111053456
Iter: 208 loss: 0.0111740325
Iter: 209 loss: 0.0110395374
Iter: 210 loss: 0.0108545618
Iter: 211 loss: 0.0115676681
Iter: 212 loss: 0.0108075021
Iter: 213 loss: 0.0108015183
Iter: 214 loss: 0.0107028903
Iter: 215 loss: 0.0106625035
Iter: 216 loss: 0.0105993897
Iter: 217 loss: 0.0105984202
Iter: 218 loss: 0.0104802456
Iter: 219 loss: 0.0103186313
Iter: 220 loss: 0.0103114937
Iter: 221 loss: 0.0100695277
Iter: 222 loss: 0.0120370882
Iter: 223 loss: 0.0100528682
Iter: 224 loss: 0.00989969634
Iter: 225 loss: 0.0105274692
Iter: 226 loss: 0.00985796
Iter: 227 loss: 0.00976291392
Iter: 228 loss: 0.00970018841
Iter: 229 loss: 0.00966453366
Iter: 230 loss: 0.00951833837
Iter: 231 loss: 0.00969296135
Iter: 232 loss: 0.00944200065
Iter: 233 loss: 0.00927693117
Iter: 234 loss: 0.0100694746
Iter: 235 loss: 0.00924604945
Iter: 236 loss: 0.00909730047
Iter: 237 loss: 0.00954897795
Iter: 238 loss: 0.00904872175
Iter: 239 loss: 0.00894405879
Iter: 240 loss: 0.00894268695
Iter: 241 loss: 0.00889694504
Iter: 242 loss: 0.00892725401
Iter: 243 loss: 0.0088676149
Iter: 244 loss: 0.00881439727
Iter: 245 loss: 0.00875466224
Iter: 246 loss: 0.00874629803
Iter: 247 loss: 0.00868418068
Iter: 248 loss: 0.00868413411
Iter: 249 loss: 0.00862669293
Iter: 250 loss: 0.00857182406
Iter: 251 loss: 0.00855848
Iter: 252 loss: 0.0084523689
Iter: 253 loss: 0.00888376
Iter: 254 loss: 0.00843012705
Iter: 255 loss: 0.00833488069
Iter: 256 loss: 0.00853974186
Iter: 257 loss: 0.0082952287
Iter: 258 loss: 0.0081919115
Iter: 259 loss: 0.00839729235
Iter: 260 loss: 0.00814790465
Iter: 261 loss: 0.00802959688
Iter: 262 loss: 0.0090619931
Iter: 263 loss: 0.00802445412
Iter: 264 loss: 0.00796546228
Iter: 265 loss: 0.00876259245
Iter: 266 loss: 0.0079646986
Iter: 267 loss: 0.0079233963
Iter: 268 loss: 0.0078426376
Iter: 269 loss: 0.00931980833
Iter: 270 loss: 0.00784184
Iter: 271 loss: 0.00792871416
Iter: 272 loss: 0.00780772604
Iter: 273 loss: 0.00777820265
Iter: 274 loss: 0.00779102556
Iter: 275 loss: 0.00775859039
Iter: 276 loss: 0.00772014866
Iter: 277 loss: 0.0076582944
Iter: 278 loss: 0.00765783293
Iter: 279 loss: 0.00758028124
Iter: 280 loss: 0.00779791968
Iter: 281 loss: 0.00755709689
Iter: 282 loss: 0.00750648696
Iter: 283 loss: 0.007505171
Iter: 284 loss: 0.00747338403
Iter: 285 loss: 0.00740059838
Iter: 286 loss: 0.00836706161
Iter: 287 loss: 0.00739563536
Iter: 288 loss: 0.00730349123
Iter: 289 loss: 0.0076223365
Iter: 290 loss: 0.00727881305
Iter: 291 loss: 0.00723665347
Iter: 292 loss: 0.00719921757
Iter: 293 loss: 0.00718884263
Iter: 294 loss: 0.0070939241
Iter: 295 loss: 0.00717114098
Iter: 296 loss: 0.00703451131
Iter: 297 loss: 0.00694286358
Iter: 298 loss: 0.00745540671
Iter: 299 loss: 0.00693055941
Iter: 300 loss: 0.00685056113
Iter: 301 loss: 0.00800910406
Iter: 302 loss: 0.0068502631
Iter: 303 loss: 0.00680043
Iter: 304 loss: 0.00720004225
Iter: 305 loss: 0.00679808948
Iter: 306 loss: 0.00676064566
Iter: 307 loss: 0.00673170574
Iter: 308 loss: 0.00671911519
Iter: 309 loss: 0.00665450655
Iter: 310 loss: 0.00688872254
Iter: 311 loss: 0.00663823402
Iter: 312 loss: 0.00658694
Iter: 313 loss: 0.00691729505
Iter: 314 loss: 0.00658036536
Iter: 315 loss: 0.00657589966
Iter: 316 loss: 0.0065561
Iter: 317 loss: 0.00653981976
Iter: 318 loss: 0.00649543852
Iter: 319 loss: 0.00684675528
Iter: 320 loss: 0.00648507196
Iter: 321 loss: 0.00643180683
Iter: 322 loss: 0.00648228731
Iter: 323 loss: 0.00640111649
Iter: 324 loss: 0.00633816235
Iter: 325 loss: 0.00682094786
Iter: 326 loss: 0.00633265777
Iter: 327 loss: 0.00626553269
Iter: 328 loss: 0.00651092
Iter: 329 loss: 0.00624898635
Iter: 330 loss: 0.00619073166
Iter: 331 loss: 0.00657737674
Iter: 332 loss: 0.00618395908
Iter: 333 loss: 0.00612670835
Iter: 334 loss: 0.00616271142
Iter: 335 loss: 0.0060896771
Iter: 336 loss: 0.00603514165
Iter: 337 loss: 0.00683962
Iter: 338 loss: 0.00603469461
Iter: 339 loss: 0.00598659739
Iter: 340 loss: 0.00642584078
Iter: 341 loss: 0.00598526653
Iter: 342 loss: 0.00596136926
Iter: 343 loss: 0.0059359232
Iter: 344 loss: 0.00593155343
Iter: 345 loss: 0.0058872588
Iter: 346 loss: 0.00582994241
Iter: 347 loss: 0.00582595356
Iter: 348 loss: 0.00582469907
Iter: 349 loss: 0.00578260329
Iter: 350 loss: 0.00573766557
Iter: 351 loss: 0.00606628647
Iter: 352 loss: 0.00573213305
Iter: 353 loss: 0.00571054732
Iter: 354 loss: 0.00566616142
Iter: 355 loss: 0.00657140044
Iter: 356 loss: 0.00566542242
Iter: 357 loss: 0.00559892925
Iter: 358 loss: 0.00566234812
Iter: 359 loss: 0.00556158228
Iter: 360 loss: 0.00551613234
Iter: 361 loss: 0.00562276226
Iter: 362 loss: 0.00549922138
Iter: 363 loss: 0.00545041496
Iter: 364 loss: 0.00544023747
Iter: 365 loss: 0.00540706422
Iter: 366 loss: 0.00537200505
Iter: 367 loss: 0.00538782496
Iter: 368 loss: 0.00534843653
Iter: 369 loss: 0.0053247232
Iter: 370 loss: 0.00531606842
Iter: 371 loss: 0.00530248275
Iter: 372 loss: 0.00527609698
Iter: 373 loss: 0.00536764925
Iter: 374 loss: 0.00526855607
Iter: 375 loss: 0.00523086824
Iter: 376 loss: 0.00579632865
Iter: 377 loss: 0.00523087103
Iter: 378 loss: 0.00520813
Iter: 379 loss: 0.00518511562
Iter: 380 loss: 0.0051804604
Iter: 381 loss: 0.00512949564
Iter: 382 loss: 0.00587389711
Iter: 383 loss: 0.00512949843
Iter: 384 loss: 0.00509800483
Iter: 385 loss: 0.00538531784
Iter: 386 loss: 0.00509614404
Iter: 387 loss: 0.0050739469
Iter: 388 loss: 0.00505790859
Iter: 389 loss: 0.00505013578
Iter: 390 loss: 0.00500489958
Iter: 391 loss: 0.00506094238
Iter: 392 loss: 0.0049822554
Iter: 393 loss: 0.00492415624
Iter: 394 loss: 0.00522667076
Iter: 395 loss: 0.00491348235
Iter: 396 loss: 0.00487290602
Iter: 397 loss: 0.00489739934
Iter: 398 loss: 0.00484711491
Iter: 399 loss: 0.00484229159
Iter: 400 loss: 0.00481996965
Iter: 401 loss: 0.00479020551
Iter: 402 loss: 0.00478482386
Iter: 403 loss: 0.00476517621
Iter: 404 loss: 0.00474022795
Iter: 405 loss: 0.00476547284
Iter: 406 loss: 0.00472591445
Iter: 407 loss: 0.00468785688
Iter: 408 loss: 0.00469319429
Iter: 409 loss: 0.00465901569
Iter: 410 loss: 0.00461872807
Iter: 411 loss: 0.00514610298
Iter: 412 loss: 0.00461861119
Iter: 413 loss: 0.00458375
Iter: 414 loss: 0.00458338112
Iter: 415 loss: 0.00456631463
Iter: 416 loss: 0.00456288457
Iter: 417 loss: 0.00455171848
Iter: 418 loss: 0.00452179
Iter: 419 loss: 0.00452345796
Iter: 420 loss: 0.00449803192
Iter: 421 loss: 0.00445871241
Iter: 422 loss: 0.00447903574
Iter: 423 loss: 0.00443238253
Iter: 424 loss: 0.0043957131
Iter: 425 loss: 0.00459329644
Iter: 426 loss: 0.00439029932
Iter: 427 loss: 0.00435311301
Iter: 428 loss: 0.00442664465
Iter: 429 loss: 0.00433689961
Iter: 430 loss: 0.00431700703
Iter: 431 loss: 0.00431685429
Iter: 432 loss: 0.00430280529
Iter: 433 loss: 0.00451174192
Iter: 434 loss: 0.00430272473
Iter: 435 loss: 0.00429323595
Iter: 436 loss: 0.00426557474
Iter: 437 loss: 0.00436814828
Iter: 438 loss: 0.00425387686
Iter: 439 loss: 0.00421848893
Iter: 440 loss: 0.00425946666
Iter: 441 loss: 0.0041991761
Iter: 442 loss: 0.00415505795
Iter: 443 loss: 0.0042203078
Iter: 444 loss: 0.00413359888
Iter: 445 loss: 0.0041157254
Iter: 446 loss: 0.00411034329
Iter: 447 loss: 0.00409107655
Iter: 448 loss: 0.00421716366
Iter: 449 loss: 0.00408927305
Iter: 450 loss: 0.00407411065
Iter: 451 loss: 0.00405787863
Iter: 452 loss: 0.00405517174
Iter: 453 loss: 0.00402399944
Iter: 454 loss: 0.00412792945
Iter: 455 loss: 0.00401494047
Iter: 456 loss: 0.0039957324
Iter: 457 loss: 0.00403999444
Iter: 458 loss: 0.00398866273
Iter: 459 loss: 0.00396581274
Iter: 460 loss: 0.00392695237
Iter: 461 loss: 0.00392687
Iter: 462 loss: 0.00390177872
Iter: 463 loss: 0.00390026765
Iter: 464 loss: 0.00388570176
Iter: 465 loss: 0.00396217033
Iter: 466 loss: 0.00388314365
Iter: 467 loss: 0.00386502314
Iter: 468 loss: 0.0038558729
Iter: 469 loss: 0.00384758809
Iter: 470 loss: 0.00382722169
Iter: 471 loss: 0.00381355453
Iter: 472 loss: 0.00380603434
Iter: 473 loss: 0.00378449075
Iter: 474 loss: 0.00380445039
Iter: 475 loss: 0.00377230858
Iter: 476 loss: 0.00374911283
Iter: 477 loss: 0.00383007154
Iter: 478 loss: 0.00374275493
Iter: 479 loss: 0.00372382114
Iter: 480 loss: 0.00388489757
Iter: 481 loss: 0.00372306025
Iter: 482 loss: 0.00370396348
Iter: 483 loss: 0.00372633454
Iter: 484 loss: 0.00369375944
Iter: 485 loss: 0.00367834931
Iter: 486 loss: 0.00364253763
Iter: 487 loss: 0.00404495
Iter: 488 loss: 0.00363955973
Iter: 489 loss: 0.0036182045
Iter: 490 loss: 0.00383178121
Iter: 491 loss: 0.00361729437
Iter: 492 loss: 0.00360522978
Iter: 493 loss: 0.00359983277
Iter: 494 loss: 0.00359368511
Iter: 495 loss: 0.00357349054
Iter: 496 loss: 0.00357947475
Iter: 497 loss: 0.00355927949
Iter: 498 loss: 0.00357362465
Iter: 499 loss: 0.00355409971
Iter: 500 loss: 0.00354885543
Iter: 501 loss: 0.00353632029
Iter: 502 loss: 0.00368438382
Iter: 503 loss: 0.00353510934
Iter: 504 loss: 0.0035134363
Iter: 505 loss: 0.0035485432
Iter: 506 loss: 0.00350333983
Iter: 507 loss: 0.00348286843
Iter: 508 loss: 0.00351818162
Iter: 509 loss: 0.0034739722
Iter: 510 loss: 0.00344963279
Iter: 511 loss: 0.00361025869
Iter: 512 loss: 0.00344710774
Iter: 513 loss: 0.00343192928
Iter: 514 loss: 0.00344340643
Iter: 515 loss: 0.00342244538
Iter: 516 loss: 0.00340709882
Iter: 517 loss: 0.00343763502
Iter: 518 loss: 0.00340104755
Iter: 519 loss: 0.00338713825
Iter: 520 loss: 0.0034204009
Iter: 521 loss: 0.00338204
Iter: 522 loss: 0.00336619932
Iter: 523 loss: 0.00339606986
Iter: 524 loss: 0.00335954688
Iter: 525 loss: 0.00332691893
Iter: 526 loss: 0.00370766106
Iter: 527 loss: 0.00332624046
Iter: 528 loss: 0.00330447825
Iter: 529 loss: 0.00331132486
Iter: 530 loss: 0.00328929117
Iter: 531 loss: 0.00327090733
Iter: 532 loss: 0.00325877778
Iter: 533 loss: 0.00325161032
Iter: 534 loss: 0.00323680695
Iter: 535 loss: 0.00325383083
Iter: 536 loss: 0.00322897104
Iter: 537 loss: 0.00321645057
Iter: 538 loss: 0.00320248399
Iter: 539 loss: 0.00320047163
Iter: 540 loss: 0.00318403449
Iter: 541 loss: 0.00324827433
Iter: 542 loss: 0.00318036508
Iter: 543 loss: 0.00316224317
Iter: 544 loss: 0.00315230666
Iter: 545 loss: 0.00314420229
Iter: 546 loss: 0.00312487455
Iter: 547 loss: 0.00312444102
Iter: 548 loss: 0.00311127072
Iter: 549 loss: 0.00319799501
Iter: 550 loss: 0.00310969236
Iter: 551 loss: 0.00308962399
Iter: 552 loss: 0.00316424691
Iter: 553 loss: 0.00308508473
Iter: 554 loss: 0.00307740876
Iter: 555 loss: 0.00307564903
Iter: 556 loss: 0.00307062361
Iter: 557 loss: 0.00305853132
Iter: 558 loss: 0.00304166973
Iter: 559 loss: 0.00304096634
Iter: 560 loss: 0.00302879838
Iter: 561 loss: 0.00306980382
Iter: 562 loss: 0.00302546681
Iter: 563 loss: 0.00301215309
Iter: 564 loss: 0.0030365421
Iter: 565 loss: 0.00300644478
Iter: 566 loss: 0.00299071451
Iter: 567 loss: 0.00301136589
Iter: 568 loss: 0.00298259058
Iter: 569 loss: 0.0029670205
Iter: 570 loss: 0.00309137348
Iter: 571 loss: 0.00296608079
Iter: 572 loss: 0.00295521016
Iter: 573 loss: 0.00294214836
Iter: 574 loss: 0.00294079399
Iter: 575 loss: 0.0029272635
Iter: 576 loss: 0.0029787831
Iter: 577 loss: 0.00292396429
Iter: 578 loss: 0.00290873088
Iter: 579 loss: 0.00292742858
Iter: 580 loss: 0.00290079438
Iter: 581 loss: 0.00288744317
Iter: 582 loss: 0.00288730208
Iter: 583 loss: 0.00287624681
Iter: 584 loss: 0.0030374825
Iter: 585 loss: 0.00287618442
Iter: 586 loss: 0.00286911032
Iter: 587 loss: 0.00286012702
Iter: 588 loss: 0.00285948021
Iter: 589 loss: 0.00284653902
Iter: 590 loss: 0.00299345562
Iter: 591 loss: 0.00284627173
Iter: 592 loss: 0.0028383336
Iter: 593 loss: 0.00282332487
Iter: 594 loss: 0.00315100653
Iter: 595 loss: 0.00282327272
Iter: 596 loss: 0.00280671241
Iter: 597 loss: 0.00285580615
Iter: 598 loss: 0.00280149281
Iter: 599 loss: 0.00278939609
Iter: 600 loss: 0.00284436019
Iter: 601 loss: 0.00278717955
Iter: 602 loss: 0.00277671777
Iter: 603 loss: 0.00281143747
Iter: 604 loss: 0.00277365907
Iter: 605 loss: 0.00276301824
Iter: 606 loss: 0.00280182762
Iter: 607 loss: 0.0027604783
Iter: 608 loss: 0.00275248801
Iter: 609 loss: 0.00273797056
Iter: 610 loss: 0.00310413027
Iter: 611 loss: 0.00273797102
Iter: 612 loss: 0.0027219723
Iter: 613 loss: 0.00275283027
Iter: 614 loss: 0.00271536736
Iter: 615 loss: 0.00270128227
Iter: 616 loss: 0.00274509238
Iter: 617 loss: 0.002696943
Iter: 618 loss: 0.00268478971
Iter: 619 loss: 0.00274309726
Iter: 620 loss: 0.00268277666
Iter: 621 loss: 0.00267217821
Iter: 622 loss: 0.00271752
Iter: 623 loss: 0.00266970834
Iter: 624 loss: 0.00266306917
Iter: 625 loss: 0.00265390333
Iter: 626 loss: 0.00265351241
Iter: 627 loss: 0.00263526663
Iter: 628 loss: 0.0027795604
Iter: 629 loss: 0.00263393181
Iter: 630 loss: 0.00262199459
Iter: 631 loss: 0.0026928049
Iter: 632 loss: 0.00262062158
Iter: 633 loss: 0.0026126795
Iter: 634 loss: 0.00260814093
Iter: 635 loss: 0.00260464498
Iter: 636 loss: 0.00259513082
Iter: 637 loss: 0.00259012193
Iter: 638 loss: 0.00258589955
Iter: 639 loss: 0.00257165544
Iter: 640 loss: 0.00257831533
Iter: 641 loss: 0.00256180903
Iter: 642 loss: 0.00254276255
Iter: 643 loss: 0.00260999799
Iter: 644 loss: 0.00253800489
Iter: 645 loss: 0.0025198143
Iter: 646 loss: 0.00258072326
Iter: 647 loss: 0.00251468318
Iter: 648 loss: 0.00250007678
Iter: 649 loss: 0.00258790795
Iter: 650 loss: 0.00249832356
Iter: 651 loss: 0.00248854375
Iter: 652 loss: 0.00264108251
Iter: 653 loss: 0.00248852046
Iter: 654 loss: 0.00248300377
Iter: 655 loss: 0.00249777944
Iter: 656 loss: 0.0024812154
Iter: 657 loss: 0.00247396063
Iter: 658 loss: 0.00246001687
Iter: 659 loss: 0.00276418868
Iter: 660 loss: 0.00245994725
Iter: 661 loss: 0.00244195666
Iter: 662 loss: 0.00249004643
Iter: 663 loss: 0.00243594684
Iter: 664 loss: 0.00242714817
Iter: 665 loss: 0.00242469087
Iter: 666 loss: 0.00241747312
Iter: 667 loss: 0.00241595274
Iter: 668 loss: 0.00241128262
Iter: 669 loss: 0.00240095239
Iter: 670 loss: 0.00257488317
Iter: 671 loss: 0.00240093842
Iter: 672 loss: 0.00239337632
Iter: 673 loss: 0.00238692877
Iter: 674 loss: 0.00238492154
Iter: 675 loss: 0.00237604347
Iter: 676 loss: 0.0023775592
Iter: 677 loss: 0.0023692851
Iter: 678 loss: 0.00236246828
Iter: 679 loss: 0.00235177903
Iter: 680 loss: 0.00235165213
Iter: 681 loss: 0.00234102644
Iter: 682 loss: 0.00235135271
Iter: 683 loss: 0.00233484106
Iter: 684 loss: 0.00232822541
Iter: 685 loss: 0.0023364
Iter: 686 loss: 0.00232478976
Iter: 687 loss: 0.00231533404
Iter: 688 loss: 0.00233814912
Iter: 689 loss: 0.00231188792
Iter: 690 loss: 0.00229650806
Iter: 691 loss: 0.00243860483
Iter: 692 loss: 0.0022959034
Iter: 693 loss: 0.00228910986
Iter: 694 loss: 0.00228475
Iter: 695 loss: 0.00228205509
Iter: 696 loss: 0.00227731955
Iter: 697 loss: 0.0023090872
Iter: 698 loss: 0.00227687787
Iter: 699 loss: 0.00227404432
Iter: 700 loss: 0.00226898934
Iter: 701 loss: 0.00238761702
Iter: 702 loss: 0.00226898817
Iter: 703 loss: 0.00225681299
Iter: 704 loss: 0.00225588353
Iter: 705 loss: 0.00224670046
Iter: 706 loss: 0.00223717745
Iter: 707 loss: 0.00223717676
Iter: 708 loss: 0.00223082583
Iter: 709 loss: 0.00233933656
Iter: 710 loss: 0.00223082909
Iter: 711 loss: 0.0022250826
Iter: 712 loss: 0.0022172872
Iter: 713 loss: 0.00221691979
Iter: 714 loss: 0.00220696954
Iter: 715 loss: 0.00227846531
Iter: 716 loss: 0.00220599142
Iter: 717 loss: 0.00220106472
Iter: 718 loss: 0.00219016522
Iter: 719 loss: 0.00234886678
Iter: 720 loss: 0.00218964601
Iter: 721 loss: 0.00217803288
Iter: 722 loss: 0.00228116848
Iter: 723 loss: 0.00217745546
Iter: 724 loss: 0.00217019208
Iter: 725 loss: 0.00224327063
Iter: 726 loss: 0.00216998463
Iter: 727 loss: 0.00216477131
Iter: 728 loss: 0.00217286847
Iter: 729 loss: 0.00216228468
Iter: 730 loss: 0.00215931
Iter: 731 loss: 0.00215905299
Iter: 732 loss: 0.00215622294
Iter: 733 loss: 0.00215225387
Iter: 734 loss: 0.00215209648
Iter: 735 loss: 0.00214860961
Iter: 736 loss: 0.00214325264
Iter: 737 loss: 0.00214317278
Iter: 738 loss: 0.00213711103
Iter: 739 loss: 0.00213003857
Iter: 740 loss: 0.00212920387
Iter: 741 loss: 0.00212258892
Iter: 742 loss: 0.00212198985
Iter: 743 loss: 0.00211371621
Iter: 744 loss: 0.00215368392
Iter: 745 loss: 0.00211227289
Iter: 746 loss: 0.00210724678
Iter: 747 loss: 0.00210073218
Iter: 748 loss: 0.00210030703
Iter: 749 loss: 0.00208719168
Iter: 750 loss: 0.00210163253
Iter: 751 loss: 0.00208004983
Iter: 752 loss: 0.00206877687
Iter: 753 loss: 0.00208792277
Iter: 754 loss: 0.00206381129
Iter: 755 loss: 0.00205484172
Iter: 756 loss: 0.00205880404
Iter: 757 loss: 0.00204873038
Iter: 758 loss: 0.00203887653
Iter: 759 loss: 0.00203879527
Iter: 760 loss: 0.00203493936
Iter: 761 loss: 0.00203493447
Iter: 762 loss: 0.00203187647
Iter: 763 loss: 0.00202749763
Iter: 764 loss: 0.00202734885
Iter: 765 loss: 0.00202186033
Iter: 766 loss: 0.00203435309
Iter: 767 loss: 0.00201974786
Iter: 768 loss: 0.00201345794
Iter: 769 loss: 0.00202548364
Iter: 770 loss: 0.00201086653
Iter: 771 loss: 0.00200363924
Iter: 772 loss: 0.00198804634
Iter: 773 loss: 0.00223476905
Iter: 774 loss: 0.00198749173
Iter: 775 loss: 0.00196797354
Iter: 776 loss: 0.00222718669
Iter: 777 loss: 0.00196783361
Iter: 778 loss: 0.00196066685
Iter: 779 loss: 0.00195984496
Iter: 780 loss: 0.00195299275
Iter: 781 loss: 0.00193538028
Iter: 782 loss: 0.0020882017
Iter: 783 loss: 0.0019323813
Iter: 784 loss: 0.0019197074
Iter: 785 loss: 0.00197567465
Iter: 786 loss: 0.00191718317
Iter: 787 loss: 0.00190448679
Iter: 788 loss: 0.00190146582
Iter: 789 loss: 0.00189333083
Iter: 790 loss: 0.00187964784
Iter: 791 loss: 0.00208851229
Iter: 792 loss: 0.00187964877
Iter: 793 loss: 0.00187042006
Iter: 794 loss: 0.00187881617
Iter: 795 loss: 0.00186495972
Iter: 796 loss: 0.001861169
Iter: 797 loss: 0.00186114758
Iter: 798 loss: 0.00185817981
Iter: 799 loss: 0.00185683218
Iter: 800 loss: 0.00185533764
Iter: 801 loss: 0.00184878265
Iter: 802 loss: 0.00188401737
Iter: 803 loss: 0.00184780569
Iter: 804 loss: 0.00184149051
Iter: 805 loss: 0.00186170591
Iter: 806 loss: 0.00183963636
Iter: 807 loss: 0.00183497788
Iter: 808 loss: 0.00183323363
Iter: 809 loss: 0.00183068216
Iter: 810 loss: 0.00182590599
Iter: 811 loss: 0.00185453508
Iter: 812 loss: 0.00182526454
Iter: 813 loss: 0.00182106218
Iter: 814 loss: 0.00181834749
Iter: 815 loss: 0.00181673514
Iter: 816 loss: 0.00181085581
Iter: 817 loss: 0.00180096575
Iter: 818 loss: 0.00180094084
Iter: 819 loss: 0.00179250678
Iter: 820 loss: 0.00179135741
Iter: 821 loss: 0.00178547762
Iter: 822 loss: 0.00177594554
Iter: 823 loss: 0.00179621042
Iter: 824 loss: 0.00177220337
Iter: 825 loss: 0.00176447909
Iter: 826 loss: 0.00176437246
Iter: 827 loss: 0.00176100573
Iter: 828 loss: 0.00176902278
Iter: 829 loss: 0.00175980979
Iter: 830 loss: 0.00175422395
Iter: 831 loss: 0.00176384836
Iter: 832 loss: 0.00175168645
Iter: 833 loss: 0.0017459403
Iter: 834 loss: 0.0017381534
Iter: 835 loss: 0.00173774175
Iter: 836 loss: 0.00172837218
Iter: 837 loss: 0.00182499853
Iter: 838 loss: 0.00172805251
Iter: 839 loss: 0.0017247505
Iter: 840 loss: 0.00172464026
Iter: 841 loss: 0.00172230229
Iter: 842 loss: 0.0017173856
Iter: 843 loss: 0.00180243887
Iter: 844 loss: 0.00171726034
Iter: 845 loss: 0.00171164225
Iter: 846 loss: 0.00172950129
Iter: 847 loss: 0.00171009253
Iter: 848 loss: 0.00170581159
Iter: 849 loss: 0.00171380129
Iter: 850 loss: 0.00170399528
Iter: 851 loss: 0.00169860153
Iter: 852 loss: 0.00170679973
Iter: 853 loss: 0.00169603364
Iter: 854 loss: 0.00168864813
Iter: 855 loss: 0.00168472133
Iter: 856 loss: 0.00168140815
Iter: 857 loss: 0.00167157548
Iter: 858 loss: 0.00175570929
Iter: 859 loss: 0.00167099689
Iter: 860 loss: 0.00166414038
Iter: 861 loss: 0.00173254299
Iter: 862 loss: 0.00166396785
Iter: 863 loss: 0.00165545987
Iter: 864 loss: 0.00167552044
Iter: 865 loss: 0.00165218138
Iter: 866 loss: 0.00164686213
Iter: 867 loss: 0.00164215069
Iter: 868 loss: 0.00164078269
Iter: 869 loss: 0.00163406529
Iter: 870 loss: 0.00164519693
Iter: 871 loss: 0.00163092813
Iter: 872 loss: 0.00162494672
Iter: 873 loss: 0.00171572063
Iter: 874 loss: 0.00162494602
Iter: 875 loss: 0.00162214786
Iter: 876 loss: 0.00165579724
Iter: 877 loss: 0.00162210432
Iter: 878 loss: 0.00162000384
Iter: 879 loss: 0.0016177214
Iter: 880 loss: 0.00161737681
Iter: 881 loss: 0.00161302718
Iter: 882 loss: 0.00161949266
Iter: 883 loss: 0.00161091937
Iter: 884 loss: 0.00160542806
Iter: 885 loss: 0.00162717677
Iter: 886 loss: 0.00160415168
Iter: 887 loss: 0.00159942382
Iter: 888 loss: 0.00159925292
Iter: 889 loss: 0.0015956047
Iter: 890 loss: 0.00159035891
Iter: 891 loss: 0.00158661208
Iter: 892 loss: 0.00158480043
Iter: 893 loss: 0.00157789106
Iter: 894 loss: 0.00159806281
Iter: 895 loss: 0.00157568883
Iter: 896 loss: 0.00157853286
Iter: 897 loss: 0.00157253467
Iter: 898 loss: 0.00156981847
Iter: 899 loss: 0.00156202249
Iter: 900 loss: 0.00159704825
Iter: 901 loss: 0.00155911478
Iter: 902 loss: 0.00155480858
Iter: 903 loss: 0.0015531946
Iter: 904 loss: 0.00155087258
Iter: 905 loss: 0.00154695346
Iter: 906 loss: 0.00154607208
Iter: 907 loss: 0.00154350954
Iter: 908 loss: 0.0015407966
Iter: 909 loss: 0.00153978798
Iter: 910 loss: 0.00153829122
Iter: 911 loss: 0.00153415604
Iter: 912 loss: 0.00153415464
Iter: 913 loss: 0.00152631523
Iter: 914 loss: 0.00154987909
Iter: 915 loss: 0.00152387784
Iter: 916 loss: 0.0015187891
Iter: 917 loss: 0.0015357025
Iter: 918 loss: 0.00151740876
Iter: 919 loss: 0.00151275098
Iter: 920 loss: 0.00152213685
Iter: 921 loss: 0.0015108505
Iter: 922 loss: 0.00150486734
Iter: 923 loss: 0.00154283806
Iter: 924 loss: 0.00150416652
Iter: 925 loss: 0.00150035461
Iter: 926 loss: 0.00152164628
Iter: 927 loss: 0.00149979815
Iter: 928 loss: 0.00149556482
Iter: 929 loss: 0.00149836624
Iter: 930 loss: 0.00149287935
Iter: 931 loss: 0.00149106537
Iter: 932 loss: 0.00149017596
Iter: 933 loss: 0.00148872961
Iter: 934 loss: 0.00149571127
Iter: 935 loss: 0.00148846372
Iter: 936 loss: 0.00148675451
Iter: 937 loss: 0.00149004709
Iter: 938 loss: 0.00148605241
Iter: 939 loss: 0.00148461899
Iter: 940 loss: 0.00148099591
Iter: 941 loss: 0.00151299906
Iter: 942 loss: 0.00148043502
Iter: 943 loss: 0.00147439796
Iter: 944 loss: 0.00147665059
Iter: 945 loss: 0.00147013774
Iter: 946 loss: 0.00146509474
Iter: 947 loss: 0.00146509532
Iter: 948 loss: 0.00146103348
Iter: 949 loss: 0.00146927149
Iter: 950 loss: 0.00145934406
Iter: 951 loss: 0.00145421596
Iter: 952 loss: 0.00145550421
Iter: 953 loss: 0.00145048252
Iter: 954 loss: 0.00144577643
Iter: 955 loss: 0.00145046099
Iter: 956 loss: 0.00144311693
Iter: 957 loss: 0.00143492932
Iter: 958 loss: 0.00146226841
Iter: 959 loss: 0.0014326711
Iter: 960 loss: 0.00142957922
Iter: 961 loss: 0.00143380638
Iter: 962 loss: 0.00142804591
Iter: 963 loss: 0.00142312166
Iter: 964 loss: 0.00142564625
Iter: 965 loss: 0.00141983188
Iter: 966 loss: 0.00141624757
Iter: 967 loss: 0.00145898038
Iter: 968 loss: 0.00141620962
Iter: 969 loss: 0.00141653884
Iter: 970 loss: 0.00141496561
Iter: 971 loss: 0.00141423522
Iter: 972 loss: 0.00141181611
Iter: 973 loss: 0.00141171389
Iter: 974 loss: 0.00140926836
Iter: 975 loss: 0.00140462944
Iter: 976 loss: 0.00141279958
Iter: 977 loss: 0.00140261045
Iter: 978 loss: 0.00139951496
Iter: 979 loss: 0.00139443413
Iter: 980 loss: 0.00139441132
Iter: 981 loss: 0.0013886845
Iter: 982 loss: 0.00142262643
Iter: 983 loss: 0.00138789206
Iter: 984 loss: 0.00138288306
Iter: 985 loss: 0.00143213128
Iter: 986 loss: 0.00138271647
Iter: 987 loss: 0.00137802423
Iter: 988 loss: 0.00136920414
Iter: 989 loss: 0.00155393954
Iter: 990 loss: 0.00136917946
Iter: 991 loss: 0.00135922374
Iter: 992 loss: 0.00140070147
Iter: 993 loss: 0.00135695084
Iter: 994 loss: 0.00135011901
Iter: 995 loss: 0.00139979552
Iter: 996 loss: 0.00134952576
Iter: 997 loss: 0.00134435517
Iter: 998 loss: 0.00133474288
Iter: 999 loss: 0.00154933613
Iter: 1000 loss: 0.00133472355
Iter: 1001 loss: 0.0013302851
Iter: 1002 loss: 0.00133547396
Iter: 1003 loss: 0.00132788427
Iter: 1004 loss: 0.00132603198
Iter: 1005 loss: 0.00132602465
Iter: 1006 loss: 0.00132394722
Iter: 1007 loss: 0.00132251973
Iter: 1008 loss: 0.00132176024
Iter: 1009 loss: 0.00131739303
Iter: 1010 loss: 0.00137992494
Iter: 1011 loss: 0.00131738349
Iter: 1012 loss: 0.00131410838
Iter: 1013 loss: 0.00131448731
Iter: 1014 loss: 0.00131160812
Iter: 1015 loss: 0.00130742532
Iter: 1016 loss: 0.00130687142
Iter: 1017 loss: 0.00130390283
Iter: 1018 loss: 0.00129948603
Iter: 1019 loss: 0.00130415731
Iter: 1020 loss: 0.00129708287
Iter: 1021 loss: 0.00129056023
Iter: 1022 loss: 0.00133994804
Iter: 1023 loss: 0.00129005627
Iter: 1024 loss: 0.00128558755
Iter: 1025 loss: 0.00130920741
Iter: 1026 loss: 0.00128490699
Iter: 1027 loss: 0.0012812959
Iter: 1028 loss: 0.00128137146
Iter: 1029 loss: 0.00127840939
Iter: 1030 loss: 0.00127473986
Iter: 1031 loss: 0.00127908529
Iter: 1032 loss: 0.00127280969
Iter: 1033 loss: 0.00126929535
Iter: 1034 loss: 0.0012749033
Iter: 1035 loss: 0.00126764609
Iter: 1036 loss: 0.00126550358
Iter: 1037 loss: 0.00126550253
Iter: 1038 loss: 0.00126275176
Iter: 1039 loss: 0.00125958445
Iter: 1040 loss: 0.00125919888
Iter: 1041 loss: 0.00125662016
Iter: 1042 loss: 0.001254295
Iter: 1043 loss: 0.00125364854
Iter: 1044 loss: 0.0012492988
Iter: 1045 loss: 0.00124387443
Iter: 1046 loss: 0.0012434274
Iter: 1047 loss: 0.00123878871
Iter: 1048 loss: 0.00123871677
Iter: 1049 loss: 0.0012348335
Iter: 1050 loss: 0.00124638272
Iter: 1051 loss: 0.0012336513
Iter: 1052 loss: 0.00122962845
Iter: 1053 loss: 0.0012354654
Iter: 1054 loss: 0.00122770341
Iter: 1055 loss: 0.0012245666
Iter: 1056 loss: 0.00123266177
Iter: 1057 loss: 0.00122348859
Iter: 1058 loss: 0.00121958484
Iter: 1059 loss: 0.00122495554
Iter: 1060 loss: 0.0012176414
Iter: 1061 loss: 0.00121413427
Iter: 1062 loss: 0.00121403963
Iter: 1063 loss: 0.0012114438
Iter: 1064 loss: 0.00121593708
Iter: 1065 loss: 0.00121029932
Iter: 1066 loss: 0.00120811327
Iter: 1067 loss: 0.00121927098
Iter: 1068 loss: 0.00120774889
Iter: 1069 loss: 0.0012050143
Iter: 1070 loss: 0.00121199782
Iter: 1071 loss: 0.00120408239
Iter: 1072 loss: 0.00120298774
Iter: 1073 loss: 0.00120057678
Iter: 1074 loss: 0.00123543
Iter: 1075 loss: 0.00120046036
Iter: 1076 loss: 0.00119679398
Iter: 1077 loss: 0.00119905814
Iter: 1078 loss: 0.00119445799
Iter: 1079 loss: 0.00119053095
Iter: 1080 loss: 0.00119442819
Iter: 1081 loss: 0.00118829787
Iter: 1082 loss: 0.00118533662
Iter: 1083 loss: 0.00118532567
Iter: 1084 loss: 0.00118297385
Iter: 1085 loss: 0.00118021434
Iter: 1086 loss: 0.00117990305
Iter: 1087 loss: 0.00117629627
Iter: 1088 loss: 0.00118960789
Iter: 1089 loss: 0.00117540685
Iter: 1090 loss: 0.00117206224
Iter: 1091 loss: 0.00117315375
Iter: 1092 loss: 0.00116967759
Iter: 1093 loss: 0.00116673391
Iter: 1094 loss: 0.00118697179
Iter: 1095 loss: 0.00116647827
Iter: 1096 loss: 0.0011638836
Iter: 1097 loss: 0.00117971527
Iter: 1098 loss: 0.00116355089
Iter: 1099 loss: 0.00116124353
Iter: 1100 loss: 0.00116608141
Iter: 1101 loss: 0.00116035482
Iter: 1102 loss: 0.00115800695
Iter: 1103 loss: 0.0011780241
Iter: 1104 loss: 0.00115786109
Iter: 1105 loss: 0.00115691067
Iter: 1106 loss: 0.00115476153
Iter: 1107 loss: 0.00118332205
Iter: 1108 loss: 0.00115462858
Iter: 1109 loss: 0.0011521338
Iter: 1110 loss: 0.0011460511
Iter: 1111 loss: 0.00120994297
Iter: 1112 loss: 0.0011453568
Iter: 1113 loss: 0.00113941787
Iter: 1114 loss: 0.00117350486
Iter: 1115 loss: 0.00113863789
Iter: 1116 loss: 0.00113609014
Iter: 1117 loss: 0.00113591028
Iter: 1118 loss: 0.0011331361
Iter: 1119 loss: 0.00113219651
Iter: 1120 loss: 0.00113060919
Iter: 1121 loss: 0.0011271378
Iter: 1122 loss: 0.0011361686
Iter: 1123 loss: 0.0011259414
Iter: 1124 loss: 0.00112260354
Iter: 1125 loss: 0.00113890367
Iter: 1126 loss: 0.00112203951
Iter: 1127 loss: 0.00111946557
Iter: 1128 loss: 0.00113038137
Iter: 1129 loss: 0.00111891259
Iter: 1130 loss: 0.00111664063
Iter: 1131 loss: 0.00113854324
Iter: 1132 loss: 0.00111655891
Iter: 1133 loss: 0.00111494481
Iter: 1134 loss: 0.00113452424
Iter: 1135 loss: 0.00111491815
Iter: 1136 loss: 0.001113954
Iter: 1137 loss: 0.00111959525
Iter: 1138 loss: 0.00111383805
Iter: 1139 loss: 0.00111307099
Iter: 1140 loss: 0.00111100799
Iter: 1141 loss: 0.00112480356
Iter: 1142 loss: 0.00111050962
Iter: 1143 loss: 0.00110737956
Iter: 1144 loss: 0.00110368151
Iter: 1145 loss: 0.00110328291
Iter: 1146 loss: 0.00109949266
Iter: 1147 loss: 0.00111032906
Iter: 1148 loss: 0.00109828415
Iter: 1149 loss: 0.0010956428
Iter: 1150 loss: 0.0010956378
Iter: 1151 loss: 0.00109285407
Iter: 1152 loss: 0.00110032735
Iter: 1153 loss: 0.00109191728
Iter: 1154 loss: 0.00108974637
Iter: 1155 loss: 0.00108993961
Iter: 1156 loss: 0.00108807953
Iter: 1157 loss: 0.00108518347
Iter: 1158 loss: 0.00109518424
Iter: 1159 loss: 0.00108441641
Iter: 1160 loss: 0.00108169892
Iter: 1161 loss: 0.00109999708
Iter: 1162 loss: 0.00108142872
Iter: 1163 loss: 0.00107964734
Iter: 1164 loss: 0.00110107171
Iter: 1165 loss: 0.00107962405
Iter: 1166 loss: 0.00107837364
Iter: 1167 loss: 0.00108833832
Iter: 1168 loss: 0.00107829471
Iter: 1169 loss: 0.00107747293
Iter: 1170 loss: 0.00107996655
Iter: 1171 loss: 0.00107722473
Iter: 1172 loss: 0.00107628154
Iter: 1173 loss: 0.00107421738
Iter: 1174 loss: 0.00110485614
Iter: 1175 loss: 0.00107412948
Iter: 1176 loss: 0.00107192225
Iter: 1177 loss: 0.00107165612
Iter: 1178 loss: 0.00107007392
Iter: 1179 loss: 0.00106727565
Iter: 1180 loss: 0.0010669285
Iter: 1181 loss: 0.00106491416
Iter: 1182 loss: 0.00106131681
Iter: 1183 loss: 0.00110884267
Iter: 1184 loss: 0.00106129434
Iter: 1185 loss: 0.00105914753
Iter: 1186 loss: 0.00107201631
Iter: 1187 loss: 0.00105889619
Iter: 1188 loss: 0.00105638721
Iter: 1189 loss: 0.00105586357
Iter: 1190 loss: 0.00105420942
Iter: 1191 loss: 0.0010516434
Iter: 1192 loss: 0.00105047319
Iter: 1193 loss: 0.00104919658
Iter: 1194 loss: 0.00104513601
Iter: 1195 loss: 0.00107926689
Iter: 1196 loss: 0.00104488328
Iter: 1197 loss: 0.00104201899
Iter: 1198 loss: 0.00107544591
Iter: 1199 loss: 0.00104197743
Iter: 1200 loss: 0.00103998487
Iter: 1201 loss: 0.00105372304
Iter: 1202 loss: 0.00103978161
Iter: 1203 loss: 0.00103840558
Iter: 1204 loss: 0.00104543427
Iter: 1205 loss: 0.00103818206
Iter: 1206 loss: 0.00103706028
Iter: 1207 loss: 0.00103527762
Iter: 1208 loss: 0.00103526027
Iter: 1209 loss: 0.00103317539
Iter: 1210 loss: 0.0010305926
Iter: 1211 loss: 0.0010303657
Iter: 1212 loss: 0.00102612213
Iter: 1213 loss: 0.00103132112
Iter: 1214 loss: 0.00102391257
Iter: 1215 loss: 0.0010187882
Iter: 1216 loss: 0.00106517714
Iter: 1217 loss: 0.0010185485
Iter: 1218 loss: 0.00101552752
Iter: 1219 loss: 0.00102431304
Iter: 1220 loss: 0.00101456128
Iter: 1221 loss: 0.00101063
Iter: 1222 loss: 0.00101496722
Iter: 1223 loss: 0.00100850617
Iter: 1224 loss: 0.00100489275
Iter: 1225 loss: 0.0010017819
Iter: 1226 loss: 0.00100080157
Iter: 1227 loss: 0.000994950533
Iter: 1228 loss: 0.00103647436
Iter: 1229 loss: 0.000994439702
Iter: 1230 loss: 0.00099223922
Iter: 1231 loss: 0.000991981826
Iter: 1232 loss: 0.0009908129
Iter: 1233 loss: 0.000990814413
Iter: 1234 loss: 0.000989964
Iter: 1235 loss: 0.000990791828
Iter: 1236 loss: 0.000989465
Iter: 1237 loss: 0.000988172134
Iter: 1238 loss: 0.000986117171
Iter: 1239 loss: 0.000986097497
Iter: 1240 loss: 0.000984057435
Iter: 1241 loss: 0.000982843223
Iter: 1242 loss: 0.000981998513
Iter: 1243 loss: 0.000979197561
Iter: 1244 loss: 0.000987412175
Iter: 1245 loss: 0.000978320371
Iter: 1246 loss: 0.000975362433
Iter: 1247 loss: 0.000979206408
Iter: 1248 loss: 0.000973855902
Iter: 1249 loss: 0.000971295405
Iter: 1250 loss: 0.00100517552
Iter: 1251 loss: 0.000971282076
Iter: 1252 loss: 0.000969413435
Iter: 1253 loss: 0.000973740767
Iter: 1254 loss: 0.000968713255
Iter: 1255 loss: 0.000966558931
Iter: 1256 loss: 0.000966843334
Iter: 1257 loss: 0.000964920735
Iter: 1258 loss: 0.000962395337
Iter: 1259 loss: 0.000970195164
Iter: 1260 loss: 0.000961657322
Iter: 1261 loss: 0.000960452948
Iter: 1262 loss: 0.000960382924
Iter: 1263 loss: 0.000959702535
Iter: 1264 loss: 0.000968561275
Iter: 1265 loss: 0.000959700439
Iter: 1266 loss: 0.000959068129
Iter: 1267 loss: 0.000959463534
Iter: 1268 loss: 0.000958666787
Iter: 1269 loss: 0.00095752714
Iter: 1270 loss: 0.000955883472
Iter: 1271 loss: 0.00095583
Iter: 1272 loss: 0.000954322459
Iter: 1273 loss: 0.000954676885
Iter: 1274 loss: 0.000953213428
Iter: 1275 loss: 0.000951412949
Iter: 1276 loss: 0.000950034941
Iter: 1277 loss: 0.000949464738
Iter: 1278 loss: 0.000945914537
Iter: 1279 loss: 0.000960705918
Iter: 1280 loss: 0.000945147127
Iter: 1281 loss: 0.000942407933
Iter: 1282 loss: 0.000970866065
Iter: 1283 loss: 0.000942333136
Iter: 1284 loss: 0.000939858612
Iter: 1285 loss: 0.000945286592
Iter: 1286 loss: 0.000938922516
Iter: 1287 loss: 0.000936372089
Iter: 1288 loss: 0.00093783217
Iter: 1289 loss: 0.000934706244
Iter: 1290 loss: 0.000931689341
Iter: 1291 loss: 0.000932676
Iter: 1292 loss: 0.000929546542
Iter: 1293 loss: 0.000927866844
Iter: 1294 loss: 0.000927384594
Iter: 1295 loss: 0.00092578039
Iter: 1296 loss: 0.000936616329
Iter: 1297 loss: 0.000925627071
Iter: 1298 loss: 0.000924091088
Iter: 1299 loss: 0.000926113338
Iter: 1300 loss: 0.00092330022
Iter: 1301 loss: 0.000921304
Iter: 1302 loss: 0.000922519132
Iter: 1303 loss: 0.00092002959
Iter: 1304 loss: 0.00091832038
Iter: 1305 loss: 0.000914876466
Iter: 1306 loss: 0.000977254356
Iter: 1307 loss: 0.000914823788
Iter: 1308 loss: 0.000910482195
Iter: 1309 loss: 0.000922436826
Iter: 1310 loss: 0.000909046619
Iter: 1311 loss: 0.000904770859
Iter: 1312 loss: 0.000912250893
Iter: 1313 loss: 0.000902856758
Iter: 1314 loss: 0.000899116741
Iter: 1315 loss: 0.000930465118
Iter: 1316 loss: 0.000898897357
Iter: 1317 loss: 0.000895749312
Iter: 1318 loss: 0.000909936498
Iter: 1319 loss: 0.000895106234
Iter: 1320 loss: 0.000892591663
Iter: 1321 loss: 0.000894132187
Iter: 1322 loss: 0.000890991068
Iter: 1323 loss: 0.000887990405
Iter: 1324 loss: 0.000892746146
Iter: 1325 loss: 0.000886591617
Iter: 1326 loss: 0.000883515924
Iter: 1327 loss: 0.000896316953
Iter: 1328 loss: 0.000882881635
Iter: 1329 loss: 0.0008809992
Iter: 1330 loss: 0.000880894775
Iter: 1331 loss: 0.000879636034
Iter: 1332 loss: 0.000884051144
Iter: 1333 loss: 0.000879316824
Iter: 1334 loss: 0.000878142542
Iter: 1335 loss: 0.00087955629
Iter: 1336 loss: 0.00087751681
Iter: 1337 loss: 0.00087625481
Iter: 1338 loss: 0.000872908568
Iter: 1339 loss: 0.000898064813
Iter: 1340 loss: 0.00087220408
Iter: 1341 loss: 0.000868813135
Iter: 1342 loss: 0.000888862065
Iter: 1343 loss: 0.00086838461
Iter: 1344 loss: 0.000865380454
Iter: 1345 loss: 0.000868156087
Iter: 1346 loss: 0.000863649417
Iter: 1347 loss: 0.000860742701
Iter: 1348 loss: 0.000892716169
Iter: 1349 loss: 0.000860683736
Iter: 1350 loss: 0.000857983308
Iter: 1351 loss: 0.00087156042
Iter: 1352 loss: 0.000857552164
Iter: 1353 loss: 0.000855588121
Iter: 1354 loss: 0.000854297192
Iter: 1355 loss: 0.000853546313
Iter: 1356 loss: 0.000850927259
Iter: 1357 loss: 0.000852868077
Iter: 1358 loss: 0.000849316304
Iter: 1359 loss: 0.000846391893
Iter: 1360 loss: 0.000873909565
Iter: 1361 loss: 0.000846258132
Iter: 1362 loss: 0.000845299801
Iter: 1363 loss: 0.00084493187
Iter: 1364 loss: 0.000844171969
Iter: 1365 loss: 0.000845369184
Iter: 1366 loss: 0.000843806192
Iter: 1367 loss: 0.000842868234
Iter: 1368 loss: 0.000842841691
Iter: 1369 loss: 0.000842111593
Iter: 1370 loss: 0.000840736669
Iter: 1371 loss: 0.000837890431
Iter: 1372 loss: 0.000886588
Iter: 1373 loss: 0.000837827101
Iter: 1374 loss: 0.000835501414
Iter: 1375 loss: 0.000850309909
Iter: 1376 loss: 0.000835232669
Iter: 1377 loss: 0.000832876074
Iter: 1378 loss: 0.000833953149
Iter: 1379 loss: 0.000831271405
Iter: 1380 loss: 0.000828952761
Iter: 1381 loss: 0.000846670591
Iter: 1382 loss: 0.000828778
Iter: 1383 loss: 0.000827027368
Iter: 1384 loss: 0.000839653832
Iter: 1385 loss: 0.000826867588
Iter: 1386 loss: 0.000825360301
Iter: 1387 loss: 0.000824556686
Iter: 1388 loss: 0.000823872746
Iter: 1389 loss: 0.00082160352
Iter: 1390 loss: 0.000824649935
Iter: 1391 loss: 0.000820457179
Iter: 1392 loss: 0.000818485743
Iter: 1393 loss: 0.000843652932
Iter: 1394 loss: 0.000818468747
Iter: 1395 loss: 0.000817779102
Iter: 1396 loss: 0.00081765221
Iter: 1397 loss: 0.000817061518
Iter: 1398 loss: 0.000819076318
Iter: 1399 loss: 0.000816907617
Iter: 1400 loss: 0.000816263142
Iter: 1401 loss: 0.000815816689
Iter: 1402 loss: 0.000815584266
Iter: 1403 loss: 0.000814328319
Iter: 1404 loss: 0.000812139711
Iter: 1405 loss: 0.000812139246
Iter: 1406 loss: 0.000810586091
Iter: 1407 loss: 0.000810743542
Iter: 1408 loss: 0.00080938579
Iter: 1409 loss: 0.00080673187
Iter: 1410 loss: 0.000812141865
Iter: 1411 loss: 0.000805650139
Iter: 1412 loss: 0.000803448725
Iter: 1413 loss: 0.000815429958
Iter: 1414 loss: 0.000803121424
Iter: 1415 loss: 0.000801178452
Iter: 1416 loss: 0.000828457531
Iter: 1417 loss: 0.00080117688
Iter: 1418 loss: 0.0007998785
Iter: 1419 loss: 0.000797956192
Iter: 1420 loss: 0.000797910616
Iter: 1421 loss: 0.000795383588
Iter: 1422 loss: 0.00079783547
Iter: 1423 loss: 0.000793938118
Iter: 1424 loss: 0.000791531347
Iter: 1425 loss: 0.000812050537
Iter: 1426 loss: 0.000791388
Iter: 1427 loss: 0.000790489488
Iter: 1428 loss: 0.000790341583
Iter: 1429 loss: 0.000789569574
Iter: 1430 loss: 0.000791894214
Iter: 1431 loss: 0.000789327896
Iter: 1432 loss: 0.000788547331
Iter: 1433 loss: 0.000787641853
Iter: 1434 loss: 0.000787534576
Iter: 1435 loss: 0.000785839278
Iter: 1436 loss: 0.000785511
Iter: 1437 loss: 0.000784379197
Iter: 1438 loss: 0.000782969408
Iter: 1439 loss: 0.000782116491
Iter: 1440 loss: 0.000781531562
Iter: 1441 loss: 0.000779249473
Iter: 1442 loss: 0.00079228665
Iter: 1443 loss: 0.000778940564
Iter: 1444 loss: 0.000777067617
Iter: 1445 loss: 0.000777033274
Iter: 1446 loss: 0.000775558816
Iter: 1447 loss: 0.000773665321
Iter: 1448 loss: 0.000773587206
Iter: 1449 loss: 0.000772166
Iter: 1450 loss: 0.000772144878
Iter: 1451 loss: 0.000771023799
Iter: 1452 loss: 0.00076948
Iter: 1453 loss: 0.000771959429
Iter: 1454 loss: 0.000768764294
Iter: 1455 loss: 0.000767587684
Iter: 1456 loss: 0.000773014035
Iter: 1457 loss: 0.000767368299
Iter: 1458 loss: 0.000766634592
Iter: 1459 loss: 0.000766541576
Iter: 1460 loss: 0.000765894772
Iter: 1461 loss: 0.000768654456
Iter: 1462 loss: 0.000765766948
Iter: 1463 loss: 0.000765268749
Iter: 1464 loss: 0.000764898141
Iter: 1465 loss: 0.00076472928
Iter: 1466 loss: 0.000763794058
Iter: 1467 loss: 0.000763658667
Iter: 1468 loss: 0.000763001037
Iter: 1469 loss: 0.000762079493
Iter: 1470 loss: 0.000760153402
Iter: 1471 loss: 0.000792214414
Iter: 1472 loss: 0.000760103518
Iter: 1473 loss: 0.000757564907
Iter: 1474 loss: 0.000772421074
Iter: 1475 loss: 0.000757222937
Iter: 1476 loss: 0.000755158719
Iter: 1477 loss: 0.000762113486
Iter: 1478 loss: 0.000754595385
Iter: 1479 loss: 0.000753120054
Iter: 1480 loss: 0.000771495397
Iter: 1481 loss: 0.000753107
Iter: 1482 loss: 0.00075188349
Iter: 1483 loss: 0.000752264867
Iter: 1484 loss: 0.000751005777
Iter: 1485 loss: 0.000749581493
Iter: 1486 loss: 0.000753916
Iter: 1487 loss: 0.00074915291
Iter: 1488 loss: 0.000747510639
Iter: 1489 loss: 0.000748882303
Iter: 1490 loss: 0.000746524078
Iter: 1491 loss: 0.000745153171
Iter: 1492 loss: 0.000765212
Iter: 1493 loss: 0.00074515189
Iter: 1494 loss: 0.000744294142
Iter: 1495 loss: 0.000745726051
Iter: 1496 loss: 0.000743899203
Iter: 1497 loss: 0.000743013225
Iter: 1498 loss: 0.000741464552
Iter: 1499 loss: 0.000741463271
Iter: 1500 loss: 0.000739272917
Iter: 1501 loss: 0.000754895213
Iter: 1502 loss: 0.000739074312
Iter: 1503 loss: 0.000738203642
Iter: 1504 loss: 0.000736651826
Iter: 1505 loss: 0.000774645712
Iter: 1506 loss: 0.00073665136
Iter: 1507 loss: 0.000735137379
Iter: 1508 loss: 0.000735209207
Iter: 1509 loss: 0.000733948662
Iter: 1510 loss: 0.000731800857
Iter: 1511 loss: 0.000744359219
Iter: 1512 loss: 0.000731517
Iter: 1513 loss: 0.000730125699
Iter: 1514 loss: 0.000736019108
Iter: 1515 loss: 0.000729831285
Iter: 1516 loss: 0.000728906947
Iter: 1517 loss: 0.00072889647
Iter: 1518 loss: 0.000728492916
Iter: 1519 loss: 0.000727866543
Iter: 1520 loss: 0.000727856823
Iter: 1521 loss: 0.000727044651
Iter: 1522 loss: 0.000726165
Iter: 1523 loss: 0.000726028462
Iter: 1524 loss: 0.000725722755
Iter: 1525 loss: 0.000725675665
Iter: 1526 loss: 0.00072542578
Iter: 1527 loss: 0.000724691665
Iter: 1528 loss: 0.00072753086
Iter: 1529 loss: 0.000724385551
Iter: 1530 loss: 0.000723076519
Iter: 1531 loss: 0.000723666453
Iter: 1532 loss: 0.000722182
Iter: 1533 loss: 0.000721598626
Iter: 1534 loss: 0.000721389777
Iter: 1535 loss: 0.000721061137
Iter: 1536 loss: 0.000719666947
Iter: 1537 loss: 0.000717062503
Iter: 1538 loss: 0.000777880894
Iter: 1539 loss: 0.00071706
Iter: 1540 loss: 0.000713513349
Iter: 1541 loss: 0.000726706348
Iter: 1542 loss: 0.000712640409
Iter: 1543 loss: 0.000710238237
Iter: 1544 loss: 0.000723135658
Iter: 1545 loss: 0.000709884916
Iter: 1546 loss: 0.000708702602
Iter: 1547 loss: 0.000707932515
Iter: 1548 loss: 0.000707472209
Iter: 1549 loss: 0.000706411549
Iter: 1550 loss: 0.000707665225
Iter: 1551 loss: 0.000705849496
Iter: 1552 loss: 0.000704896753
Iter: 1553 loss: 0.000702969497
Iter: 1554 loss: 0.000739385
Iter: 1555 loss: 0.00070294278
Iter: 1556 loss: 0.000700849923
Iter: 1557 loss: 0.00072315085
Iter: 1558 loss: 0.0007008
Iter: 1559 loss: 0.000702052785
Iter: 1560 loss: 0.000700161851
Iter: 1561 loss: 0.000699593453
Iter: 1562 loss: 0.00069928437
Iter: 1563 loss: 0.000699030177
Iter: 1564 loss: 0.000697978772
Iter: 1565 loss: 0.000698882097
Iter: 1566 loss: 0.000697352458
Iter: 1567 loss: 0.000696346338
Iter: 1568 loss: 0.000695178751
Iter: 1569 loss: 0.000695040566
Iter: 1570 loss: 0.000693330192
Iter: 1571 loss: 0.000694227288
Iter: 1572 loss: 0.000692195958
Iter: 1573 loss: 0.000690338493
Iter: 1574 loss: 0.000689207867
Iter: 1575 loss: 0.000688447384
Iter: 1576 loss: 0.000686627289
Iter: 1577 loss: 0.000707888161
Iter: 1578 loss: 0.000686602085
Iter: 1579 loss: 0.000685761
Iter: 1580 loss: 0.00068574422
Iter: 1581 loss: 0.000685049454
Iter: 1582 loss: 0.000684476458
Iter: 1583 loss: 0.000684274244
Iter: 1584 loss: 0.000682816841
Iter: 1585 loss: 0.00068010611
Iter: 1586 loss: 0.000743455195
Iter: 1587 loss: 0.000680102268
Iter: 1588 loss: 0.000677980366
Iter: 1589 loss: 0.000696070958
Iter: 1590 loss: 0.000677869655
Iter: 1591 loss: 0.000675958116
Iter: 1592 loss: 0.000675622548
Iter: 1593 loss: 0.00067432283
Iter: 1594 loss: 0.000677369186
Iter: 1595 loss: 0.0006738191
Iter: 1596 loss: 0.000673257862
Iter: 1597 loss: 0.00067210081
Iter: 1598 loss: 0.000693048816
Iter: 1599 loss: 0.000672078808
Iter: 1600 loss: 0.000670713955
Iter: 1601 loss: 0.000672063208
Iter: 1602 loss: 0.000669940899
Iter: 1603 loss: 0.000668665336
Iter: 1604 loss: 0.000675118761
Iter: 1605 loss: 0.000668441528
Iter: 1606 loss: 0.000666651758
Iter: 1607 loss: 0.000664541149
Iter: 1608 loss: 0.000664305175
Iter: 1609 loss: 0.000664109364
Iter: 1610 loss: 0.000663130078
Iter: 1611 loss: 0.000662331935
Iter: 1612 loss: 0.000662149047
Iter: 1613 loss: 0.000661642174
Iter: 1614 loss: 0.000660724705
Iter: 1615 loss: 0.000662540551
Iter: 1616 loss: 0.000660337042
Iter: 1617 loss: 0.000659548794
Iter: 1618 loss: 0.000658568228
Iter: 1619 loss: 0.000658485922
Iter: 1620 loss: 0.000656519958
Iter: 1621 loss: 0.000663992774
Iter: 1622 loss: 0.000656052725
Iter: 1623 loss: 0.000654587697
Iter: 1624 loss: 0.000656591379
Iter: 1625 loss: 0.000653866795
Iter: 1626 loss: 0.000653583673
Iter: 1627 loss: 0.000653385301
Iter: 1628 loss: 0.000652822
Iter: 1629 loss: 0.000652882038
Iter: 1630 loss: 0.000652388902
Iter: 1631 loss: 0.000651491689
Iter: 1632 loss: 0.000652061775
Iter: 1633 loss: 0.000650923117
Iter: 1634 loss: 0.00064975163
Iter: 1635 loss: 0.00065355323
Iter: 1636 loss: 0.000649423921
Iter: 1637 loss: 0.000647853361
Iter: 1638 loss: 0.000650541
Iter: 1639 loss: 0.000647150795
Iter: 1640 loss: 0.000646011496
Iter: 1641 loss: 0.000644887565
Iter: 1642 loss: 0.000644652871
Iter: 1643 loss: 0.000643536798
Iter: 1644 loss: 0.000643340056
Iter: 1645 loss: 0.000642509316
Iter: 1646 loss: 0.000653967145
Iter: 1647 loss: 0.000642506522
Iter: 1648 loss: 0.000641784747
Iter: 1649 loss: 0.000639882172
Iter: 1650 loss: 0.000653797062
Iter: 1651 loss: 0.000639475067
Iter: 1652 loss: 0.000637609046
Iter: 1653 loss: 0.00065031182
Iter: 1654 loss: 0.00063742476
Iter: 1655 loss: 0.00063612184
Iter: 1656 loss: 0.000637415273
Iter: 1657 loss: 0.000635391
Iter: 1658 loss: 0.000633814954
Iter: 1659 loss: 0.000635068689
Iter: 1660 loss: 0.000632867
Iter: 1661 loss: 0.000633552438
Iter: 1662 loss: 0.000632225303
Iter: 1663 loss: 0.00063161226
Iter: 1664 loss: 0.000630087743
Iter: 1665 loss: 0.000645060558
Iter: 1666 loss: 0.0006298878
Iter: 1667 loss: 0.000628800364
Iter: 1668 loss: 0.000630020921
Iter: 1669 loss: 0.0006282127
Iter: 1670 loss: 0.000626794354
Iter: 1671 loss: 0.00063503976
Iter: 1672 loss: 0.000626613037
Iter: 1673 loss: 0.000625598594
Iter: 1674 loss: 0.000627992
Iter: 1675 loss: 0.000625226297
Iter: 1676 loss: 0.00062415679
Iter: 1677 loss: 0.000626317342
Iter: 1678 loss: 0.000623721106
Iter: 1679 loss: 0.000623392407
Iter: 1680 loss: 0.000623063126
Iter: 1681 loss: 0.00062258821
Iter: 1682 loss: 0.000622035703
Iter: 1683 loss: 0.000621972373
Iter: 1684 loss: 0.000620948558
Iter: 1685 loss: 0.000618746039
Iter: 1686 loss: 0.000654006726
Iter: 1687 loss: 0.00061867066
Iter: 1688 loss: 0.000616382691
Iter: 1689 loss: 0.000625635148
Iter: 1690 loss: 0.000615874364
Iter: 1691 loss: 0.000613915094
Iter: 1692 loss: 0.000620013219
Iter: 1693 loss: 0.00061335566
Iter: 1694 loss: 0.000612952339
Iter: 1695 loss: 0.000612818345
Iter: 1696 loss: 0.000612385047
Iter: 1697 loss: 0.000611378
Iter: 1698 loss: 0.000623926753
Iter: 1699 loss: 0.000611301628
Iter: 1700 loss: 0.000610051909
Iter: 1701 loss: 0.000612136
Iter: 1702 loss: 0.000609490206
Iter: 1703 loss: 0.00060858205
Iter: 1704 loss: 0.000607091584
Iter: 1705 loss: 0.000607085414
Iter: 1706 loss: 0.000605157577
Iter: 1707 loss: 0.000634573167
Iter: 1708 loss: 0.000605156471
Iter: 1709 loss: 0.00060406985
Iter: 1710 loss: 0.000607588154
Iter: 1711 loss: 0.00060376944
Iter: 1712 loss: 0.000603105291
Iter: 1713 loss: 0.000603088818
Iter: 1714 loss: 0.000602221116
Iter: 1715 loss: 0.000602131069
Iter: 1716 loss: 0.000601498585
Iter: 1717 loss: 0.000600707
Iter: 1718 loss: 0.000599459
Iter: 1719 loss: 0.000599446066
Iter: 1720 loss: 0.000598320214
Iter: 1721 loss: 0.000604629167
Iter: 1722 loss: 0.00059816445
Iter: 1723 loss: 0.000597367121
Iter: 1724 loss: 0.000598637853
Iter: 1725 loss: 0.000597002509
Iter: 1726 loss: 0.000596337253
Iter: 1727 loss: 0.00060639414
Iter: 1728 loss: 0.000596337952
Iter: 1729 loss: 0.000595580088
Iter: 1730 loss: 0.000596001453
Iter: 1731 loss: 0.000595089514
Iter: 1732 loss: 0.000594392186
Iter: 1733 loss: 0.000592979253
Iter: 1734 loss: 0.000618614897
Iter: 1735 loss: 0.000592953525
Iter: 1736 loss: 0.000591401767
Iter: 1737 loss: 0.000595945399
Iter: 1738 loss: 0.000590922835
Iter: 1739 loss: 0.000589201925
Iter: 1740 loss: 0.000599725812
Iter: 1741 loss: 0.000588989
Iter: 1742 loss: 0.000587689574
Iter: 1743 loss: 0.000589324452
Iter: 1744 loss: 0.000587018905
Iter: 1745 loss: 0.000585490081
Iter: 1746 loss: 0.000590557465
Iter: 1747 loss: 0.000585069414
Iter: 1748 loss: 0.000585121452
Iter: 1749 loss: 0.000584699446
Iter: 1750 loss: 0.000584198511
Iter: 1751 loss: 0.000583194778
Iter: 1752 loss: 0.000602939283
Iter: 1753 loss: 0.000583183893
Iter: 1754 loss: 0.000582559733
Iter: 1755 loss: 0.000581953907
Iter: 1756 loss: 0.000581820263
Iter: 1757 loss: 0.00058085029
Iter: 1758 loss: 0.000580425782
Iter: 1759 loss: 0.000579931075
Iter: 1760 loss: 0.000578874839
Iter: 1761 loss: 0.000578860869
Iter: 1762 loss: 0.000578254636
Iter: 1763 loss: 0.000586244103
Iter: 1764 loss: 0.000578251726
Iter: 1765 loss: 0.000577770232
Iter: 1766 loss: 0.000576518534
Iter: 1767 loss: 0.000586748705
Iter: 1768 loss: 0.000576296
Iter: 1769 loss: 0.000575127196
Iter: 1770 loss: 0.000585083209
Iter: 1771 loss: 0.000575063052
Iter: 1772 loss: 0.000574463746
Iter: 1773 loss: 0.000573993952
Iter: 1774 loss: 0.000573805824
Iter: 1775 loss: 0.00057313859
Iter: 1776 loss: 0.000573485566
Iter: 1777 loss: 0.000572700403
Iter: 1778 loss: 0.000572379387
Iter: 1779 loss: 0.00057164696
Iter: 1780 loss: 0.000581420725
Iter: 1781 loss: 0.000571601617
Iter: 1782 loss: 0.000570985372
Iter: 1783 loss: 0.000572609832
Iter: 1784 loss: 0.000570778502
Iter: 1785 loss: 0.000570170814
Iter: 1786 loss: 0.000570619595
Iter: 1787 loss: 0.000569797179
Iter: 1788 loss: 0.000568746706
Iter: 1789 loss: 0.00057016185
Iter: 1790 loss: 0.000568223593
Iter: 1791 loss: 0.000567066425
Iter: 1792 loss: 0.000569781638
Iter: 1793 loss: 0.000566640287
Iter: 1794 loss: 0.000565348892
Iter: 1795 loss: 0.000565860071
Iter: 1796 loss: 0.000564453658
Iter: 1797 loss: 0.000563214184
Iter: 1798 loss: 0.000575155
Iter: 1799 loss: 0.000563170412
Iter: 1800 loss: 0.000561935303
Iter: 1801 loss: 0.000569833966
Iter: 1802 loss: 0.000561793393
Iter: 1803 loss: 0.000561299443
Iter: 1804 loss: 0.000561204855
Iter: 1805 loss: 0.000560874469
Iter: 1806 loss: 0.000560265267
Iter: 1807 loss: 0.000559260545
Iter: 1808 loss: 0.000559257343
Iter: 1809 loss: 0.000558611704
Iter: 1810 loss: 0.000558596337
Iter: 1811 loss: 0.000558337721
Iter: 1812 loss: 0.000558309141
Iter: 1813 loss: 0.000557993
Iter: 1814 loss: 0.000557298947
Iter: 1815 loss: 0.000567624
Iter: 1816 loss: 0.000557270949
Iter: 1817 loss: 0.000556660583
Iter: 1818 loss: 0.000559426495
Iter: 1819 loss: 0.000556543295
Iter: 1820 loss: 0.000556102663
Iter: 1821 loss: 0.000557528343
Iter: 1822 loss: 0.000555979961
Iter: 1823 loss: 0.00055552338
Iter: 1824 loss: 0.000554688624
Iter: 1825 loss: 0.000574164384
Iter: 1826 loss: 0.000554686063
Iter: 1827 loss: 0.000553716
Iter: 1828 loss: 0.000561182853
Iter: 1829 loss: 0.000553639431
Iter: 1830 loss: 0.000552826
Iter: 1831 loss: 0.000553270103
Iter: 1832 loss: 0.00055228814
Iter: 1833 loss: 0.00055231
Iter: 1834 loss: 0.000551831501
Iter: 1835 loss: 0.00055138208
Iter: 1836 loss: 0.000550102792
Iter: 1837 loss: 0.000556379033
Iter: 1838 loss: 0.000549662451
Iter: 1839 loss: 0.000547957141
Iter: 1840 loss: 0.000553195132
Iter: 1841 loss: 0.000547456089
Iter: 1842 loss: 0.000546319934
Iter: 1843 loss: 0.000544947048
Iter: 1844 loss: 0.000544816954
Iter: 1845 loss: 0.000545559393
Iter: 1846 loss: 0.00054425135
Iter: 1847 loss: 0.000543758739
Iter: 1848 loss: 0.000545724353
Iter: 1849 loss: 0.000543646747
Iter: 1850 loss: 0.000543034519
Iter: 1851 loss: 0.000545748509
Iter: 1852 loss: 0.000542918
Iter: 1853 loss: 0.000542160706
Iter: 1854 loss: 0.000541742891
Iter: 1855 loss: 0.000541407091
Iter: 1856 loss: 0.000540409121
Iter: 1857 loss: 0.000540512439
Iter: 1858 loss: 0.000539643399
Iter: 1859 loss: 0.000537794782
Iter: 1860 loss: 0.000541282876
Iter: 1861 loss: 0.000537009095
Iter: 1862 loss: 0.000535754603
Iter: 1863 loss: 0.000535652332
Iter: 1864 loss: 0.000534719089
Iter: 1865 loss: 0.000534686842
Iter: 1866 loss: 0.000534052728
Iter: 1867 loss: 0.000533578568
Iter: 1868 loss: 0.000532568
Iter: 1869 loss: 0.000548428739
Iter: 1870 loss: 0.000532533333
Iter: 1871 loss: 0.000531612313
Iter: 1872 loss: 0.000533794228
Iter: 1873 loss: 0.00053127564
Iter: 1874 loss: 0.000530274934
Iter: 1875 loss: 0.000529861427
Iter: 1876 loss: 0.000529335579
Iter: 1877 loss: 0.000528499542
Iter: 1878 loss: 0.000528496283
Iter: 1879 loss: 0.000527695345
Iter: 1880 loss: 0.000532869541
Iter: 1881 loss: 0.000527604483
Iter: 1882 loss: 0.000527147553
Iter: 1883 loss: 0.000527160591
Iter: 1884 loss: 0.000526785618
Iter: 1885 loss: 0.000526546733
Iter: 1886 loss: 0.00052634225
Iter: 1887 loss: 0.000526022108
Iter: 1888 loss: 0.000525272044
Iter: 1889 loss: 0.000534297666
Iter: 1890 loss: 0.000525207142
Iter: 1891 loss: 0.000524531759
Iter: 1892 loss: 0.000523781
Iter: 1893 loss: 0.000523677096
Iter: 1894 loss: 0.00052262051
Iter: 1895 loss: 0.000523007067
Iter: 1896 loss: 0.000521879469
Iter: 1897 loss: 0.00052102044
Iter: 1898 loss: 0.000529992045
Iter: 1899 loss: 0.000520996517
Iter: 1900 loss: 0.000520681439
Iter: 1901 loss: 0.000520671427
Iter: 1902 loss: 0.000520316768
Iter: 1903 loss: 0.000519563677
Iter: 1904 loss: 0.000531587051
Iter: 1905 loss: 0.000519537425
Iter: 1906 loss: 0.000518839341
Iter: 1907 loss: 0.000520441099
Iter: 1908 loss: 0.000518577872
Iter: 1909 loss: 0.00051805051
Iter: 1910 loss: 0.000519702677
Iter: 1911 loss: 0.00051789725
Iter: 1912 loss: 0.000517285895
Iter: 1913 loss: 0.000523527153
Iter: 1914 loss: 0.00051726948
Iter: 1915 loss: 0.000516896544
Iter: 1916 loss: 0.000516030937
Iter: 1917 loss: 0.000526967
Iter: 1918 loss: 0.000515966618
Iter: 1919 loss: 0.000515129941
Iter: 1920 loss: 0.000519957102
Iter: 1921 loss: 0.00051501795
Iter: 1922 loss: 0.000514145358
Iter: 1923 loss: 0.000515320105
Iter: 1924 loss: 0.000513713225
Iter: 1925 loss: 0.00051323924
Iter: 1926 loss: 0.000513068866
Iter: 1927 loss: 0.000512896
Iter: 1928 loss: 0.000512427476
Iter: 1929 loss: 0.000515372
Iter: 1930 loss: 0.000512307626
Iter: 1931 loss: 0.000511721
Iter: 1932 loss: 0.000512250292
Iter: 1933 loss: 0.000511378108
Iter: 1934 loss: 0.000511041377
Iter: 1935 loss: 0.00051089609
Iter: 1936 loss: 0.000510723097
Iter: 1937 loss: 0.00051022484
Iter: 1938 loss: 0.000513707055
Iter: 1939 loss: 0.000510177459
Iter: 1940 loss: 0.000509722508
Iter: 1941 loss: 0.000509305275
Iter: 1942 loss: 0.000509192818
Iter: 1943 loss: 0.000508654
Iter: 1944 loss: 0.000509484264
Iter: 1945 loss: 0.000508401834
Iter: 1946 loss: 0.000508038851
Iter: 1947 loss: 0.000507969584
Iter: 1948 loss: 0.000507591118
Iter: 1949 loss: 0.000507245713
Iter: 1950 loss: 0.000507154968
Iter: 1951 loss: 0.000506742275
Iter: 1952 loss: 0.000507189485
Iter: 1953 loss: 0.000506517594
Iter: 1954 loss: 0.000506059383
Iter: 1955 loss: 0.000507274759
Iter: 1956 loss: 0.000505902455
Iter: 1957 loss: 0.000505474804
Iter: 1958 loss: 0.000508122204
Iter: 1959 loss: 0.000505423523
Iter: 1960 loss: 0.000504882541
Iter: 1961 loss: 0.000505383126
Iter: 1962 loss: 0.000504568685
Iter: 1963 loss: 0.000504174212
Iter: 1964 loss: 0.000505609671
Iter: 1965 loss: 0.00050407456
Iter: 1966 loss: 0.000503724965
Iter: 1967 loss: 0.000503805
Iter: 1968 loss: 0.000503470656
Iter: 1969 loss: 0.000503079733
Iter: 1970 loss: 0.000504765252
Iter: 1971 loss: 0.0005030022
Iter: 1972 loss: 0.000502530369
Iter: 1973 loss: 0.000503450749
Iter: 1974 loss: 0.000502334326
Iter: 1975 loss: 0.000501912669
Iter: 1976 loss: 0.00050087925
Iter: 1977 loss: 0.000511378807
Iter: 1978 loss: 0.000500754628
Iter: 1979 loss: 0.000500119873
Iter: 1980 loss: 0.000500042224
Iter: 1981 loss: 0.000499127316
Iter: 1982 loss: 0.000499631162
Iter: 1983 loss: 0.000498528942
Iter: 1984 loss: 0.000497779634
Iter: 1985 loss: 0.00049812
Iter: 1986 loss: 0.000497272704
Iter: 1987 loss: 0.000496459892
Iter: 1988 loss: 0.000495634333
Iter: 1989 loss: 0.000495474553
Iter: 1990 loss: 0.000495216635
Iter: 1991 loss: 0.000494740263
Iter: 1992 loss: 0.000494255801
Iter: 1993 loss: 0.00049727282
Iter: 1994 loss: 0.000494200387
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3
+ date
Tue Oct 27 19:29:09 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f1 --psi 1 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b9410dea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6bb9a61d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6bb9a61ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6bb9a61bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b94094730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b940adae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b9401bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b9404b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b9404e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b807d3378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b807909d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80750400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80758378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80777c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80735a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80735510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b806c38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80758400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b806a8378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80676d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80676158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b806798c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b805e2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80589950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b8058db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b805b7d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80573598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b8050f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b8050fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b804bd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b804e2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b804a77b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80499620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b804a7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80407598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6b80407ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0353861488
Iter: 2 loss: 2.31195307
Iter: 3 loss: 2.30361271
Iter: 4 loss: 1.65786219
Iter: 5 loss: 1.65051472
Iter: 6 loss: 1.20177162
Iter: 7 loss: 1.19403481
Iter: 8 loss: 0.86743325
Iter: 9 loss: 0.859067559
Iter: 10 loss: 0.615189672
Iter: 11 loss: 0.605043054
Iter: 12 loss: 0.412577868
Iter: 13 loss: 0.399633229
Iter: 14 loss: 0.253936291
Iter: 15 loss: 0.239905387
Iter: 16 loss: 0.138612181
Iter: 17 loss: 0.125019848
Iter: 18 loss: 0.0622882731
Iter: 19 loss: 0.053343
Iter: 20 loss: 0.0256280452
Iter: 21 loss: 0.0230908133
Iter: 22 loss: 0.0209071189
Iter: 23 loss: 0.0150503758
Iter: 24 loss: 880.909363
Iter: 25 loss: 4344.50146
Iter: 26 loss: 0.0150412954
Iter: 27 loss: 0.015077943
Iter: 28 loss: 0.01361119
Iter: 29 loss: 0.0134093203
Iter: 30 loss: 0.0111701768
Iter: 31 loss: 0.0111286342
Iter: 32 loss: 0.00864642952
Iter: 33 loss: 0.0166188627
Iter: 34 loss: 0.00856269896
Iter: 35 loss: 0.00775505789
Iter: 36 loss: 0.0455185845
Iter: 37 loss: 0.00773948478
Iter: 38 loss: 0.00728548272
Iter: 39 loss: 0.0148867555
Iter: 40 loss: 0.00726738
Iter: 41 loss: 0.00692189438
Iter: 42 loss: 0.00765819103
Iter: 43 loss: 0.00682064565
Iter: 44 loss: 0.00642898493
Iter: 45 loss: 0.00670134
Iter: 46 loss: 0.00623049913
Iter: 47 loss: 0.00584345264
Iter: 48 loss: 0.00607613754
Iter: 49 loss: 0.00556351524
Iter: 50 loss: 0.00529414695
Iter: 51 loss: 0.00496439449
Iter: 52 loss: 0.00494099734
Iter: 53 loss: 0.00426305085
Iter: 54 loss: 0.00632622838
Iter: 55 loss: 0.00407489389
Iter: 56 loss: 0.00367847015
Iter: 57 loss: 0.00776222628
Iter: 58 loss: 0.00366624887
Iter: 59 loss: 0.00344661134
Iter: 60 loss: 0.00357881468
Iter: 61 loss: 0.00329750543
Iter: 62 loss: 0.00309578865
Iter: 63 loss: 0.00383586623
Iter: 64 loss: 0.0030529669
Iter: 65 loss: 0.0028603347
Iter: 66 loss: 0.00357077667
Iter: 67 loss: 0.00282069715
Iter: 68 loss: 0.00270556868
Iter: 69 loss: 0.00267864484
Iter: 70 loss: 0.00260601752
Iter: 71 loss: 0.00247060927
Iter: 72 loss: 0.00272155018
Iter: 73 loss: 0.00241158274
Iter: 74 loss: 0.0023899097
Iter: 75 loss: 0.00234159641
Iter: 76 loss: 0.00229629269
Iter: 77 loss: 0.00220714952
Iter: 78 loss: 0.00476617459
Iter: 79 loss: 0.00220669759
Iter: 80 loss: 0.00207469566
Iter: 81 loss: 0.00219410099
Iter: 82 loss: 0.0019993654
Iter: 83 loss: 0.00194353552
Iter: 84 loss: 0.00193031481
Iter: 85 loss: 0.00187128945
Iter: 86 loss: 0.00187698123
Iter: 87 loss: 0.00182344951
Iter: 88 loss: 0.00175273116
Iter: 89 loss: 0.00178780314
Iter: 90 loss: 0.00170462194
Iter: 91 loss: 0.00163098378
Iter: 92 loss: 0.00179967773
Iter: 93 loss: 0.00160592981
Iter: 94 loss: 0.00153639121
Iter: 95 loss: 0.00177471503
Iter: 96 loss: 0.00151757477
Iter: 97 loss: 0.00145830098
Iter: 98 loss: 0.00157569454
Iter: 99 loss: 0.00143400778
Iter: 100 loss: 0.0013681401
Iter: 101 loss: 0.00151151465
Iter: 102 loss: 0.00134349754
Iter: 103 loss: 0.00129240949
Iter: 104 loss: 0.0013160489
Iter: 105 loss: 0.00125932309
Iter: 106 loss: 0.00128057657
Iter: 107 loss: 0.00123894331
Iter: 108 loss: 0.00121940055
Iter: 109 loss: 0.00121064356
Iter: 110 loss: 0.00120073056
Iter: 111 loss: 0.00115995901
Iter: 112 loss: 0.00118679344
Iter: 113 loss: 0.00113463984
Iter: 114 loss: 0.00111402874
Iter: 115 loss: 0.00111789326
Iter: 116 loss: 0.00109808287
Iter: 117 loss: 0.00107361609
Iter: 118 loss: 0.00110522984
Iter: 119 loss: 0.00106111472
Iter: 120 loss: 0.00102954637
Iter: 121 loss: 0.00105118041
Iter: 122 loss: 0.00101052888
Iter: 123 loss: 0.000985963619
Iter: 124 loss: 0.000982406316
Iter: 125 loss: 0.000964721199
Iter: 126 loss: 0.000952013419
Iter: 127 loss: 0.000946555112
Iter: 128 loss: 0.000940088357
Iter: 129 loss: 0.000916523917
Iter: 130 loss: 0.00091387087
Iter: 131 loss: 0.000896759331
Iter: 132 loss: 0.000872859615
Iter: 133 loss: 0.00109591463
Iter: 134 loss: 0.000871901168
Iter: 135 loss: 0.000853054633
Iter: 136 loss: 0.000865587092
Iter: 137 loss: 0.000841100642
Iter: 138 loss: 0.000818355358
Iter: 139 loss: 0.000950791815
Iter: 140 loss: 0.0008156572
Iter: 141 loss: 0.000798395136
Iter: 142 loss: 0.00105030346
Iter: 143 loss: 0.000798318302
Iter: 144 loss: 0.000785830489
Iter: 145 loss: 0.000824163086
Iter: 146 loss: 0.000782345422
Iter: 147 loss: 0.000775922672
Iter: 148 loss: 0.000775863
Iter: 149 loss: 0.000771115767
Iter: 150 loss: 0.00075937435
Iter: 151 loss: 0.000870838063
Iter: 152 loss: 0.000757831382
Iter: 153 loss: 0.000743073
Iter: 154 loss: 0.000852816796
Iter: 155 loss: 0.000741860364
Iter: 156 loss: 0.000729966094
Iter: 157 loss: 0.000746496255
Iter: 158 loss: 0.000724059413
Iter: 159 loss: 0.000726217462
Iter: 160 loss: 0.00071805343
Iter: 161 loss: 0.000713964342
Iter: 162 loss: 0.000706937513
Iter: 163 loss: 0.00070692692
Iter: 164 loss: 0.000698953401
Iter: 165 loss: 0.000707799685
Iter: 166 loss: 0.000694697257
Iter: 167 loss: 0.000687569205
Iter: 168 loss: 0.000683849212
Iter: 169 loss: 0.000680589816
Iter: 170 loss: 0.000670230133
Iter: 171 loss: 0.000753341
Iter: 172 loss: 0.000669503934
Iter: 173 loss: 0.000663408369
Iter: 174 loss: 0.000668173889
Iter: 175 loss: 0.000659698911
Iter: 176 loss: 0.00065500394
Iter: 177 loss: 0.000654126285
Iter: 178 loss: 0.000650264556
Iter: 179 loss: 0.000663692306
Iter: 180 loss: 0.000649214722
Iter: 181 loss: 0.000644077081
Iter: 182 loss: 0.000656597782
Iter: 183 loss: 0.000642279163
Iter: 184 loss: 0.000638194
Iter: 185 loss: 0.000633066
Iter: 186 loss: 0.000632650161
Iter: 187 loss: 0.000625569839
Iter: 188 loss: 0.000654988922
Iter: 189 loss: 0.000624026055
Iter: 190 loss: 0.000621339539
Iter: 191 loss: 0.000620390405
Iter: 192 loss: 0.000616715522
Iter: 193 loss: 0.000634104537
Iter: 194 loss: 0.000616014702
Iter: 195 loss: 0.00061371387
Iter: 196 loss: 0.00060899544
Iter: 197 loss: 0.000691770692
Iter: 198 loss: 0.000608904404
Iter: 199 loss: 0.000603404245
Iter: 200 loss: 0.00061137788
Iter: 201 loss: 0.000600756088
Iter: 202 loss: 0.000594332931
Iter: 203 loss: 0.000602755172
Iter: 204 loss: 0.000591095246
Iter: 205 loss: 0.000586324779
Iter: 206 loss: 0.000624436769
Iter: 207 loss: 0.000586002949
Iter: 208 loss: 0.000582765439
Iter: 209 loss: 0.000591921329
Iter: 210 loss: 0.000581753
Iter: 211 loss: 0.000578449224
Iter: 212 loss: 0.000617499347
Iter: 213 loss: 0.000578397186
Iter: 214 loss: 0.000575914106
Iter: 215 loss: 0.000578089093
Iter: 216 loss: 0.000574473524
Iter: 217 loss: 0.000572126
Iter: 218 loss: 0.000567434821
Iter: 219 loss: 0.000657824043
Iter: 220 loss: 0.000567377545
Iter: 221 loss: 0.000562655739
Iter: 222 loss: 0.000560696353
Iter: 223 loss: 0.000558225205
Iter: 224 loss: 0.000553580234
Iter: 225 loss: 0.000604224915
Iter: 226 loss: 0.000553499849
Iter: 227 loss: 0.000551564619
Iter: 228 loss: 0.000551078818
Iter: 229 loss: 0.000549335615
Iter: 230 loss: 0.000546344614
Iter: 231 loss: 0.000546341646
Iter: 232 loss: 0.000543428061
Iter: 233 loss: 0.000546403928
Iter: 234 loss: 0.00054179877
Iter: 235 loss: 0.000538143795
Iter: 236 loss: 0.000548298063
Iter: 237 loss: 0.000536968349
Iter: 238 loss: 0.000533553888
Iter: 239 loss: 0.000549904071
Iter: 240 loss: 0.000532944105
Iter: 241 loss: 0.000529698795
Iter: 242 loss: 0.000531893224
Iter: 243 loss: 0.000527655124
Iter: 244 loss: 0.000524001545
Iter: 245 loss: 0.000547013711
Iter: 246 loss: 0.000523569528
Iter: 247 loss: 0.000523056951
Iter: 248 loss: 0.000522018236
Iter: 249 loss: 0.000521234586
Iter: 250 loss: 0.000518954941
Iter: 251 loss: 0.000528349949
Iter: 252 loss: 0.000518034853
Iter: 253 loss: 0.000514642103
Iter: 254 loss: 0.000524184434
Iter: 255 loss: 0.000513569859
Iter: 256 loss: 0.000510680955
Iter: 257 loss: 0.000508275756
Iter: 258 loss: 0.000507452292
Iter: 259 loss: 0.000503128278
Iter: 260 loss: 0.000527391443
Iter: 261 loss: 0.000502529903
Iter: 262 loss: 0.000504046
Iter: 263 loss: 0.000501384959
Iter: 264 loss: 0.000500287861
Iter: 265 loss: 0.000497707573
Iter: 266 loss: 0.000527971191
Iter: 267 loss: 0.000497485453
Iter: 268 loss: 0.000494763372
Iter: 269 loss: 0.000500715338
Iter: 270 loss: 0.000493722269
Iter: 271 loss: 0.00049150188
Iter: 272 loss: 0.000493205967
Iter: 273 loss: 0.000490148959
Iter: 274 loss: 0.000487206329
Iter: 275 loss: 0.000504402793
Iter: 276 loss: 0.00048682373
Iter: 277 loss: 0.000484301971
Iter: 278 loss: 0.000487475307
Iter: 279 loss: 0.000482988631
Iter: 280 loss: 0.000481032592
Iter: 281 loss: 0.000483917247
Iter: 282 loss: 0.000480098417
Iter: 283 loss: 0.000479126669
Iter: 284 loss: 0.000492278079
Iter: 285 loss: 0.000479121431
Iter: 286 loss: 0.000477901514
Iter: 287 loss: 0.000477212976
Iter: 288 loss: 0.000476685702
Iter: 289 loss: 0.000474929984
Iter: 290 loss: 0.000473949534
Iter: 291 loss: 0.000473182881
Iter: 292 loss: 0.000471159088
Iter: 293 loss: 0.00048124406
Iter: 294 loss: 0.00047081738
Iter: 295 loss: 0.000469374383
Iter: 296 loss: 0.000482813921
Iter: 297 loss: 0.000469306775
Iter: 298 loss: 0.00046757
Iter: 299 loss: 0.000470426749
Iter: 300 loss: 0.000466787169
Iter: 301 loss: 0.000465912104
Iter: 302 loss: 0.000465144141
Iter: 303 loss: 0.000464913959
Iter: 304 loss: 0.000463357253
Iter: 305 loss: 0.000464404729
Iter: 306 loss: 0.000462383672
Iter: 307 loss: 0.000460605661
Iter: 308 loss: 0.000467530568
Iter: 309 loss: 0.000460193085
Iter: 310 loss: 0.000458506547
Iter: 311 loss: 0.000461470219
Iter: 312 loss: 0.00045776242
Iter: 313 loss: 0.000455833477
Iter: 314 loss: 0.000476641551
Iter: 315 loss: 0.000455793081
Iter: 316 loss: 0.000454721448
Iter: 317 loss: 0.000461623276
Iter: 318 loss: 0.000454598456
Iter: 319 loss: 0.000453335408
Iter: 320 loss: 0.000454313762
Iter: 321 loss: 0.000452575303
Iter: 322 loss: 0.000451426517
Iter: 323 loss: 0.000450714026
Iter: 324 loss: 0.000450254651
Iter: 325 loss: 0.000448636798
Iter: 326 loss: 0.000455882226
Iter: 327 loss: 0.000448319741
Iter: 328 loss: 0.000447197817
Iter: 329 loss: 0.000450758642
Iter: 330 loss: 0.000446870166
Iter: 331 loss: 0.000445572165
Iter: 332 loss: 0.000460157462
Iter: 333 loss: 0.000445551443
Iter: 334 loss: 0.000444932753
Iter: 335 loss: 0.00044342078
Iter: 336 loss: 0.000459167699
Iter: 337 loss: 0.000443244819
Iter: 338 loss: 0.000441524317
Iter: 339 loss: 0.000447904342
Iter: 340 loss: 0.000441113603
Iter: 341 loss: 0.000439823139
Iter: 342 loss: 0.00044491695
Iter: 343 loss: 0.000439528783
Iter: 344 loss: 0.000438319985
Iter: 345 loss: 0.000436579052
Iter: 346 loss: 0.000436523784
Iter: 347 loss: 0.000434999412
Iter: 348 loss: 0.000434940041
Iter: 349 loss: 0.000433997018
Iter: 350 loss: 0.000448030536
Iter: 351 loss: 0.000433995825
Iter: 352 loss: 0.000433122856
Iter: 353 loss: 0.000435671973
Iter: 354 loss: 0.000432858098
Iter: 355 loss: 0.000432132336
Iter: 356 loss: 0.000430583226
Iter: 357 loss: 0.000455852161
Iter: 358 loss: 0.000430532964
Iter: 359 loss: 0.000429160049
Iter: 360 loss: 0.000434378569
Iter: 361 loss: 0.000428829633
Iter: 362 loss: 0.00042751187
Iter: 363 loss: 0.000430901069
Iter: 364 loss: 0.000427060353
Iter: 365 loss: 0.000425805367
Iter: 366 loss: 0.000427453197
Iter: 367 loss: 0.000425174192
Iter: 368 loss: 0.000424461061
Iter: 369 loss: 0.000424172409
Iter: 370 loss: 0.000423715828
Iter: 371 loss: 0.000422447716
Iter: 372 loss: 0.000429410255
Iter: 373 loss: 0.000422070589
Iter: 374 loss: 0.000420379511
Iter: 375 loss: 0.000423261925
Iter: 376 loss: 0.000419617922
Iter: 377 loss: 0.000418221462
Iter: 378 loss: 0.000426622806
Iter: 379 loss: 0.000418043812
Iter: 380 loss: 0.000416703115
Iter: 381 loss: 0.000418780721
Iter: 382 loss: 0.000416073512
Iter: 383 loss: 0.000414995622
Iter: 384 loss: 0.00041510968
Iter: 385 loss: 0.000414170849
Iter: 386 loss: 0.000415214832
Iter: 387 loss: 0.000413692789
Iter: 388 loss: 0.000413147092
Iter: 389 loss: 0.000412231922
Iter: 390 loss: 0.00041222974
Iter: 391 loss: 0.000411455781
Iter: 392 loss: 0.000412737136
Iter: 393 loss: 0.000411103305
Iter: 394 loss: 0.000410399633
Iter: 395 loss: 0.000408934982
Iter: 396 loss: 0.000433535577
Iter: 397 loss: 0.000408901076
Iter: 398 loss: 0.000407291
Iter: 399 loss: 0.000415867369
Iter: 400 loss: 0.000407044048
Iter: 401 loss: 0.000406081381
Iter: 402 loss: 0.000416298164
Iter: 403 loss: 0.000406056148
Iter: 404 loss: 0.000405226456
Iter: 405 loss: 0.000412744
Iter: 406 loss: 0.000405190047
Iter: 407 loss: 0.000404567167
Iter: 408 loss: 0.000403726473
Iter: 409 loss: 0.000403682468
Iter: 410 loss: 0.000402831123
Iter: 411 loss: 0.000403086597
Iter: 412 loss: 0.000402218546
Iter: 413 loss: 0.000401157304
Iter: 414 loss: 0.000403214304
Iter: 415 loss: 0.000400715711
Iter: 416 loss: 0.000399774464
Iter: 417 loss: 0.000401056081
Iter: 418 loss: 0.000399305427
Iter: 419 loss: 0.000398368633
Iter: 420 loss: 0.000406233245
Iter: 421 loss: 0.000398317236
Iter: 422 loss: 0.000397927186
Iter: 423 loss: 0.000397837226
Iter: 424 loss: 0.000397515018
Iter: 425 loss: 0.000396870455
Iter: 426 loss: 0.000408965512
Iter: 427 loss: 0.000396863441
Iter: 428 loss: 0.000396215299
Iter: 429 loss: 0.000397036143
Iter: 430 loss: 0.000395880954
Iter: 431 loss: 0.000394940522
Iter: 432 loss: 0.000394831819
Iter: 433 loss: 0.000394156086
Iter: 434 loss: 0.000393027032
Iter: 435 loss: 0.000395244977
Iter: 436 loss: 0.000392561022
Iter: 437 loss: 0.000391216512
Iter: 438 loss: 0.000393394643
Iter: 439 loss: 0.000390599191
Iter: 440 loss: 0.000389641151
Iter: 441 loss: 0.000400574412
Iter: 442 loss: 0.000389623456
Iter: 443 loss: 0.000388600514
Iter: 444 loss: 0.000396319374
Iter: 445 loss: 0.000388525368
Iter: 446 loss: 0.00038797193
Iter: 447 loss: 0.000387742097
Iter: 448 loss: 0.000387450098
Iter: 449 loss: 0.000386889616
Iter: 450 loss: 0.00038578012
Iter: 451 loss: 0.00040739114
Iter: 452 loss: 0.000385768479
Iter: 453 loss: 0.000384610612
Iter: 454 loss: 0.000387838
Iter: 455 loss: 0.000384238694
Iter: 456 loss: 0.000383126375
Iter: 457 loss: 0.000387175765
Iter: 458 loss: 0.000382850179
Iter: 459 loss: 0.000382249214
Iter: 460 loss: 0.000382064289
Iter: 461 loss: 0.000381724676
Iter: 462 loss: 0.000380682788
Iter: 463 loss: 0.00038302847
Iter: 464 loss: 0.000380062265
Iter: 465 loss: 0.00037885856
Iter: 466 loss: 0.000387545762
Iter: 467 loss: 0.000378751953
Iter: 468 loss: 0.000377875578
Iter: 469 loss: 0.00037756181
Iter: 470 loss: 0.00037706882
Iter: 471 loss: 0.000375853328
Iter: 472 loss: 0.000375861884
Iter: 473 loss: 0.000374883472
Iter: 474 loss: 0.000373825256
Iter: 475 loss: 0.000375098316
Iter: 476 loss: 0.000373268645
Iter: 477 loss: 0.000372225943
Iter: 478 loss: 0.000376285432
Iter: 479 loss: 0.000371980888
Iter: 480 loss: 0.000371467439
Iter: 481 loss: 0.000371369242
Iter: 482 loss: 0.000370907161
Iter: 483 loss: 0.000370351481
Iter: 484 loss: 0.000370293972
Iter: 485 loss: 0.000369788671
Iter: 486 loss: 0.000369389891
Iter: 487 loss: 0.000369235029
Iter: 488 loss: 0.000368648674
Iter: 489 loss: 0.000367892615
Iter: 490 loss: 0.000367840257
Iter: 491 loss: 0.000367140106
Iter: 492 loss: 0.000370858528
Iter: 493 loss: 0.000367035129
Iter: 494 loss: 0.000366202265
Iter: 495 loss: 0.000365848537
Iter: 496 loss: 0.000365414482
Iter: 497 loss: 0.000364769076
Iter: 498 loss: 0.000369608868
Iter: 499 loss: 0.000364719541
Iter: 500 loss: 0.00036408368
Iter: 501 loss: 0.000363240804
Iter: 502 loss: 0.000363191968
Iter: 503 loss: 0.000362080697
Iter: 504 loss: 0.00036763167
Iter: 505 loss: 0.000361891085
Iter: 506 loss: 0.00036101538
Iter: 507 loss: 0.000368879118
Iter: 508 loss: 0.000360973354
Iter: 509 loss: 0.000360322709
Iter: 510 loss: 0.000358913676
Iter: 511 loss: 0.000380732701
Iter: 512 loss: 0.000358859485
Iter: 513 loss: 0.000357662851
Iter: 514 loss: 0.000373409886
Iter: 515 loss: 0.000357655634
Iter: 516 loss: 0.000356986071
Iter: 517 loss: 0.00035696
Iter: 518 loss: 0.000356463308
Iter: 519 loss: 0.000356153934
Iter: 520 loss: 0.000355953787
Iter: 521 loss: 0.000355241762
Iter: 522 loss: 0.000357029523
Iter: 523 loss: 0.000354995544
Iter: 524 loss: 0.000354374177
Iter: 525 loss: 0.000355102908
Iter: 526 loss: 0.000354041229
Iter: 527 loss: 0.000353229465
Iter: 528 loss: 0.000356749777
Iter: 529 loss: 0.000353063311
Iter: 530 loss: 0.000352511357
Iter: 531 loss: 0.000351890078
Iter: 532 loss: 0.000351806782
Iter: 533 loss: 0.000350932329
Iter: 534 loss: 0.000359062513
Iter: 535 loss: 0.000350896182
Iter: 536 loss: 0.000350160757
Iter: 537 loss: 0.000348696689
Iter: 538 loss: 0.000376740267
Iter: 539 loss: 0.000348679954
Iter: 540 loss: 0.000347870402
Iter: 541 loss: 0.00034777337
Iter: 542 loss: 0.000346999877
Iter: 543 loss: 0.000347500958
Iter: 544 loss: 0.000346509682
Iter: 545 loss: 0.000345503213
Iter: 546 loss: 0.000345625536
Iter: 547 loss: 0.000344735628
Iter: 548 loss: 0.000344364613
Iter: 549 loss: 0.0003442085
Iter: 550 loss: 0.000343621767
Iter: 551 loss: 0.000345490203
Iter: 552 loss: 0.0003434518
Iter: 553 loss: 0.000342919026
Iter: 554 loss: 0.000342849962
Iter: 555 loss: 0.000342474028
Iter: 556 loss: 0.000341743667
Iter: 557 loss: 0.000344456144
Iter: 558 loss: 0.000341561041
Iter: 559 loss: 0.000340914819
Iter: 560 loss: 0.000343640946
Iter: 561 loss: 0.000340779428
Iter: 562 loss: 0.00034024287
Iter: 563 loss: 0.000340336701
Iter: 564 loss: 0.000339839899
Iter: 565 loss: 0.000339291524
Iter: 566 loss: 0.000340073195
Iter: 567 loss: 0.000339022459
Iter: 568 loss: 0.000338196289
Iter: 569 loss: 0.00033923419
Iter: 570 loss: 0.000337768171
Iter: 571 loss: 0.00033696118
Iter: 572 loss: 0.000337128935
Iter: 573 loss: 0.000336363126
Iter: 574 loss: 0.000335318618
Iter: 575 loss: 0.000343129126
Iter: 576 loss: 0.000335235294
Iter: 577 loss: 0.000334193173
Iter: 578 loss: 0.00033642113
Iter: 579 loss: 0.000333783362
Iter: 580 loss: 0.000332933269
Iter: 581 loss: 0.000332128635
Iter: 582 loss: 0.000331933028
Iter: 583 loss: 0.000333018892
Iter: 584 loss: 0.00033137697
Iter: 585 loss: 0.000331040123
Iter: 586 loss: 0.000330494542
Iter: 587 loss: 0.000330491253
Iter: 588 loss: 0.000329682603
Iter: 589 loss: 0.000330819283
Iter: 590 loss: 0.000329279923
Iter: 591 loss: 0.000328424736
Iter: 592 loss: 0.000332013704
Iter: 593 loss: 0.000328244729
Iter: 594 loss: 0.000327529619
Iter: 595 loss: 0.000328348833
Iter: 596 loss: 0.000327143731
Iter: 597 loss: 0.000326608366
Iter: 598 loss: 0.000326274894
Iter: 599 loss: 0.000326062232
Iter: 600 loss: 0.000325290312
Iter: 601 loss: 0.000328274444
Iter: 602 loss: 0.00032510719
Iter: 603 loss: 0.000324366731
Iter: 604 loss: 0.000323927263
Iter: 605 loss: 0.000323617831
Iter: 606 loss: 0.00032233735
Iter: 607 loss: 0.000325329485
Iter: 608 loss: 0.000321866
Iter: 609 loss: 0.000320945
Iter: 610 loss: 0.000325068017
Iter: 611 loss: 0.000320765248
Iter: 612 loss: 0.000319658022
Iter: 613 loss: 0.000327576388
Iter: 614 loss: 0.000319561892
Iter: 615 loss: 0.000319274259
Iter: 616 loss: 0.000319182844
Iter: 617 loss: 0.000318793434
Iter: 618 loss: 0.000318229373
Iter: 619 loss: 0.000318212318
Iter: 620 loss: 0.000317602942
Iter: 621 loss: 0.000320002378
Iter: 622 loss: 0.000317462196
Iter: 623 loss: 0.00031689278
Iter: 624 loss: 0.000319382118
Iter: 625 loss: 0.000316779042
Iter: 626 loss: 0.00031622377
Iter: 627 loss: 0.000317541591
Iter: 628 loss: 0.000316019868
Iter: 629 loss: 0.000315540296
Iter: 630 loss: 0.000315473037
Iter: 631 loss: 0.000315136393
Iter: 632 loss: 0.000314478239
Iter: 633 loss: 0.000315911369
Iter: 634 loss: 0.000314223231
Iter: 635 loss: 0.000313305354
Iter: 636 loss: 0.000313147088
Iter: 637 loss: 0.000312521
Iter: 638 loss: 0.000311455893
Iter: 639 loss: 0.000319006329
Iter: 640 loss: 0.000311360898
Iter: 641 loss: 0.000310393341
Iter: 642 loss: 0.000310076954
Iter: 643 loss: 0.000309515191
Iter: 644 loss: 0.000308317
Iter: 645 loss: 0.000314822362
Iter: 646 loss: 0.00030814184
Iter: 647 loss: 0.000307403388
Iter: 648 loss: 0.000318202161
Iter: 649 loss: 0.000307402603
Iter: 650 loss: 0.000306751928
Iter: 651 loss: 0.00030941458
Iter: 652 loss: 0.000306611881
Iter: 653 loss: 0.000306250819
Iter: 654 loss: 0.000305546622
Iter: 655 loss: 0.00031999257
Iter: 656 loss: 0.000305540947
Iter: 657 loss: 0.000304640678
Iter: 658 loss: 0.00030917587
Iter: 659 loss: 0.00030449545
Iter: 660 loss: 0.000303956971
Iter: 661 loss: 0.000310139148
Iter: 662 loss: 0.000303947367
Iter: 663 loss: 0.000303531706
Iter: 664 loss: 0.000302595319
Iter: 665 loss: 0.000315259123
Iter: 666 loss: 0.000302540488
Iter: 667 loss: 0.000301420077
Iter: 668 loss: 0.000308492687
Iter: 669 loss: 0.000301290449
Iter: 670 loss: 0.000300384359
Iter: 671 loss: 0.000301334716
Iter: 672 loss: 0.000299882871
Iter: 673 loss: 0.000298843166
Iter: 674 loss: 0.000302929
Iter: 675 loss: 0.000298599887
Iter: 676 loss: 0.000297648774
Iter: 677 loss: 0.000298534316
Iter: 678 loss: 0.000297099788
Iter: 679 loss: 0.000296095415
Iter: 680 loss: 0.000301434455
Iter: 681 loss: 0.00029594131
Iter: 682 loss: 0.000295499
Iter: 683 loss: 0.0002954886
Iter: 684 loss: 0.000295088335
Iter: 685 loss: 0.000296234939
Iter: 686 loss: 0.000294962432
Iter: 687 loss: 0.000294596539
Iter: 688 loss: 0.000294280646
Iter: 689 loss: 0.000294182042
Iter: 690 loss: 0.000293677032
Iter: 691 loss: 0.00029604818
Iter: 692 loss: 0.000293584191
Iter: 693 loss: 0.000293166901
Iter: 694 loss: 0.00029546622
Iter: 695 loss: 0.000293105899
Iter: 696 loss: 0.000292671553
Iter: 697 loss: 0.00029215723
Iter: 698 loss: 0.000292102428
Iter: 699 loss: 0.000291378557
Iter: 700 loss: 0.000292454264
Iter: 701 loss: 0.000291030126
Iter: 702 loss: 0.000290250289
Iter: 703 loss: 0.000293919089
Iter: 704 loss: 0.000290107157
Iter: 705 loss: 0.000289421558
Iter: 706 loss: 0.00028914155
Iter: 707 loss: 0.000288777781
Iter: 708 loss: 0.000287855451
Iter: 709 loss: 0.000295997597
Iter: 710 loss: 0.000287809235
Iter: 711 loss: 0.000287101051
Iter: 712 loss: 0.000287984149
Iter: 713 loss: 0.000286734459
Iter: 714 loss: 0.000286342576
Iter: 715 loss: 0.000286307826
Iter: 716 loss: 0.000285911432
Iter: 717 loss: 0.000286815717
Iter: 718 loss: 0.000285764108
Iter: 719 loss: 0.000285343558
Iter: 720 loss: 0.000285272545
Iter: 721 loss: 0.000284985173
Iter: 722 loss: 0.000284476846
Iter: 723 loss: 0.000286385941
Iter: 724 loss: 0.000284355454
Iter: 725 loss: 0.000283919595
Iter: 726 loss: 0.000287176459
Iter: 727 loss: 0.000283884292
Iter: 728 loss: 0.000283487199
Iter: 729 loss: 0.000283127389
Iter: 730 loss: 0.000283029221
Iter: 731 loss: 0.000282365188
Iter: 732 loss: 0.000282937574
Iter: 733 loss: 0.00028197316
Iter: 734 loss: 0.000281231711
Iter: 735 loss: 0.000284018519
Iter: 736 loss: 0.000281053712
Iter: 737 loss: 0.000280315318
Iter: 738 loss: 0.000281353452
Iter: 739 loss: 0.000279948086
Iter: 740 loss: 0.000279129192
Iter: 741 loss: 0.000279940839
Iter: 742 loss: 0.000278665131
Iter: 743 loss: 0.000277921237
Iter: 744 loss: 0.000287854753
Iter: 745 loss: 0.000277917541
Iter: 746 loss: 0.000277381565
Iter: 747 loss: 0.000278922409
Iter: 748 loss: 0.000277211511
Iter: 749 loss: 0.000276557112
Iter: 750 loss: 0.000282173103
Iter: 751 loss: 0.000276522536
Iter: 752 loss: 0.000276149483
Iter: 753 loss: 0.000275844941
Iter: 754 loss: 0.000275734812
Iter: 755 loss: 0.000275134691
Iter: 756 loss: 0.000276091101
Iter: 757 loss: 0.000274857826
Iter: 758 loss: 0.000274291466
Iter: 759 loss: 0.000279482
Iter: 760 loss: 0.000274264574
Iter: 761 loss: 0.000273774232
Iter: 762 loss: 0.000273885
Iter: 763 loss: 0.000273414829
Iter: 764 loss: 0.000272828445
Iter: 765 loss: 0.000272551202
Iter: 766 loss: 0.000272264326
Iter: 767 loss: 0.000271356839
Iter: 768 loss: 0.00027557931
Iter: 769 loss: 0.000271188852
Iter: 770 loss: 0.000270413875
Iter: 771 loss: 0.000272041769
Iter: 772 loss: 0.00027010488
Iter: 773 loss: 0.000269243523
Iter: 774 loss: 0.000269580021
Iter: 775 loss: 0.000268646167
Iter: 776 loss: 0.000267861906
Iter: 777 loss: 0.000275747967
Iter: 778 loss: 0.000267836847
Iter: 779 loss: 0.000267142372
Iter: 780 loss: 0.000270098681
Iter: 781 loss: 0.000266993389
Iter: 782 loss: 0.000266497489
Iter: 783 loss: 0.000266493938
Iter: 784 loss: 0.000266223447
Iter: 785 loss: 0.000265781942
Iter: 786 loss: 0.00026577973
Iter: 787 loss: 0.000265179056
Iter: 788 loss: 0.000266370771
Iter: 789 loss: 0.000264932518
Iter: 790 loss: 0.000264497357
Iter: 791 loss: 0.000267861411
Iter: 792 loss: 0.000264464703
Iter: 793 loss: 0.000264051545
Iter: 794 loss: 0.000264201517
Iter: 795 loss: 0.000263763417
Iter: 796 loss: 0.000263262511
Iter: 797 loss: 0.000263112364
Iter: 798 loss: 0.000262812653
Iter: 799 loss: 0.00026213855
Iter: 800 loss: 0.000265888928
Iter: 801 loss: 0.00026204309
Iter: 802 loss: 0.000261468318
Iter: 803 loss: 0.000262289745
Iter: 804 loss: 0.000261185691
Iter: 805 loss: 0.000260488072
Iter: 806 loss: 0.000260723231
Iter: 807 loss: 0.000259995984
Iter: 808 loss: 0.000259224616
Iter: 809 loss: 0.000263025431
Iter: 810 loss: 0.000259092834
Iter: 811 loss: 0.000258500513
Iter: 812 loss: 0.000266290794
Iter: 813 loss: 0.000258496497
Iter: 814 loss: 0.00025815476
Iter: 815 loss: 0.000262323418
Iter: 816 loss: 0.000258151
Iter: 817 loss: 0.000257893349
Iter: 818 loss: 0.000257549604
Iter: 819 loss: 0.000257529347
Iter: 820 loss: 0.000257075357
Iter: 821 loss: 0.000258661632
Iter: 822 loss: 0.000256957399
Iter: 823 loss: 0.00025661019
Iter: 824 loss: 0.000257314881
Iter: 825 loss: 0.000256469386
Iter: 826 loss: 0.000256006897
Iter: 827 loss: 0.000256984116
Iter: 828 loss: 0.000255826133
Iter: 829 loss: 0.000255425635
Iter: 830 loss: 0.000255156861
Iter: 831 loss: 0.000255007879
Iter: 832 loss: 0.000254448387
Iter: 833 loss: 0.000257199776
Iter: 834 loss: 0.000254350831
Iter: 835 loss: 0.000253847684
Iter: 836 loss: 0.000254883169
Iter: 837 loss: 0.000253644015
Iter: 838 loss: 0.000253061065
Iter: 839 loss: 0.000253599137
Iter: 840 loss: 0.000252725498
Iter: 841 loss: 0.000252087135
Iter: 842 loss: 0.000253014325
Iter: 843 loss: 0.000251778081
Iter: 844 loss: 0.000251417281
Iter: 845 loss: 0.000251350517
Iter: 846 loss: 0.00025106431
Iter: 847 loss: 0.000252715225
Iter: 848 loss: 0.000251026475
Iter: 849 loss: 0.000250732875
Iter: 850 loss: 0.000250510522
Iter: 851 loss: 0.000250414887
Iter: 852 loss: 0.000250026671
Iter: 853 loss: 0.0002520532
Iter: 854 loss: 0.000249966193
Iter: 855 loss: 0.000249665958
Iter: 856 loss: 0.000249821052
Iter: 857 loss: 0.00024946552
Iter: 858 loss: 0.000248999248
Iter: 859 loss: 0.000250228186
Iter: 860 loss: 0.00024884264
Iter: 861 loss: 0.000248423254
Iter: 862 loss: 0.000248159806
Iter: 863 loss: 0.000247993099
Iter: 864 loss: 0.000247400167
Iter: 865 loss: 0.000249177159
Iter: 866 loss: 0.000247220218
Iter: 867 loss: 0.000246551237
Iter: 868 loss: 0.000248482276
Iter: 869 loss: 0.000246341981
Iter: 870 loss: 0.000245684
Iter: 871 loss: 0.000246445416
Iter: 872 loss: 0.000245332281
Iter: 873 loss: 0.000244563154
Iter: 874 loss: 0.000245443545
Iter: 875 loss: 0.000244150287
Iter: 876 loss: 0.000243739254
Iter: 877 loss: 0.000243682473
Iter: 878 loss: 0.000243298942
Iter: 879 loss: 0.000245367934
Iter: 880 loss: 0.000243242568
Iter: 881 loss: 0.00024286026
Iter: 882 loss: 0.000242903916
Iter: 883 loss: 0.000242564929
Iter: 884 loss: 0.000242165755
Iter: 885 loss: 0.000244087772
Iter: 886 loss: 0.000242096605
Iter: 887 loss: 0.000241743372
Iter: 888 loss: 0.000241809641
Iter: 889 loss: 0.000241478265
Iter: 890 loss: 0.000240965863
Iter: 891 loss: 0.000243535949
Iter: 892 loss: 0.000240880559
Iter: 893 loss: 0.000240504683
Iter: 894 loss: 0.000240219946
Iter: 895 loss: 0.000240097
Iter: 896 loss: 0.000239543209
Iter: 897 loss: 0.000240519803
Iter: 898 loss: 0.000239299101
Iter: 899 loss: 0.000238643319
Iter: 900 loss: 0.000241567555
Iter: 901 loss: 0.000238513763
Iter: 902 loss: 0.000237929387
Iter: 903 loss: 0.00023884757
Iter: 904 loss: 0.000237655593
Iter: 905 loss: 0.00023701138
Iter: 906 loss: 0.000237764616
Iter: 907 loss: 0.000236666747
Iter: 908 loss: 0.000236243679
Iter: 909 loss: 0.000236232096
Iter: 910 loss: 0.000235863699
Iter: 911 loss: 0.000239242072
Iter: 912 loss: 0.000235848551
Iter: 913 loss: 0.000235570551
Iter: 914 loss: 0.000235610292
Iter: 915 loss: 0.000235359024
Iter: 916 loss: 0.000235054409
Iter: 917 loss: 0.000236143795
Iter: 918 loss: 0.000234977444
Iter: 919 loss: 0.000234668987
Iter: 920 loss: 0.000234601932
Iter: 921 loss: 0.000234400315
Iter: 922 loss: 0.000233938539
Iter: 923 loss: 0.000236668173
Iter: 924 loss: 0.000233879648
Iter: 925 loss: 0.000233527884
Iter: 926 loss: 0.000233301034
Iter: 927 loss: 0.000233163912
Iter: 928 loss: 0.000232665116
Iter: 929 loss: 0.000233402214
Iter: 930 loss: 0.000232424063
Iter: 931 loss: 0.0002318935
Iter: 932 loss: 0.000234735664
Iter: 933 loss: 0.000231812504
Iter: 934 loss: 0.000231343976
Iter: 935 loss: 0.000231672253
Iter: 936 loss: 0.000231052443
Iter: 937 loss: 0.000230434525
Iter: 938 loss: 0.000231269747
Iter: 939 loss: 0.000230122561
Iter: 940 loss: 0.000229596248
Iter: 941 loss: 0.000235446467
Iter: 942 loss: 0.000229585086
Iter: 943 loss: 0.000229217243
Iter: 944 loss: 0.000229214726
Iter: 945 loss: 0.000228982011
Iter: 946 loss: 0.000228979072
Iter: 947 loss: 0.000228794
Iter: 948 loss: 0.000228516525
Iter: 949 loss: 0.000229296769
Iter: 950 loss: 0.000228428195
Iter: 951 loss: 0.000228129269
Iter: 952 loss: 0.00022797109
Iter: 953 loss: 0.000227833967
Iter: 954 loss: 0.000227389668
Iter: 955 loss: 0.000230292178
Iter: 956 loss: 0.000227342549
Iter: 957 loss: 0.000226971664
Iter: 958 loss: 0.00022682127
Iter: 959 loss: 0.000226622564
Iter: 960 loss: 0.000226146367
Iter: 961 loss: 0.000227095341
Iter: 962 loss: 0.000225951808
Iter: 963 loss: 0.000225528143
Iter: 964 loss: 0.000227924145
Iter: 965 loss: 0.000225469092
Iter: 966 loss: 0.000225102864
Iter: 967 loss: 0.000225196171
Iter: 968 loss: 0.000224835181
Iter: 969 loss: 0.000224320102
Iter: 970 loss: 0.000225291675
Iter: 971 loss: 0.000224101139
Iter: 972 loss: 0.000223663752
Iter: 973 loss: 0.000226906559
Iter: 974 loss: 0.000223627561
Iter: 975 loss: 0.000223391573
Iter: 976 loss: 0.000223364317
Iter: 977 loss: 0.000223197654
Iter: 978 loss: 0.000223156676
Iter: 979 loss: 0.000223050971
Iter: 980 loss: 0.000222831
Iter: 981 loss: 0.000223287352
Iter: 982 loss: 0.00022274346
Iter: 983 loss: 0.000222484145
Iter: 984 loss: 0.000222433737
Iter: 985 loss: 0.00022226022
Iter: 986 loss: 0.000221938477
Iter: 987 loss: 0.000223783878
Iter: 988 loss: 0.000221894908
Iter: 989 loss: 0.000221576745
Iter: 990 loss: 0.000221610811
Iter: 991 loss: 0.000221330789
Iter: 992 loss: 0.000220968854
Iter: 993 loss: 0.000221659109
Iter: 994 loss: 0.000220817485
Iter: 995 loss: 0.000220463495
Iter: 996 loss: 0.000221845024
Iter: 997 loss: 0.000220380374
Iter: 998 loss: 0.000220022252
Iter: 999 loss: 0.000220148155
Iter: 1000 loss: 0.000219769281
Iter: 1001 loss: 0.000219304391
Iter: 1002 loss: 0.000220519971
Iter: 1003 loss: 0.000219146023
Iter: 1004 loss: 0.000218757108
Iter: 1005 loss: 0.000220790098
Iter: 1006 loss: 0.000218694928
Iter: 1007 loss: 0.0002185427
Iter: 1008 loss: 0.000218486661
Iter: 1009 loss: 0.00021834232
Iter: 1010 loss: 0.000218252724
Iter: 1011 loss: 0.000218194444
Iter: 1012 loss: 0.000217967274
Iter: 1013 loss: 0.00021825693
Iter: 1014 loss: 0.000217851
Iter: 1015 loss: 0.000217561028
Iter: 1016 loss: 0.000217796551
Iter: 1017 loss: 0.000217387613
Iter: 1018 loss: 0.000217121793
Iter: 1019 loss: 0.000218257264
Iter: 1020 loss: 0.00021706603
Iter: 1021 loss: 0.000216754255
Iter: 1022 loss: 0.000216959612
Iter: 1023 loss: 0.000216556989
Iter: 1024 loss: 0.000216221262
Iter: 1025 loss: 0.000216661792
Iter: 1026 loss: 0.000216051878
Iter: 1027 loss: 0.000215684326
Iter: 1028 loss: 0.000216721484
Iter: 1029 loss: 0.000215567474
Iter: 1030 loss: 0.00021516782
Iter: 1031 loss: 0.000215703607
Iter: 1032 loss: 0.000214966916
Iter: 1033 loss: 0.000214547064
Iter: 1034 loss: 0.00021540797
Iter: 1035 loss: 0.000214377054
Iter: 1036 loss: 0.000213962703
Iter: 1037 loss: 0.000215667518
Iter: 1038 loss: 0.000213871652
Iter: 1039 loss: 0.000213793086
Iter: 1040 loss: 0.000213677544
Iter: 1041 loss: 0.000213534498
Iter: 1042 loss: 0.000213436899
Iter: 1043 loss: 0.000213383726
Iter: 1044 loss: 0.000213148
Iter: 1045 loss: 0.000213450054
Iter: 1046 loss: 0.000213026244
Iter: 1047 loss: 0.000212745319
Iter: 1048 loss: 0.000213150313
Iter: 1049 loss: 0.000212607396
Iter: 1050 loss: 0.00021236841
Iter: 1051 loss: 0.00021283103
Iter: 1052 loss: 0.000212268889
Iter: 1053 loss: 0.000211926439
Iter: 1054 loss: 0.000212505242
Iter: 1055 loss: 0.000211771257
Iter: 1056 loss: 0.000211449034
Iter: 1057 loss: 0.000211994906
Iter: 1058 loss: 0.000211303835
Iter: 1059 loss: 0.000210968108
Iter: 1060 loss: 0.000211704639
Iter: 1061 loss: 0.000210838552
Iter: 1062 loss: 0.000210453087
Iter: 1063 loss: 0.000211138409
Iter: 1064 loss: 0.000210283964
Iter: 1065 loss: 0.000209907274
Iter: 1066 loss: 0.000210580853
Iter: 1067 loss: 0.000209741702
Iter: 1068 loss: 0.00020934522
Iter: 1069 loss: 0.000210886588
Iter: 1070 loss: 0.000209251913
Iter: 1071 loss: 0.000209201462
Iter: 1072 loss: 0.000209083315
Iter: 1073 loss: 0.000208956044
Iter: 1074 loss: 0.00020888017
Iter: 1075 loss: 0.000208826707
Iter: 1076 loss: 0.000208616228
Iter: 1077 loss: 0.000208885554
Iter: 1078 loss: 0.00020850799
Iter: 1079 loss: 0.000208258265
Iter: 1080 loss: 0.00020862672
Iter: 1081 loss: 0.000208136393
Iter: 1082 loss: 0.000207901947
Iter: 1083 loss: 0.000208047553
Iter: 1084 loss: 0.000207751349
Iter: 1085 loss: 0.000207350211
Iter: 1086 loss: 0.000208358397
Iter: 1087 loss: 0.000207208504
Iter: 1088 loss: 0.000206873461
Iter: 1089 loss: 0.000207467965
Iter: 1090 loss: 0.000206725177
Iter: 1091 loss: 0.000206374549
Iter: 1092 loss: 0.000206939934
Iter: 1093 loss: 0.00020621196
Iter: 1094 loss: 0.000205791817
Iter: 1095 loss: 0.0002068092
Iter: 1096 loss: 0.000205641714
Iter: 1097 loss: 0.000205265125
Iter: 1098 loss: 0.000205905
Iter: 1099 loss: 0.00020509609
Iter: 1100 loss: 0.000204704556
Iter: 1101 loss: 0.000206186261
Iter: 1102 loss: 0.000204610667
Iter: 1103 loss: 0.000204569325
Iter: 1104 loss: 0.000204451426
Iter: 1105 loss: 0.000204327021
Iter: 1106 loss: 0.000204269629
Iter: 1107 loss: 0.000204207783
Iter: 1108 loss: 0.000204007782
Iter: 1109 loss: 0.000204278564
Iter: 1110 loss: 0.000203909149
Iter: 1111 loss: 0.000203678122
Iter: 1112 loss: 0.000204067168
Iter: 1113 loss: 0.000203573261
Iter: 1114 loss: 0.000203356438
Iter: 1115 loss: 0.000203379415
Iter: 1116 loss: 0.000203189527
Iter: 1117 loss: 0.000202819181
Iter: 1118 loss: 0.000204249503
Iter: 1119 loss: 0.000202731288
Iter: 1120 loss: 0.000202458104
Iter: 1121 loss: 0.000202890646
Iter: 1122 loss: 0.000202330964
Iter: 1123 loss: 0.000202033014
Iter: 1124 loss: 0.000202439172
Iter: 1125 loss: 0.000201883711
Iter: 1126 loss: 0.000201538554
Iter: 1127 loss: 0.00020257468
Iter: 1128 loss: 0.000201434508
Iter: 1129 loss: 0.000201130926
Iter: 1130 loss: 0.000201520801
Iter: 1131 loss: 0.000200974901
Iter: 1132 loss: 0.000200650538
Iter: 1133 loss: 0.000201974195
Iter: 1134 loss: 0.000200578899
Iter: 1135 loss: 0.000200517854
Iter: 1136 loss: 0.000200444076
Iter: 1137 loss: 0.000200331924
Iter: 1138 loss: 0.00020031142
Iter: 1139 loss: 0.000200235227
Iter: 1140 loss: 0.000200071401
Iter: 1141 loss: 0.000200239563
Iter: 1142 loss: 0.000199980248
Iter: 1143 loss: 0.000199782953
Iter: 1144 loss: 0.000200005758
Iter: 1145 loss: 0.000199675953
Iter: 1146 loss: 0.000199454444
Iter: 1147 loss: 0.00019938295
Iter: 1148 loss: 0.000199253758
Iter: 1149 loss: 0.000198887108
Iter: 1150 loss: 0.000201335104
Iter: 1151 loss: 0.000198848778
Iter: 1152 loss: 0.000198622569
Iter: 1153 loss: 0.000198906549
Iter: 1154 loss: 0.000198505571
Iter: 1155 loss: 0.000198235357
Iter: 1156 loss: 0.000198584399
Iter: 1157 loss: 0.000198095891
Iter: 1158 loss: 0.000197792673
Iter: 1159 loss: 0.000198825728
Iter: 1160 loss: 0.000197711372
Iter: 1161 loss: 0.000197436078
Iter: 1162 loss: 0.000197627785
Iter: 1163 loss: 0.000197264046
Iter: 1164 loss: 0.000196953813
Iter: 1165 loss: 0.000198638401
Iter: 1166 loss: 0.000196907524
Iter: 1167 loss: 0.000196829758
Iter: 1168 loss: 0.00019678325
Iter: 1169 loss: 0.000196671026
Iter: 1170 loss: 0.000196714012
Iter: 1171 loss: 0.000196592358
Iter: 1172 loss: 0.000196454392
Iter: 1173 loss: 0.000196578709
Iter: 1174 loss: 0.000196374051
Iter: 1175 loss: 0.000196201174
Iter: 1176 loss: 0.000196321926
Iter: 1177 loss: 0.000196092267
Iter: 1178 loss: 0.000195867411
Iter: 1179 loss: 0.000195780944
Iter: 1180 loss: 0.000195659319
Iter: 1181 loss: 0.000195338042
Iter: 1182 loss: 0.000198588648
Iter: 1183 loss: 0.000195327302
Iter: 1184 loss: 0.000195151224
Iter: 1185 loss: 0.0001953131
Iter: 1186 loss: 0.000195049652
Iter: 1187 loss: 0.000194817607
Iter: 1188 loss: 0.000195115979
Iter: 1189 loss: 0.000194698892
Iter: 1190 loss: 0.000194435925
Iter: 1191 loss: 0.000195407541
Iter: 1192 loss: 0.000194371562
Iter: 1193 loss: 0.00019413518
Iter: 1194 loss: 0.000194218068
Iter: 1195 loss: 0.00019396859
Iter: 1196 loss: 0.000193690561
Iter: 1197 loss: 0.000195225235
Iter: 1198 loss: 0.000193649787
Iter: 1199 loss: 0.0001935529
Iter: 1200 loss: 0.000193533066
Iter: 1201 loss: 0.000193423097
Iter: 1202 loss: 0.000193485495
Iter: 1203 loss: 0.000193351108
Iter: 1204 loss: 0.000193223
Iter: 1205 loss: 0.000193309868
Iter: 1206 loss: 0.000193142652
Iter: 1207 loss: 0.000192966254
Iter: 1208 loss: 0.000193102518
Iter: 1209 loss: 0.000192858686
Iter: 1210 loss: 0.000192627311
Iter: 1211 loss: 0.000192624255
Iter: 1212 loss: 0.000192442269
Iter: 1213 loss: 0.000192173175
Iter: 1214 loss: 0.000195607412
Iter: 1215 loss: 0.000192171166
Iter: 1216 loss: 0.000192022853
Iter: 1217 loss: 0.000192029838
Iter: 1218 loss: 0.000191906947
Iter: 1219 loss: 0.000191671526
Iter: 1220 loss: 0.000191980595
Iter: 1221 loss: 0.000191551691
Iter: 1222 loss: 0.000191285042
Iter: 1223 loss: 0.000192557811
Iter: 1224 loss: 0.000191237195
Iter: 1225 loss: 0.000191012601
Iter: 1226 loss: 0.000191011728
Iter: 1227 loss: 0.000190832419
Iter: 1228 loss: 0.000190553765
Iter: 1229 loss: 0.000192252308
Iter: 1230 loss: 0.000190520252
Iter: 1231 loss: 0.000190432082
Iter: 1232 loss: 0.000190407707
Iter: 1233 loss: 0.000190304447
Iter: 1234 loss: 0.000190357357
Iter: 1235 loss: 0.000190235791
Iter: 1236 loss: 0.000190113948
Iter: 1237 loss: 0.000190152874
Iter: 1238 loss: 0.000190027218
Iter: 1239 loss: 0.000189848826
Iter: 1240 loss: 0.000189945436
Iter: 1241 loss: 0.000189730461
Iter: 1242 loss: 0.000189493672
Iter: 1243 loss: 0.000189560174
Iter: 1244 loss: 0.000189323269
Iter: 1245 loss: 0.000189085491
Iter: 1246 loss: 0.000192488777
Iter: 1247 loss: 0.000189085345
Iter: 1248 loss: 0.000188938691
Iter: 1249 loss: 0.000188831822
Iter: 1250 loss: 0.000188782607
Iter: 1251 loss: 0.000188505292
Iter: 1252 loss: 0.000188842489
Iter: 1253 loss: 0.000188359991
Iter: 1254 loss: 0.000188065867
Iter: 1255 loss: 0.000189801969
Iter: 1256 loss: 0.000188028818
Iter: 1257 loss: 0.000187785045
Iter: 1258 loss: 0.000187718819
Iter: 1259 loss: 0.000187568483
Iter: 1260 loss: 0.000187240599
Iter: 1261 loss: 0.000188929102
Iter: 1262 loss: 0.000187187543
Iter: 1263 loss: 0.000187109443
Iter: 1264 loss: 0.000187054073
Iter: 1265 loss: 0.00018693626
Iter: 1266 loss: 0.000187024038
Iter: 1267 loss: 0.000186864709
Iter: 1268 loss: 0.000186733203
Iter: 1269 loss: 0.00018678364
Iter: 1270 loss: 0.000186642312
Iter: 1271 loss: 0.000186455058
Iter: 1272 loss: 0.000186628444
Iter: 1273 loss: 0.000186346166
Iter: 1274 loss: 0.000186122023
Iter: 1275 loss: 0.000186256395
Iter: 1276 loss: 0.000185977944
Iter: 1277 loss: 0.000185776036
Iter: 1278 loss: 0.000188419974
Iter: 1279 loss: 0.000185775018
Iter: 1280 loss: 0.00018563593
Iter: 1281 loss: 0.000185495883
Iter: 1282 loss: 0.00018546838
Iter: 1283 loss: 0.000185189449
Iter: 1284 loss: 0.000185793091
Iter: 1285 loss: 0.000185081211
Iter: 1286 loss: 0.000184834906
Iter: 1287 loss: 0.000186418561
Iter: 1288 loss: 0.000184807781
Iter: 1289 loss: 0.000184606761
Iter: 1290 loss: 0.000184563425
Iter: 1291 loss: 0.000184431672
Iter: 1292 loss: 0.000184157136
Iter: 1293 loss: 0.000185075871
Iter: 1294 loss: 0.000184082106
Iter: 1295 loss: 0.000184025703
Iter: 1296 loss: 0.000183959695
Iter: 1297 loss: 0.000183851444
Iter: 1298 loss: 0.000183962227
Iter: 1299 loss: 0.000183790457
Iter: 1300 loss: 0.000183682132
Iter: 1301 loss: 0.000183696975
Iter: 1302 loss: 0.000183599303
Iter: 1303 loss: 0.000183439261
Iter: 1304 loss: 0.000183692333
Iter: 1305 loss: 0.000183365279
Iter: 1306 loss: 0.00018318565
Iter: 1307 loss: 0.0001833274
Iter: 1308 loss: 0.000183077907
Iter: 1309 loss: 0.000182920965
Iter: 1310 loss: 0.000184843608
Iter: 1311 loss: 0.000182918331
Iter: 1312 loss: 0.000182800868
Iter: 1313 loss: 0.000182682226
Iter: 1314 loss: 0.000182657881
Iter: 1315 loss: 0.000182436052
Iter: 1316 loss: 0.000182918651
Iter: 1317 loss: 0.000182349526
Iter: 1318 loss: 0.000182157964
Iter: 1319 loss: 0.000183205848
Iter: 1320 loss: 0.000182130301
Iter: 1321 loss: 0.000181957977
Iter: 1322 loss: 0.000182014366
Iter: 1323 loss: 0.000181836047
Iter: 1324 loss: 0.000181637704
Iter: 1325 loss: 0.000182146425
Iter: 1326 loss: 0.000181569732
Iter: 1327 loss: 0.000181526906
Iter: 1328 loss: 0.000181477371
Iter: 1329 loss: 0.000181390584
Iter: 1330 loss: 0.00018149364
Iter: 1331 loss: 0.000181344556
Iter: 1332 loss: 0.000181256823
Iter: 1333 loss: 0.000181229785
Iter: 1334 loss: 0.000181177573
Iter: 1335 loss: 0.000181040639
Iter: 1336 loss: 0.000181252282
Iter: 1337 loss: 0.000180975738
Iter: 1338 loss: 0.00018082287
Iter: 1339 loss: 0.000180907504
Iter: 1340 loss: 0.00018072399
Iter: 1341 loss: 0.000180567731
Iter: 1342 loss: 0.000182085147
Iter: 1343 loss: 0.000180562172
Iter: 1344 loss: 0.000180430172
Iter: 1345 loss: 0.000180341827
Iter: 1346 loss: 0.000180292118
Iter: 1347 loss: 0.00018007544
Iter: 1348 loss: 0.000180499395
Iter: 1349 loss: 0.000179985509
Iter: 1350 loss: 0.000179796247
Iter: 1351 loss: 0.000180500676
Iter: 1352 loss: 0.000179749666
Iter: 1353 loss: 0.00017954738
Iter: 1354 loss: 0.000179696683
Iter: 1355 loss: 0.000179423019
Iter: 1356 loss: 0.000179206108
Iter: 1357 loss: 0.000179657858
Iter: 1358 loss: 0.000179119263
Iter: 1359 loss: 0.000179049195
Iter: 1360 loss: 0.000179008901
Iter: 1361 loss: 0.000178896458
Iter: 1362 loss: 0.000179143695
Iter: 1363 loss: 0.000178853647
Iter: 1364 loss: 0.000178759394
Iter: 1365 loss: 0.000178688046
Iter: 1366 loss: 0.00017865737
Iter: 1367 loss: 0.000178497023
Iter: 1368 loss: 0.000178850838
Iter: 1369 loss: 0.000178435337
Iter: 1370 loss: 0.000178275732
Iter: 1371 loss: 0.000178326678
Iter: 1372 loss: 0.000178162183
Iter: 1373 loss: 0.000177988113
Iter: 1374 loss: 0.000179476556
Iter: 1375 loss: 0.000177978247
Iter: 1376 loss: 0.000177817623
Iter: 1377 loss: 0.000177794136
Iter: 1378 loss: 0.000177681446
Iter: 1379 loss: 0.000177451409
Iter: 1380 loss: 0.000178052229
Iter: 1381 loss: 0.000177372538
Iter: 1382 loss: 0.000177189926
Iter: 1383 loss: 0.000177776616
Iter: 1384 loss: 0.00017713767
Iter: 1385 loss: 0.000176933827
Iter: 1386 loss: 0.000177093636
Iter: 1387 loss: 0.000176810776
Iter: 1388 loss: 0.000176590198
Iter: 1389 loss: 0.000176904548
Iter: 1390 loss: 0.000176482514
Iter: 1391 loss: 0.00017634414
Iter: 1392 loss: 0.000176333124
Iter: 1393 loss: 0.000176176793
Iter: 1394 loss: 0.000176873829
Iter: 1395 loss: 0.000176145448
Iter: 1396 loss: 0.000176047295
Iter: 1397 loss: 0.000175917914
Iter: 1398 loss: 0.000175910129
Iter: 1399 loss: 0.000175709196
Iter: 1400 loss: 0.000176363188
Iter: 1401 loss: 0.000175652822
Iter: 1402 loss: 0.000175464636
Iter: 1403 loss: 0.000175461115
Iter: 1404 loss: 0.000175313296
Iter: 1405 loss: 0.000175090536
Iter: 1406 loss: 0.000176844958
Iter: 1407 loss: 0.000175075038
Iter: 1408 loss: 0.000174875473
Iter: 1409 loss: 0.000174983841
Iter: 1410 loss: 0.000174744928
Iter: 1411 loss: 0.000174499553
Iter: 1412 loss: 0.000175304682
Iter: 1413 loss: 0.000174430665
Iter: 1414 loss: 0.000174247747
Iter: 1415 loss: 0.000174657383
Iter: 1416 loss: 0.000174178567
Iter: 1417 loss: 0.000173959852
Iter: 1418 loss: 0.000174249464
Iter: 1419 loss: 0.000173849927
Iter: 1420 loss: 0.000173630804
Iter: 1421 loss: 0.000173832959
Iter: 1422 loss: 0.000173503708
Iter: 1423 loss: 0.000173316803
Iter: 1424 loss: 0.000173317094
Iter: 1425 loss: 0.000173140521
Iter: 1426 loss: 0.000174739253
Iter: 1427 loss: 0.000173131848
Iter: 1428 loss: 0.000173048044
Iter: 1429 loss: 0.000172894521
Iter: 1430 loss: 0.000176419504
Iter: 1431 loss: 0.000172894404
Iter: 1432 loss: 0.000172688233
Iter: 1433 loss: 0.000173539913
Iter: 1434 loss: 0.000172643253
Iter: 1435 loss: 0.000172452506
Iter: 1436 loss: 0.000172414992
Iter: 1437 loss: 0.000172288099
Iter: 1438 loss: 0.000172068016
Iter: 1439 loss: 0.000174007786
Iter: 1440 loss: 0.000172056592
Iter: 1441 loss: 0.000171886757
Iter: 1442 loss: 0.000172073778
Iter: 1443 loss: 0.00017179476
Iter: 1444 loss: 0.000171600172
Iter: 1445 loss: 0.000172329834
Iter: 1446 loss: 0.000171553431
Iter: 1447 loss: 0.000171385298
Iter: 1448 loss: 0.000171500084
Iter: 1449 loss: 0.000171279462
Iter: 1450 loss: 0.000171040185
Iter: 1451 loss: 0.000171658452
Iter: 1452 loss: 0.000170957923
Iter: 1453 loss: 0.000170752479
Iter: 1454 loss: 0.000170804793
Iter: 1455 loss: 0.000170602783
Iter: 1456 loss: 0.000170386775
Iter: 1457 loss: 0.000173108609
Iter: 1458 loss: 0.000170385232
Iter: 1459 loss: 0.000170221218
Iter: 1460 loss: 0.000172658154
Iter: 1461 loss: 0.000170221276
Iter: 1462 loss: 0.000170145868
Iter: 1463 loss: 0.000169976702
Iter: 1464 loss: 0.000172312633
Iter: 1465 loss: 0.000169966734
Iter: 1466 loss: 0.000169770574
Iter: 1467 loss: 0.000170902684
Iter: 1468 loss: 0.000169745064
Iter: 1469 loss: 0.000169584586
Iter: 1470 loss: 0.000169582345
Iter: 1471 loss: 0.000169455961
Iter: 1472 loss: 0.00016927901
Iter: 1473 loss: 0.000170726009
Iter: 1474 loss: 0.000169267267
Iter: 1475 loss: 0.000169109189
Iter: 1476 loss: 0.000169176477
Iter: 1477 loss: 0.000169000952
Iter: 1478 loss: 0.000168804152
Iter: 1479 loss: 0.000169471925
Iter: 1480 loss: 0.000168751474
Iter: 1481 loss: 0.000168565064
Iter: 1482 loss: 0.000168660612
Iter: 1483 loss: 0.0001684413
Iter: 1484 loss: 0.000168188635
Iter: 1485 loss: 0.000169370687
Iter: 1486 loss: 0.000168141938
Iter: 1487 loss: 0.000167946695
Iter: 1488 loss: 0.000167819439
Iter: 1489 loss: 0.000167744482
Iter: 1490 loss: 0.000167553037
Iter: 1491 loss: 0.000167549064
Iter: 1492 loss: 0.000167432649
Iter: 1493 loss: 0.000167429098
Iter: 1494 loss: 0.000167371909
Iter: 1495 loss: 0.000167230595
Iter: 1496 loss: 0.00016860741
Iter: 1497 loss: 0.000167211576
Iter: 1498 loss: 0.000167065678
Iter: 1499 loss: 0.000168155209
Iter: 1500 loss: 0.000167053862
Iter: 1501 loss: 0.0001669341
Iter: 1502 loss: 0.000166972299
Iter: 1503 loss: 0.00016684935
Iter: 1504 loss: 0.000166713377
Iter: 1505 loss: 0.000167222868
Iter: 1506 loss: 0.000166680838
Iter: 1507 loss: 0.000166512589
Iter: 1508 loss: 0.000166599537
Iter: 1509 loss: 0.000166401063
Iter: 1510 loss: 0.000166202954
Iter: 1511 loss: 0.000166928381
Iter: 1512 loss: 0.000166153535
Iter: 1513 loss: 0.00016596209
Iter: 1514 loss: 0.000166088183
Iter: 1515 loss: 0.000165841251
Iter: 1516 loss: 0.000165606456
Iter: 1517 loss: 0.000166969388
Iter: 1518 loss: 0.000165575257
Iter: 1519 loss: 0.000165391888
Iter: 1520 loss: 0.000165265519
Iter: 1521 loss: 0.000165199046
Iter: 1522 loss: 0.000165005855
Iter: 1523 loss: 0.000165006
Iter: 1524 loss: 0.000164918194
Iter: 1525 loss: 0.000164905476
Iter: 1526 loss: 0.000164850528
Iter: 1527 loss: 0.000164710771
Iter: 1528 loss: 0.000165866164
Iter: 1529 loss: 0.00016468596
Iter: 1530 loss: 0.0001645476
Iter: 1531 loss: 0.000165416248
Iter: 1532 loss: 0.000164532088
Iter: 1533 loss: 0.000164401019
Iter: 1534 loss: 0.000164391589
Iter: 1535 loss: 0.000164292534
Iter: 1536 loss: 0.000164113138
Iter: 1537 loss: 0.000164436206
Iter: 1538 loss: 0.00016403466
Iter: 1539 loss: 0.000163777746
Iter: 1540 loss: 0.000164853962
Iter: 1541 loss: 0.000163723424
Iter: 1542 loss: 0.000163553093
Iter: 1543 loss: 0.000163921984
Iter: 1544 loss: 0.000163486504
Iter: 1545 loss: 0.000163297023
Iter: 1546 loss: 0.000163360819
Iter: 1547 loss: 0.000163163058
Iter: 1548 loss: 0.00016295386
Iter: 1549 loss: 0.000164777404
Iter: 1550 loss: 0.000162942844
Iter: 1551 loss: 0.00016279002
Iter: 1552 loss: 0.000162704731
Iter: 1553 loss: 0.000162638084
Iter: 1554 loss: 0.000162437616
Iter: 1555 loss: 0.000163631965
Iter: 1556 loss: 0.000162412311
Iter: 1557 loss: 0.000162350596
Iter: 1558 loss: 0.00016230793
Iter: 1559 loss: 0.000162245415
Iter: 1560 loss: 0.000162089273
Iter: 1561 loss: 0.000163499586
Iter: 1562 loss: 0.000162064913
Iter: 1563 loss: 0.000161909964
Iter: 1564 loss: 0.000162833021
Iter: 1565 loss: 0.000161890115
Iter: 1566 loss: 0.00016172172
Iter: 1567 loss: 0.000161743068
Iter: 1568 loss: 0.000161593634
Iter: 1569 loss: 0.000161405347
Iter: 1570 loss: 0.000161559947
Iter: 1571 loss: 0.000161293
Iter: 1572 loss: 0.000161102551
Iter: 1573 loss: 0.000162509954
Iter: 1574 loss: 0.000161086864
Iter: 1575 loss: 0.000160965457
Iter: 1576 loss: 0.000160885989
Iter: 1577 loss: 0.0001608397
Iter: 1578 loss: 0.00016057046
Iter: 1579 loss: 0.000161472461
Iter: 1580 loss: 0.000160497206
Iter: 1581 loss: 0.000160293304
Iter: 1582 loss: 0.000161586184
Iter: 1583 loss: 0.00016026973
Iter: 1584 loss: 0.000160083451
Iter: 1585 loss: 0.000159854942
Iter: 1586 loss: 0.000159834715
Iter: 1587 loss: 0.000159581454
Iter: 1588 loss: 0.000161979842
Iter: 1589 loss: 0.00015957182
Iter: 1590 loss: 0.000159491727
Iter: 1591 loss: 0.000159481933
Iter: 1592 loss: 0.000159403746
Iter: 1593 loss: 0.000159218776
Iter: 1594 loss: 0.00016139308
Iter: 1595 loss: 0.000159202857
Iter: 1596 loss: 0.000159045012
Iter: 1597 loss: 0.000159642397
Iter: 1598 loss: 0.000159006333
Iter: 1599 loss: 0.000158857205
Iter: 1600 loss: 0.00015962054
Iter: 1601 loss: 0.000158833252
Iter: 1602 loss: 0.000158740731
Iter: 1603 loss: 0.000158880081
Iter: 1604 loss: 0.000158696828
Iter: 1605 loss: 0.000158598559
Iter: 1606 loss: 0.000159355579
Iter: 1607 loss: 0.000158592011
Iter: 1608 loss: 0.00015850761
Iter: 1609 loss: 0.000158321258
Iter: 1610 loss: 0.000160974712
Iter: 1611 loss: 0.000158311246
Iter: 1612 loss: 0.00015807437
Iter: 1613 loss: 0.000159455405
Iter: 1614 loss: 0.000158043942
Iter: 1615 loss: 0.000157842878
Iter: 1616 loss: 0.000158277777
Iter: 1617 loss: 0.000157764647
Iter: 1618 loss: 0.000157515489
Iter: 1619 loss: 0.000157914532
Iter: 1620 loss: 0.000157400325
Iter: 1621 loss: 0.000157254486
Iter: 1622 loss: 0.000158723153
Iter: 1623 loss: 0.000157250033
Iter: 1624 loss: 0.000157170449
Iter: 1625 loss: 0.000157169445
Iter: 1626 loss: 0.000157095259
Iter: 1627 loss: 0.000156978218
Iter: 1628 loss: 0.000156976341
Iter: 1629 loss: 0.000156884
Iter: 1630 loss: 0.000157048256
Iter: 1631 loss: 0.000156842958
Iter: 1632 loss: 0.000156735216
Iter: 1633 loss: 0.000157303846
Iter: 1634 loss: 0.000156718423
Iter: 1635 loss: 0.00015662513
Iter: 1636 loss: 0.000156568087
Iter: 1637 loss: 0.000156530266
Iter: 1638 loss: 0.000156413749
Iter: 1639 loss: 0.000157885574
Iter: 1640 loss: 0.000156412614
Iter: 1641 loss: 0.00015630397
Iter: 1642 loss: 0.000156124064
Iter: 1643 loss: 0.000156122929
Iter: 1644 loss: 0.000155911461
Iter: 1645 loss: 0.0001566383
Iter: 1646 loss: 0.00015585628
Iter: 1647 loss: 0.000155672882
Iter: 1648 loss: 0.000156876064
Iter: 1649 loss: 0.000155653353
Iter: 1650 loss: 0.000155530637
Iter: 1651 loss: 0.000155919057
Iter: 1652 loss: 0.000155495858
Iter: 1653 loss: 0.000155361136
Iter: 1654 loss: 0.000155146015
Iter: 1655 loss: 0.000155145157
Iter: 1656 loss: 0.00015532822
Iter: 1657 loss: 0.000155052519
Iter: 1658 loss: 0.000154994705
Iter: 1659 loss: 0.000154885958
Iter: 1660 loss: 0.000157305956
Iter: 1661 loss: 0.0001548859
Iter: 1662 loss: 0.000154744819
Iter: 1663 loss: 0.000154619935
Iter: 1664 loss: 0.00015458242
Iter: 1665 loss: 0.000154402398
Iter: 1666 loss: 0.0001543978
Iter: 1667 loss: 0.000154267414
Iter: 1668 loss: 0.000154299167
Iter: 1669 loss: 0.000154172332
Iter: 1670 loss: 0.00015406069
Iter: 1671 loss: 0.000154463167
Iter: 1672 loss: 0.000154032386
Iter: 1673 loss: 0.000153895293
Iter: 1674 loss: 0.000153894463
Iter: 1675 loss: 0.000153785135
Iter: 1676 loss: 0.000153659013
Iter: 1677 loss: 0.000153820089
Iter: 1678 loss: 0.000153594709
Iter: 1679 loss: 0.000153434245
Iter: 1680 loss: 0.000153871952
Iter: 1681 loss: 0.000153381639
Iter: 1682 loss: 0.000153230096
Iter: 1683 loss: 0.000153341462
Iter: 1684 loss: 0.000153137313
Iter: 1685 loss: 0.00015295489
Iter: 1686 loss: 0.0001528094
Iter: 1687 loss: 0.000152754365
Iter: 1688 loss: 0.000152801236
Iter: 1689 loss: 0.000152667984
Iter: 1690 loss: 0.000152576948
Iter: 1691 loss: 0.000152447319
Iter: 1692 loss: 0.000152442779
Iter: 1693 loss: 0.000152305292
Iter: 1694 loss: 0.000152374414
Iter: 1695 loss: 0.00015221331
Iter: 1696 loss: 0.000152080509
Iter: 1697 loss: 0.000152838547
Iter: 1698 loss: 0.000152062697
Iter: 1699 loss: 0.000151922941
Iter: 1700 loss: 0.00015254991
Iter: 1701 loss: 0.000151895219
Iter: 1702 loss: 0.000151808708
Iter: 1703 loss: 0.000151843764
Iter: 1704 loss: 0.000151748798
Iter: 1705 loss: 0.000151621876
Iter: 1706 loss: 0.000152068
Iter: 1707 loss: 0.00015158912
Iter: 1708 loss: 0.000151466549
Iter: 1709 loss: 0.000151249493
Iter: 1710 loss: 0.000151249173
Iter: 1711 loss: 0.000151069631
Iter: 1712 loss: 0.000153385627
Iter: 1713 loss: 0.000151068
Iter: 1714 loss: 0.000150948501
Iter: 1715 loss: 0.000151583023
Iter: 1716 loss: 0.000150930675
Iter: 1717 loss: 0.000150830878
Iter: 1718 loss: 0.000151194094
Iter: 1719 loss: 0.000150806038
Iter: 1720 loss: 0.000150722262
Iter: 1721 loss: 0.000150577864
Iter: 1722 loss: 0.00015057766
Iter: 1723 loss: 0.000150530541
Iter: 1724 loss: 0.000150492269
Iter: 1725 loss: 0.00015039189
Iter: 1726 loss: 0.000150470194
Iter: 1727 loss: 0.000150330452
Iter: 1728 loss: 0.000150266191
Iter: 1729 loss: 0.000150186563
Iter: 1730 loss: 0.000150179636
Iter: 1731 loss: 0.000150071661
Iter: 1732 loss: 0.000150574371
Iter: 1733 loss: 0.000150051463
Iter: 1734 loss: 0.000149939864
Iter: 1735 loss: 0.000150215128
Iter: 1736 loss: 0.000149900501
Iter: 1737 loss: 0.000149814616
Iter: 1738 loss: 0.000150169013
Iter: 1739 loss: 0.00014979564
Iter: 1740 loss: 0.000149693864
Iter: 1741 loss: 0.000149603307
Iter: 1742 loss: 0.000149577187
Iter: 1743 loss: 0.000149422369
Iter: 1744 loss: 0.000149686588
Iter: 1745 loss: 0.000149353116
Iter: 1746 loss: 0.00014921205
Iter: 1747 loss: 0.000149791056
Iter: 1748 loss: 0.000149181666
Iter: 1749 loss: 0.000149046493
Iter: 1750 loss: 0.000149740081
Iter: 1751 loss: 0.00014902465
Iter: 1752 loss: 0.000148915948
Iter: 1753 loss: 0.000149610569
Iter: 1754 loss: 0.000148903928
Iter: 1755 loss: 0.000148831023
Iter: 1756 loss: 0.000148876541
Iter: 1757 loss: 0.000148784588
Iter: 1758 loss: 0.000148769468
Iter: 1759 loss: 0.000148739637
Iter: 1760 loss: 0.000148717983
Iter: 1761 loss: 0.000148647639
Iter: 1762 loss: 0.00014867702
Iter: 1763 loss: 0.000148582229
Iter: 1764 loss: 0.000148477557
Iter: 1765 loss: 0.000149979227
Iter: 1766 loss: 0.000148477629
Iter: 1767 loss: 0.000148368417
Iter: 1768 loss: 0.000148728024
Iter: 1769 loss: 0.000148338251
Iter: 1770 loss: 0.00014823355
Iter: 1771 loss: 0.000148253748
Iter: 1772 loss: 0.000148156076
Iter: 1773 loss: 0.000148030012
Iter: 1774 loss: 0.0001480965
Iter: 1775 loss: 0.000147946426
Iter: 1776 loss: 0.000147754647
Iter: 1777 loss: 0.000148284016
Iter: 1778 loss: 0.000147693296
Iter: 1779 loss: 0.000147523766
Iter: 1780 loss: 0.000147392086
Iter: 1781 loss: 0.000147338753
Iter: 1782 loss: 0.000147104598
Iter: 1783 loss: 0.000149900807
Iter: 1784 loss: 0.000147101295
Iter: 1785 loss: 0.000146962819
Iter: 1786 loss: 0.000147348546
Iter: 1787 loss: 0.000146918464
Iter: 1788 loss: 0.000146791659
Iter: 1789 loss: 0.000147579151
Iter: 1790 loss: 0.000146777835
Iter: 1791 loss: 0.000146718288
Iter: 1792 loss: 0.000146715669
Iter: 1793 loss: 0.000146666192
Iter: 1794 loss: 0.000146539183
Iter: 1795 loss: 0.000147534272
Iter: 1796 loss: 0.000146514314
Iter: 1797 loss: 0.000146386126
Iter: 1798 loss: 0.000146379927
Iter: 1799 loss: 0.000146281207
Iter: 1800 loss: 0.000146182487
Iter: 1801 loss: 0.00014616987
Iter: 1802 loss: 0.000146084407
Iter: 1803 loss: 0.000146076578
Iter: 1804 loss: 0.000146012768
Iter: 1805 loss: 0.000145857484
Iter: 1806 loss: 0.000145979255
Iter: 1807 loss: 0.000145763304
Iter: 1808 loss: 0.000145651778
Iter: 1809 loss: 0.000146041406
Iter: 1810 loss: 0.00014562186
Iter: 1811 loss: 0.000145498605
Iter: 1812 loss: 0.000145638071
Iter: 1813 loss: 0.00014543219
Iter: 1814 loss: 0.00014532276
Iter: 1815 loss: 0.000145423284
Iter: 1816 loss: 0.000145260216
Iter: 1817 loss: 0.000145125698
Iter: 1818 loss: 0.000146539329
Iter: 1819 loss: 0.000145122685
Iter: 1820 loss: 0.000145026483
Iter: 1821 loss: 0.000145265338
Iter: 1822 loss: 0.000144992024
Iter: 1823 loss: 0.000144941179
Iter: 1824 loss: 0.000144934369
Iter: 1825 loss: 0.000144886406
Iter: 1826 loss: 0.000144767138
Iter: 1827 loss: 0.000145961734
Iter: 1828 loss: 0.000144752208
Iter: 1829 loss: 0.000144613688
Iter: 1830 loss: 0.000144738558
Iter: 1831 loss: 0.000144532722
Iter: 1832 loss: 0.000144434307
Iter: 1833 loss: 0.000144432313
Iter: 1834 loss: 0.000144330217
Iter: 1835 loss: 0.000144237609
Iter: 1836 loss: 0.000144212332
Iter: 1837 loss: 0.00014404676
Iter: 1838 loss: 0.00014476855
Iter: 1839 loss: 0.000144012796
Iter: 1840 loss: 0.000143877915
Iter: 1841 loss: 0.00014379916
Iter: 1842 loss: 0.000143742902
Iter: 1843 loss: 0.000143544035
Iter: 1844 loss: 0.000144911101
Iter: 1845 loss: 0.00014352474
Iter: 1846 loss: 0.000143395067
Iter: 1847 loss: 0.000143357523
Iter: 1848 loss: 0.000143279525
Iter: 1849 loss: 0.000143119105
Iter: 1850 loss: 0.000144565245
Iter: 1851 loss: 0.000143110869
Iter: 1852 loss: 0.00014297459
Iter: 1853 loss: 0.000143548459
Iter: 1854 loss: 0.000142945937
Iter: 1855 loss: 0.000142877107
Iter: 1856 loss: 0.000142871897
Iter: 1857 loss: 0.000142801466
Iter: 1858 loss: 0.000142666511
Iter: 1859 loss: 0.000145497586
Iter: 1860 loss: 0.000142665318
Iter: 1861 loss: 0.000142549805
Iter: 1862 loss: 0.000142574136
Iter: 1863 loss: 0.000142464327
Iter: 1864 loss: 0.000142331497
Iter: 1865 loss: 0.000143349418
Iter: 1866 loss: 0.000142322388
Iter: 1867 loss: 0.000142182223
Iter: 1868 loss: 0.000142852805
Iter: 1869 loss: 0.000142156918
Iter: 1870 loss: 0.000142066041
Iter: 1871 loss: 0.000142162229
Iter: 1872 loss: 0.0001420154
Iter: 1873 loss: 0.000141889614
Iter: 1874 loss: 0.000141864555
Iter: 1875 loss: 0.000141780809
Iter: 1876 loss: 0.000141643599
Iter: 1877 loss: 0.000142420846
Iter: 1878 loss: 0.000141625016
Iter: 1879 loss: 0.000141504017
Iter: 1880 loss: 0.000141717552
Iter: 1881 loss: 0.000141451106
Iter: 1882 loss: 0.000141329874
Iter: 1883 loss: 0.000141459182
Iter: 1884 loss: 0.000141263168
Iter: 1885 loss: 0.000141131051
Iter: 1886 loss: 0.000142721
Iter: 1887 loss: 0.000141129378
Iter: 1888 loss: 0.000141078577
Iter: 1889 loss: 0.0001410767
Iter: 1890 loss: 0.000141023847
Iter: 1891 loss: 0.000140926801
Iter: 1892 loss: 0.000143190409
Iter: 1893 loss: 0.000140926611
Iter: 1894 loss: 0.000140833959
Iter: 1895 loss: 0.000140769582
Iter: 1896 loss: 0.000140736345
Iter: 1897 loss: 0.000140590098
Iter: 1898 loss: 0.000141183395
Iter: 1899 loss: 0.000140557517
Iter: 1900 loss: 0.000140455479
Iter: 1901 loss: 0.000140453776
Iter: 1902 loss: 0.0001403934
Iter: 1903 loss: 0.000140280987
Iter: 1904 loss: 0.000142831384
Iter: 1905 loss: 0.000140280797
Iter: 1906 loss: 0.000140122356
Iter: 1907 loss: 0.000140705786
Iter: 1908 loss: 0.000140083255
Iter: 1909 loss: 0.00013998177
Iter: 1910 loss: 0.000140031378
Iter: 1911 loss: 0.000139913551
Iter: 1912 loss: 0.000139765034
Iter: 1913 loss: 0.000140320335
Iter: 1914 loss: 0.000139729513
Iter: 1915 loss: 0.000139596086
Iter: 1916 loss: 0.000139730066
Iter: 1917 loss: 0.000139521406
Iter: 1918 loss: 0.000139410389
Iter: 1919 loss: 0.000139410564
Iter: 1920 loss: 0.00013935985
Iter: 1921 loss: 0.000139952899
Iter: 1922 loss: 0.000139358992
Iter: 1923 loss: 0.000139301206
Iter: 1924 loss: 0.00013926113
Iter: 1925 loss: 0.000139240554
Iter: 1926 loss: 0.000139167911
Iter: 1927 loss: 0.000139054842
Iter: 1928 loss: 0.000139053242
Iter: 1929 loss: 0.000138923147
Iter: 1930 loss: 0.000139684329
Iter: 1931 loss: 0.000138906253
Iter: 1932 loss: 0.000138827178
Iter: 1933 loss: 0.000138826654
Iter: 1934 loss: 0.000138760108
Iter: 1935 loss: 0.000138630174
Iter: 1936 loss: 0.000141234574
Iter: 1937 loss: 0.000138629388
Iter: 1938 loss: 0.000138499701
Iter: 1939 loss: 0.000139722295
Iter: 1940 loss: 0.000138494521
Iter: 1941 loss: 0.00013841092
Iter: 1942 loss: 0.000138355783
Iter: 1943 loss: 0.00013832454
Iter: 1944 loss: 0.000138208619
Iter: 1945 loss: 0.000138846124
Iter: 1946 loss: 0.000138192
Iter: 1947 loss: 0.00013808228
Iter: 1948 loss: 0.000138228686
Iter: 1949 loss: 0.000138026968
Iter: 1950 loss: 0.000137936047
Iter: 1951 loss: 0.000138781659
Iter: 1952 loss: 0.000137932409
Iter: 1953 loss: 0.000137872063
Iter: 1954 loss: 0.000138633404
Iter: 1955 loss: 0.000137871844
Iter: 1956 loss: 0.000137816
Iter: 1957 loss: 0.00013784974
Iter: 1958 loss: 0.000137780095
Iter: 1959 loss: 0.000137731229
Iter: 1960 loss: 0.000137616662
Iter: 1961 loss: 0.000138947973
Iter: 1962 loss: 0.000137606781
Iter: 1963 loss: 0.000137478288
Iter: 1964 loss: 0.000138429517
Iter: 1965 loss: 0.000137467519
Iter: 1966 loss: 0.000137394527
Iter: 1967 loss: 0.000137393683
Iter: 1968 loss: 0.000137322582
Iter: 1969 loss: 0.000137199168
Iter: 1970 loss: 0.00013719924
Iter: 1971 loss: 0.000137086463
Iter: 1972 loss: 0.000138241201
Iter: 1973 loss: 0.000137083378
Iter: 1974 loss: 0.000137013718
Iter: 1975 loss: 0.000136978662
Iter: 1976 loss: 0.0001369456
Iter: 1977 loss: 0.000136840201
Iter: 1978 loss: 0.000137125535
Iter: 1979 loss: 0.000136805815
Iter: 1980 loss: 0.000136694391
Iter: 1981 loss: 0.000137031951
Iter: 1982 loss: 0.000136660383
Iter: 1983 loss: 0.000136559451
Iter: 1984 loss: 0.00013702453
Iter: 1985 loss: 0.000136540271
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/k4
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0
+ date
Tue Oct 27 19:54:56 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf3404b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf3407ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf3407c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf3402cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf3402f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf3402f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33f8eb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf3402f048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33fb3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33fb3c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33eea268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33ec9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33fb3ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33e63d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33e63950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33e34048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33e34400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33e342f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33d9eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33d9ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33d54378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33d54d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33d41598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33cc7d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33cc7e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33c9e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33c578c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33c57048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33c65840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33ce06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33c08b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33bf7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33b99488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33bf7bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33bb6f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fdf33b1a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.00221821712
Iter: 2 loss: 0.00220804708
Iter: 3 loss: 0.00216994202
Iter: 4 loss: 0.00204168796
Iter: 5 loss: 0.00301897107
Iter: 6 loss: 0.00201440044
Iter: 7 loss: 0.00195144652
Iter: 8 loss: 0.00230514398
Iter: 9 loss: 0.00194261572
Iter: 10 loss: 0.0019065371
Iter: 11 loss: 0.00235616323
Iter: 12 loss: 0.00190621405
Iter: 13 loss: 0.00188907306
Iter: 14 loss: 0.00189521129
Iter: 15 loss: 0.00187705993
Iter: 16 loss: 0.00186670828
Iter: 17 loss: 0.00200112024
Iter: 18 loss: 0.00186663913
Iter: 19 loss: 0.00185988448
Iter: 20 loss: 0.00189613609
Iter: 21 loss: 0.00185886561
Iter: 22 loss: 0.00185571192
Iter: 23 loss: 0.00185728283
Iter: 24 loss: 0.0018536069
Iter: 25 loss: 0.001851846
Iter: 26 loss: 0.00185184111
Iter: 27 loss: 0.0018506
Iter: 28 loss: 0.00185714802
Iter: 29 loss: 0.00185040757
Iter: 30 loss: 0.0018498844
Iter: 31 loss: 0.00184987276
Iter: 32 loss: 0.00184946181
Iter: 33 loss: 0.0018490986
Iter: 34 loss: 0.00185273529
Iter: 35 loss: 0.00184908696
Iter: 36 loss: 0.00184893282
Iter: 37 loss: 0.00184892653
Iter: 38 loss: 0.00184885308
Iter: 39 loss: 0.00184882176
Iter: 40 loss: 0.00184878381
Iter: 41 loss: 0.00184872479
Iter: 42 loss: 0.0018489497
Iter: 43 loss: 0.00184871047
Iter: 44 loss: 0.00184867927
Iter: 45 loss: 0.00184889138
Iter: 46 loss: 0.00184867682
Iter: 47 loss: 0.00184866483
Iter: 48 loss: 0.0018488284
Iter: 49 loss: 0.00184866483
Iter: 50 loss: 0.00184865808
Iter: 51 loss: 0.00184874341
Iter: 52 loss: 0.00184865866
Iter: 53 loss: 0.00184865482
Iter: 54 loss: 0.00184865773
Iter: 55 loss: 0.00184865342
Iter: 56 loss: 0.00184865086
Iter: 57 loss: 0.00184866739
Iter: 58 loss: 0.0018486504
Iter: 59 loss: 0.00184864958
Iter: 60 loss: 0.0018486625
Iter: 61 loss: 0.0018486497
Iter: 62 loss: 0.00184864877
Iter: 63 loss: 0.00184864888
Iter: 64 loss: 0.00184864772
Iter: 65 loss: 0.00184864784
Iter: 66 loss: 0.00184865016
Iter: 67 loss: 0.00184864772
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4
+ date
Tue Oct 27 19:55:36 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9595488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a95941e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8be029840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a95d4bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9534d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9528f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9513f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a94c6950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a94dfd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a94c6e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9439598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9458f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9458e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9439488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a93d6400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a93d6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a936b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a938f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a935bc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a92fb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a930d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a92be7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a92fbd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9297510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9297f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a91e4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a92168c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a92169d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a91c2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a9163378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a91c29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a914d488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a915c1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a90f0d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a90ae510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff8a90ae378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0284755155
Iter: 2 loss: 0.0273381881
Iter: 3 loss: 0.0231363475
Iter: 4 loss: 0.00964224059
Iter: 5 loss: 0.186315805
Iter: 6 loss: 0.00808439497
Iter: 7 loss: 0.00340528367
Iter: 8 loss: 0.0798666179
Iter: 9 loss: 0.00340119656
Iter: 10 loss: 0.00291104754
Iter: 11 loss: 0.00255421735
Iter: 12 loss: 0.00229358044
Iter: 13 loss: 0.00283930753
Iter: 14 loss: 0.00218958035
Iter: 15 loss: 0.00207202067
Iter: 16 loss: 0.00301786675
Iter: 17 loss: 0.00206391048
Iter: 18 loss: 0.00200973498
Iter: 19 loss: 0.00268255919
Iter: 20 loss: 0.00200919854
Iter: 21 loss: 0.00198511104
Iter: 22 loss: 0.00202179071
Iter: 23 loss: 0.00197357917
Iter: 24 loss: 0.00195914553
Iter: 25 loss: 0.00213080598
Iter: 26 loss: 0.00195895624
Iter: 27 loss: 0.00194990286
Iter: 28 loss: 0.00196769
Iter: 29 loss: 0.00194617233
Iter: 30 loss: 0.00194127974
Iter: 31 loss: 0.00194765232
Iter: 32 loss: 0.00193877658
Iter: 33 loss: 0.00193561614
Iter: 34 loss: 0.00196970394
Iter: 35 loss: 0.00193554373
Iter: 36 loss: 0.00193330983
Iter: 37 loss: 0.00193975633
Iter: 38 loss: 0.00193261565
Iter: 39 loss: 0.00193126674
Iter: 40 loss: 0.00193422928
Iter: 41 loss: 0.00193074637
Iter: 42 loss: 0.00192993903
Iter: 43 loss: 0.00193320331
Iter: 44 loss: 0.0019297594
Iter: 45 loss: 0.00192930945
Iter: 46 loss: 0.00193215674
Iter: 47 loss: 0.00192925846
Iter: 48 loss: 0.00192901166
Iter: 49 loss: 0.00193052622
Iter: 50 loss: 0.00192898209
Iter: 51 loss: 0.00192885159
Iter: 52 loss: 0.00192989199
Iter: 53 loss: 0.00192884391
Iter: 54 loss: 0.00192876533
Iter: 55 loss: 0.00192949316
Iter: 56 loss: 0.00192876253
Iter: 57 loss: 0.00192872155
Iter: 58 loss: 0.00192876696
Iter: 59 loss: 0.00192869885
Iter: 60 loss: 0.00192867033
Iter: 61 loss: 0.00192900328
Iter: 62 loss: 0.00192866928
Iter: 63 loss: 0.00192865066
Iter: 64 loss: 0.00192875275
Iter: 65 loss: 0.00192864821
Iter: 66 loss: 0.00192863727
Iter: 67 loss: 0.00192866288
Iter: 68 loss: 0.00192863308
Iter: 69 loss: 0.0019286254
Iter: 70 loss: 0.0019286914
Iter: 71 loss: 0.00192862435
Iter: 72 loss: 0.00192861934
Iter: 73 loss: 0.00192863168
Iter: 74 loss: 0.00192861794
Iter: 75 loss: 0.0019286148
Iter: 76 loss: 0.00192862866
Iter: 77 loss: 0.00192861352
Iter: 78 loss: 0.00192861143
Iter: 79 loss: 0.00192862516
Iter: 80 loss: 0.00192861154
Iter: 81 loss: 0.00192861026
Iter: 82 loss: 0.00192861829
Iter: 83 loss: 0.00192860945
Iter: 84 loss: 0.00192860863
Iter: 85 loss: 0.00192861
Iter: 86 loss: 0.00192860793
Iter: 87 loss: 0.00192860793
Iter: 88 loss: 0.00192861166
Iter: 89 loss: 0.00192860805
Iter: 90 loss: 0.00192860758
Iter: 91 loss: 0.0019286098
Iter: 92 loss: 0.00192860758
Iter: 93 loss: 0.00192860758
Iter: 94 loss: 0.00192860747
Iter: 95 loss: 0.00192860689
Iter: 96 loss: 0.00192860712
Iter: 97 loss: 0.0019286077
Iter: 98 loss: 0.00192860677
Iter: 99 loss: 0.00192860735
Iter: 100 loss: 0.00192860654
Iter: 101 loss: 0.00192860758
Iter: 102 loss: 0.00192860689
Iter: 103 loss: 0.00192860677
Iter: 104 loss: 0.00192860654
Iter: 105 loss: 0.00192860654
Iter: 106 loss: 0.00192860677
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8
+ date
Tue Oct 27 19:56:27 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9deea9a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9e307adf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9e307add90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9deea4e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dee9a4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dee9a41e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dc80a5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dc80cf730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dc80cf9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dc80cfd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dc8035598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9dc8050e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9db00f9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9db00b9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9db00b9730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9db0082d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9db009d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9db0082ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64770598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d6479e620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d6472b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64746950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d647468c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d6472b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d647158c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64667598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d6469a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64645730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d6464f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d6464f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64619a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d645c5620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d645c51e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64572620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64530400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9d64542d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0210845042
Iter: 2 loss: 0.0201475751
Iter: 3 loss: 0.0167907476
Iter: 4 loss: 0.0143774897
Iter: 5 loss: 0.0119000832
Iter: 6 loss: 0.00693139061
Iter: 7 loss: 0.0788003951
Iter: 8 loss: 0.00658156909
Iter: 9 loss: 0.00355866342
Iter: 10 loss: 0.00350764766
Iter: 11 loss: 0.00290254271
Iter: 12 loss: 0.00687323837
Iter: 13 loss: 0.00280479854
Iter: 14 loss: 0.00257532578
Iter: 15 loss: 0.00257465616
Iter: 16 loss: 0.002436487
Iter: 17 loss: 0.00257716537
Iter: 18 loss: 0.00236025872
Iter: 19 loss: 0.00225597527
Iter: 20 loss: 0.0025681823
Iter: 21 loss: 0.00222260132
Iter: 22 loss: 0.00216237409
Iter: 23 loss: 0.00251160562
Iter: 24 loss: 0.00215408183
Iter: 25 loss: 0.00211996445
Iter: 26 loss: 0.00237906957
Iter: 27 loss: 0.00211733766
Iter: 28 loss: 0.00209728046
Iter: 29 loss: 0.00215943344
Iter: 30 loss: 0.0020913356
Iter: 31 loss: 0.00207983842
Iter: 32 loss: 0.00212681154
Iter: 33 loss: 0.00207730988
Iter: 34 loss: 0.00207036547
Iter: 35 loss: 0.00211348524
Iter: 36 loss: 0.00206954475
Iter: 37 loss: 0.00206508813
Iter: 38 loss: 0.00208443
Iter: 39 loss: 0.00206416892
Iter: 40 loss: 0.00206122315
Iter: 41 loss: 0.00207713596
Iter: 42 loss: 0.00206078659
Iter: 43 loss: 0.00205879356
Iter: 44 loss: 0.00206938526
Iter: 45 loss: 0.00205848482
Iter: 46 loss: 0.00205702381
Iter: 47 loss: 0.00206000917
Iter: 48 loss: 0.00205643848
Iter: 49 loss: 0.00205512578
Iter: 50 loss: 0.00205731578
Iter: 51 loss: 0.00205453089
Iter: 52 loss: 0.00205331109
Iter: 53 loss: 0.00206201267
Iter: 54 loss: 0.0020532026
Iter: 55 loss: 0.00205233484
Iter: 56 loss: 0.00205842243
Iter: 57 loss: 0.00205225591
Iter: 58 loss: 0.00205166824
Iter: 59 loss: 0.00205184636
Iter: 60 loss: 0.00205124542
Iter: 61 loss: 0.00205068802
Iter: 62 loss: 0.00205214
Iter: 63 loss: 0.00205049827
Iter: 64 loss: 0.00205001957
Iter: 65 loss: 0.00205199816
Iter: 66 loss: 0.00204991503
Iter: 67 loss: 0.00204956252
Iter: 68 loss: 0.002051319
Iter: 69 loss: 0.00204950362
Iter: 70 loss: 0.00204924
Iter: 71 loss: 0.00205015042
Iter: 72 loss: 0.0020491709
Iter: 73 loss: 0.00204898627
Iter: 74 loss: 0.0020499269
Iter: 75 loss: 0.0020489567
Iter: 76 loss: 0.00204883679
Iter: 77 loss: 0.00205005542
Iter: 78 loss: 0.00204883283
Iter: 79 loss: 0.0020487518
Iter: 80 loss: 0.00204910059
Iter: 81 loss: 0.00204873411
Iter: 82 loss: 0.00204867683
Iter: 83 loss: 0.00204874016
Iter: 84 loss: 0.00204864424
Iter: 85 loss: 0.00204859255
Iter: 86 loss: 0.00204880396
Iter: 87 loss: 0.00204858137
Iter: 88 loss: 0.00204855367
Iter: 89 loss: 0.00204895856
Iter: 90 loss: 0.00204855343
Iter: 91 loss: 0.00204853504
Iter: 92 loss: 0.00204858417
Iter: 93 loss: 0.00204852805
Iter: 94 loss: 0.00204851385
Iter: 95 loss: 0.00204853527
Iter: 96 loss: 0.00204850733
Iter: 97 loss: 0.00204849546
Iter: 98 loss: 0.00204853644
Iter: 99 loss: 0.00204849266
Iter: 100 loss: 0.00204848335
Iter: 101 loss: 0.00204851152
Iter: 102 loss: 0.00204848149
Iter: 103 loss: 0.0020484752
Iter: 104 loss: 0.00204851571
Iter: 105 loss: 0.00204847427
Iter: 106 loss: 0.00204847101
Iter: 107 loss: 0.00204848591
Iter: 108 loss: 0.00204847
Iter: 109 loss: 0.00204846775
Iter: 110 loss: 0.00204848
Iter: 111 loss: 0.00204846729
Iter: 112 loss: 0.00204846589
Iter: 113 loss: 0.00204848335
Iter: 114 loss: 0.00204846589
Iter: 115 loss: 0.00204846496
Iter: 116 loss: 0.00204846798
Iter: 117 loss: 0.00204846449
Iter: 118 loss: 0.00204846403
Iter: 119 loss: 0.00204846449
Iter: 120 loss: 0.00204846356
Iter: 121 loss: 0.00204846286
Iter: 122 loss: 0.00204846566
Iter: 123 loss: 0.00204846309
Iter: 124 loss: 0.00204846193
Iter: 125 loss: 0.00204846659
Iter: 126 loss: 0.00204846216
Iter: 127 loss: 0.00204846216
Iter: 128 loss: 0.00204846216
Iter: 129 loss: 0.00204846193
Iter: 130 loss: 0.00204846193
Iter: 131 loss: 0.00204846216
Iter: 132 loss: 0.0020484617
Iter: 133 loss: 0.002048461
Iter: 134 loss: 0.00204846263
Iter: 135 loss: 0.00204846123
Iter: 136 loss: 0.00204846147
Iter: 137 loss: 0.0020484617
Iter: 138 loss: 0.00204846147
Iter: 139 loss: 0.002048461
Iter: 140 loss: 0.00204846123
Iter: 141 loss: 0.00204846123
Iter: 142 loss: 0.00204846123
Iter: 143 loss: 0.00204846123
Iter: 144 loss: 0.00204846
Iter: 145 loss: 0.00204846077
Iter: 146 loss: 0.00204846077
Iter: 147 loss: 0.00204846077
Iter: 148 loss: 0.002048461
Iter: 149 loss: 0.002048461
Iter: 150 loss: 0.0020484603
Iter: 151 loss: 0.0020484603
Iter: 152 loss: 0.00204846123
Iter: 153 loss: 0.002048461
Iter: 154 loss: 0.00204846053
Iter: 155 loss: 0.00204846123
Iter: 156 loss: 0.00204846077
Iter: 157 loss: 0.00204846123
Iter: 158 loss: 0.002048461
Iter: 159 loss: 0.00204846123
Iter: 160 loss: 0.0020484617
Iter: 161 loss: 0.0020484603
Iter: 162 loss: 0.002048461
Iter: 163 loss: 0.0020484603
Iter: 164 loss: 0.00204846147
Iter: 165 loss: 0.00204846123
Iter: 166 loss: 0.00204846123
Iter: 167 loss: 0.00204846077
Iter: 168 loss: 0.00204846123
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2
+ date
Tue Oct 27 19:57:32 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d7466730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5a00724d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5a00724ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d74a5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d73fd7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d74179d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d73ead90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d739a9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d73b4378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d73b47b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d73109d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d72c90d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d72c9c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d7279bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d72b3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d7242d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d7254730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d72b30d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d722fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d71e2048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d71e21e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d7193620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d71509d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d7167f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d70fa840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d710ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d70eb620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d708c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d70eb840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d703d158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d706b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d706b048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d706b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d6fc0ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d6f7b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f59d6f8ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0226670802
Iter: 2 loss: 0.0202026777
Iter: 3 loss: 0.0135721043
Iter: 4 loss: 2255.02197
Iter: 5 loss: 0.0722415149
Iter: 6 loss: 0.0211060774
Iter: 7 loss: 0.03565339
Iter: 8 loss: 0.0131542692
Iter: 9 loss: 0.0131474864
Iter: 10 loss: 0.0100872423
Iter: 11 loss: 0.0109777618
Iter: 12 loss: 0.00748517178
Iter: 13 loss: 0.00458394457
Iter: 14 loss: 0.0719013959
Iter: 15 loss: 0.00458393153
Iter: 16 loss: 0.00367231085
Iter: 17 loss: 0.016159229
Iter: 18 loss: 0.00364059303
Iter: 19 loss: 0.00317786261
Iter: 20 loss: 0.0114647895
Iter: 21 loss: 0.00317254756
Iter: 22 loss: 0.00293029845
Iter: 23 loss: 0.00386038935
Iter: 24 loss: 0.00287490711
Iter: 25 loss: 0.00271118665
Iter: 26 loss: 0.00433921441
Iter: 27 loss: 0.0027008662
Iter: 28 loss: 0.00260740286
Iter: 29 loss: 0.00291847065
Iter: 30 loss: 0.00258316612
Iter: 31 loss: 0.00250268215
Iter: 32 loss: 0.0026373486
Iter: 33 loss: 0.00246458128
Iter: 34 loss: 0.00238894578
Iter: 35 loss: 0.00275428244
Iter: 36 loss: 0.00237527769
Iter: 37 loss: 0.0023223015
Iter: 38 loss: 0.00260523334
Iter: 39 loss: 0.00231380877
Iter: 40 loss: 0.00227676891
Iter: 41 loss: 0.00239207596
Iter: 42 loss: 0.00226572901
Iter: 43 loss: 0.0022359516
Iter: 44 loss: 0.00235982565
Iter: 45 loss: 0.00222955178
Iter: 46 loss: 0.00221063104
Iter: 47 loss: 0.00238477113
Iter: 48 loss: 0.00220974581
Iter: 49 loss: 0.00219743978
Iter: 50 loss: 0.00223540096
Iter: 51 loss: 0.00219374313
Iter: 52 loss: 0.0021859468
Iter: 53 loss: 0.00222644769
Iter: 54 loss: 0.00218469044
Iter: 55 loss: 0.0021799684
Iter: 56 loss: 0.00221027969
Iter: 57 loss: 0.00217944128
Iter: 58 loss: 0.00217607548
Iter: 59 loss: 0.00220305868
Iter: 60 loss: 0.00217585778
Iter: 61 loss: 0.00217357115
Iter: 62 loss: 0.00218373863
Iter: 63 loss: 0.00217310758
Iter: 64 loss: 0.00217123283
Iter: 65 loss: 0.00218102778
Iter: 66 loss: 0.00217094203
Iter: 67 loss: 0.002169454
Iter: 68 loss: 0.00216977461
Iter: 69 loss: 0.00216835365
Iter: 70 loss: 0.00216671219
Iter: 71 loss: 0.0021695036
Iter: 72 loss: 0.00216597551
Iter: 73 loss: 0.00216431962
Iter: 74 loss: 0.00216676109
Iter: 75 loss: 0.00216352055
Iter: 76 loss: 0.0021618607
Iter: 77 loss: 0.00216697762
Iter: 78 loss: 0.00216137012
Iter: 79 loss: 0.00215991307
Iter: 80 loss: 0.00216556783
Iter: 81 loss: 0.00215957384
Iter: 82 loss: 0.00215835683
Iter: 83 loss: 0.0021639138
Iter: 84 loss: 0.00215812493
Iter: 85 loss: 0.00215716381
Iter: 86 loss: 0.00215943973
Iter: 87 loss: 0.0021568127
Iter: 88 loss: 0.0021559014
Iter: 89 loss: 0.00216033356
Iter: 90 loss: 0.00215574214
Iter: 91 loss: 0.00215498637
Iter: 92 loss: 0.0021569822
Iter: 93 loss: 0.00215473166
Iter: 94 loss: 0.00215412444
Iter: 95 loss: 0.00215850607
Iter: 96 loss: 0.00215407205
Iter: 97 loss: 0.00215357589
Iter: 98 loss: 0.00215728162
Iter: 99 loss: 0.00215353584
Iter: 100 loss: 0.00215317798
Iter: 101 loss: 0.00215385528
Iter: 102 loss: 0.00215302804
Iter: 103 loss: 0.00215264037
Iter: 104 loss: 0.00215361826
Iter: 105 loss: 0.0021525058
Iter: 106 loss: 0.00215216517
Iter: 107 loss: 0.00215216307
Iter: 108 loss: 0.00215189299
Iter: 109 loss: 0.00215151208
Iter: 110 loss: 0.00215333095
Iter: 111 loss: 0.00215144409
Iter: 112 loss: 0.00215112325
Iter: 113 loss: 0.00215167366
Iter: 114 loss: 0.00215097982
Iter: 115 loss: 0.00215067808
Iter: 116 loss: 0.00215180404
Iter: 117 loss: 0.00215060357
Iter: 118 loss: 0.00215037283
Iter: 119 loss: 0.00215107296
Iter: 120 loss: 0.00215030322
Iter: 121 loss: 0.00215012231
Iter: 122 loss: 0.00215135654
Iter: 123 loss: 0.00215010555
Iter: 124 loss: 0.00214997097
Iter: 125 loss: 0.00215040706
Iter: 126 loss: 0.00214993302
Iter: 127 loss: 0.00214982405
Iter: 128 loss: 0.00215001
Iter: 129 loss: 0.00214977586
Iter: 130 loss: 0.00214968086
Iter: 131 loss: 0.00215019868
Iter: 132 loss: 0.00214966806
Iter: 133 loss: 0.00214961218
Iter: 134 loss: 0.00214961171
Iter: 135 loss: 0.00214956608
Iter: 136 loss: 0.00214966852
Iter: 137 loss: 0.00214954838
Iter: 138 loss: 0.00214951672
Iter: 139 loss: 0.00214960612
Iter: 140 loss: 0.0021495074
Iter: 141 loss: 0.00214947481
Iter: 142 loss: 0.00214954186
Iter: 143 loss: 0.00214946247
Iter: 144 loss: 0.00214943709
Iter: 145 loss: 0.00214943779
Iter: 146 loss: 0.00214941613
Iter: 147 loss: 0.00214939169
Iter: 148 loss: 0.00214963406
Iter: 149 loss: 0.00214939
Iter: 150 loss: 0.00214937143
Iter: 151 loss: 0.00214939797
Iter: 152 loss: 0.00214936165
Iter: 153 loss: 0.00214934559
Iter: 154 loss: 0.00214939378
Iter: 155 loss: 0.00214933977
Iter: 156 loss: 0.00214932556
Iter: 157 loss: 0.00214938
Iter: 158 loss: 0.002149323
Iter: 159 loss: 0.00214931229
Iter: 160 loss: 0.00214938819
Iter: 161 loss: 0.00214931183
Iter: 162 loss: 0.00214930484
Iter: 163 loss: 0.00214932254
Iter: 164 loss: 0.00214930228
Iter: 165 loss: 0.00214929553
Iter: 166 loss: 0.00214931532
Iter: 167 loss: 0.00214929366
Iter: 168 loss: 0.00214928947
Iter: 169 loss: 0.0021493258
Iter: 170 loss: 0.00214929017
Iter: 171 loss: 0.00214928668
Iter: 172 loss: 0.00214932463
Iter: 173 loss: 0.00214928645
Iter: 174 loss: 0.00214928505
Iter: 175 loss: 0.00214928458
Iter: 176 loss: 0.00214928389
Iter: 177 loss: 0.00214928132
Iter: 178 loss: 0.00214929297
Iter: 179 loss: 0.00214928132
Iter: 180 loss: 0.00214928
Iter: 181 loss: 0.00214928319
Iter: 182 loss: 0.0021492797
Iter: 183 loss: 0.0021492783
Iter: 184 loss: 0.0021492797
Iter: 185 loss: 0.0021492762
Iter: 186 loss: 0.00214927574
Iter: 187 loss: 0.00214927923
Iter: 188 loss: 0.00214927527
Iter: 189 loss: 0.00214927457
Iter: 190 loss: 0.00214927923
Iter: 191 loss: 0.00214927411
Iter: 192 loss: 0.00214927341
Iter: 193 loss: 0.00214927644
Iter: 194 loss: 0.00214927387
Iter: 195 loss: 0.00214927271
Iter: 196 loss: 0.00214927411
Iter: 197 loss: 0.00214927248
Iter: 198 loss: 0.00214927131
Iter: 199 loss: 0.00214927597
Iter: 200 loss: 0.00214927201
Iter: 201 loss: 0.00214927155
Iter: 202 loss: 0.00214927271
Iter: 203 loss: 0.00214927131
Iter: 204 loss: 0.00214927178
Iter: 205 loss: 0.00214927178
Iter: 206 loss: 0.00214927085
Iter: 207 loss: 0.00214927085
Iter: 208 loss: 0.00214927061
Iter: 209 loss: 0.00214927131
Iter: 210 loss: 0.00214927085
Iter: 211 loss: 0.00214927038
Iter: 212 loss: 0.00214927
Iter: 213 loss: 0.00214927038
Iter: 214 loss: 0.00214927
Iter: 215 loss: 0.00214927038
Iter: 216 loss: 0.00214927108
Iter: 217 loss: 0.00214927038
Iter: 218 loss: 0.00214927038
Iter: 219 loss: 0.00214927085
Iter: 220 loss: 0.00214927
Iter: 221 loss: 0.00214927
Iter: 222 loss: 0.00214927038
Iter: 223 loss: 0.00214926968
Iter: 224 loss: 0.00214927
Iter: 225 loss: 0.00214927085
Iter: 226 loss: 0.00214926945
Iter: 227 loss: 0.00214927038
Iter: 228 loss: 0.00214926968
Iter: 229 loss: 0.00214926968
Iter: 230 loss: 0.00214926968
Iter: 231 loss: 0.00214926945
Iter: 232 loss: 0.00214926945
Iter: 233 loss: 0.00214926968
Iter: 234 loss: 0.00214927
Iter: 235 loss: 0.00214926968
Iter: 236 loss: 0.00214927
Iter: 237 loss: 0.00214927
Iter: 238 loss: 0.00214926922
Iter: 239 loss: 0.00214926922
Iter: 240 loss: 0.00214927
Iter: 241 loss: 0.00214927015
Iter: 242 loss: 0.00214926945
Iter: 243 loss: 0.00214927
Iter: 244 loss: 0.00214926945
Iter: 245 loss: 0.00214926968
Iter: 246 loss: 0.00214927015
Iter: 247 loss: 0.00214926968
Iter: 248 loss: 0.00214927038
Iter: 249 loss: 0.00214926945
Iter: 250 loss: 0.00214926968
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6
+ date
Tue Oct 27 19:58:56 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd7c3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11f2a70f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11f2a70d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd806bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd7586a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd7581e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd73dd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd6f48c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd70c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd70ce18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd70c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd61a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd61a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd5cf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd5cff28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd5cf8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd5afc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd5bd9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd587f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd526620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd53a1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd4ead90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd526d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd460268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd460598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd465e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd4459d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd4457b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd3f2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd399400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd3f29d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd3f2ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd3701e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd31c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd2da9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f11dd2da158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0321754515
Iter: 2 loss: 0.020869026
Iter: 3 loss: 3451.51758
Iter: 4 loss: 0.0208690222
Iter: 5 loss: 0.0331065133
Iter: 6 loss: 0.0189487636
Iter: 7 loss: 0.0144089833
Iter: 8 loss: 0.014024999
Iter: 9 loss: 0.0110773696
Iter: 10 loss: 0.0363300368
Iter: 11 loss: 0.0106426077
Iter: 12 loss: 0.00773323141
Iter: 13 loss: 0.0413553044
Iter: 14 loss: 0.00761214457
Iter: 15 loss: 0.00623448286
Iter: 16 loss: 0.013032265
Iter: 17 loss: 0.00609019818
Iter: 18 loss: 0.00538928341
Iter: 19 loss: 0.00512907142
Iter: 20 loss: 0.00465906877
Iter: 21 loss: 0.00417961879
Iter: 22 loss: 0.00884346291
Iter: 23 loss: 0.0041350876
Iter: 24 loss: 0.00370114017
Iter: 25 loss: 0.00567588024
Iter: 26 loss: 0.00361658353
Iter: 27 loss: 0.00343129691
Iter: 28 loss: 0.00372496224
Iter: 29 loss: 0.00333835767
Iter: 30 loss: 0.0031249118
Iter: 31 loss: 0.00344287232
Iter: 32 loss: 0.00302081415
Iter: 33 loss: 0.00286733056
Iter: 34 loss: 0.00479528913
Iter: 35 loss: 0.00286355312
Iter: 36 loss: 0.00277037499
Iter: 37 loss: 0.00331373024
Iter: 38 loss: 0.00275829667
Iter: 39 loss: 0.00270224223
Iter: 40 loss: 0.00284252875
Iter: 41 loss: 0.00268135639
Iter: 42 loss: 0.00262556458
Iter: 43 loss: 0.00277904235
Iter: 44 loss: 0.00260726968
Iter: 45 loss: 0.00255520176
Iter: 46 loss: 0.00289272796
Iter: 47 loss: 0.00254970067
Iter: 48 loss: 0.00251920265
Iter: 49 loss: 0.00258444436
Iter: 50 loss: 0.00250689313
Iter: 51 loss: 0.00248105312
Iter: 52 loss: 0.00271456828
Iter: 53 loss: 0.00247995462
Iter: 54 loss: 0.0024589207
Iter: 55 loss: 0.00256960164
Iter: 56 loss: 0.0024553556
Iter: 57 loss: 0.00243682833
Iter: 58 loss: 0.00247405795
Iter: 59 loss: 0.00242948299
Iter: 60 loss: 0.00240886421
Iter: 61 loss: 0.00246135145
Iter: 62 loss: 0.00240137405
Iter: 63 loss: 0.00238326192
Iter: 64 loss: 0.00239631906
Iter: 65 loss: 0.00237205252
Iter: 66 loss: 0.00235205842
Iter: 67 loss: 0.00241198577
Iter: 68 loss: 0.00234591728
Iter: 69 loss: 0.00232782145
Iter: 70 loss: 0.00236799824
Iter: 71 loss: 0.0023207562
Iter: 72 loss: 0.00230421824
Iter: 73 loss: 0.00235464959
Iter: 74 loss: 0.00229925429
Iter: 75 loss: 0.00228679832
Iter: 76 loss: 0.00240456732
Iter: 77 loss: 0.00228625932
Iter: 78 loss: 0.00227757683
Iter: 79 loss: 0.00231761322
Iter: 80 loss: 0.00227596
Iter: 81 loss: 0.00226853509
Iter: 82 loss: 0.00227876683
Iter: 83 loss: 0.00226480281
Iter: 84 loss: 0.00225863187
Iter: 85 loss: 0.0022687905
Iter: 86 loss: 0.00225581485
Iter: 87 loss: 0.00225059222
Iter: 88 loss: 0.0023033144
Iter: 89 loss: 0.00225041364
Iter: 90 loss: 0.00224723341
Iter: 91 loss: 0.00229153805
Iter: 92 loss: 0.00224722712
Iter: 93 loss: 0.00224481942
Iter: 94 loss: 0.00224604411
Iter: 95 loss: 0.00224320218
Iter: 96 loss: 0.00224091345
Iter: 97 loss: 0.00224627694
Iter: 98 loss: 0.00224007666
Iter: 99 loss: 0.00223787548
Iter: 100 loss: 0.00223754696
Iter: 101 loss: 0.00223600538
Iter: 102 loss: 0.0022337446
Iter: 103 loss: 0.00224630116
Iter: 104 loss: 0.00223341701
Iter: 105 loss: 0.0022317511
Iter: 106 loss: 0.00223975349
Iter: 107 loss: 0.00223145448
Iter: 108 loss: 0.00223009894
Iter: 109 loss: 0.00223132968
Iter: 110 loss: 0.00222931243
Iter: 111 loss: 0.00222785422
Iter: 112 loss: 0.00223651459
Iter: 113 loss: 0.00222766981
Iter: 114 loss: 0.00222648052
Iter: 115 loss: 0.0022307781
Iter: 116 loss: 0.002226179
Iter: 117 loss: 0.00222523697
Iter: 118 loss: 0.00222959602
Iter: 119 loss: 0.00222506281
Iter: 120 loss: 0.00222420902
Iter: 121 loss: 0.00222731475
Iter: 122 loss: 0.00222399575
Iter: 123 loss: 0.00222342298
Iter: 124 loss: 0.00222511333
Iter: 125 loss: 0.00222325
Iter: 126 loss: 0.00222256547
Iter: 127 loss: 0.00222754804
Iter: 128 loss: 0.0022225061
Iter: 129 loss: 0.00222214404
Iter: 130 loss: 0.00222194311
Iter: 131 loss: 0.00222178502
Iter: 132 loss: 0.00222121784
Iter: 133 loss: 0.00222244859
Iter: 134 loss: 0.002221
Iter: 135 loss: 0.00222047744
Iter: 136 loss: 0.00222075288
Iter: 137 loss: 0.00222013379
Iter: 138 loss: 0.00221958105
Iter: 139 loss: 0.0022236472
Iter: 140 loss: 0.00221953541
Iter: 141 loss: 0.00221906672
Iter: 142 loss: 0.00221905485
Iter: 143 loss: 0.00221868837
Iter: 144 loss: 0.00221814401
Iter: 145 loss: 0.00222119037
Iter: 146 loss: 0.00221806765
Iter: 147 loss: 0.00221757544
Iter: 148 loss: 0.00221952749
Iter: 149 loss: 0.00221746415
Iter: 150 loss: 0.00221705204
Iter: 151 loss: 0.00221779943
Iter: 152 loss: 0.00221687462
Iter: 153 loss: 0.00221645692
Iter: 154 loss: 0.00222004019
Iter: 155 loss: 0.00221643364
Iter: 156 loss: 0.0022161575
Iter: 157 loss: 0.00221642293
Iter: 158 loss: 0.00221600081
Iter: 159 loss: 0.00221579964
Iter: 160 loss: 0.00221578986
Iter: 161 loss: 0.00221562851
Iter: 162 loss: 0.00221540034
Iter: 163 loss: 0.00221539149
Iter: 164 loss: 0.00221512
Iter: 165 loss: 0.00221584225
Iter: 166 loss: 0.00221502921
Iter: 167 loss: 0.00221474748
Iter: 168 loss: 0.00221495423
Iter: 169 loss: 0.00221457332
Iter: 170 loss: 0.00221426552
Iter: 171 loss: 0.00221561687
Iter: 172 loss: 0.00221420359
Iter: 173 loss: 0.00221392605
Iter: 174 loss: 0.00221441966
Iter: 175 loss: 0.00221380335
Iter: 176 loss: 0.00221354421
Iter: 177 loss: 0.0022142895
Iter: 178 loss: 0.00221346295
Iter: 179 loss: 0.00221320405
Iter: 180 loss: 0.0022140427
Iter: 181 loss: 0.0022131321
Iter: 182 loss: 0.00221290463
Iter: 183 loss: 0.00221414468
Iter: 184 loss: 0.00221287156
Iter: 185 loss: 0.00221268367
Iter: 186 loss: 0.002213164
Iter: 187 loss: 0.00221261894
Iter: 188 loss: 0.00221244153
Iter: 189 loss: 0.00221357984
Iter: 190 loss: 0.00221242243
Iter: 191 loss: 0.00221230276
Iter: 192 loss: 0.00221305108
Iter: 193 loss: 0.00221228809
Iter: 194 loss: 0.00221215514
Iter: 195 loss: 0.00221229438
Iter: 196 loss: 0.00221208204
Iter: 197 loss: 0.00221194793
Iter: 198 loss: 0.00221193815
Iter: 199 loss: 0.00221183896
Iter: 200 loss: 0.00221166899
Iter: 201 loss: 0.00221196376
Iter: 202 loss: 0.00221159309
Iter: 203 loss: 0.00221141218
Iter: 204 loss: 0.00221219682
Iter: 205 loss: 0.00221137516
Iter: 206 loss: 0.002211218
Iter: 207 loss: 0.00221133931
Iter: 208 loss: 0.00221112277
Iter: 209 loss: 0.00221094163
Iter: 210 loss: 0.00221142732
Iter: 211 loss: 0.00221088156
Iter: 212 loss: 0.00221071206
Iter: 213 loss: 0.00221161777
Iter: 214 loss: 0.00221068575
Iter: 215 loss: 0.00221053814
Iter: 216 loss: 0.00221074698
Iter: 217 loss: 0.00221046642
Iter: 218 loss: 0.00221033022
Iter: 219 loss: 0.00221143849
Iter: 220 loss: 0.00221032114
Iter: 221 loss: 0.00221021357
Iter: 222 loss: 0.00221054815
Iter: 223 loss: 0.0022101826
Iter: 224 loss: 0.00221008202
Iter: 225 loss: 0.00221069902
Iter: 226 loss: 0.00221007
Iter: 227 loss: 0.00220998237
Iter: 228 loss: 0.00221048016
Iter: 229 loss: 0.00220997143
Iter: 230 loss: 0.00220990879
Iter: 231 loss: 0.00220983941
Iter: 232 loss: 0.00220983033
Iter: 233 loss: 0.00220972649
Iter: 234 loss: 0.00220996747
Iter: 235 loss: 0.0022096897
Iter: 236 loss: 0.0022095968
Iter: 237 loss: 0.00220985198
Iter: 238 loss: 0.002209567
Iter: 239 loss: 0.00220947713
Iter: 240 loss: 0.00220981659
Iter: 241 loss: 0.00220945617
Iter: 242 loss: 0.00220937887
Iter: 243 loss: 0.00220946711
Iter: 244 loss: 0.00220933487
Iter: 245 loss: 0.00220925547
Iter: 246 loss: 0.00220957
Iter: 247 loss: 0.00220923778
Iter: 248 loss: 0.00220916606
Iter: 249 loss: 0.00220937887
Iter: 250 loss: 0.00220914464
Iter: 251 loss: 0.00220908
Iter: 252 loss: 0.00220940216
Iter: 253 loss: 0.00220906967
Iter: 254 loss: 0.00220902031
Iter: 255 loss: 0.00220922846
Iter: 256 loss: 0.0022090096
Iter: 257 loss: 0.00220896746
Iter: 258 loss: 0.00220930972
Iter: 259 loss: 0.00220896513
Iter: 260 loss: 0.00220893743
Iter: 261 loss: 0.00220918679
Iter: 262 loss: 0.00220893673
Iter: 263 loss: 0.0022089174
Iter: 264 loss: 0.00220888853
Iter: 265 loss: 0.00220888783
Iter: 266 loss: 0.0022088543
Iter: 267 loss: 0.00220895186
Iter: 268 loss: 0.00220884406
Iter: 269 loss: 0.00220881263
Iter: 270 loss: 0.00220885687
Iter: 271 loss: 0.0022087968
Iter: 272 loss: 0.00220876932
Iter: 273 loss: 0.00220892
Iter: 274 loss: 0.00220876443
Iter: 275 loss: 0.00220873905
Iter: 276 loss: 0.00220880983
Iter: 277 loss: 0.00220873114
Iter: 278 loss: 0.00220871042
Iter: 279 loss: 0.00220872927
Iter: 280 loss: 0.00220869947
Iter: 281 loss: 0.00220867759
Iter: 282 loss: 0.00220880145
Iter: 283 loss: 0.00220867433
Iter: 284 loss: 0.00220865686
Iter: 285 loss: 0.00220872462
Iter: 286 loss: 0.00220865384
Iter: 287 loss: 0.0022086394
Iter: 288 loss: 0.00220869412
Iter: 289 loss: 0.00220863521
Iter: 290 loss: 0.00220862357
Iter: 291 loss: 0.00220873952
Iter: 292 loss: 0.00220862334
Iter: 293 loss: 0.00220861635
Iter: 294 loss: 0.00220867386
Iter: 295 loss: 0.00220861565
Iter: 296 loss: 0.00220860937
Iter: 297 loss: 0.00220860634
Iter: 298 loss: 0.00220860355
Iter: 299 loss: 0.00220859516
Iter: 300 loss: 0.00220860122
Iter: 301 loss: 0.00220859051
Iter: 302 loss: 0.00220858143
Iter: 303 loss: 0.00220861123
Iter: 304 loss: 0.0022085791
Iter: 305 loss: 0.00220857048
Iter: 306 loss: 0.00220858958
Iter: 307 loss: 0.00220856862
Iter: 308 loss: 0.00220856047
Iter: 309 loss: 0.00220860238
Iter: 310 loss: 0.00220856024
Iter: 311 loss: 0.00220855325
Iter: 312 loss: 0.00220855721
Iter: 313 loss: 0.00220855
Iter: 314 loss: 0.00220854394
Iter: 315 loss: 0.00220857724
Iter: 316 loss: 0.00220854278
Iter: 317 loss: 0.00220853835
Iter: 318 loss: 0.00220854906
Iter: 319 loss: 0.00220853603
Iter: 320 loss: 0.00220853114
Iter: 321 loss: 0.00220855372
Iter: 322 loss: 0.00220852974
Iter: 323 loss: 0.00220852625
Iter: 324 loss: 0.00220856722
Iter: 325 loss: 0.00220852578
Iter: 326 loss: 0.00220852369
Iter: 327 loss: 0.00220854301
Iter: 328 loss: 0.00220852206
Iter: 329 loss: 0.00220852112
Iter: 330 loss: 0.00220852066
Iter: 331 loss: 0.00220851926
Iter: 332 loss: 0.00220851647
Iter: 333 loss: 0.00220851973
Iter: 334 loss: 0.00220851507
Iter: 335 loss: 0.00220851251
Iter: 336 loss: 0.00220851647
Iter: 337 loss: 0.00220851088
Iter: 338 loss: 0.00220850762
Iter: 339 loss: 0.00220852112
Iter: 340 loss: 0.00220850739
Iter: 341 loss: 0.00220850459
Iter: 342 loss: 0.00220851041
Iter: 343 loss: 0.00220850343
Iter: 344 loss: 0.00220850133
Iter: 345 loss: 0.00220850762
Iter: 346 loss: 0.00220850063
Iter: 347 loss: 0.00220849761
Iter: 348 loss: 0.00220850599
Iter: 349 loss: 0.00220849714
Iter: 350 loss: 0.00220849528
Iter: 351 loss: 0.0022085011
Iter: 352 loss: 0.00220849458
Iter: 353 loss: 0.00220849202
Iter: 354 loss: 0.00220850017
Iter: 355 loss: 0.00220849249
Iter: 356 loss: 0.00220849016
Iter: 357 loss: 0.00220850063
Iter: 358 loss: 0.00220849
Iter: 359 loss: 0.00220848946
Iter: 360 loss: 0.00220850343
Iter: 361 loss: 0.00220848899
Iter: 362 loss: 0.00220848806
Iter: 363 loss: 0.00220849039
Iter: 364 loss: 0.00220848643
Iter: 365 loss: 0.00220848667
Iter: 366 loss: 0.0022084862
Iter: 367 loss: 0.00220848504
Iter: 368 loss: 0.0022084841
Iter: 369 loss: 0.00220848783
Iter: 370 loss: 0.00220848341
Iter: 371 loss: 0.00220848201
Iter: 372 loss: 0.0022084876
Iter: 373 loss: 0.00220848271
Iter: 374 loss: 0.00220848084
Iter: 375 loss: 0.00220848201
Iter: 376 loss: 0.00220848108
Iter: 377 loss: 0.00220848
Iter: 378 loss: 0.00220848736
Iter: 379 loss: 0.00220848
Iter: 380 loss: 0.00220847875
Iter: 381 loss: 0.00220848015
Iter: 382 loss: 0.00220847828
Iter: 383 loss: 0.00220847782
Iter: 384 loss: 0.00220848015
Iter: 385 loss: 0.00220847665
Iter: 386 loss: 0.00220847642
Iter: 387 loss: 0.00220848084
Iter: 388 loss: 0.00220847619
Iter: 389 loss: 0.00220847526
Iter: 390 loss: 0.00220847689
Iter: 391 loss: 0.00220847502
Iter: 392 loss: 0.00220847433
Iter: 393 loss: 0.00220847433
Iter: 394 loss: 0.00220847433
Iter: 395 loss: 0.00220847386
Iter: 396 loss: 0.00220847433
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2
+ date
Tue Oct 27 20:00:51 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa105cbf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa54355ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa54355e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa10605048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa105606a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ffa10560f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e83056a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8336620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e83447b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e82d9378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8297bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8297d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e82d9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e827f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e82392f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8239510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e81dc048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e81ed840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e82391e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8175158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8182400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8182d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e80e6730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8092950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e80926a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e80bf378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e80bfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e80156a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8021950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8042378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9d026f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9d026fea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9e8042510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9d01c8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9d0199950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9d01996a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0617559254
Iter: 2 loss: 1293.9624
Iter: 3 loss: 1883.15186
Iter: 4 loss: 0.0617215447
Iter: 5 loss: 0.0399326
Iter: 6 loss: 0.0464374796
Iter: 7 loss: 1088.03601
Iter: 8 loss: 0.0464374498
Iter: 9 loss: 1688.75769
Iter: 10 loss: 0.265460312
Iter: 11 loss: 0.0460312292
Iter: 12 loss: 0.0348282978
Iter: 13 loss: 0.0348336063
Iter: 14 loss: 0.0306327213
Iter: 15 loss: 0.0309201162
Iter: 16 loss: 0.0266113095
Iter: 17 loss: 0.0201568063
Iter: 18 loss: 0.0195010416
Iter: 19 loss: 0.0173427425
Iter: 20 loss: 0.0229097325
Iter: 21 loss: 0.0166763123
Iter: 22 loss: 0.0155390184
Iter: 23 loss: 0.0210037958
Iter: 24 loss: 0.0151993837
Iter: 25 loss: 0.0136966072
Iter: 26 loss: 0.0481051
Iter: 27 loss: 0.0136705274
Iter: 28 loss: 0.0120589882
Iter: 29 loss: 0.0175893065
Iter: 30 loss: 0.0115329474
Iter: 31 loss: 0.00990889221
Iter: 32 loss: 0.0176065434
Iter: 33 loss: 0.00963087846
Iter: 34 loss: 0.00858539715
Iter: 35 loss: 0.0138100674
Iter: 36 loss: 0.00829060562
Iter: 37 loss: 0.00749849156
Iter: 38 loss: 0.011018604
Iter: 39 loss: 0.00728446571
Iter: 40 loss: 0.00640695
Iter: 41 loss: 0.00993179251
Iter: 42 loss: 0.0061836564
Iter: 43 loss: 0.00567576615
Iter: 44 loss: 0.0109282155
Iter: 45 loss: 0.00566489669
Iter: 46 loss: 0.00535668945
Iter: 47 loss: 0.00752965873
Iter: 48 loss: 0.0053099189
Iter: 49 loss: 0.00513872784
Iter: 50 loss: 0.00720097031
Iter: 51 loss: 0.00513684237
Iter: 52 loss: 0.00498045702
Iter: 53 loss: 0.00527272094
Iter: 54 loss: 0.00490545761
Iter: 55 loss: 0.00473165419
Iter: 56 loss: 0.00569287129
Iter: 57 loss: 0.00470990967
Iter: 58 loss: 0.00457972288
Iter: 59 loss: 0.00458388124
Iter: 60 loss: 0.00447300309
Iter: 61 loss: 0.0042709033
Iter: 62 loss: 0.00433935365
Iter: 63 loss: 0.00412154756
Iter: 64 loss: 0.00389458332
Iter: 65 loss: 0.00578388385
Iter: 66 loss: 0.00387711567
Iter: 67 loss: 0.00372269331
Iter: 68 loss: 0.00413879938
Iter: 69 loss: 0.00366776972
Iter: 70 loss: 0.00354159926
Iter: 71 loss: 0.00390175823
Iter: 72 loss: 0.00350027438
Iter: 73 loss: 0.00339017017
Iter: 74 loss: 0.00371352071
Iter: 75 loss: 0.00335450284
Iter: 76 loss: 0.00324057462
Iter: 77 loss: 0.00412950572
Iter: 78 loss: 0.00323236897
Iter: 79 loss: 0.003209905
Iter: 80 loss: 0.0031946674
Iter: 81 loss: 0.00316292048
Iter: 82 loss: 0.00312261377
Iter: 83 loss: 0.00311949849
Iter: 84 loss: 0.00306393905
Iter: 85 loss: 0.00373144681
Iter: 86 loss: 0.00306254067
Iter: 87 loss: 0.00302266935
Iter: 88 loss: 0.00302249123
Iter: 89 loss: 0.00299887056
Iter: 90 loss: 0.00298490329
Iter: 91 loss: 0.00297484687
Iter: 92 loss: 0.00294241682
Iter: 93 loss: 0.00291537959
Iter: 94 loss: 0.00290589244
Iter: 95 loss: 0.00286691543
Iter: 96 loss: 0.00312059047
Iter: 97 loss: 0.00286267558
Iter: 98 loss: 0.00283878157
Iter: 99 loss: 0.00287001533
Iter: 100 loss: 0.00282658776
Iter: 101 loss: 0.00280715665
Iter: 102 loss: 0.00295733358
Iter: 103 loss: 0.00280568982
Iter: 104 loss: 0.0027892103
Iter: 105 loss: 0.00280777132
Iter: 106 loss: 0.00278014457
Iter: 107 loss: 0.00276519964
Iter: 108 loss: 0.00276364153
Iter: 109 loss: 0.00275288103
Iter: 110 loss: 0.00274176663
Iter: 111 loss: 0.00279915053
Iter: 112 loss: 0.00273986207
Iter: 113 loss: 0.00272704475
Iter: 114 loss: 0.00275187427
Iter: 115 loss: 0.00272183679
Iter: 116 loss: 0.00270839874
Iter: 117 loss: 0.00273206201
Iter: 118 loss: 0.00270253816
Iter: 119 loss: 0.00269111665
Iter: 120 loss: 0.002748976
Iter: 121 loss: 0.00268929405
Iter: 122 loss: 0.00268101646
Iter: 123 loss: 0.00268097
Iter: 124 loss: 0.00267473864
Iter: 125 loss: 0.00266413088
Iter: 126 loss: 0.00266411575
Iter: 127 loss: 0.00265231403
Iter: 128 loss: 0.00265140226
Iter: 129 loss: 0.00264261733
Iter: 130 loss: 0.00262733735
Iter: 131 loss: 0.00268453266
Iter: 132 loss: 0.00262359204
Iter: 133 loss: 0.00261056423
Iter: 134 loss: 0.00269198907
Iter: 135 loss: 0.0026090045
Iter: 136 loss: 0.0025982291
Iter: 137 loss: 0.00263400935
Iter: 138 loss: 0.00259525981
Iter: 139 loss: 0.00258671213
Iter: 140 loss: 0.00264780852
Iter: 141 loss: 0.00258589443
Iter: 142 loss: 0.00257892534
Iter: 143 loss: 0.00262741372
Iter: 144 loss: 0.00257831952
Iter: 145 loss: 0.00257216254
Iter: 146 loss: 0.00257046055
Iter: 147 loss: 0.00256663607
Iter: 148 loss: 0.0025600316
Iter: 149 loss: 0.00255328789
Iter: 150 loss: 0.0025519873
Iter: 151 loss: 0.00254062796
Iter: 152 loss: 0.00261564972
Iter: 153 loss: 0.0025393737
Iter: 154 loss: 0.00253480882
Iter: 155 loss: 0.00253418111
Iter: 156 loss: 0.00252910564
Iter: 157 loss: 0.00252162432
Iter: 158 loss: 0.00252142549
Iter: 159 loss: 0.00251426082
Iter: 160 loss: 0.00252134074
Iter: 161 loss: 0.00251021981
Iter: 162 loss: 0.00250321487
Iter: 163 loss: 0.00251129409
Iter: 164 loss: 0.00249944907
Iter: 165 loss: 0.00249039801
Iter: 166 loss: 0.0025289841
Iter: 167 loss: 0.00248845574
Iter: 168 loss: 0.00248163659
Iter: 169 loss: 0.00252890959
Iter: 170 loss: 0.00248097396
Iter: 171 loss: 0.00247545727
Iter: 172 loss: 0.00249124225
Iter: 173 loss: 0.00247374363
Iter: 174 loss: 0.00246868399
Iter: 175 loss: 0.00251541473
Iter: 176 loss: 0.0024684302
Iter: 177 loss: 0.00246450352
Iter: 178 loss: 0.00247751107
Iter: 179 loss: 0.00246344646
Iter: 180 loss: 0.00246013701
Iter: 181 loss: 0.0024535472
Iter: 182 loss: 0.00258571119
Iter: 183 loss: 0.00245347619
Iter: 184 loss: 0.0024468021
Iter: 185 loss: 0.00250055641
Iter: 186 loss: 0.00244636345
Iter: 187 loss: 0.00244193058
Iter: 188 loss: 0.00248907506
Iter: 189 loss: 0.00244179368
Iter: 190 loss: 0.00243704254
Iter: 191 loss: 0.00244343164
Iter: 192 loss: 0.00243470073
Iter: 193 loss: 0.00243102666
Iter: 194 loss: 0.00242794049
Iter: 195 loss: 0.00242690183
Iter: 196 loss: 0.00242053159
Iter: 197 loss: 0.00242116093
Iter: 198 loss: 0.00241562864
Iter: 199 loss: 0.00240771566
Iter: 200 loss: 0.00247676577
Iter: 201 loss: 0.0024073082
Iter: 202 loss: 0.00240190234
Iter: 203 loss: 0.00242252136
Iter: 204 loss: 0.00240062946
Iter: 205 loss: 0.0023957754
Iter: 206 loss: 0.00241282722
Iter: 207 loss: 0.00239448459
Iter: 208 loss: 0.00239084056
Iter: 209 loss: 0.00242887507
Iter: 210 loss: 0.0023907586
Iter: 211 loss: 0.00238797534
Iter: 212 loss: 0.00238777511
Iter: 213 loss: 0.00238567404
Iter: 214 loss: 0.00238160766
Iter: 215 loss: 0.00238456018
Iter: 216 loss: 0.00237911288
Iter: 217 loss: 0.0023747466
Iter: 218 loss: 0.00238163816
Iter: 219 loss: 0.00237270701
Iter: 220 loss: 0.00236966694
Iter: 221 loss: 0.00236963457
Iter: 222 loss: 0.00236685108
Iter: 223 loss: 0.00237491657
Iter: 224 loss: 0.00236596633
Iter: 225 loss: 0.0023638159
Iter: 226 loss: 0.00236227922
Iter: 227 loss: 0.00236152927
Iter: 228 loss: 0.00235839677
Iter: 229 loss: 0.00235783309
Iter: 230 loss: 0.00235571293
Iter: 231 loss: 0.0023515902
Iter: 232 loss: 0.0023802584
Iter: 233 loss: 0.00235119741
Iter: 234 loss: 0.00234805839
Iter: 235 loss: 0.0023598792
Iter: 236 loss: 0.00234729401
Iter: 237 loss: 0.0023448416
Iter: 238 loss: 0.00235993089
Iter: 239 loss: 0.00234455452
Iter: 240 loss: 0.00234275451
Iter: 241 loss: 0.00235365611
Iter: 242 loss: 0.00234252377
Iter: 243 loss: 0.0023405829
Iter: 244 loss: 0.00234655337
Iter: 245 loss: 0.00234001735
Iter: 246 loss: 0.00233874
Iter: 247 loss: 0.00233905134
Iter: 248 loss: 0.00233780383
Iter: 249 loss: 0.00233628089
Iter: 250 loss: 0.00233634608
Iter: 251 loss: 0.00233508134
Iter: 252 loss: 0.00233367481
Iter: 253 loss: 0.00234928727
Iter: 254 loss: 0.00233364524
Iter: 255 loss: 0.00233242614
Iter: 256 loss: 0.00234229863
Iter: 257 loss: 0.00233235303
Iter: 258 loss: 0.00233152113
Iter: 259 loss: 0.00233046012
Iter: 260 loss: 0.00233038026
Iter: 261 loss: 0.00232895976
Iter: 262 loss: 0.00232881051
Iter: 263 loss: 0.00232777395
Iter: 264 loss: 0.00232603
Iter: 265 loss: 0.00233498123
Iter: 266 loss: 0.00232574949
Iter: 267 loss: 0.0023242631
Iter: 268 loss: 0.00232931552
Iter: 269 loss: 0.00232386449
Iter: 270 loss: 0.00232253876
Iter: 271 loss: 0.00233155442
Iter: 272 loss: 0.00232240837
Iter: 273 loss: 0.00232149707
Iter: 274 loss: 0.0023270892
Iter: 275 loss: 0.00232139044
Iter: 276 loss: 0.00232051266
Iter: 277 loss: 0.00232394366
Iter: 278 loss: 0.00232030544
Iter: 279 loss: 0.00231959554
Iter: 280 loss: 0.0023195541
Iter: 281 loss: 0.00231901533
Iter: 282 loss: 0.00231818
Iter: 283 loss: 0.00232052617
Iter: 284 loss: 0.00231791101
Iter: 285 loss: 0.00231715315
Iter: 286 loss: 0.00232044025
Iter: 287 loss: 0.00231699948
Iter: 288 loss: 0.0023164812
Iter: 289 loss: 0.00231647748
Iter: 290 loss: 0.00231615617
Iter: 291 loss: 0.00231572334
Iter: 292 loss: 0.00231570238
Iter: 293 loss: 0.00231508841
Iter: 294 loss: 0.00231526396
Iter: 295 loss: 0.00231464603
Iter: 296 loss: 0.0023139047
Iter: 297 loss: 0.00231500925
Iter: 298 loss: 0.002313548
Iter: 299 loss: 0.00231275824
Iter: 300 loss: 0.00231793756
Iter: 301 loss: 0.00231267489
Iter: 302 loss: 0.00231207348
Iter: 303 loss: 0.00231546164
Iter: 304 loss: 0.00231198943
Iter: 305 loss: 0.00231153
Iter: 306 loss: 0.00231388141
Iter: 307 loss: 0.00231145322
Iter: 308 loss: 0.00231103133
Iter: 309 loss: 0.00231454219
Iter: 310 loss: 0.00231100619
Iter: 311 loss: 0.00231071911
Iter: 312 loss: 0.00231048837
Iter: 313 loss: 0.00231040223
Iter: 314 loss: 0.00231006322
Iter: 315 loss: 0.00231097382
Iter: 316 loss: 0.00230995123
Iter: 317 loss: 0.00230958476
Iter: 318 loss: 0.00231029978
Iter: 319 loss: 0.00230943598
Iter: 320 loss: 0.002309273
Iter: 321 loss: 0.00230922457
Iter: 322 loss: 0.00230908627
Iter: 323 loss: 0.00230884552
Iter: 324 loss: 0.00230884505
Iter: 325 loss: 0.00230855145
Iter: 326 loss: 0.00230870047
Iter: 327 loss: 0.00230835681
Iter: 328 loss: 0.00230802735
Iter: 329 loss: 0.00230822293
Iter: 330 loss: 0.00230781501
Iter: 331 loss: 0.00230742269
Iter: 332 loss: 0.00231020851
Iter: 333 loss: 0.00230738753
Iter: 334 loss: 0.00230709929
Iter: 335 loss: 0.00230824435
Iter: 336 loss: 0.00230703456
Iter: 337 loss: 0.00230675563
Iter: 338 loss: 0.00230790838
Iter: 339 loss: 0.00230669463
Iter: 340 loss: 0.00230647717
Iter: 341 loss: 0.00230884971
Iter: 342 loss: 0.00230647158
Iter: 343 loss: 0.00230630673
Iter: 344 loss: 0.00230612187
Iter: 345 loss: 0.00230609765
Iter: 346 loss: 0.00230585528
Iter: 347 loss: 0.00230633258
Iter: 348 loss: 0.00230575656
Iter: 349 loss: 0.00230550277
Iter: 350 loss: 0.00230648206
Iter: 351 loss: 0.00230544433
Iter: 352 loss: 0.00230532372
Iter: 353 loss: 0.00230531371
Iter: 354 loss: 0.00230520451
Iter: 355 loss: 0.00230502384
Iter: 356 loss: 0.00230502267
Iter: 357 loss: 0.0023047952
Iter: 358 loss: 0.0023051335
Iter: 359 loss: 0.00230468623
Iter: 360 loss: 0.00230445014
Iter: 361 loss: 0.00230455259
Iter: 362 loss: 0.00230429065
Iter: 363 loss: 0.00230399822
Iter: 364 loss: 0.00230522058
Iter: 365 loss: 0.00230393629
Iter: 366 loss: 0.0023037116
Iter: 367 loss: 0.00230506202
Iter: 368 loss: 0.0023036832
Iter: 369 loss: 0.0023034825
Iter: 370 loss: 0.00230442826
Iter: 371 loss: 0.00230344641
Iter: 372 loss: 0.002303313
Iter: 373 loss: 0.00230533769
Iter: 374 loss: 0.00230331277
Iter: 375 loss: 0.00230321218
Iter: 376 loss: 0.00230311183
Iter: 377 loss: 0.00230309251
Iter: 378 loss: 0.00230293
Iter: 379 loss: 0.00230297353
Iter: 380 loss: 0.00230281497
Iter: 381 loss: 0.00230265502
Iter: 382 loss: 0.00230411883
Iter: 383 loss: 0.00230264803
Iter: 384 loss: 0.00230254978
Iter: 385 loss: 0.00230364176
Iter: 386 loss: 0.00230254699
Iter: 387 loss: 0.0023024471
Iter: 388 loss: 0.00230238563
Iter: 389 loss: 0.00230234442
Iter: 390 loss: 0.00230222195
Iter: 391 loss: 0.00230231555
Iter: 392 loss: 0.00230214908
Iter: 393 loss: 0.00230199983
Iter: 394 loss: 0.00230219564
Iter: 395 loss: 0.00230192277
Iter: 396 loss: 0.00230176
Iter: 397 loss: 0.00230190624
Iter: 398 loss: 0.00230166363
Iter: 399 loss: 0.00230149436
Iter: 400 loss: 0.00230300683
Iter: 401 loss: 0.00230148621
Iter: 402 loss: 0.00230135117
Iter: 403 loss: 0.00230209227
Iter: 404 loss: 0.0023013337
Iter: 405 loss: 0.00230125338
Iter: 406 loss: 0.00230248831
Iter: 407 loss: 0.00230125384
Iter: 408 loss: 0.00230118842
Iter: 409 loss: 0.00230112951
Iter: 410 loss: 0.00230111368
Iter: 411 loss: 0.00230100658
Iter: 412 loss: 0.00230099843
Iter: 413 loss: 0.00230091787
Iter: 414 loss: 0.00230081705
Iter: 415 loss: 0.00230180542
Iter: 416 loss: 0.00230081333
Iter: 417 loss: 0.00230074115
Iter: 418 loss: 0.00230132765
Iter: 419 loss: 0.0023007358
Iter: 420 loss: 0.00230066059
Iter: 421 loss: 0.00230071391
Iter: 422 loss: 0.00230061263
Iter: 423 loss: 0.0023005465
Iter: 424 loss: 0.00230051437
Iter: 425 loss: 0.00230048201
Iter: 426 loss: 0.00230037258
Iter: 427 loss: 0.00230059773
Iter: 428 loss: 0.00230032951
Iter: 429 loss: 0.00230022357
Iter: 430 loss: 0.00230031111
Iter: 431 loss: 0.0023001607
Iter: 432 loss: 0.00230004732
Iter: 433 loss: 0.00230084779
Iter: 434 loss: 0.00230003567
Iter: 435 loss: 0.00229994976
Iter: 436 loss: 0.0023005805
Iter: 437 loss: 0.00229994184
Iter: 438 loss: 0.00229988876
Iter: 439 loss: 0.00230046478
Iter: 440 loss: 0.00229988713
Iter: 441 loss: 0.0022998366
Iter: 442 loss: 0.00229980052
Iter: 443 loss: 0.00229978189
Iter: 444 loss: 0.00229970529
Iter: 445 loss: 0.00229972042
Iter: 446 loss: 0.00229964731
Iter: 447 loss: 0.00229957514
Iter: 448 loss: 0.00230001775
Iter: 449 loss: 0.00229956536
Iter: 450 loss: 0.00229951
Iter: 451 loss: 0.00230005686
Iter: 452 loss: 0.00229950761
Iter: 453 loss: 0.00229945499
Iter: 454 loss: 0.00229954952
Iter: 455 loss: 0.00229943125
Iter: 456 loss: 0.0022993884
Iter: 457 loss: 0.00229934067
Iter: 458 loss: 0.00229933276
Iter: 459 loss: 0.00229925057
Iter: 460 loss: 0.00229942705
Iter: 461 loss: 0.00229921844
Iter: 462 loss: 0.00229913765
Iter: 463 loss: 0.00229925895
Iter: 464 loss: 0.00229909876
Iter: 465 loss: 0.00229901541
Iter: 466 loss: 0.00229935627
Iter: 467 loss: 0.00229899678
Iter: 468 loss: 0.00229893532
Iter: 469 loss: 0.00229963567
Iter: 470 loss: 0.00229893508
Iter: 471 loss: 0.00229888945
Iter: 472 loss: 0.0022991267
Iter: 473 loss: 0.00229888107
Iter: 474 loss: 0.00229882961
Iter: 475 loss: 0.00229889574
Iter: 476 loss: 0.00229880353
Iter: 477 loss: 0.00229875837
Iter: 478 loss: 0.00229872856
Iter: 479 loss: 0.00229871017
Iter: 480 loss: 0.002298648
Iter: 481 loss: 0.00229887036
Iter: 482 loss: 0.00229863077
Iter: 483 loss: 0.00229858421
Iter: 484 loss: 0.0022992054
Iter: 485 loss: 0.00229858304
Iter: 486 loss: 0.00229853741
Iter: 487 loss: 0.00229863799
Iter: 488 loss: 0.00229852158
Iter: 489 loss: 0.00229848386
Iter: 490 loss: 0.00229844917
Iter: 491 loss: 0.00229843915
Iter: 492 loss: 0.00229837419
Iter: 493 loss: 0.00229841284
Iter: 494 loss: 0.00229833205
Iter: 495 loss: 0.00229825615
Iter: 496 loss: 0.00229859771
Iter: 497 loss: 0.00229824218
Iter: 498 loss: 0.0022981693
Iter: 499 loss: 0.00229821098
Iter: 500 loss: 0.00229812227
Iter: 501 loss: 0.0022980622
Iter: 502 loss: 0.00229895
Iter: 503 loss: 0.0022980629
Iter: 504 loss: 0.00229801191
Iter: 505 loss: 0.00229827059
Iter: 506 loss: 0.0022980026
Iter: 507 loss: 0.00229795696
Iter: 508 loss: 0.00229814975
Iter: 509 loss: 0.00229794718
Iter: 510 loss: 0.00229791319
Iter: 511 loss: 0.00229786267
Iter: 512 loss: 0.00229786336
Iter: 513 loss: 0.00229780655
Iter: 514 loss: 0.0022980927
Iter: 515 loss: 0.00229779584
Iter: 516 loss: 0.00229775906
Iter: 517 loss: 0.00229822239
Iter: 518 loss: 0.00229775766
Iter: 519 loss: 0.00229772064
Iter: 520 loss: 0.00229782797
Iter: 521 loss: 0.00229771156
Iter: 522 loss: 0.00229768082
Iter: 523 loss: 0.0022976452
Iter: 524 loss: 0.00229764264
Iter: 525 loss: 0.00229758373
Iter: 526 loss: 0.00229761866
Iter: 527 loss: 0.00229754439
Iter: 528 loss: 0.00229748036
Iter: 529 loss: 0.00229776488
Iter: 530 loss: 0.00229746848
Iter: 531 loss: 0.00229740539
Iter: 532 loss: 0.00229748059
Iter: 533 loss: 0.00229737163
Iter: 534 loss: 0.00229731877
Iter: 535 loss: 0.00229776511
Iter: 536 loss: 0.00229731435
Iter: 537 loss: 0.00229727477
Iter: 538 loss: 0.00229768199
Iter: 539 loss: 0.00229727407
Iter: 540 loss: 0.0022972424
Iter: 541 loss: 0.00229738979
Iter: 542 loss: 0.00229723775
Iter: 543 loss: 0.0022972133
Iter: 544 loss: 0.00229716883
Iter: 545 loss: 0.00229818607
Iter: 546 loss: 0.0022971679
Iter: 547 loss: 0.00229711784
Iter: 548 loss: 0.00229725498
Iter: 549 loss: 0.00229710154
Iter: 550 loss: 0.00229706638
Iter: 551 loss: 0.00229706522
Iter: 552 loss: 0.00229703658
Iter: 553 loss: 0.00229716371
Iter: 554 loss: 0.0022970296
Iter: 555 loss: 0.00229700515
Iter: 556 loss: 0.00229696045
Iter: 557 loss: 0.00229796139
Iter: 558 loss: 0.00229695952
Iter: 559 loss: 0.00229690224
Iter: 560 loss: 0.00229702285
Iter: 561 loss: 0.00229687942
Iter: 562 loss: 0.0022968282
Iter: 563 loss: 0.00229699118
Iter: 564 loss: 0.00229681493
Iter: 565 loss: 0.00229676045
Iter: 566 loss: 0.00229680235
Iter: 567 loss: 0.00229672575
Iter: 568 loss: 0.00229666848
Iter: 569 loss: 0.00229709363
Iter: 570 loss: 0.00229666382
Iter: 571 loss: 0.00229662471
Iter: 572 loss: 0.00229709968
Iter: 573 loss: 0.00229662377
Iter: 574 loss: 0.00229659234
Iter: 575 loss: 0.0022967027
Iter: 576 loss: 0.00229658419
Iter: 577 loss: 0.00229655486
Iter: 578 loss: 0.00229653437
Iter: 579 loss: 0.00229652366
Iter: 580 loss: 0.00229647802
Iter: 581 loss: 0.00229646289
Iter: 582 loss: 0.00229643658
Iter: 583 loss: 0.00229640771
Iter: 584 loss: 0.00229640352
Iter: 585 loss: 0.00229637511
Iter: 586 loss: 0.00229647034
Iter: 587 loss: 0.0022963658
Iter: 588 loss: 0.00229633786
Iter: 589 loss: 0.00229629478
Iter: 590 loss: 0.00229629641
Iter: 591 loss: 0.002296241
Iter: 592 loss: 0.00229634088
Iter: 593 loss: 0.00229621911
Iter: 594 loss: 0.00229616743
Iter: 595 loss: 0.00229638629
Iter: 596 loss: 0.00229615788
Iter: 597 loss: 0.00229610805
Iter: 598 loss: 0.00229611178
Iter: 599 loss: 0.00229606964
Iter: 600 loss: 0.00229601702
Iter: 601 loss: 0.00229643984
Iter: 602 loss: 0.00229601515
Iter: 603 loss: 0.00229597627
Iter: 604 loss: 0.00229640957
Iter: 605 loss: 0.00229597394
Iter: 606 loss: 0.00229594368
Iter: 607 loss: 0.00229607662
Iter: 608 loss: 0.00229593855
Iter: 609 loss: 0.00229591
Iter: 610 loss: 0.00229588756
Iter: 611 loss: 0.00229587918
Iter: 612 loss: 0.00229583611
Iter: 613 loss: 0.00229585031
Iter: 614 loss: 0.00229580398
Iter: 615 loss: 0.00229577255
Iter: 616 loss: 0.00229577255
Iter: 617 loss: 0.00229574274
Iter: 618 loss: 0.00229591038
Iter: 619 loss: 0.00229573855
Iter: 620 loss: 0.0022957162
Iter: 621 loss: 0.00229568454
Iter: 622 loss: 0.00229568221
Iter: 623 loss: 0.00229564309
Iter: 624 loss: 0.00229571387
Iter: 625 loss: 0.00229562586
Iter: 626 loss: 0.00229558395
Iter: 627 loss: 0.00229564705
Iter: 628 loss: 0.00229556276
Iter: 629 loss: 0.00229550945
Iter: 630 loss: 0.00229563192
Iter: 631 loss: 0.00229549
Iter: 632 loss: 0.00229544542
Iter: 633 loss: 0.0022956538
Iter: 634 loss: 0.0022954375
Iter: 635 loss: 0.00229540374
Iter: 636 loss: 0.00229578768
Iter: 637 loss: 0.00229540281
Iter: 638 loss: 0.00229537301
Iter: 639 loss: 0.00229547848
Iter: 640 loss: 0.00229536626
Iter: 641 loss: 0.00229534134
Iter: 642 loss: 0.00229535159
Iter: 643 loss: 0.00229532062
Iter: 644 loss: 0.00229529198
Iter: 645 loss: 0.0022952673
Iter: 646 loss: 0.00229525729
Iter: 647 loss: 0.00229522609
Iter: 648 loss: 0.00229567359
Iter: 649 loss: 0.00229522726
Iter: 650 loss: 0.00229519885
Iter: 651 loss: 0.00229540118
Iter: 652 loss: 0.00229519699
Iter: 653 loss: 0.00229517487
Iter: 654 loss: 0.00229514809
Iter: 655 loss: 0.00229514437
Iter: 656 loss: 0.00229510968
Iter: 657 loss: 0.00229516253
Iter: 658 loss: 0.00229509315
Iter: 659 loss: 0.00229505124
Iter: 660 loss: 0.00229512434
Iter: 661 loss: 0.00229503284
Iter: 662 loss: 0.00229498977
Iter: 663 loss: 0.0022951162
Iter: 664 loss: 0.00229497603
Iter: 665 loss: 0.00229493901
Iter: 666 loss: 0.00229507894
Iter: 667 loss: 0.00229493063
Iter: 668 loss: 0.0022948985
Iter: 669 loss: 0.00229517161
Iter: 670 loss: 0.0022948985
Iter: 671 loss: 0.00229487079
Iter: 672 loss: 0.00229507778
Iter: 673 loss: 0.0022948687
Iter: 674 loss: 0.00229485193
Iter: 675 loss: 0.00229485054
Iter: 676 loss: 0.0022948361
Iter: 677 loss: 0.00229481282
Iter: 678 loss: 0.00229479233
Iter: 679 loss: 0.00229478348
Iter: 680 loss: 0.00229475461
Iter: 681 loss: 0.00229497277
Iter: 682 loss: 0.00229475298
Iter: 683 loss: 0.00229473226
Iter: 684 loss: 0.00229473226
Iter: 685 loss: 0.00229471852
Iter: 686 loss: 0.002294695
Iter: 687 loss: 0.00229469594
Iter: 688 loss: 0.00229466939
Iter: 689 loss: 0.00229469547
Iter: 690 loss: 0.00229465449
Iter: 691 loss: 0.0022946212
Iter: 692 loss: 0.00229468546
Iter: 693 loss: 0.00229460606
Iter: 694 loss: 0.00229457696
Iter: 695 loss: 0.00229470339
Iter: 696 loss: 0.00229457021
Iter: 697 loss: 0.0022945418
Iter: 698 loss: 0.00229460234
Iter: 699 loss: 0.002294529
Iter: 700 loss: 0.00229450688
Iter: 701 loss: 0.00229473133
Iter: 702 loss: 0.00229450525
Iter: 703 loss: 0.00229448639
Iter: 704 loss: 0.00229467126
Iter: 705 loss: 0.00229448476
Iter: 706 loss: 0.00229447149
Iter: 707 loss: 0.00229447125
Iter: 708 loss: 0.00229446054
Iter: 709 loss: 0.00229444308
Iter: 710 loss: 0.00229442585
Iter: 711 loss: 0.0022944205
Iter: 712 loss: 0.00229439652
Iter: 713 loss: 0.00229455554
Iter: 714 loss: 0.00229439419
Iter: 715 loss: 0.00229438208
Iter: 716 loss: 0.00229438068
Iter: 717 loss: 0.00229437067
Iter: 718 loss: 0.00229435321
Iter: 719 loss: 0.00229435228
Iter: 720 loss: 0.00229433272
Iter: 721 loss: 0.00229434739
Iter: 722 loss: 0.00229432085
Iter: 723 loss: 0.00229429617
Iter: 724 loss: 0.00229436671
Iter: 725 loss: 0.00229428802
Iter: 726 loss: 0.00229426427
Iter: 727 loss: 0.00229430804
Iter: 728 loss: 0.00229425519
Iter: 729 loss: 0.00229423214
Iter: 730 loss: 0.00229432783
Iter: 731 loss: 0.00229422748
Iter: 732 loss: 0.00229420862
Iter: 733 loss: 0.00229434064
Iter: 734 loss: 0.00229420676
Iter: 735 loss: 0.00229419186
Iter: 736 loss: 0.00229436764
Iter: 737 loss: 0.00229419302
Iter: 738 loss: 0.00229418301
Iter: 739 loss: 0.00229417346
Iter: 740 loss: 0.0022941716
Iter: 741 loss: 0.00229415484
Iter: 742 loss: 0.00229416741
Iter: 743 loss: 0.00229414529
Iter: 744 loss: 0.00229412923
Iter: 745 loss: 0.00229416694
Iter: 746 loss: 0.00229412317
Iter: 747 loss: 0.00229411572
Iter: 748 loss: 0.00229411456
Iter: 749 loss: 0.00229410571
Iter: 750 loss: 0.00229409058
Iter: 751 loss: 0.00229409104
Iter: 752 loss: 0.00229407661
Iter: 753 loss: 0.00229409058
Iter: 754 loss: 0.00229406939
Iter: 755 loss: 0.00229405053
Iter: 756 loss: 0.00229408452
Iter: 757 loss: 0.00229404238
Iter: 758 loss: 0.00229402608
Iter: 759 loss: 0.00229405938
Iter: 760 loss: 0.00229401793
Iter: 761 loss: 0.0022940014
Iter: 762 loss: 0.00229410431
Iter: 763 loss: 0.00229399954
Iter: 764 loss: 0.00229398534
Iter: 765 loss: 0.00229403237
Iter: 766 loss: 0.00229398208
Iter: 767 loss: 0.00229397044
Iter: 768 loss: 0.00229397137
Iter: 769 loss: 0.00229396345
Iter: 770 loss: 0.00229395879
Iter: 771 loss: 0.002293956
Iter: 772 loss: 0.00229394506
Iter: 773 loss: 0.00229395437
Iter: 774 loss: 0.00229393877
Iter: 775 loss: 0.00229392736
Iter: 776 loss: 0.00229394692
Iter: 777 loss: 0.00229392247
Iter: 778 loss: 0.00229391502
Iter: 779 loss: 0.00229391223
Iter: 780 loss: 0.00229390711
Iter: 781 loss: 0.00229390105
Iter: 782 loss: 0.00229389942
Iter: 783 loss: 0.00229389081
Iter: 784 loss: 0.00229388988
Iter: 785 loss: 0.00229388289
Iter: 786 loss: 0.00229386869
Iter: 787 loss: 0.00229391339
Iter: 788 loss: 0.00229386566
Iter: 789 loss: 0.00229385425
Iter: 790 loss: 0.00229386985
Iter: 791 loss: 0.0022938489
Iter: 792 loss: 0.00229383446
Iter: 793 loss: 0.00229389104
Iter: 794 loss: 0.0022938319
Iter: 795 loss: 0.00229382236
Iter: 796 loss: 0.00229387684
Iter: 797 loss: 0.00229382
Iter: 798 loss: 0.00229381374
Iter: 799 loss: 0.00229381304
Iter: 800 loss: 0.00229380699
Iter: 801 loss: 0.00229380326
Iter: 802 loss: 0.00229380187
Iter: 803 loss: 0.00229379395
Iter: 804 loss: 0.00229379814
Iter: 805 loss: 0.00229378976
Iter: 806 loss: 0.00229377951
Iter: 807 loss: 0.00229380094
Iter: 808 loss: 0.00229377579
Iter: 809 loss: 0.00229377206
Iter: 810 loss: 0.0022937716
Iter: 811 loss: 0.00229376601
Iter: 812 loss: 0.00229376205
Iter: 813 loss: 0.00229376135
Iter: 814 loss: 0.0022937546
Iter: 815 loss: 0.00229374948
Iter: 816 loss: 0.00229374785
Iter: 817 loss: 0.0022937383
Iter: 818 loss: 0.00229378627
Iter: 819 loss: 0.00229373574
Iter: 820 loss: 0.00229372736
Iter: 821 loss: 0.00229373062
Iter: 822 loss: 0.00229372247
Iter: 823 loss: 0.00229371223
Iter: 824 loss: 0.00229377579
Iter: 825 loss: 0.0022937106
Iter: 826 loss: 0.00229370361
Iter: 827 loss: 0.00229373295
Iter: 828 loss: 0.00229370315
Iter: 829 loss: 0.00229369756
Iter: 830 loss: 0.00229369802
Iter: 831 loss: 0.00229369523
Iter: 832 loss: 0.00229369104
Iter: 833 loss: 0.00229368941
Iter: 834 loss: 0.00229368405
Iter: 835 loss: 0.00229369057
Iter: 836 loss: 0.00229368
Iter: 837 loss: 0.00229367381
Iter: 838 loss: 0.00229368638
Iter: 839 loss: 0.00229367102
Iter: 840 loss: 0.00229366799
Iter: 841 loss: 0.00229366636
Iter: 842 loss: 0.0022936645
Iter: 843 loss: 0.00229366194
Iter: 844 loss: 0.00229366124
Iter: 845 loss: 0.00229365518
Iter: 846 loss: 0.00229365239
Iter: 847 loss: 0.00229365076
Iter: 848 loss: 0.00229364471
Iter: 849 loss: 0.00229367474
Iter: 850 loss: 0.00229364401
Iter: 851 loss: 0.00229363795
Iter: 852 loss: 0.00229363632
Iter: 853 loss: 0.00229363376
Iter: 854 loss: 0.00229362538
Iter: 855 loss: 0.00229367032
Iter: 856 loss: 0.00229362375
Iter: 857 loss: 0.00229361933
Iter: 858 loss: 0.00229364214
Iter: 859 loss: 0.002293617
Iter: 860 loss: 0.00229361397
Iter: 861 loss: 0.00229361327
Iter: 862 loss: 0.00229361
Iter: 863 loss: 0.00229360769
Iter: 864 loss: 0.00229360629
Iter: 865 loss: 0.00229360047
Iter: 866 loss: 0.00229360699
Iter: 867 loss: 0.00229359884
Iter: 868 loss: 0.00229359278
Iter: 869 loss: 0.00229360932
Iter: 870 loss: 0.00229359325
Iter: 871 loss: 0.00229358883
Iter: 872 loss: 0.0022935879
Iter: 873 loss: 0.00229358394
Iter: 874 loss: 0.00229358301
Iter: 875 loss: 0.00229358114
Iter: 876 loss: 0.00229357928
Iter: 877 loss: 0.00229357602
Iter: 878 loss: 0.00229357323
Iter: 879 loss: 0.00229356904
Iter: 880 loss: 0.00229359139
Iter: 881 loss: 0.0022935681
Iter: 882 loss: 0.00229356322
Iter: 883 loss: 0.00229356065
Iter: 884 loss: 0.00229355739
Iter: 885 loss: 0.00229355111
Iter: 886 loss: 0.00229360792
Iter: 887 loss: 0.00229355134
Iter: 888 loss: 0.00229354575
Iter: 889 loss: 0.0022935688
Iter: 890 loss: 0.00229354505
Iter: 891 loss: 0.00229354063
Iter: 892 loss: 0.00229354016
Iter: 893 loss: 0.00229353877
Iter: 894 loss: 0.00229353528
Iter: 895 loss: 0.00229353574
Iter: 896 loss: 0.00229352945
Iter: 897 loss: 0.00229354063
Iter: 898 loss: 0.00229352782
Iter: 899 loss: 0.0022935234
Iter: 900 loss: 0.00229353225
Iter: 901 loss: 0.00229352131
Iter: 902 loss: 0.00229351874
Iter: 903 loss: 0.00229351921
Iter: 904 loss: 0.00229351572
Iter: 905 loss: 0.00229351828
Iter: 906 loss: 0.00229351292
Iter: 907 loss: 0.00229351106
Iter: 908 loss: 0.00229350873
Iter: 909 loss: 0.00229350943
Iter: 910 loss: 0.00229350477
Iter: 911 loss: 0.00229351874
Iter: 912 loss: 0.00229350245
Iter: 913 loss: 0.00229349802
Iter: 914 loss: 0.00229350058
Iter: 915 loss: 0.00229349732
Iter: 916 loss: 0.00229349174
Iter: 917 loss: 0.00229352526
Iter: 918 loss: 0.0022934908
Iter: 919 loss: 0.00229348568
Iter: 920 loss: 0.00229349476
Iter: 921 loss: 0.00229348522
Iter: 922 loss: 0.00229348359
Iter: 923 loss: 0.00229348335
Iter: 924 loss: 0.00229348149
Iter: 925 loss: 0.00229348056
Iter: 926 loss: 0.00229347823
Iter: 927 loss: 0.00229347707
Iter: 928 loss: 0.00229348103
Iter: 929 loss: 0.00229347451
Iter: 930 loss: 0.00229347
Iter: 931 loss: 0.00229347823
Iter: 932 loss: 0.00229347125
Iter: 933 loss: 0.00229346892
Iter: 934 loss: 0.00229350151
Iter: 935 loss: 0.00229346775
Iter: 936 loss: 0.00229346473
Iter: 937 loss: 0.00229346915
Iter: 938 loss: 0.00229346519
Iter: 939 loss: 0.00229346356
Iter: 940 loss: 0.00229346054
Iter: 941 loss: 0.00229353178
Iter: 942 loss: 0.00229346
Iter: 943 loss: 0.00229345728
Iter: 944 loss: 0.00229347195
Iter: 945 loss: 0.00229345658
Iter: 946 loss: 0.00229345262
Iter: 947 loss: 0.00229345961
Iter: 948 loss: 0.00229344983
Iter: 949 loss: 0.00229344843
Iter: 950 loss: 0.00229345914
Iter: 951 loss: 0.00229344773
Iter: 952 loss: 0.00229344494
Iter: 953 loss: 0.00229344959
Iter: 954 loss: 0.00229344377
Iter: 955 loss: 0.00229344331
Iter: 956 loss: 0.00229344284
Iter: 957 loss: 0.00229344075
Iter: 958 loss: 0.00229343958
Iter: 959 loss: 0.00229344
Iter: 960 loss: 0.00229343725
Iter: 961 loss: 0.00229343632
Iter: 962 loss: 0.00229343539
Iter: 963 loss: 0.00229343073
Iter: 964 loss: 0.00229343888
Iter: 965 loss: 0.00229343167
Iter: 966 loss: 0.0022934298
Iter: 967 loss: 0.00229345961
Iter: 968 loss: 0.00229342957
Iter: 969 loss: 0.00229342771
Iter: 970 loss: 0.00229343213
Iter: 971 loss: 0.00229342747
Iter: 972 loss: 0.00229342701
Iter: 973 loss: 0.00229342328
Iter: 974 loss: 0.0022934766
Iter: 975 loss: 0.00229342282
Iter: 976 loss: 0.00229342072
Iter: 977 loss: 0.00229343749
Iter: 978 loss: 0.00229342026
Iter: 979 loss: 0.00229341863
Iter: 980 loss: 0.00229342119
Iter: 981 loss: 0.0022934163
Iter: 982 loss: 0.0022934149
Iter: 983 loss: 0.00229342072
Iter: 984 loss: 0.00229341513
Iter: 985 loss: 0.00229341164
Iter: 986 loss: 0.00229341956
Iter: 987 loss: 0.00229341118
Iter: 988 loss: 0.00229341048
Iter: 989 loss: 0.00229341025
Iter: 990 loss: 0.00229340862
Iter: 991 loss: 0.00229340745
Iter: 992 loss: 0.00229340629
Iter: 993 loss: 0.00229340466
Iter: 994 loss: 0.00229340815
Iter: 995 loss: 0.00229340279
Iter: 996 loss: 0.00229340186
Iter: 997 loss: 0.00229340536
Iter: 998 loss: 0.00229340163
Iter: 999 loss: 0.00229339837
Iter: 1000 loss: 0.0022934177
Iter: 1001 loss: 0.00229339884
Iter: 1002 loss: 0.00229339814
Iter: 1003 loss: 0.0022934021
Iter: 1004 loss: 0.00229339791
Iter: 1005 loss: 0.00229339674
Iter: 1006 loss: 0.00229339534
Iter: 1007 loss: 0.00229343865
Iter: 1008 loss: 0.00229339488
Iter: 1009 loss: 0.00229339371
Iter: 1010 loss: 0.0022934021
Iter: 1011 loss: 0.00229339255
Iter: 1012 loss: 0.00229339115
Iter: 1013 loss: 0.00229339441
Iter: 1014 loss: 0.00229339
Iter: 1015 loss: 0.00229338859
Iter: 1016 loss: 0.00229339208
Iter: 1017 loss: 0.00229338836
Iter: 1018 loss: 0.0022933851
Iter: 1019 loss: 0.00229338836
Iter: 1020 loss: 0.0022933858
Iter: 1021 loss: 0.00229338324
Iter: 1022 loss: 0.0022933837
Iter: 1023 loss: 0.002293383
Iter: 1024 loss: 0.00229338184
Iter: 1025 loss: 0.00229337974
Iter: 1026 loss: 0.00229337858
Iter: 1027 loss: 0.00229338254
Iter: 1028 loss: 0.00229337858
Iter: 1029 loss: 0.00229337672
Iter: 1030 loss: 0.00229337811
Iter: 1031 loss: 0.00229337602
Iter: 1032 loss: 0.00229337346
Iter: 1033 loss: 0.00229339115
Iter: 1034 loss: 0.00229337299
Iter: 1035 loss: 0.00229337323
Iter: 1036 loss: 0.00229337951
Iter: 1037 loss: 0.00229337276
Iter: 1038 loss: 0.0022933716
Iter: 1039 loss: 0.00229337
Iter: 1040 loss: 0.00229338836
Iter: 1041 loss: 0.00229337
Iter: 1042 loss: 0.00229336787
Iter: 1043 loss: 0.00229337765
Iter: 1044 loss: 0.00229336554
Iter: 1045 loss: 0.00229336461
Iter: 1046 loss: 0.00229337462
Iter: 1047 loss: 0.00229336414
Iter: 1048 loss: 0.00229336228
Iter: 1049 loss: 0.00229336647
Iter: 1050 loss: 0.00229336182
Iter: 1051 loss: 0.00229336065
Iter: 1052 loss: 0.00229336275
Iter: 1053 loss: 0.00229335832
Iter: 1054 loss: 0.00229335669
Iter: 1055 loss: 0.00229337858
Iter: 1056 loss: 0.00229335809
Iter: 1057 loss: 0.00229335623
Iter: 1058 loss: 0.00229335856
Iter: 1059 loss: 0.00229335669
Iter: 1060 loss: 0.00229335413
Iter: 1061 loss: 0.00229335576
Iter: 1062 loss: 0.00229335437
Iter: 1063 loss: 0.0022933525
Iter: 1064 loss: 0.00229335483
Iter: 1065 loss: 0.00229335204
Iter: 1066 loss: 0.00229335204
Iter: 1067 loss: 0.00229335926
Iter: 1068 loss: 0.0022933525
Iter: 1069 loss: 0.00229334971
Iter: 1070 loss: 0.00229335786
Iter: 1071 loss: 0.00229335087
Iter: 1072 loss: 0.00229334901
Iter: 1073 loss: 0.00229334855
Iter: 1074 loss: 0.00229335972
Iter: 1075 loss: 0.00229334808
Iter: 1076 loss: 0.00229334715
Iter: 1077 loss: 0.0022933539
Iter: 1078 loss: 0.00229334692
Iter: 1079 loss: 0.00229334598
Iter: 1080 loss: 0.00229334831
Iter: 1081 loss: 0.00229334552
Iter: 1082 loss: 0.00229334366
Iter: 1083 loss: 0.00229334598
Iter: 1084 loss: 0.00229334459
Iter: 1085 loss: 0.00229334296
Iter: 1086 loss: 0.00229334552
Iter: 1087 loss: 0.00229334226
Iter: 1088 loss: 0.00229334133
Iter: 1089 loss: 0.00229334319
Iter: 1090 loss: 0.0022933404
Iter: 1091 loss: 0.0022933404
Iter: 1092 loss: 0.00229334831
Iter: 1093 loss: 0.00229334
Iter: 1094 loss: 0.00229333923
Iter: 1095 loss: 0.00229333877
Iter: 1096 loss: 0.00229333923
Iter: 1097 loss: 0.00229333853
Iter: 1098 loss: 0.00229334
Iter: 1099 loss: 0.0022933369
Iter: 1100 loss: 0.00229333597
Iter: 1101 loss: 0.00229334179
Iter: 1102 loss: 0.0022933369
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4
+ date
Tue Oct 27 20:05:24 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c3f0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e90b19d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e90b196a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c3a67b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c2fa0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c316d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c27d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c27d840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c2afd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c23e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c20cd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c1c4488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c1c4c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c17a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c1b0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c1b0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c151598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c1642f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c0c18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c0c12f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c0ee598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c099ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c05c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c0ee730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e6c064ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e5073e840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e50772730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e5071b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e5071b620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e506c4488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e506f1bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e506f1840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e506f1510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e5064a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e506089d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6e506082f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.236395806
Iter: 2 loss: 9919.34766
Iter: 3 loss: 0.236394316
Iter: 4 loss: 2992.47803
Iter: 5 loss: 0.236393288
Iter: 6 loss: 4162.11523
Iter: 7 loss: 0.236392826
Iter: 8 loss: 2283.49219
Iter: 9 loss: 369.224091
Iter: 10 loss: 0.236391217
Iter: 11 loss: 417.017883
Iter: 12 loss: 5.87511158
Iter: 13 loss: 0.236374259
Iter: 14 loss: 0.177220866
Iter: 15 loss: 0.177206933
Iter: 16 loss: 0.145173341
Iter: 17 loss: 0.145170107
Iter: 18 loss: 1456.83801
Iter: 19 loss: 533.966675
Iter: 20 loss: 0.145169288
Iter: 21 loss: 0.142281294
Iter: 22 loss: 0.136978149
Iter: 23 loss: 0.141127497
Iter: 24 loss: 0.135787487
Iter: 25 loss: 0.129769802
Iter: 26 loss: 0.657739878
Iter: 27 loss: 0.12976779
Iter: 28 loss: 0.12714085
Iter: 29 loss: 0.153037488
Iter: 30 loss: 0.126730978
Iter: 31 loss: 0.117806993
Iter: 32 loss: 0.295057356
Iter: 33 loss: 0.117538355
Iter: 34 loss: 0.134846807
Iter: 35 loss: 0.112405524
Iter: 36 loss: 0.103473365
Iter: 37 loss: 0.1033566
Iter: 38 loss: 0.096269846
Iter: 39 loss: 0.107214525
Iter: 40 loss: 0.0957514048
Iter: 41 loss: 0.0905624628
Iter: 42 loss: 0.096455887
Iter: 43 loss: 0.0873931795
Iter: 44 loss: 0.0832837522
Iter: 45 loss: 0.0832114518
Iter: 46 loss: 0.07790488
Iter: 47 loss: 0.233889878
Iter: 48 loss: 0.0778027
Iter: 49 loss: 0.0751577169
Iter: 50 loss: 0.0851908
Iter: 51 loss: 0.0749299526
Iter: 52 loss: 0.072669223
Iter: 53 loss: 0.161720589
Iter: 54 loss: 0.0726672411
Iter: 55 loss: 0.0702841729
Iter: 56 loss: 0.0821106285
Iter: 57 loss: 0.0695281178
Iter: 58 loss: 0.0659181401
Iter: 59 loss: 0.176603824
Iter: 60 loss: 0.0659159869
Iter: 61 loss: 0.0625315458
Iter: 62 loss: 0.0775870159
Iter: 63 loss: 0.0622570068
Iter: 64 loss: 0.0609420501
Iter: 65 loss: 0.0702028
Iter: 66 loss: 0.0609105825
Iter: 67 loss: 0.0598134622
Iter: 68 loss: 0.0690607429
Iter: 69 loss: 0.0596073
Iter: 70 loss: 0.0583099797
Iter: 71 loss: 0.0888134614
Iter: 72 loss: 0.0582754463
Iter: 73 loss: 0.0571559705
Iter: 74 loss: 0.0629550666
Iter: 75 loss: 0.0568900257
Iter: 76 loss: 0.0538371019
Iter: 77 loss: 0.0633936077
Iter: 78 loss: 0.0527655743
Iter: 79 loss: 0.0500799119
Iter: 80 loss: 0.0787076
Iter: 81 loss: 0.0498834476
Iter: 82 loss: 0.0479884818
Iter: 83 loss: 0.0691821277
Iter: 84 loss: 0.047789894
Iter: 85 loss: 0.0458996482
Iter: 86 loss: 0.195756793
Iter: 87 loss: 0.0458980203
Iter: 88 loss: 0.0448566116
Iter: 89 loss: 0.0494707674
Iter: 90 loss: 0.0445849821
Iter: 91 loss: 0.0427184664
Iter: 92 loss: 0.062890023
Iter: 93 loss: 0.042681016
Iter: 94 loss: 0.0408840626
Iter: 95 loss: 0.0786998421
Iter: 96 loss: 0.040868111
Iter: 97 loss: 0.0397758558
Iter: 98 loss: 0.0409737714
Iter: 99 loss: 0.0391824
Iter: 100 loss: 0.0397215597
Iter: 101 loss: 0.0388322771
Iter: 102 loss: 0.0383325368
Iter: 103 loss: 0.0431417301
Iter: 104 loss: 0.0383176506
Iter: 105 loss: 0.0378724821
Iter: 106 loss: 0.0375233665
Iter: 107 loss: 0.0373845547
Iter: 108 loss: 0.0370623097
Iter: 109 loss: 0.0370035768
Iter: 110 loss: 0.0365755334
Iter: 111 loss: 0.0365497917
Iter: 112 loss: 0.0362145863
Iter: 113 loss: 0.0357854255
Iter: 114 loss: 0.0359111317
Iter: 115 loss: 0.0354806781
Iter: 116 loss: 0.0346642062
Iter: 117 loss: 0.0357437246
Iter: 118 loss: 0.0342428759
Iter: 119 loss: 0.0336971059
Iter: 120 loss: 0.0362278596
Iter: 121 loss: 0.0335848257
Iter: 122 loss: 0.0328300148
Iter: 123 loss: 0.0399951041
Iter: 124 loss: 0.032770928
Iter: 125 loss: 0.0320388377
Iter: 126 loss: 0.0380095
Iter: 127 loss: 0.0319462679
Iter: 128 loss: 0.0313619748
Iter: 129 loss: 0.0325053968
Iter: 130 loss: 0.0311482567
Iter: 131 loss: 0.0328501649
Iter: 132 loss: 0.031003844
Iter: 133 loss: 0.0307372436
Iter: 134 loss: 0.0310995113
Iter: 135 loss: 0.0305950604
Iter: 136 loss: 0.0301521532
Iter: 137 loss: 0.030351419
Iter: 138 loss: 0.0298406612
Iter: 139 loss: 0.0298730768
Iter: 140 loss: 0.0295686014
Iter: 141 loss: 0.029255962
Iter: 142 loss: 0.0296133906
Iter: 143 loss: 0.0290799029
Iter: 144 loss: 0.0285743214
Iter: 145 loss: 0.0280560385
Iter: 146 loss: 0.0279483963
Iter: 147 loss: 0.0274639856
Iter: 148 loss: 0.0299554449
Iter: 149 loss: 0.0273972638
Iter: 150 loss: 0.0272712633
Iter: 151 loss: 0.0272694752
Iter: 152 loss: 0.0271702595
Iter: 153 loss: 0.0268579423
Iter: 154 loss: 0.0264830366
Iter: 155 loss: 0.0264440142
Iter: 156 loss: 0.0257868189
Iter: 157 loss: 0.0288832523
Iter: 158 loss: 0.0256427545
Iter: 159 loss: 0.0250945799
Iter: 160 loss: 0.0297886506
Iter: 161 loss: 0.0250716843
Iter: 162 loss: 0.0244328436
Iter: 163 loss: 0.0266470034
Iter: 164 loss: 0.0242059119
Iter: 165 loss: 0.0247310251
Iter: 166 loss: 0.0240446031
Iter: 167 loss: 0.0239223279
Iter: 168 loss: 0.024179168
Iter: 169 loss: 0.0238696747
Iter: 170 loss: 0.0236771163
Iter: 171 loss: 0.023183044
Iter: 172 loss: 0.027568046
Iter: 173 loss: 0.023099415
Iter: 174 loss: 0.0226691552
Iter: 175 loss: 0.0281659067
Iter: 176 loss: 0.0226583369
Iter: 177 loss: 0.022615239
Iter: 178 loss: 0.0225054659
Iter: 179 loss: 0.0224171691
Iter: 180 loss: 0.0224093795
Iter: 181 loss: 0.0222955216
Iter: 182 loss: 0.0222928748
Iter: 183 loss: 0.0222021658
Iter: 184 loss: 0.0217243582
Iter: 185 loss: 0.0237193778
Iter: 186 loss: 0.0216084681
Iter: 187 loss: 0.0211297572
Iter: 188 loss: 0.0238348786
Iter: 189 loss: 0.0210731179
Iter: 190 loss: 0.020584546
Iter: 191 loss: 0.0214219801
Iter: 192 loss: 0.0203622412
Iter: 193 loss: 0.0198055245
Iter: 194 loss: 0.0223967619
Iter: 195 loss: 0.0196889043
Iter: 196 loss: 0.0197556689
Iter: 197 loss: 0.019554412
Iter: 198 loss: 0.0194261558
Iter: 199 loss: 0.0199524797
Iter: 200 loss: 0.0194003377
Iter: 201 loss: 0.0192891546
Iter: 202 loss: 0.0190661401
Iter: 203 loss: 0.0236545429
Iter: 204 loss: 0.019063551
Iter: 205 loss: 0.0187572874
Iter: 206 loss: 0.0198300052
Iter: 207 loss: 0.0186732225
Iter: 208 loss: 0.0185703468
Iter: 209 loss: 0.0185625888
Iter: 210 loss: 0.0184570551
Iter: 211 loss: 0.0196049716
Iter: 212 loss: 0.0184529163
Iter: 213 loss: 0.0183245167
Iter: 214 loss: 0.0181291252
Iter: 215 loss: 0.0181250572
Iter: 216 loss: 0.0178075489
Iter: 217 loss: 0.019721739
Iter: 218 loss: 0.0177704245
Iter: 219 loss: 0.0176243819
Iter: 220 loss: 0.0175759755
Iter: 221 loss: 0.0174908917
Iter: 222 loss: 0.0172756389
Iter: 223 loss: 0.0173667967
Iter: 224 loss: 0.0171242561
Iter: 225 loss: 0.0169491693
Iter: 226 loss: 0.0171816982
Iter: 227 loss: 0.0168597978
Iter: 228 loss: 0.0165149402
Iter: 229 loss: 0.0174091607
Iter: 230 loss: 0.0163990669
Iter: 231 loss: 0.0162719227
Iter: 232 loss: 0.0162272844
Iter: 233 loss: 0.0161705054
Iter: 234 loss: 0.0161837135
Iter: 235 loss: 0.0161285866
Iter: 236 loss: 0.0159182753
Iter: 237 loss: 0.0156910326
Iter: 238 loss: 0.0156572685
Iter: 239 loss: 0.0154441725
Iter: 240 loss: 0.0188220181
Iter: 241 loss: 0.0154415099
Iter: 242 loss: 0.0154083669
Iter: 243 loss: 0.015398303
Iter: 244 loss: 0.0153314723
Iter: 245 loss: 0.0152264489
Iter: 246 loss: 0.0152250659
Iter: 247 loss: 0.0151248444
Iter: 248 loss: 0.0153894238
Iter: 249 loss: 0.0150946509
Iter: 250 loss: 0.0150511451
Iter: 251 loss: 0.0149712069
Iter: 252 loss: 0.0172873773
Iter: 253 loss: 0.0149711883
Iter: 254 loss: 0.014844453
Iter: 255 loss: 0.0151181929
Iter: 256 loss: 0.0147944205
Iter: 257 loss: 0.0147335678
Iter: 258 loss: 0.0146806482
Iter: 259 loss: 0.0146058314
Iter: 260 loss: 0.0145060942
Iter: 261 loss: 0.0145000424
Iter: 262 loss: 0.0143386517
Iter: 263 loss: 0.0162811428
Iter: 264 loss: 0.0143347243
Iter: 265 loss: 0.0141581763
Iter: 266 loss: 0.014156159
Iter: 267 loss: 0.0140148029
Iter: 268 loss: 0.0145755429
Iter: 269 loss: 0.013980397
Iter: 270 loss: 0.0138611281
Iter: 271 loss: 0.0138606839
Iter: 272 loss: 0.0137352906
Iter: 273 loss: 0.0141578391
Iter: 274 loss: 0.0137000699
Iter: 275 loss: 0.0139654372
Iter: 276 loss: 0.0136608733
Iter: 277 loss: 0.0136168022
Iter: 278 loss: 0.0138048232
Iter: 279 loss: 0.013606403
Iter: 280 loss: 0.0135664828
Iter: 281 loss: 0.0134416744
Iter: 282 loss: 0.013701505
Iter: 283 loss: 0.0133608449
Iter: 284 loss: 0.0131334262
Iter: 285 loss: 0.0146651445
Iter: 286 loss: 0.0131112728
Iter: 287 loss: 0.0130354399
Iter: 288 loss: 0.0134091582
Iter: 289 loss: 0.0130220698
Iter: 290 loss: 0.0130999805
Iter: 291 loss: 0.0129439346
Iter: 292 loss: 0.0128960218
Iter: 293 loss: 0.0128714284
Iter: 294 loss: 0.0128483521
Iter: 295 loss: 0.0127925873
Iter: 296 loss: 0.0127829611
Iter: 297 loss: 0.0127451178
Iter: 298 loss: 0.0126617216
Iter: 299 loss: 0.0125086475
Iter: 300 loss: 0.0163871273
Iter: 301 loss: 0.0125085823
Iter: 302 loss: 0.0123320073
Iter: 303 loss: 0.0133121833
Iter: 304 loss: 0.0123041188
Iter: 305 loss: 0.0122176632
Iter: 306 loss: 0.0125840148
Iter: 307 loss: 0.0122007765
Iter: 308 loss: 0.012157144
Iter: 309 loss: 0.0124303326
Iter: 310 loss: 0.0121515654
Iter: 311 loss: 0.012122497
Iter: 312 loss: 0.0121015115
Iter: 313 loss: 0.0120917112
Iter: 314 loss: 0.01199314
Iter: 315 loss: 0.0118464027
Iter: 316 loss: 0.0118427332
Iter: 317 loss: 0.0117064286
Iter: 318 loss: 0.0126833878
Iter: 319 loss: 0.0116930511
Iter: 320 loss: 0.0116044013
Iter: 321 loss: 0.011838153
Iter: 322 loss: 0.0115729487
Iter: 323 loss: 0.011530621
Iter: 324 loss: 0.0115098394
Iter: 325 loss: 0.0114635294
Iter: 326 loss: 0.0116375741
Iter: 327 loss: 0.0114522483
Iter: 328 loss: 0.0113779102
Iter: 329 loss: 0.0114080049
Iter: 330 loss: 0.0113283983
Iter: 331 loss: 0.0112365168
Iter: 332 loss: 0.0116115138
Iter: 333 loss: 0.01121487
Iter: 334 loss: 0.0111356452
Iter: 335 loss: 0.011037223
Iter: 336 loss: 0.0110290647
Iter: 337 loss: 0.0109706149
Iter: 338 loss: 0.0114904363
Iter: 339 loss: 0.0109671988
Iter: 340 loss: 0.0109345447
Iter: 341 loss: 0.0109719289
Iter: 342 loss: 0.0109168962
Iter: 343 loss: 0.0108596012
Iter: 344 loss: 0.0107699335
Iter: 345 loss: 0.0107688121
Iter: 346 loss: 0.0107252318
Iter: 347 loss: 0.01063467
Iter: 348 loss: 0.0105387643
Iter: 349 loss: 0.0111195743
Iter: 350 loss: 0.010526347
Iter: 351 loss: 0.010483887
Iter: 352 loss: 0.0105138188
Iter: 353 loss: 0.0104582235
Iter: 354 loss: 0.0104022864
Iter: 355 loss: 0.0106225777
Iter: 356 loss: 0.0103909373
Iter: 357 loss: 0.0103304265
Iter: 358 loss: 0.010328928
Iter: 359 loss: 0.010313699
Iter: 360 loss: 0.0102653876
Iter: 361 loss: 0.0103252633
Iter: 362 loss: 0.0102290567
Iter: 363 loss: 0.0101417881
Iter: 364 loss: 0.0113283228
Iter: 365 loss: 0.0101406863
Iter: 366 loss: 0.010074174
Iter: 367 loss: 0.0100719631
Iter: 368 loss: 0.010049752
Iter: 369 loss: 0.0101080742
Iter: 370 loss: 0.0100420984
Iter: 371 loss: 0.0100174071
Iter: 372 loss: 0.00995883904
Iter: 373 loss: 0.0105648367
Iter: 374 loss: 0.00995308161
Iter: 375 loss: 0.00987173896
Iter: 376 loss: 0.00985507853
Iter: 377 loss: 0.00980158895
Iter: 378 loss: 0.00977699645
Iter: 379 loss: 0.00975780841
Iter: 380 loss: 0.00972573552
Iter: 381 loss: 0.00972373
Iter: 382 loss: 0.00969907083
Iter: 383 loss: 0.00963558629
Iter: 384 loss: 0.0101591963
Iter: 385 loss: 0.00962442346
Iter: 386 loss: 0.00953121111
Iter: 387 loss: 0.0101329889
Iter: 388 loss: 0.00952014606
Iter: 389 loss: 0.00940712169
Iter: 390 loss: 0.00936694629
Iter: 391 loss: 0.00930221938
Iter: 392 loss: 0.0100289527
Iter: 393 loss: 0.00921965856
Iter: 394 loss: 0.00915226154
Iter: 395 loss: 0.00931936316
Iter: 396 loss: 0.00912814494
Iter: 397 loss: 0.00911124796
Iter: 398 loss: 0.00911032408
Iter: 399 loss: 0.00909745228
Iter: 400 loss: 0.00903200265
Iter: 401 loss: 0.00914231874
Iter: 402 loss: 0.00900305063
Iter: 403 loss: 0.0089565618
Iter: 404 loss: 0.00893069804
Iter: 405 loss: 0.00887316652
Iter: 406 loss: 0.00894275308
Iter: 407 loss: 0.00884337071
Iter: 408 loss: 0.00880328845
Iter: 409 loss: 0.00887089
Iter: 410 loss: 0.00878535211
Iter: 411 loss: 0.00872146431
Iter: 412 loss: 0.00867079105
Iter: 413 loss: 0.00865120627
Iter: 414 loss: 0.00859165378
Iter: 415 loss: 0.00898490287
Iter: 416 loss: 0.00858376734
Iter: 417 loss: 0.00856271945
Iter: 418 loss: 0.008503085
Iter: 419 loss: 0.00882122852
Iter: 420 loss: 0.00848338
Iter: 421 loss: 0.00841049
Iter: 422 loss: 0.00860750675
Iter: 423 loss: 0.00838704
Iter: 424 loss: 0.00836431142
Iter: 425 loss: 0.00836107787
Iter: 426 loss: 0.00834521279
Iter: 427 loss: 0.00835120585
Iter: 428 loss: 0.00831783563
Iter: 429 loss: 0.00828165375
Iter: 430 loss: 0.00827450212
Iter: 431 loss: 0.00825017411
Iter: 432 loss: 0.008229414
Iter: 433 loss: 0.00825824775
Iter: 434 loss: 0.00821935851
Iter: 435 loss: 0.00820472743
Iter: 436 loss: 0.0081844423
Iter: 437 loss: 0.00818355195
Iter: 438 loss: 0.00815588702
Iter: 439 loss: 0.00810530502
Iter: 440 loss: 0.009313724
Iter: 441 loss: 0.00810526591
Iter: 442 loss: 0.00806587283
Iter: 443 loss: 0.00818122923
Iter: 444 loss: 0.00805380754
Iter: 445 loss: 0.00798578188
Iter: 446 loss: 0.00846943725
Iter: 447 loss: 0.00797907542
Iter: 448 loss: 0.00793128368
Iter: 449 loss: 0.00828838814
Iter: 450 loss: 0.00792752579
Iter: 451 loss: 0.00791285466
Iter: 452 loss: 0.00791586377
Iter: 453 loss: 0.00790189393
Iter: 454 loss: 0.00785705447
Iter: 455 loss: 0.00798946619
Iter: 456 loss: 0.00784444
Iter: 457 loss: 0.00779445376
Iter: 458 loss: 0.00777496956
Iter: 459 loss: 0.00774664292
Iter: 460 loss: 0.00767859817
Iter: 461 loss: 0.00764618302
Iter: 462 loss: 0.00761343958
Iter: 463 loss: 0.00759561174
Iter: 464 loss: 0.00759197399
Iter: 465 loss: 0.00758276461
Iter: 466 loss: 0.00760279736
Iter: 467 loss: 0.00757928565
Iter: 468 loss: 0.00754239177
Iter: 469 loss: 0.00750261825
Iter: 470 loss: 0.00749636441
Iter: 471 loss: 0.00741759315
Iter: 472 loss: 0.00745322742
Iter: 473 loss: 0.00736327609
Iter: 474 loss: 0.00731940754
Iter: 475 loss: 0.00730433129
Iter: 476 loss: 0.00727162324
Iter: 477 loss: 0.00755647104
Iter: 478 loss: 0.00727000134
Iter: 479 loss: 0.00724338181
Iter: 480 loss: 0.00748909498
Iter: 481 loss: 0.00724205188
Iter: 482 loss: 0.00721515
Iter: 483 loss: 0.00724646496
Iter: 484 loss: 0.00720075704
Iter: 485 loss: 0.0071591828
Iter: 486 loss: 0.00711852126
Iter: 487 loss: 0.00710952049
Iter: 488 loss: 0.00710717309
Iter: 489 loss: 0.00707523804
Iter: 490 loss: 0.00705046766
Iter: 491 loss: 0.00714575965
Iter: 492 loss: 0.00704478845
Iter: 493 loss: 0.00702988869
Iter: 494 loss: 0.00716960756
Iter: 495 loss: 0.00702921441
Iter: 496 loss: 0.00701491442
Iter: 497 loss: 0.00697849831
Iter: 498 loss: 0.00727065094
Iter: 499 loss: 0.0069723404
Iter: 500 loss: 0.00694576418
Iter: 501 loss: 0.00703111663
Iter: 502 loss: 0.00693812035
Iter: 503 loss: 0.00692489278
Iter: 504 loss: 0.00689226389
Iter: 505 loss: 0.00723980367
Iter: 506 loss: 0.00688825827
Iter: 507 loss: 0.00684130099
Iter: 508 loss: 0.00685739564
Iter: 509 loss: 0.0068082409
Iter: 510 loss: 0.00677028485
Iter: 511 loss: 0.00694876304
Iter: 512 loss: 0.00676359376
Iter: 513 loss: 0.00672355946
Iter: 514 loss: 0.0069895233
Iter: 515 loss: 0.00671913242
Iter: 516 loss: 0.00669723144
Iter: 517 loss: 0.00675271
Iter: 518 loss: 0.00668947073
Iter: 519 loss: 0.00665663555
Iter: 520 loss: 0.0070637255
Iter: 521 loss: 0.00665636221
Iter: 522 loss: 0.0066283443
Iter: 523 loss: 0.00701837381
Iter: 524 loss: 0.00662825536
Iter: 525 loss: 0.00661651511
Iter: 526 loss: 0.00663179718
Iter: 527 loss: 0.00661049783
Iter: 528 loss: 0.00659806142
Iter: 529 loss: 0.00666121487
Iter: 530 loss: 0.00659606885
Iter: 531 loss: 0.00658573397
Iter: 532 loss: 0.00657646731
Iter: 533 loss: 0.00657374086
Iter: 534 loss: 0.00655731838
Iter: 535 loss: 0.00655425387
Iter: 536 loss: 0.00654325727
Iter: 537 loss: 0.00653022248
Iter: 538 loss: 0.00650587818
Iter: 539 loss: 0.0070567457
Iter: 540 loss: 0.0065058358
Iter: 541 loss: 0.00645514904
Iter: 542 loss: 0.00676498329
Iter: 543 loss: 0.00644924771
Iter: 544 loss: 0.00641915156
Iter: 545 loss: 0.00657625776
Iter: 546 loss: 0.00641416665
Iter: 547 loss: 0.00638852734
Iter: 548 loss: 0.0064401729
Iter: 549 loss: 0.00637781387
Iter: 550 loss: 0.00633364217
Iter: 551 loss: 0.00629178435
Iter: 552 loss: 0.00628148299
Iter: 553 loss: 0.00622977177
Iter: 554 loss: 0.00619801553
Iter: 555 loss: 0.00617671432
Iter: 556 loss: 0.00612571696
Iter: 557 loss: 0.00612332765
Iter: 558 loss: 0.00609711371
Iter: 559 loss: 0.00627815351
Iter: 560 loss: 0.00609482545
Iter: 561 loss: 0.0060813562
Iter: 562 loss: 0.0060461536
Iter: 563 loss: 0.006345951
Iter: 564 loss: 0.00603960548
Iter: 565 loss: 0.005991254
Iter: 566 loss: 0.00656301389
Iter: 567 loss: 0.00599054666
Iter: 568 loss: 0.0059686536
Iter: 569 loss: 0.00596768595
Iter: 570 loss: 0.00595631078
Iter: 571 loss: 0.00592937041
Iter: 572 loss: 0.00624483
Iter: 573 loss: 0.00592692848
Iter: 574 loss: 0.00587798748
Iter: 575 loss: 0.00605493318
Iter: 576 loss: 0.00586572383
Iter: 577 loss: 0.00582570443
Iter: 578 loss: 0.00580994692
Iter: 579 loss: 0.00578799844
Iter: 580 loss: 0.00574108586
Iter: 581 loss: 0.00593157113
Iter: 582 loss: 0.00573013164
Iter: 583 loss: 0.005691492
Iter: 584 loss: 0.0060746097
Iter: 585 loss: 0.00569011504
Iter: 586 loss: 0.00566267036
Iter: 587 loss: 0.00569866318
Iter: 588 loss: 0.00564811
Iter: 589 loss: 0.00566031784
Iter: 590 loss: 0.00563188083
Iter: 591 loss: 0.00563547341
Iter: 592 loss: 0.00562386494
Iter: 593 loss: 0.00562088564
Iter: 594 loss: 0.00561701693
Iter: 595 loss: 0.00561675336
Iter: 596 loss: 0.00560017303
Iter: 597 loss: 0.00573725626
Iter: 598 loss: 0.00559926312
Iter: 599 loss: 0.00558268465
Iter: 600 loss: 0.00573260384
Iter: 601 loss: 0.00558178686
Iter: 602 loss: 0.00556383934
Iter: 603 loss: 0.00553478673
Iter: 604 loss: 0.00553454831
Iter: 605 loss: 0.00549952965
Iter: 606 loss: 0.00546443462
Iter: 607 loss: 0.00545711955
Iter: 608 loss: 0.00539893564
Iter: 609 loss: 0.00573131628
Iter: 610 loss: 0.00538973
Iter: 611 loss: 0.00536717288
Iter: 612 loss: 0.00551144918
Iter: 613 loss: 0.00536445109
Iter: 614 loss: 0.00534571707
Iter: 615 loss: 0.00541152526
Iter: 616 loss: 0.00534085743
Iter: 617 loss: 0.00531497831
Iter: 618 loss: 0.00535478955
Iter: 619 loss: 0.00530258333
Iter: 620 loss: 0.00527676381
Iter: 621 loss: 0.00527641643
Iter: 622 loss: 0.00525557436
Iter: 623 loss: 0.00538688106
Iter: 624 loss: 0.00524737127
Iter: 625 loss: 0.00524164643
Iter: 626 loss: 0.0052268533
Iter: 627 loss: 0.00534179
Iter: 628 loss: 0.00522413198
Iter: 629 loss: 0.00519223697
Iter: 630 loss: 0.00533389673
Iter: 631 loss: 0.005185619
Iter: 632 loss: 0.00518238405
Iter: 633 loss: 0.00516487518
Iter: 634 loss: 0.00514840474
Iter: 635 loss: 0.00513304211
Iter: 636 loss: 0.0051288968
Iter: 637 loss: 0.00511262566
Iter: 638 loss: 0.0051243864
Iter: 639 loss: 0.00510239229
Iter: 640 loss: 0.00505096
Iter: 641 loss: 0.00557689136
Iter: 642 loss: 0.00504849805
Iter: 643 loss: 0.00502104964
Iter: 644 loss: 0.00501778256
Iter: 645 loss: 0.00499784714
Iter: 646 loss: 0.00497903
Iter: 647 loss: 0.00497202063
Iter: 648 loss: 0.00496153906
Iter: 649 loss: 0.00494110957
Iter: 650 loss: 0.00491859298
Iter: 651 loss: 0.00491525419
Iter: 652 loss: 0.00487492094
Iter: 653 loss: 0.00544047
Iter: 654 loss: 0.00487483107
Iter: 655 loss: 0.00488306
Iter: 656 loss: 0.00486419862
Iter: 657 loss: 0.00485117873
Iter: 658 loss: 0.004864302
Iter: 659 loss: 0.00484387
Iter: 660 loss: 0.00483096624
Iter: 661 loss: 0.00484138075
Iter: 662 loss: 0.00482306164
Iter: 663 loss: 0.00481316447
Iter: 664 loss: 0.00484732026
Iter: 665 loss: 0.00481062941
Iter: 666 loss: 0.00479797507
Iter: 667 loss: 0.00485509
Iter: 668 loss: 0.00479534408
Iter: 669 loss: 0.00479086768
Iter: 670 loss: 0.00478305202
Iter: 671 loss: 0.00478305807
Iter: 672 loss: 0.00477158092
Iter: 673 loss: 0.00475753797
Iter: 674 loss: 0.00475622527
Iter: 675 loss: 0.00473712105
Iter: 676 loss: 0.00469819875
Iter: 677 loss: 0.00550257554
Iter: 678 loss: 0.00469764369
Iter: 679 loss: 0.0046979459
Iter: 680 loss: 0.00468093622
Iter: 681 loss: 0.00465417281
Iter: 682 loss: 0.00487849442
Iter: 683 loss: 0.0046525849
Iter: 684 loss: 0.00463632541
Iter: 685 loss: 0.00463155052
Iter: 686 loss: 0.00462158583
Iter: 687 loss: 0.0046072728
Iter: 688 loss: 0.00471672788
Iter: 689 loss: 0.00460619479
Iter: 690 loss: 0.00459113298
Iter: 691 loss: 0.00460281549
Iter: 692 loss: 0.00458193291
Iter: 693 loss: 0.00457051117
Iter: 694 loss: 0.00455994578
Iter: 695 loss: 0.00455706567
Iter: 696 loss: 0.00454133
Iter: 697 loss: 0.00454065716
Iter: 698 loss: 0.00452867756
Iter: 699 loss: 0.00451807212
Iter: 700 loss: 0.00454505347
Iter: 701 loss: 0.00451437384
Iter: 702 loss: 0.00450275838
Iter: 703 loss: 0.00449019857
Iter: 704 loss: 0.00448821113
Iter: 705 loss: 0.00446965
Iter: 706 loss: 0.00468230387
Iter: 707 loss: 0.0044691721
Iter: 708 loss: 0.0044448385
Iter: 709 loss: 0.00463041477
Iter: 710 loss: 0.00444308389
Iter: 711 loss: 0.00443843845
Iter: 712 loss: 0.00443054363
Iter: 713 loss: 0.00443053292
Iter: 714 loss: 0.00441650674
Iter: 715 loss: 0.00442170445
Iter: 716 loss: 0.00440661283
Iter: 717 loss: 0.00439056475
Iter: 718 loss: 0.00442111259
Iter: 719 loss: 0.00438369857
Iter: 720 loss: 0.00437075179
Iter: 721 loss: 0.0044252621
Iter: 722 loss: 0.00436795224
Iter: 723 loss: 0.00436386093
Iter: 724 loss: 0.00436207559
Iter: 725 loss: 0.00435846625
Iter: 726 loss: 0.0043497039
Iter: 727 loss: 0.00443793
Iter: 728 loss: 0.00434871577
Iter: 729 loss: 0.0043378165
Iter: 730 loss: 0.00450657262
Iter: 731 loss: 0.00433780532
Iter: 732 loss: 0.00433361158
Iter: 733 loss: 0.00434031337
Iter: 734 loss: 0.00433166558
Iter: 735 loss: 0.00432078401
Iter: 736 loss: 0.00431015063
Iter: 737 loss: 0.00430779392
Iter: 738 loss: 0.00429189764
Iter: 739 loss: 0.00428935746
Iter: 740 loss: 0.0042805681
Iter: 741 loss: 0.00427947659
Iter: 742 loss: 0.00427502
Iter: 743 loss: 0.00426762225
Iter: 744 loss: 0.00426758407
Iter: 745 loss: 0.00425696513
Iter: 746 loss: 0.00425354764
Iter: 747 loss: 0.00424732221
Iter: 748 loss: 0.00423665065
Iter: 749 loss: 0.00429992145
Iter: 750 loss: 0.00423530303
Iter: 751 loss: 0.00422838423
Iter: 752 loss: 0.00422543846
Iter: 753 loss: 0.00422182633
Iter: 754 loss: 0.00421365909
Iter: 755 loss: 0.00430851802
Iter: 756 loss: 0.00421350356
Iter: 757 loss: 0.00420736801
Iter: 758 loss: 0.00420799199
Iter: 759 loss: 0.004202615
Iter: 760 loss: 0.0041974429
Iter: 761 loss: 0.00419743918
Iter: 762 loss: 0.00419419119
Iter: 763 loss: 0.00418828474
Iter: 764 loss: 0.00433419
Iter: 765 loss: 0.00418828195
Iter: 766 loss: 0.0041839974
Iter: 767 loss: 0.00418041367
Iter: 768 loss: 0.00417919457
Iter: 769 loss: 0.00416329689
Iter: 770 loss: 0.004236056
Iter: 771 loss: 0.00416026
Iter: 772 loss: 0.0041745659
Iter: 773 loss: 0.00415268913
Iter: 774 loss: 0.00414740574
Iter: 775 loss: 0.00414157705
Iter: 776 loss: 0.00414072489
Iter: 777 loss: 0.00413241377
Iter: 778 loss: 0.00412959605
Iter: 779 loss: 0.00412483467
Iter: 780 loss: 0.00411974546
Iter: 781 loss: 0.00411127415
Iter: 782 loss: 0.00411124527
Iter: 783 loss: 0.00410276512
Iter: 784 loss: 0.00411330443
Iter: 785 loss: 0.00409838185
Iter: 786 loss: 0.00409442559
Iter: 787 loss: 0.00409307051
Iter: 788 loss: 0.00409081578
Iter: 789 loss: 0.00408520363
Iter: 790 loss: 0.00408494938
Iter: 791 loss: 0.00408061408
Iter: 792 loss: 0.00413274625
Iter: 793 loss: 0.00407753326
Iter: 794 loss: 0.00407382939
Iter: 795 loss: 0.00406721141
Iter: 796 loss: 0.00422942592
Iter: 797 loss: 0.00406721234
Iter: 798 loss: 0.00405653333
Iter: 799 loss: 0.004052734
Iter: 800 loss: 0.00404675864
Iter: 801 loss: 0.00404997543
Iter: 802 loss: 0.00403482839
Iter: 803 loss: 0.00402348954
Iter: 804 loss: 0.00402687863
Iter: 805 loss: 0.00401531812
Iter: 806 loss: 0.00400814321
Iter: 807 loss: 0.00410685129
Iter: 808 loss: 0.00400812319
Iter: 809 loss: 0.00400453713
Iter: 810 loss: 0.00399326347
Iter: 811 loss: 0.00401050458
Iter: 812 loss: 0.00398533233
Iter: 813 loss: 0.0039567342
Iter: 814 loss: 0.00395479659
Iter: 815 loss: 0.00394070614
Iter: 816 loss: 0.00409988407
Iter: 817 loss: 0.0039404463
Iter: 818 loss: 0.0039247158
Iter: 819 loss: 0.00398239493
Iter: 820 loss: 0.00392083265
Iter: 821 loss: 0.00391325541
Iter: 822 loss: 0.0039040409
Iter: 823 loss: 0.00390315126
Iter: 824 loss: 0.00389214582
Iter: 825 loss: 0.00388827734
Iter: 826 loss: 0.00388208078
Iter: 827 loss: 0.00387680181
Iter: 828 loss: 0.0038766712
Iter: 829 loss: 0.00387282786
Iter: 830 loss: 0.00387783581
Iter: 831 loss: 0.00387088722
Iter: 832 loss: 0.0038614939
Iter: 833 loss: 0.00384294055
Iter: 834 loss: 0.00421887822
Iter: 835 loss: 0.0038427671
Iter: 836 loss: 0.00382227404
Iter: 837 loss: 0.00398828229
Iter: 838 loss: 0.0038209334
Iter: 839 loss: 0.00384321809
Iter: 840 loss: 0.00381858321
Iter: 841 loss: 0.00381522835
Iter: 842 loss: 0.00380724529
Iter: 843 loss: 0.00390029163
Iter: 844 loss: 0.00380649976
Iter: 845 loss: 0.00379473763
Iter: 846 loss: 0.0038083829
Iter: 847 loss: 0.00378838228
Iter: 848 loss: 0.00376457302
Iter: 849 loss: 0.00385676417
Iter: 850 loss: 0.00375896576
Iter: 851 loss: 0.00376394112
Iter: 852 loss: 0.00374637987
Iter: 853 loss: 0.00374011323
Iter: 854 loss: 0.00373584125
Iter: 855 loss: 0.00373354414
Iter: 856 loss: 0.00372866471
Iter: 857 loss: 0.00373328128
Iter: 858 loss: 0.00372588541
Iter: 859 loss: 0.0037233131
Iter: 860 loss: 0.0037150688
Iter: 861 loss: 0.00372364558
Iter: 862 loss: 0.0037084897
Iter: 863 loss: 0.00369748101
Iter: 864 loss: 0.00374528579
Iter: 865 loss: 0.00369520509
Iter: 866 loss: 0.00370449969
Iter: 867 loss: 0.00368875125
Iter: 868 loss: 0.00367416115
Iter: 869 loss: 0.00365053816
Iter: 870 loss: 0.00365034584
Iter: 871 loss: 0.00368395098
Iter: 872 loss: 0.00364610273
Iter: 873 loss: 0.00364055904
Iter: 874 loss: 0.00363371195
Iter: 875 loss: 0.00363311451
Iter: 876 loss: 0.00361868506
Iter: 877 loss: 0.00361829367
Iter: 878 loss: 0.00360695552
Iter: 879 loss: 0.00359656778
Iter: 880 loss: 0.00374305085
Iter: 881 loss: 0.00359655987
Iter: 882 loss: 0.00359164109
Iter: 883 loss: 0.00364151737
Iter: 884 loss: 0.00359147135
Iter: 885 loss: 0.00358852046
Iter: 886 loss: 0.00358246965
Iter: 887 loss: 0.00369066419
Iter: 888 loss: 0.00358234951
Iter: 889 loss: 0.00358424662
Iter: 890 loss: 0.00357923959
Iter: 891 loss: 0.00357749593
Iter: 892 loss: 0.00357690174
Iter: 893 loss: 0.00357589568
Iter: 894 loss: 0.00356975151
Iter: 895 loss: 0.00356997922
Iter: 896 loss: 0.00356490351
Iter: 897 loss: 0.00355666177
Iter: 898 loss: 0.00356426137
Iter: 899 loss: 0.00355186081
Iter: 900 loss: 0.00354353548
Iter: 901 loss: 0.00367225148
Iter: 902 loss: 0.00354352919
Iter: 903 loss: 0.00354013708
Iter: 904 loss: 0.00354209216
Iter: 905 loss: 0.00353790564
Iter: 906 loss: 0.00353165134
Iter: 907 loss: 0.00353279174
Iter: 908 loss: 0.00352697074
Iter: 909 loss: 0.00352346967
Iter: 910 loss: 0.00351938279
Iter: 911 loss: 0.00351892086
Iter: 912 loss: 0.00351342862
Iter: 913 loss: 0.00352205848
Iter: 914 loss: 0.00351083
Iter: 915 loss: 0.00351137388
Iter: 916 loss: 0.0035076947
Iter: 917 loss: 0.0035055757
Iter: 918 loss: 0.00351240858
Iter: 919 loss: 0.00350498036
Iter: 920 loss: 0.00350348675
Iter: 921 loss: 0.00351006165
Iter: 922 loss: 0.00350318337
Iter: 923 loss: 0.00350078871
Iter: 924 loss: 0.00349395536
Iter: 925 loss: 0.00352718565
Iter: 926 loss: 0.00349157164
Iter: 927 loss: 0.00348251499
Iter: 928 loss: 0.00348620396
Iter: 929 loss: 0.00347624975
Iter: 930 loss: 0.00346918497
Iter: 931 loss: 0.00352391251
Iter: 932 loss: 0.00346864085
Iter: 933 loss: 0.00346378936
Iter: 934 loss: 0.0035134973
Iter: 935 loss: 0.00346365059
Iter: 936 loss: 0.00346133392
Iter: 937 loss: 0.00346127409
Iter: 938 loss: 0.00345887174
Iter: 939 loss: 0.00346518471
Iter: 940 loss: 0.0034580559
Iter: 941 loss: 0.00345653482
Iter: 942 loss: 0.00345230685
Iter: 943 loss: 0.0034753324
Iter: 944 loss: 0.00345102395
Iter: 945 loss: 0.0034461855
Iter: 946 loss: 0.00344570447
Iter: 947 loss: 0.00344529259
Iter: 948 loss: 0.00344333635
Iter: 949 loss: 0.00344156427
Iter: 950 loss: 0.00345348124
Iter: 951 loss: 0.00344138918
Iter: 952 loss: 0.00344006158
Iter: 953 loss: 0.00344056776
Iter: 954 loss: 0.00343912304
Iter: 955 loss: 0.00343629741
Iter: 956 loss: 0.00343412417
Iter: 957 loss: 0.00343322405
Iter: 958 loss: 0.00343156839
Iter: 959 loss: 0.00342819048
Iter: 960 loss: 0.00348943658
Iter: 961 loss: 0.0034281367
Iter: 962 loss: 0.00342393178
Iter: 963 loss: 0.00341560622
Iter: 964 loss: 0.00357371313
Iter: 965 loss: 0.00341552263
Iter: 966 loss: 0.00340887159
Iter: 967 loss: 0.00344426162
Iter: 968 loss: 0.00340780523
Iter: 969 loss: 0.00340552186
Iter: 970 loss: 0.00340334373
Iter: 971 loss: 0.00340283522
Iter: 972 loss: 0.00340252137
Iter: 973 loss: 0.0033999444
Iter: 974 loss: 0.00339725148
Iter: 975 loss: 0.00339785265
Iter: 976 loss: 0.0033952822
Iter: 977 loss: 0.00339278928
Iter: 978 loss: 0.00338783115
Iter: 979 loss: 0.00348188775
Iter: 980 loss: 0.00338777457
Iter: 981 loss: 0.00338261831
Iter: 982 loss: 0.00343309063
Iter: 983 loss: 0.00338241458
Iter: 984 loss: 0.00337945926
Iter: 985 loss: 0.00342097064
Iter: 986 loss: 0.00337944506
Iter: 987 loss: 0.00337774539
Iter: 988 loss: 0.00339645566
Iter: 989 loss: 0.00337771676
Iter: 990 loss: 0.00337615097
Iter: 991 loss: 0.00337494444
Iter: 992 loss: 0.00337444432
Iter: 993 loss: 0.00337086199
Iter: 994 loss: 0.00336737046
Iter: 995 loss: 0.00336660817
Iter: 996 loss: 0.00336340675
Iter: 997 loss: 0.00336421956
Iter: 998 loss: 0.00336106308
Iter: 999 loss: 0.00335518667
Iter: 1000 loss: 0.00335511519
Iter: 1001 loss: 0.00335305859
Iter: 1002 loss: 0.00334849954
Iter: 1003 loss: 0.00341595639
Iter: 1004 loss: 0.00334827323
Iter: 1005 loss: 0.00334720733
Iter: 1006 loss: 0.00334610185
Iter: 1007 loss: 0.00334433839
Iter: 1008 loss: 0.00334824016
Iter: 1009 loss: 0.00334367692
Iter: 1010 loss: 0.00334046944
Iter: 1011 loss: 0.00335096195
Iter: 1012 loss: 0.00333956722
Iter: 1013 loss: 0.00333603518
Iter: 1014 loss: 0.00333603169
Iter: 1015 loss: 0.00333458791
Iter: 1016 loss: 0.00334163546
Iter: 1017 loss: 0.00333434134
Iter: 1018 loss: 0.00333320862
Iter: 1019 loss: 0.00334212277
Iter: 1020 loss: 0.0033331241
Iter: 1021 loss: 0.00333182374
Iter: 1022 loss: 0.00333024212
Iter: 1023 loss: 0.00333007751
Iter: 1024 loss: 0.00332771474
Iter: 1025 loss: 0.00332857063
Iter: 1026 loss: 0.00332604349
Iter: 1027 loss: 0.00332195032
Iter: 1028 loss: 0.00330952019
Iter: 1029 loss: 0.00334218331
Iter: 1030 loss: 0.00330273295
Iter: 1031 loss: 0.00329775526
Iter: 1032 loss: 0.00329670496
Iter: 1033 loss: 0.00328911887
Iter: 1034 loss: 0.0033141044
Iter: 1035 loss: 0.00328700198
Iter: 1036 loss: 0.00328495586
Iter: 1037 loss: 0.0032872837
Iter: 1038 loss: 0.00328384596
Iter: 1039 loss: 0.00328154117
Iter: 1040 loss: 0.00328511512
Iter: 1041 loss: 0.00328046666
Iter: 1042 loss: 0.00327773159
Iter: 1043 loss: 0.00327232317
Iter: 1044 loss: 0.00337849394
Iter: 1045 loss: 0.00327228103
Iter: 1046 loss: 0.0032640826
Iter: 1047 loss: 0.00330422679
Iter: 1048 loss: 0.00326262671
Iter: 1049 loss: 0.00325822039
Iter: 1050 loss: 0.00331593608
Iter: 1051 loss: 0.00325818709
Iter: 1052 loss: 0.00325877266
Iter: 1053 loss: 0.00325738895
Iter: 1054 loss: 0.00325670885
Iter: 1055 loss: 0.00325503619
Iter: 1056 loss: 0.00327211828
Iter: 1057 loss: 0.00325482362
Iter: 1058 loss: 0.00325260265
Iter: 1059 loss: 0.00324620446
Iter: 1060 loss: 0.00327508571
Iter: 1061 loss: 0.00324380514
Iter: 1062 loss: 0.00323831826
Iter: 1063 loss: 0.00331655215
Iter: 1064 loss: 0.00323829893
Iter: 1065 loss: 0.00323336665
Iter: 1066 loss: 0.00324856094
Iter: 1067 loss: 0.00323189981
Iter: 1068 loss: 0.00323260785
Iter: 1069 loss: 0.00322919851
Iter: 1070 loss: 0.00322699128
Iter: 1071 loss: 0.00323547423
Iter: 1072 loss: 0.00322647858
Iter: 1073 loss: 0.00322506321
Iter: 1074 loss: 0.00322003686
Iter: 1075 loss: 0.00321044913
Iter: 1076 loss: 0.00321023469
Iter: 1077 loss: 0.00320401136
Iter: 1078 loss: 0.00319612212
Iter: 1079 loss: 0.00319552654
Iter: 1080 loss: 0.00319096912
Iter: 1081 loss: 0.00319084898
Iter: 1082 loss: 0.00318637118
Iter: 1083 loss: 0.00321578607
Iter: 1084 loss: 0.00318591949
Iter: 1085 loss: 0.00318375416
Iter: 1086 loss: 0.00317972293
Iter: 1087 loss: 0.0032700072
Iter: 1088 loss: 0.00317971013
Iter: 1089 loss: 0.00332226115
Iter: 1090 loss: 0.00317837344
Iter: 1091 loss: 0.0031776207
Iter: 1092 loss: 0.00317889056
Iter: 1093 loss: 0.00317727821
Iter: 1094 loss: 0.00317652384
Iter: 1095 loss: 0.00317462347
Iter: 1096 loss: 0.00319057936
Iter: 1097 loss: 0.00317429588
Iter: 1098 loss: 0.0031721429
Iter: 1099 loss: 0.00316894357
Iter: 1100 loss: 0.00316887163
Iter: 1101 loss: 0.00316534238
Iter: 1102 loss: 0.00316212419
Iter: 1103 loss: 0.00316124689
Iter: 1104 loss: 0.0031569479
Iter: 1105 loss: 0.00317857461
Iter: 1106 loss: 0.0031562373
Iter: 1107 loss: 0.00315348571
Iter: 1108 loss: 0.00314784306
Iter: 1109 loss: 0.00324834161
Iter: 1110 loss: 0.00314772921
Iter: 1111 loss: 0.00314365863
Iter: 1112 loss: 0.00314360857
Iter: 1113 loss: 0.0031374516
Iter: 1114 loss: 0.00314982771
Iter: 1115 loss: 0.00313490536
Iter: 1116 loss: 0.00313081359
Iter: 1117 loss: 0.0031307051
Iter: 1118 loss: 0.00312743196
Iter: 1119 loss: 0.00312234694
Iter: 1120 loss: 0.0031222757
Iter: 1121 loss: 0.00311966939
Iter: 1122 loss: 0.00312742055
Iter: 1123 loss: 0.00311889173
Iter: 1124 loss: 0.00311712548
Iter: 1125 loss: 0.00311223022
Iter: 1126 loss: 0.00313886465
Iter: 1127 loss: 0.00311075849
Iter: 1128 loss: 0.00310577336
Iter: 1129 loss: 0.00311394106
Iter: 1130 loss: 0.00310347136
Iter: 1131 loss: 0.00309904572
Iter: 1132 loss: 0.00310047809
Iter: 1133 loss: 0.00309590809
Iter: 1134 loss: 0.00309294602
Iter: 1135 loss: 0.00309221726
Iter: 1136 loss: 0.00309009757
Iter: 1137 loss: 0.00308438949
Iter: 1138 loss: 0.00312338118
Iter: 1139 loss: 0.00308307214
Iter: 1140 loss: 0.00307527394
Iter: 1141 loss: 0.00315054599
Iter: 1142 loss: 0.00307496754
Iter: 1143 loss: 0.00307132583
Iter: 1144 loss: 0.00309449527
Iter: 1145 loss: 0.00307092024
Iter: 1146 loss: 0.00306542241
Iter: 1147 loss: 0.00307098404
Iter: 1148 loss: 0.00306235813
Iter: 1149 loss: 0.00305919861
Iter: 1150 loss: 0.00307372212
Iter: 1151 loss: 0.00305859
Iter: 1152 loss: 0.00305820489
Iter: 1153 loss: 0.00305682933
Iter: 1154 loss: 0.0030534782
Iter: 1155 loss: 0.00312580587
Iter: 1156 loss: 0.00305347
Iter: 1157 loss: 0.00311032892
Iter: 1158 loss: 0.00305192987
Iter: 1159 loss: 0.00304926233
Iter: 1160 loss: 0.00305873272
Iter: 1161 loss: 0.00304856873
Iter: 1162 loss: 0.00304447114
Iter: 1163 loss: 0.00308199855
Iter: 1164 loss: 0.00304427557
Iter: 1165 loss: 0.00303964177
Iter: 1166 loss: 0.00304382108
Iter: 1167 loss: 0.0030369428
Iter: 1168 loss: 0.00303151552
Iter: 1169 loss: 0.00302377203
Iter: 1170 loss: 0.00302351499
Iter: 1171 loss: 0.00302456669
Iter: 1172 loss: 0.00302067702
Iter: 1173 loss: 0.00301922904
Iter: 1174 loss: 0.00302155828
Iter: 1175 loss: 0.00301855523
Iter: 1176 loss: 0.00301467767
Iter: 1177 loss: 0.00300468
Iter: 1178 loss: 0.00308624119
Iter: 1179 loss: 0.00300286524
Iter: 1180 loss: 0.00299394154
Iter: 1181 loss: 0.003034672
Iter: 1182 loss: 0.00299221138
Iter: 1183 loss: 0.00304650981
Iter: 1184 loss: 0.0029899755
Iter: 1185 loss: 0.00298921834
Iter: 1186 loss: 0.00298696244
Iter: 1187 loss: 0.00299469428
Iter: 1188 loss: 0.00298590399
Iter: 1189 loss: 0.00298367906
Iter: 1190 loss: 0.0029916116
Iter: 1191 loss: 0.00298312469
Iter: 1192 loss: 0.00298216613
Iter: 1193 loss: 0.00298128836
Iter: 1194 loss: 0.00298105739
Iter: 1195 loss: 0.00297665549
Iter: 1196 loss: 0.00302805519
Iter: 1197 loss: 0.00297659962
Iter: 1198 loss: 0.00297314906
Iter: 1199 loss: 0.00297739776
Iter: 1200 loss: 0.00297135022
Iter: 1201 loss: 0.00296795112
Iter: 1202 loss: 0.00299958093
Iter: 1203 loss: 0.00296780793
Iter: 1204 loss: 0.00296605052
Iter: 1205 loss: 0.00298193982
Iter: 1206 loss: 0.00296597625
Iter: 1207 loss: 0.00296364306
Iter: 1208 loss: 0.00296346284
Iter: 1209 loss: 0.00296172383
Iter: 1210 loss: 0.00295959134
Iter: 1211 loss: 0.00295703067
Iter: 1212 loss: 0.00295677106
Iter: 1213 loss: 0.00295451377
Iter: 1214 loss: 0.00295823184
Iter: 1215 loss: 0.00295350188
Iter: 1216 loss: 0.00295509398
Iter: 1217 loss: 0.00295190327
Iter: 1218 loss: 0.00295073213
Iter: 1219 loss: 0.00294886483
Iter: 1220 loss: 0.00294884737
Iter: 1221 loss: 0.00294523756
Iter: 1222 loss: 0.00295289955
Iter: 1223 loss: 0.00294380449
Iter: 1224 loss: 0.0029430259
Iter: 1225 loss: 0.00294221845
Iter: 1226 loss: 0.00294207106
Iter: 1227 loss: 0.00293883169
Iter: 1228 loss: 0.00293914322
Iter: 1229 loss: 0.00293632504
Iter: 1230 loss: 0.00293243723
Iter: 1231 loss: 0.00295161898
Iter: 1232 loss: 0.00293179112
Iter: 1233 loss: 0.00293023093
Iter: 1234 loss: 0.00293232617
Iter: 1235 loss: 0.00292944163
Iter: 1236 loss: 0.0029277117
Iter: 1237 loss: 0.00292668305
Iter: 1238 loss: 0.00292594964
Iter: 1239 loss: 0.00292353029
Iter: 1240 loss: 0.0029479498
Iter: 1241 loss: 0.00292345276
Iter: 1242 loss: 0.00292118033
Iter: 1243 loss: 0.00294062425
Iter: 1244 loss: 0.00292105367
Iter: 1245 loss: 0.00292044366
Iter: 1246 loss: 0.00291888788
Iter: 1247 loss: 0.00293277041
Iter: 1248 loss: 0.00291865249
Iter: 1249 loss: 0.00291727204
Iter: 1250 loss: 0.00291636493
Iter: 1251 loss: 0.00291409297
Iter: 1252 loss: 0.00293050753
Iter: 1253 loss: 0.0029139095
Iter: 1254 loss: 0.00291294185
Iter: 1255 loss: 0.00291059539
Iter: 1256 loss: 0.00293449
Iter: 1257 loss: 0.00291031599
Iter: 1258 loss: 0.00290801562
Iter: 1259 loss: 0.00291262171
Iter: 1260 loss: 0.00290707755
Iter: 1261 loss: 0.00290385145
Iter: 1262 loss: 0.00291600404
Iter: 1263 loss: 0.00290307263
Iter: 1264 loss: 0.00290056737
Iter: 1265 loss: 0.00292424555
Iter: 1266 loss: 0.00290047191
Iter: 1267 loss: 0.00289789727
Iter: 1268 loss: 0.00289397803
Iter: 1269 loss: 0.00289390702
Iter: 1270 loss: 0.0028910609
Iter: 1271 loss: 0.0028910574
Iter: 1272 loss: 0.00288957777
Iter: 1273 loss: 0.00288968813
Iter: 1274 loss: 0.00288842362
Iter: 1275 loss: 0.00288548274
Iter: 1276 loss: 0.00288775284
Iter: 1277 loss: 0.00288371323
Iter: 1278 loss: 0.00288077118
Iter: 1279 loss: 0.00288060494
Iter: 1280 loss: 0.00288008526
Iter: 1281 loss: 0.00287832599
Iter: 1282 loss: 0.0028772
Iter: 1283 loss: 0.00287611852
Iter: 1284 loss: 0.00288927788
Iter: 1285 loss: 0.00287487055
Iter: 1286 loss: 0.00287394
Iter: 1287 loss: 0.00288099097
Iter: 1288 loss: 0.00287386682
Iter: 1289 loss: 0.00287283259
Iter: 1290 loss: 0.00287404284
Iter: 1291 loss: 0.00287227705
Iter: 1292 loss: 0.00287066773
Iter: 1293 loss: 0.0028681769
Iter: 1294 loss: 0.00286813895
Iter: 1295 loss: 0.0028640884
Iter: 1296 loss: 0.00290361536
Iter: 1297 loss: 0.00286393426
Iter: 1298 loss: 0.00286161504
Iter: 1299 loss: 0.00288402801
Iter: 1300 loss: 0.00286152633
Iter: 1301 loss: 0.00286024273
Iter: 1302 loss: 0.00286586327
Iter: 1303 loss: 0.00285997614
Iter: 1304 loss: 0.00285842922
Iter: 1305 loss: 0.00285799033
Iter: 1306 loss: 0.00285704457
Iter: 1307 loss: 0.00285526
Iter: 1308 loss: 0.00285807671
Iter: 1309 loss: 0.00285443035
Iter: 1310 loss: 0.00285280263
Iter: 1311 loss: 0.00286736479
Iter: 1312 loss: 0.00285272812
Iter: 1313 loss: 0.00285143172
Iter: 1314 loss: 0.00285143801
Iter: 1315 loss: 0.00285108015
Iter: 1316 loss: 0.00285042333
Iter: 1317 loss: 0.00286462484
Iter: 1318 loss: 0.00285041472
Iter: 1319 loss: 0.00284871971
Iter: 1320 loss: 0.0028492026
Iter: 1321 loss: 0.00284749386
Iter: 1322 loss: 0.0028464871
Iter: 1323 loss: 0.00284400862
Iter: 1324 loss: 0.00286871102
Iter: 1325 loss: 0.00284370128
Iter: 1326 loss: 0.00284217857
Iter: 1327 loss: 0.00284384517
Iter: 1328 loss: 0.00284135598
Iter: 1329 loss: 0.00284051709
Iter: 1330 loss: 0.00283944095
Iter: 1331 loss: 0.00283936737
Iter: 1332 loss: 0.00283838902
Iter: 1333 loss: 0.00283664651
Iter: 1334 loss: 0.00288057327
Iter: 1335 loss: 0.00283665187
Iter: 1336 loss: 0.00283503579
Iter: 1337 loss: 0.00283565186
Iter: 1338 loss: 0.00283391657
Iter: 1339 loss: 0.00283159851
Iter: 1340 loss: 0.00283694873
Iter: 1341 loss: 0.00283074565
Iter: 1342 loss: 0.00282934587
Iter: 1343 loss: 0.00282924017
Iter: 1344 loss: 0.00282787066
Iter: 1345 loss: 0.00282433839
Iter: 1346 loss: 0.00285369088
Iter: 1347 loss: 0.00282372
Iter: 1348 loss: 0.00282135326
Iter: 1349 loss: 0.00283152191
Iter: 1350 loss: 0.00282087014
Iter: 1351 loss: 0.00282054348
Iter: 1352 loss: 0.00282032508
Iter: 1353 loss: 0.00281979376
Iter: 1354 loss: 0.0028190515
Iter: 1355 loss: 0.00281902216
Iter: 1356 loss: 0.00281792763
Iter: 1357 loss: 0.0028181076
Iter: 1358 loss: 0.00281709619
Iter: 1359 loss: 0.00281570223
Iter: 1360 loss: 0.00282050762
Iter: 1361 loss: 0.00281533366
Iter: 1362 loss: 0.00281393854
Iter: 1363 loss: 0.00281394273
Iter: 1364 loss: 0.00281329523
Iter: 1365 loss: 0.00281191291
Iter: 1366 loss: 0.00283414847
Iter: 1367 loss: 0.00281186961
Iter: 1368 loss: 0.00280989311
Iter: 1369 loss: 0.00281044166
Iter: 1370 loss: 0.00280846842
Iter: 1371 loss: 0.00280679297
Iter: 1372 loss: 0.0028030097
Iter: 1373 loss: 0.00285323686
Iter: 1374 loss: 0.00280279154
Iter: 1375 loss: 0.00279744063
Iter: 1376 loss: 0.00280403672
Iter: 1377 loss: 0.00279466156
Iter: 1378 loss: 0.00279594748
Iter: 1379 loss: 0.00279272371
Iter: 1380 loss: 0.00279109948
Iter: 1381 loss: 0.00280219712
Iter: 1382 loss: 0.00279093557
Iter: 1383 loss: 0.00279020751
Iter: 1384 loss: 0.00279021403
Iter: 1385 loss: 0.00278949318
Iter: 1386 loss: 0.00278870971
Iter: 1387 loss: 0.00278859306
Iter: 1388 loss: 0.00278747175
Iter: 1389 loss: 0.0027876161
Iter: 1390 loss: 0.00278662192
Iter: 1391 loss: 0.00278520794
Iter: 1392 loss: 0.00279289111
Iter: 1393 loss: 0.00278499397
Iter: 1394 loss: 0.00278392062
Iter: 1395 loss: 0.00278391014
Iter: 1396 loss: 0.00278324541
Iter: 1397 loss: 0.00278145447
Iter: 1398 loss: 0.00279405527
Iter: 1399 loss: 0.00278105284
Iter: 1400 loss: 0.00277888821
Iter: 1401 loss: 0.00280034542
Iter: 1402 loss: 0.00277882116
Iter: 1403 loss: 0.00277780928
Iter: 1404 loss: 0.00277550588
Iter: 1405 loss: 0.00280515663
Iter: 1406 loss: 0.00277535385
Iter: 1407 loss: 0.00277291425
Iter: 1408 loss: 0.00277960417
Iter: 1409 loss: 0.00277210353
Iter: 1410 loss: 0.00276985415
Iter: 1411 loss: 0.00277027627
Iter: 1412 loss: 0.00276816823
Iter: 1413 loss: 0.00277298363
Iter: 1414 loss: 0.00276718894
Iter: 1415 loss: 0.00276679965
Iter: 1416 loss: 0.00277057616
Iter: 1417 loss: 0.00276678777
Iter: 1418 loss: 0.00276642293
Iter: 1419 loss: 0.00276554446
Iter: 1420 loss: 0.00277492707
Iter: 1421 loss: 0.0027654469
Iter: 1422 loss: 0.00276410417
Iter: 1423 loss: 0.00276413513
Iter: 1424 loss: 0.00276304176
Iter: 1425 loss: 0.00276128389
Iter: 1426 loss: 0.00276124477
Iter: 1427 loss: 0.0027596252
Iter: 1428 loss: 0.00275962939
Iter: 1429 loss: 0.0027587798
Iter: 1430 loss: 0.0027567884
Iter: 1431 loss: 0.00278061279
Iter: 1432 loss: 0.00275662239
Iter: 1433 loss: 0.002754068
Iter: 1434 loss: 0.00275389152
Iter: 1435 loss: 0.00275199208
Iter: 1436 loss: 0.00275023025
Iter: 1437 loss: 0.00274770777
Iter: 1438 loss: 0.00274763163
Iter: 1439 loss: 0.00274512125
Iter: 1440 loss: 0.00274229841
Iter: 1441 loss: 0.00274191308
Iter: 1442 loss: 0.00273905275
Iter: 1443 loss: 0.00274464511
Iter: 1444 loss: 0.00273785647
Iter: 1445 loss: 0.00273653446
Iter: 1446 loss: 0.00273230812
Iter: 1447 loss: 0.00273747183
Iter: 1448 loss: 0.00272910926
Iter: 1449 loss: 0.00273160939
Iter: 1450 loss: 0.00272580795
Iter: 1451 loss: 0.0027248126
Iter: 1452 loss: 0.00272486312
Iter: 1453 loss: 0.00272403937
Iter: 1454 loss: 0.00272301119
Iter: 1455 loss: 0.00272410852
Iter: 1456 loss: 0.00272244215
Iter: 1457 loss: 0.00272154226
Iter: 1458 loss: 0.00271993596
Iter: 1459 loss: 0.00271993736
Iter: 1460 loss: 0.00271775667
Iter: 1461 loss: 0.00272101769
Iter: 1462 loss: 0.00271670637
Iter: 1463 loss: 0.00271429564
Iter: 1464 loss: 0.00272242259
Iter: 1465 loss: 0.00271364022
Iter: 1466 loss: 0.00271246256
Iter: 1467 loss: 0.00271214079
Iter: 1468 loss: 0.00271129236
Iter: 1469 loss: 0.00271051237
Iter: 1470 loss: 0.00271030515
Iter: 1471 loss: 0.00270802248
Iter: 1472 loss: 0.0027079985
Iter: 1473 loss: 0.00270673749
Iter: 1474 loss: 0.00270650932
Iter: 1475 loss: 0.00270534283
Iter: 1476 loss: 0.00270650606
Iter: 1477 loss: 0.00270467764
Iter: 1478 loss: 0.00270411512
Iter: 1479 loss: 0.00270399032
Iter: 1480 loss: 0.00270336564
Iter: 1481 loss: 0.00270342617
Iter: 1482 loss: 0.00270288112
Iter: 1483 loss: 0.00270216377
Iter: 1484 loss: 0.00270110043
Iter: 1485 loss: 0.00270107668
Iter: 1486 loss: 0.00269865524
Iter: 1487 loss: 0.00271009235
Iter: 1488 loss: 0.00269821263
Iter: 1489 loss: 0.00269733882
Iter: 1490 loss: 0.00269742124
Iter: 1491 loss: 0.00269665779
Iter: 1492 loss: 0.00269570109
Iter: 1493 loss: 0.00269299
Iter: 1494 loss: 0.00270670559
Iter: 1495 loss: 0.00269209337
Iter: 1496 loss: 0.0027009917
Iter: 1497 loss: 0.00269157882
Iter: 1498 loss: 0.00269110501
Iter: 1499 loss: 0.0026915858
Iter: 1500 loss: 0.00269084936
Iter: 1501 loss: 0.0026896554
Iter: 1502 loss: 0.00269237789
Iter: 1503 loss: 0.00268919906
Iter: 1504 loss: 0.00268778158
Iter: 1505 loss: 0.00268773735
Iter: 1506 loss: 0.00268662907
Iter: 1507 loss: 0.00268507213
Iter: 1508 loss: 0.00270512397
Iter: 1509 loss: 0.00268505677
Iter: 1510 loss: 0.00268565537
Iter: 1511 loss: 0.00268454407
Iter: 1512 loss: 0.00268425839
Iter: 1513 loss: 0.00268367445
Iter: 1514 loss: 0.00269417139
Iter: 1515 loss: 0.0026836684
Iter: 1516 loss: 0.00268290564
Iter: 1517 loss: 0.00268204138
Iter: 1518 loss: 0.00268193
Iter: 1519 loss: 0.00268080877
Iter: 1520 loss: 0.00269235787
Iter: 1521 loss: 0.00268077711
Iter: 1522 loss: 0.00267998641
Iter: 1523 loss: 0.00268587423
Iter: 1524 loss: 0.00267992704
Iter: 1525 loss: 0.00267928187
Iter: 1526 loss: 0.00267789676
Iter: 1527 loss: 0.00270028319
Iter: 1528 loss: 0.00267785764
Iter: 1529 loss: 0.00267909118
Iter: 1530 loss: 0.00267752772
Iter: 1531 loss: 0.00267711887
Iter: 1532 loss: 0.00267620012
Iter: 1533 loss: 0.00268852455
Iter: 1534 loss: 0.0026761468
Iter: 1535 loss: 0.00267458241
Iter: 1536 loss: 0.00267630676
Iter: 1537 loss: 0.00267372653
Iter: 1538 loss: 0.00267128833
Iter: 1539 loss: 0.00267386
Iter: 1540 loss: 0.00266994443
Iter: 1541 loss: 0.00266812276
Iter: 1542 loss: 0.00267097121
Iter: 1543 loss: 0.00266726082
Iter: 1544 loss: 0.00266704219
Iter: 1545 loss: 0.00266673
Iter: 1546 loss: 0.00266623264
Iter: 1547 loss: 0.00266535557
Iter: 1548 loss: 0.00268707
Iter: 1549 loss: 0.00266535138
Iter: 1550 loss: 0.0026640608
Iter: 1551 loss: 0.00266324566
Iter: 1552 loss: 0.00266274158
Iter: 1553 loss: 0.00266173552
Iter: 1554 loss: 0.0026616836
Iter: 1555 loss: 0.00266095856
Iter: 1556 loss: 0.00266218791
Iter: 1557 loss: 0.00266063609
Iter: 1558 loss: 0.00265976926
Iter: 1559 loss: 0.00265791593
Iter: 1560 loss: 0.0026874519
Iter: 1561 loss: 0.00265784934
Iter: 1562 loss: 0.00265782792
Iter: 1563 loss: 0.00265715062
Iter: 1564 loss: 0.002656064
Iter: 1565 loss: 0.00265291892
Iter: 1566 loss: 0.00266692485
Iter: 1567 loss: 0.00265174173
Iter: 1568 loss: 0.00264571048
Iter: 1569 loss: 0.00266246521
Iter: 1570 loss: 0.00264373841
Iter: 1571 loss: 0.00264267251
Iter: 1572 loss: 0.00264252629
Iter: 1573 loss: 0.00264164596
Iter: 1574 loss: 0.00264947768
Iter: 1575 loss: 0.00264160265
Iter: 1576 loss: 0.00264169718
Iter: 1577 loss: 0.00264132884
Iter: 1578 loss: 0.00264108321
Iter: 1579 loss: 0.00264055212
Iter: 1580 loss: 0.00264831586
Iter: 1581 loss: 0.0026405286
Iter: 1582 loss: 0.00263982709
Iter: 1583 loss: 0.00263848854
Iter: 1584 loss: 0.00266695721
Iter: 1585 loss: 0.00263848412
Iter: 1586 loss: 0.00263764174
Iter: 1587 loss: 0.00264555775
Iter: 1588 loss: 0.00263761613
Iter: 1589 loss: 0.00263684406
Iter: 1590 loss: 0.00263910601
Iter: 1591 loss: 0.00263660331
Iter: 1592 loss: 0.0026356685
Iter: 1593 loss: 0.00263539026
Iter: 1594 loss: 0.00263482356
Iter: 1595 loss: 0.00263341796
Iter: 1596 loss: 0.0026453156
Iter: 1597 loss: 0.00263334345
Iter: 1598 loss: 0.00263136183
Iter: 1599 loss: 0.00263511296
Iter: 1600 loss: 0.00263051922
Iter: 1601 loss: 0.00262966566
Iter: 1602 loss: 0.00262701418
Iter: 1603 loss: 0.00263280678
Iter: 1604 loss: 0.00262540719
Iter: 1605 loss: 0.00262246653
Iter: 1606 loss: 0.00263288664
Iter: 1607 loss: 0.0026217117
Iter: 1608 loss: 0.00262054522
Iter: 1609 loss: 0.0026201373
Iter: 1610 loss: 0.00261973124
Iter: 1611 loss: 0.00261970842
Iter: 1612 loss: 0.0026192246
Iter: 1613 loss: 0.00261943974
Iter: 1614 loss: 0.00261888909
Iter: 1615 loss: 0.00261828024
Iter: 1616 loss: 0.00261707744
Iter: 1617 loss: 0.00264076283
Iter: 1618 loss: 0.00261707
Iter: 1619 loss: 0.00261564716
Iter: 1620 loss: 0.00261592539
Iter: 1621 loss: 0.0026145943
Iter: 1622 loss: 0.00261265226
Iter: 1623 loss: 0.00261256145
Iter: 1624 loss: 0.00261146412
Iter: 1625 loss: 0.00260791974
Iter: 1626 loss: 0.00261035562
Iter: 1627 loss: 0.00260482496
Iter: 1628 loss: 0.00260454509
Iter: 1629 loss: 0.00260293833
Iter: 1630 loss: 0.00260203844
Iter: 1631 loss: 0.00261229835
Iter: 1632 loss: 0.00260202936
Iter: 1633 loss: 0.00260115089
Iter: 1634 loss: 0.00260041375
Iter: 1635 loss: 0.00260015577
Iter: 1636 loss: 0.00259815902
Iter: 1637 loss: 0.00259694969
Iter: 1638 loss: 0.00259612431
Iter: 1639 loss: 0.00259454525
Iter: 1640 loss: 0.00259754481
Iter: 1641 loss: 0.00259387773
Iter: 1642 loss: 0.00259286212
Iter: 1643 loss: 0.00259285537
Iter: 1644 loss: 0.0025930726
Iter: 1645 loss: 0.00259228423
Iter: 1646 loss: 0.00259207841
Iter: 1647 loss: 0.00259133754
Iter: 1648 loss: 0.00258960924
Iter: 1649 loss: 0.0026301411
Iter: 1650 loss: 0.00258960272
Iter: 1651 loss: 0.00258835219
Iter: 1652 loss: 0.0025883466
Iter: 1653 loss: 0.00258758548
Iter: 1654 loss: 0.00258585578
Iter: 1655 loss: 0.0026086017
Iter: 1656 loss: 0.00258574728
Iter: 1657 loss: 0.00258576591
Iter: 1658 loss: 0.00258519081
Iter: 1659 loss: 0.00258472934
Iter: 1660 loss: 0.00258918083
Iter: 1661 loss: 0.00258471607
Iter: 1662 loss: 0.00258423365
Iter: 1663 loss: 0.00258449558
Iter: 1664 loss: 0.002583917
Iter: 1665 loss: 0.00258303015
Iter: 1666 loss: 0.00258652214
Iter: 1667 loss: 0.00258282293
Iter: 1668 loss: 0.00258204481
Iter: 1669 loss: 0.00258278754
Iter: 1670 loss: 0.00258160383
Iter: 1671 loss: 0.00258116634
Iter: 1672 loss: 0.00257998612
Iter: 1673 loss: 0.00258741761
Iter: 1674 loss: 0.00257967599
Iter: 1675 loss: 0.00257839356
Iter: 1676 loss: 0.00257751532
Iter: 1677 loss: 0.0025770464
Iter: 1678 loss: 0.00257579656
Iter: 1679 loss: 0.00258116052
Iter: 1680 loss: 0.0025755337
Iter: 1681 loss: 0.00257444871
Iter: 1682 loss: 0.00257211365
Iter: 1683 loss: 0.00260737911
Iter: 1684 loss: 0.00257202052
Iter: 1685 loss: 0.00257049175
Iter: 1686 loss: 0.00258368673
Iter: 1687 loss: 0.00257040677
Iter: 1688 loss: 0.00256944913
Iter: 1689 loss: 0.00256908569
Iter: 1690 loss: 0.00256856484
Iter: 1691 loss: 0.0025680114
Iter: 1692 loss: 0.00256799208
Iter: 1693 loss: 0.00256774714
Iter: 1694 loss: 0.00256809196
Iter: 1695 loss: 0.00256761769
Iter: 1696 loss: 0.00256603397
Iter: 1697 loss: 0.00256411219
Iter: 1698 loss: 0.00256392616
Iter: 1699 loss: 0.00257501984
Iter: 1700 loss: 0.00256332895
Iter: 1701 loss: 0.0025625506
Iter: 1702 loss: 0.00256124628
Iter: 1703 loss: 0.00256123673
Iter: 1704 loss: 0.00255955197
Iter: 1705 loss: 0.00256726798
Iter: 1706 loss: 0.00255923672
Iter: 1707 loss: 0.00256303069
Iter: 1708 loss: 0.00255883858
Iter: 1709 loss: 0.00255861063
Iter: 1710 loss: 0.00255841296
Iter: 1711 loss: 0.00255835918
Iter: 1712 loss: 0.00255789072
Iter: 1713 loss: 0.00255721551
Iter: 1714 loss: 0.00255719712
Iter: 1715 loss: 0.00255636685
Iter: 1716 loss: 0.00255696708
Iter: 1717 loss: 0.002555846
Iter: 1718 loss: 0.00255466066
Iter: 1719 loss: 0.0025529922
Iter: 1720 loss: 0.00255292701
Iter: 1721 loss: 0.00255989912
Iter: 1722 loss: 0.0025524376
Iter: 1723 loss: 0.00255197193
Iter: 1724 loss: 0.00255188067
Iter: 1725 loss: 0.00255157286
Iter: 1726 loss: 0.00255042734
Iter: 1727 loss: 0.00254986784
Iter: 1728 loss: 0.00254931976
Iter: 1729 loss: 0.00254619191
Iter: 1730 loss: 0.00255818944
Iter: 1731 loss: 0.00254544266
Iter: 1732 loss: 0.00254404545
Iter: 1733 loss: 0.00254878355
Iter: 1734 loss: 0.0025436664
Iter: 1735 loss: 0.00254328037
Iter: 1736 loss: 0.00254373532
Iter: 1737 loss: 0.00254308106
Iter: 1738 loss: 0.00254287198
Iter: 1739 loss: 0.00254229805
Iter: 1740 loss: 0.00254559191
Iter: 1741 loss: 0.00254214392
Iter: 1742 loss: 0.00254162122
Iter: 1743 loss: 0.00254230923
Iter: 1744 loss: 0.00254134648
Iter: 1745 loss: 0.00254037511
Iter: 1746 loss: 0.00254037138
Iter: 1747 loss: 0.00253889756
Iter: 1748 loss: 0.00253889337
Iter: 1749 loss: 0.00253771967
Iter: 1750 loss: 0.00253549381
Iter: 1751 loss: 0.00254013157
Iter: 1752 loss: 0.00253459811
Iter: 1753 loss: 0.00253362185
Iter: 1754 loss: 0.00253539579
Iter: 1755 loss: 0.00253319927
Iter: 1756 loss: 0.00253289286
Iter: 1757 loss: 0.00253242813
Iter: 1758 loss: 0.00253214641
Iter: 1759 loss: 0.00253173546
Iter: 1760 loss: 0.00253172079
Iter: 1761 loss: 0.00253134663
Iter: 1762 loss: 0.00253053196
Iter: 1763 loss: 0.00254307687
Iter: 1764 loss: 0.00253049936
Iter: 1765 loss: 0.0025294479
Iter: 1766 loss: 0.00253594923
Iter: 1767 loss: 0.00252931984
Iter: 1768 loss: 0.00253304304
Iter: 1769 loss: 0.00252834056
Iter: 1770 loss: 0.00252802833
Iter: 1771 loss: 0.00252877711
Iter: 1772 loss: 0.00252791378
Iter: 1773 loss: 0.00252692122
Iter: 1774 loss: 0.00252425438
Iter: 1775 loss: 0.00254260097
Iter: 1776 loss: 0.0025236411
Iter: 1777 loss: 0.00252579898
Iter: 1778 loss: 0.00252199406
Iter: 1779 loss: 0.00252097333
Iter: 1780 loss: 0.00251971511
Iter: 1781 loss: 0.00251960196
Iter: 1782 loss: 0.00251806038
Iter: 1783 loss: 0.00252316287
Iter: 1784 loss: 0.00251763221
Iter: 1785 loss: 0.00251560472
Iter: 1786 loss: 0.00252804463
Iter: 1787 loss: 0.00251536397
Iter: 1788 loss: 0.00251361076
Iter: 1789 loss: 0.00253355387
Iter: 1790 loss: 0.00251358305
Iter: 1791 loss: 0.00251251017
Iter: 1792 loss: 0.00252612215
Iter: 1793 loss: 0.0025124955
Iter: 1794 loss: 0.00251209526
Iter: 1795 loss: 0.00251090201
Iter: 1796 loss: 0.00251602312
Iter: 1797 loss: 0.00251045031
Iter: 1798 loss: 0.00250915019
Iter: 1799 loss: 0.00252138311
Iter: 1800 loss: 0.0025090985
Iter: 1801 loss: 0.00250842934
Iter: 1802 loss: 0.0025078617
Iter: 1803 loss: 0.00250767218
Iter: 1804 loss: 0.00250593666
Iter: 1805 loss: 0.0025196916
Iter: 1806 loss: 0.00250580208
Iter: 1807 loss: 0.00250534411
Iter: 1808 loss: 0.00250420487
Iter: 1809 loss: 0.00251557259
Iter: 1810 loss: 0.0025040654
Iter: 1811 loss: 0.00250222161
Iter: 1812 loss: 0.00250295177
Iter: 1813 loss: 0.00250094896
Iter: 1814 loss: 0.00249926606
Iter: 1815 loss: 0.00250734319
Iter: 1816 loss: 0.0024989706
Iter: 1817 loss: 0.00249696942
Iter: 1818 loss: 0.00250680279
Iter: 1819 loss: 0.00249661785
Iter: 1820 loss: 0.00249529653
Iter: 1821 loss: 0.00249855686
Iter: 1822 loss: 0.00249482598
Iter: 1823 loss: 0.0024939396
Iter: 1824 loss: 0.00249289908
Iter: 1825 loss: 0.00249277567
Iter: 1826 loss: 0.00249387231
Iter: 1827 loss: 0.00249236
Iter: 1828 loss: 0.00249206834
Iter: 1829 loss: 0.00249188882
Iter: 1830 loss: 0.00249176798
Iter: 1831 loss: 0.0024907724
Iter: 1832 loss: 0.0024981352
Iter: 1833 loss: 0.00249069
Iter: 1834 loss: 0.0024901866
Iter: 1835 loss: 0.00249016797
Iter: 1836 loss: 0.00248989416
Iter: 1837 loss: 0.00248905
Iter: 1838 loss: 0.00249148533
Iter: 1839 loss: 0.00248861616
Iter: 1840 loss: 0.00248796772
Iter: 1841 loss: 0.00248964969
Iter: 1842 loss: 0.00248774374
Iter: 1843 loss: 0.00248730602
Iter: 1844 loss: 0.00248627039
Iter: 1845 loss: 0.00249809306
Iter: 1846 loss: 0.00248618238
Iter: 1847 loss: 0.00248501822
Iter: 1848 loss: 0.00249263365
Iter: 1849 loss: 0.00248489529
Iter: 1850 loss: 0.00248330249
Iter: 1851 loss: 0.00248414814
Iter: 1852 loss: 0.00248225452
Iter: 1853 loss: 0.00248147966
Iter: 1854 loss: 0.0024798587
Iter: 1855 loss: 0.00250763912
Iter: 1856 loss: 0.00247981516
Iter: 1857 loss: 0.00247862516
Iter: 1858 loss: 0.00247985101
Iter: 1859 loss: 0.00247795694
Iter: 1860 loss: 0.00247674529
Iter: 1861 loss: 0.00247874809
Iter: 1862 loss: 0.00247620791
Iter: 1863 loss: 0.00247440906
Iter: 1864 loss: 0.00250293594
Iter: 1865 loss: 0.00247440953
Iter: 1866 loss: 0.00247407472
Iter: 1867 loss: 0.00247308169
Iter: 1868 loss: 0.00247608731
Iter: 1869 loss: 0.00247257878
Iter: 1870 loss: 0.00247145607
Iter: 1871 loss: 0.00247700489
Iter: 1872 loss: 0.00247125607
Iter: 1873 loss: 0.00247101416
Iter: 1874 loss: 0.00247140089
Iter: 1875 loss: 0.00247090217
Iter: 1876 loss: 0.00246989634
Iter: 1877 loss: 0.00247143302
Iter: 1878 loss: 0.00246941671
Iter: 1879 loss: 0.00246847328
Iter: 1880 loss: 0.00247968547
Iter: 1881 loss: 0.0024684621
Iter: 1882 loss: 0.00246766675
Iter: 1883 loss: 0.00246672891
Iter: 1884 loss: 0.00246662856
Iter: 1885 loss: 0.00246636476
Iter: 1886 loss: 0.0024660402
Iter: 1887 loss: 0.0024653431
Iter: 1888 loss: 0.00246465858
Iter: 1889 loss: 0.00246451725
Iter: 1890 loss: 0.0024637226
Iter: 1891 loss: 0.00246329978
Iter: 1892 loss: 0.00246294122
Iter: 1893 loss: 0.00246315426
Iter: 1894 loss: 0.00246234355
Iter: 1895 loss: 0.00246180594
Iter: 1896 loss: 0.00246928516
Iter: 1897 loss: 0.00246181269
Iter: 1898 loss: 0.00246164692
Iter: 1899 loss: 0.00246140617
Iter: 1900 loss: 0.00246139849
Iter: 1901 loss: 0.00246105529
Iter: 1902 loss: 0.00246463204
Iter: 1903 loss: 0.00246104295
Iter: 1904 loss: 0.00246087415
Iter: 1905 loss: 0.00246034609
Iter: 1906 loss: 0.00246099243
Iter: 1907 loss: 0.00245994213
Iter: 1908 loss: 0.00245860568
Iter: 1909 loss: 0.00245736772
Iter: 1910 loss: 0.00245704572
Iter: 1911 loss: 0.00245558587
Iter: 1912 loss: 0.0024527614
Iter: 1913 loss: 0.00251151668
Iter: 1914 loss: 0.00245274487
Iter: 1915 loss: 0.00245031388
Iter: 1916 loss: 0.0024595
Iter: 1917 loss: 0.00244972249
Iter: 1918 loss: 0.00244889827
Iter: 1919 loss: 0.00244876882
Iter: 1920 loss: 0.00244819047
Iter: 1921 loss: 0.00245085149
Iter: 1922 loss: 0.00244808476
Iter: 1923 loss: 0.00244722608
Iter: 1924 loss: 0.00244553317
Iter: 1925 loss: 0.00247914018
Iter: 1926 loss: 0.00244551664
Iter: 1927 loss: 0.00244480232
Iter: 1928 loss: 0.00244477927
Iter: 1929 loss: 0.00244438555
Iter: 1930 loss: 0.00244432618
Iter: 1931 loss: 0.00244414015
Iter: 1932 loss: 0.00244386611
Iter: 1933 loss: 0.00244385796
Iter: 1934 loss: 0.00244344864
Iter: 1935 loss: 0.0024483162
Iter: 1936 loss: 0.00244344119
Iter: 1937 loss: 0.00244318414
Iter: 1938 loss: 0.00244244118
Iter: 1939 loss: 0.00244513876
Iter: 1940 loss: 0.00244211033
Iter: 1941 loss: 0.0024411378
Iter: 1942 loss: 0.00244134921
Iter: 1943 loss: 0.00244041579
Iter: 1944 loss: 0.00243945024
Iter: 1945 loss: 0.00243715849
Iter: 1946 loss: 0.00246263039
Iter: 1947 loss: 0.00243693101
Iter: 1948 loss: 0.00243556313
Iter: 1949 loss: 0.00243592705
Iter: 1950 loss: 0.00243456708
Iter: 1951 loss: 0.00243344461
Iter: 1952 loss: 0.00243559899
Iter: 1953 loss: 0.0024329708
Iter: 1954 loss: 0.00243168464
Iter: 1955 loss: 0.00243951194
Iter: 1956 loss: 0.00243152864
Iter: 1957 loss: 0.00243066158
Iter: 1958 loss: 0.00244174851
Iter: 1959 loss: 0.00243065786
Iter: 1960 loss: 0.00243019359
Iter: 1961 loss: 0.00242910651
Iter: 1962 loss: 0.00244213524
Iter: 1963 loss: 0.00242901803
Iter: 1964 loss: 0.00243643112
Iter: 1965 loss: 0.00242870697
Iter: 1966 loss: 0.00242849672
Iter: 1967 loss: 0.00242858171
Iter: 1968 loss: 0.002428354
Iter: 1969 loss: 0.00242806366
Iter: 1970 loss: 0.00242748717
Iter: 1971 loss: 0.00243865955
Iter: 1972 loss: 0.00242748205
Iter: 1973 loss: 0.0024268073
Iter: 1974 loss: 0.00242557283
Iter: 1975 loss: 0.00245493674
Iter: 1976 loss: 0.0024255733
Iter: 1977 loss: 0.0024242322
Iter: 1978 loss: 0.00244182069
Iter: 1979 loss: 0.00242422707
Iter: 1980 loss: 0.00242328132
Iter: 1981 loss: 0.00242580101
Iter: 1982 loss: 0.00242296187
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8
+ date
Tue Oct 27 20:13:10 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7d2060620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7d2003378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7d2060268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7d1fd61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac6ab510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac6abd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac62b6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac654bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac654840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac5fb378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac5b8a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac576d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac576510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac5217b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac55c950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac5076a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac507ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac4b76a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac4d5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac49c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac427950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac4277b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac403620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac3ae8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac3bc2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac35f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac39d730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac341950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac341a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac2f7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac312f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac2ca158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac2d3620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac26e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac21f9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fb7ac259268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.188161105
Iter: 2 loss: 13.8959427
Iter: 3 loss: 13.8790407
Iter: 4 loss: 8.22098732
Iter: 5 loss: 8.21289253
Iter: 6 loss: 5.15162754
Iter: 7 loss: 5.1461544
Iter: 8 loss: 3.35064
Iter: 9 loss: 3.34684324
Iter: 10 loss: 2.27817965
Iter: 11 loss: 2.27533722
Iter: 12 loss: 1.59380674
Iter: 13 loss: 1.59124517
Iter: 14 loss: 1.12300277
Iter: 15 loss: 1.12050831
Iter: 16 loss: 0.790359
Iter: 17 loss: 0.787746
Iter: 18 loss: 0.542042553
Iter: 19 loss: 0.539019227
Iter: 20 loss: 0.357177824
Iter: 21 loss: 0.354101419
Iter: 22 loss: 0.228739813
Iter: 23 loss: 0.225930139
Iter: 24 loss: 0.145468503
Iter: 25 loss: 0.143444225
Iter: 26 loss: 0.140791953
Iter: 27 loss: 0.1300928
Iter: 28 loss: 0.0810136274
Iter: 29 loss: 384.337036
Iter: 30 loss: 0.0810135156
Iter: 31 loss: 987.657043
Iter: 32 loss: 0.0810112357
Iter: 33 loss: 0.0853074044
Iter: 34 loss: 0.0722502917
Iter: 35 loss: 0.0599974766
Iter: 36 loss: 850.742188
Iter: 37 loss: 0.0599973723
Iter: 38 loss: 0.0521517284
Iter: 39 loss: 0.0521420389
Iter: 40 loss: 0.0479447842
Iter: 41 loss: 0.0479450859
Iter: 42 loss: 0.0448433645
Iter: 43 loss: 0.0386953279
Iter: 44 loss: 10.9784145
Iter: 45 loss: 0.0386950262
Iter: 46 loss: 0.0339728892
Iter: 47 loss: 0.0339381397
Iter: 48 loss: 0.0323334
Iter: 49 loss: 0.0294296555
Iter: 50 loss: 4309.39453
Iter: 51 loss: 0.0294296555
Iter: 52 loss: 0.0277265
Iter: 53 loss: 0.0239111036
Iter: 54 loss: 526.863159
Iter: 55 loss: 0.0326371789
Iter: 56 loss: 0.0238380227
Iter: 57 loss: 0.0208484177
Iter: 58 loss: 0.0321986601
Iter: 59 loss: 0.0201425012
Iter: 60 loss: 0.0176010672
Iter: 61 loss: 0.0197007358
Iter: 62 loss: 0.0162689127
Iter: 63 loss: 0.013625009
Iter: 64 loss: 0.020352751
Iter: 65 loss: 0.0129588936
Iter: 66 loss: 0.0119106639
Iter: 67 loss: 0.0137230605
Iter: 68 loss: 0.0115407687
Iter: 69 loss: 0.0107874023
Iter: 70 loss: 0.0112242401
Iter: 71 loss: 0.0102924956
Iter: 72 loss: 0.00965648796
Iter: 73 loss: 0.0130982585
Iter: 74 loss: 0.00956621952
Iter: 75 loss: 0.00902746432
Iter: 76 loss: 0.0158942733
Iter: 77 loss: 0.00900907256
Iter: 78 loss: 0.00861262903
Iter: 79 loss: 0.0106878933
Iter: 80 loss: 0.00856422
Iter: 81 loss: 0.00824257731
Iter: 82 loss: 0.0134835234
Iter: 83 loss: 0.0082324
Iter: 84 loss: 0.00801668502
Iter: 85 loss: 0.00863274746
Iter: 86 loss: 0.00795787852
Iter: 87 loss: 0.00767571898
Iter: 88 loss: 0.00721182069
Iter: 89 loss: 0.00721105747
Iter: 90 loss: 0.00668976922
Iter: 91 loss: 0.00898701
Iter: 92 loss: 0.00660285261
Iter: 93 loss: 0.00623781141
Iter: 94 loss: 0.00956222787
Iter: 95 loss: 0.00620555691
Iter: 96 loss: 0.00608808
Iter: 97 loss: 0.00591264293
Iter: 98 loss: 0.00590924919
Iter: 99 loss: 0.00557790603
Iter: 100 loss: 0.00837412104
Iter: 101 loss: 0.00555373216
Iter: 102 loss: 0.00534921931
Iter: 103 loss: 0.00631294958
Iter: 104 loss: 0.00532074319
Iter: 105 loss: 0.00517699216
Iter: 106 loss: 0.00505526131
Iter: 107 loss: 0.00501569593
Iter: 108 loss: 0.00487462757
Iter: 109 loss: 0.00498090638
Iter: 110 loss: 0.00478588138
Iter: 111 loss: 0.00466883508
Iter: 112 loss: 0.00540945586
Iter: 113 loss: 0.004659025
Iter: 114 loss: 0.00457232725
Iter: 115 loss: 0.00490045175
Iter: 116 loss: 0.00454874057
Iter: 117 loss: 0.00447257049
Iter: 118 loss: 0.00472888537
Iter: 119 loss: 0.00445398828
Iter: 120 loss: 0.00439990265
Iter: 121 loss: 0.00435213558
Iter: 122 loss: 0.00433841627
Iter: 123 loss: 0.00420309883
Iter: 124 loss: 0.00426707882
Iter: 125 loss: 0.00411258172
Iter: 126 loss: 0.00402456708
Iter: 127 loss: 0.00402296241
Iter: 128 loss: 0.00394874951
Iter: 129 loss: 0.00399195915
Iter: 130 loss: 0.0038998744
Iter: 131 loss: 0.00379244518
Iter: 132 loss: 0.00379240187
Iter: 133 loss: 0.00374984276
Iter: 134 loss: 0.00393175427
Iter: 135 loss: 0.00373957749
Iter: 136 loss: 0.00370923849
Iter: 137 loss: 0.00365606276
Iter: 138 loss: 0.00365605671
Iter: 139 loss: 0.00359787303
Iter: 140 loss: 0.00403491361
Iter: 141 loss: 0.00359387
Iter: 142 loss: 0.00354120973
Iter: 143 loss: 0.00359996711
Iter: 144 loss: 0.00351273362
Iter: 145 loss: 0.00347478408
Iter: 146 loss: 0.00346682779
Iter: 147 loss: 0.00343119632
Iter: 148 loss: 0.0035993557
Iter: 149 loss: 0.003423705
Iter: 150 loss: 0.00340816961
Iter: 151 loss: 0.0033713968
Iter: 152 loss: 0.00380842644
Iter: 153 loss: 0.00336808851
Iter: 154 loss: 0.003314398
Iter: 155 loss: 0.00331381336
Iter: 156 loss: 0.00326997973
Iter: 157 loss: 0.00363210891
Iter: 158 loss: 0.00326752174
Iter: 159 loss: 0.00322426483
Iter: 160 loss: 0.00317587936
Iter: 161 loss: 0.00316916499
Iter: 162 loss: 0.00314745167
Iter: 163 loss: 0.00312811602
Iter: 164 loss: 0.00309489644
Iter: 165 loss: 0.00323505886
Iter: 166 loss: 0.00308706984
Iter: 167 loss: 0.00307320245
Iter: 168 loss: 0.00305673154
Iter: 169 loss: 0.00305502443
Iter: 170 loss: 0.00303029362
Iter: 171 loss: 0.0030369
Iter: 172 loss: 0.00301232701
Iter: 173 loss: 0.00298131118
Iter: 174 loss: 0.00304022571
Iter: 175 loss: 0.00296846335
Iter: 176 loss: 0.0029533105
Iter: 177 loss: 0.00295057963
Iter: 178 loss: 0.00293876184
Iter: 179 loss: 0.00293871877
Iter: 180 loss: 0.0029322179
Iter: 181 loss: 0.00291636866
Iter: 182 loss: 0.00308319577
Iter: 183 loss: 0.00291453861
Iter: 184 loss: 0.0028963217
Iter: 185 loss: 0.00287789037
Iter: 186 loss: 0.00287435274
Iter: 187 loss: 0.00284998352
Iter: 188 loss: 0.00285476865
Iter: 189 loss: 0.00283195684
Iter: 190 loss: 0.00280967285
Iter: 191 loss: 0.00282690022
Iter: 192 loss: 0.00279630441
Iter: 193 loss: 0.00277854945
Iter: 194 loss: 0.00277792872
Iter: 195 loss: 0.0027687049
Iter: 196 loss: 0.00289585092
Iter: 197 loss: 0.00276869559
Iter: 198 loss: 0.00276116282
Iter: 199 loss: 0.0027500859
Iter: 200 loss: 0.00274978089
Iter: 201 loss: 0.00273700827
Iter: 202 loss: 0.0027500086
Iter: 203 loss: 0.00272988295
Iter: 204 loss: 0.00271819602
Iter: 205 loss: 0.00271163788
Iter: 206 loss: 0.00270658266
Iter: 207 loss: 0.00269317371
Iter: 208 loss: 0.00275669922
Iter: 209 loss: 0.00269075669
Iter: 210 loss: 0.00269274763
Iter: 211 loss: 0.00268605188
Iter: 212 loss: 0.00268211961
Iter: 213 loss: 0.00267761666
Iter: 214 loss: 0.00267705042
Iter: 215 loss: 0.00267222058
Iter: 216 loss: 0.00267029
Iter: 217 loss: 0.00266771438
Iter: 218 loss: 0.00266152853
Iter: 219 loss: 0.00268811733
Iter: 220 loss: 0.00266019534
Iter: 221 loss: 0.00265424303
Iter: 222 loss: 0.00267356262
Iter: 223 loss: 0.00265259203
Iter: 224 loss: 0.00264427462
Iter: 225 loss: 0.00265780929
Iter: 226 loss: 0.00264043314
Iter: 227 loss: 0.00263637118
Iter: 228 loss: 0.00263580773
Iter: 229 loss: 0.0026329488
Iter: 230 loss: 0.00263278279
Iter: 231 loss: 0.00263061235
Iter: 232 loss: 0.00262237154
Iter: 233 loss: 0.0026137277
Iter: 234 loss: 0.00261222385
Iter: 235 loss: 0.00260221935
Iter: 236 loss: 0.00265821186
Iter: 237 loss: 0.00260068499
Iter: 238 loss: 0.00259573548
Iter: 239 loss: 0.00259309728
Iter: 240 loss: 0.00259087468
Iter: 241 loss: 0.0025843787
Iter: 242 loss: 0.00260003284
Iter: 243 loss: 0.00258200965
Iter: 244 loss: 0.00258731
Iter: 245 loss: 0.00258049415
Iter: 246 loss: 0.00257912721
Iter: 247 loss: 0.00257519586
Iter: 248 loss: 0.00259295
Iter: 249 loss: 0.00257372344
Iter: 250 loss: 0.00256962422
Iter: 251 loss: 0.00258117216
Iter: 252 loss: 0.00256833131
Iter: 253 loss: 0.00256501418
Iter: 254 loss: 0.00256885588
Iter: 255 loss: 0.00256322743
Iter: 256 loss: 0.00255787326
Iter: 257 loss: 0.00256401813
Iter: 258 loss: 0.00255501363
Iter: 259 loss: 0.00255335798
Iter: 260 loss: 0.00255249185
Iter: 261 loss: 0.00255033118
Iter: 262 loss: 0.00254953839
Iter: 263 loss: 0.00254834606
Iter: 264 loss: 0.00254538353
Iter: 265 loss: 0.0025495959
Iter: 266 loss: 0.00254392065
Iter: 267 loss: 0.00254157814
Iter: 268 loss: 0.00254578143
Iter: 269 loss: 0.00254056603
Iter: 270 loss: 0.00253734132
Iter: 271 loss: 0.00254878402
Iter: 272 loss: 0.00253650779
Iter: 273 loss: 0.00253461022
Iter: 274 loss: 0.00253613107
Iter: 275 loss: 0.00253347168
Iter: 276 loss: 0.00253109587
Iter: 277 loss: 0.00253322441
Iter: 278 loss: 0.00252969842
Iter: 279 loss: 0.00252887188
Iter: 280 loss: 0.00252789375
Iter: 281 loss: 0.00252729794
Iter: 282 loss: 0.00252538943
Iter: 283 loss: 0.00252728187
Iter: 284 loss: 0.00252384925
Iter: 285 loss: 0.0025210029
Iter: 286 loss: 0.00252423249
Iter: 287 loss: 0.00251948065
Iter: 288 loss: 0.00251714699
Iter: 289 loss: 0.00251885
Iter: 290 loss: 0.00251569878
Iter: 291 loss: 0.00251322892
Iter: 292 loss: 0.0025181612
Iter: 293 loss: 0.00251223054
Iter: 294 loss: 0.00250941142
Iter: 295 loss: 0.00250939652
Iter: 296 loss: 0.00250759488
Iter: 297 loss: 0.00250659697
Iter: 298 loss: 0.00250580674
Iter: 299 loss: 0.00250361208
Iter: 300 loss: 0.00250172615
Iter: 301 loss: 0.0025011329
Iter: 302 loss: 0.00249692472
Iter: 303 loss: 0.0025101481
Iter: 304 loss: 0.00249570259
Iter: 305 loss: 0.00249114539
Iter: 306 loss: 0.00251764
Iter: 307 loss: 0.00249051768
Iter: 308 loss: 0.0024852585
Iter: 309 loss: 0.00248357374
Iter: 310 loss: 0.00248050946
Iter: 311 loss: 0.00248045987
Iter: 312 loss: 0.00247731153
Iter: 313 loss: 0.00247525191
Iter: 314 loss: 0.00247268239
Iter: 315 loss: 0.00247247564
Iter: 316 loss: 0.00246983953
Iter: 317 loss: 0.0024763844
Iter: 318 loss: 0.00246890658
Iter: 319 loss: 0.00246569142
Iter: 320 loss: 0.00247210474
Iter: 321 loss: 0.00246438896
Iter: 322 loss: 0.00246105716
Iter: 323 loss: 0.00245747948
Iter: 324 loss: 0.00245690206
Iter: 325 loss: 0.00245232857
Iter: 326 loss: 0.00245230435
Iter: 327 loss: 0.00244886475
Iter: 328 loss: 0.00245424872
Iter: 329 loss: 0.00244723028
Iter: 330 loss: 0.00244290102
Iter: 331 loss: 0.00243953755
Iter: 332 loss: 0.00243816385
Iter: 333 loss: 0.00243067346
Iter: 334 loss: 0.00246021687
Iter: 335 loss: 0.00242895959
Iter: 336 loss: 0.00242413627
Iter: 337 loss: 0.00245148968
Iter: 338 loss: 0.00242348108
Iter: 339 loss: 0.00241939398
Iter: 340 loss: 0.00242350553
Iter: 341 loss: 0.00241706055
Iter: 342 loss: 0.00241472246
Iter: 343 loss: 0.00241468055
Iter: 344 loss: 0.00241233641
Iter: 345 loss: 0.00241276133
Iter: 346 loss: 0.00241056643
Iter: 347 loss: 0.00240852218
Iter: 348 loss: 0.00240562484
Iter: 349 loss: 0.00240552379
Iter: 350 loss: 0.00240139244
Iter: 351 loss: 0.00243331888
Iter: 352 loss: 0.00240107672
Iter: 353 loss: 0.00239730161
Iter: 354 loss: 0.00240074238
Iter: 355 loss: 0.002395113
Iter: 356 loss: 0.00239233975
Iter: 357 loss: 0.00242772745
Iter: 358 loss: 0.00239231274
Iter: 359 loss: 0.00238994276
Iter: 360 loss: 0.00239389203
Iter: 361 loss: 0.00238888408
Iter: 362 loss: 0.00238666171
Iter: 363 loss: 0.00238942308
Iter: 364 loss: 0.00238549942
Iter: 365 loss: 0.00238280557
Iter: 366 loss: 0.00238204445
Iter: 367 loss: 0.00238039345
Iter: 368 loss: 0.00237603136
Iter: 369 loss: 0.00240854826
Iter: 370 loss: 0.00237567071
Iter: 371 loss: 0.00237261644
Iter: 372 loss: 0.00240106578
Iter: 373 loss: 0.00237249257
Iter: 374 loss: 0.00237060618
Iter: 375 loss: 0.00237278361
Iter: 376 loss: 0.00236958684
Iter: 377 loss: 0.00236637471
Iter: 378 loss: 0.00237594591
Iter: 379 loss: 0.00236541452
Iter: 380 loss: 0.00236351788
Iter: 381 loss: 0.00235911016
Iter: 382 loss: 0.002415383
Iter: 383 loss: 0.00235878676
Iter: 384 loss: 0.00235482329
Iter: 385 loss: 0.00235475926
Iter: 386 loss: 0.00235208403
Iter: 387 loss: 0.002368988
Iter: 388 loss: 0.0023517753
Iter: 389 loss: 0.00235046912
Iter: 390 loss: 0.00235138834
Iter: 391 loss: 0.00234965794
Iter: 392 loss: 0.00234742137
Iter: 393 loss: 0.00235001603
Iter: 394 loss: 0.00234621507
Iter: 395 loss: 0.00234349887
Iter: 396 loss: 0.00234228559
Iter: 397 loss: 0.00234091049
Iter: 398 loss: 0.00233702548
Iter: 399 loss: 0.00234932126
Iter: 400 loss: 0.00233590091
Iter: 401 loss: 0.00233223895
Iter: 402 loss: 0.00234898878
Iter: 403 loss: 0.00233154395
Iter: 404 loss: 0.00232851086
Iter: 405 loss: 0.00236406014
Iter: 406 loss: 0.00232845964
Iter: 407 loss: 0.00232681609
Iter: 408 loss: 0.00233101752
Iter: 409 loss: 0.00232626079
Iter: 410 loss: 0.00232430827
Iter: 411 loss: 0.00233338634
Iter: 412 loss: 0.00232393621
Iter: 413 loss: 0.00232275
Iter: 414 loss: 0.00231969124
Iter: 415 loss: 0.00234510377
Iter: 416 loss: 0.00231916714
Iter: 417 loss: 0.00231658621
Iter: 418 loss: 0.00232832506
Iter: 419 loss: 0.00231608655
Iter: 420 loss: 0.00231410284
Iter: 421 loss: 0.00233774306
Iter: 422 loss: 0.00231407955
Iter: 423 loss: 0.00231260527
Iter: 424 loss: 0.00231299084
Iter: 425 loss: 0.00231153169
Iter: 426 loss: 0.0023094255
Iter: 427 loss: 0.00232196134
Iter: 428 loss: 0.00230916496
Iter: 429 loss: 0.00230731489
Iter: 430 loss: 0.00230463454
Iter: 431 loss: 0.00230455026
Iter: 432 loss: 0.00230090925
Iter: 433 loss: 0.00231402321
Iter: 434 loss: 0.00229998818
Iter: 435 loss: 0.00229641097
Iter: 436 loss: 0.0023048548
Iter: 437 loss: 0.00229510595
Iter: 438 loss: 0.00229222141
Iter: 439 loss: 0.00232602819
Iter: 440 loss: 0.002292183
Iter: 441 loss: 0.00229045469
Iter: 442 loss: 0.00230651535
Iter: 443 loss: 0.00229037367
Iter: 444 loss: 0.00228915317
Iter: 445 loss: 0.00229660794
Iter: 446 loss: 0.00228900695
Iter: 447 loss: 0.00228795735
Iter: 448 loss: 0.00228536269
Iter: 449 loss: 0.00231117359
Iter: 450 loss: 0.0022850302
Iter: 451 loss: 0.00228231307
Iter: 452 loss: 0.00228378479
Iter: 453 loss: 0.00228052423
Iter: 454 loss: 0.00227813143
Iter: 455 loss: 0.00227804668
Iter: 456 loss: 0.00227609789
Iter: 457 loss: 0.00227711373
Iter: 458 loss: 0.00227480708
Iter: 459 loss: 0.00227267761
Iter: 460 loss: 0.0022862372
Iter: 461 loss: 0.00227244105
Iter: 462 loss: 0.00227061
Iter: 463 loss: 0.00227010157
Iter: 464 loss: 0.00226898282
Iter: 465 loss: 0.00226660282
Iter: 466 loss: 0.00226446567
Iter: 467 loss: 0.00226385985
Iter: 468 loss: 0.00226058229
Iter: 469 loss: 0.00227711862
Iter: 470 loss: 0.0022600377
Iter: 471 loss: 0.00225802744
Iter: 472 loss: 0.00227361405
Iter: 473 loss: 0.0022578747
Iter: 474 loss: 0.0022564251
Iter: 475 loss: 0.00227513164
Iter: 476 loss: 0.00225641695
Iter: 477 loss: 0.00225533964
Iter: 478 loss: 0.00226151804
Iter: 479 loss: 0.00225519203
Iter: 480 loss: 0.00225426187
Iter: 481 loss: 0.00225286116
Iter: 482 loss: 0.00225283159
Iter: 483 loss: 0.00225131
Iter: 484 loss: 0.00225207
Iter: 485 loss: 0.00225028768
Iter: 486 loss: 0.00224946067
Iter: 487 loss: 0.00224930351
Iter: 488 loss: 0.00224839058
Iter: 489 loss: 0.00224834913
Iter: 490 loss: 0.00224764692
Iter: 491 loss: 0.00224654167
Iter: 492 loss: 0.00224864692
Iter: 493 loss: 0.00224607671
Iter: 494 loss: 0.00224484503
Iter: 495 loss: 0.00224703364
Iter: 496 loss: 0.00224430417
Iter: 497 loss: 0.00224288809
Iter: 498 loss: 0.00224334
Iter: 499 loss: 0.00224188529
Iter: 500 loss: 0.00224019471
Iter: 501 loss: 0.00225940347
Iter: 502 loss: 0.0022401656
Iter: 503 loss: 0.0022391
Iter: 504 loss: 0.00223990344
Iter: 505 loss: 0.0022384522
Iter: 506 loss: 0.00223711436
Iter: 507 loss: 0.00224818313
Iter: 508 loss: 0.00223702821
Iter: 509 loss: 0.00223600026
Iter: 510 loss: 0.00224055443
Iter: 511 loss: 0.00223579886
Iter: 512 loss: 0.00223471876
Iter: 513 loss: 0.00223333715
Iter: 514 loss: 0.00223323447
Iter: 515 loss: 0.00223157159
Iter: 516 loss: 0.00222951872
Iter: 517 loss: 0.00222933874
Iter: 518 loss: 0.00222731614
Iter: 519 loss: 0.00222731708
Iter: 520 loss: 0.00222547934
Iter: 521 loss: 0.00222917716
Iter: 522 loss: 0.00222473405
Iter: 523 loss: 0.0022230281
Iter: 524 loss: 0.00222766958
Iter: 525 loss: 0.0022224579
Iter: 526 loss: 0.00222060527
Iter: 527 loss: 0.00222396222
Iter: 528 loss: 0.00221980643
Iter: 529 loss: 0.00221784832
Iter: 530 loss: 0.00221795216
Iter: 531 loss: 0.00221630116
Iter: 532 loss: 0.00221437635
Iter: 533 loss: 0.00222986843
Iter: 534 loss: 0.00221425341
Iter: 535 loss: 0.00221256772
Iter: 536 loss: 0.00221533724
Iter: 537 loss: 0.00221179286
Iter: 538 loss: 0.00221009366
Iter: 539 loss: 0.00222973689
Iter: 540 loss: 0.00221006782
Iter: 541 loss: 0.00220880285
Iter: 542 loss: 0.00221469812
Iter: 543 loss: 0.00220856443
Iter: 544 loss: 0.00220739399
Iter: 545 loss: 0.00220638374
Iter: 546 loss: 0.00220607314
Iter: 547 loss: 0.00220447616
Iter: 548 loss: 0.00220367289
Iter: 549 loss: 0.00220291526
Iter: 550 loss: 0.00220134901
Iter: 551 loss: 0.00222431822
Iter: 552 loss: 0.00220134621
Iter: 553 loss: 0.00219983188
Iter: 554 loss: 0.00220590713
Iter: 555 loss: 0.00219949195
Iter: 556 loss: 0.00219846214
Iter: 557 loss: 0.00219930313
Iter: 558 loss: 0.00219784607
Iter: 559 loss: 0.00219646771
Iter: 560 loss: 0.00220152782
Iter: 561 loss: 0.00219612126
Iter: 562 loss: 0.00219491636
Iter: 563 loss: 0.00219563441
Iter: 564 loss: 0.00219414569
Iter: 565 loss: 0.00219295942
Iter: 566 loss: 0.00219948636
Iter: 567 loss: 0.0021927862
Iter: 568 loss: 0.00219170377
Iter: 569 loss: 0.00219344534
Iter: 570 loss: 0.00219120574
Iter: 571 loss: 0.00219024159
Iter: 572 loss: 0.00220336276
Iter: 573 loss: 0.00219023437
Iter: 574 loss: 0.00218948582
Iter: 575 loss: 0.00219317572
Iter: 576 loss: 0.00218935404
Iter: 577 loss: 0.00218864321
Iter: 578 loss: 0.00218827813
Iter: 579 loss: 0.00218794029
Iter: 580 loss: 0.00218712143
Iter: 581 loss: 0.00218667276
Iter: 582 loss: 0.00218631094
Iter: 583 loss: 0.00218525459
Iter: 584 loss: 0.00218903
Iter: 585 loss: 0.00218498264
Iter: 586 loss: 0.00218381383
Iter: 587 loss: 0.00219385698
Iter: 588 loss: 0.00218375074
Iter: 589 loss: 0.00218309625
Iter: 590 loss: 0.00218322827
Iter: 591 loss: 0.00218261057
Iter: 592 loss: 0.00218168902
Iter: 593 loss: 0.00218411302
Iter: 594 loss: 0.00218137959
Iter: 595 loss: 0.00218044175
Iter: 596 loss: 0.00218084501
Iter: 597 loss: 0.00217979774
Iter: 598 loss: 0.00217885897
Iter: 599 loss: 0.0021837526
Iter: 600 loss: 0.00217871
Iter: 601 loss: 0.00217778608
Iter: 602 loss: 0.00218000915
Iter: 603 loss: 0.00217744452
Iter: 604 loss: 0.00217671762
Iter: 605 loss: 0.00218685367
Iter: 606 loss: 0.00217671529
Iter: 607 loss: 0.00217616535
Iter: 608 loss: 0.00217907364
Iter: 609 loss: 0.00217607967
Iter: 610 loss: 0.00217558863
Iter: 611 loss: 0.00217550178
Iter: 612 loss: 0.0021751707
Iter: 613 loss: 0.00217459933
Iter: 614 loss: 0.00217392249
Iter: 615 loss: 0.00217384985
Iter: 616 loss: 0.00217288337
Iter: 617 loss: 0.0021770508
Iter: 618 loss: 0.00217268942
Iter: 619 loss: 0.00217187451
Iter: 620 loss: 0.00217187684
Iter: 621 loss: 0.00217145262
Iter: 622 loss: 0.00217117555
Iter: 623 loss: 0.0021710142
Iter: 624 loss: 0.00217029871
Iter: 625 loss: 0.00217264844
Iter: 626 loss: 0.00217010034
Iter: 627 loss: 0.00216942141
Iter: 628 loss: 0.0021704745
Iter: 629 loss: 0.00216910033
Iter: 630 loss: 0.00216849567
Iter: 631 loss: 0.0021700114
Iter: 632 loss: 0.00216828473
Iter: 633 loss: 0.00216762046
Iter: 634 loss: 0.00217044819
Iter: 635 loss: 0.002167481
Iter: 636 loss: 0.00216703792
Iter: 637 loss: 0.00217128801
Iter: 638 loss: 0.00216702092
Iter: 639 loss: 0.00216665119
Iter: 640 loss: 0.00216878485
Iter: 641 loss: 0.00216660323
Iter: 642 loss: 0.00216627494
Iter: 643 loss: 0.00216630311
Iter: 644 loss: 0.00216601952
Iter: 645 loss: 0.00216563279
Iter: 646 loss: 0.00216509821
Iter: 647 loss: 0.00216507353
Iter: 648 loss: 0.002164362
Iter: 649 loss: 0.0021661655
Iter: 650 loss: 0.00216410635
Iter: 651 loss: 0.00216356665
Iter: 652 loss: 0.00216354895
Iter: 653 loss: 0.0021632507
Iter: 654 loss: 0.00216296548
Iter: 655 loss: 0.00216289982
Iter: 656 loss: 0.00216237316
Iter: 657 loss: 0.00216427795
Iter: 658 loss: 0.00216224138
Iter: 659 loss: 0.00216174219
Iter: 660 loss: 0.00216225442
Iter: 661 loss: 0.00216146605
Iter: 662 loss: 0.00216097548
Iter: 663 loss: 0.00216226513
Iter: 664 loss: 0.0021608083
Iter: 665 loss: 0.00216028723
Iter: 666 loss: 0.0021626628
Iter: 667 loss: 0.00216018967
Iter: 668 loss: 0.00215981249
Iter: 669 loss: 0.00216316292
Iter: 670 loss: 0.00215979619
Iter: 671 loss: 0.00215948978
Iter: 672 loss: 0.0021612756
Iter: 673 loss: 0.00215944787
Iter: 674 loss: 0.00215919293
Iter: 675 loss: 0.00215916988
Iter: 676 loss: 0.00215898314
Iter: 677 loss: 0.00215866603
Iter: 678 loss: 0.00215814845
Iter: 679 loss: 0.00215814379
Iter: 680 loss: 0.00215749489
Iter: 681 loss: 0.00216062483
Iter: 682 loss: 0.00215738174
Iter: 683 loss: 0.0021570567
Iter: 684 loss: 0.00215701526
Iter: 685 loss: 0.00215680036
Iter: 686 loss: 0.00215650839
Iter: 687 loss: 0.00215649139
Iter: 688 loss: 0.00215605134
Iter: 689 loss: 0.00215773028
Iter: 690 loss: 0.0021559475
Iter: 691 loss: 0.00215549814
Iter: 692 loss: 0.00215625949
Iter: 693 loss: 0.00215529045
Iter: 694 loss: 0.00215488952
Iter: 695 loss: 0.00215545041
Iter: 696 loss: 0.00215469045
Iter: 697 loss: 0.00215425575
Iter: 698 loss: 0.00215653656
Iter: 699 loss: 0.00215418427
Iter: 700 loss: 0.00215389905
Iter: 701 loss: 0.00215613679
Iter: 702 loss: 0.00215388043
Iter: 703 loss: 0.00215364411
Iter: 704 loss: 0.00215575099
Iter: 705 loss: 0.00215363642
Iter: 706 loss: 0.00215345807
Iter: 707 loss: 0.00215345481
Iter: 708 loss: 0.00215331139
Iter: 709 loss: 0.00215308205
Iter: 710 loss: 0.00215269881
Iter: 711 loss: 0.00215269974
Iter: 712 loss: 0.00215225434
Iter: 713 loss: 0.00215384667
Iter: 714 loss: 0.00215213979
Iter: 715 loss: 0.0021519321
Iter: 716 loss: 0.00215189299
Iter: 717 loss: 0.00215172465
Iter: 718 loss: 0.0021514378
Iter: 719 loss: 0.00215143664
Iter: 720 loss: 0.00215107948
Iter: 721 loss: 0.00215210579
Iter: 722 loss: 0.00215096585
Iter: 723 loss: 0.00215061032
Iter: 724 loss: 0.00215130835
Iter: 725 loss: 0.00215046015
Iter: 726 loss: 0.00215011695
Iter: 727 loss: 0.00215129252
Iter: 728 loss: 0.00215002662
Iter: 729 loss: 0.00214972021
Iter: 730 loss: 0.0021519633
Iter: 731 loss: 0.00214969693
Iter: 732 loss: 0.00214948459
Iter: 733 loss: 0.00215039332
Iter: 734 loss: 0.00214944594
Iter: 735 loss: 0.00214925269
Iter: 736 loss: 0.00215076166
Iter: 737 loss: 0.00214924081
Iter: 738 loss: 0.00214908365
Iter: 739 loss: 0.00214908784
Iter: 740 loss: 0.00214896235
Iter: 741 loss: 0.00214875117
Iter: 742 loss: 0.00214836164
Iter: 743 loss: 0.00215739547
Iter: 744 loss: 0.00214836234
Iter: 745 loss: 0.00214791577
Iter: 746 loss: 0.00214979192
Iter: 747 loss: 0.00214782334
Iter: 748 loss: 0.00214762846
Iter: 749 loss: 0.00214759354
Iter: 750 loss: 0.0021474245
Iter: 751 loss: 0.0021471777
Iter: 752 loss: 0.00214717141
Iter: 753 loss: 0.00214684638
Iter: 754 loss: 0.00214840658
Iter: 755 loss: 0.00214678678
Iter: 756 loss: 0.00214648736
Iter: 757 loss: 0.00214705453
Iter: 758 loss: 0.00214636372
Iter: 759 loss: 0.00214611017
Iter: 760 loss: 0.00214636815
Iter: 761 loss: 0.00214597024
Iter: 762 loss: 0.00214569457
Iter: 763 loss: 0.0021472415
Iter: 764 loss: 0.00214565871
Iter: 765 loss: 0.00214544334
Iter: 766 loss: 0.00214658817
Iter: 767 loss: 0.00214540958
Iter: 768 loss: 0.00214522937
Iter: 769 loss: 0.00214704499
Iter: 770 loss: 0.00214522309
Iter: 771 loss: 0.00214507803
Iter: 772 loss: 0.00214506965
Iter: 773 loss: 0.00214496255
Iter: 774 loss: 0.00214476185
Iter: 775 loss: 0.00214439235
Iter: 776 loss: 0.00215277704
Iter: 777 loss: 0.00214439165
Iter: 778 loss: 0.0021439977
Iter: 779 loss: 0.0021458664
Iter: 780 loss: 0.00214392738
Iter: 781 loss: 0.0021437821
Iter: 782 loss: 0.00214374345
Iter: 783 loss: 0.00214360887
Iter: 784 loss: 0.00214339886
Iter: 785 loss: 0.00214339513
Iter: 786 loss: 0.00214313902
Iter: 787 loss: 0.00214407127
Iter: 788 loss: 0.00214307033
Iter: 789 loss: 0.00214282447
Iter: 790 loss: 0.00214342703
Iter: 791 loss: 0.0021427332
Iter: 792 loss: 0.00214249641
Iter: 793 loss: 0.00214293553
Iter: 794 loss: 0.00214239303
Iter: 795 loss: 0.00214216067
Iter: 796 loss: 0.00214374275
Iter: 797 loss: 0.00214213738
Iter: 798 loss: 0.00214197021
Iter: 799 loss: 0.00214271178
Iter: 800 loss: 0.00214193389
Iter: 801 loss: 0.00214178953
Iter: 802 loss: 0.00214321818
Iter: 803 loss: 0.00214178441
Iter: 804 loss: 0.00214167149
Iter: 805 loss: 0.00214165915
Iter: 806 loss: 0.00214157626
Iter: 807 loss: 0.00214141584
Iter: 808 loss: 0.00214115786
Iter: 809 loss: 0.00214115554
Iter: 810 loss: 0.00214089872
Iter: 811 loss: 0.00214236486
Iter: 812 loss: 0.00214086333
Iter: 813 loss: 0.00214075344
Iter: 814 loss: 0.00214074133
Iter: 815 loss: 0.00214063935
Iter: 816 loss: 0.00214047171
Iter: 817 loss: 0.00214046706
Iter: 818 loss: 0.0021402589
Iter: 819 loss: 0.00214108638
Iter: 820 loss: 0.00214020908
Iter: 821 loss: 0.0021400135
Iter: 822 loss: 0.00214052643
Iter: 823 loss: 0.00213994249
Iter: 824 loss: 0.00213976693
Iter: 825 loss: 0.00214005588
Iter: 826 loss: 0.00213968987
Iter: 827 loss: 0.00213951617
Iter: 828 loss: 0.00214034086
Iter: 829 loss: 0.00213948358
Iter: 830 loss: 0.00213933527
Iter: 831 loss: 0.00214010617
Iter: 832 loss: 0.00213931222
Iter: 833 loss: 0.00213919464
Iter: 834 loss: 0.00214052782
Iter: 835 loss: 0.00213919114
Iter: 836 loss: 0.00213909615
Iter: 837 loss: 0.002139105
Iter: 838 loss: 0.0021390249
Iter: 839 loss: 0.00213890104
Iter: 840 loss: 0.00213872
Iter: 841 loss: 0.0021387171
Iter: 842 loss: 0.00213852874
Iter: 843 loss: 0.0021392717
Iter: 844 loss: 0.0021384852
Iter: 845 loss: 0.00213838741
Iter: 846 loss: 0.00213838136
Iter: 847 loss: 0.0021382838
Iter: 848 loss: 0.00213813595
Iter: 849 loss: 0.00213813409
Iter: 850 loss: 0.00213795574
Iter: 851 loss: 0.0021386249
Iter: 852 loss: 0.0021379129
Iter: 853 loss: 0.0021377448
Iter: 854 loss: 0.00213822955
Iter: 855 loss: 0.00213769311
Iter: 856 loss: 0.00213754014
Iter: 857 loss: 0.00213772268
Iter: 858 loss: 0.00213745888
Iter: 859 loss: 0.00213727821
Iter: 860 loss: 0.00213815761
Iter: 861 loss: 0.00213724468
Iter: 862 loss: 0.0021370945
Iter: 863 loss: 0.00213773735
Iter: 864 loss: 0.0021370668
Iter: 865 loss: 0.00213695
Iter: 866 loss: 0.00213851267
Iter: 867 loss: 0.00213695038
Iter: 868 loss: 0.00213686679
Iter: 869 loss: 0.00213685539
Iter: 870 loss: 0.0021368
Iter: 871 loss: 0.00213668169
Iter: 872 loss: 0.00213650754
Iter: 873 loss: 0.00213650474
Iter: 874 loss: 0.00213632546
Iter: 875 loss: 0.00213688496
Iter: 876 loss: 0.00213627
Iter: 877 loss: 0.00213616504
Iter: 878 loss: 0.0021361562
Iter: 879 loss: 0.00213604141
Iter: 880 loss: 0.00213589589
Iter: 881 loss: 0.00213588728
Iter: 882 loss: 0.00213570497
Iter: 883 loss: 0.00213630102
Iter: 884 loss: 0.00213565375
Iter: 885 loss: 0.00213547586
Iter: 886 loss: 0.00213587936
Iter: 887 loss: 0.0021354109
Iter: 888 loss: 0.00213521859
Iter: 889 loss: 0.0021355371
Iter: 890 loss: 0.00213513151
Iter: 891 loss: 0.00213493034
Iter: 892 loss: 0.00213597622
Iter: 893 loss: 0.00213489868
Iter: 894 loss: 0.00213473476
Iter: 895 loss: 0.00213573501
Iter: 896 loss: 0.00213471567
Iter: 897 loss: 0.00213461556
Iter: 898 loss: 0.00213599834
Iter: 899 loss: 0.00213461323
Iter: 900 loss: 0.00213453546
Iter: 901 loss: 0.002134535
Iter: 902 loss: 0.00213447446
Iter: 903 loss: 0.0021343613
Iter: 904 loss: 0.00213420764
Iter: 905 loss: 0.00213419856
Iter: 906 loss: 0.00213402044
Iter: 907 loss: 0.00213434547
Iter: 908 loss: 0.0021339443
Iter: 909 loss: 0.00213381811
Iter: 910 loss: 0.00213381532
Iter: 911 loss: 0.00213368749
Iter: 912 loss: 0.00213356246
Iter: 913 loss: 0.00213354127
Iter: 914 loss: 0.00213334896
Iter: 915 loss: 0.00213392358
Iter: 916 loss: 0.00213329168
Iter: 917 loss: 0.00213309983
Iter: 918 loss: 0.00213358831
Iter: 919 loss: 0.00213303068
Iter: 920 loss: 0.00213285023
Iter: 921 loss: 0.00213302951
Iter: 922 loss: 0.00213274988
Iter: 923 loss: 0.00213254872
Iter: 924 loss: 0.00213372661
Iter: 925 loss: 0.00213252287
Iter: 926 loss: 0.00213238178
Iter: 927 loss: 0.00213324372
Iter: 928 loss: 0.00213236315
Iter: 929 loss: 0.00213227514
Iter: 930 loss: 0.00213357946
Iter: 931 loss: 0.00213227654
Iter: 932 loss: 0.00213220413
Iter: 933 loss: 0.00213217596
Iter: 934 loss: 0.00213213591
Iter: 935 loss: 0.00213202671
Iter: 936 loss: 0.00213187421
Iter: 937 loss: 0.00213186839
Iter: 938 loss: 0.00213169912
Iter: 939 loss: 0.00213211728
Iter: 940 loss: 0.00213164091
Iter: 941 loss: 0.00213153614
Iter: 942 loss: 0.00213153
Iter: 943 loss: 0.00213141879
Iter: 944 loss: 0.00213133194
Iter: 945 loss: 0.00213129981
Iter: 946 loss: 0.00213115336
Iter: 947 loss: 0.00213149656
Iter: 948 loss: 0.00213109562
Iter: 949 loss: 0.00213093706
Iter: 950 loss: 0.00213123043
Iter: 951 loss: 0.00213087117
Iter: 952 loss: 0.0021306905
Iter: 953 loss: 0.00213103648
Iter: 954 loss: 0.0021306125
Iter: 955 loss: 0.00213043089
Iter: 956 loss: 0.0021314919
Iter: 957 loss: 0.00213041017
Iter: 958 loss: 0.0021302735
Iter: 959 loss: 0.00213110959
Iter: 960 loss: 0.00213025883
Iter: 961 loss: 0.00213017571
Iter: 962 loss: 0.00213132193
Iter: 963 loss: 0.00213017315
Iter: 964 loss: 0.00213010283
Iter: 965 loss: 0.00213008258
Iter: 966 loss: 0.00213003834
Iter: 967 loss: 0.0021299338
Iter: 968 loss: 0.00212982763
Iter: 969 loss: 0.00212980644
Iter: 970 loss: 0.00212967489
Iter: 971 loss: 0.00212989654
Iter: 972 loss: 0.00212961272
Iter: 973 loss: 0.00212951493
Iter: 974 loss: 0.0021295154
Iter: 975 loss: 0.00212940387
Iter: 976 loss: 0.00212938874
Iter: 977 loss: 0.00212931167
Iter: 978 loss: 0.00212917826
Iter: 979 loss: 0.00212940201
Iter: 980 loss: 0.00212911959
Iter: 981 loss: 0.00212896033
Iter: 982 loss: 0.0021293289
Iter: 983 loss: 0.00212889863
Iter: 984 loss: 0.00212874589
Iter: 985 loss: 0.00212893542
Iter: 986 loss: 0.00212866347
Iter: 987 loss: 0.00212849816
Iter: 988 loss: 0.00212935894
Iter: 989 loss: 0.00212847302
Iter: 990 loss: 0.00212834496
Iter: 991 loss: 0.0021290849
Iter: 992 loss: 0.00212833169
Iter: 993 loss: 0.00212825299
Iter: 994 loss: 0.00212825229
Iter: 995 loss: 0.0021281878
Iter: 996 loss: 0.00212817499
Iter: 997 loss: 0.00212813332
Iter: 998 loss: 0.00212804298
Iter: 999 loss: 0.00212795474
Iter: 1000 loss: 0.00212793611
Iter: 1001 loss: 0.00212781667
Iter: 1002 loss: 0.00212790864
Iter: 1003 loss: 0.00212774146
Iter: 1004 loss: 0.00212762505
Iter: 1005 loss: 0.00212940271
Iter: 1006 loss: 0.00212762319
Iter: 1007 loss: 0.00212749816
Iter: 1008 loss: 0.00212753983
Iter: 1009 loss: 0.00212741084
Iter: 1010 loss: 0.00212728512
Iter: 1011 loss: 0.00212751655
Iter: 1012 loss: 0.00212722598
Iter: 1013 loss: 0.00212708255
Iter: 1014 loss: 0.00212745555
Iter: 1015 loss: 0.00212703
Iter: 1016 loss: 0.00212688232
Iter: 1017 loss: 0.00212709419
Iter: 1018 loss: 0.00212680968
Iter: 1019 loss: 0.00212666392
Iter: 1020 loss: 0.00212752377
Iter: 1021 loss: 0.002126646
Iter: 1022 loss: 0.00212653913
Iter: 1023 loss: 0.0021271396
Iter: 1024 loss: 0.00212652306
Iter: 1025 loss: 0.00212645507
Iter: 1026 loss: 0.00212645484
Iter: 1027 loss: 0.00212640129
Iter: 1028 loss: 0.00212639128
Iter: 1029 loss: 0.0021263524
Iter: 1030 loss: 0.00212626345
Iter: 1031 loss: 0.00212619966
Iter: 1032 loss: 0.00212617381
Iter: 1033 loss: 0.00212605437
Iter: 1034 loss: 0.00212614052
Iter: 1035 loss: 0.0021259822
Iter: 1036 loss: 0.00212587183
Iter: 1037 loss: 0.00212750467
Iter: 1038 loss: 0.00212587276
Iter: 1039 loss: 0.00212576985
Iter: 1040 loss: 0.00212582923
Iter: 1041 loss: 0.00212570187
Iter: 1042 loss: 0.00212559896
Iter: 1043 loss: 0.00212576776
Iter: 1044 loss: 0.00212555076
Iter: 1045 loss: 0.00212542294
Iter: 1046 loss: 0.00212575356
Iter: 1047 loss: 0.00212538475
Iter: 1048 loss: 0.00212526089
Iter: 1049 loss: 0.00212538196
Iter: 1050 loss: 0.00212519569
Iter: 1051 loss: 0.00212506531
Iter: 1052 loss: 0.0021255766
Iter: 1053 loss: 0.0021250369
Iter: 1054 loss: 0.00212493539
Iter: 1055 loss: 0.00212552538
Iter: 1056 loss: 0.00212492095
Iter: 1057 loss: 0.00212485855
Iter: 1058 loss: 0.00212580431
Iter: 1059 loss: 0.00212485949
Iter: 1060 loss: 0.00212480593
Iter: 1061 loss: 0.00212478684
Iter: 1062 loss: 0.00212475797
Iter: 1063 loss: 0.00212467555
Iter: 1064 loss: 0.0021246376
Iter: 1065 loss: 0.00212459732
Iter: 1066 loss: 0.00212450116
Iter: 1067 loss: 0.00212459406
Iter: 1068 loss: 0.00212444924
Iter: 1069 loss: 0.00212437566
Iter: 1070 loss: 0.0021243752
Iter: 1071 loss: 0.00212429976
Iter: 1072 loss: 0.00212433189
Iter: 1073 loss: 0.00212424924
Iter: 1074 loss: 0.00212417659
Iter: 1075 loss: 0.00212423597
Iter: 1076 loss: 0.00212413399
Iter: 1077 loss: 0.00212403713
Iter: 1078 loss: 0.00212422619
Iter: 1079 loss: 0.00212399871
Iter: 1080 loss: 0.00212388206
Iter: 1081 loss: 0.00212411652
Iter: 1082 loss: 0.00212383643
Iter: 1083 loss: 0.00212372281
Iter: 1084 loss: 0.00212433934
Iter: 1085 loss: 0.00212370581
Iter: 1086 loss: 0.00212362362
Iter: 1087 loss: 0.00212408276
Iter: 1088 loss: 0.00212360779
Iter: 1089 loss: 0.00212355214
Iter: 1090 loss: 0.00212418125
Iter: 1091 loss: 0.00212355028
Iter: 1092 loss: 0.00212349882
Iter: 1093 loss: 0.00212348672
Iter: 1094 loss: 0.00212345226
Iter: 1095 loss: 0.00212337589
Iter: 1096 loss: 0.00212338241
Iter: 1097 loss: 0.00212331722
Iter: 1098 loss: 0.00212323945
Iter: 1099 loss: 0.00212332373
Iter: 1100 loss: 0.0021232008
Iter: 1101 loss: 0.0021231412
Iter: 1102 loss: 0.00212314166
Iter: 1103 loss: 0.00212307926
Iter: 1104 loss: 0.00212313235
Iter: 1105 loss: 0.00212304201
Iter: 1106 loss: 0.00212298241
Iter: 1107 loss: 0.00212300289
Iter: 1108 loss: 0.00212294213
Iter: 1109 loss: 0.00212285481
Iter: 1110 loss: 0.00212308695
Iter: 1111 loss: 0.00212282455
Iter: 1112 loss: 0.00212273886
Iter: 1113 loss: 0.00212284969
Iter: 1114 loss: 0.00212269044
Iter: 1115 loss: 0.0021225987
Iter: 1116 loss: 0.00212302781
Iter: 1117 loss: 0.00212258
Iter: 1118 loss: 0.00212250231
Iter: 1119 loss: 0.0021229526
Iter: 1120 loss: 0.00212249695
Iter: 1121 loss: 0.00212244713
Iter: 1122 loss: 0.0021230788
Iter: 1123 loss: 0.00212244457
Iter: 1124 loss: 0.00212240242
Iter: 1125 loss: 0.00212238473
Iter: 1126 loss: 0.00212236214
Iter: 1127 loss: 0.00212229881
Iter: 1128 loss: 0.0021223193
Iter: 1129 loss: 0.00212224945
Iter: 1130 loss: 0.00212219032
Iter: 1131 loss: 0.0021222115
Iter: 1132 loss: 0.00212214841
Iter: 1133 loss: 0.00212209299
Iter: 1134 loss: 0.00212209066
Iter: 1135 loss: 0.00212203618
Iter: 1136 loss: 0.00212208321
Iter: 1137 loss: 0.00212200545
Iter: 1138 loss: 0.00212195097
Iter: 1139 loss: 0.00212199055
Iter: 1140 loss: 0.00212191883
Iter: 1141 loss: 0.00212184503
Iter: 1142 loss: 0.00212203129
Iter: 1143 loss: 0.00212181918
Iter: 1144 loss: 0.00212173583
Iter: 1145 loss: 0.00212184153
Iter: 1146 loss: 0.00212169439
Iter: 1147 loss: 0.00212161103
Iter: 1148 loss: 0.0021220122
Iter: 1149 loss: 0.0021215966
Iter: 1150 loss: 0.00212153653
Iter: 1151 loss: 0.00212194398
Iter: 1152 loss: 0.00212152954
Iter: 1153 loss: 0.00212149345
Iter: 1154 loss: 0.00212193234
Iter: 1155 loss: 0.00212149299
Iter: 1156 loss: 0.0021214555
Iter: 1157 loss: 0.0021214392
Iter: 1158 loss: 0.00212142221
Iter: 1159 loss: 0.00212137122
Iter: 1160 loss: 0.00212137168
Iter: 1161 loss: 0.00212132698
Iter: 1162 loss: 0.0021212732
Iter: 1163 loss: 0.00212127087
Iter: 1164 loss: 0.00212122919
Iter: 1165 loss: 0.00212117494
Iter: 1166 loss: 0.00212117354
Iter: 1167 loss: 0.00212111929
Iter: 1168 loss: 0.00212121266
Iter: 1169 loss: 0.00212109275
Iter: 1170 loss: 0.00212104688
Iter: 1171 loss: 0.00212104735
Iter: 1172 loss: 0.00212100893
Iter: 1173 loss: 0.0021209307
Iter: 1174 loss: 0.0021211335
Iter: 1175 loss: 0.00212090416
Iter: 1176 loss: 0.00212082174
Iter: 1177 loss: 0.00212096097
Iter: 1178 loss: 0.00212078425
Iter: 1179 loss: 0.0021207137
Iter: 1180 loss: 0.00212103128
Iter: 1181 loss: 0.00212069834
Iter: 1182 loss: 0.00212064548
Iter: 1183 loss: 0.00212092046
Iter: 1184 loss: 0.00212063384
Iter: 1185 loss: 0.00212059589
Iter: 1186 loss: 0.00212104665
Iter: 1187 loss: 0.00212059426
Iter: 1188 loss: 0.00212055584
Iter: 1189 loss: 0.00212054327
Iter: 1190 loss: 0.00212051859
Iter: 1191 loss: 0.00212045852
Iter: 1192 loss: 0.00212048
Iter: 1193 loss: 0.00212041894
Iter: 1194 loss: 0.00212035794
Iter: 1195 loss: 0.00212037307
Iter: 1196 loss: 0.0021203116
Iter: 1197 loss: 0.00212025922
Iter: 1198 loss: 0.00212026108
Iter: 1199 loss: 0.00212020869
Iter: 1200 loss: 0.00212024804
Iter: 1201 loss: 0.00212017912
Iter: 1202 loss: 0.00212012813
Iter: 1203 loss: 0.00212013093
Iter: 1204 loss: 0.00212008692
Iter: 1205 loss: 0.00212000241
Iter: 1206 loss: 0.00212031743
Iter: 1207 loss: 0.00211998215
Iter: 1208 loss: 0.00211990508
Iter: 1209 loss: 0.00212011393
Iter: 1210 loss: 0.00211987831
Iter: 1211 loss: 0.0021198187
Iter: 1212 loss: 0.00211998727
Iter: 1213 loss: 0.00211979728
Iter: 1214 loss: 0.00211973838
Iter: 1215 loss: 0.00212001242
Iter: 1216 loss: 0.00211973116
Iter: 1217 loss: 0.0021196804
Iter: 1218 loss: 0.0021200527
Iter: 1219 loss: 0.00211968063
Iter: 1220 loss: 0.00211962778
Iter: 1221 loss: 0.00211961824
Iter: 1222 loss: 0.00211958517
Iter: 1223 loss: 0.00211951835
Iter: 1224 loss: 0.00211953046
Iter: 1225 loss: 0.00211946969
Iter: 1226 loss: 0.00211940147
Iter: 1227 loss: 0.00211943826
Iter: 1228 loss: 0.00211936026
Iter: 1229 loss: 0.00211930275
Iter: 1230 loss: 0.0021193
Iter: 1231 loss: 0.00211923872
Iter: 1232 loss: 0.00211930089
Iter: 1233 loss: 0.00211920403
Iter: 1234 loss: 0.00211914442
Iter: 1235 loss: 0.00211913674
Iter: 1236 loss: 0.00211909739
Iter: 1237 loss: 0.00211901171
Iter: 1238 loss: 0.00211934978
Iter: 1239 loss: 0.00211899611
Iter: 1240 loss: 0.00211891579
Iter: 1241 loss: 0.00211919378
Iter: 1242 loss: 0.00211889576
Iter: 1243 loss: 0.00211883173
Iter: 1244 loss: 0.00211905409
Iter: 1245 loss: 0.00211881613
Iter: 1246 loss: 0.00211875234
Iter: 1247 loss: 0.00211896235
Iter: 1248 loss: 0.00211873674
Iter: 1249 loss: 0.00211868226
Iter: 1250 loss: 0.00211916352
Iter: 1251 loss: 0.00211867969
Iter: 1252 loss: 0.00211862335
Iter: 1253 loss: 0.00211862777
Iter: 1254 loss: 0.00211857958
Iter: 1255 loss: 0.00211851229
Iter: 1256 loss: 0.00211854558
Iter: 1257 loss: 0.00211846596
Iter: 1258 loss: 0.00211840402
Iter: 1259 loss: 0.00211838773
Iter: 1260 loss: 0.00211834698
Iter: 1261 loss: 0.00211827178
Iter: 1262 loss: 0.00211919565
Iter: 1263 loss: 0.00211827038
Iter: 1264 loss: 0.00211819075
Iter: 1265 loss: 0.00211835257
Iter: 1266 loss: 0.00211815466
Iter: 1267 loss: 0.00211808924
Iter: 1268 loss: 0.00211808
Iter: 1269 loss: 0.00211803126
Iter: 1270 loss: 0.00211793534
Iter: 1271 loss: 0.00211833441
Iter: 1272 loss: 0.00211791089
Iter: 1273 loss: 0.00211782707
Iter: 1274 loss: 0.0021180585
Iter: 1275 loss: 0.0021177989
Iter: 1276 loss: 0.00211772532
Iter: 1277 loss: 0.00211796537
Iter: 1278 loss: 0.0021177046
Iter: 1279 loss: 0.0021176266
Iter: 1280 loss: 0.00211794465
Iter: 1281 loss: 0.0021176138
Iter: 1282 loss: 0.00211755908
Iter: 1283 loss: 0.00211814698
Iter: 1284 loss: 0.00211755466
Iter: 1285 loss: 0.00211749878
Iter: 1286 loss: 0.00211751321
Iter: 1287 loss: 0.00211746152
Iter: 1288 loss: 0.0021173954
Iter: 1289 loss: 0.00211742986
Iter: 1290 loss: 0.00211735629
Iter: 1291 loss: 0.0021172855
Iter: 1292 loss: 0.00211724197
Iter: 1293 loss: 0.00211721612
Iter: 1294 loss: 0.00211713254
Iter: 1295 loss: 0.00211834046
Iter: 1296 loss: 0.00211713556
Iter: 1297 loss: 0.00211705267
Iter: 1298 loss: 0.00211723242
Iter: 1299 loss: 0.00211702287
Iter: 1300 loss: 0.00211695908
Iter: 1301 loss: 0.00211695535
Iter: 1302 loss: 0.00211690227
Iter: 1303 loss: 0.00211681239
Iter: 1304 loss: 0.00211719377
Iter: 1305 loss: 0.00211679516
Iter: 1306 loss: 0.00211671717
Iter: 1307 loss: 0.00211688178
Iter: 1308 loss: 0.00211668573
Iter: 1309 loss: 0.00211661193
Iter: 1310 loss: 0.00211688061
Iter: 1311 loss: 0.00211659237
Iter: 1312 loss: 0.00211652671
Iter: 1313 loss: 0.00211686571
Iter: 1314 loss: 0.0021165167
Iter: 1315 loss: 0.00211647246
Iter: 1316 loss: 0.0021169621
Iter: 1317 loss: 0.00211647246
Iter: 1318 loss: 0.00211643171
Iter: 1319 loss: 0.00211643195
Iter: 1320 loss: 0.00211639563
Iter: 1321 loss: 0.00211633882
Iter: 1322 loss: 0.00211635698
Iter: 1323 loss: 0.0021162997
Iter: 1324 loss: 0.0021162394
Iter: 1325 loss: 0.00211620843
Iter: 1326 loss: 0.00211618259
Iter: 1327 loss: 0.00211611902
Iter: 1328 loss: 0.00211611856
Iter: 1329 loss: 0.00211606082
Iter: 1330 loss: 0.00211622985
Iter: 1331 loss: 0.00211604661
Iter: 1332 loss: 0.00211600377
Iter: 1333 loss: 0.00211599609
Iter: 1334 loss: 0.00211596908
Iter: 1335 loss: 0.00211590691
Iter: 1336 loss: 0.00211611483
Iter: 1337 loss: 0.00211589132
Iter: 1338 loss: 0.00211582799
Iter: 1339 loss: 0.00211600936
Iter: 1340 loss: 0.00211581215
Iter: 1341 loss: 0.00211576303
Iter: 1342 loss: 0.00211597327
Iter: 1343 loss: 0.00211575348
Iter: 1344 loss: 0.00211571436
Iter: 1345 loss: 0.00211588666
Iter: 1346 loss: 0.00211570458
Iter: 1347 loss: 0.00211567665
Iter: 1348 loss: 0.0021159579
Iter: 1349 loss: 0.00211567781
Iter: 1350 loss: 0.00211564265
Iter: 1351 loss: 0.00211564777
Iter: 1352 loss: 0.00211561844
Iter: 1353 loss: 0.00211557886
Iter: 1354 loss: 0.00211561564
Iter: 1355 loss: 0.0021155565
Iter: 1356 loss: 0.00211552111
Iter: 1357 loss: 0.00211550971
Iter: 1358 loss: 0.00211548619
Iter: 1359 loss: 0.00211545546
Iter: 1360 loss: 0.00211545336
Iter: 1361 loss: 0.00211542333
Iter: 1362 loss: 0.00211548153
Iter: 1363 loss: 0.00211541448
Iter: 1364 loss: 0.00211538561
Iter: 1365 loss: 0.00211536605
Iter: 1366 loss: 0.00211535534
Iter: 1367 loss: 0.00211530365
Iter: 1368 loss: 0.00211556046
Iter: 1369 loss: 0.00211529643
Iter: 1370 loss: 0.00211525103
Iter: 1371 loss: 0.00211539818
Iter: 1372 loss: 0.00211524125
Iter: 1373 loss: 0.00211520866
Iter: 1374 loss: 0.00211528456
Iter: 1375 loss: 0.00211519841
Iter: 1376 loss: 0.00211516628
Iter: 1377 loss: 0.00211528223
Iter: 1378 loss: 0.00211515906
Iter: 1379 loss: 0.00211513392
Iter: 1380 loss: 0.00211537699
Iter: 1381 loss: 0.00211513462
Iter: 1382 loss: 0.00211510574
Iter: 1383 loss: 0.00211512903
Iter: 1384 loss: 0.00211509
Iter: 1385 loss: 0.00211506058
Iter: 1386 loss: 0.0021150778
Iter: 1387 loss: 0.00211504288
Iter: 1388 loss: 0.00211501773
Iter: 1389 loss: 0.00211500516
Iter: 1390 loss: 0.00211499678
Iter: 1391 loss: 0.00211496907
Iter: 1392 loss: 0.00211531669
Iter: 1393 loss: 0.00211496651
Iter: 1394 loss: 0.00211493648
Iter: 1395 loss: 0.00211498048
Iter: 1396 loss: 0.00211492111
Iter: 1397 loss: 0.00211488688
Iter: 1398 loss: 0.0021148813
Iter: 1399 loss: 0.00211485638
Iter: 1400 loss: 0.00211481
Iter: 1401 loss: 0.00211499282
Iter: 1402 loss: 0.00211479678
Iter: 1403 loss: 0.00211475301
Iter: 1404 loss: 0.0021149409
Iter: 1405 loss: 0.0021147402
Iter: 1406 loss: 0.00211470621
Iter: 1407 loss: 0.00211477955
Iter: 1408 loss: 0.00211468944
Iter: 1409 loss: 0.00211464986
Iter: 1410 loss: 0.00211477582
Iter: 1411 loss: 0.00211464
Iter: 1412 loss: 0.00211460469
Iter: 1413 loss: 0.00211495184
Iter: 1414 loss: 0.00211460562
Iter: 1415 loss: 0.0021145714
Iter: 1416 loss: 0.00211461331
Iter: 1417 loss: 0.00211455184
Iter: 1418 loss: 0.00211451901
Iter: 1419 loss: 0.00211454276
Iter: 1420 loss: 0.00211449852
Iter: 1421 loss: 0.00211446825
Iter: 1422 loss: 0.0021144459
Iter: 1423 loss: 0.00211443356
Iter: 1424 loss: 0.00211438374
Iter: 1425 loss: 0.00211482588
Iter: 1426 loss: 0.00211438118
Iter: 1427 loss: 0.00211432623
Iter: 1428 loss: 0.00211448735
Iter: 1429 loss: 0.002114309
Iter: 1430 loss: 0.00211426336
Iter: 1431 loss: 0.00211422332
Iter: 1432 loss: 0.002114214
Iter: 1433 loss: 0.00211413973
Iter: 1434 loss: 0.0021144331
Iter: 1435 loss: 0.00211412436
Iter: 1436 loss: 0.0021140594
Iter: 1437 loss: 0.00211428571
Iter: 1438 loss: 0.00211404427
Iter: 1439 loss: 0.00211398257
Iter: 1440 loss: 0.00211416
Iter: 1441 loss: 0.00211396301
Iter: 1442 loss: 0.00211389968
Iter: 1443 loss: 0.00211414043
Iter: 1444 loss: 0.00211387919
Iter: 1445 loss: 0.00211383216
Iter: 1446 loss: 0.0021143402
Iter: 1447 loss: 0.00211383239
Iter: 1448 loss: 0.00211378722
Iter: 1449 loss: 0.00211383728
Iter: 1450 loss: 0.00211375952
Iter: 1451 loss: 0.00211371598
Iter: 1452 loss: 0.00211374462
Iter: 1453 loss: 0.00211368455
Iter: 1454 loss: 0.00211363472
Iter: 1455 loss: 0.0021135686
Iter: 1456 loss: 0.00211356115
Iter: 1457 loss: 0.00211348059
Iter: 1458 loss: 0.00211444637
Iter: 1459 loss: 0.00211348
Iter: 1460 loss: 0.00211340375
Iter: 1461 loss: 0.00211370504
Iter: 1462 loss: 0.00211338419
Iter: 1463 loss: 0.00211332738
Iter: 1464 loss: 0.00211329432
Iter: 1465 loss: 0.00211326825
Iter: 1466 loss: 0.00211317977
Iter: 1467 loss: 0.00211359654
Iter: 1468 loss: 0.0021131651
Iter: 1469 loss: 0.00211308827
Iter: 1470 loss: 0.00211323495
Iter: 1471 loss: 0.00211305544
Iter: 1472 loss: 0.00211297954
Iter: 1473 loss: 0.00211321842
Iter: 1474 loss: 0.00211295369
Iter: 1475 loss: 0.0021128878
Iter: 1476 loss: 0.00211319071
Iter: 1477 loss: 0.00211287173
Iter: 1478 loss: 0.00211282307
Iter: 1479 loss: 0.00211344636
Iter: 1480 loss: 0.00211282191
Iter: 1481 loss: 0.00211277651
Iter: 1482 loss: 0.00211280864
Iter: 1483 loss: 0.00211274857
Iter: 1484 loss: 0.00211269874
Iter: 1485 loss: 0.00211271131
Iter: 1486 loss: 0.00211266335
Iter: 1487 loss: 0.00211260375
Iter: 1488 loss: 0.00211254298
Iter: 1489 loss: 0.00211252971
Iter: 1490 loss: 0.0021124552
Iter: 1491 loss: 0.00211360352
Iter: 1492 loss: 0.00211245893
Iter: 1493 loss: 0.0021123928
Iter: 1494 loss: 0.0021127006
Iter: 1495 loss: 0.00211238093
Iter: 1496 loss: 0.00211233925
Iter: 1497 loss: 0.00211230433
Iter: 1498 loss: 0.00211229175
Iter: 1499 loss: 0.00211222074
Iter: 1500 loss: 0.00211248128
Iter: 1501 loss: 0.00211220188
Iter: 1502 loss: 0.00211212831
Iter: 1503 loss: 0.00211232691
Iter: 1504 loss: 0.00211210339
Iter: 1505 loss: 0.00211204239
Iter: 1506 loss: 0.0021122708
Iter: 1507 loss: 0.00211202819
Iter: 1508 loss: 0.00211197278
Iter: 1509 loss: 0.00211218698
Iter: 1510 loss: 0.00211196113
Iter: 1511 loss: 0.00211192202
Iter: 1512 loss: 0.00211236
Iter: 1513 loss: 0.00211191876
Iter: 1514 loss: 0.00211188104
Iter: 1515 loss: 0.00211192272
Iter: 1516 loss: 0.00211185869
Iter: 1517 loss: 0.00211181631
Iter: 1518 loss: 0.00211185054
Iter: 1519 loss: 0.00211178698
Iter: 1520 loss: 0.00211174414
Iter: 1521 loss: 0.00211172132
Iter: 1522 loss: 0.00211170246
Iter: 1523 loss: 0.00211165985
Iter: 1524 loss: 0.0021122836
Iter: 1525 loss: 0.00211166125
Iter: 1526 loss: 0.00211162493
Iter: 1527 loss: 0.00211173901
Iter: 1528 loss: 0.00211161957
Iter: 1529 loss: 0.00211158674
Iter: 1530 loss: 0.00211155741
Iter: 1531 loss: 0.00211155182
Iter: 1532 loss: 0.00211149477
Iter: 1533 loss: 0.00211176137
Iter: 1534 loss: 0.00211148593
Iter: 1535 loss: 0.00211143796
Iter: 1536 loss: 0.00211157743
Iter: 1537 loss: 0.00211141771
Iter: 1538 loss: 0.00211137813
Iter: 1539 loss: 0.00211149431
Iter: 1540 loss: 0.00211136462
Iter: 1541 loss: 0.00211132667
Iter: 1542 loss: 0.00211143284
Iter: 1543 loss: 0.00211131363
Iter: 1544 loss: 0.00211127894
Iter: 1545 loss: 0.00211161259
Iter: 1546 loss: 0.00211127778
Iter: 1547 loss: 0.00211124122
Iter: 1548 loss: 0.00211128406
Iter: 1549 loss: 0.00211122073
Iter: 1550 loss: 0.00211118953
Iter: 1551 loss: 0.00211122399
Iter: 1552 loss: 0.00211116648
Iter: 1553 loss: 0.00211113878
Iter: 1554 loss: 0.00211112341
Iter: 1555 loss: 0.00211110967
Iter: 1556 loss: 0.00211108034
Iter: 1557 loss: 0.00211154483
Iter: 1558 loss: 0.00211107777
Iter: 1559 loss: 0.00211105263
Iter: 1560 loss: 0.00211112457
Iter: 1561 loss: 0.00211104332
Iter: 1562 loss: 0.0021110184
Iter: 1563 loss: 0.00211099349
Iter: 1564 loss: 0.0021109879
Iter: 1565 loss: 0.00211093877
Iter: 1566 loss: 0.00211112294
Iter: 1567 loss: 0.00211092737
Iter: 1568 loss: 0.00211088196
Iter: 1569 loss: 0.00211105123
Iter: 1570 loss: 0.00211087195
Iter: 1571 loss: 0.00211083214
Iter: 1572 loss: 0.00211088546
Iter: 1573 loss: 0.00211081328
Iter: 1574 loss: 0.00211077323
Iter: 1575 loss: 0.00211084634
Iter: 1576 loss: 0.00211075414
Iter: 1577 loss: 0.00211071363
Iter: 1578 loss: 0.0021110645
Iter: 1579 loss: 0.0021107113
Iter: 1580 loss: 0.00211066823
Iter: 1581 loss: 0.00211075181
Iter: 1582 loss: 0.0021106468
Iter: 1583 loss: 0.00211060699
Iter: 1584 loss: 0.00211065519
Iter: 1585 loss: 0.00211058464
Iter: 1586 loss: 0.00211055321
Iter: 1587 loss: 0.00211052876
Iter: 1588 loss: 0.00211051456
Iter: 1589 loss: 0.00211047335
Iter: 1590 loss: 0.00211098511
Iter: 1591 loss: 0.00211047428
Iter: 1592 loss: 0.00211043376
Iter: 1593 loss: 0.00211054459
Iter: 1594 loss: 0.00211042282
Iter: 1595 loss: 0.00211038883
Iter: 1596 loss: 0.00211034762
Iter: 1597 loss: 0.00211034343
Iter: 1598 loss: 0.00211027032
Iter: 1599 loss: 0.00211060676
Iter: 1600 loss: 0.00211026147
Iter: 1601 loss: 0.00211019698
Iter: 1602 loss: 0.00211046264
Iter: 1603 loss: 0.00211018301
Iter: 1604 loss: 0.00211013341
Iter: 1605 loss: 0.00211020606
Iter: 1606 loss: 0.0021101064
Iter: 1607 loss: 0.00211004796
Iter: 1608 loss: 0.00211015856
Iter: 1609 loss: 0.00211002654
Iter: 1610 loss: 0.00210996484
Iter: 1611 loss: 0.00211042445
Iter: 1612 loss: 0.00210996182
Iter: 1613 loss: 0.00210990058
Iter: 1614 loss: 0.00211005495
Iter: 1615 loss: 0.00210987753
Iter: 1616 loss: 0.00210983073
Iter: 1617 loss: 0.00210986892
Iter: 1618 loss: 0.0021098014
Iter: 1619 loss: 0.00210975157
Iter: 1620 loss: 0.00210971176
Iter: 1621 loss: 0.00210969755
Iter: 1622 loss: 0.00210964144
Iter: 1623 loss: 0.00211043935
Iter: 1624 loss: 0.00210964074
Iter: 1625 loss: 0.00210958975
Iter: 1626 loss: 0.00210975297
Iter: 1627 loss: 0.00210957229
Iter: 1628 loss: 0.00210952689
Iter: 1629 loss: 0.00210948056
Iter: 1630 loss: 0.00210946891
Iter: 1631 loss: 0.0021093844
Iter: 1632 loss: 0.00210973108
Iter: 1633 loss: 0.00210936903
Iter: 1634 loss: 0.00210928731
Iter: 1635 loss: 0.00210974528
Iter: 1636 loss: 0.00210927683
Iter: 1637 loss: 0.00210921932
Iter: 1638 loss: 0.00210933946
Iter: 1639 loss: 0.0021091965
Iter: 1640 loss: 0.0021091355
Iter: 1641 loss: 0.00210924819
Iter: 1642 loss: 0.00210910849
Iter: 1643 loss: 0.00210904516
Iter: 1644 loss: 0.00210945052
Iter: 1645 loss: 0.00210903864
Iter: 1646 loss: 0.0021089646
Iter: 1647 loss: 0.00210918626
Iter: 1648 loss: 0.00210894574
Iter: 1649 loss: 0.00210889429
Iter: 1650 loss: 0.00210894248
Iter: 1651 loss: 0.00210886402
Iter: 1652 loss: 0.00210881187
Iter: 1653 loss: 0.00210878486
Iter: 1654 loss: 0.00210875948
Iter: 1655 loss: 0.00210870104
Iter: 1656 loss: 0.00210921513
Iter: 1657 loss: 0.00210870104
Iter: 1658 loss: 0.00210864376
Iter: 1659 loss: 0.00210880628
Iter: 1660 loss: 0.00210862374
Iter: 1661 loss: 0.00210857159
Iter: 1662 loss: 0.00210852176
Iter: 1663 loss: 0.00210851012
Iter: 1664 loss: 0.00210841978
Iter: 1665 loss: 0.00210895389
Iter: 1666 loss: 0.00210840977
Iter: 1667 loss: 0.00210833526
Iter: 1668 loss: 0.00210877135
Iter: 1669 loss: 0.00210832618
Iter: 1670 loss: 0.00210827473
Iter: 1671 loss: 0.00210835598
Iter: 1672 loss: 0.00210825121
Iter: 1673 loss: 0.00210819463
Iter: 1674 loss: 0.00210826984
Iter: 1675 loss: 0.00210816506
Iter: 1676 loss: 0.0021081008
Iter: 1677 loss: 0.00210852618
Iter: 1678 loss: 0.00210809358
Iter: 1679 loss: 0.00210802443
Iter: 1680 loss: 0.00210828404
Iter: 1681 loss: 0.00210801116
Iter: 1682 loss: 0.00210795924
Iter: 1683 loss: 0.00210800488
Iter: 1684 loss: 0.00210793
Iter: 1685 loss: 0.0021078838
Iter: 1686 loss: 0.00210784841
Iter: 1687 loss: 0.00210783537
Iter: 1688 loss: 0.00210777554
Iter: 1689 loss: 0.00210841978
Iter: 1690 loss: 0.00210777624
Iter: 1691 loss: 0.00210772199
Iter: 1692 loss: 0.00210784608
Iter: 1693 loss: 0.0021077008
Iter: 1694 loss: 0.00210764864
Iter: 1695 loss: 0.00210761745
Iter: 1696 loss: 0.00210759277
Iter: 1697 loss: 0.00210751966
Iter: 1698 loss: 0.00210785447
Iter: 1699 loss: 0.00210750103
Iter: 1700 loss: 0.00210743514
Iter: 1701 loss: 0.00210793223
Iter: 1702 loss: 0.00210743072
Iter: 1703 loss: 0.00210738415
Iter: 1704 loss: 0.00210744538
Iter: 1705 loss: 0.0021073611
Iter: 1706 loss: 0.00210730219
Iter: 1707 loss: 0.00210736133
Iter: 1708 loss: 0.00210726913
Iter: 1709 loss: 0.00210719695
Iter: 1710 loss: 0.00210756063
Iter: 1711 loss: 0.00210718485
Iter: 1712 loss: 0.00210710592
Iter: 1713 loss: 0.00210747938
Iter: 1714 loss: 0.00210709032
Iter: 1715 loss: 0.00210703909
Iter: 1716 loss: 0.0021070654
Iter: 1717 loss: 0.00210700464
Iter: 1718 loss: 0.00210694969
Iter: 1719 loss: 0.00210692734
Iter: 1720 loss: 0.00210689567
Iter: 1721 loss: 0.00210683164
Iter: 1722 loss: 0.00210738881
Iter: 1723 loss: 0.00210682978
Iter: 1724 loss: 0.00210676575
Iter: 1725 loss: 0.0021069909
Iter: 1726 loss: 0.00210674945
Iter: 1727 loss: 0.0021066945
Iter: 1728 loss: 0.00210664468
Iter: 1729 loss: 0.00210663071
Iter: 1730 loss: 0.0021065441
Iter: 1731 loss: 0.00210701744
Iter: 1732 loss: 0.00210653106
Iter: 1733 loss: 0.00210646167
Iter: 1734 loss: 0.00210690731
Iter: 1735 loss: 0.00210645283
Iter: 1736 loss: 0.00210639648
Iter: 1737 loss: 0.00210646261
Iter: 1738 loss: 0.00210636854
Iter: 1739 loss: 0.00210629194
Iter: 1740 loss: 0.00210633967
Iter: 1741 loss: 0.00210624607
Iter: 1742 loss: 0.00210614875
Iter: 1743 loss: 0.00210677413
Iter: 1744 loss: 0.00210614
Iter: 1745 loss: 0.00210604444
Iter: 1746 loss: 0.00210647983
Iter: 1747 loss: 0.00210602395
Iter: 1748 loss: 0.00210596016
Iter: 1749 loss: 0.00210601185
Iter: 1750 loss: 0.00210592
Iter: 1751 loss: 0.00210585305
Iter: 1752 loss: 0.00210581184
Iter: 1753 loss: 0.00210578786
Iter: 1754 loss: 0.00210570684
Iter: 1755 loss: 0.00210637832
Iter: 1756 loss: 0.00210570311
Iter: 1757 loss: 0.00210562302
Iter: 1758 loss: 0.0021058789
Iter: 1759 loss: 0.00210560067
Iter: 1760 loss: 0.00210553315
Iter: 1761 loss: 0.00210551475
Iter: 1762 loss: 0.00210547377
Iter: 1763 loss: 0.0021053853
Iter: 1764 loss: 0.00210578833
Iter: 1765 loss: 0.00210536923
Iter: 1766 loss: 0.00210528658
Iter: 1767 loss: 0.00210581045
Iter: 1768 loss: 0.00210527866
Iter: 1769 loss: 0.00210521254
Iter: 1770 loss: 0.00210528122
Iter: 1771 loss: 0.00210517738
Iter: 1772 loss: 0.00210510031
Iter: 1773 loss: 0.00210518576
Iter: 1774 loss: 0.00210505724
Iter: 1775 loss: 0.00210496713
Iter: 1776 loss: 0.00210548425
Iter: 1777 loss: 0.00210495153
Iter: 1778 loss: 0.00210486236
Iter: 1779 loss: 0.00210539019
Iter: 1780 loss: 0.00210485165
Iter: 1781 loss: 0.00210479833
Iter: 1782 loss: 0.00210484769
Iter: 1783 loss: 0.00210476061
Iter: 1784 loss: 0.00210469984
Iter: 1785 loss: 0.00210468424
Iter: 1786 loss: 0.00210464606
Iter: 1787 loss: 0.00210457551
Iter: 1788 loss: 0.00210507354
Iter: 1789 loss: 0.00210457155
Iter: 1790 loss: 0.00210450497
Iter: 1791 loss: 0.00210475433
Iter: 1792 loss: 0.00210449146
Iter: 1793 loss: 0.00210444303
Iter: 1794 loss: 0.00210441579
Iter: 1795 loss: 0.00210439507
Iter: 1796 loss: 0.00210432475
Iter: 1797 loss: 0.0021046598
Iter: 1798 loss: 0.00210431358
Iter: 1799 loss: 0.00210425397
Iter: 1800 loss: 0.00210470217
Iter: 1801 loss: 0.00210424862
Iter: 1802 loss: 0.00210420671
Iter: 1803 loss: 0.00210426748
Iter: 1804 loss: 0.00210418552
Iter: 1805 loss: 0.00210414012
Iter: 1806 loss: 0.00210417435
Iter: 1807 loss: 0.00210411195
Iter: 1808 loss: 0.00210405793
Iter: 1809 loss: 0.00210446049
Iter: 1810 loss: 0.00210405374
Iter: 1811 loss: 0.00210400764
Iter: 1812 loss: 0.00210428843
Iter: 1813 loss: 0.00210399972
Iter: 1814 loss: 0.0021039662
Iter: 1815 loss: 0.00210398249
Iter: 1816 loss: 0.00210394431
Iter: 1817 loss: 0.00210391078
Iter: 1818 loss: 0.00210388354
Iter: 1819 loss: 0.00210387097
Iter: 1820 loss: 0.00210383115
Iter: 1821 loss: 0.00210431125
Iter: 1822 loss: 0.00210383139
Iter: 1823 loss: 0.00210379716
Iter: 1824 loss: 0.00210391963
Iter: 1825 loss: 0.00210378901
Iter: 1826 loss: 0.00210376317
Iter: 1827 loss: 0.00210374128
Iter: 1828 loss: 0.0021037329
Iter: 1829 loss: 0.00210369192
Iter: 1830 loss: 0.00210384303
Iter: 1831 loss: 0.00210368168
Iter: 1832 loss: 0.00210364512
Iter: 1833 loss: 0.00210406794
Iter: 1834 loss: 0.00210364535
Iter: 1835 loss: 0.00210362067
Iter: 1836 loss: 0.00210364303
Iter: 1837 loss: 0.0021036081
Iter: 1838 loss: 0.00210358249
Iter: 1839 loss: 0.00210361113
Iter: 1840 loss: 0.0021035634
Iter: 1841 loss: 0.00210353476
Iter: 1842 loss: 0.00210364233
Iter: 1843 loss: 0.00210352661
Iter: 1844 loss: 0.002103484
Iter: 1845 loss: 0.00210373593
Iter: 1846 loss: 0.00210348284
Iter: 1847 loss: 0.00210345467
Iter: 1848 loss: 0.00210346328
Iter: 1849 loss: 0.00210343604
Iter: 1850 loss: 0.00210340461
Iter: 1851 loss: 0.00210340437
Iter: 1852 loss: 0.00210337806
Iter: 1853 loss: 0.0021033464
Iter: 1854 loss: 0.00210355222
Iter: 1855 loss: 0.00210334151
Iter: 1856 loss: 0.00210330845
Iter: 1857 loss: 0.00210340321
Iter: 1858 loss: 0.00210329983
Iter: 1859 loss: 0.00210326747
Iter: 1860 loss: 0.00210323255
Iter: 1861 loss: 0.00210322905
Iter: 1862 loss: 0.00210317317
Iter: 1863 loss: 0.00210336037
Iter: 1864 loss: 0.00210316153
Iter: 1865 loss: 0.00210311264
Iter: 1866 loss: 0.00210365
Iter: 1867 loss: 0.00210310845
Iter: 1868 loss: 0.00210307911
Iter: 1869 loss: 0.00210314151
Iter: 1870 loss: 0.00210306514
Iter: 1871 loss: 0.00210302835
Iter: 1872 loss: 0.00210301508
Iter: 1873 loss: 0.00210299529
Iter: 1874 loss: 0.00210293219
Iter: 1875 loss: 0.0021030975
Iter: 1876 loss: 0.00210290635
Iter: 1877 loss: 0.00210282509
Iter: 1878 loss: 0.00210329727
Iter: 1879 loss: 0.00210281461
Iter: 1880 loss: 0.00210275431
Iter: 1881 loss: 0.00210281275
Iter: 1882 loss: 0.00210272
Iter: 1883 loss: 0.00210265419
Iter: 1884 loss: 0.0021026209
Iter: 1885 loss: 0.00210259296
Iter: 1886 loss: 0.00210250914
Iter: 1887 loss: 0.00210319133
Iter: 1888 loss: 0.00210250495
Iter: 1889 loss: 0.00210242695
Iter: 1890 loss: 0.00210269028
Iter: 1891 loss: 0.00210240716
Iter: 1892 loss: 0.00210234243
Iter: 1893 loss: 0.00210227864
Iter: 1894 loss: 0.00210226281
Iter: 1895 loss: 0.00210214849
Iter: 1896 loss: 0.00210247748
Iter: 1897 loss: 0.0021021103
Iter: 1898 loss: 0.00210201414
Iter: 1899 loss: 0.0021032372
Iter: 1900 loss: 0.00210201298
Iter: 1901 loss: 0.00210194429
Iter: 1902 loss: 0.00210202718
Iter: 1903 loss: 0.0021019117
Iter: 1904 loss: 0.00210182299
Iter: 1905 loss: 0.00210184581
Iter: 1906 loss: 0.00210175896
Iter: 1907 loss: 0.00210163952
Iter: 1908 loss: 0.00210223719
Iter: 1909 loss: 0.00210161973
Iter: 1910 loss: 0.00210150378
Iter: 1911 loss: 0.00210231636
Iter: 1912 loss: 0.00210149307
Iter: 1913 loss: 0.00210141181
Iter: 1914 loss: 0.00210146233
Iter: 1915 loss: 0.00210136222
Iter: 1916 loss: 0.00210127467
Iter: 1917 loss: 0.00210125372
Iter: 1918 loss: 0.00210119877
Iter: 1919 loss: 0.00210110797
Iter: 1920 loss: 0.00210191216
Iter: 1921 loss: 0.00210109958
Iter: 1922 loss: 0.00210102065
Iter: 1923 loss: 0.00210134336
Iter: 1924 loss: 0.00210100017
Iter: 1925 loss: 0.00210093916
Iter: 1926 loss: 0.00210088026
Iter: 1927 loss: 0.00210086303
Iter: 1928 loss: 0.00210076105
Iter: 1929 loss: 0.00210107979
Iter: 1930 loss: 0.00210073171
Iter: 1931 loss: 0.00210063858
Iter: 1932 loss: 0.00210161041
Iter: 1933 loss: 0.00210063672
Iter: 1934 loss: 0.00210057106
Iter: 1935 loss: 0.00210071844
Iter: 1936 loss: 0.00210054684
Iter: 1937 loss: 0.00210048514
Iter: 1938 loss: 0.00210056733
Iter: 1939 loss: 0.00210045604
Iter: 1940 loss: 0.00210038875
Iter: 1941 loss: 0.00210073427
Iter: 1942 loss: 0.00210037827
Iter: 1943 loss: 0.00210031727
Iter: 1944 loss: 0.00210070331
Iter: 1945 loss: 0.00210030912
Iter: 1946 loss: 0.00210026652
Iter: 1947 loss: 0.00210029865
Iter: 1948 loss: 0.00210023741
Iter: 1949 loss: 0.00210018875
Iter: 1950 loss: 0.00210018712
Iter: 1951 loss: 0.00210015429
Iter: 1952 loss: 0.00210010353
Iter: 1953 loss: 0.00210055197
Iter: 1954 loss: 0.00210010423
Iter: 1955 loss: 0.00210006582
Iter: 1956 loss: 0.00210019341
Iter: 1957 loss: 0.00210005371
Iter: 1958 loss: 0.00210001692
Iter: 1959 loss: 0.00209999271
Iter: 1960 loss: 0.00209998013
Iter: 1961 loss: 0.00209991797
Iter: 1962 loss: 0.00210000668
Iter: 1963 loss: 0.00209988724
Iter: 1964 loss: 0.00209982553
Iter: 1965 loss: 0.0021006281
Iter: 1966 loss: 0.00209982274
Iter: 1967 loss: 0.00209977943
Iter: 1968 loss: 0.0020998749
Iter: 1969 loss: 0.00209976407
Iter: 1970 loss: 0.00209972984
Iter: 1971 loss: 0.00209975569
Iter: 1972 loss: 0.00209970889
Iter: 1973 loss: 0.00209966535
Iter: 1974 loss: 0.00209990982
Iter: 1975 loss: 0.0020996586
Iter: 1976 loss: 0.00209961575
Iter: 1977 loss: 0.00209992658
Iter: 1978 loss: 0.00209961
Iter: 1979 loss: 0.00209958223
Iter: 1980 loss: 0.00209960341
Iter: 1981 loss: 0.00209956337
Iter: 1982 loss: 0.00209952705
Iter: 1983 loss: 0.00209951843
Iter: 1984 loss: 0.00209949771
Iter: 1985 loss: 0.00209946092
Iter: 1986 loss: 0.00209976942
Iter: 1987 loss: 0.00209945627
Iter: 1988 loss: 0.00209942088
Iter: 1989 loss: 0.00209953962
Iter: 1990 loss: 0.00209941296
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k3
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3
+ date
Tue Oct 27 20:20:58 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/k3 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k3 --OuterProductNN_k 3 --optimizer lbfgs --function f1 --psi 1 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/ --save_name k3 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k3
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c346cf268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c346d1598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c346e6d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3465b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3465b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3468a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3464abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3468a620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34610488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c345a0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34610510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3452c8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3456eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34555d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3452c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c345a01e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c344a78c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3445e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34420598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34420ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c344532f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c344537b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c343bf7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34365950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34365840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34398b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3434e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c342da7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c342f2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3429b488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c342f2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3427c048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3428a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c3428a378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c34226598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f9c341f50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0372061431
Iter: 2 loss: 1.69298077
Iter: 3 loss: 1.65058589
Iter: 4 loss: 1.09604228
Iter: 5 loss: 1.06286204
Iter: 6 loss: 0.705447555
Iter: 7 loss: 0.674546957
Iter: 8 loss: 0.431665361
Iter: 9 loss: 0.40023312
Iter: 10 loss: 0.233974606
Iter: 11 loss: 0.204022229
Iter: 12 loss: 0.103016317
Iter: 13 loss: 0.0820481777
Iter: 14 loss: 0.0357430056
Iter: 15 loss: 0.0287898351
Iter: 16 loss: 0.0235751532
Iter: 17 loss: 0.0171033293
Iter: 18 loss: 0.0160418488
Iter: 19 loss: 0.0190854
Iter: 20 loss: 0.0141877597
Iter: 21 loss: 0.0115368227
Iter: 22 loss: 0.0114396131
Iter: 23 loss: 0.00927732605
Iter: 24 loss: 0.0126002077
Iter: 25 loss: 0.00817778241
Iter: 26 loss: 0.00651496556
Iter: 27 loss: 0.00646934751
Iter: 28 loss: 0.00618910836
Iter: 29 loss: 0.00590861216
Iter: 30 loss: 0.00583936647
Iter: 31 loss: 0.00546126161
Iter: 32 loss: 0.00498909038
Iter: 33 loss: 0.00495050522
Iter: 34 loss: 0.00438046735
Iter: 35 loss: 0.00522751175
Iter: 36 loss: 0.00410544267
Iter: 37 loss: 0.00368351163
Iter: 38 loss: 0.00365398242
Iter: 39 loss: 0.00335523975
Iter: 40 loss: 0.00308572454
Iter: 41 loss: 0.00587330852
Iter: 42 loss: 0.00307092257
Iter: 43 loss: 0.00296457973
Iter: 44 loss: 0.00324528618
Iter: 45 loss: 0.00292728515
Iter: 46 loss: 0.00285185617
Iter: 47 loss: 0.00281770946
Iter: 48 loss: 0.00278152479
Iter: 49 loss: 0.00270741619
Iter: 50 loss: 0.00278710434
Iter: 51 loss: 0.00266979239
Iter: 52 loss: 0.00258780201
Iter: 53 loss: 0.00285625877
Iter: 54 loss: 0.00256459415
Iter: 55 loss: 0.00249876361
Iter: 56 loss: 0.00278922357
Iter: 57 loss: 0.00248623407
Iter: 58 loss: 0.00243020104
Iter: 59 loss: 0.00252965279
Iter: 60 loss: 0.00240659364
Iter: 61 loss: 0.00241472013
Iter: 62 loss: 0.00238723168
Iter: 63 loss: 0.00236446457
Iter: 64 loss: 0.00235700607
Iter: 65 loss: 0.00234395196
Iter: 66 loss: 0.00230436749
Iter: 67 loss: 0.00236515561
Iter: 68 loss: 0.00228641531
Iter: 69 loss: 0.00226019556
Iter: 70 loss: 0.0023211441
Iter: 71 loss: 0.00225080503
Iter: 72 loss: 0.00222447282
Iter: 73 loss: 0.00254689017
Iter: 74 loss: 0.00222406117
Iter: 75 loss: 0.00220313272
Iter: 76 loss: 0.00219264929
Iter: 77 loss: 0.00218286179
Iter: 78 loss: 0.0021550979
Iter: 79 loss: 0.00221794867
Iter: 80 loss: 0.00214481
Iter: 81 loss: 0.00212204223
Iter: 82 loss: 0.00231160922
Iter: 83 loss: 0.00212057843
Iter: 84 loss: 0.00210312242
Iter: 85 loss: 0.0021512527
Iter: 86 loss: 0.00209764135
Iter: 87 loss: 0.00208272203
Iter: 88 loss: 0.002148306
Iter: 89 loss: 0.00207958836
Iter: 90 loss: 0.00207000948
Iter: 91 loss: 0.00206218031
Iter: 92 loss: 0.00205939426
Iter: 93 loss: 0.00205274951
Iter: 94 loss: 0.00205252087
Iter: 95 loss: 0.00204581767
Iter: 96 loss: 0.00205072761
Iter: 97 loss: 0.00204176712
Iter: 98 loss: 0.00203410536
Iter: 99 loss: 0.00202464382
Iter: 100 loss: 0.00202382798
Iter: 101 loss: 0.00201621861
Iter: 102 loss: 0.00203999598
Iter: 103 loss: 0.0020140477
Iter: 104 loss: 0.00200852309
Iter: 105 loss: 0.00207970804
Iter: 106 loss: 0.00200848118
Iter: 107 loss: 0.00200522691
Iter: 108 loss: 0.0020291307
Iter: 109 loss: 0.00200497312
Iter: 110 loss: 0.00200185739
Iter: 111 loss: 0.00200075
Iter: 112 loss: 0.00199898519
Iter: 113 loss: 0.00199583685
Iter: 114 loss: 0.00200801296
Iter: 115 loss: 0.00199510902
Iter: 116 loss: 0.00199250667
Iter: 117 loss: 0.00199623266
Iter: 118 loss: 0.00199123169
Iter: 119 loss: 0.00198845193
Iter: 120 loss: 0.00200282945
Iter: 121 loss: 0.00198801
Iter: 122 loss: 0.0019859469
Iter: 123 loss: 0.00200161641
Iter: 124 loss: 0.00198578415
Iter: 125 loss: 0.00198410801
Iter: 126 loss: 0.00199100561
Iter: 127 loss: 0.00198375061
Iter: 128 loss: 0.00198211265
Iter: 129 loss: 0.00198757043
Iter: 130 loss: 0.00198165467
Iter: 131 loss: 0.0019804358
Iter: 132 loss: 0.00198132917
Iter: 133 loss: 0.00197968446
Iter: 134 loss: 0.00197838759
Iter: 135 loss: 0.00197709724
Iter: 136 loss: 0.00197682739
Iter: 137 loss: 0.00197496894
Iter: 138 loss: 0.00198421767
Iter: 139 loss: 0.00197465206
Iter: 140 loss: 0.00197319849
Iter: 141 loss: 0.00198387937
Iter: 142 loss: 0.00197307579
Iter: 143 loss: 0.00197197217
Iter: 144 loss: 0.0019812258
Iter: 145 loss: 0.0019719121
Iter: 146 loss: 0.00197107042
Iter: 147 loss: 0.00197119871
Iter: 148 loss: 0.00197043363
Iter: 149 loss: 0.00196961081
Iter: 150 loss: 0.00197463739
Iter: 151 loss: 0.00196951302
Iter: 152 loss: 0.00196884293
Iter: 153 loss: 0.00196814
Iter: 154 loss: 0.00196801848
Iter: 155 loss: 0.00196713489
Iter: 156 loss: 0.00197547325
Iter: 157 loss: 0.00196710136
Iter: 158 loss: 0.00196657749
Iter: 159 loss: 0.00196657795
Iter: 160 loss: 0.00196615513
Iter: 161 loss: 0.00196655886
Iter: 162 loss: 0.00196591578
Iter: 163 loss: 0.00196542684
Iter: 164 loss: 0.00196566805
Iter: 165 loss: 0.00196509808
Iter: 166 loss: 0.00196438795
Iter: 167 loss: 0.00196341448
Iter: 168 loss: 0.00196336908
Iter: 169 loss: 0.00196234602
Iter: 170 loss: 0.00196810765
Iter: 171 loss: 0.00196220656
Iter: 172 loss: 0.00196111109
Iter: 173 loss: 0.00196217792
Iter: 174 loss: 0.00196049362
Iter: 175 loss: 0.0019598268
Iter: 176 loss: 0.0019597935
Iter: 177 loss: 0.00195919396
Iter: 178 loss: 0.00195955532
Iter: 179 loss: 0.0019588084
Iter: 180 loss: 0.00195815205
Iter: 181 loss: 0.00195873296
Iter: 182 loss: 0.00195776764
Iter: 183 loss: 0.00195692084
Iter: 184 loss: 0.00195947406
Iter: 185 loss: 0.00195666589
Iter: 186 loss: 0.00195603771
Iter: 187 loss: 0.00195795437
Iter: 188 loss: 0.00195585075
Iter: 189 loss: 0.0019555043
Iter: 190 loss: 0.00195549894
Iter: 191 loss: 0.00195515668
Iter: 192 loss: 0.00195575133
Iter: 193 loss: 0.00195500441
Iter: 194 loss: 0.00195466354
Iter: 195 loss: 0.00195448287
Iter: 196 loss: 0.00195432873
Iter: 197 loss: 0.00195381604
Iter: 198 loss: 0.00195510755
Iter: 199 loss: 0.00195363653
Iter: 200 loss: 0.00195317459
Iter: 201 loss: 0.00195305631
Iter: 202 loss: 0.00195276737
Iter: 203 loss: 0.00195211289
Iter: 204 loss: 0.00195424631
Iter: 205 loss: 0.00195192767
Iter: 206 loss: 0.00195142278
Iter: 207 loss: 0.00195634668
Iter: 208 loss: 0.00195140683
Iter: 209 loss: 0.00195100065
Iter: 210 loss: 0.00195328682
Iter: 211 loss: 0.00195094396
Iter: 212 loss: 0.00195053569
Iter: 213 loss: 0.00195016107
Iter: 214 loss: 0.00195006316
Iter: 215 loss: 0.00194955431
Iter: 216 loss: 0.00195273594
Iter: 217 loss: 0.00194949529
Iter: 218 loss: 0.00194907363
Iter: 219 loss: 0.00194957154
Iter: 220 loss: 0.00194885035
Iter: 221 loss: 0.00194843835
Iter: 222 loss: 0.00195277692
Iter: 223 loss: 0.0019484252
Iter: 224 loss: 0.0019481905
Iter: 225 loss: 0.00194818911
Iter: 226 loss: 0.00194804976
Iter: 227 loss: 0.00194772566
Iter: 228 loss: 0.00195151696
Iter: 229 loss: 0.00194769795
Iter: 230 loss: 0.0019473281
Iter: 231 loss: 0.00194910227
Iter: 232 loss: 0.00194726046
Iter: 233 loss: 0.00194692484
Iter: 234 loss: 0.00194655987
Iter: 235 loss: 0.0019465026
Iter: 236 loss: 0.00194598653
Iter: 237 loss: 0.00194905337
Iter: 238 loss: 0.00194592238
Iter: 239 loss: 0.00194549037
Iter: 240 loss: 0.00194622029
Iter: 241 loss: 0.00194529537
Iter: 242 loss: 0.00194495032
Iter: 243 loss: 0.00194494659
Iter: 244 loss: 0.00194469863
Iter: 245 loss: 0.00194474473
Iter: 246 loss: 0.00194451283
Iter: 247 loss: 0.00194418605
Iter: 248 loss: 0.00194459688
Iter: 249 loss: 0.00194401515
Iter: 250 loss: 0.00194364158
Iter: 251 loss: 0.00194417697
Iter: 252 loss: 0.00194345973
Iter: 253 loss: 0.00194304169
Iter: 254 loss: 0.00194645964
Iter: 255 loss: 0.00194301736
Iter: 256 loss: 0.00194286334
Iter: 257 loss: 0.00194284902
Iter: 258 loss: 0.00194272306
Iter: 259 loss: 0.00194244646
Iter: 260 loss: 0.00194656965
Iter: 261 loss: 0.00194243412
Iter: 262 loss: 0.00194213632
Iter: 263 loss: 0.00194302201
Iter: 264 loss: 0.00194204808
Iter: 265 loss: 0.00194177742
Iter: 266 loss: 0.00194229325
Iter: 267 loss: 0.00194166368
Iter: 268 loss: 0.00194136403
Iter: 269 loss: 0.00194144784
Iter: 270 loss: 0.00194114877
Iter: 271 loss: 0.00194084249
Iter: 272 loss: 0.00194197963
Iter: 273 loss: 0.00194076623
Iter: 274 loss: 0.00194059114
Iter: 275 loss: 0.00194058195
Iter: 276 loss: 0.00194043259
Iter: 277 loss: 0.00194058707
Iter: 278 loss: 0.00194034632
Iter: 279 loss: 0.00194017612
Iter: 280 loss: 0.00194020069
Iter: 281 loss: 0.00194004527
Iter: 282 loss: 0.00193982013
Iter: 283 loss: 0.00194037857
Iter: 284 loss: 0.00193974108
Iter: 285 loss: 0.00193953374
Iter: 286 loss: 0.00194083038
Iter: 287 loss: 0.00193951197
Iter: 288 loss: 0.00193941221
Iter: 289 loss: 0.00193940708
Iter: 290 loss: 0.00193932
Iter: 291 loss: 0.00193925062
Iter: 292 loss: 0.00193922454
Iter: 293 loss: 0.00193911023
Iter: 294 loss: 0.00193902978
Iter: 295 loss: 0.0019389902
Iter: 296 loss: 0.00193879846
Iter: 297 loss: 0.00193931791
Iter: 298 loss: 0.00193873607
Iter: 299 loss: 0.00193854526
Iter: 300 loss: 0.00193885458
Iter: 301 loss: 0.00193845737
Iter: 302 loss: 0.0019382647
Iter: 303 loss: 0.00193853676
Iter: 304 loss: 0.00193817017
Iter: 305 loss: 0.00193796528
Iter: 306 loss: 0.0019389746
Iter: 307 loss: 0.0019379328
Iter: 308 loss: 0.0019377789
Iter: 309 loss: 0.00193777948
Iter: 310 loss: 0.00193769822
Iter: 311 loss: 0.00193756935
Iter: 312 loss: 0.00193756889
Iter: 313 loss: 0.00193736411
Iter: 314 loss: 0.00193786481
Iter: 315 loss: 0.00193728961
Iter: 316 loss: 0.00193712744
Iter: 317 loss: 0.00193813653
Iter: 318 loss: 0.0019371073
Iter: 319 loss: 0.00193702453
Iter: 320 loss: 0.00193702173
Iter: 321 loss: 0.00193694443
Iter: 322 loss: 0.00193692953
Iter: 323 loss: 0.00193687645
Iter: 324 loss: 0.00193678145
Iter: 325 loss: 0.0019367286
Iter: 326 loss: 0.00193668692
Iter: 327 loss: 0.00193653395
Iter: 328 loss: 0.00193679612
Iter: 329 loss: 0.00193646597
Iter: 330 loss: 0.00193632289
Iter: 331 loss: 0.00193713815
Iter: 332 loss: 0.00193630229
Iter: 333 loss: 0.00193618645
Iter: 334 loss: 0.0019360719
Iter: 335 loss: 0.00193604664
Iter: 336 loss: 0.00193587
Iter: 337 loss: 0.00193687167
Iter: 338 loss: 0.00193584536
Iter: 339 loss: 0.00193573069
Iter: 340 loss: 0.00193573
Iter: 341 loss: 0.00193563465
Iter: 342 loss: 0.0019356109
Iter: 343 loss: 0.00193555083
Iter: 344 loss: 0.0019354322
Iter: 345 loss: 0.00193543325
Iter: 346 loss: 0.00193534023
Iter: 347 loss: 0.00193521543
Iter: 348 loss: 0.00193667714
Iter: 349 loss: 0.00193521485
Iter: 350 loss: 0.00193513813
Iter: 351 loss: 0.00193572592
Iter: 352 loss: 0.00193513371
Iter: 353 loss: 0.00193504617
Iter: 354 loss: 0.00193521113
Iter: 355 loss: 0.00193500821
Iter: 356 loss: 0.00193494931
Iter: 357 loss: 0.00193491974
Iter: 358 loss: 0.0019348918
Iter: 359 loss: 0.00193479971
Iter: 360 loss: 0.00193479378
Iter: 361 loss: 0.00193472486
Iter: 362 loss: 0.00193462
Iter: 363 loss: 0.00193565816
Iter: 364 loss: 0.0019346159
Iter: 365 loss: 0.00193453417
Iter: 366 loss: 0.00193447829
Iter: 367 loss: 0.00193445
Iter: 368 loss: 0.00193434372
Iter: 369 loss: 0.0019346911
Iter: 370 loss: 0.001934311
Iter: 371 loss: 0.00193421857
Iter: 372 loss: 0.00193527038
Iter: 373 loss: 0.00193421892
Iter: 374 loss: 0.00193413137
Iter: 375 loss: 0.00193437911
Iter: 376 loss: 0.00193410285
Iter: 377 loss: 0.00193403405
Iter: 378 loss: 0.00193398027
Iter: 379 loss: 0.00193395885
Iter: 380 loss: 0.00193386339
Iter: 381 loss: 0.00193443033
Iter: 382 loss: 0.00193385198
Iter: 383 loss: 0.00193378376
Iter: 384 loss: 0.00193444476
Iter: 385 loss: 0.00193378155
Iter: 386 loss: 0.00193372159
Iter: 387 loss: 0.00193417957
Iter: 388 loss: 0.00193371717
Iter: 389 loss: 0.00193368096
Iter: 390 loss: 0.00193360844
Iter: 391 loss: 0.00193494442
Iter: 392 loss: 0.00193360785
Iter: 393 loss: 0.00193353568
Iter: 394 loss: 0.00193381275
Iter: 395 loss: 0.00193351659
Iter: 396 loss: 0.00193344615
Iter: 397 loss: 0.00193358609
Iter: 398 loss: 0.00193341798
Iter: 399 loss: 0.0019333479
Iter: 400 loss: 0.00193358143
Iter: 401 loss: 0.00193333044
Iter: 402 loss: 0.00193325861
Iter: 403 loss: 0.00193330948
Iter: 404 loss: 0.00193321588
Iter: 405 loss: 0.00193314045
Iter: 406 loss: 0.00193328562
Iter: 407 loss: 0.00193310785
Iter: 408 loss: 0.00193302846
Iter: 409 loss: 0.00193303078
Iter: 410 loss: 0.00193298655
Iter: 411 loss: 0.00193292846
Iter: 412 loss: 0.00193292298
Iter: 413 loss: 0.00193285127
Iter: 414 loss: 0.00193295418
Iter: 415 loss: 0.00193281751
Iter: 416 loss: 0.00193275232
Iter: 417 loss: 0.00193362706
Iter: 418 loss: 0.00193275278
Iter: 419 loss: 0.00193271518
Iter: 420 loss: 0.00193271472
Iter: 421 loss: 0.00193268852
Iter: 422 loss: 0.00193262752
Iter: 423 loss: 0.00193343952
Iter: 424 loss: 0.00193262368
Iter: 425 loss: 0.00193256512
Iter: 426 loss: 0.00193267502
Iter: 427 loss: 0.00193253905
Iter: 428 loss: 0.00193247246
Iter: 429 loss: 0.00193265488
Iter: 430 loss: 0.00193244987
Iter: 431 loss: 0.00193238817
Iter: 432 loss: 0.00193267514
Iter: 433 loss: 0.00193237618
Iter: 434 loss: 0.00193231844
Iter: 435 loss: 0.00193230435
Iter: 436 loss: 0.0019322678
Iter: 437 loss: 0.00193219644
Iter: 438 loss: 0.00193268806
Iter: 439 loss: 0.0019321898
Iter: 440 loss: 0.00193213369
Iter: 441 loss: 0.00193235185
Iter: 442 loss: 0.00193211925
Iter: 443 loss: 0.00193204929
Iter: 444 loss: 0.00193230866
Iter: 445 loss: 0.00193203287
Iter: 446 loss: 0.00193199061
Iter: 447 loss: 0.00193192787
Iter: 448 loss: 0.0019319267
Iter: 449 loss: 0.00193187804
Iter: 450 loss: 0.00193188037
Iter: 451 loss: 0.00193184637
Iter: 452 loss: 0.00193230854
Iter: 453 loss: 0.00193184544
Iter: 454 loss: 0.00193182018
Iter: 455 loss: 0.00193176977
Iter: 456 loss: 0.0019329919
Iter: 457 loss: 0.00193177
Iter: 458 loss: 0.00193172554
Iter: 459 loss: 0.00193179224
Iter: 460 loss: 0.00193170598
Iter: 461 loss: 0.00193166395
Iter: 462 loss: 0.0019317742
Iter: 463 loss: 0.00193164905
Iter: 464 loss: 0.00193160109
Iter: 465 loss: 0.00193173578
Iter: 466 loss: 0.00193158607
Iter: 467 loss: 0.00193153694
Iter: 468 loss: 0.00193162193
Iter: 469 loss: 0.00193151715
Iter: 470 loss: 0.00193146407
Iter: 471 loss: 0.00193153333
Iter: 472 loss: 0.00193143566
Iter: 473 loss: 0.00193138106
Iter: 474 loss: 0.00193173217
Iter: 475 loss: 0.00193137326
Iter: 476 loss: 0.00193132262
Iter: 477 loss: 0.00193174486
Iter: 478 loss: 0.00193131855
Iter: 479 loss: 0.00193128537
Iter: 480 loss: 0.00193127093
Iter: 481 loss: 0.00193125731
Iter: 482 loss: 0.00193121331
Iter: 483 loss: 0.0019312565
Iter: 484 loss: 0.00193119061
Iter: 485 loss: 0.00193118432
Iter: 486 loss: 0.00193116791
Iter: 487 loss: 0.00193114963
Iter: 488 loss: 0.00193112809
Iter: 489 loss: 0.00193112541
Iter: 490 loss: 0.0019310927
Iter: 491 loss: 0.00193106476
Iter: 492 loss: 0.00193105754
Iter: 493 loss: 0.0019310154
Iter: 494 loss: 0.00193113694
Iter: 495 loss: 0.00193100295
Iter: 496 loss: 0.00193095545
Iter: 497 loss: 0.00193113426
Iter: 498 loss: 0.00193094532
Iter: 499 loss: 0.00193090434
Iter: 500 loss: 0.00193098374
Iter: 501 loss: 0.00193088525
Iter: 502 loss: 0.00193083752
Iter: 503 loss: 0.00193087605
Iter: 504 loss: 0.00193080958
Iter: 505 loss: 0.00193075533
Iter: 506 loss: 0.00193105242
Iter: 507 loss: 0.00193074858
Iter: 508 loss: 0.00193070888
Iter: 509 loss: 0.00193126453
Iter: 510 loss: 0.001930709
Iter: 511 loss: 0.00193067931
Iter: 512 loss: 0.00193066313
Iter: 513 loss: 0.00193065056
Iter: 514 loss: 0.00193061377
Iter: 515 loss: 0.0019306289
Iter: 516 loss: 0.00193058886
Iter: 517 loss: 0.0019305785
Iter: 518 loss: 0.00193056534
Iter: 519 loss: 0.00193054625
Iter: 520 loss: 0.00193054206
Iter: 521 loss: 0.00193052844
Iter: 522 loss: 0.00193050713
Iter: 523 loss: 0.00193048292
Iter: 524 loss: 0.00193047896
Iter: 525 loss: 0.00193043938
Iter: 526 loss: 0.00193051773
Iter: 527 loss: 0.00193042145
Iter: 528 loss: 0.0019303814
Iter: 529 loss: 0.00193044264
Iter: 530 loss: 0.00193036068
Iter: 531 loss: 0.00193032273
Iter: 532 loss: 0.00193080027
Iter: 533 loss: 0.00193032261
Iter: 534 loss: 0.00193029095
Iter: 535 loss: 0.00193024229
Iter: 536 loss: 0.0019302431
Iter: 537 loss: 0.00193019875
Iter: 538 loss: 0.00193080353
Iter: 539 loss: 0.00193019887
Iter: 540 loss: 0.00193017034
Iter: 541 loss: 0.00193046825
Iter: 542 loss: 0.00193017232
Iter: 543 loss: 0.00193014543
Iter: 544 loss: 0.00193017058
Iter: 545 loss: 0.00193013356
Iter: 546 loss: 0.0019301062
Iter: 547 loss: 0.00193008513
Iter: 548 loss: 0.00193007849
Iter: 549 loss: 0.00193007162
Iter: 550 loss: 0.00193006045
Iter: 551 loss: 0.00193004275
Iter: 552 loss: 0.00193004846
Iter: 553 loss: 0.0019300303
Iter: 554 loss: 0.00193001307
Iter: 555 loss: 0.00192999467
Iter: 556 loss: 0.00192999258
Iter: 557 loss: 0.00192996208
Iter: 558 loss: 0.00192999037
Iter: 559 loss: 0.00192994345
Iter: 560 loss: 0.00192990957
Iter: 561 loss: 0.00193000678
Iter: 562 loss: 0.00192989758
Iter: 563 loss: 0.00192986382
Iter: 564 loss: 0.0019300303
Iter: 565 loss: 0.00192985835
Iter: 566 loss: 0.00192982703
Iter: 567 loss: 0.00192989653
Iter: 568 loss: 0.00192981574
Iter: 569 loss: 0.00192978198
Iter: 570 loss: 0.00192979234
Iter: 571 loss: 0.00192976
Iter: 572 loss: 0.00192973344
Iter: 573 loss: 0.00192973402
Iter: 574 loss: 0.00192970806
Iter: 575 loss: 0.00192971807
Iter: 576 loss: 0.00192969013
Iter: 577 loss: 0.00192966196
Iter: 578 loss: 0.00192971737
Iter: 579 loss: 0.0019296488
Iter: 580 loss: 0.00192962494
Iter: 581 loss: 0.0019297665
Iter: 582 loss: 0.00192962075
Iter: 583 loss: 0.00192959164
Iter: 584 loss: 0.00192971027
Iter: 585 loss: 0.00192958547
Iter: 586 loss: 0.00192957069
Iter: 587 loss: 0.00192955462
Iter: 588 loss: 0.0019295516
Iter: 589 loss: 0.00192952424
Iter: 590 loss: 0.00192952855
Iter: 591 loss: 0.00192950515
Iter: 592 loss: 0.00192947418
Iter: 593 loss: 0.00192954391
Iter: 594 loss: 0.00192946219
Iter: 595 loss: 0.00192942331
Iter: 596 loss: 0.00192954647
Iter: 597 loss: 0.00192941085
Iter: 598 loss: 0.00192937767
Iter: 599 loss: 0.00192954345
Iter: 600 loss: 0.00192936976
Iter: 601 loss: 0.0019293403
Iter: 602 loss: 0.00192935066
Iter: 603 loss: 0.0019293197
Iter: 604 loss: 0.00192928698
Iter: 605 loss: 0.0019295013
Iter: 606 loss: 0.00192928419
Iter: 607 loss: 0.00192924892
Iter: 608 loss: 0.00192938815
Iter: 609 loss: 0.00192924018
Iter: 610 loss: 0.00192921725
Iter: 611 loss: 0.00192923774
Iter: 612 loss: 0.00192920398
Iter: 613 loss: 0.00192918046
Iter: 614 loss: 0.00192926405
Iter: 615 loss: 0.00192917418
Iter: 616 loss: 0.00192914682
Iter: 617 loss: 0.00192940189
Iter: 618 loss: 0.0019291467
Iter: 619 loss: 0.00192913308
Iter: 620 loss: 0.00192911
Iter: 621 loss: 0.00192910829
Iter: 622 loss: 0.0019290857
Iter: 623 loss: 0.00192911748
Iter: 624 loss: 0.00192907243
Iter: 625 loss: 0.00192904135
Iter: 626 loss: 0.00192908035
Iter: 627 loss: 0.00192902505
Iter: 628 loss: 0.00192898652
Iter: 629 loss: 0.00192903425
Iter: 630 loss: 0.00192896696
Iter: 631 loss: 0.00192893145
Iter: 632 loss: 0.00192942866
Iter: 633 loss: 0.00192893052
Iter: 634 loss: 0.00192890642
Iter: 635 loss: 0.00192888547
Iter: 636 loss: 0.00192887988
Iter: 637 loss: 0.00192884798
Iter: 638 loss: 0.00192911283
Iter: 639 loss: 0.00192884495
Iter: 640 loss: 0.00192881795
Iter: 641 loss: 0.00192899874
Iter: 642 loss: 0.0019288148
Iter: 643 loss: 0.00192878954
Iter: 644 loss: 0.00192878395
Iter: 645 loss: 0.00192876824
Iter: 646 loss: 0.00192874251
Iter: 647 loss: 0.00192882947
Iter: 648 loss: 0.00192873413
Iter: 649 loss: 0.00192871
Iter: 650 loss: 0.00192870887
Iter: 651 loss: 0.00192869734
Iter: 652 loss: 0.00192867429
Iter: 653 loss: 0.00192918826
Iter: 654 loss: 0.00192867289
Iter: 655 loss: 0.00192864961
Iter: 656 loss: 0.00192866055
Iter: 657 loss: 0.00192862889
Iter: 658 loss: 0.00192859501
Iter: 659 loss: 0.00192870107
Iter: 660 loss: 0.00192858302
Iter: 661 loss: 0.00192854926
Iter: 662 loss: 0.00192859792
Iter: 663 loss: 0.0019285318
Iter: 664 loss: 0.00192849315
Iter: 665 loss: 0.00192866963
Iter: 666 loss: 0.00192848686
Iter: 667 loss: 0.00192845147
Iter: 668 loss: 0.00192858628
Iter: 669 loss: 0.00192844355
Iter: 670 loss: 0.00192841422
Iter: 671 loss: 0.0019284318
Iter: 672 loss: 0.00192839641
Iter: 673 loss: 0.00192837196
Iter: 674 loss: 0.00192837219
Iter: 675 loss: 0.00192835042
Iter: 676 loss: 0.00192831678
Iter: 677 loss: 0.00192831899
Iter: 678 loss: 0.00192828337
Iter: 679 loss: 0.00192851119
Iter: 680 loss: 0.00192827848
Iter: 681 loss: 0.0019282673
Iter: 682 loss: 0.0019282616
Iter: 683 loss: 0.00192825077
Iter: 684 loss: 0.00192822097
Iter: 685 loss: 0.00192842376
Iter: 686 loss: 0.00192821294
Iter: 687 loss: 0.00192818185
Iter: 688 loss: 0.00192828279
Iter: 689 loss: 0.00192817347
Iter: 690 loss: 0.00192813564
Iter: 691 loss: 0.00192814297
Iter: 692 loss: 0.00192810968
Iter: 693 loss: 0.00192807056
Iter: 694 loss: 0.00192832726
Iter: 695 loss: 0.00192806649
Iter: 696 loss: 0.00192803144
Iter: 697 loss: 0.00192805624
Iter: 698 loss: 0.00192800967
Iter: 699 loss: 0.00192796881
Iter: 700 loss: 0.00192828022
Iter: 701 loss: 0.00192796602
Iter: 702 loss: 0.00192793761
Iter: 703 loss: 0.00192793226
Iter: 704 loss: 0.001927912
Iter: 705 loss: 0.00192788779
Iter: 706 loss: 0.00192788488
Iter: 707 loss: 0.0019278602
Iter: 708 loss: 0.001927851
Iter: 709 loss: 0.00192783796
Iter: 710 loss: 0.00192780886
Iter: 711 loss: 0.00192781375
Iter: 712 loss: 0.00192778825
Iter: 713 loss: 0.00192776916
Iter: 714 loss: 0.00192776904
Iter: 715 loss: 0.00192775461
Iter: 716 loss: 0.00192772876
Iter: 717 loss: 0.00192820898
Iter: 718 loss: 0.0019277262
Iter: 719 loss: 0.00192769361
Iter: 720 loss: 0.00192773307
Iter: 721 loss: 0.00192767498
Iter: 722 loss: 0.00192764052
Iter: 723 loss: 0.00192770013
Iter: 724 loss: 0.00192762411
Iter: 725 loss: 0.00192758
Iter: 726 loss: 0.00192768569
Iter: 727 loss: 0.00192756648
Iter: 728 loss: 0.0019275269
Iter: 729 loss: 0.00192760199
Iter: 730 loss: 0.00192751
Iter: 731 loss: 0.00192746916
Iter: 732 loss: 0.00192783517
Iter: 733 loss: 0.00192746788
Iter: 734 loss: 0.00192743936
Iter: 735 loss: 0.00192741072
Iter: 736 loss: 0.00192740583
Iter: 737 loss: 0.00192736532
Iter: 738 loss: 0.00192791666
Iter: 739 loss: 0.00192736601
Iter: 740 loss: 0.00192733528
Iter: 741 loss: 0.00192755694
Iter: 742 loss: 0.00192733377
Iter: 743 loss: 0.00192731619
Iter: 744 loss: 0.00192731421
Iter: 745 loss: 0.00192730071
Iter: 746 loss: 0.0019272886
Iter: 747 loss: 0.00192728476
Iter: 748 loss: 0.00192727451
Iter: 749 loss: 0.00192725239
Iter: 750 loss: 0.00192763447
Iter: 751 loss: 0.00192725135
Iter: 752 loss: 0.00192722632
Iter: 753 loss: 0.00192725973
Iter: 754 loss: 0.00192721246
Iter: 755 loss: 0.00192718336
Iter: 756 loss: 0.00192722469
Iter: 757 loss: 0.00192716881
Iter: 758 loss: 0.00192713214
Iter: 759 loss: 0.00192720769
Iter: 760 loss: 0.00192711898
Iter: 761 loss: 0.00192708266
Iter: 762 loss: 0.00192716822
Iter: 763 loss: 0.00192706787
Iter: 764 loss: 0.00192703295
Iter: 765 loss: 0.00192725193
Iter: 766 loss: 0.00192702841
Iter: 767 loss: 0.00192699162
Iter: 768 loss: 0.00192699756
Iter: 769 loss: 0.00192696531
Iter: 770 loss: 0.0019269241
Iter: 771 loss: 0.00192713877
Iter: 772 loss: 0.00192691688
Iter: 773 loss: 0.00192688359
Iter: 774 loss: 0.00192734192
Iter: 775 loss: 0.0019268851
Iter: 776 loss: 0.00192686892
Iter: 777 loss: 0.00192687137
Iter: 778 loss: 0.001926856
Iter: 779 loss: 0.00192684215
Iter: 780 loss: 0.00192684121
Iter: 781 loss: 0.00192682724
Iter: 782 loss: 0.00192680489
Iter: 783 loss: 0.00192680489
Iter: 784 loss: 0.00192678138
Iter: 785 loss: 0.00192682026
Iter: 786 loss: 0.00192677067
Iter: 787 loss: 0.0019267418
Iter: 788 loss: 0.00192674086
Iter: 789 loss: 0.0019267184
Iter: 790 loss: 0.00192668091
Iter: 791 loss: 0.00192687032
Iter: 792 loss: 0.00192667742
Iter: 793 loss: 0.00192664331
Iter: 794 loss: 0.00192668277
Iter: 795 loss: 0.00192662375
Iter: 796 loss: 0.00192658976
Iter: 797 loss: 0.00192677497
Iter: 798 loss: 0.00192658557
Iter: 799 loss: 0.00192654692
Iter: 800 loss: 0.00192658114
Iter: 801 loss: 0.00192652433
Iter: 802 loss: 0.00192649267
Iter: 803 loss: 0.00192662701
Iter: 804 loss: 0.00192648394
Iter: 805 loss: 0.00192645693
Iter: 806 loss: 0.00192681036
Iter: 807 loss: 0.00192645576
Iter: 808 loss: 0.00192643667
Iter: 809 loss: 0.00192644261
Iter: 810 loss: 0.00192642305
Iter: 811 loss: 0.00192640722
Iter: 812 loss: 0.00192640699
Iter: 813 loss: 0.00192639139
Iter: 814 loss: 0.00192637765
Iter: 815 loss: 0.00192637357
Iter: 816 loss: 0.00192635669
Iter: 817 loss: 0.00192637148
Iter: 818 loss: 0.00192634342
Iter: 819 loss: 0.00192631944
Iter: 820 loss: 0.00192631921
Iter: 821 loss: 0.0019262979
Iter: 822 loss: 0.00192626333
Iter: 823 loss: 0.00192642095
Iter: 824 loss: 0.00192625716
Iter: 825 loss: 0.0019262291
Iter: 826 loss: 0.00192631152
Iter: 827 loss: 0.00192622154
Iter: 828 loss: 0.00192619464
Iter: 829 loss: 0.0019262589
Iter: 830 loss: 0.00192618789
Iter: 831 loss: 0.00192615751
Iter: 832 loss: 0.00192628475
Iter: 833 loss: 0.00192615157
Iter: 834 loss: 0.00192612689
Iter: 835 loss: 0.00192616438
Iter: 836 loss: 0.00192611397
Iter: 837 loss: 0.00192610023
Iter: 838 loss: 0.00192609942
Iter: 839 loss: 0.00192608777
Iter: 840 loss: 0.00192608696
Iter: 841 loss: 0.00192607834
Iter: 842 loss: 0.00192606624
Iter: 843 loss: 0.00192620629
Iter: 844 loss: 0.00192606612
Iter: 845 loss: 0.00192605413
Iter: 846 loss: 0.00192605308
Iter: 847 loss: 0.00192604552
Iter: 848 loss: 0.00192603387
Iter: 849 loss: 0.00192602398
Iter: 850 loss: 0.00192602095
Iter: 851 loss: 0.00192599685
Iter: 852 loss: 0.00192602724
Iter: 853 loss: 0.00192598556
Iter: 854 loss: 0.00192596111
Iter: 855 loss: 0.00192606356
Iter: 856 loss: 0.00192595494
Iter: 857 loss: 0.00192593806
Iter: 858 loss: 0.00192597718
Iter: 859 loss: 0.00192592887
Iter: 860 loss: 0.00192590826
Iter: 861 loss: 0.00192597369
Iter: 862 loss: 0.00192590302
Iter: 863 loss: 0.00192588009
Iter: 864 loss: 0.00192594202
Iter: 865 loss: 0.00192587124
Iter: 866 loss: 0.00192585075
Iter: 867 loss: 0.00192594784
Iter: 868 loss: 0.00192584726
Iter: 869 loss: 0.00192583457
Iter: 870 loss: 0.00192595343
Iter: 871 loss: 0.00192583352
Iter: 872 loss: 0.0019258213
Iter: 873 loss: 0.00192583993
Iter: 874 loss: 0.0019258149
Iter: 875 loss: 0.00192580745
Iter: 876 loss: 0.00192586926
Iter: 877 loss: 0.001925805
Iter: 878 loss: 0.00192579627
Iter: 879 loss: 0.00192579196
Iter: 880 loss: 0.00192578731
Iter: 881 loss: 0.00192577566
Iter: 882 loss: 0.00192576391
Iter: 883 loss: 0.00192576146
Iter: 884 loss: 0.00192574
Iter: 885 loss: 0.00192577345
Iter: 886 loss: 0.00192573201
Iter: 887 loss: 0.00192570768
Iter: 888 loss: 0.00192582421
Iter: 889 loss: 0.001925705
Iter: 890 loss: 0.00192568963
Iter: 891 loss: 0.00192570046
Iter: 892 loss: 0.00192567916
Iter: 893 loss: 0.00192565692
Iter: 894 loss: 0.00192572922
Iter: 895 loss: 0.00192565145
Iter: 896 loss: 0.00192562968
Iter: 897 loss: 0.00192572945
Iter: 898 loss: 0.00192562747
Iter: 899 loss: 0.00192561094
Iter: 900 loss: 0.00192567869
Iter: 901 loss: 0.00192560733
Iter: 902 loss: 0.00192559487
Iter: 903 loss: 0.00192568637
Iter: 904 loss: 0.00192559417
Iter: 905 loss: 0.00192558323
Iter: 906 loss: 0.00192562514
Iter: 907 loss: 0.00192557892
Iter: 908 loss: 0.00192557147
Iter: 909 loss: 0.00192559406
Iter: 910 loss: 0.00192556926
Iter: 911 loss: 0.00192555843
Iter: 912 loss: 0.00192556623
Iter: 913 loss: 0.00192555157
Iter: 914 loss: 0.00192554109
Iter: 915 loss: 0.00192553352
Iter: 916 loss: 0.00192553061
Iter: 917 loss: 0.00192551455
Iter: 918 loss: 0.0019255355
Iter: 919 loss: 0.00192550768
Iter: 920 loss: 0.00192549103
Iter: 921 loss: 0.00192559906
Iter: 922 loss: 0.0019254887
Iter: 923 loss: 0.00192547846
Iter: 924 loss: 0.00192547659
Iter: 925 loss: 0.0019254681
Iter: 926 loss: 0.00192544993
Iter: 927 loss: 0.00192553806
Iter: 928 loss: 0.00192544959
Iter: 929 loss: 0.00192543375
Iter: 930 loss: 0.00192549196
Iter: 931 loss: 0.00192543026
Iter: 932 loss: 0.00192541839
Iter: 933 loss: 0.00192547403
Iter: 934 loss: 0.00192541571
Iter: 935 loss: 0.00192540779
Iter: 936 loss: 0.00192544505
Iter: 937 loss: 0.00192540511
Iter: 938 loss: 0.00192539394
Iter: 939 loss: 0.00192545634
Iter: 940 loss: 0.00192539277
Iter: 941 loss: 0.00192538556
Iter: 942 loss: 0.00192539755
Iter: 943 loss: 0.00192538532
Iter: 944 loss: 0.00192537624
Iter: 945 loss: 0.00192539371
Iter: 946 loss: 0.0019253717
Iter: 947 loss: 0.00192536553
Iter: 948 loss: 0.00192535797
Iter: 949 loss: 0.00192535587
Iter: 950 loss: 0.00192534598
Iter: 951 loss: 0.0019253717
Iter: 952 loss: 0.00192534
Iter: 953 loss: 0.00192533107
Iter: 954 loss: 0.00192536647
Iter: 955 loss: 0.00192532793
Iter: 956 loss: 0.00192531943
Iter: 957 loss: 0.00192533084
Iter: 958 loss: 0.00192531175
Iter: 959 loss: 0.00192529953
Iter: 960 loss: 0.00192533
Iter: 961 loss: 0.00192529568
Iter: 962 loss: 0.00192528334
Iter: 963 loss: 0.0019253589
Iter: 964 loss: 0.00192528381
Iter: 965 loss: 0.00192527322
Iter: 966 loss: 0.0019252972
Iter: 967 loss: 0.00192527066
Iter: 968 loss: 0.0019252589
Iter: 969 loss: 0.00192530686
Iter: 970 loss: 0.00192525727
Iter: 971 loss: 0.00192524842
Iter: 972 loss: 0.00192532351
Iter: 973 loss: 0.00192524889
Iter: 974 loss: 0.00192524353
Iter: 975 loss: 0.0019252497
Iter: 976 loss: 0.00192524213
Iter: 977 loss: 0.00192523445
Iter: 978 loss: 0.00192527194
Iter: 979 loss: 0.00192523131
Iter: 980 loss: 0.00192522991
Iter: 981 loss: 0.00192521943
Iter: 982 loss: 0.00192540861
Iter: 983 loss: 0.00192522106
Iter: 984 loss: 0.0019252114
Iter: 985 loss: 0.0019252419
Iter: 986 loss: 0.00192520896
Iter: 987 loss: 0.00192519743
Iter: 988 loss: 0.00192521699
Iter: 989 loss: 0.00192519487
Iter: 990 loss: 0.00192518637
Iter: 991 loss: 0.00192520663
Iter: 992 loss: 0.0019251823
Iter: 993 loss: 0.00192517089
Iter: 994 loss: 0.00192519906
Iter: 995 loss: 0.00192516658
Iter: 996 loss: 0.00192515715
Iter: 997 loss: 0.00192520383
Iter: 998 loss: 0.00192515482
Iter: 999 loss: 0.00192514551
Iter: 1000 loss: 0.00192517031
Iter: 1001 loss: 0.0019251433
Iter: 1002 loss: 0.00192513363
Iter: 1003 loss: 0.00192517415
Iter: 1004 loss: 0.00192513235
Iter: 1005 loss: 0.00192512525
Iter: 1006 loss: 0.00192519045
Iter: 1007 loss: 0.00192512432
Iter: 1008 loss: 0.00192512
Iter: 1009 loss: 0.00192512432
Iter: 1010 loss: 0.00192511745
Iter: 1011 loss: 0.0019251121
Iter: 1012 loss: 0.00192515599
Iter: 1013 loss: 0.00192511128
Iter: 1014 loss: 0.00192510779
Iter: 1015 loss: 0.00192509987
Iter: 1016 loss: 0.00192522444
Iter: 1017 loss: 0.00192509848
Iter: 1018 loss: 0.00192509056
Iter: 1019 loss: 0.00192512886
Iter: 1020 loss: 0.00192509033
Iter: 1021 loss: 0.00192508264
Iter: 1022 loss: 0.00192509
Iter: 1023 loss: 0.00192507752
Iter: 1024 loss: 0.00192506984
Iter: 1025 loss: 0.00192508753
Iter: 1026 loss: 0.00192506518
Iter: 1027 loss: 0.00192505424
Iter: 1028 loss: 0.00192509172
Iter: 1029 loss: 0.00192505273
Iter: 1030 loss: 0.00192504493
Iter: 1031 loss: 0.00192506565
Iter: 1032 loss: 0.00192504132
Iter: 1033 loss: 0.00192503375
Iter: 1034 loss: 0.00192508369
Iter: 1035 loss: 0.00192503282
Iter: 1036 loss: 0.00192502537
Iter: 1037 loss: 0.00192504411
Iter: 1038 loss: 0.00192502234
Iter: 1039 loss: 0.00192501699
Iter: 1040 loss: 0.00192508439
Iter: 1041 loss: 0.00192501664
Iter: 1042 loss: 0.00192501338
Iter: 1043 loss: 0.00192501722
Iter: 1044 loss: 0.00192501163
Iter: 1045 loss: 0.00192500791
Iter: 1046 loss: 0.00192504132
Iter: 1047 loss: 0.00192500697
Iter: 1048 loss: 0.00192500371
Iter: 1049 loss: 0.00192499696
Iter: 1050 loss: 0.00192509464
Iter: 1051 loss: 0.00192499557
Iter: 1052 loss: 0.00192498788
Iter: 1053 loss: 0.0019250121
Iter: 1054 loss: 0.00192498707
Iter: 1055 loss: 0.00192497903
Iter: 1056 loss: 0.00192499475
Iter: 1057 loss: 0.00192497578
Iter: 1058 loss: 0.00192496879
Iter: 1059 loss: 0.00192498683
Iter: 1060 loss: 0.00192496658
Iter: 1061 loss: 0.00192495866
Iter: 1062 loss: 0.00192498497
Iter: 1063 loss: 0.0019249554
Iter: 1064 loss: 0.00192494877
Iter: 1065 loss: 0.0019249724
Iter: 1066 loss: 0.00192494621
Iter: 1067 loss: 0.00192494038
Iter: 1068 loss: 0.00192497706
Iter: 1069 loss: 0.00192493887
Iter: 1070 loss: 0.0019249327
Iter: 1071 loss: 0.00192495168
Iter: 1072 loss: 0.00192493177
Iter: 1073 loss: 0.00192492735
Iter: 1074 loss: 0.00192498777
Iter: 1075 loss: 0.00192492944
Iter: 1076 loss: 0.00192492595
Iter: 1077 loss: 0.00192492537
Iter: 1078 loss: 0.00192492269
Iter: 1079 loss: 0.0019249199
Iter: 1080 loss: 0.00192494853
Iter: 1081 loss: 0.00192492013
Iter: 1082 loss: 0.00192491664
Iter: 1083 loss: 0.00192491175
Iter: 1084 loss: 0.00192499964
Iter: 1085 loss: 0.00192491175
Iter: 1086 loss: 0.00192490639
Iter: 1087 loss: 0.00192491687
Iter: 1088 loss: 0.0019249029
Iter: 1089 loss: 0.00192489638
Iter: 1090 loss: 0.00192491664
Iter: 1091 loss: 0.00192489463
Iter: 1092 loss: 0.00192488951
Iter: 1093 loss: 0.00192490418
Iter: 1094 loss: 0.00192488579
Iter: 1095 loss: 0.00192488078
Iter: 1096 loss: 0.00192489033
Iter: 1097 loss: 0.00192487705
Iter: 1098 loss: 0.00192487065
Iter: 1099 loss: 0.00192490243
Iter: 1100 loss: 0.00192486891
Iter: 1101 loss: 0.00192486309
Iter: 1102 loss: 0.00192488765
Iter: 1103 loss: 0.00192486309
Iter: 1104 loss: 0.0019248582
Iter: 1105 loss: 0.00192487903
Iter: 1106 loss: 0.0019248561
Iter: 1107 loss: 0.00192485354
Iter: 1108 loss: 0.00192488893
Iter: 1109 loss: 0.00192485342
Iter: 1110 loss: 0.00192485098
Iter: 1111 loss: 0.00192485237
Iter: 1112 loss: 0.00192484818
Iter: 1113 loss: 0.00192484551
Iter: 1114 loss: 0.00192487426
Iter: 1115 loss: 0.00192484562
Iter: 1116 loss: 0.00192484283
Iter: 1117 loss: 0.00192483782
Iter: 1118 loss: 0.0019249086
Iter: 1119 loss: 0.00192483829
Iter: 1120 loss: 0.0019248327
Iter: 1121 loss: 0.00192485016
Iter: 1122 loss: 0.00192483212
Iter: 1123 loss: 0.0019248256
Iter: 1124 loss: 0.00192483328
Iter: 1125 loss: 0.00192482362
Iter: 1126 loss: 0.00192481687
Iter: 1127 loss: 0.0019248412
Iter: 1128 loss: 0.00192481489
Iter: 1129 loss: 0.00192481012
Iter: 1130 loss: 0.00192481291
Iter: 1131 loss: 0.00192480604
Iter: 1132 loss: 0.0019248
Iter: 1133 loss: 0.00192484271
Iter: 1134 loss: 0.0019248
Iter: 1135 loss: 0.00192479452
Iter: 1136 loss: 0.00192481757
Iter: 1137 loss: 0.00192479254
Iter: 1138 loss: 0.00192478951
Iter: 1139 loss: 0.00192479789
Iter: 1140 loss: 0.00192478765
Iter: 1141 loss: 0.00192478497
Iter: 1142 loss: 0.00192481466
Iter: 1143 loss: 0.00192478346
Iter: 1144 loss: 0.00192478043
Iter: 1145 loss: 0.00192478893
Iter: 1146 loss: 0.0019247795
Iter: 1147 loss: 0.0019247767
Iter: 1148 loss: 0.00192480208
Iter: 1149 loss: 0.00192477764
Iter: 1150 loss: 0.00192477752
Iter: 1151 loss: 0.00192477321
Iter: 1152 loss: 0.00192481629
Iter: 1153 loss: 0.00192477135
Iter: 1154 loss: 0.00192476728
Iter: 1155 loss: 0.00192478171
Iter: 1156 loss: 0.00192476483
Iter: 1157 loss: 0.00192475948
Iter: 1158 loss: 0.00192476797
Iter: 1159 loss: 0.00192475691
Iter: 1160 loss: 0.00192475156
Iter: 1161 loss: 0.00192477601
Iter: 1162 loss: 0.00192475168
Iter: 1163 loss: 0.00192474632
Iter: 1164 loss: 0.00192474958
Iter: 1165 loss: 0.00192474306
Iter: 1166 loss: 0.00192473619
Iter: 1167 loss: 0.00192476844
Iter: 1168 loss: 0.00192473596
Iter: 1169 loss: 0.00192473235
Iter: 1170 loss: 0.00192475831
Iter: 1171 loss: 0.00192473142
Iter: 1172 loss: 0.00192472816
Iter: 1173 loss: 0.00192474353
Iter: 1174 loss: 0.00192472606
Iter: 1175 loss: 0.00192472374
Iter: 1176 loss: 0.00192474842
Iter: 1177 loss: 0.00192472409
Iter: 1178 loss: 0.00192472269
Iter: 1179 loss: 0.00192472525
Iter: 1180 loss: 0.00192472152
Iter: 1181 loss: 0.00192471768
Iter: 1182 loss: 0.00192473421
Iter: 1183 loss: 0.0019247185
Iter: 1184 loss: 0.00192471687
Iter: 1185 loss: 0.00192471268
Iter: 1186 loss: 0.00192477414
Iter: 1187 loss: 0.00192471268
Iter: 1188 loss: 0.00192470918
Iter: 1189 loss: 0.00192471757
Iter: 1190 loss: 0.00192470627
Iter: 1191 loss: 0.00192470197
Iter: 1192 loss: 0.00192472071
Iter: 1193 loss: 0.00192470127
Iter: 1194 loss: 0.00192469731
Iter: 1195 loss: 0.00192470942
Iter: 1196 loss: 0.00192469591
Iter: 1197 loss: 0.0019246923
Iter: 1198 loss: 0.00192469265
Iter: 1199 loss: 0.00192468951
Iter: 1200 loss: 0.0019246852
Iter: 1201 loss: 0.00192471524
Iter: 1202 loss: 0.00192468381
Iter: 1203 loss: 0.00192468101
Iter: 1204 loss: 0.00192469696
Iter: 1205 loss: 0.00192468066
Iter: 1206 loss: 0.00192467752
Iter: 1207 loss: 0.00192468707
Iter: 1208 loss: 0.00192467752
Iter: 1209 loss: 0.00192467519
Iter: 1210 loss: 0.00192469475
Iter: 1211 loss: 0.00192467368
Iter: 1212 loss: 0.00192467181
Iter: 1213 loss: 0.00192467775
Iter: 1214 loss: 0.00192467135
Iter: 1215 loss: 0.0019246703
Iter: 1216 loss: 0.00192468334
Iter: 1217 loss: 0.00192467053
Iter: 1218 loss: 0.00192466704
Iter: 1219 loss: 0.00192466367
Iter: 1220 loss: 0.00192466425
Iter: 1221 loss: 0.00192466122
Iter: 1222 loss: 0.00192466425
Iter: 1223 loss: 0.00192465982
Iter: 1224 loss: 0.00192465587
Iter: 1225 loss: 0.00192467403
Iter: 1226 loss: 0.00192465726
Iter: 1227 loss: 0.00192465179
Iter: 1228 loss: 0.00192465971
Iter: 1229 loss: 0.00192465319
Iter: 1230 loss: 0.00192464935
Iter: 1231 loss: 0.00192464911
Iter: 1232 loss: 0.0019246476
Iter: 1233 loss: 0.00192464353
Iter: 1234 loss: 0.0019246731
Iter: 1235 loss: 0.00192464248
Iter: 1236 loss: 0.00192464096
Iter: 1237 loss: 0.00192464772
Iter: 1238 loss: 0.00192463992
Iter: 1239 loss: 0.00192463631
Iter: 1240 loss: 0.0019246497
Iter: 1241 loss: 0.00192463677
Iter: 1242 loss: 0.00192463328
Iter: 1243 loss: 0.00192465156
Iter: 1244 loss: 0.00192463503
Iter: 1245 loss: 0.00192463235
Iter: 1246 loss: 0.00192463631
Iter: 1247 loss: 0.00192463107
Iter: 1248 loss: 0.0019246313
Iter: 1249 loss: 0.00192464248
Iter: 1250 loss: 0.00192463037
Iter: 1251 loss: 0.00192463095
Iter: 1252 loss: 0.00192462769
Iter: 1253 loss: 0.00192462711
Iter: 1254 loss: 0.00192462641
Iter: 1255 loss: 0.00192462618
Iter: 1256 loss: 0.0019246242
Iter: 1257 loss: 0.00192462187
Iter: 1258 loss: 0.00192462979
Iter: 1259 loss: 0.00192462141
Iter: 1260 loss: 0.00192461768
Iter: 1261 loss: 0.00192462862
Iter: 1262 loss: 0.00192461838
Iter: 1263 loss: 0.00192461605
Iter: 1264 loss: 0.00192461605
Iter: 1265 loss: 0.00192461396
Iter: 1266 loss: 0.00192461128
Iter: 1267 loss: 0.00192463491
Iter: 1268 loss: 0.00192461209
Iter: 1269 loss: 0.00192460977
Iter: 1270 loss: 0.00192461279
Iter: 1271 loss: 0.00192460965
Iter: 1272 loss: 0.00192460732
Iter: 1273 loss: 0.00192461966
Iter: 1274 loss: 0.00192460662
Iter: 1275 loss: 0.00192460441
Iter: 1276 loss: 0.00192461978
Iter: 1277 loss: 0.00192460429
Iter: 1278 loss: 0.00192460185
Iter: 1279 loss: 0.00192460534
Iter: 1280 loss: 0.00192460325
Iter: 1281 loss: 0.00192460243
Iter: 1282 loss: 0.00192460837
Iter: 1283 loss: 0.00192460115
Iter: 1284 loss: 0.00192460115
Iter: 1285 loss: 0.00192459871
Iter: 1286 loss: 0.00192460045
Iter: 1287 loss: 0.00192459871
Iter: 1288 loss: 0.00192459812
Iter: 1289 loss: 0.00192459906
Iter: 1290 loss: 0.00192459603
Iter: 1291 loss: 0.00192460069
Iter: 1292 loss: 0.00192459463
Iter: 1293 loss: 0.00192459265
Iter: 1294 loss: 0.00192459801
Iter: 1295 loss: 0.00192459323
Iter: 1296 loss: 0.00192459009
Iter: 1297 loss: 0.00192458986
Iter: 1298 loss: 0.00192459
Iter: 1299 loss: 0.00192458823
Iter: 1300 loss: 0.00192460301
Iter: 1301 loss: 0.00192458834
Iter: 1302 loss: 0.00192458625
Iter: 1303 loss: 0.00192459149
Iter: 1304 loss: 0.00192458567
Iter: 1305 loss: 0.00192458287
Iter: 1306 loss: 0.00192459009
Iter: 1307 loss: 0.00192458392
Iter: 1308 loss: 0.00192458148
Iter: 1309 loss: 0.00192459871
Iter: 1310 loss: 0.00192458171
Iter: 1311 loss: 0.00192458229
Iter: 1312 loss: 0.00192458357
Iter: 1313 loss: 0.00192458089
Iter: 1314 loss: 0.0019245795
Iter: 1315 loss: 0.00192458485
Iter: 1316 loss: 0.00192458183
Iter: 1317 loss: 0.00192457926
Iter: 1318 loss: 0.0019245795
Iter: 1319 loss: 0.00192457833
Iter: 1320 loss: 0.00192457833
Iter: 1321 loss: 0.00192457705
Iter: 1322 loss: 0.00192457635
Iter: 1323 loss: 0.001924576
Iter: 1324 loss: 0.00192458101
Iter: 1325 loss: 0.00192457414
Iter: 1326 loss: 0.00192457566
Iter: 1327 loss: 0.001924576
Iter: 1328 loss: 0.00192457286
Iter: 1329 loss: 0.00192457321
Iter: 1330 loss: 0.00192457426
Iter: 1331 loss: 0.00192457158
Iter: 1332 loss: 0.00192457088
Iter: 1333 loss: 0.00192457787
Iter: 1334 loss: 0.0019245696
Iter: 1335 loss: 0.00192456914
Iter: 1336 loss: 0.00192457298
Iter: 1337 loss: 0.00192456821
Iter: 1338 loss: 0.00192456786
Iter: 1339 loss: 0.00192457181
Iter: 1340 loss: 0.00192456762
Iter: 1341 loss: 0.00192456576
Iter: 1342 loss: 0.00192456739
Iter: 1343 loss: 0.00192456495
Iter: 1344 loss: 0.00192456506
Iter: 1345 loss: 0.00192456599
Iter: 1346 loss: 0.00192456413
Iter: 1347 loss: 0.00192456855
Iter: 1348 loss: 0.00192456483
Iter: 1349 loss: 0.0019245625
Iter: 1350 loss: 0.00192456273
Iter: 1351 loss: 0.0019245625
Iter: 1352 loss: 0.0019245618
Iter: 1353 loss: 0.0019245618
Iter: 1354 loss: 0.00192456064
Iter: 1355 loss: 0.00192456099
Iter: 1356 loss: 0.00192456529
Iter: 1357 loss: 0.00192455866
Iter: 1358 loss: 0.00192455831
Iter: 1359 loss: 0.00192455831
Iter: 1360 loss: 0.00192455878
Iter: 1361 loss: 0.00192455715
Iter: 1362 loss: 0.00192455924
Iter: 1363 loss: 0.00192455575
Iter: 1364 loss: 0.00192455482
Iter: 1365 loss: 0.0019245632
Iter: 1366 loss: 0.00192455505
Iter: 1367 loss: 0.00192455435
Iter: 1368 loss: 0.00192455621
Iter: 1369 loss: 0.00192455284
Iter: 1370 loss: 0.00192455202
Iter: 1371 loss: 0.00192455505
Iter: 1372 loss: 0.00192455214
Iter: 1373 loss: 0.00192455272
Iter: 1374 loss: 0.00192456495
Iter: 1375 loss: 0.00192455132
Iter: 1376 loss: 0.00192455132
Iter: 1377 loss: 0.00192455051
Iter: 1378 loss: 0.00192454923
Iter: 1379 loss: 0.0019245497
Iter: 1380 loss: 0.00192455202
Iter: 1381 loss: 0.00192454888
Iter: 1382 loss: 0.00192454748
Iter: 1383 loss: 0.00192454853
Iter: 1384 loss: 0.00192454923
Iter: 1385 loss: 0.00192454713
Iter: 1386 loss: 0.0019245462
Iter: 1387 loss: 0.00192454713
Iter: 1388 loss: 0.00192454585
Iter: 1389 loss: 0.00192454632
Iter: 1390 loss: 0.00192454527
Iter: 1391 loss: 0.00192454294
Iter: 1392 loss: 0.00192454725
Iter: 1393 loss: 0.00192454294
Iter: 1394 loss: 0.00192454108
Iter: 1395 loss: 0.00192454283
Iter: 1396 loss: 0.00192454096
Iter: 1397 loss: 0.00192453898
Iter: 1398 loss: 0.00192454562
Iter: 1399 loss: 0.00192454061
Iter: 1400 loss: 0.00192453782
Iter: 1401 loss: 0.00192453922
Iter: 1402 loss: 0.0019245384
Iter: 1403 loss: 0.00192453549
Iter: 1404 loss: 0.00192454481
Iter: 1405 loss: 0.00192453526
Iter: 1406 loss: 0.00192453433
Iter: 1407 loss: 0.00192454865
Iter: 1408 loss: 0.00192453456
Iter: 1409 loss: 0.00192453491
Iter: 1410 loss: 0.00192453398
Iter: 1411 loss: 0.00192453398
Iter: 1412 loss: 0.00192453386
Iter: 1413 loss: 0.00192453549
Iter: 1414 loss: 0.00192453386
Iter: 1415 loss: 0.0019245327
Iter: 1416 loss: 0.00192453107
Iter: 1417 loss: 0.00192453084
Iter: 1418 loss: 0.00192453142
Iter: 1419 loss: 0.00192453119
Iter: 1420 loss: 0.00192453049
Iter: 1421 loss: 0.00192452967
Iter: 1422 loss: 0.00192453223
Iter: 1423 loss: 0.00192452944
Iter: 1424 loss: 0.00192452839
Iter: 1425 loss: 0.0019245334
Iter: 1426 loss: 0.00192452816
Iter: 1427 loss: 0.00192452676
Iter: 1428 loss: 0.00192453014
Iter: 1429 loss: 0.00192452641
Iter: 1430 loss: 0.00192452548
Iter: 1431 loss: 0.00192452769
Iter: 1432 loss: 0.00192452664
Iter: 1433 loss: 0.00192452548
Iter: 1434 loss: 0.00192452653
Iter: 1435 loss: 0.00192452571
Iter: 1436 loss: 0.00192452315
Iter: 1437 loss: 0.00192452723
Iter: 1438 loss: 0.0019245242
Iter: 1439 loss: 0.00192452292
Iter: 1440 loss: 0.00192453025
Iter: 1441 loss: 0.00192452432
Iter: 1442 loss: 0.00192452234
Iter: 1443 loss: 0.00192452385
Iter: 1444 loss: 0.00192452339
Iter: 1445 loss: 0.00192452187
Iter: 1446 loss: 0.0019245228
Iter: 1447 loss: 0.00192452222
Iter: 1448 loss: 0.00192452059
Iter: 1449 loss: 0.00192452094
Iter: 1450 loss: 0.00192452059
Iter: 1451 loss: 0.00192452013
Iter: 1452 loss: 0.00192451943
Iter: 1453 loss: 0.00192452036
Iter: 1454 loss: 0.00192451885
Iter: 1455 loss: 0.00192452059
Iter: 1456 loss: 0.0019245185
Iter: 1457 loss: 0.00192451791
Iter: 1458 loss: 0.00192452304
Iter: 1459 loss: 0.00192451826
Iter: 1460 loss: 0.00192451617
Iter: 1461 loss: 0.00192451896
Iter: 1462 loss: 0.00192451663
Iter: 1463 loss: 0.00192451733
Iter: 1464 loss: 0.00192451652
Iter: 1465 loss: 0.00192451489
Iter: 1466 loss: 0.00192451477
Iter: 1467 loss: 0.00192451675
Iter: 1468 loss: 0.00192451361
Iter: 1469 loss: 0.00192451221
Iter: 1470 loss: 0.00192451919
Iter: 1471 loss: 0.00192451326
Iter: 1472 loss: 0.00192451221
Iter: 1473 loss: 0.00192452024
Iter: 1474 loss: 0.00192451279
Iter: 1475 loss: 0.00192451116
Iter: 1476 loss: 0.00192451349
Iter: 1477 loss: 0.00192451081
Iter: 1478 loss: 0.00192451151
Iter: 1479 loss: 0.00192451361
Iter: 1480 loss: 0.00192451151
Iter: 1481 loss: 0.00192450942
Iter: 1482 loss: 0.00192451151
Iter: 1483 loss: 0.00192451023
Iter: 1484 loss: 0.00192450976
Iter: 1485 loss: 0.00192451011
Iter: 1486 loss: 0.00192450825
Iter: 1487 loss: 0.00192450813
Iter: 1488 loss: 0.00192451011
Iter: 1489 loss: 0.00192450779
Iter: 1490 loss: 0.00192450627
Iter: 1491 loss: 0.00192451268
Iter: 1492 loss: 0.00192450709
Iter: 1493 loss: 0.00192450616
Iter: 1494 loss: 0.00192450709
Iter: 1495 loss: 0.00192450476
Iter: 1496 loss: 0.00192450499
Iter: 1497 loss: 0.00192450476
Iter: 1498 loss: 0.00192450499
Iter: 1499 loss: 0.00192450394
Iter: 1500 loss: 0.00192450522
Iter: 1501 loss: 0.00192450359
Iter: 1502 loss: 0.00192450266
Iter: 1503 loss: 0.00192450779
Iter: 1504 loss: 0.00192450278
Iter: 1505 loss: 0.00192450278
Iter: 1506 loss: 0.00192450662
Iter: 1507 loss: 0.00192450068
Iter: 1508 loss: 0.0019245015
Iter: 1509 loss: 0.00192450243
Iter: 1510 loss: 0.00192450243
Iter: 1511 loss: 0.00192450103
Iter: 1512 loss: 0.00192450185
Iter: 1513 loss: 0.00192449987
Iter: 1514 loss: 0.00192449964
Iter: 1515 loss: 0.0019245008
Iter: 1516 loss: 0.00192450092
Iter: 1517 loss: 0.00192449964
Iter: 1518 loss: 0.00192449754
Iter: 1519 loss: 0.0019244994
Iter: 1520 loss: 0.00192449696
Iter: 1521 loss: 0.00192450057
Iter: 1522 loss: 0.00192449708
Iter: 1523 loss: 0.00192449708
Iter: 1524 loss: 0.00192450441
Iter: 1525 loss: 0.00192449766
Iter: 1526 loss: 0.00192449626
Iter: 1527 loss: 0.00192449801
Iter: 1528 loss: 0.00192449638
Iter: 1529 loss: 0.00192449451
Iter: 1530 loss: 0.00192449545
Iter: 1531 loss: 0.00192449591
Iter: 1532 loss: 0.00192449498
Iter: 1533 loss: 0.00192449673
Iter: 1534 loss: 0.00192449568
Iter: 1535 loss: 0.00192449545
Iter: 1536 loss: 0.00192449871
Iter: 1537 loss: 0.00192449475
Iter: 1538 loss: 0.00192449556
Iter: 1539 loss: 0.00192449696
Iter: 1540 loss: 0.00192449568
Iter: 1541 loss: 0.00192449358
Iter: 1542 loss: 0.00192449545
Iter: 1543 loss: 0.00192449416
Iter: 1544 loss: 0.00192449428
Iter: 1545 loss: 0.0019244944
Iter: 1546 loss: 0.00192449335
Iter: 1547 loss: 0.0019244916
Iter: 1548 loss: 0.00192449416
Iter: 1549 loss: 0.00192449358
Iter: 1550 loss: 0.00192449428
Iter: 1551 loss: 0.00192449184
Iter: 1552 loss: 0.00192449335
Iter: 1553 loss: 0.00192448986
Iter: 1554 loss: 0.00192449335
Iter: 1555 loss: 0.00192449172
Iter: 1556 loss: 0.00192449056
Iter: 1557 loss: 0.00192449638
Iter: 1558 loss: 0.00192449056
Iter: 1559 loss: 0.00192449044
Iter: 1560 loss: 0.0019244916
Iter: 1561 loss: 0.00192448986
Iter: 1562 loss: 0.00192448951
Iter: 1563 loss: 0.00192449044
Iter: 1564 loss: 0.00192448916
Iter: 1565 loss: 0.00192448869
Iter: 1566 loss: 0.00192449021
Iter: 1567 loss: 0.00192448904
Iter: 1568 loss: 0.00192448858
Iter: 1569 loss: 0.00192449009
Iter: 1570 loss: 0.00192448811
Iter: 1571 loss: 0.00192448637
Iter: 1572 loss: 0.00192449277
Iter: 1573 loss: 0.00192448741
Iter: 1574 loss: 0.00192448555
Iter: 1575 loss: 0.00192448939
Iter: 1576 loss: 0.00192448683
Iter: 1577 loss: 0.0019244859
Iter: 1578 loss: 0.00192448567
Iter: 1579 loss: 0.00192448543
Iter: 1580 loss: 0.00192448555
Iter: 1581 loss: 0.00192448683
Iter: 1582 loss: 0.00192448555
Iter: 1583 loss: 0.00192448474
Iter: 1584 loss: 0.00192448648
Iter: 1585 loss: 0.00192448602
Iter: 1586 loss: 0.0019244845
Iter: 1587 loss: 0.00192448613
Iter: 1588 loss: 0.0019244845
Iter: 1589 loss: 0.00192448462
Iter: 1590 loss: 0.00192448916
Iter: 1591 loss: 0.00192448555
Iter: 1592 loss: 0.0019244845
Iter: 1593 loss: 0.00192448753
Iter: 1594 loss: 0.00192448357
Iter: 1595 loss: 0.00192448415
Iter: 1596 loss: 0.00192448276
Iter: 1597 loss: 0.00192448474
Iter: 1598 loss: 0.00192448345
Iter: 1599 loss: 0.00192448474
Iter: 1600 loss: 0.00192448276
Iter: 1601 loss: 0.00192448474
Iter: 1602 loss: 0.00192448497
Iter: 1603 loss: 0.00192448206
Iter: 1604 loss: 0.00192448415
Iter: 1605 loss: 0.00192448334
Iter: 1606 loss: 0.00192448334
Iter: 1607 loss: 0.00192448357
Iter: 1608 loss: 0.0019244838
Iter: 1609 loss: 0.0019244838
Iter: 1610 loss: 0.00192448299
Iter: 1611 loss: 0.00192448357
Iter: 1612 loss: 0.00192448357
Iter: 1613 loss: 0.00192448264
Iter: 1614 loss: 0.00192448217
Iter: 1615 loss: 0.00192448357
Iter: 1616 loss: 0.00192448334
Iter: 1617 loss: 0.00192448357
Iter: 1618 loss: 0.00192448357
Iter: 1619 loss: 0.00192448369
Iter: 1620 loss: 0.00192448369
Iter: 1621 loss: 0.00192448427
Iter: 1622 loss: 0.00192448404
Iter: 1623 loss: 0.00192448404
Iter: 1624 loss: 0.00192448427
Iter: 1625 loss: 0.00192448427
Iter: 1626 loss: 0.00192448427
Iter: 1627 loss: 0.00192448427
Iter: 1628 loss: 0.00192448404
Iter: 1629 loss: 0.00192448427
Iter: 1630 loss: 0.00192448322
Iter: 1631 loss: 0.00192448357
Iter: 1632 loss: 0.00192448264
Iter: 1633 loss: 0.00192448171
Iter: 1634 loss: 0.0019244838
Iter: 1635 loss: 0.00192448159
Iter: 1636 loss: 0.00192448194
Iter: 1637 loss: 0.00192448287
Iter: 1638 loss: 0.00192448148
Iter: 1639 loss: 0.00192448311
Iter: 1640 loss: 0.00192448299
Iter: 1641 loss: 0.0019244845
Iter: 1642 loss: 0.00192448171
Iter: 1643 loss: 0.00192448311
Iter: 1644 loss: 0.00192448311
Iter: 1645 loss: 0.00192448217
Iter: 1646 loss: 0.00192448229
Iter: 1647 loss: 0.00192448171
Iter: 1648 loss: 0.00192448089
Iter: 1649 loss: 0.00192448148
Iter: 1650 loss: 0.00192448264
Iter: 1651 loss: 0.00192448089
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/k3
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0
+ date
Tue Oct 27 20:27:32 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac03a8488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feae8659c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feae86597b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feae861cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feae8618730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feae8618d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac036b510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac030e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac030ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac02db510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac02db2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac030e950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac031ee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac020a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac031eea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac01baf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac01756a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac019b400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0153a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0107598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0114378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0107378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0074b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0082f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0082ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feac0050ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa0425e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa0449400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa0449e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa03f46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa03a2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa03a2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa0355400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa0355d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa0335620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7feaa02cde18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0052812472
Iter: 2 loss: 0.00526236743
Iter: 3 loss: 0.00520317676
Iter: 4 loss: 0.00529924035
Iter: 5 loss: 0.00516246213
Iter: 6 loss: 0.00515130069
Iter: 7 loss: 0.00514186081
Iter: 8 loss: 0.0051386822
Iter: 9 loss: 0.00513875578
Iter: 10 loss: 0.00513616297
Iter: 11 loss: 0.00513612293
Iter: 12 loss: 0.00513568055
Iter: 13 loss: 0.0051355185
Iter: 14 loss: 0.0051356256
Iter: 15 loss: 0.00513541512
Iter: 16 loss: 0.00513539463
Iter: 17 loss: 0.00513561023
Iter: 18 loss: 0.00513539463
Iter: 19 loss: 0.00513539277
Iter: 20 loss: 0.00513539091
Iter: 21 loss: 0.00513538858
Iter: 22 loss: 0.00513539137
Iter: 23 loss: 0.00513538904
Iter: 24 loss: 0.00513539044
Iter: 25 loss: 0.00513539277
Iter: 26 loss: 0.00513539044
Iter: 27 loss: 0.00513539
Iter: 28 loss: 0.00513539
Iter: 29 loss: 0.00513539044
Iter: 30 loss: 0.00513538904
Iter: 31 loss: 0.00513539
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4
+ date
Tue Oct 27 20:27:57 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557d1d9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557d1d96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557d190ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f557d1d9bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5558220d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f555823f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55581f8c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f555823f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55581c0378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55581c08c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f555811a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f555813af28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55580d39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5558084b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55580bcd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55580bc158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f555804d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5558072b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f555803cc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55400ee620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55400ff1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55400ee6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55400b4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f55400b50d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f5540019598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f4621598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f46588c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f46589d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f45f9488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f45f9f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f45d0ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f45897b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f4594268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f452bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f44e69d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f54f44e6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0319592133
Iter: 2 loss: 0.0275468603
Iter: 3 loss: 0.014541165
Iter: 4 loss: 0.0546087809
Iter: 5 loss: 0.00790303
Iter: 6 loss: 0.00694897538
Iter: 7 loss: 0.00662050769
Iter: 8 loss: 0.00613737386
Iter: 9 loss: 0.0120797567
Iter: 10 loss: 0.00612385757
Iter: 11 loss: 0.00601849519
Iter: 12 loss: 0.00631976686
Iter: 13 loss: 0.0059855096
Iter: 14 loss: 0.00596807245
Iter: 15 loss: 0.00595713127
Iter: 16 loss: 0.00594559824
Iter: 17 loss: 0.00596826337
Iter: 18 loss: 0.00594086619
Iter: 19 loss: 0.00593789201
Iter: 20 loss: 0.00597636821
Iter: 21 loss: 0.00593786966
Iter: 22 loss: 0.005937248
Iter: 23 loss: 0.00593715627
Iter: 24 loss: 0.0059370161
Iter: 25 loss: 0.00593736395
Iter: 26 loss: 0.00593696628
Iter: 27 loss: 0.00593693275
Iter: 28 loss: 0.0059374962
Iter: 29 loss: 0.00593693135
Iter: 30 loss: 0.00593691971
Iter: 31 loss: 0.00593710318
Iter: 32 loss: 0.00593691878
Iter: 33 loss: 0.00593691599
Iter: 34 loss: 0.00593691878
Iter: 35 loss: 0.00593691552
Iter: 36 loss: 0.00593691319
Iter: 37 loss: 0.00593692
Iter: 38 loss: 0.00593691319
Iter: 39 loss: 0.00593691505
Iter: 40 loss: 0.00593691459
Iter: 41 loss: 0.00593691459
Iter: 42 loss: 0.00593691412
Iter: 43 loss: 0.00593691599
Iter: 44 loss: 0.00593691459
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8
+ date
Tue Oct 27 20:28:24 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7466c2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd746732ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd746732f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd74670b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7466587b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd746672d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7205c2d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7205798c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720584378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720584e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7204ede18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7204a6158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7204a6bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720456b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7205847b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72041fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720432488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720490048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72040c620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7204476a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7203c11e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72037ad90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72033dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7202e3950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7202e3510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720296378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7202c8620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72026fbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72026f510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720213ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72024a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72024a048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72024a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd7201a2ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd72015e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7fd720170ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0255676825
Iter: 2 loss: 0.0220164545
Iter: 3 loss: 0.0137804095
Iter: 4 loss: 1.02292633
Iter: 5 loss: 0.0137635181
Iter: 6 loss: 0.00884350762
Iter: 7 loss: 0.0464593396
Iter: 8 loss: 0.00831469521
Iter: 9 loss: 0.00738421781
Iter: 10 loss: 0.00727762282
Iter: 11 loss: 0.00712589268
Iter: 12 loss: 0.0080344528
Iter: 13 loss: 0.00710498495
Iter: 14 loss: 0.00701082451
Iter: 15 loss: 0.00720931124
Iter: 16 loss: 0.0069726361
Iter: 17 loss: 0.00691075344
Iter: 18 loss: 0.00720410328
Iter: 19 loss: 0.00689982157
Iter: 20 loss: 0.00687949732
Iter: 21 loss: 0.00704168528
Iter: 22 loss: 0.00687809847
Iter: 23 loss: 0.0068730046
Iter: 24 loss: 0.00687287
Iter: 25 loss: 0.00687133754
Iter: 26 loss: 0.00687468518
Iter: 27 loss: 0.00687074568
Iter: 28 loss: 0.00687047653
Iter: 29 loss: 0.00687410356
Iter: 30 loss: 0.00687047374
Iter: 31 loss: 0.00687038107
Iter: 32 loss: 0.0068717422
Iter: 33 loss: 0.00687038153
Iter: 34 loss: 0.0068703508
Iter: 35 loss: 0.00687043555
Iter: 36 loss: 0.00687034
Iter: 37 loss: 0.00687033124
Iter: 38 loss: 0.00687039271
Iter: 39 loss: 0.00687032891
Iter: 40 loss: 0.00687032659
Iter: 41 loss: 0.0068703508
Iter: 42 loss: 0.00687032659
Iter: 43 loss: 0.00687032612
Iter: 44 loss: 0.00687032472
Iter: 45 loss: 0.00687032659
Iter: 46 loss: 0.00687032659
Iter: 47 loss: 0.00687032565
Iter: 48 loss: 0.00687032426
Iter: 49 loss: 0.00687032659
Iter: 50 loss: 0.00687032565
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2
+ date
Tue Oct 27 20:28:53 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi0.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ec4eed598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ec4eed9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ec4f52730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ec4eedc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ec4eaf2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ec4f23ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea072a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0755598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea072a8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea06fc378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea06ba950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea06748c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea06801e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0623a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0623598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea06ba268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0609378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0611b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea056c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0590400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0524488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea05901e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea04fd950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea04b2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea04b26a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0463598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0499840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0499598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0444510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0444e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0415ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea04156a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea03bfae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea03718c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0371e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1ea0371510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0274763517
Iter: 2 loss: 0.0212350264
Iter: 3 loss: 0.0235116407
Iter: 4 loss: 0.0158461109
Iter: 5 loss: 0.0117748212
Iter: 6 loss: 0.19783619
Iter: 7 loss: 0.0117644724
Iter: 8 loss: 0.00888311677
Iter: 9 loss: 0.0263412744
Iter: 10 loss: 0.00847588852
Iter: 11 loss: 0.00779405376
Iter: 12 loss: 0.00907579437
Iter: 13 loss: 0.0074934517
Iter: 14 loss: 0.00732432446
Iter: 15 loss: 0.00953576341
Iter: 16 loss: 0.007322249
Iter: 17 loss: 0.0072482191
Iter: 18 loss: 0.00774733117
Iter: 19 loss: 0.00724037271
Iter: 20 loss: 0.00716960197
Iter: 21 loss: 0.00719550392
Iter: 22 loss: 0.00712020369
Iter: 23 loss: 0.00708535872
Iter: 24 loss: 0.00742677459
Iter: 25 loss: 0.00708414288
Iter: 26 loss: 0.00707293488
Iter: 27 loss: 0.00714638876
Iter: 28 loss: 0.00707172649
Iter: 29 loss: 0.00706780283
Iter: 30 loss: 0.0070996494
Iter: 31 loss: 0.00706755277
Iter: 32 loss: 0.0070663
Iter: 33 loss: 0.00707462663
Iter: 34 loss: 0.00706616789
Iter: 35 loss: 0.00706580281
Iter: 36 loss: 0.00706764963
Iter: 37 loss: 0.00706574135
Iter: 38 loss: 0.00706561562
Iter: 39 loss: 0.00706714531
Iter: 40 loss: 0.00706561375
Iter: 41 loss: 0.00706555974
Iter: 42 loss: 0.00706581399
Iter: 43 loss: 0.00706555
Iter: 44 loss: 0.00706552342
Iter: 45 loss: 0.00706580048
Iter: 46 loss: 0.00706552155
Iter: 47 loss: 0.00706550851
Iter: 48 loss: 0.0070655467
Iter: 49 loss: 0.00706550432
Iter: 50 loss: 0.00706549594
Iter: 51 loss: 0.00706553878
Iter: 52 loss: 0.00706549641
Iter: 53 loss: 0.00706549408
Iter: 54 loss: 0.00706551084
Iter: 55 loss: 0.00706549501
Iter: 56 loss: 0.00706549129
Iter: 57 loss: 0.00706549129
Iter: 58 loss: 0.00706549082
Iter: 59 loss: 0.00706549315
Iter: 60 loss: 0.00706549175
Iter: 61 loss: 0.00706549082
Iter: 62 loss: 0.00706549222
Iter: 63 loss: 0.00706549035
Iter: 64 loss: 0.00706549129
Iter: 65 loss: 0.00706549222
Iter: 66 loss: 0.00706549082
Iter: 67 loss: 0.00706549082
Iter: 68 loss: 0.00706549268
Iter: 69 loss: 0.00706549175
Iter: 70 loss: 0.00706549222
Iter: 71 loss: 0.00706549035
Iter: 72 loss: 0.00706549082
Iter: 73 loss: 0.00706549175
Iter: 74 loss: 0.00706549035
Iter: 75 loss: 0.00706549
Iter: 76 loss: 0.00706549035
Iter: 77 loss: 0.00706549
Iter: 78 loss: 0.00706549082
Iter: 79 loss: 0.00706549082
Iter: 80 loss: 0.00706549129
Iter: 81 loss: 0.00706549129
Iter: 82 loss: 0.00706549082
Iter: 83 loss: 0.00706549082
Iter: 84 loss: 0.00706549
Iter: 85 loss: 0.00706549082
Iter: 86 loss: 0.00706549082
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6
+ date
Tue Oct 27 20:29:23 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019351598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701934e1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70193cfe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701939ab70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70192e4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70192e42f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019264c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019264ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701927b598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701927b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70191f57b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019208d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019208e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701915fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019199840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019199d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019120e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70190e2598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019115bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019115ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70190d7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701907b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7019038bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f701904df28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018fef840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018f9d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018fd28c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018f79c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018f79620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018f20620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018f460d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018efe048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018efeae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018efee18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018e6a598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f7018e6a2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.036635451
Iter: 2 loss: 0.019714281
Iter: 3 loss: 3097.5376
Iter: 4 loss: 0.0534533933
Iter: 5 loss: 0.0261866301
Iter: 6 loss: 0.0377311036
Iter: 7 loss: 0.0190562531
Iter: 8 loss: 0.0160118546
Iter: 9 loss: 0.0136773493
Iter: 10 loss: 0.0115040131
Iter: 11 loss: 0.0375038758
Iter: 12 loss: 0.0113399327
Iter: 13 loss: 0.00933876447
Iter: 14 loss: 0.0180801563
Iter: 15 loss: 0.00889814924
Iter: 16 loss: 0.00817289297
Iter: 17 loss: 0.00837166328
Iter: 18 loss: 0.00765697937
Iter: 19 loss: 0.00721765
Iter: 20 loss: 0.00988420099
Iter: 21 loss: 0.0071388334
Iter: 22 loss: 0.00707045523
Iter: 23 loss: 0.00721320976
Iter: 24 loss: 0.00704192696
Iter: 25 loss: 0.00697574764
Iter: 26 loss: 0.00707039051
Iter: 27 loss: 0.00694380235
Iter: 28 loss: 0.00688611576
Iter: 29 loss: 0.00688912254
Iter: 30 loss: 0.00684074825
Iter: 31 loss: 0.0067729787
Iter: 32 loss: 0.00696980581
Iter: 33 loss: 0.00675066
Iter: 34 loss: 0.00671428815
Iter: 35 loss: 0.00670628389
Iter: 36 loss: 0.00668263342
Iter: 37 loss: 0.00665628863
Iter: 38 loss: 0.00682366
Iter: 39 loss: 0.00665337825
Iter: 40 loss: 0.00664676866
Iter: 41 loss: 0.00671404321
Iter: 42 loss: 0.00664656935
Iter: 43 loss: 0.00664366502
Iter: 44 loss: 0.00665727584
Iter: 45 loss: 0.00664312812
Iter: 46 loss: 0.00664158864
Iter: 47 loss: 0.0066556856
Iter: 48 loss: 0.00664151646
Iter: 49 loss: 0.00664088456
Iter: 50 loss: 0.00664563477
Iter: 51 loss: 0.0066408338
Iter: 52 loss: 0.00664054183
Iter: 53 loss: 0.00664167479
Iter: 54 loss: 0.00664047385
Iter: 55 loss: 0.00664032064
Iter: 56 loss: 0.00664056558
Iter: 57 loss: 0.00664025
Iter: 58 loss: 0.00664014556
Iter: 59 loss: 0.00664079143
Iter: 60 loss: 0.00664013112
Iter: 61 loss: 0.00664008642
Iter: 62 loss: 0.00664008595
Iter: 63 loss: 0.00664005196
Iter: 64 loss: 0.00664014462
Iter: 65 loss: 0.00664004125
Iter: 66 loss: 0.00664002448
Iter: 67 loss: 0.00664010132
Iter: 68 loss: 0.00664002215
Iter: 69 loss: 0.00664000958
Iter: 70 loss: 0.00664011529
Iter: 71 loss: 0.00664000865
Iter: 72 loss: 0.00664000213
Iter: 73 loss: 0.0066400012
Iter: 74 loss: 0.00663999561
Iter: 75 loss: 0.00663998909
Iter: 76 loss: 0.0066400175
Iter: 77 loss: 0.00663998816
Iter: 78 loss: 0.00663998257
Iter: 79 loss: 0.00664001377
Iter: 80 loss: 0.00663998351
Iter: 81 loss: 0.00663998118
Iter: 82 loss: 0.00663999
Iter: 83 loss: 0.00663998071
Iter: 84 loss: 0.00663998071
Iter: 85 loss: 0.00663998071
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2
+ date
Tue Oct 27 20:29:54 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi1.6/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f04051378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f040d9840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f040d9158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f04048620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03fa3d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03fc88c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03f83c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03f57bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03f4b378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03f4b0d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03ea7598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03e55598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03e55b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03e12730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03e45d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03e45b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03e45400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03df9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03dc7ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03d86048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03d861e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03d2bd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03cf8730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03ca1730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03ca18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03cce378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03c846a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03c2d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03c31620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03bd7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03bfdbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03bfd840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03bfdd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03b5cea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03b129d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f1f03b122f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0659774244
Iter: 2 loss: 2107.16064
Iter: 3 loss: 0.0316221565
Iter: 4 loss: 0.0340194739
Iter: 5 loss: 0.245330438
Iter: 6 loss: 0.033117082
Iter: 7 loss: 0.0331654213
Iter: 8 loss: 0.0269908682
Iter: 9 loss: 0.0232212245
Iter: 10 loss: 0.0231003948
Iter: 11 loss: 0.0197048
Iter: 12 loss: 0.0170563832
Iter: 13 loss: 0.0157687813
Iter: 14 loss: 0.0124809407
Iter: 15 loss: 0.0124795707
Iter: 16 loss: 0.0114551783
Iter: 17 loss: 0.0115868812
Iter: 18 loss: 0.010705648
Iter: 19 loss: 0.0097136125
Iter: 20 loss: 0.0119027849
Iter: 21 loss: 0.00923061
Iter: 22 loss: 0.00872808509
Iter: 23 loss: 0.0102899736
Iter: 24 loss: 0.00855894
Iter: 25 loss: 0.00805756357
Iter: 26 loss: 0.00981505774
Iter: 27 loss: 0.00792768784
Iter: 28 loss: 0.00778766815
Iter: 29 loss: 0.00763233751
Iter: 30 loss: 0.00760869356
Iter: 31 loss: 0.00739988452
Iter: 32 loss: 0.00871414319
Iter: 33 loss: 0.00737325847
Iter: 34 loss: 0.00726856245
Iter: 35 loss: 0.00889907591
Iter: 36 loss: 0.00726834685
Iter: 37 loss: 0.00721895928
Iter: 38 loss: 0.00741701294
Iter: 39 loss: 0.00720761064
Iter: 40 loss: 0.00717439223
Iter: 41 loss: 0.00723962672
Iter: 42 loss: 0.0071607586
Iter: 43 loss: 0.00712300045
Iter: 44 loss: 0.00721307797
Iter: 45 loss: 0.00710878428
Iter: 46 loss: 0.00707089761
Iter: 47 loss: 0.0070409975
Iter: 48 loss: 0.00702914875
Iter: 49 loss: 0.00694869226
Iter: 50 loss: 0.0077938484
Iter: 51 loss: 0.00694605848
Iter: 52 loss: 0.00689686043
Iter: 53 loss: 0.0073182811
Iter: 54 loss: 0.00689448882
Iter: 55 loss: 0.00687322952
Iter: 56 loss: 0.00689755101
Iter: 57 loss: 0.00686161174
Iter: 58 loss: 0.00684269471
Iter: 59 loss: 0.00688281935
Iter: 60 loss: 0.00683518406
Iter: 61 loss: 0.0068141222
Iter: 62 loss: 0.00697310828
Iter: 63 loss: 0.00681239786
Iter: 64 loss: 0.00680249
Iter: 65 loss: 0.00682835
Iter: 66 loss: 0.00679911
Iter: 67 loss: 0.00679164892
Iter: 68 loss: 0.00680309348
Iter: 69 loss: 0.00678812247
Iter: 70 loss: 0.00678202603
Iter: 71 loss: 0.00684006186
Iter: 72 loss: 0.00678178854
Iter: 73 loss: 0.00677783228
Iter: 74 loss: 0.00678999349
Iter: 75 loss: 0.00677666115
Iter: 76 loss: 0.00677450374
Iter: 77 loss: 0.00679348689
Iter: 78 loss: 0.00677439664
Iter: 79 loss: 0.00677316356
Iter: 80 loss: 0.00678169215
Iter: 81 loss: 0.00677304529
Iter: 82 loss: 0.00677215075
Iter: 83 loss: 0.00677847629
Iter: 84 loss: 0.00677206879
Iter: 85 loss: 0.00677159242
Iter: 86 loss: 0.00677248416
Iter: 87 loss: 0.00677139
Iter: 88 loss: 0.00677090324
Iter: 89 loss: 0.00677469326
Iter: 90 loss: 0.00677087158
Iter: 91 loss: 0.00677064899
Iter: 92 loss: 0.00677108765
Iter: 93 loss: 0.00677055772
Iter: 94 loss: 0.00677030906
Iter: 95 loss: 0.00677091116
Iter: 96 loss: 0.00677022105
Iter: 97 loss: 0.00677001197
Iter: 98 loss: 0.006770676
Iter: 99 loss: 0.00676995236
Iter: 100 loss: 0.00676979683
Iter: 101 loss: 0.00676974608
Iter: 102 loss: 0.00676965527
Iter: 103 loss: 0.00676949462
Iter: 104 loss: 0.00677059079
Iter: 105 loss: 0.00676948158
Iter: 106 loss: 0.00676935446
Iter: 107 loss: 0.00677009579
Iter: 108 loss: 0.00676933583
Iter: 109 loss: 0.0067692576
Iter: 110 loss: 0.00676937215
Iter: 111 loss: 0.00676921895
Iter: 112 loss: 0.00676915143
Iter: 113 loss: 0.00677000126
Iter: 114 loss: 0.00676915143
Iter: 115 loss: 0.00676910486
Iter: 116 loss: 0.00676929578
Iter: 117 loss: 0.00676909089
Iter: 118 loss: 0.00676904758
Iter: 119 loss: 0.0067691463
Iter: 120 loss: 0.00676903035
Iter: 121 loss: 0.00676899403
Iter: 122 loss: 0.00676929858
Iter: 123 loss: 0.00676899357
Iter: 124 loss: 0.00676896702
Iter: 125 loss: 0.00676897261
Iter: 126 loss: 0.0067689484
Iter: 127 loss: 0.00676891534
Iter: 128 loss: 0.00676907692
Iter: 129 loss: 0.00676890928
Iter: 130 loss: 0.006768886
Iter: 131 loss: 0.00676892325
Iter: 132 loss: 0.00676887482
Iter: 133 loss: 0.00676885061
Iter: 134 loss: 0.00676890835
Iter: 135 loss: 0.0067688413
Iter: 136 loss: 0.00676882267
Iter: 137 loss: 0.0067688413
Iter: 138 loss: 0.00676881149
Iter: 139 loss: 0.00676879613
Iter: 140 loss: 0.00676890649
Iter: 141 loss: 0.00676879287
Iter: 142 loss: 0.00676878076
Iter: 143 loss: 0.00676886924
Iter: 144 loss: 0.0067687789
Iter: 145 loss: 0.00676877331
Iter: 146 loss: 0.00676879752
Iter: 147 loss: 0.00676877052
Iter: 148 loss: 0.00676876772
Iter: 149 loss: 0.00676883338
Iter: 150 loss: 0.00676876679
Iter: 151 loss: 0.00676876353
Iter: 152 loss: 0.00676877238
Iter: 153 loss: 0.00676876213
Iter: 154 loss: 0.00676876167
Iter: 155 loss: 0.00676877052
Iter: 156 loss: 0.00676876074
Iter: 157 loss: 0.00676875934
Iter: 158 loss: 0.00676876307
Iter: 159 loss: 0.00676875748
Iter: 160 loss: 0.00676875794
Iter: 161 loss: 0.0067687626
Iter: 162 loss: 0.00676875608
Iter: 163 loss: 0.00676875701
Iter: 164 loss: 0.00676875794
Iter: 165 loss: 0.00676875329
Iter: 166 loss: 0.00676875468
Iter: 167 loss: 0.00676875655
Iter: 168 loss: 0.00676875468
Iter: 169 loss: 0.00676875236
Iter: 170 loss: 0.00676875468
Iter: 171 loss: 0.00676875282
Iter: 172 loss: 0.00676875236
Iter: 173 loss: 0.00676875748
Iter: 174 loss: 0.00676875049
Iter: 175 loss: 0.00676875282
Iter: 176 loss: 0.00676875282
Iter: 177 loss: 0.00676875282
Iter: 178 loss: 0.00676875096
Iter: 179 loss: 0.00676875701
Iter: 180 loss: 0.00676875142
Iter: 181 loss: 0.00676875049
Iter: 182 loss: 0.00676875
Iter: 183 loss: 0.0067687491
Iter: 184 loss: 0.00676874956
Iter: 185 loss: 0.00676875096
Iter: 186 loss: 0.00676874816
Iter: 187 loss: 0.00676874816
Iter: 188 loss: 0.0067687491
Iter: 189 loss: 0.00676875049
Iter: 190 loss: 0.00676875096
Iter: 191 loss: 0.00676874956
Iter: 192 loss: 0.0067687491
Iter: 193 loss: 0.0067687491
Iter: 194 loss: 0.0067687491
Iter: 195 loss: 0.0067687491
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4
+ date
Tue Oct 27 20:30:32 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 2.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d606c6620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d6065a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d6065a158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d6065a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d383ca6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d383ca268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38340620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38363840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d382f66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38312378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d382f68c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d3827bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d382b20d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38236bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38236f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38236378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d382367b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38223730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d381eed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d381b1400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38135268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d381537b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d381539d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d380c7950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d380c7620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38076378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38076d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d38054620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d380536a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d2024e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d2027aae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d2027ae18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d2027a730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d201cb950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d201936a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f2d20193598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.241255075
Iter: 2 loss: 6723.28955
Iter: 3 loss: 2238.2876
Iter: 4 loss: 460.746826
Iter: 5 loss: 374.368225
Iter: 6 loss: 0.241253346
Iter: 7 loss: 0.0926358402
Iter: 8 loss: 0.0926354378
Iter: 9 loss: 725.119873
Iter: 10 loss: 111.624763
Iter: 11 loss: 0.0926203
Iter: 12 loss: 0.0927764103
Iter: 13 loss: 0.0879758447
Iter: 14 loss: 0.0819976702
Iter: 15 loss: 0.081724152
Iter: 16 loss: 0.0776833594
Iter: 17 loss: 0.1774593
Iter: 18 loss: 0.077659443
Iter: 19 loss: 0.0710402727
Iter: 20 loss: 0.0838052332
Iter: 21 loss: 0.0690303519
Iter: 22 loss: 0.0659131706
Iter: 23 loss: 0.0633996949
Iter: 24 loss: 0.061987102
Iter: 25 loss: 0.0584698692
Iter: 26 loss: 0.131613925
Iter: 27 loss: 0.0582852624
Iter: 28 loss: 0.0517293885
Iter: 29 loss: 0.127163142
Iter: 30 loss: 0.0511695296
Iter: 31 loss: 0.04692306
Iter: 32 loss: 0.0826981887
Iter: 33 loss: 0.0464794785
Iter: 34 loss: 0.0436860099
Iter: 35 loss: 0.0442365967
Iter: 36 loss: 0.0417585745
Iter: 37 loss: 0.0398703441
Iter: 38 loss: 0.0601748973
Iter: 39 loss: 0.0396540239
Iter: 40 loss: 0.0384450406
Iter: 41 loss: 0.0538224727
Iter: 42 loss: 0.0383517742
Iter: 43 loss: 0.0375478417
Iter: 44 loss: 0.0381196737
Iter: 45 loss: 0.0370475054
Iter: 46 loss: 0.0352443606
Iter: 47 loss: 0.0369282439
Iter: 48 loss: 0.0343597569
Iter: 49 loss: 0.0329229981
Iter: 50 loss: 0.0355008543
Iter: 51 loss: 0.0321234688
Iter: 52 loss: 0.0302213077
Iter: 53 loss: 0.0353656188
Iter: 54 loss: 0.0295283329
Iter: 55 loss: 0.028556278
Iter: 56 loss: 0.0282471105
Iter: 57 loss: 0.0273552947
Iter: 58 loss: 0.0305327103
Iter: 59 loss: 0.0271319188
Iter: 60 loss: 0.0264002867
Iter: 61 loss: 0.0281078555
Iter: 62 loss: 0.0261040889
Iter: 63 loss: 0.0254185833
Iter: 64 loss: 0.0281179138
Iter: 65 loss: 0.0252754167
Iter: 66 loss: 0.0247461684
Iter: 67 loss: 0.0294582043
Iter: 68 loss: 0.0247025639
Iter: 69 loss: 0.0243556947
Iter: 70 loss: 0.0255130902
Iter: 71 loss: 0.0242836494
Iter: 72 loss: 0.0240271688
Iter: 73 loss: 0.0235308111
Iter: 74 loss: 0.0367774591
Iter: 75 loss: 0.0235292055
Iter: 76 loss: 0.0230224542
Iter: 77 loss: 0.026135385
Iter: 78 loss: 0.0229528807
Iter: 79 loss: 0.0220267288
Iter: 80 loss: 0.0243659839
Iter: 81 loss: 0.0216604173
Iter: 82 loss: 0.0204564184
Iter: 83 loss: 0.022600932
Iter: 84 loss: 0.0198261961
Iter: 85 loss: 0.0185153745
Iter: 86 loss: 0.0185096301
Iter: 87 loss: 0.017873
Iter: 88 loss: 0.0183194745
Iter: 89 loss: 0.017438408
Iter: 90 loss: 0.0168629177
Iter: 91 loss: 0.0191506743
Iter: 92 loss: 0.0167381614
Iter: 93 loss: 0.0165599175
Iter: 94 loss: 0.0173416249
Iter: 95 loss: 0.0165233631
Iter: 96 loss: 0.0158608481
Iter: 97 loss: 0.0199275967
Iter: 98 loss: 0.0157626197
Iter: 99 loss: 0.0155400056
Iter: 100 loss: 0.0155310202
Iter: 101 loss: 0.0153159536
Iter: 102 loss: 0.0153573956
Iter: 103 loss: 0.0151500031
Iter: 104 loss: 0.0160907898
Iter: 105 loss: 0.0150165809
Iter: 106 loss: 0.0149034951
Iter: 107 loss: 0.0149873756
Iter: 108 loss: 0.0148300547
Iter: 109 loss: 0.0145868193
Iter: 110 loss: 0.0176420026
Iter: 111 loss: 0.0145837013
Iter: 112 loss: 0.0143543072
Iter: 113 loss: 0.0153880697
Iter: 114 loss: 0.014305003
Iter: 115 loss: 0.0141674438
Iter: 116 loss: 0.0141753
Iter: 117 loss: 0.0140606835
Iter: 118 loss: 0.0139525328
Iter: 119 loss: 0.0139522273
Iter: 120 loss: 0.0139025729
Iter: 121 loss: 0.0138993096
Iter: 122 loss: 0.0138554014
Iter: 123 loss: 0.0137436632
Iter: 124 loss: 0.0147002405
Iter: 125 loss: 0.0137255285
Iter: 126 loss: 0.0136588365
Iter: 127 loss: 0.0138263879
Iter: 128 loss: 0.0136354957
Iter: 129 loss: 0.0136003746
Iter: 130 loss: 0.0136326533
Iter: 131 loss: 0.0135796564
Iter: 132 loss: 0.0135533679
Iter: 133 loss: 0.0135708237
Iter: 134 loss: 0.0135366451
Iter: 135 loss: 0.0135228578
Iter: 136 loss: 0.013519939
Iter: 137 loss: 0.0135107692
Iter: 138 loss: 0.0134577043
Iter: 139 loss: 0.0139212515
Iter: 140 loss: 0.0134544894
Iter: 141 loss: 0.0134150963
Iter: 142 loss: 0.0136763174
Iter: 143 loss: 0.0134111755
Iter: 144 loss: 0.0133762229
Iter: 145 loss: 0.0134854941
Iter: 146 loss: 0.0133661442
Iter: 147 loss: 0.0133275678
Iter: 148 loss: 0.0136230178
Iter: 149 loss: 0.0133244302
Iter: 150 loss: 0.0132985841
Iter: 151 loss: 0.0135367941
Iter: 152 loss: 0.0132975401
Iter: 153 loss: 0.0132808089
Iter: 154 loss: 0.0132620595
Iter: 155 loss: 0.0132595431
Iter: 156 loss: 0.0132479686
Iter: 157 loss: 0.0132455779
Iter: 158 loss: 0.0132315513
Iter: 159 loss: 0.0132745337
Iter: 160 loss: 0.0132272793
Iter: 161 loss: 0.0132191703
Iter: 162 loss: 0.0131968409
Iter: 163 loss: 0.0133348508
Iter: 164 loss: 0.0131906942
Iter: 165 loss: 0.0134197967
Iter: 166 loss: 0.0131864231
Iter: 167 loss: 0.0131812217
Iter: 168 loss: 0.013206074
Iter: 169 loss: 0.0131802643
Iter: 170 loss: 0.0131710786
Iter: 171 loss: 0.0131599838
Iter: 172 loss: 0.0131588895
Iter: 173 loss: 0.0131492363
Iter: 174 loss: 0.0131504014
Iter: 175 loss: 0.013141837
Iter: 176 loss: 0.0131288618
Iter: 177 loss: 0.0132259224
Iter: 178 loss: 0.0131278103
Iter: 179 loss: 0.0131180678
Iter: 180 loss: 0.0131176487
Iter: 181 loss: 0.0131101077
Iter: 182 loss: 0.0130921742
Iter: 183 loss: 0.0131072542
Iter: 184 loss: 0.013081504
Iter: 185 loss: 0.0130685428
Iter: 186 loss: 0.0130683556
Iter: 187 loss: 0.0130604673
Iter: 188 loss: 0.0130720129
Iter: 189 loss: 0.0130566787
Iter: 190 loss: 0.0130487103
Iter: 191 loss: 0.013049853
Iter: 192 loss: 0.0130426884
Iter: 193 loss: 0.0130377105
Iter: 194 loss: 0.0130360033
Iter: 195 loss: 0.0130339246
Iter: 196 loss: 0.0130288154
Iter: 197 loss: 0.0130786933
Iter: 198 loss: 0.0130281802
Iter: 199 loss: 0.0130152181
Iter: 200 loss: 0.0130142123
Iter: 201 loss: 0.0130044874
Iter: 202 loss: 0.0130001176
Iter: 203 loss: 0.0129979365
Iter: 204 loss: 0.0129958969
Iter: 205 loss: 0.0129865278
Iter: 206 loss: 0.0129714506
Iter: 207 loss: 0.0129713332
Iter: 208 loss: 0.0129583115
Iter: 209 loss: 0.0129601853
Iter: 210 loss: 0.0129483985
Iter: 211 loss: 0.0129280183
Iter: 212 loss: 0.013017199
Iter: 213 loss: 0.0129238935
Iter: 214 loss: 0.0129116792
Iter: 215 loss: 0.0130367912
Iter: 216 loss: 0.012911357
Iter: 217 loss: 0.0129051991
Iter: 218 loss: 0.0128960898
Iter: 219 loss: 0.0128958635
Iter: 220 loss: 0.0128883496
Iter: 221 loss: 0.0128942505
Iter: 222 loss: 0.0128837777
Iter: 223 loss: 0.0128789358
Iter: 224 loss: 0.0128700342
Iter: 225 loss: 0.0130848587
Iter: 226 loss: 0.0128700398
Iter: 227 loss: 0.0128677776
Iter: 228 loss: 0.0128654391
Iter: 229 loss: 0.0128623564
Iter: 230 loss: 0.0128728058
Iter: 231 loss: 0.0128615014
Iter: 232 loss: 0.0128582958
Iter: 233 loss: 0.012863433
Iter: 234 loss: 0.0128568318
Iter: 235 loss: 0.0128539838
Iter: 236 loss: 0.0128467334
Iter: 237 loss: 0.01291099
Iter: 238 loss: 0.0128455525
Iter: 239 loss: 0.0128347827
Iter: 240 loss: 0.0128620965
Iter: 241 loss: 0.0128310435
Iter: 242 loss: 0.0128228851
Iter: 243 loss: 0.012809569
Iter: 244 loss: 0.012809488
Iter: 245 loss: 0.0127921198
Iter: 246 loss: 0.0128577948
Iter: 247 loss: 0.0127879083
Iter: 248 loss: 0.0127769299
Iter: 249 loss: 0.0128753539
Iter: 250 loss: 0.0127763599
Iter: 251 loss: 0.0127675915
Iter: 252 loss: 0.012804063
Iter: 253 loss: 0.0127656525
Iter: 254 loss: 0.0127587318
Iter: 255 loss: 0.0128104798
Iter: 256 loss: 0.0127581935
Iter: 257 loss: 0.0127528124
Iter: 258 loss: 0.0127400393
Iter: 259 loss: 0.0128900241
Iter: 260 loss: 0.0127388742
Iter: 261 loss: 0.0127251297
Iter: 262 loss: 0.0127213886
Iter: 263 loss: 0.012712854
Iter: 264 loss: 0.0127933696
Iter: 265 loss: 0.0127117215
Iter: 266 loss: 0.0127102491
Iter: 267 loss: 0.0127088018
Iter: 268 loss: 0.0127084833
Iter: 269 loss: 0.0127066579
Iter: 270 loss: 0.0127025358
Iter: 271 loss: 0.0127571719
Iter: 272 loss: 0.0127022751
Iter: 273 loss: 0.0126970261
Iter: 274 loss: 0.0127169583
Iter: 275 loss: 0.0126957595
Iter: 276 loss: 0.0126909912
Iter: 277 loss: 0.0127256755
Iter: 278 loss: 0.0126905674
Iter: 279 loss: 0.0126866316
Iter: 280 loss: 0.0126823578
Iter: 281 loss: 0.0126817
Iter: 282 loss: 0.0126775876
Iter: 283 loss: 0.0126785059
Iter: 284 loss: 0.0126745636
Iter: 285 loss: 0.0126699321
Iter: 286 loss: 0.0126883499
Iter: 287 loss: 0.0126688704
Iter: 288 loss: 0.0126636364
Iter: 289 loss: 0.0126701221
Iter: 290 loss: 0.0126609057
Iter: 291 loss: 0.0126687847
Iter: 292 loss: 0.0126577709
Iter: 293 loss: 0.0126553839
Iter: 294 loss: 0.0126508586
Iter: 295 loss: 0.012746946
Iter: 296 loss: 0.0126508418
Iter: 297 loss: 0.0126455724
Iter: 298 loss: 0.012666733
Iter: 299 loss: 0.012644371
Iter: 300 loss: 0.0126428269
Iter: 301 loss: 0.0126478188
Iter: 302 loss: 0.0126423985
Iter: 303 loss: 0.0126396213
Iter: 304 loss: 0.0126452809
Iter: 305 loss: 0.0126385121
Iter: 306 loss: 0.0126369
Iter: 307 loss: 0.0126364212
Iter: 308 loss: 0.0126354657
Iter: 309 loss: 0.0126330862
Iter: 310 loss: 0.012630308
Iter: 311 loss: 0.0126299933
Iter: 312 loss: 0.0126279611
Iter: 313 loss: 0.0126278913
Iter: 314 loss: 0.012626
Iter: 315 loss: 0.012628315
Iter: 316 loss: 0.0126249911
Iter: 317 loss: 0.0126228528
Iter: 318 loss: 0.0126233008
Iter: 319 loss: 0.0126212593
Iter: 320 loss: 0.0126192328
Iter: 321 loss: 0.0126167014
Iter: 322 loss: 0.0126165105
Iter: 323 loss: 0.0126130935
Iter: 324 loss: 0.0126389526
Iter: 325 loss: 0.0126128327
Iter: 326 loss: 0.012610239
Iter: 327 loss: 0.0126293339
Iter: 328 loss: 0.0126100108
Iter: 329 loss: 0.0126155391
Iter: 330 loss: 0.0126096606
Iter: 331 loss: 0.0126094222
Iter: 332 loss: 0.0126089472
Iter: 333 loss: 0.0126179568
Iter: 334 loss: 0.0126089277
Iter: 335 loss: 0.0126080764
Iter: 336 loss: 0.0126081817
Iter: 337 loss: 0.0126074348
Iter: 338 loss: 0.0126065379
Iter: 339 loss: 0.012610035
Iter: 340 loss: 0.012606319
Iter: 341 loss: 0.0126055777
Iter: 342 loss: 0.0126052685
Iter: 343 loss: 0.0126048597
Iter: 344 loss: 0.0126041546
Iter: 345 loss: 0.012602441
Iter: 346 loss: 0.0126220901
Iter: 347 loss: 0.0126022808
Iter: 348 loss: 0.0126011977
Iter: 349 loss: 0.0126045793
Iter: 350 loss: 0.0126008866
Iter: 351 loss: 0.0126005802
Iter: 352 loss: 0.0125999162
Iter: 353 loss: 0.0126094278
Iter: 354 loss: 0.0125998706
Iter: 355 loss: 0.0125990063
Iter: 356 loss: 0.0125990631
Iter: 357 loss: 0.0125983432
Iter: 358 loss: 0.0125974491
Iter: 359 loss: 0.0125975683
Iter: 360 loss: 0.0125967637
Iter: 361 loss: 0.0125961918
Iter: 362 loss: 0.0125999842
Iter: 363 loss: 0.0125961239
Iter: 364 loss: 0.0125955464
Iter: 365 loss: 0.0125953984
Iter: 366 loss: 0.0125950342
Iter: 367 loss: 0.0125945043
Iter: 368 loss: 0.012597369
Iter: 369 loss: 0.0125944242
Iter: 370 loss: 0.0125944447
Iter: 371 loss: 0.0125942715
Iter: 372 loss: 0.0125941541
Iter: 373 loss: 0.012593952
Iter: 374 loss: 0.0125939585
Iter: 375 loss: 0.0125936707
Iter: 376 loss: 0.012594182
Iter: 377 loss: 0.0125935525
Iter: 378 loss: 0.0125933625
Iter: 379 loss: 0.012595675
Iter: 380 loss: 0.0125933625
Iter: 381 loss: 0.0125932787
Iter: 382 loss: 0.0125945807
Iter: 383 loss: 0.0125932824
Iter: 384 loss: 0.0125931958
Iter: 385 loss: 0.0125930142
Iter: 386 loss: 0.01259505
Iter: 387 loss: 0.0125929862
Iter: 388 loss: 0.0125927487
Iter: 389 loss: 0.0125922468
Iter: 390 loss: 0.0126018282
Iter: 391 loss: 0.0125922393
Iter: 392 loss: 0.012591606
Iter: 393 loss: 0.0125954151
Iter: 394 loss: 0.0125915278
Iter: 395 loss: 0.0125910398
Iter: 396 loss: 0.0125930365
Iter: 397 loss: 0.0125909299
Iter: 398 loss: 0.0125904437
Iter: 399 loss: 0.0125924442
Iter: 400 loss: 0.0125903478
Iter: 401 loss: 0.0125900619
Iter: 402 loss: 0.0125924945
Iter: 403 loss: 0.0125900423
Iter: 404 loss: 0.0125899594
Iter: 405 loss: 0.0125899576
Iter: 406 loss: 0.0125898682
Iter: 407 loss: 0.0125897052
Iter: 408 loss: 0.0125897266
Iter: 409 loss: 0.0125895459
Iter: 410 loss: 0.012589626
Iter: 411 loss: 0.0125894397
Iter: 412 loss: 0.0125892852
Iter: 413 loss: 0.0125907985
Iter: 414 loss: 0.012589287
Iter: 415 loss: 0.0125892013
Iter: 416 loss: 0.012590358
Iter: 417 loss: 0.0125892069
Iter: 418 loss: 0.0125891212
Iter: 419 loss: 0.0125889787
Iter: 420 loss: 0.0125922
Iter: 421 loss: 0.0125889676
Iter: 422 loss: 0.0125888139
Iter: 423 loss: 0.0125885941
Iter: 424 loss: 0.0125885801
Iter: 425 loss: 0.0125883361
Iter: 426 loss: 0.0125909615
Iter: 427 loss: 0.0125883268
Iter: 428 loss: 0.0125881694
Iter: 429 loss: 0.0125884516
Iter: 430 loss: 0.012588108
Iter: 431 loss: 0.0125879468
Iter: 432 loss: 0.0125885662
Iter: 433 loss: 0.0125879087
Iter: 434 loss: 0.0125877801
Iter: 435 loss: 0.0125892926
Iter: 436 loss: 0.0125877801
Iter: 437 loss: 0.0125877373
Iter: 438 loss: 0.0125877354
Iter: 439 loss: 0.0125876749
Iter: 440 loss: 0.0125876013
Iter: 441 loss: 0.0125876069
Iter: 442 loss: 0.0125874979
Iter: 443 loss: 0.0125874318
Iter: 444 loss: 0.0125873871
Iter: 445 loss: 0.0125872418
Iter: 446 loss: 0.0125891268
Iter: 447 loss: 0.0125872381
Iter: 448 loss: 0.0125871692
Iter: 449 loss: 0.0125871748
Iter: 450 loss: 0.0125871105
Iter: 451 loss: 0.0125869848
Iter: 452 loss: 0.0125889499
Iter: 453 loss: 0.0125869904
Iter: 454 loss: 0.0125868479
Iter: 455 loss: 0.0125867203
Iter: 456 loss: 0.012586684
Iter: 457 loss: 0.0125865489
Iter: 458 loss: 0.0125865545
Iter: 459 loss: 0.0125864688
Iter: 460 loss: 0.0125864502
Iter: 461 loss: 0.0125863971
Iter: 462 loss: 0.0125863012
Iter: 463 loss: 0.012586657
Iter: 464 loss: 0.0125862602
Iter: 465 loss: 0.012586182
Iter: 466 loss: 0.0125870612
Iter: 467 loss: 0.012586168
Iter: 468 loss: 0.012586154
Iter: 469 loss: 0.0125861429
Iter: 470 loss: 0.0125861121
Iter: 471 loss: 0.0125860609
Iter: 472 loss: 0.0125860712
Iter: 473 loss: 0.0125859985
Iter: 474 loss: 0.0125859808
Iter: 475 loss: 0.0125859305
Iter: 476 loss: 0.0125858476
Iter: 477 loss: 0.012586914
Iter: 478 loss: 0.0125858486
Iter: 479 loss: 0.0125858076
Iter: 480 loss: 0.0125857946
Iter: 481 loss: 0.0125857648
Iter: 482 loss: 0.012585694
Iter: 483 loss: 0.0125863552
Iter: 484 loss: 0.0125856809
Iter: 485 loss: 0.0125856
Iter: 486 loss: 0.0125854816
Iter: 487 loss: 0.0125854732
Iter: 488 loss: 0.0125854071
Iter: 489 loss: 0.0125853755
Iter: 490 loss: 0.0125853242
Iter: 491 loss: 0.0125852525
Iter: 492 loss: 0.0125852525
Iter: 493 loss: 0.0125851519
Iter: 494 loss: 0.0125857592
Iter: 495 loss: 0.012585137
Iter: 496 loss: 0.0125850653
Iter: 497 loss: 0.0125855142
Iter: 498 loss: 0.0125850523
Iter: 499 loss: 0.0125850225
Iter: 500 loss: 0.0125850281
Iter: 501 loss: 0.0125849964
Iter: 502 loss: 0.0125849573
Iter: 503 loss: 0.0125849517
Iter: 504 loss: 0.0125848819
Iter: 505 loss: 0.0125849843
Iter: 506 loss: 0.0125848437
Iter: 507 loss: 0.0125848092
Iter: 508 loss: 0.0125851743
Iter: 509 loss: 0.0125847906
Iter: 510 loss: 0.0125847701
Iter: 511 loss: 0.0125847664
Iter: 512 loss: 0.0125847645
Iter: 513 loss: 0.0125847254
Iter: 514 loss: 0.0125849042
Iter: 515 loss: 0.0125847086
Iter: 516 loss: 0.0125846583
Iter: 517 loss: 0.0125845987
Iter: 518 loss: 0.0125845913
Iter: 519 loss: 0.0125845559
Iter: 520 loss: 0.0125845373
Iter: 521 loss: 0.0125845103
Iter: 522 loss: 0.0125844721
Iter: 523 loss: 0.01258446
Iter: 524 loss: 0.0125844292
Iter: 525 loss: 0.0125848893
Iter: 526 loss: 0.0125844255
Iter: 527 loss: 0.0125843957
Iter: 528 loss: 0.0125845708
Iter: 529 loss: 0.0125843976
Iter: 530 loss: 0.0125843938
Iter: 531 loss: 0.0125843864
Iter: 532 loss: 0.0125843752
Iter: 533 loss: 0.0125843557
Iter: 534 loss: 0.012584676
Iter: 535 loss: 0.0125843575
Iter: 536 loss: 0.0125843314
Iter: 537 loss: 0.0125843287
Iter: 538 loss: 0.012584311
Iter: 539 loss: 0.0125842877
Iter: 540 loss: 0.0125843063
Iter: 541 loss: 0.0125842448
Iter: 542 loss: 0.0125843491
Iter: 543 loss: 0.0125842458
Iter: 544 loss: 0.0125842411
Iter: 545 loss: 0.0125842271
Iter: 546 loss: 0.0125842392
Iter: 547 loss: 0.012584215
Iter: 548 loss: 0.0125841787
Iter: 549 loss: 0.0125843082
Iter: 550 loss: 0.0125841685
Iter: 551 loss: 0.0125841452
Iter: 552 loss: 0.0125841517
Iter: 553 loss: 0.0125841331
Iter: 554 loss: 0.0125841126
Iter: 555 loss: 0.0125841182
Iter: 556 loss: 0.0125841061
Iter: 557 loss: 0.0125841163
Iter: 558 loss: 0.0125841061
Iter: 559 loss: 0.0125841089
Iter: 560 loss: 0.0125841005
Iter: 561 loss: 0.0125840865
Iter: 562 loss: 0.0125840874
Iter: 563 loss: 0.0125840846
Iter: 564 loss: 0.0125840921
Iter: 565 loss: 0.0125840735
Iter: 566 loss: 0.0125840781
Iter: 567 loss: 0.0125840753
Iter: 568 loss: 0.0125840604
Iter: 569 loss: 0.0125840493
Iter: 570 loss: 0.0125840474
Iter: 571 loss: 0.0125840791
Iter: 572 loss: 0.0125840483
Iter: 573 loss: 0.0125840381
Iter: 574 loss: 0.0125840325
Iter: 575 loss: 0.0125840688
Iter: 576 loss: 0.0125840213
Iter: 577 loss: 0.0125840204
Iter: 578 loss: 0.0125840241
Iter: 579 loss: 0.012584
Iter: 580 loss: 0.012583999
Iter: 581 loss: 0.0125840027
Iter: 582 loss: 0.012584
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8
+ date
Tue Oct 27 20:31:34 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.4/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 2.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c5ba7378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c5ba7400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c5b5bea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89c5b5b158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a0251378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a02511e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a01d38c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a01d3598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a018f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a01af378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a0160950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a011e8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a01281e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a00cca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a0108840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a0108158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a0094598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a00b96a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a00128c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a003f6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8980091510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a003f378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89800789d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89a003f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89800ae9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89347b9598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89347f06a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89347f0840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8934799510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8934799e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f893476dae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8934724158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f893472d1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89346ced08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f89346849d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f8934684158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.186527133
Iter: 2 loss: 12.1023369
Iter: 3 loss: 11.5207434
Iter: 4 loss: 5.35578823
Iter: 5 loss: 5.21576786
Iter: 6 loss: 2.80525303
Iter: 7 loss: 2.74728227
Iter: 8 loss: 1.57755041
Iter: 9 loss: 1.54503465
Iter: 10 loss: 0.906685352
Iter: 11 loss: 0.885222077
Iter: 12 loss: 0.51448077
Iter: 13 loss: 0.498773336
Iter: 14 loss: 0.27527684
Iter: 15 loss: 0.263539255
Iter: 16 loss: 0.13534458
Iter: 17 loss: 0.128456101
Iter: 18 loss: 0.12104518
Iter: 19 loss: 0.0921434
Iter: 20 loss: 586.155579
Iter: 21 loss: 0.0523660257
Iter: 22 loss: 0.131221801
Iter: 23 loss: 0.0519911423
Iter: 24 loss: 0.0765322298
Iter: 25 loss: 0.0493721068
Iter: 26 loss: 0.0401256047
Iter: 27 loss: 0.037782751
Iter: 28 loss: 0.031394925
Iter: 29 loss: 0.0324555039
Iter: 30 loss: 0.0277608298
Iter: 31 loss: 0.0230972432
Iter: 32 loss: 0.0658642501
Iter: 33 loss: 0.0224322639
Iter: 34 loss: 0.020425126
Iter: 35 loss: 0.0279229805
Iter: 36 loss: 0.0199113674
Iter: 37 loss: 0.0175177641
Iter: 38 loss: 0.0221582
Iter: 39 loss: 0.0164134838
Iter: 40 loss: 0.0147584677
Iter: 41 loss: 0.0238317139
Iter: 42 loss: 0.0145592894
Iter: 43 loss: 0.0140525457
Iter: 44 loss: 0.0158080142
Iter: 45 loss: 0.0138874147
Iter: 46 loss: 0.0136596579
Iter: 47 loss: 0.014287997
Iter: 48 loss: 0.0135865621
Iter: 49 loss: 0.0134167317
Iter: 50 loss: 0.0141468151
Iter: 51 loss: 0.0133812288
Iter: 52 loss: 0.0132767288
Iter: 53 loss: 0.0133508425
Iter: 54 loss: 0.0132150576
Iter: 55 loss: 0.0131536815
Iter: 56 loss: 0.0133682434
Iter: 57 loss: 0.0131362528
Iter: 58 loss: 0.0131078465
Iter: 59 loss: 0.0130702397
Iter: 60 loss: 0.0130680874
Iter: 61 loss: 0.0130062718
Iter: 62 loss: 0.0131293517
Iter: 63 loss: 0.0129816309
Iter: 64 loss: 0.0129279839
Iter: 65 loss: 0.0135925766
Iter: 66 loss: 0.0129275462
Iter: 67 loss: 0.0128866788
Iter: 68 loss: 0.0129026091
Iter: 69 loss: 0.0128587
Iter: 70 loss: 0.0128253736
Iter: 71 loss: 0.0130760185
Iter: 72 loss: 0.0128230248
Iter: 73 loss: 0.0128053073
Iter: 74 loss: 0.0129101463
Iter: 75 loss: 0.0128031177
Iter: 76 loss: 0.0127897151
Iter: 77 loss: 0.012920755
Iter: 78 loss: 0.0127892336
Iter: 79 loss: 0.0127807446
Iter: 80 loss: 0.0127814924
Iter: 81 loss: 0.0127742132
Iter: 82 loss: 0.0127656218
Iter: 83 loss: 0.0128673129
Iter: 84 loss: 0.0127655119
Iter: 85 loss: 0.012760086
Iter: 86 loss: 0.0127636539
Iter: 87 loss: 0.0127566885
Iter: 88 loss: 0.0127545707
Iter: 89 loss: 0.0127535984
Iter: 90 loss: 0.0127524296
Iter: 91 loss: 0.0127501292
Iter: 92 loss: 0.0127960294
Iter: 93 loss: 0.0127501115
Iter: 94 loss: 0.0127430437
Iter: 95 loss: 0.0127994213
Iter: 96 loss: 0.0127425585
Iter: 97 loss: 0.012738606
Iter: 98 loss: 0.0127525907
Iter: 99 loss: 0.0127375834
Iter: 100 loss: 0.0127324108
Iter: 101 loss: 0.012741277
Iter: 102 loss: 0.0127301048
Iter: 103 loss: 0.0127252843
Iter: 104 loss: 0.0127549935
Iter: 105 loss: 0.0127246939
Iter: 106 loss: 0.0127222966
Iter: 107 loss: 0.0127221011
Iter: 108 loss: 0.0127203166
Iter: 109 loss: 0.0127172302
Iter: 110 loss: 0.0127354674
Iter: 111 loss: 0.0127168261
Iter: 112 loss: 0.0127138356
Iter: 113 loss: 0.012724977
Iter: 114 loss: 0.0127131026
Iter: 115 loss: 0.0127109569
Iter: 116 loss: 0.0127251092
Iter: 117 loss: 0.012710725
Iter: 118 loss: 0.0127092935
Iter: 119 loss: 0.0127126221
Iter: 120 loss: 0.012708772
Iter: 121 loss: 0.012708541
Iter: 122 loss: 0.0127082
Iter: 123 loss: 0.0127075613
Iter: 124 loss: 0.0127059417
Iter: 125 loss: 0.0127203017
Iter: 126 loss: 0.0127056809
Iter: 127 loss: 0.0127045121
Iter: 128 loss: 0.0127029857
Iter: 129 loss: 0.0127028907
Iter: 130 loss: 0.0127008865
Iter: 131 loss: 0.01271661
Iter: 132 loss: 0.012700744
Iter: 133 loss: 0.0126996245
Iter: 134 loss: 0.0127032995
Iter: 135 loss: 0.0126993209
Iter: 136 loss: 0.0126982788
Iter: 137 loss: 0.0126994792
Iter: 138 loss: 0.01269772
Iter: 139 loss: 0.0126964776
Iter: 140 loss: 0.0127052423
Iter: 141 loss: 0.012696363
Iter: 142 loss: 0.012695374
Iter: 143 loss: 0.0126976818
Iter: 144 loss: 0.0126950052
Iter: 145 loss: 0.0126943085
Iter: 146 loss: 0.0127012841
Iter: 147 loss: 0.0126942918
Iter: 148 loss: 0.0126937944
Iter: 149 loss: 0.0126938391
Iter: 150 loss: 0.0126934126
Iter: 151 loss: 0.0126925819
Iter: 152 loss: 0.0126963
Iter: 153 loss: 0.0126924161
Iter: 154 loss: 0.0126918899
Iter: 155 loss: 0.0126963612
Iter: 156 loss: 0.0126918564
Iter: 157 loss: 0.0126913339
Iter: 158 loss: 0.0126946811
Iter: 159 loss: 0.0126912724
Iter: 160 loss: 0.012691088
Iter: 161 loss: 0.0126905562
Iter: 162 loss: 0.012693095
Iter: 163 loss: 0.0126903774
Iter: 164 loss: 0.012689935
Iter: 165 loss: 0.0126926824
Iter: 166 loss: 0.0126898801
Iter: 167 loss: 0.0126895178
Iter: 168 loss: 0.0126898475
Iter: 169 loss: 0.0126893111
Iter: 170 loss: 0.0126888547
Iter: 171 loss: 0.0126906894
Iter: 172 loss: 0.0126887504
Iter: 173 loss: 0.012688444
Iter: 174 loss: 0.0126903094
Iter: 175 loss: 0.0126884021
Iter: 176 loss: 0.0126882382
Iter: 177 loss: 0.0126905739
Iter: 178 loss: 0.0126882382
Iter: 179 loss: 0.0126881059
Iter: 180 loss: 0.0126880407
Iter: 181 loss: 0.0126879746
Iter: 182 loss: 0.0126877483
Iter: 183 loss: 0.0126884924
Iter: 184 loss: 0.0126876887
Iter: 185 loss: 0.0126875434
Iter: 186 loss: 0.0126890419
Iter: 187 loss: 0.0126875415
Iter: 188 loss: 0.0126874503
Iter: 189 loss: 0.0126885083
Iter: 190 loss: 0.0126874484
Iter: 191 loss: 0.0126873795
Iter: 192 loss: 0.012687875
Iter: 193 loss: 0.0126873776
Iter: 194 loss: 0.0126873329
Iter: 195 loss: 0.0126872398
Iter: 196 loss: 0.0126883984
Iter: 197 loss: 0.0126872361
Iter: 198 loss: 0.0126871541
Iter: 199 loss: 0.0126871113
Iter: 200 loss: 0.0126870731
Iter: 201 loss: 0.0126869418
Iter: 202 loss: 0.0126873832
Iter: 203 loss: 0.0126869092
Iter: 204 loss: 0.0126867946
Iter: 205 loss: 0.0126875089
Iter: 206 loss: 0.0126867816
Iter: 207 loss: 0.0126867052
Iter: 208 loss: 0.0126869343
Iter: 209 loss: 0.0126866829
Iter: 210 loss: 0.0126866205
Iter: 211 loss: 0.0126869865
Iter: 212 loss: 0.0126866139
Iter: 213 loss: 0.0126865497
Iter: 214 loss: 0.0126867928
Iter: 215 loss: 0.012686532
Iter: 216 loss: 0.0126864854
Iter: 217 loss: 0.012686681
Iter: 218 loss: 0.0126864817
Iter: 219 loss: 0.0126864398
Iter: 220 loss: 0.0126864994
Iter: 221 loss: 0.0126864258
Iter: 222 loss: 0.0126864035
Iter: 223 loss: 0.0126864025
Iter: 224 loss: 0.0126863839
Iter: 225 loss: 0.012686491
Iter: 226 loss: 0.012686383
Iter: 227 loss: 0.0126863699
Iter: 228 loss: 0.0126863429
Iter: 229 loss: 0.0126867797
Iter: 230 loss: 0.0126863439
Iter: 231 loss: 0.0126863169
Iter: 232 loss: 0.0126862973
Iter: 233 loss: 0.0126862861
Iter: 234 loss: 0.0126862526
Iter: 235 loss: 0.0126863942
Iter: 236 loss: 0.0126862414
Iter: 237 loss: 0.0126862163
Iter: 238 loss: 0.0126864575
Iter: 239 loss: 0.0126862172
Iter: 240 loss: 0.0126861967
Iter: 241 loss: 0.0126862107
Iter: 242 loss: 0.0126861874
Iter: 243 loss: 0.012686165
Iter: 244 loss: 0.0126863047
Iter: 245 loss: 0.0126861632
Iter: 246 loss: 0.0126861539
Iter: 247 loss: 0.0126862926
Iter: 248 loss: 0.0126861529
Iter: 249 loss: 0.0126861446
Iter: 250 loss: 0.0126861539
Iter: 251 loss: 0.0126861399
Iter: 252 loss: 0.0126861278
Iter: 253 loss: 0.0126861501
Iter: 254 loss: 0.0126861241
Iter: 255 loss: 0.0126861213
Iter: 256 loss: 0.0126861203
Iter: 257 loss: 0.0126861129
Iter: 258 loss: 0.0126861343
Iter: 259 loss: 0.0126861157
Iter: 260 loss: 0.0126861129
Iter: 261 loss: 0.0126861073
Iter: 262 loss: 0.012686247
Iter: 263 loss: 0.0126861092
Iter: 264 loss: 0.0126861064
Iter: 265 loss: 0.0126861036
Iter: 266 loss: 0.0126860989
Iter: 267 loss: 0.0126860961
Iter: 268 loss: 0.0126861092
Iter: 269 loss: 0.0126860933
Iter: 270 loss: 0.012686085
Iter: 271 loss: 0.0126861157
Iter: 272 loss: 0.0126860887
Iter: 273 loss: 0.012686084
Iter: 274 loss: 0.0126860905
Iter: 275 loss: 0.0126860831
Iter: 276 loss: 0.0126860775
Iter: 277 loss: 0.0126861017
Iter: 278 loss: 0.0126860775
Iter: 279 loss: 0.0126860747
Iter: 280 loss: 0.012686084
Iter: 281 loss: 0.0126860756
Iter: 282 loss: 0.0126860738
Iter: 283 loss: 0.0126860766
Iter: 284 loss: 0.0126860701
Iter: 285 loss: 0.0126860701
Iter: 286 loss: 0.0126860756
Iter: 287 loss: 0.0126860663
Iter: 288 loss: 0.0126860682
Iter: 289 loss: 0.0126860673
Iter: 290 loss: 0.0126860645
Iter: 291 loss: 0.0126860682
Iter: 292 loss: 0.0126860663
Iter: 293 loss: 0.0126860701
Iter: 294 loss: 0.0126860626
Iter: 295 loss: 0.0126860626
Iter: 296 loss: 0.0126860645
Iter: 297 loss: 0.0126860626
Iter: 298 loss: 0.0126860626
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k2
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3
+ date
Tue Oct 27 20:32:19 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/k2 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi2.8/k2 --OuterProductNN_k 2 --optimizer lbfgs --function f1 --psi 1 --phi 3 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/ --save_name k2 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k2
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9edb5e2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9edae0730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9edbb2950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9edbb2510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9eda6d400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9eda907b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9eda6d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed9fb9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9eda17378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9eda17730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9eda17a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed92d8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed974d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed95bbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed915840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed8c2730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed8c2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed8df620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed8dfb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed8572f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed8571e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed7fcbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed7c49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed857a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed7be9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed79b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed75b8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed6f1ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed6f16a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed71f268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed6cd6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed6911e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed68d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed62b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed68db70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff9ed60f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.043514438
Iter: 2 loss: 1.1329329
Iter: 3 loss: 0.923793316
Iter: 4 loss: 0.49489519
Iter: 5 loss: 0.388284087
Iter: 6 loss: 0.186677277
Iter: 7 loss: 0.129222646
Iter: 8 loss: 0.0493854098
Iter: 9 loss: 0.0330184884
Iter: 10 loss: 0.0237945281
Iter: 11 loss: 0.0548236333
Iter: 12 loss: 0.0199973974
Iter: 13 loss: 0.0241656918
Iter: 14 loss: 0.0161238164
Iter: 15 loss: 0.0146204075
Iter: 16 loss: 0.0144759864
Iter: 17 loss: 0.0139439199
Iter: 18 loss: 0.0130982678
Iter: 19 loss: 0.0130914506
Iter: 20 loss: 0.0124429073
Iter: 21 loss: 0.0167952813
Iter: 22 loss: 0.0124248751
Iter: 23 loss: 0.0123372488
Iter: 24 loss: 0.0121980086
Iter: 25 loss: 0.0121961171
Iter: 26 loss: 0.0120714344
Iter: 27 loss: 0.0119778663
Iter: 28 loss: 0.0119388774
Iter: 29 loss: 0.0117467949
Iter: 30 loss: 0.0120687801
Iter: 31 loss: 0.0116614299
Iter: 32 loss: 0.0115392171
Iter: 33 loss: 0.0121213216
Iter: 34 loss: 0.0115189254
Iter: 35 loss: 0.0114726089
Iter: 36 loss: 0.0117898909
Iter: 37 loss: 0.0114680519
Iter: 38 loss: 0.0114425421
Iter: 39 loss: 0.0114423046
Iter: 40 loss: 0.0114222709
Iter: 41 loss: 0.0113915224
Iter: 42 loss: 0.0115518626
Iter: 43 loss: 0.0113869011
Iter: 44 loss: 0.0113737127
Iter: 45 loss: 0.0115075409
Iter: 46 loss: 0.0113733727
Iter: 47 loss: 0.0113690756
Iter: 48 loss: 0.0113985725
Iter: 49 loss: 0.011368677
Iter: 50 loss: 0.011365585
Iter: 51 loss: 0.0113744456
Iter: 52 loss: 0.011364622
Iter: 53 loss: 0.0113629028
Iter: 54 loss: 0.0113738403
Iter: 55 loss: 0.0113627147
Iter: 56 loss: 0.011362141
Iter: 57 loss: 0.0113637839
Iter: 58 loss: 0.0113619594
Iter: 59 loss: 0.0113614136
Iter: 60 loss: 0.0113636237
Iter: 61 loss: 0.0113612916
Iter: 62 loss: 0.0113613307
Iter: 63 loss: 0.0113610849
Iter: 64 loss: 0.011360921
Iter: 65 loss: 0.011360459
Iter: 66 loss: 0.0113630816
Iter: 67 loss: 0.0113603286
Iter: 68 loss: 0.0113598835
Iter: 69 loss: 0.0113602811
Iter: 70 loss: 0.0113596227
Iter: 71 loss: 0.0113591198
Iter: 72 loss: 0.0113622565
Iter: 73 loss: 0.011359062
Iter: 74 loss: 0.0113586728
Iter: 75 loss: 0.0113601107
Iter: 76 loss: 0.0113585778
Iter: 77 loss: 0.0113582946
Iter: 78 loss: 0.0113601601
Iter: 79 loss: 0.0113582667
Iter: 80 loss: 0.0113580767
Iter: 81 loss: 0.0113587501
Iter: 82 loss: 0.0113580273
Iter: 83 loss: 0.0113578895
Iter: 84 loss: 0.0113582313
Iter: 85 loss: 0.011357842
Iter: 86 loss: 0.0113577042
Iter: 87 loss: 0.0113578346
Iter: 88 loss: 0.0113576222
Iter: 89 loss: 0.0113574667
Iter: 90 loss: 0.0113584027
Iter: 91 loss: 0.0113574509
Iter: 92 loss: 0.0113573465
Iter: 93 loss: 0.0113578625
Iter: 94 loss: 0.0113573279
Iter: 95 loss: 0.0113572404
Iter: 96 loss: 0.0113573391
Iter: 97 loss: 0.0113571947
Iter: 98 loss: 0.0113572134
Iter: 99 loss: 0.0113571584
Iter: 100 loss: 0.0113571193
Iter: 101 loss: 0.0113570467
Iter: 102 loss: 0.0113583943
Iter: 103 loss: 0.0113570504
Iter: 104 loss: 0.0113569926
Iter: 105 loss: 0.0113570336
Iter: 106 loss: 0.0113569628
Iter: 107 loss: 0.0113569135
Iter: 108 loss: 0.0113569563
Iter: 109 loss: 0.0113568865
Iter: 110 loss: 0.0113568315
Iter: 111 loss: 0.0113571407
Iter: 112 loss: 0.011356825
Iter: 113 loss: 0.0113567915
Iter: 114 loss: 0.0113569517
Iter: 115 loss: 0.0113567859
Iter: 116 loss: 0.0113567635
Iter: 117 loss: 0.011356879
Iter: 118 loss: 0.0113567561
Iter: 119 loss: 0.0113567347
Iter: 120 loss: 0.0113568921
Iter: 121 loss: 0.0113567319
Iter: 122 loss: 0.0113567207
Iter: 123 loss: 0.011356717
Iter: 124 loss: 0.0113567058
Iter: 125 loss: 0.0113566946
Iter: 126 loss: 0.0113568027
Iter: 127 loss: 0.0113566946
Iter: 128 loss: 0.0113566816
Iter: 129 loss: 0.0113566872
Iter: 130 loss: 0.0113566779
Iter: 131 loss: 0.0113566648
Iter: 132 loss: 0.0113566676
Iter: 133 loss: 0.0113566611
Iter: 134 loss: 0.0113567542
Iter: 135 loss: 0.011356662
Iter: 136 loss: 0.0113566592
Iter: 137 loss: 0.0113566536
Iter: 138 loss: 0.0113567291
Iter: 139 loss: 0.0113566536
Iter: 140 loss: 0.011356649
Iter: 141 loss: 0.011356663
Iter: 142 loss: 0.011356649
Iter: 143 loss: 0.0113566443
Iter: 144 loss: 0.0113566611
Iter: 145 loss: 0.0113566425
Iter: 146 loss: 0.0113566425
Iter: 147 loss: 0.0113566518
Iter: 148 loss: 0.0113566406
Iter: 149 loss: 0.0113566387
Iter: 150 loss: 0.0113566406
Iter: 151 loss: 0.0113566378
Iter: 152 loss: 0.011356635
Iter: 153 loss: 0.0113566378
Iter: 154 loss: 0.011356635
Iter: 155 loss: 0.0113566304
Iter: 156 loss: 0.0113566462
Iter: 157 loss: 0.0113566332
Iter: 158 loss: 0.0113566322
Iter: 159 loss: 0.011356635
Iter: 160 loss: 0.0113566313
Iter: 161 loss: 0.0113566332
Iter: 162 loss: 0.0113566415
Iter: 163 loss: 0.0113566294
Iter: 164 loss: 0.0113566322
Iter: 165 loss: 0.0113566322
Iter: 166 loss: 0.0113566294
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f1_psi1_phi3/k2
+ for fn in f1 f2
+ case $fn in
+ OPT=--alpha
+ for psi in $PSI
+ for layers in $LAYERS
+ MODEL=experiments.final/output11a/f0_psi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0
+ date
Tue Oct 27 20:32:55 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model experiments.final/output11a/f0_psi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 0 --alpha 0 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f0d49b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f0d4fe268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f0d511c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f0d452730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f0d4731e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3f0d429bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee84ba6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee84de158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee84e2b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee84a2620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee84480d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee844fae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee840c598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee842e048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee8436a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee83f0510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee837cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee83b5950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee8351400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee835de18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee83178c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee82bd378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee82c1d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee8283840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee82a62f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee82acd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee82627b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee820c268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee820fc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee81ce730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee81f61e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee817abf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee81b46a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee8154158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee8160b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f3ee8120620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 8.60515429e-05
Iter: 2 loss: 8.57218402e-05
Iter: 3 loss: 8.44442402e-05
Iter: 4 loss: 7.90505583e-05
Iter: 5 loss: 7.67654856e-05
Iter: 6 loss: 7.27242877e-05
Iter: 7 loss: 6.57801138e-05
Iter: 8 loss: 9.54770367e-05
Iter: 9 loss: 6.43234671e-05
Iter: 10 loss: 6.07030743e-05
Iter: 11 loss: 6.42010418e-05
Iter: 12 loss: 5.86474926e-05
Iter: 13 loss: 5.54971448e-05
Iter: 14 loss: 9.66835432e-05
Iter: 15 loss: 5.54791914e-05
Iter: 16 loss: 5.31198566e-05
Iter: 17 loss: 5.24554271e-05
Iter: 18 loss: 5.10192294e-05
Iter: 19 loss: 4.85422206e-05
Iter: 20 loss: 5.35867948e-05
Iter: 21 loss: 4.75449779e-05
Iter: 22 loss: 4.57743045e-05
Iter: 23 loss: 6.84955594e-05
Iter: 24 loss: 4.57618662e-05
Iter: 25 loss: 4.42950331e-05
Iter: 26 loss: 4.92347172e-05
Iter: 27 loss: 4.38986172e-05
Iter: 28 loss: 4.29441498e-05
Iter: 29 loss: 4.29549327e-05
Iter: 30 loss: 4.21843433e-05
Iter: 31 loss: 4.13085363e-05
Iter: 32 loss: 4.92223298e-05
Iter: 33 loss: 4.12682e-05
Iter: 34 loss: 4.06270847e-05
Iter: 35 loss: 4.62218522e-05
Iter: 36 loss: 4.05937972e-05
Iter: 37 loss: 4.02095175e-05
Iter: 38 loss: 3.99295604e-05
Iter: 39 loss: 3.97987824e-05
Iter: 40 loss: 3.9391336e-05
Iter: 41 loss: 4.42228848e-05
Iter: 42 loss: 3.9385759e-05
Iter: 43 loss: 3.90304704e-05
Iter: 44 loss: 3.97473086e-05
Iter: 45 loss: 3.88862245e-05
Iter: 46 loss: 3.85980675e-05
Iter: 47 loss: 3.85156673e-05
Iter: 48 loss: 3.8340746e-05
Iter: 49 loss: 3.79920057e-05
Iter: 50 loss: 3.91881404e-05
Iter: 51 loss: 3.78993136e-05
Iter: 52 loss: 3.76086973e-05
Iter: 53 loss: 3.88200642e-05
Iter: 54 loss: 3.7546477e-05
Iter: 55 loss: 3.73745861e-05
Iter: 56 loss: 3.73739531e-05
Iter: 57 loss: 3.72295617e-05
Iter: 58 loss: 3.73880612e-05
Iter: 59 loss: 3.71509086e-05
Iter: 60 loss: 3.70217676e-05
Iter: 61 loss: 3.70765774e-05
Iter: 62 loss: 3.69333175e-05
Iter: 63 loss: 3.68035799e-05
Iter: 64 loss: 3.76913631e-05
Iter: 65 loss: 3.67909452e-05
Iter: 66 loss: 3.66883687e-05
Iter: 67 loss: 3.75269665e-05
Iter: 68 loss: 3.6681944e-05
Iter: 69 loss: 3.66121603e-05
Iter: 70 loss: 3.65850428e-05
Iter: 71 loss: 3.65473097e-05
Iter: 72 loss: 3.64708176e-05
Iter: 73 loss: 3.73655e-05
Iter: 74 loss: 3.6469668e-05
Iter: 75 loss: 3.64086809e-05
Iter: 76 loss: 3.64645311e-05
Iter: 77 loss: 3.63733634e-05
Iter: 78 loss: 3.63142608e-05
Iter: 79 loss: 3.63833678e-05
Iter: 80 loss: 3.62829232e-05
Iter: 81 loss: 3.62332576e-05
Iter: 82 loss: 3.62332248e-05
Iter: 83 loss: 3.61941966e-05
Iter: 84 loss: 3.61776401e-05
Iter: 85 loss: 3.61573839e-05
Iter: 86 loss: 3.61113816e-05
Iter: 87 loss: 3.61889179e-05
Iter: 88 loss: 3.60906415e-05
Iter: 89 loss: 3.60551967e-05
Iter: 90 loss: 3.6582911e-05
Iter: 91 loss: 3.60552294e-05
Iter: 92 loss: 3.60251579e-05
Iter: 93 loss: 3.60411141e-05
Iter: 94 loss: 3.60052509e-05
Iter: 95 loss: 3.59754486e-05
Iter: 96 loss: 3.59871301e-05
Iter: 97 loss: 3.59549304e-05
Iter: 98 loss: 3.59214973e-05
Iter: 99 loss: 3.60373051e-05
Iter: 100 loss: 3.59126861e-05
Iter: 101 loss: 3.58839752e-05
Iter: 102 loss: 3.59706755e-05
Iter: 103 loss: 3.58755e-05
Iter: 104 loss: 3.58506659e-05
Iter: 105 loss: 3.59381374e-05
Iter: 106 loss: 3.58442921e-05
Iter: 107 loss: 3.58281904e-05
Iter: 108 loss: 3.60781924e-05
Iter: 109 loss: 3.58281795e-05
Iter: 110 loss: 3.5814046e-05
Iter: 111 loss: 3.5851448e-05
Iter: 112 loss: 3.58093312e-05
Iter: 113 loss: 3.57983299e-05
Iter: 114 loss: 3.57934587e-05
Iter: 115 loss: 3.57878671e-05
Iter: 116 loss: 3.57744066e-05
Iter: 117 loss: 3.58521138e-05
Iter: 118 loss: 3.57726385e-05
Iter: 119 loss: 3.57617828e-05
Iter: 120 loss: 3.5866251e-05
Iter: 121 loss: 3.57614699e-05
Iter: 122 loss: 3.5754194e-05
Iter: 123 loss: 3.57543031e-05
Iter: 124 loss: 3.57484969e-05
Iter: 125 loss: 3.57408135e-05
Iter: 126 loss: 3.5822115e-05
Iter: 127 loss: 3.57406789e-05
Iter: 128 loss: 3.57344616e-05
Iter: 129 loss: 3.57361423e-05
Iter: 130 loss: 3.57299286e-05
Iter: 131 loss: 3.57233876e-05
Iter: 132 loss: 3.57280078e-05
Iter: 133 loss: 3.57192112e-05
Iter: 134 loss: 3.57128374e-05
Iter: 135 loss: 3.57711979e-05
Iter: 136 loss: 3.571259e-05
Iter: 137 loss: 3.57069075e-05
Iter: 138 loss: 3.57314639e-05
Iter: 139 loss: 3.57057543e-05
Iter: 140 loss: 3.57015851e-05
Iter: 141 loss: 3.56997771e-05
Iter: 142 loss: 3.56976e-05
Iter: 143 loss: 3.56921555e-05
Iter: 144 loss: 3.57081699e-05
Iter: 145 loss: 3.56905075e-05
Iter: 146 loss: 3.56867167e-05
Iter: 147 loss: 3.57404497e-05
Iter: 148 loss: 3.56866876e-05
Iter: 149 loss: 3.56832825e-05
Iter: 150 loss: 3.56888559e-05
Iter: 151 loss: 3.56817509e-05
Iter: 152 loss: 3.56788587e-05
Iter: 153 loss: 3.56778146e-05
Iter: 154 loss: 3.56762393e-05
Iter: 155 loss: 3.56724049e-05
Iter: 156 loss: 3.56840246e-05
Iter: 157 loss: 3.56712844e-05
Iter: 158 loss: 3.56679302e-05
Iter: 159 loss: 3.56788551e-05
Iter: 160 loss: 3.56669261e-05
Iter: 161 loss: 3.56644596e-05
Iter: 162 loss: 3.56828095e-05
Iter: 163 loss: 3.5664285e-05
Iter: 164 loss: 3.56622404e-05
Iter: 165 loss: 3.56853416e-05
Iter: 166 loss: 3.56622331e-05
Iter: 167 loss: 3.56610035e-05
Iter: 168 loss: 3.56595483e-05
Iter: 169 loss: 3.5659381e-05
Iter: 170 loss: 3.56576202e-05
Iter: 171 loss: 3.56636956e-05
Iter: 172 loss: 3.56570235e-05
Iter: 173 loss: 3.56558157e-05
Iter: 174 loss: 3.56558121e-05
Iter: 175 loss: 3.56547716e-05
Iter: 176 loss: 3.5654266e-05
Iter: 177 loss: 3.5653833e-05
Iter: 178 loss: 3.5652658e-05
Iter: 179 loss: 3.56604141e-05
Iter: 180 loss: 3.56525925e-05
Iter: 181 loss: 3.56515811e-05
Iter: 182 loss: 3.56540841e-05
Iter: 183 loss: 3.56510791e-05
Iter: 184 loss: 3.5650246e-05
Iter: 185 loss: 3.56505152e-05
Iter: 186 loss: 3.56496566e-05
Iter: 187 loss: 3.56487108e-05
Iter: 188 loss: 3.56531673e-05
Iter: 189 loss: 3.56486198e-05
Iter: 190 loss: 3.56477685e-05
Iter: 191 loss: 3.5655863e-05
Iter: 192 loss: 3.56477576e-05
Iter: 193 loss: 3.56471937e-05
Iter: 194 loss: 3.56470337e-05
Iter: 195 loss: 3.56466699e-05
Iter: 196 loss: 3.56460405e-05
Iter: 197 loss: 3.56470482e-05
Iter: 198 loss: 3.5645764e-05
Iter: 199 loss: 3.56450801e-05
Iter: 200 loss: 3.56471937e-05
Iter: 201 loss: 3.564488e-05
Iter: 202 loss: 3.56442833e-05
Iter: 203 loss: 3.56464188e-05
Iter: 204 loss: 3.56442324e-05
Iter: 205 loss: 3.56438031e-05
Iter: 206 loss: 3.56497767e-05
Iter: 207 loss: 3.56437777e-05
Iter: 208 loss: 3.56433957e-05
Iter: 209 loss: 3.5643905e-05
Iter: 210 loss: 3.56432211e-05
Iter: 211 loss: 3.564297e-05
Iter: 212 loss: 3.56430246e-05
Iter: 213 loss: 3.56427627e-05
Iter: 214 loss: 3.56424425e-05
Iter: 215 loss: 3.56454e-05
Iter: 216 loss: 3.56423479e-05
Iter: 217 loss: 3.56420569e-05
Iter: 218 loss: 3.56437558e-05
Iter: 219 loss: 3.56420715e-05
Iter: 220 loss: 3.56418823e-05
Iter: 221 loss: 3.56416422e-05
Iter: 222 loss: 3.56417e-05
Iter: 223 loss: 3.56414675e-05
Iter: 224 loss: 3.56425335e-05
Iter: 225 loss: 3.56414239e-05
Iter: 226 loss: 3.56412129e-05
Iter: 227 loss: 3.5643774e-05
Iter: 228 loss: 3.56412784e-05
Iter: 229 loss: 3.56410965e-05
Iter: 230 loss: 3.56410128e-05
Iter: 231 loss: 3.56409255e-05
Iter: 232 loss: 3.56407836e-05
Iter: 233 loss: 3.56419696e-05
Iter: 234 loss: 3.56407763e-05
Iter: 235 loss: 3.56406163e-05
Iter: 236 loss: 3.56408673e-05
Iter: 237 loss: 3.56406235e-05
Iter: 238 loss: 3.56404198e-05
Iter: 239 loss: 3.56405071e-05
Iter: 240 loss: 3.56403398e-05
Iter: 241 loss: 3.5640147e-05
Iter: 242 loss: 3.56409109e-05
Iter: 243 loss: 3.56402161e-05
Iter: 244 loss: 3.56400778e-05
Iter: 245 loss: 3.56414312e-05
Iter: 246 loss: 3.56401288e-05
Iter: 247 loss: 3.56401069e-05
Iter: 248 loss: 3.56400051e-05
Iter: 249 loss: 3.56399432e-05
Iter: 250 loss: 3.56398705e-05
Iter: 251 loss: 3.56401e-05
Iter: 252 loss: 3.56398377e-05
Iter: 253 loss: 3.56397941e-05
Iter: 254 loss: 3.56405253e-05
Iter: 255 loss: 3.56397722e-05
Iter: 256 loss: 3.56397e-05
Iter: 257 loss: 3.56402088e-05
Iter: 258 loss: 3.56397286e-05
Iter: 259 loss: 3.56396522e-05
Iter: 260 loss: 3.56395685e-05
Iter: 261 loss: 3.56395904e-05
Iter: 262 loss: 3.56395612e-05
Iter: 263 loss: 3.56399469e-05
Iter: 264 loss: 3.56395685e-05
Iter: 265 loss: 3.5639514e-05
Iter: 266 loss: 3.56398232e-05
Iter: 267 loss: 3.56395176e-05
Iter: 268 loss: 3.56394121e-05
Iter: 269 loss: 3.56394376e-05
Iter: 270 loss: 3.5639423e-05
Iter: 271 loss: 3.56393721e-05
Iter: 272 loss: 3.5639554e-05
Iter: 273 loss: 3.56393866e-05
Iter: 274 loss: 3.56393721e-05
Iter: 275 loss: 3.56393502e-05
Iter: 276 loss: 3.56393684e-05
Iter: 277 loss: 3.56392629e-05
Iter: 278 loss: 3.56392338e-05
Iter: 279 loss: 3.56392484e-05
Iter: 280 loss: 3.56394703e-05
Iter: 281 loss: 3.56392593e-05
Iter: 282 loss: 3.56391974e-05
Iter: 283 loss: 3.5639292e-05
Iter: 284 loss: 3.56392447e-05
Iter: 285 loss: 3.56391902e-05
Iter: 286 loss: 3.56392084e-05
Iter: 287 loss: 3.56392156e-05
Iter: 288 loss: 3.56391465e-05
Iter: 289 loss: 3.56392557e-05
Iter: 290 loss: 3.56391829e-05
Iter: 291 loss: 3.56391029e-05
Iter: 292 loss: 3.5639303e-05
Iter: 293 loss: 3.5639081e-05
Iter: 294 loss: 3.56391465e-05
Iter: 295 loss: 3.56391065e-05
Iter: 296 loss: 3.56391138e-05
Iter: 297 loss: 3.56391138e-05
Iter: 298 loss: 3.56391247e-05
Iter: 299 loss: 3.56390883e-05
Iter: 300 loss: 3.5639132e-05
Iter: 301 loss: 3.56391211e-05
Iter: 302 loss: 3.56390956e-05
Iter: 303 loss: 3.56391247e-05
Iter: 304 loss: 3.5639132e-05
Iter: 305 loss: 3.5639132e-05
Iter: 306 loss: 3.56391101e-05
Iter: 307 loss: 3.56391283e-05
Iter: 308 loss: 3.56391174e-05
Iter: 309 loss: 3.56391247e-05
Iter: 310 loss: 3.56391211e-05
Iter: 311 loss: 3.56391174e-05
Iter: 312 loss: 3.56391247e-05
Iter: 313 loss: 3.56391174e-05
Iter: 314 loss: 3.56391174e-05
Iter: 315 loss: 3.56391174e-05
Iter: 316 loss: 3.56391211e-05
Iter: 317 loss: 3.56391211e-05
Iter: 318 loss: 3.56391211e-05
Iter: 319 loss: 3.56391174e-05
Iter: 320 loss: 3.56390774e-05
Iter: 321 loss: 3.56391793e-05
Iter: 322 loss: 3.56391101e-05
Iter: 323 loss: 3.56391101e-05
Iter: 324 loss: 3.56390265e-05
Iter: 325 loss: 3.56390774e-05
Iter: 326 loss: 3.56390374e-05
Iter: 327 loss: 3.56390265e-05
Iter: 328 loss: 3.56390301e-05
Iter: 329 loss: 3.56390519e-05
Iter: 330 loss: 3.56393648e-05
Iter: 331 loss: 3.56390665e-05
Iter: 332 loss: 3.56390883e-05
Iter: 333 loss: 3.56390556e-05
Iter: 334 loss: 3.56390374e-05
Iter: 335 loss: 3.56390483e-05
Iter: 336 loss: 3.56390374e-05
Iter: 337 loss: 3.56390628e-05
Iter: 338 loss: 3.56390374e-05
Iter: 339 loss: 3.56390519e-05
Iter: 340 loss: 3.56390447e-05
Iter: 341 loss: 3.56390701e-05
Iter: 342 loss: 3.56390519e-05
Iter: 343 loss: 3.56390628e-05
Iter: 344 loss: 3.5639041e-05
Iter: 345 loss: 3.56391e-05
Iter: 346 loss: 3.5639081e-05
Iter: 347 loss: 3.56391029e-05
Iter: 348 loss: 3.56390738e-05
Iter: 349 loss: 3.56390592e-05
Iter: 350 loss: 3.56390228e-05
Iter: 351 loss: 3.56390301e-05
Iter: 352 loss: 3.56390156e-05
Iter: 353 loss: 3.56390774e-05
Iter: 354 loss: 3.56390447e-05
Iter: 355 loss: 3.56389974e-05
Iter: 356 loss: 3.56389646e-05
Iter: 357 loss: 3.56390119e-05
Iter: 358 loss: 3.56390046e-05
Iter: 359 loss: 3.56390301e-05
Iter: 360 loss: 3.56390447e-05
Iter: 361 loss: 3.56390556e-05
Iter: 362 loss: 3.56390228e-05
Iter: 363 loss: 3.56390337e-05
Iter: 364 loss: 3.56390519e-05
Iter: 365 loss: 3.56390519e-05
Iter: 366 loss: 3.56390519e-05
Iter: 367 loss: 3.56390519e-05
Iter: 368 loss: 3.56390592e-05
Iter: 369 loss: 3.56390592e-05
Iter: 370 loss: 3.56390519e-05
Iter: 371 loss: 3.56390592e-05
Iter: 372 loss: 3.56390519e-05
Iter: 373 loss: 3.56390519e-05
Iter: 374 loss: 3.56390556e-05
Iter: 375 loss: 3.56390519e-05
Iter: 376 loss: 3.56390519e-05
Iter: 377 loss: 3.56390519e-05
Iter: 378 loss: 3.56390556e-05
Iter: 379 loss: 3.56390083e-05
Iter: 380 loss: 3.56391611e-05
Iter: 381 loss: 3.56390156e-05
Iter: 382 loss: 3.56389937e-05
Iter: 383 loss: 3.56389719e-05
Iter: 384 loss: 3.56389646e-05
Iter: 385 loss: 3.56389864e-05
Iter: 386 loss: 3.5639e-05
Iter: 387 loss: 3.56389646e-05
Iter: 388 loss: 3.56389864e-05
Iter: 389 loss: 3.56390265e-05
Iter: 390 loss: 3.56390046e-05
Iter: 391 loss: 3.56390228e-05
Iter: 392 loss: 3.56389864e-05
Iter: 393 loss: 3.5638961e-05
Iter: 394 loss: 3.56389646e-05
Iter: 395 loss: 3.56390046e-05
Iter: 396 loss: 3.56390301e-05
Iter: 397 loss: 3.56390046e-05
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.4
+ date
Tue Oct 27 20:38:24 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.4
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.4/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 0 --alpha 0.4 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.4/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7caa488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7caabf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7caa158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7caa9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7c626a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7c629d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7c62a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7c62840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7b7e6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7b7e510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7b75d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7af2158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7af2bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7ab8ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7ada6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7ada9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7ada730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7aafd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7aaf510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c79f32f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c79f39d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c79d66a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7974840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c79747b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7998598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c79498c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7949d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4a04a98c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7caa950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4a0442268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4c7974730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4a0428488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4a043c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4a043ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4a03d0a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7ff4a043cae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.061491482
Iter: 2 loss: 0.0602579564
Iter: 3 loss: 0.055498898
Iter: 4 loss: 0.0358086
Iter: 5 loss: 0.0849257857
Iter: 6 loss: 0.0235043466
Iter: 7 loss: 0.00911031198
Iter: 8 loss: 0.00862684101
Iter: 9 loss: 0.00491694547
Iter: 10 loss: 0.00488964096
Iter: 11 loss: 0.00314725353
Iter: 12 loss: 0.0164712146
Iter: 13 loss: 0.0030329721
Iter: 14 loss: 0.00221091649
Iter: 15 loss: 0.00563873071
Iter: 16 loss: 0.00198992691
Iter: 17 loss: 0.00149695249
Iter: 18 loss: 0.006910027
Iter: 19 loss: 0.00148584694
Iter: 20 loss: 0.00115933944
Iter: 21 loss: 0.00214139512
Iter: 22 loss: 0.00105770351
Iter: 23 loss: 0.000850190874
Iter: 24 loss: 0.00156389561
Iter: 25 loss: 0.000795089756
Iter: 26 loss: 0.000651685521
Iter: 27 loss: 0.00146148354
Iter: 28 loss: 0.000632133801
Iter: 29 loss: 0.000539660803
Iter: 30 loss: 0.00106331776
Iter: 31 loss: 0.000525646
Iter: 32 loss: 0.000461550429
Iter: 33 loss: 0.000695481198
Iter: 34 loss: 0.000445523241
Iter: 35 loss: 0.000395758776
Iter: 36 loss: 0.000672271068
Iter: 37 loss: 0.000388777233
Iter: 38 loss: 0.000351704191
Iter: 39 loss: 0.000454616093
Iter: 40 loss: 0.000339593098
Iter: 41 loss: 0.000309508061
Iter: 42 loss: 0.000366353896
Iter: 43 loss: 0.00029674152
Iter: 44 loss: 0.00027099729
Iter: 45 loss: 0.00039751135
Iter: 46 loss: 0.000266481191
Iter: 47 loss: 0.000246545766
Iter: 48 loss: 0.000371011614
Iter: 49 loss: 0.000244189374
Iter: 50 loss: 0.000229900383
Iter: 51 loss: 0.000256186264
Iter: 52 loss: 0.000223818191
Iter: 53 loss: 0.000211345367
Iter: 54 loss: 0.000291324483
Iter: 55 loss: 0.000209913327
Iter: 56 loss: 0.00020037475
Iter: 57 loss: 0.000233675135
Iter: 58 loss: 0.000197880421
Iter: 59 loss: 0.000189563
Iter: 60 loss: 0.000211349514
Iter: 61 loss: 0.000186717953
Iter: 62 loss: 0.000179325347
Iter: 63 loss: 0.000195255183
Iter: 64 loss: 0.000176462694
Iter: 65 loss: 0.000169837789
Iter: 66 loss: 0.000196858819
Iter: 67 loss: 0.000168368
Iter: 68 loss: 0.000163060016
Iter: 69 loss: 0.000189778119
Iter: 70 loss: 0.000162178039
Iter: 71 loss: 0.000157769275
Iter: 72 loss: 0.000168674684
Iter: 73 loss: 0.000156212045
Iter: 74 loss: 0.000152136679
Iter: 75 loss: 0.000158625568
Iter: 76 loss: 0.000150234817
Iter: 77 loss: 0.000146483522
Iter: 78 loss: 0.00016164218
Iter: 79 loss: 0.000145654747
Iter: 80 loss: 0.000142639721
Iter: 81 loss: 0.000155313697
Iter: 82 loss: 0.000141993602
Iter: 83 loss: 0.000139528871
Iter: 84 loss: 0.000151145039
Iter: 85 loss: 0.000139077834
Iter: 86 loss: 0.000136963019
Iter: 87 loss: 0.000143215919
Iter: 88 loss: 0.000136318
Iter: 89 loss: 0.00013445373
Iter: 90 loss: 0.000141059441
Iter: 91 loss: 0.000133971262
Iter: 92 loss: 0.000132250178
Iter: 93 loss: 0.000135731476
Iter: 94 loss: 0.000131552544
Iter: 95 loss: 0.000129966385
Iter: 96 loss: 0.000134694797
Iter: 97 loss: 0.000129483858
Iter: 98 loss: 0.000128156127
Iter: 99 loss: 0.000132424466
Iter: 100 loss: 0.00012778063
Iter: 101 loss: 0.000126587256
Iter: 102 loss: 0.000134234419
Iter: 103 loss: 0.000126455328
Iter: 104 loss: 0.000125533654
Iter: 105 loss: 0.000127414198
Iter: 106 loss: 0.000125161227
Iter: 107 loss: 0.000124296988
Iter: 108 loss: 0.00012657886
Iter: 109 loss: 0.000124006387
Iter: 110 loss: 0.000123242
Iter: 111 loss: 0.000129298933
Iter: 112 loss: 0.000123190359
Iter: 113 loss: 0.000122588943
Iter: 114 loss: 0.000123613863
Iter: 115 loss: 0.000122319019
Iter: 116 loss: 0.000121712044
Iter: 117 loss: 0.000122911093
Iter: 118 loss: 0.000121462632
Iter: 119 loss: 0.000120896686
Iter: 120 loss: 0.000122522644
Iter: 121 loss: 0.000120719356
Iter: 122 loss: 0.000120205128
Iter: 123 loss: 0.000122521742
Iter: 124 loss: 0.00012010504
Iter: 125 loss: 0.000119668694
Iter: 126 loss: 0.00012082883
Iter: 127 loss: 0.000119522636
Iter: 128 loss: 0.000119117445
Iter: 129 loss: 0.000119789467
Iter: 130 loss: 0.000118933203
Iter: 131 loss: 0.000118554737
Iter: 132 loss: 0.000119948723
Iter: 133 loss: 0.000118461066
Iter: 134 loss: 0.000118135882
Iter: 135 loss: 0.000119360258
Iter: 136 loss: 0.000118057695
Iter: 137 loss: 0.000117761025
Iter: 138 loss: 0.000119156553
Iter: 139 loss: 0.000117706921
Iter: 140 loss: 0.000117461947
Iter: 141 loss: 0.000118049218
Iter: 142 loss: 0.00011737326
Iter: 143 loss: 0.00011714705
Iter: 144 loss: 0.00011784974
Iter: 145 loss: 0.000117080803
Iter: 146 loss: 0.000116870651
Iter: 147 loss: 0.000117441334
Iter: 148 loss: 0.000116801661
Iter: 149 loss: 0.000116617892
Iter: 150 loss: 0.000117624571
Iter: 151 loss: 0.000116591131
Iter: 152 loss: 0.000116425792
Iter: 153 loss: 0.00011697528
Iter: 154 loss: 0.000116380237
Iter: 155 loss: 0.000116238225
Iter: 156 loss: 0.000116358868
Iter: 157 loss: 0.000116154195
Iter: 158 loss: 0.000116006333
Iter: 159 loss: 0.00011665999
Iter: 160 loss: 0.000115976785
Iter: 161 loss: 0.00011585169
Iter: 162 loss: 0.000116337316
Iter: 163 loss: 0.000115822579
Iter: 164 loss: 0.000115710456
Iter: 165 loss: 0.000115788614
Iter: 166 loss: 0.000115640563
Iter: 167 loss: 0.000115523624
Iter: 168 loss: 0.000115866555
Iter: 169 loss: 0.000115487761
Iter: 170 loss: 0.000115382958
Iter: 171 loss: 0.000115839328
Iter: 172 loss: 0.000115361661
Iter: 173 loss: 0.000115272152
Iter: 174 loss: 0.00011570919
Iter: 175 loss: 0.000115256538
Iter: 176 loss: 0.000115180927
Iter: 177 loss: 0.000115468029
Iter: 178 loss: 0.000115162657
Iter: 179 loss: 0.000115100207
Iter: 180 loss: 0.000115187162
Iter: 181 loss: 0.000115069168
Iter: 182 loss: 0.000115004477
Iter: 183 loss: 0.000115310359
Iter: 184 loss: 0.000114992683
Iter: 185 loss: 0.00011493788
Iter: 186 loss: 0.000115114177
Iter: 187 loss: 0.000114922521
Iter: 188 loss: 0.000114875111
Iter: 189 loss: 0.000115155504
Iter: 190 loss: 0.000114868941
Iter: 191 loss: 0.000114828988
Iter: 192 loss: 0.000114870476
Iter: 193 loss: 0.000114806768
Iter: 194 loss: 0.000114764181
Iter: 195 loss: 0.000114876922
Iter: 196 loss: 0.000114749972
Iter: 197 loss: 0.000114711205
Iter: 198 loss: 0.000114894014
Iter: 199 loss: 0.000114704279
Iter: 200 loss: 0.000114670023
Iter: 201 loss: 0.000114718081
Iter: 202 loss: 0.000114653019
Iter: 203 loss: 0.000114620321
Iter: 204 loss: 0.000114689625
Iter: 205 loss: 0.000114607428
Iter: 206 loss: 0.000114576607
Iter: 207 loss: 0.000114751303
Iter: 208 loss: 0.000114572256
Iter: 209 loss: 0.000114546536
Iter: 210 loss: 0.000114633374
Iter: 211 loss: 0.000114539616
Iter: 212 loss: 0.000114515758
Iter: 213 loss: 0.000114553084
Iter: 214 loss: 0.000114504539
Iter: 215 loss: 0.000114481358
Iter: 216 loss: 0.000114549723
Iter: 217 loss: 0.000114474286
Iter: 218 loss: 0.000114452429
Iter: 219 loss: 0.000114521434
Iter: 220 loss: 0.000114446157
Iter: 221 loss: 0.000114426774
Iter: 222 loss: 0.000114495844
Iter: 223 loss: 0.000114421789
Iter: 224 loss: 0.000114405513
Iter: 225 loss: 0.00011451231
Iter: 226 loss: 0.000114403738
Iter: 227 loss: 0.000114389266
Iter: 228 loss: 0.000114428265
Iter: 229 loss: 0.000114384755
Iter: 230 loss: 0.000114372247
Iter: 231 loss: 0.000114387047
Iter: 232 loss: 0.000114365546
Iter: 233 loss: 0.00011435234
Iter: 234 loss: 0.000114408322
Iter: 235 loss: 0.000114349605
Iter: 236 loss: 0.000114337658
Iter: 237 loss: 0.000114372378
Iter: 238 loss: 0.000114333918
Iter: 239 loss: 0.000114323135
Iter: 240 loss: 0.000114339869
Iter: 241 loss: 0.000114317969
Iter: 242 loss: 0.000114307404
Iter: 243 loss: 0.000114358649
Iter: 244 loss: 0.000114305491
Iter: 245 loss: 0.000114296563
Iter: 246 loss: 0.000114321709
Iter: 247 loss: 0.000114293747
Iter: 248 loss: 0.000114285605
Iter: 249 loss: 0.000114312505
Iter: 250 loss: 0.000114283335
Iter: 251 loss: 0.000114275994
Iter: 252 loss: 0.00011429876
Iter: 253 loss: 0.000114273804
Iter: 254 loss: 0.000114266913
Iter: 255 loss: 0.000114281152
Iter: 256 loss: 0.000114264105
Iter: 257 loss: 0.000114257513
Iter: 258 loss: 0.000114268929
Iter: 259 loss: 0.000114254406
Iter: 260 loss: 0.000114248447
Iter: 261 loss: 0.000114303301
Iter: 262 loss: 0.000114248025
Iter: 263 loss: 0.000114243558
Iter: 264 loss: 0.000114255505
Iter: 265 loss: 0.000114241913
Iter: 266 loss: 0.000114237591
Iter: 267 loss: 0.000114250674
Iter: 268 loss: 0.000114236325
Iter: 269 loss: 0.000114232447
Iter: 270 loss: 0.000114253016
Iter: 271 loss: 0.000114231749
Iter: 272 loss: 0.000114228613
Iter: 273 loss: 0.000114228678
Iter: 274 loss: 0.000114225943
Iter: 275 loss: 0.00011422189
Iter: 276 loss: 0.000114229937
Iter: 277 loss: 0.000114220384
Iter: 278 loss: 0.000114216346
Iter: 279 loss: 0.000114232709
Iter: 280 loss: 0.000114215611
Iter: 281 loss: 0.000114212256
Iter: 282 loss: 0.000114227558
Iter: 283 loss: 0.000114211696
Iter: 284 loss: 0.000114208873
Iter: 285 loss: 0.000114218281
Iter: 286 loss: 0.000114207985
Iter: 287 loss: 0.000114205461
Iter: 288 loss: 0.000114211776
Iter: 289 loss: 0.000114204573
Iter: 290 loss: 0.000114202274
Iter: 291 loss: 0.000114211551
Iter: 292 loss: 0.000114201554
Iter: 293 loss: 0.000114199531
Iter: 294 loss: 0.000114202921
Iter: 295 loss: 0.000114198599
Iter: 296 loss: 0.000114196533
Iter: 297 loss: 0.000114205832
Iter: 298 loss: 0.000114196184
Iter: 299 loss: 0.000114194459
Iter: 300 loss: 0.000114202128
Iter: 301 loss: 0.000114193965
Iter: 302 loss: 0.000114192713
Iter: 303 loss: 0.000114194132
Iter: 304 loss: 0.00011419168
Iter: 305 loss: 0.00011419037
Iter: 306 loss: 0.00011420346
Iter: 307 loss: 0.000114190269
Iter: 308 loss: 0.000114188988
Iter: 309 loss: 0.000114190698
Iter: 310 loss: 0.000114188435
Iter: 311 loss: 0.000114187285
Iter: 312 loss: 0.000114188064
Iter: 313 loss: 0.000114186565
Iter: 314 loss: 0.000114185154
Iter: 315 loss: 0.000114189839
Iter: 316 loss: 0.000114184732
Iter: 317 loss: 0.00011418364
Iter: 318 loss: 0.000114189272
Iter: 319 loss: 0.000114183378
Iter: 320 loss: 0.00011418241
Iter: 321 loss: 0.000114185968
Iter: 322 loss: 0.000114182214
Iter: 323 loss: 0.000114181457
Iter: 324 loss: 0.000114183829
Iter: 325 loss: 0.000114181159
Iter: 326 loss: 0.000114180162
Iter: 327 loss: 0.000114181996
Iter: 328 loss: 0.000114179995
Iter: 329 loss: 0.000114179129
Iter: 330 loss: 0.000114181399
Iter: 331 loss: 0.000114178976
Iter: 332 loss: 0.000114178372
Iter: 333 loss: 0.000114180941
Iter: 334 loss: 0.000114177987
Iter: 335 loss: 0.000114177434
Iter: 336 loss: 0.000114180497
Iter: 337 loss: 0.000114177325
Iter: 338 loss: 0.000114176932
Iter: 339 loss: 0.000114178023
Iter: 340 loss: 0.000114176612
Iter: 341 loss: 0.000114176197
Iter: 342 loss: 0.000114178009
Iter: 343 loss: 0.00011417616
Iter: 344 loss: 0.000114175789
Iter: 345 loss: 0.000114177674
Iter: 346 loss: 0.000114175695
Iter: 347 loss: 0.000114175185
Iter: 348 loss: 0.000114175535
Iter: 349 loss: 0.000114175054
Iter: 350 loss: 0.000114174582
Iter: 351 loss: 0.00011417616
Iter: 352 loss: 0.000114174472
Iter: 353 loss: 0.00011417424
Iter: 354 loss: 0.000114174996
Iter: 355 loss: 0.000114174145
Iter: 356 loss: 0.000114173818
Iter: 357 loss: 0.000114175389
Iter: 358 loss: 0.000114173687
Iter: 359 loss: 0.000114173476
Iter: 360 loss: 0.000114174094
Iter: 361 loss: 0.000114173294
Iter: 362 loss: 0.000114173083
Iter: 363 loss: 0.000114173497
Iter: 364 loss: 0.000114172981
Iter: 365 loss: 0.000114172704
Iter: 366 loss: 0.000114173483
Iter: 367 loss: 0.000114172653
Iter: 368 loss: 0.000114172261
Iter: 369 loss: 0.000114173381
Iter: 370 loss: 0.000114172246
Iter: 371 loss: 0.000114172071
Iter: 372 loss: 0.000114173417
Iter: 373 loss: 0.000114172115
Iter: 374 loss: 0.000114171897
Iter: 375 loss: 0.000114172406
Iter: 376 loss: 0.000114171708
Iter: 377 loss: 0.000114171729
Iter: 378 loss: 0.000114171977
Iter: 379 loss: 0.000114171518
Iter: 380 loss: 0.000114171446
Iter: 381 loss: 0.000114172595
Iter: 382 loss: 0.000114171504
Iter: 383 loss: 0.000114171256
Iter: 384 loss: 0.000114171475
Iter: 385 loss: 0.000114171293
Iter: 386 loss: 0.000114171198
Iter: 387 loss: 0.000114171402
Iter: 388 loss: 0.000114171024
Iter: 389 loss: 0.000114170922
Iter: 390 loss: 0.000114171329
Iter: 391 loss: 0.000114170951
Iter: 392 loss: 0.000114170762
Iter: 393 loss: 0.000114171089
Iter: 394 loss: 0.000114170813
Iter: 395 loss: 0.000114170689
Iter: 396 loss: 0.000114171024
Iter: 397 loss: 0.000114170711
Iter: 398 loss: 0.000114170645
Iter: 399 loss: 0.000114170762
Iter: 400 loss: 0.000114170522
Iter: 401 loss: 0.000114170376
Iter: 402 loss: 0.000114170565
Iter: 403 loss: 0.000114170361
Iter: 404 loss: 0.000114170449
Iter: 405 loss: 0.000114170834
Iter: 406 loss: 0.000114170398
Iter: 407 loss: 0.000114170303
Iter: 408 loss: 0.000114170485
Iter: 409 loss: 0.000114170252
Iter: 410 loss: 0.000114170238
Iter: 411 loss: 0.000114170281
Iter: 412 loss: 0.000114170107
Iter: 413 loss: 0.00011417002
Iter: 414 loss: 0.00011417034
Iter: 415 loss: 0.000114170121
Iter: 416 loss: 0.000114169889
Iter: 417 loss: 0.000114170216
Iter: 418 loss: 0.00011417
Iter: 419 loss: 0.00011416991
Iter: 420 loss: 0.000114170311
Iter: 421 loss: 0.000114169932
Iter: 422 loss: 0.000114169881
Iter: 423 loss: 0.000114169859
Iter: 424 loss: 0.000114169838
Iter: 425 loss: 0.000114169787
Iter: 426 loss: 0.000114169983
Iter: 427 loss: 0.000114169816
Iter: 428 loss: 0.000114169692
Iter: 429 loss: 0.000114169859
Iter: 430 loss: 0.000114169801
Iter: 431 loss: 0.000114169859
Iter: 432 loss: 0.000114169823
Iter: 433 loss: 0.000114169758
Iter: 434 loss: 0.000114169641
Iter: 435 loss: 0.000114169794
Iter: 436 loss: 0.000114169743
Iter: 437 loss: 0.000114169532
Iter: 438 loss: 0.000114169852
Iter: 439 loss: 0.000114169568
Iter: 440 loss: 0.000114169568
Iter: 441 loss: 0.000114169685
Iter: 442 loss: 0.000114169539
Iter: 443 loss: 0.000114169634
Iter: 444 loss: 0.000114169728
Iter: 445 loss: 0.00011416951
Iter: 446 loss: 0.000114169554
Iter: 447 loss: 0.00011416967
Iter: 448 loss: 0.000114169445
Iter: 449 loss: 0.000114169547
Iter: 450 loss: 0.000114169598
Iter: 451 loss: 0.000114169437
Iter: 452 loss: 0.000114169539
Iter: 453 loss: 0.000114169525
Iter: 454 loss: 0.000114169437
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.4/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.8
+ date
Tue Oct 27 20:44:59 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.8
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.8/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.4/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 0 --alpha 0.8 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.8/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e064a510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0656ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e061b950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e061b9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e05d4598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0578950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0578b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e052c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e052cf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e054c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e054cb70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e045e378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e045ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e04298c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e044a6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e044a840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e044a488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e03a9048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e03ef8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0361268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0361c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e03399d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e02e9ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e02e9510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e02fb598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e02a2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e02fbc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e028ed90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e052c6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e045e488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e021c378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e021c2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e020b2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e01dc8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e01768c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f70e0176400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0387214795
Iter: 2 loss: 0.037222378
Iter: 3 loss: 0.0316215791
Iter: 4 loss: 0.0224729069
Iter: 5 loss: 0.0211585313
Iter: 6 loss: 0.0133574288
Iter: 7 loss: 0.0126340054
Iter: 8 loss: 0.00781629886
Iter: 9 loss: 1.25993955
Iter: 10 loss: 0.00781569723
Iter: 11 loss: 0.00529685896
Iter: 12 loss: 0.0302944817
Iter: 13 loss: 0.0052399314
Iter: 14 loss: 0.00413930789
Iter: 15 loss: 0.00680606812
Iter: 16 loss: 0.00367727783
Iter: 17 loss: 0.0027165811
Iter: 18 loss: 0.0102059506
Iter: 19 loss: 0.00260291202
Iter: 20 loss: 0.00208307
Iter: 21 loss: 0.00979998335
Iter: 22 loss: 0.00208055344
Iter: 23 loss: 0.00175252091
Iter: 24 loss: 0.00322738383
Iter: 25 loss: 0.00168365811
Iter: 26 loss: 0.00145798805
Iter: 27 loss: 0.0020966786
Iter: 28 loss: 0.00138422614
Iter: 29 loss: 0.00121225871
Iter: 30 loss: 0.00272570364
Iter: 31 loss: 0.00119928748
Iter: 32 loss: 0.0010818881
Iter: 33 loss: 0.00146643084
Iter: 34 loss: 0.00104898866
Iter: 35 loss: 0.000963918632
Iter: 36 loss: 0.00178270438
Iter: 37 loss: 0.000959295372
Iter: 38 loss: 0.000892377226
Iter: 39 loss: 0.00125599047
Iter: 40 loss: 0.000883565
Iter: 41 loss: 0.000832887599
Iter: 42 loss: 0.000961027341
Iter: 43 loss: 0.000814621802
Iter: 44 loss: 0.000767801
Iter: 45 loss: 0.000893105811
Iter: 46 loss: 0.000751685584
Iter: 47 loss: 0.000711485394
Iter: 48 loss: 0.000818796689
Iter: 49 loss: 0.000698068936
Iter: 50 loss: 0.000660535123
Iter: 51 loss: 0.000780810835
Iter: 52 loss: 0.000649844878
Iter: 53 loss: 0.000619188824
Iter: 54 loss: 0.000766108104
Iter: 55 loss: 0.000613497803
Iter: 56 loss: 0.00058924628
Iter: 57 loss: 0.000670981943
Iter: 58 loss: 0.000582583481
Iter: 59 loss: 0.000561942172
Iter: 60 loss: 0.000678776065
Iter: 61 loss: 0.000559060252
Iter: 62 loss: 0.000541988295
Iter: 63 loss: 0.000587764254
Iter: 64 loss: 0.000536259613
Iter: 65 loss: 0.000522432383
Iter: 66 loss: 0.00058166869
Iter: 67 loss: 0.000519473746
Iter: 68 loss: 0.000506608456
Iter: 69 loss: 0.000550070312
Iter: 70 loss: 0.000503168965
Iter: 71 loss: 0.000493348285
Iter: 72 loss: 0.000561664696
Iter: 73 loss: 0.000492357765
Iter: 74 loss: 0.000483871379
Iter: 75 loss: 0.000510132639
Iter: 76 loss: 0.000481410098
Iter: 77 loss: 0.000473670312
Iter: 78 loss: 0.000486929377
Iter: 79 loss: 0.000470200292
Iter: 80 loss: 0.0004621158
Iter: 81 loss: 0.000477248046
Iter: 82 loss: 0.000458668801
Iter: 83 loss: 0.000450972933
Iter: 84 loss: 0.000467247562
Iter: 85 loss: 0.000447915139
Iter: 86 loss: 0.000440549891
Iter: 87 loss: 0.000469297
Iter: 88 loss: 0.000438842661
Iter: 89 loss: 0.000432448724
Iter: 90 loss: 0.00045672484
Iter: 91 loss: 0.000430914923
Iter: 92 loss: 0.00042561951
Iter: 93 loss: 0.000440907053
Iter: 94 loss: 0.000423955818
Iter: 95 loss: 0.000419093529
Iter: 96 loss: 0.000440249743
Iter: 97 loss: 0.000418105628
Iter: 98 loss: 0.000413724832
Iter: 99 loss: 0.000427257561
Iter: 100 loss: 0.000412419962
Iter: 101 loss: 0.000408498221
Iter: 102 loss: 0.000420091965
Iter: 103 loss: 0.000407289626
Iter: 104 loss: 0.000403727
Iter: 105 loss: 0.000421203353
Iter: 106 loss: 0.00040311896
Iter: 107 loss: 0.00040021824
Iter: 108 loss: 0.00041778537
Iter: 109 loss: 0.000399846758
Iter: 110 loss: 0.000397353957
Iter: 111 loss: 0.000400324876
Iter: 112 loss: 0.000396040385
Iter: 113 loss: 0.000393418944
Iter: 114 loss: 0.00040057482
Iter: 115 loss: 0.000392563117
Iter: 116 loss: 0.000390068075
Iter: 117 loss: 0.000393757073
Iter: 118 loss: 0.000388863322
Iter: 119 loss: 0.000386279891
Iter: 120 loss: 0.000392279326
Iter: 121 loss: 0.000385327177
Iter: 122 loss: 0.000382912229
Iter: 123 loss: 0.000393893337
Iter: 124 loss: 0.000382440601
Iter: 125 loss: 0.000380239275
Iter: 126 loss: 0.000384598039
Iter: 127 loss: 0.000379336183
Iter: 128 loss: 0.00037728282
Iter: 129 loss: 0.000384275103
Iter: 130 loss: 0.000376731768
Iter: 131 loss: 0.000374769443
Iter: 132 loss: 0.000382969563
Iter: 133 loss: 0.000374348
Iter: 134 loss: 0.000372676412
Iter: 135 loss: 0.000377819437
Iter: 136 loss: 0.000372183626
Iter: 137 loss: 0.000370645372
Iter: 138 loss: 0.000375705713
Iter: 139 loss: 0.000370218651
Iter: 140 loss: 0.000368936133
Iter: 141 loss: 0.000376890821
Iter: 142 loss: 0.000368786743
Iter: 143 loss: 0.00036768592
Iter: 144 loss: 0.000372118084
Iter: 145 loss: 0.000367436267
Iter: 146 loss: 0.000366528489
Iter: 147 loss: 0.000367384055
Iter: 148 loss: 0.000366009364
Iter: 149 loss: 0.000364960026
Iter: 150 loss: 0.000366873341
Iter: 151 loss: 0.000364507432
Iter: 152 loss: 0.000363478262
Iter: 153 loss: 0.000367076515
Iter: 154 loss: 0.000363206957
Iter: 155 loss: 0.000362226507
Iter: 156 loss: 0.000363801431
Iter: 157 loss: 0.000361775106
Iter: 158 loss: 0.000360812701
Iter: 159 loss: 0.000364105246
Iter: 160 loss: 0.000360554724
Iter: 161 loss: 0.000359707861
Iter: 162 loss: 0.000362682971
Iter: 163 loss: 0.000359488302
Iter: 164 loss: 0.000358704536
Iter: 165 loss: 0.000361166807
Iter: 166 loss: 0.000358477817
Iter: 167 loss: 0.000357760757
Iter: 168 loss: 0.000360518694
Iter: 169 loss: 0.000357591111
Iter: 170 loss: 0.000356932112
Iter: 171 loss: 0.000358346733
Iter: 172 loss: 0.000356674427
Iter: 173 loss: 0.000356060773
Iter: 174 loss: 0.000359811
Iter: 175 loss: 0.0003559865
Iter: 176 loss: 0.000355505908
Iter: 177 loss: 0.000358043
Iter: 178 loss: 0.000355432509
Iter: 179 loss: 0.000354991527
Iter: 180 loss: 0.000355809636
Iter: 181 loss: 0.000354802934
Iter: 182 loss: 0.000354380289
Iter: 183 loss: 0.000354578719
Iter: 184 loss: 0.000354095129
Iter: 185 loss: 0.00035356867
Iter: 186 loss: 0.000355464872
Iter: 187 loss: 0.000353436102
Iter: 188 loss: 0.000352996343
Iter: 189 loss: 0.000354246935
Iter: 190 loss: 0.000352856645
Iter: 191 loss: 0.000352430216
Iter: 192 loss: 0.000353241921
Iter: 193 loss: 0.000352251373
Iter: 194 loss: 0.000351800525
Iter: 195 loss: 0.000353089621
Iter: 196 loss: 0.000351658615
Iter: 197 loss: 0.000351258379
Iter: 198 loss: 0.000352777104
Iter: 199 loss: 0.000351162162
Iter: 200 loss: 0.000350782415
Iter: 201 loss: 0.000351761293
Iter: 202 loss: 0.000350652204
Iter: 203 loss: 0.000350295915
Iter: 204 loss: 0.000351579656
Iter: 205 loss: 0.000350205722
Iter: 206 loss: 0.000349896582
Iter: 207 loss: 0.000351354945
Iter: 208 loss: 0.000349839742
Iter: 209 loss: 0.000349583221
Iter: 210 loss: 0.000350507558
Iter: 211 loss: 0.000349518086
Iter: 212 loss: 0.000349274545
Iter: 213 loss: 0.000350724673
Iter: 214 loss: 0.000349244132
Iter: 215 loss: 0.000349050038
Iter: 216 loss: 0.000349050213
Iter: 217 loss: 0.000348895
Iter: 218 loss: 0.000348663103
Iter: 219 loss: 0.000349409587
Iter: 220 loss: 0.000348597619
Iter: 221 loss: 0.000348384929
Iter: 222 loss: 0.000348814938
Iter: 223 loss: 0.000348298927
Iter: 224 loss: 0.000348068948
Iter: 225 loss: 0.000348618341
Iter: 226 loss: 0.000347985188
Iter: 227 loss: 0.000347764493
Iter: 228 loss: 0.000348568894
Iter: 229 loss: 0.000347709458
Iter: 230 loss: 0.000347507361
Iter: 231 loss: 0.000347800902
Iter: 232 loss: 0.000347408757
Iter: 233 loss: 0.000347201858
Iter: 234 loss: 0.00034814066
Iter: 235 loss: 0.000347161898
Iter: 236 loss: 0.000346981047
Iter: 237 loss: 0.000347507244
Iter: 238 loss: 0.00034692511
Iter: 239 loss: 0.000346761255
Iter: 240 loss: 0.000347467343
Iter: 241 loss: 0.000346727757
Iter: 242 loss: 0.00034658151
Iter: 243 loss: 0.000346960442
Iter: 244 loss: 0.000346532033
Iter: 245 loss: 0.000346400775
Iter: 246 loss: 0.000347587833
Iter: 247 loss: 0.000346394663
Iter: 248 loss: 0.000346291752
Iter: 249 loss: 0.00034641294
Iter: 250 loss: 0.000346237037
Iter: 251 loss: 0.000346125453
Iter: 252 loss: 0.000346264394
Iter: 253 loss: 0.00034606742
Iter: 254 loss: 0.000345949607
Iter: 255 loss: 0.000346192566
Iter: 256 loss: 0.000345902488
Iter: 257 loss: 0.000345777196
Iter: 258 loss: 0.000346129178
Iter: 259 loss: 0.000345736917
Iter: 260 loss: 0.000345626642
Iter: 261 loss: 0.000346034067
Iter: 262 loss: 0.000345599197
Iter: 263 loss: 0.000345494889
Iter: 264 loss: 0.000345735229
Iter: 265 loss: 0.000345455715
Iter: 266 loss: 0.000345358276
Iter: 267 loss: 0.000345571374
Iter: 268 loss: 0.000345320877
Iter: 269 loss: 0.00034522402
Iter: 270 loss: 0.000345617067
Iter: 271 loss: 0.000345202803
Iter: 272 loss: 0.000345116045
Iter: 273 loss: 0.000345391803
Iter: 274 loss: 0.000345091277
Iter: 275 loss: 0.000345011067
Iter: 276 loss: 0.000345287408
Iter: 277 loss: 0.000344989821
Iter: 278 loss: 0.000344925968
Iter: 279 loss: 0.000345382665
Iter: 280 loss: 0.00034492038
Iter: 281 loss: 0.000344864151
Iter: 282 loss: 0.000345041626
Iter: 283 loss: 0.000344848144
Iter: 284 loss: 0.000344797503
Iter: 285 loss: 0.000344874046
Iter: 286 loss: 0.000344773289
Iter: 287 loss: 0.000344720902
Iter: 288 loss: 0.000344755535
Iter: 289 loss: 0.000344687898
Iter: 290 loss: 0.000344625209
Iter: 291 loss: 0.00034484567
Iter: 292 loss: 0.00034460891
Iter: 293 loss: 0.000344555796
Iter: 294 loss: 0.000344716624
Iter: 295 loss: 0.000344540109
Iter: 296 loss: 0.000344486529
Iter: 297 loss: 0.000344653439
Iter: 298 loss: 0.000344471133
Iter: 299 loss: 0.000344425236
Iter: 300 loss: 0.000344520668
Iter: 301 loss: 0.000344406872
Iter: 302 loss: 0.000344360305
Iter: 303 loss: 0.000344513624
Iter: 304 loss: 0.000344347325
Iter: 305 loss: 0.000344304077
Iter: 306 loss: 0.000344432687
Iter: 307 loss: 0.000344291126
Iter: 308 loss: 0.00034425137
Iter: 309 loss: 0.000344392465
Iter: 310 loss: 0.000344240805
Iter: 311 loss: 0.00034420492
Iter: 312 loss: 0.000344352797
Iter: 313 loss: 0.000344196858
Iter: 314 loss: 0.000344166445
Iter: 315 loss: 0.000344396656
Iter: 316 loss: 0.000344164495
Iter: 317 loss: 0.000344140775
Iter: 318 loss: 0.000344181666
Iter: 319 loss: 0.000344130327
Iter: 320 loss: 0.000344104716
Iter: 321 loss: 0.000344110129
Iter: 322 loss: 0.000344085711
Iter: 323 loss: 0.000344055763
Iter: 324 loss: 0.000344169966
Iter: 325 loss: 0.000344048545
Iter: 326 loss: 0.000344020751
Iter: 327 loss: 0.000344063505
Iter: 328 loss: 0.000344007771
Iter: 329 loss: 0.000343979627
Iter: 330 loss: 0.000344121101
Iter: 331 loss: 0.000343974971
Iter: 332 loss: 0.000343950232
Iter: 333 loss: 0.000343981694
Iter: 334 loss: 0.000343937776
Iter: 335 loss: 0.000343913067
Iter: 336 loss: 0.000344047148
Iter: 337 loss: 0.000343909371
Iter: 338 loss: 0.000343889
Iter: 339 loss: 0.000343918
Iter: 340 loss: 0.000343878753
Iter: 341 loss: 0.0003438571
Iter: 342 loss: 0.000343932479
Iter: 343 loss: 0.000343851571
Iter: 344 loss: 0.000343831722
Iter: 345 loss: 0.00034391
Iter: 346 loss: 0.00034382724
Iter: 347 loss: 0.000343810971
Iter: 348 loss: 0.000343915483
Iter: 349 loss: 0.000343809166
Iter: 350 loss: 0.000343794789
Iter: 351 loss: 0.000343846041
Iter: 352 loss: 0.000343791326
Iter: 353 loss: 0.000343778316
Iter: 354 loss: 0.000343793945
Iter: 355 loss: 0.000343771128
Iter: 356 loss: 0.000343757769
Iter: 357 loss: 0.000343770138
Iter: 358 loss: 0.000343750289
Iter: 359 loss: 0.000343735388
Iter: 360 loss: 0.000343801919
Iter: 361 loss: 0.000343732652
Iter: 362 loss: 0.000343719672
Iter: 363 loss: 0.000343742577
Iter: 364 loss: 0.000343713851
Iter: 365 loss: 0.000343701045
Iter: 366 loss: 0.00034374051
Iter: 367 loss: 0.00034369732
Iter: 368 loss: 0.000343684806
Iter: 369 loss: 0.000343732157
Iter: 370 loss: 0.000343682128
Iter: 371 loss: 0.000343670923
Iter: 372 loss: 0.000343695574
Iter: 373 loss: 0.000343666936
Iter: 374 loss: 0.00034365608
Iter: 375 loss: 0.000343686203
Iter: 376 loss: 0.000343652471
Iter: 377 loss: 0.000343642459
Iter: 378 loss: 0.000343668682
Iter: 379 loss: 0.000343638705
Iter: 380 loss: 0.000343629217
Iter: 381 loss: 0.000343687076
Iter: 382 loss: 0.000343628
Iter: 383 loss: 0.000343620399
Iter: 384 loss: 0.000343667169
Iter: 385 loss: 0.000343619729
Iter: 386 loss: 0.000343612977
Iter: 387 loss: 0.000343625841
Iter: 388 loss: 0.000343610358
Iter: 389 loss: 0.000343603839
Iter: 390 loss: 0.000343607477
Iter: 391 loss: 0.000343599531
Iter: 392 loss: 0.000343591848
Iter: 393 loss: 0.000343613559
Iter: 394 loss: 0.000343589461
Iter: 395 loss: 0.000343582098
Iter: 396 loss: 0.000343601539
Iter: 397 loss: 0.000343579566
Iter: 398 loss: 0.000343572639
Iter: 399 loss: 0.000343589491
Iter: 400 loss: 0.000343569962
Iter: 401 loss: 0.00034356321
Iter: 402 loss: 0.00034358626
Iter: 403 loss: 0.000343561551
Iter: 404 loss: 0.000343555526
Iter: 405 loss: 0.000343577238
Iter: 406 loss: 0.000343553664
Iter: 407 loss: 0.000343548134
Iter: 408 loss: 0.000343561289
Iter: 409 loss: 0.000343546097
Iter: 410 loss: 0.000343540509
Iter: 411 loss: 0.000343553635
Iter: 412 loss: 0.00034353853
Iter: 413 loss: 0.000343533145
Iter: 414 loss: 0.000343558786
Iter: 415 loss: 0.000343532069
Iter: 416 loss: 0.000343528169
Iter: 417 loss: 0.000343550812
Iter: 418 loss: 0.000343527528
Iter: 419 loss: 0.000343523774
Iter: 420 loss: 0.000343540567
Iter: 421 loss: 0.00034352293
Iter: 422 loss: 0.000343519496
Iter: 423 loss: 0.000343520369
Iter: 424 loss: 0.000343517167
Iter: 425 loss: 0.000343512918
Iter: 426 loss: 0.000343524909
Iter: 427 loss: 0.000343511667
Iter: 428 loss: 0.000343508174
Iter: 429 loss: 0.000343516091
Iter: 430 loss: 0.000343506574
Iter: 431 loss: 0.00034350279
Iter: 432 loss: 0.000343513588
Iter: 433 loss: 0.000343501742
Iter: 434 loss: 0.000343498279
Iter: 435 loss: 0.00034350832
Iter: 436 loss: 0.000343497464
Iter: 437 loss: 0.000343494234
Iter: 438 loss: 0.000343506
Iter: 439 loss: 0.000343493419
Iter: 440 loss: 0.000343490305
Iter: 441 loss: 0.000343497202
Iter: 442 loss: 0.000343489519
Iter: 443 loss: 0.00034348687
Iter: 444 loss: 0.000343494321
Iter: 445 loss: 0.000343485794
Iter: 446 loss: 0.000343483058
Iter: 447 loss: 0.00034349371
Iter: 448 loss: 0.000343482476
Iter: 449 loss: 0.000343479885
Iter: 450 loss: 0.000343485852
Iter: 451 loss: 0.000343479041
Iter: 452 loss: 0.000343477179
Iter: 453 loss: 0.000343501393
Iter: 454 loss: 0.000343477295
Iter: 455 loss: 0.000343475782
Iter: 456 loss: 0.000343476189
Iter: 457 loss: 0.00034347453
Iter: 458 loss: 0.000343472493
Iter: 459 loss: 0.000343476364
Iter: 460 loss: 0.000343471824
Iter: 461 loss: 0.000343469816
Iter: 462 loss: 0.000343473599
Iter: 463 loss: 0.000343469204
Iter: 464 loss: 0.000343466701
Iter: 465 loss: 0.000343472784
Iter: 466 loss: 0.000343466556
Iter: 467 loss: 0.000343464519
Iter: 468 loss: 0.000343468681
Iter: 469 loss: 0.000343463675
Iter: 470 loss: 0.000343461696
Iter: 471 loss: 0.000343468913
Iter: 472 loss: 0.000343461143
Iter: 473 loss: 0.000343459542
Iter: 474 loss: 0.000343463034
Iter: 475 loss: 0.000343458902
Iter: 476 loss: 0.000343457243
Iter: 477 loss: 0.000343463733
Iter: 478 loss: 0.00034345669
Iter: 479 loss: 0.000343455205
Iter: 480 loss: 0.00034346024
Iter: 481 loss: 0.000343454798
Iter: 482 loss: 0.00034345343
Iter: 483 loss: 0.00034345832
Iter: 484 loss: 0.000343453139
Iter: 485 loss: 0.000343452033
Iter: 486 loss: 0.000343456632
Iter: 487 loss: 0.000343451626
Iter: 488 loss: 0.000343450898
Iter: 489 loss: 0.000343458494
Iter: 490 loss: 0.000343450753
Iter: 491 loss: 0.000343449792
Iter: 492 loss: 0.00034344921
Iter: 493 loss: 0.000343448977
Iter: 494 loss: 0.000343448133
Iter: 495 loss: 0.000343452848
Iter: 496 loss: 0.000343447813
Iter: 497 loss: 0.000343446794
Iter: 498 loss: 0.000343448191
Iter: 499 loss: 0.000343446416
Iter: 500 loss: 0.000343445194
Iter: 501 loss: 0.000343448191
Iter: 502 loss: 0.000343445048
Iter: 503 loss: 0.000343444117
Iter: 504 loss: 0.000343447929
Iter: 505 loss: 0.000343443709
Iter: 506 loss: 0.000343442953
Iter: 507 loss: 0.000343444146
Iter: 508 loss: 0.000343442312
Iter: 509 loss: 0.000343441818
Iter: 510 loss: 0.000343445514
Iter: 511 loss: 0.000343441556
Iter: 512 loss: 0.00034344045
Iter: 513 loss: 0.000343442487
Iter: 514 loss: 0.000343440246
Iter: 515 loss: 0.000343439577
Iter: 516 loss: 0.000343442429
Iter: 517 loss: 0.000343439344
Iter: 518 loss: 0.000343438616
Iter: 519 loss: 0.000343441148
Iter: 520 loss: 0.000343438442
Iter: 521 loss: 0.000343437947
Iter: 522 loss: 0.000343442749
Iter: 523 loss: 0.000343437801
Iter: 524 loss: 0.000343437539
Iter: 525 loss: 0.000343437889
Iter: 526 loss: 0.000343436841
Iter: 527 loss: 0.00034343655
Iter: 528 loss: 0.00034343719
Iter: 529 loss: 0.000343436288
Iter: 530 loss: 0.000343435764
Iter: 531 loss: 0.000343437452
Iter: 532 loss: 0.000343435589
Iter: 533 loss: 0.00034343492
Iter: 534 loss: 0.000343436288
Iter: 535 loss: 0.000343434804
Iter: 536 loss: 0.000343434134
Iter: 537 loss: 0.000343435939
Iter: 538 loss: 0.000343434047
Iter: 539 loss: 0.00034343364
Iter: 540 loss: 0.000343434978
Iter: 541 loss: 0.000343433465
Iter: 542 loss: 0.000343433174
Iter: 543 loss: 0.000343434367
Iter: 544 loss: 0.000343432825
Iter: 545 loss: 0.000343432184
Iter: 546 loss: 0.000343434251
Iter: 547 loss: 0.000343432243
Iter: 548 loss: 0.000343431922
Iter: 549 loss: 0.000343432854
Iter: 550 loss: 0.000343431719
Iter: 551 loss: 0.000343431224
Iter: 552 loss: 0.000343432417
Iter: 553 loss: 0.000343431137
Iter: 554 loss: 0.000343430962
Iter: 555 loss: 0.000343433348
Iter: 556 loss: 0.000343430875
Iter: 557 loss: 0.000343430584
Iter: 558 loss: 0.00034343166
Iter: 559 loss: 0.000343430496
Iter: 560 loss: 0.000343430409
Iter: 561 loss: 0.00034343038
Iter: 562 loss: 0.000343430089
Iter: 563 loss: 0.000343429943
Iter: 564 loss: 0.000343430147
Iter: 565 loss: 0.000343429478
Iter: 566 loss: 0.000343429449
Iter: 567 loss: 0.000343430904
Iter: 568 loss: 0.000343429274
Iter: 569 loss: 0.000343428866
Iter: 570 loss: 0.000343429536
Iter: 571 loss: 0.000343428866
Iter: 572 loss: 0.000343428634
Iter: 573 loss: 0.000343429216
Iter: 574 loss: 0.000343428692
Iter: 575 loss: 0.00034342811
Iter: 576 loss: 0.000343428866
Iter: 577 loss: 0.000343428168
Iter: 578 loss: 0.000343427935
Iter: 579 loss: 0.000343428925
Iter: 580 loss: 0.000343428022
Iter: 581 loss: 0.000343427644
Iter: 582 loss: 0.000343428168
Iter: 583 loss: 0.000343427877
Iter: 584 loss: 0.000343427469
Iter: 585 loss: 0.00034342811
Iter: 586 loss: 0.00034342744
Iter: 587 loss: 0.000343427178
Iter: 588 loss: 0.000343428
Iter: 589 loss: 0.000343427149
Iter: 590 loss: 0.000343427062
Iter: 591 loss: 0.000343428052
Iter: 592 loss: 0.000343426829
Iter: 593 loss: 0.000343426655
Iter: 594 loss: 0.000343427
Iter: 595 loss: 0.000343426946
Iter: 596 loss: 0.000343426596
Iter: 597 loss: 0.000343426625
Iter: 598 loss: 0.000343426596
Iter: 599 loss: 0.000343426247
Iter: 600 loss: 0.000343426829
Iter: 601 loss: 0.000343426218
Iter: 602 loss: 0.000343426422
Iter: 603 loss: 0.000343426334
Iter: 604 loss: 0.000343425956
Iter: 605 loss: 0.000343425985
Iter: 606 loss: 0.000343426713
Iter: 607 loss: 0.000343426
Iter: 608 loss: 0.000343425927
Iter: 609 loss: 0.000343425723
Iter: 610 loss: 0.000343425607
Iter: 611 loss: 0.000343425665
Iter: 612 loss: 0.000343426364
Iter: 613 loss: 0.000343425549
Iter: 614 loss: 0.00034342584
Iter: 615 loss: 0.000343425781
Iter: 616 loss: 0.000343425316
Iter: 617 loss: 0.000343425258
Iter: 618 loss: 0.000343425578
Iter: 619 loss: 0.000343425228
Iter: 620 loss: 0.000343425054
Iter: 621 loss: 0.000343425549
Iter: 622 loss: 0.000343425141
Iter: 623 loss: 0.00034342517
Iter: 624 loss: 0.000343425927
Iter: 625 loss: 0.000343425199
Iter: 626 loss: 0.000343425083
Iter: 627 loss: 0.000343425025
Iter: 628 loss: 0.000343425
Iter: 629 loss: 0.000343424792
Iter: 630 loss: 0.00034342485
Iter: 631 loss: 0.000343424908
Iter: 632 loss: 0.000343425
Iter: 633 loss: 0.000343424908
Iter: 634 loss: 0.000343424763
Iter: 635 loss: 0.000343424821
Iter: 636 loss: 0.000343424967
Iter: 637 loss: 0.000343424734
Iter: 638 loss: 0.000343424472
Iter: 639 loss: 0.000343425083
Iter: 640 loss: 0.000343424501
Iter: 641 loss: 0.000343424414
Iter: 642 loss: 0.000343424501
Iter: 643 loss: 0.00034342421
Iter: 644 loss: 0.000343424384
Iter: 645 loss: 0.000343424501
Iter: 646 loss: 0.000343424443
Iter: 647 loss: 0.00034342421
Iter: 648 loss: 0.000343424617
Iter: 649 loss: 0.000343424384
Iter: 650 loss: 0.000343424297
Iter: 651 loss: 0.00034342421
Iter: 652 loss: 0.000343424268
Iter: 653 loss: 0.000343424123
Iter: 654 loss: 0.00034342453
Iter: 655 loss: 0.000343424355
Iter: 656 loss: 0.000343424152
Iter: 657 loss: 0.000343424
Iter: 658 loss: 0.000343423832
Iter: 659 loss: 0.000343424064
Iter: 660 loss: 0.000343424181
Iter: 661 loss: 0.000343424268
Iter: 662 loss: 0.00034342421
Iter: 663 loss: 0.000343424123
Iter: 664 loss: 0.000343423977
Iter: 665 loss: 0.000343423977
Iter: 666 loss: 0.00034342421
Iter: 667 loss: 0.000343424035
Iter: 668 loss: 0.000343423832
Iter: 669 loss: 0.000343423861
Iter: 670 loss: 0.000343423977
Iter: 671 loss: 0.000343424
Iter: 672 loss: 0.000343423919
Iter: 673 loss: 0.00034342389
Iter: 674 loss: 0.000343424064
Iter: 675 loss: 0.00034342389
Iter: 676 loss: 0.000343424093
Iter: 677 loss: 0.000343424093
Iter: 678 loss: 0.000343423773
Iter: 679 loss: 0.000343423657
Iter: 680 loss: 0.00034342389
Iter: 681 loss: 0.000343423628
Iter: 682 loss: 0.000343423599
Iter: 683 loss: 0.000343423744
Iter: 684 loss: 0.000343423599
Iter: 685 loss: 0.000343423919
Iter: 686 loss: 0.000343423919
Iter: 687 loss: 0.000343423744
Iter: 688 loss: 0.000343423686
Iter: 689 loss: 0.000343423861
Iter: 690 loss: 0.000343423832
Iter: 691 loss: 0.000343423628
Iter: 692 loss: 0.000343423832
Iter: 693 loss: 0.000343423773
Iter: 694 loss: 0.000343423308
Iter: 695 loss: 0.000343424093
Iter: 696 loss: 0.000343423744
Iter: 697 loss: 0.000343423482
Iter: 698 loss: 0.000343423686
Iter: 699 loss: 0.00034342357
Iter: 700 loss: 0.000343423715
Iter: 701 loss: 0.000343423802
Iter: 702 loss: 0.000343423424
Iter: 703 loss: 0.000343423744
Iter: 704 loss: 0.00034342357
Iter: 705 loss: 0.000343423686
Iter: 706 loss: 0.00034342357
Iter: 707 loss: 0.00034342357
Iter: 708 loss: 0.000343423511
Iter: 709 loss: 0.000343423453
Iter: 710 loss: 0.000343423802
Iter: 711 loss: 0.000343423861
Iter: 712 loss: 0.000343423395
Iter: 713 loss: 0.00034342354
Iter: 714 loss: 0.000343423453
Iter: 715 loss: 0.000343423511
Iter: 716 loss: 0.000343423511
Iter: 717 loss: 0.00034342357
Iter: 718 loss: 0.00034342357
Iter: 719 loss: 0.000343423482
Iter: 720 loss: 0.000343423686
Iter: 721 loss: 0.000343423366
Iter: 722 loss: 0.000343423279
Iter: 723 loss: 0.000343423511
Iter: 724 loss: 0.00034342322
Iter: 725 loss: 0.000343423482
Iter: 726 loss: 0.000343423511
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.8/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.2
+ date
Tue Oct 27 20:55:01 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi0.8/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 0 --alpha 1.2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866c7b268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866c7ed08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866c047b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866c04d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866c397b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866c39b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b90950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b908c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b90488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b5fe18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b5f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b5fa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b25b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b5f620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b259d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866b25c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866a8ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866a0f730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866a0f7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48669e0bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48669e0950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f486699e9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866942a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f486699ea60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866976400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866911620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4866911b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48668d7268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48668d79d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48668d7c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48668d7ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48668d7b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f48668791e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482a39b7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482a32c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f482a32c9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0276654493
Iter: 2 loss: 0.0251441672
Iter: 3 loss: 0.0172556266
Iter: 4 loss: 20890.2402
Iter: 5 loss: 0.0223117694
Iter: 6 loss: 0.0182894096
Iter: 7 loss: 0.0125451554
Iter: 8 loss: 0.0109932236
Iter: 9 loss: 0.00791758578
Iter: 10 loss: 0.106822714
Iter: 11 loss: 0.00791565888
Iter: 12 loss: 0.00608781
Iter: 13 loss: 0.00608541816
Iter: 14 loss: 0.00496893376
Iter: 15 loss: 0.00806929916
Iter: 16 loss: 0.00469288602
Iter: 17 loss: 0.00389127713
Iter: 18 loss: 0.00512250373
Iter: 19 loss: 0.00344417
Iter: 20 loss: 0.00288274046
Iter: 21 loss: 0.00539096631
Iter: 22 loss: 0.00275791599
Iter: 23 loss: 0.00231959368
Iter: 24 loss: 0.00633337302
Iter: 25 loss: 0.00229875441
Iter: 26 loss: 0.0020049708
Iter: 27 loss: 0.00501030544
Iter: 28 loss: 0.00199348922
Iter: 29 loss: 0.00181388925
Iter: 30 loss: 0.00233861664
Iter: 31 loss: 0.00175763539
Iter: 32 loss: 0.00160612282
Iter: 33 loss: 0.00301550841
Iter: 34 loss: 0.00159461144
Iter: 35 loss: 0.00148853892
Iter: 36 loss: 0.00176416198
Iter: 37 loss: 0.00145166297
Iter: 38 loss: 0.00134510442
Iter: 39 loss: 0.00170185
Iter: 40 loss: 0.00131684134
Iter: 41 loss: 0.00124484708
Iter: 42 loss: 0.00210878812
Iter: 43 loss: 0.00124316488
Iter: 44 loss: 0.00118815119
Iter: 45 loss: 0.00128739316
Iter: 46 loss: 0.00116435508
Iter: 47 loss: 0.00111243315
Iter: 48 loss: 0.00123184337
Iter: 49 loss: 0.00109308772
Iter: 50 loss: 0.00105145085
Iter: 51 loss: 0.00142985175
Iter: 52 loss: 0.00104959658
Iter: 53 loss: 0.00101501076
Iter: 54 loss: 0.001064096
Iter: 55 loss: 0.000997767085
Iter: 56 loss: 0.000967164058
Iter: 57 loss: 0.00101220864
Iter: 58 loss: 0.000952157076
Iter: 59 loss: 0.000919806422
Iter: 60 loss: 0.00106249773
Iter: 61 loss: 0.00091354805
Iter: 62 loss: 0.000887086557
Iter: 63 loss: 0.00092853
Iter: 64 loss: 0.000874511141
Iter: 65 loss: 0.000849178177
Iter: 66 loss: 0.000962413556
Iter: 67 loss: 0.000844344613
Iter: 68 loss: 0.00082162465
Iter: 69 loss: 0.000935461663
Iter: 70 loss: 0.000817602966
Iter: 71 loss: 0.000802268623
Iter: 72 loss: 0.000904704619
Iter: 73 loss: 0.000800718379
Iter: 74 loss: 0.000787308265
Iter: 75 loss: 0.000798081
Iter: 76 loss: 0.000779320602
Iter: 77 loss: 0.000766034878
Iter: 78 loss: 0.000850704499
Iter: 79 loss: 0.000764429453
Iter: 80 loss: 0.000752759166
Iter: 81 loss: 0.00078066875
Iter: 82 loss: 0.00074857939
Iter: 83 loss: 0.000737509807
Iter: 84 loss: 0.000753622153
Iter: 85 loss: 0.000732120883
Iter: 86 loss: 0.000721850141
Iter: 87 loss: 0.000800461043
Iter: 88 loss: 0.00072107889
Iter: 89 loss: 0.000712708046
Iter: 90 loss: 0.000734024681
Iter: 91 loss: 0.000709828339
Iter: 92 loss: 0.000701552839
Iter: 93 loss: 0.00071369519
Iter: 94 loss: 0.000697564159
Iter: 95 loss: 0.000689534936
Iter: 96 loss: 0.000703781669
Iter: 97 loss: 0.000686012208
Iter: 98 loss: 0.000677428
Iter: 99 loss: 0.000703662285
Iter: 100 loss: 0.000674823299
Iter: 101 loss: 0.000666871318
Iter: 102 loss: 0.000701205223
Iter: 103 loss: 0.000665268279
Iter: 104 loss: 0.000658771663
Iter: 105 loss: 0.000669079483
Iter: 106 loss: 0.000655725715
Iter: 107 loss: 0.000649326772
Iter: 108 loss: 0.00067748013
Iter: 109 loss: 0.000648035319
Iter: 110 loss: 0.000642347848
Iter: 111 loss: 0.000686433
Iter: 112 loss: 0.00064195256
Iter: 113 loss: 0.000637704507
Iter: 114 loss: 0.000640908722
Iter: 115 loss: 0.000635097327
Iter: 116 loss: 0.000630299095
Iter: 117 loss: 0.00064683333
Iter: 118 loss: 0.000629037735
Iter: 119 loss: 0.000624749286
Iter: 120 loss: 0.000646416214
Iter: 121 loss: 0.000624012901
Iter: 122 loss: 0.000620470033
Iter: 123 loss: 0.000627320143
Iter: 124 loss: 0.000619006052
Iter: 125 loss: 0.000615315628
Iter: 126 loss: 0.000626710127
Iter: 127 loss: 0.000614216435
Iter: 128 loss: 0.000610886607
Iter: 129 loss: 0.00062284572
Iter: 130 loss: 0.000610029907
Iter: 131 loss: 0.000606893096
Iter: 132 loss: 0.000614808931
Iter: 133 loss: 0.000605813169
Iter: 134 loss: 0.000602803251
Iter: 135 loss: 0.000604236557
Iter: 136 loss: 0.000600777101
Iter: 137 loss: 0.000597122242
Iter: 138 loss: 0.000604691624
Iter: 139 loss: 0.000595664722
Iter: 140 loss: 0.000592236465
Iter: 141 loss: 0.00061004766
Iter: 142 loss: 0.000591682969
Iter: 143 loss: 0.000588668394
Iter: 144 loss: 0.0005984077
Iter: 145 loss: 0.000587823684
Iter: 146 loss: 0.000585133
Iter: 147 loss: 0.000588349707
Iter: 148 loss: 0.000583709276
Iter: 149 loss: 0.000581014261
Iter: 150 loss: 0.000598782208
Iter: 151 loss: 0.000580734108
Iter: 152 loss: 0.000578480889
Iter: 153 loss: 0.000583088084
Iter: 154 loss: 0.000577573199
Iter: 155 loss: 0.000575443613
Iter: 156 loss: 0.000584221096
Iter: 157 loss: 0.000574973063
Iter: 158 loss: 0.000573235913
Iter: 159 loss: 0.000584333611
Iter: 160 loss: 0.000573049
Iter: 161 loss: 0.000571485434
Iter: 162 loss: 0.000575909682
Iter: 163 loss: 0.000570986653
Iter: 164 loss: 0.000569632917
Iter: 165 loss: 0.000571220357
Iter: 166 loss: 0.000568913878
Iter: 167 loss: 0.000567324692
Iter: 168 loss: 0.000576006365
Iter: 169 loss: 0.000567094539
Iter: 170 loss: 0.000565815833
Iter: 171 loss: 0.000565772469
Iter: 172 loss: 0.000564778922
Iter: 173 loss: 0.000563094218
Iter: 174 loss: 0.000567032839
Iter: 175 loss: 0.000562471396
Iter: 176 loss: 0.000560979126
Iter: 177 loss: 0.000569425756
Iter: 178 loss: 0.000560780463
Iter: 179 loss: 0.000559372886
Iter: 180 loss: 0.000564649468
Iter: 181 loss: 0.000559026841
Iter: 182 loss: 0.000557918334
Iter: 183 loss: 0.000557639287
Iter: 184 loss: 0.000556941493
Iter: 185 loss: 0.000555504521
Iter: 186 loss: 0.000563561916
Iter: 187 loss: 0.000555303588
Iter: 188 loss: 0.000554124243
Iter: 189 loss: 0.000558228639
Iter: 190 loss: 0.000553814811
Iter: 191 loss: 0.000552714919
Iter: 192 loss: 0.000553918886
Iter: 193 loss: 0.000552115438
Iter: 194 loss: 0.000550985802
Iter: 195 loss: 0.000556948711
Iter: 196 loss: 0.000550809549
Iter: 197 loss: 0.000549824676
Iter: 198 loss: 0.000552030513
Iter: 199 loss: 0.000549452554
Iter: 200 loss: 0.000548623619
Iter: 201 loss: 0.000560320797
Iter: 202 loss: 0.00054862164
Iter: 203 loss: 0.000548002543
Iter: 204 loss: 0.000547661912
Iter: 205 loss: 0.000547388277
Iter: 206 loss: 0.00054651493
Iter: 207 loss: 0.000551951409
Iter: 208 loss: 0.000546413823
Iter: 209 loss: 0.000545703049
Iter: 210 loss: 0.000546840369
Iter: 211 loss: 0.000545372663
Iter: 212 loss: 0.000544637674
Iter: 213 loss: 0.000545419287
Iter: 214 loss: 0.000544234063
Iter: 215 loss: 0.000543439412
Iter: 216 loss: 0.000546652183
Iter: 217 loss: 0.000543264
Iter: 218 loss: 0.000542512687
Iter: 219 loss: 0.000545517483
Iter: 220 loss: 0.000542341731
Iter: 221 loss: 0.000541717687
Iter: 222 loss: 0.000543347094
Iter: 223 loss: 0.000541506917
Iter: 224 loss: 0.000540835783
Iter: 225 loss: 0.000542137888
Iter: 226 loss: 0.000540556153
Iter: 227 loss: 0.000539933331
Iter: 228 loss: 0.000541313319
Iter: 229 loss: 0.000539695437
Iter: 230 loss: 0.000539055036
Iter: 231 loss: 0.000539868837
Iter: 232 loss: 0.000538725697
Iter: 233 loss: 0.000538084481
Iter: 234 loss: 0.000540720706
Iter: 235 loss: 0.000537944725
Iter: 236 loss: 0.000537424698
Iter: 237 loss: 0.000541645335
Iter: 238 loss: 0.000537392742
Iter: 239 loss: 0.000536942389
Iter: 240 loss: 0.000538670691
Iter: 241 loss: 0.000536835345
Iter: 242 loss: 0.000536433596
Iter: 243 loss: 0.000537207583
Iter: 244 loss: 0.000536266074
Iter: 245 loss: 0.000535857107
Iter: 246 loss: 0.000536531
Iter: 247 loss: 0.000535670668
Iter: 248 loss: 0.000535239233
Iter: 249 loss: 0.000537095533
Iter: 250 loss: 0.000535150641
Iter: 251 loss: 0.000534770254
Iter: 252 loss: 0.00053535495
Iter: 253 loss: 0.000534590217
Iter: 254 loss: 0.00053419359
Iter: 255 loss: 0.000535037543
Iter: 256 loss: 0.000534038176
Iter: 257 loss: 0.000533640152
Iter: 258 loss: 0.000534579274
Iter: 259 loss: 0.000533494458
Iter: 260 loss: 0.000533123559
Iter: 261 loss: 0.000536419102
Iter: 262 loss: 0.000533106155
Iter: 263 loss: 0.000532823731
Iter: 264 loss: 0.000532738224
Iter: 265 loss: 0.000532570179
Iter: 266 loss: 0.000532190956
Iter: 267 loss: 0.000533115643
Iter: 268 loss: 0.000532055856
Iter: 269 loss: 0.000531693397
Iter: 270 loss: 0.000532798585
Iter: 271 loss: 0.000531585305
Iter: 272 loss: 0.000531243277
Iter: 273 loss: 0.000532767503
Iter: 274 loss: 0.000531175756
Iter: 275 loss: 0.000530861202
Iter: 276 loss: 0.000532039732
Iter: 277 loss: 0.000530785765
Iter: 278 loss: 0.000530528545
Iter: 279 loss: 0.000532914186
Iter: 280 loss: 0.000530516845
Iter: 281 loss: 0.000530333
Iter: 282 loss: 0.000530187564
Iter: 283 loss: 0.000530130928
Iter: 284 loss: 0.000529859797
Iter: 285 loss: 0.00053121394
Iter: 286 loss: 0.000529814162
Iter: 287 loss: 0.000529573066
Iter: 288 loss: 0.00053035235
Iter: 289 loss: 0.000529505429
Iter: 290 loss: 0.000529290119
Iter: 291 loss: 0.000529826735
Iter: 292 loss: 0.000529214158
Iter: 293 loss: 0.000528992
Iter: 294 loss: 0.000529137906
Iter: 295 loss: 0.000528851233
Iter: 296 loss: 0.000528620672
Iter: 297 loss: 0.000530156074
Iter: 298 loss: 0.000528596749
Iter: 299 loss: 0.000528401
Iter: 300 loss: 0.000528966484
Iter: 301 loss: 0.000528340344
Iter: 302 loss: 0.000528156059
Iter: 303 loss: 0.00052868994
Iter: 304 loss: 0.000528098957
Iter: 305 loss: 0.000527918455
Iter: 306 loss: 0.000528009143
Iter: 307 loss: 0.000527797849
Iter: 308 loss: 0.000527582364
Iter: 309 loss: 0.00052819564
Iter: 310 loss: 0.000527514261
Iter: 311 loss: 0.000527307391
Iter: 312 loss: 0.000528120785
Iter: 313 loss: 0.000527259894
Iter: 314 loss: 0.00052709796
Iter: 315 loss: 0.000528635457
Iter: 316 loss: 0.000527092256
Iter: 317 loss: 0.000526951277
Iter: 318 loss: 0.0005271876
Iter: 319 loss: 0.000526887656
Iter: 320 loss: 0.000526760472
Iter: 321 loss: 0.000526815769
Iter: 322 loss: 0.000526673335
Iter: 323 loss: 0.000526504416
Iter: 324 loss: 0.000527314143
Iter: 325 loss: 0.000526474381
Iter: 326 loss: 0.000526344753
Iter: 327 loss: 0.000526699354
Iter: 328 loss: 0.000526302494
Iter: 329 loss: 0.000526155403
Iter: 330 loss: 0.000526499527
Iter: 331 loss: 0.000526101328
Iter: 332 loss: 0.000525972864
Iter: 333 loss: 0.000526087824
Iter: 334 loss: 0.000525898184
Iter: 335 loss: 0.000525751151
Iter: 336 loss: 0.000526475604
Iter: 337 loss: 0.000525725714
Iter: 338 loss: 0.000525602256
Iter: 339 loss: 0.000526263379
Iter: 340 loss: 0.000525584095
Iter: 341 loss: 0.00052547449
Iter: 342 loss: 0.0005255008
Iter: 343 loss: 0.000525394804
Iter: 344 loss: 0.000525270181
Iter: 345 loss: 0.000525551266
Iter: 346 loss: 0.00052522344
Iter: 347 loss: 0.000525094219
Iter: 348 loss: 0.000525593874
Iter: 349 loss: 0.000525063835
Iter: 350 loss: 0.000524963078
Iter: 351 loss: 0.000525713607
Iter: 352 loss: 0.000524955
Iter: 353 loss: 0.000524866569
Iter: 354 loss: 0.000525192474
Iter: 355 loss: 0.000524845556
Iter: 356 loss: 0.000524764648
Iter: 357 loss: 0.000524810865
Iter: 358 loss: 0.000524711912
Iter: 359 loss: 0.000524614588
Iter: 360 loss: 0.000524796196
Iter: 361 loss: 0.000524572679
Iter: 362 loss: 0.000524483039
Iter: 363 loss: 0.000524870877
Iter: 364 loss: 0.00052446482
Iter: 365 loss: 0.000524380594
Iter: 366 loss: 0.000524798059
Iter: 367 loss: 0.000524366274
Iter: 368 loss: 0.000524297822
Iter: 369 loss: 0.000524255272
Iter: 370 loss: 0.000524227624
Iter: 371 loss: 0.000524130824
Iter: 372 loss: 0.000524775
Iter: 373 loss: 0.000524120871
Iter: 374 loss: 0.000524046482
Iter: 375 loss: 0.000524308
Iter: 376 loss: 0.000524027389
Iter: 377 loss: 0.00052395626
Iter: 378 loss: 0.000524155097
Iter: 379 loss: 0.000523933733
Iter: 380 loss: 0.000523860683
Iter: 381 loss: 0.000523967436
Iter: 382 loss: 0.000523824943
Iter: 383 loss: 0.000523752533
Iter: 384 loss: 0.000523900089
Iter: 385 loss: 0.000523723196
Iter: 386 loss: 0.000523649447
Iter: 387 loss: 0.000523945782
Iter: 388 loss: 0.000523633207
Iter: 389 loss: 0.00052357692
Iter: 390 loss: 0.000524228
Iter: 391 loss: 0.000523576164
Iter: 392 loss: 0.000523529947
Iter: 393 loss: 0.000523522962
Iter: 394 loss: 0.000523490598
Iter: 395 loss: 0.000523431576
Iter: 396 loss: 0.00052355323
Iter: 397 loss: 0.000523407827
Iter: 398 loss: 0.000523348572
Iter: 399 loss: 0.000523533206
Iter: 400 loss: 0.000523331284
Iter: 401 loss: 0.000523278548
Iter: 402 loss: 0.000523576513
Iter: 403 loss: 0.000523271505
Iter: 404 loss: 0.000523226103
Iter: 405 loss: 0.000523286581
Iter: 406 loss: 0.000523202762
Iter: 407 loss: 0.000523148337
Iter: 408 loss: 0.000523258641
Iter: 409 loss: 0.000523126
Iter: 410 loss: 0.000523075869
Iter: 411 loss: 0.000523177965
Iter: 412 loss: 0.000523055904
Iter: 413 loss: 0.00052300503
Iter: 414 loss: 0.000523326104
Iter: 415 loss: 0.000522999384
Iter: 416 loss: 0.000522957125
Iter: 417 loss: 0.000523048802
Iter: 418 loss: 0.000522941118
Iter: 419 loss: 0.000522895716
Iter: 420 loss: 0.000522947055
Iter: 421 loss: 0.000522871385
Iter: 422 loss: 0.000522827322
Iter: 423 loss: 0.000522905029
Iter: 424 loss: 0.000522807124
Iter: 425 loss: 0.000522767543
Iter: 426 loss: 0.000523382914
Iter: 427 loss: 0.000522768
Iter: 428 loss: 0.000522736576
Iter: 429 loss: 0.00052276405
Iter: 430 loss: 0.000522718066
Iter: 431 loss: 0.000522684713
Iter: 432 loss: 0.000522742048
Iter: 433 loss: 0.00052267022
Iter: 434 loss: 0.00052263448
Iter: 435 loss: 0.000522686401
Iter: 436 loss: 0.000522616785
Iter: 437 loss: 0.000522578717
Iter: 438 loss: 0.00052274554
Iter: 439 loss: 0.000522570859
Iter: 440 loss: 0.000522536342
Iter: 441 loss: 0.000522700488
Iter: 442 loss: 0.000522530056
Iter: 443 loss: 0.00052250037
Iter: 444 loss: 0.000522524118
Iter: 445 loss: 0.000522481918
Iter: 446 loss: 0.000522445829
Iter: 447 loss: 0.000522500835
Iter: 448 loss: 0.00052242924
Iter: 449 loss: 0.000522395363
Iter: 450 loss: 0.000522629416
Iter: 451 loss: 0.000522392453
Iter: 452 loss: 0.000522363349
Iter: 453 loss: 0.00052243541
Iter: 454 loss: 0.000522352639
Iter: 455 loss: 0.000522323651
Iter: 456 loss: 0.000522388669
Iter: 457 loss: 0.000522312592
Iter: 458 loss: 0.000522285642
Iter: 459 loss: 0.000522331276
Iter: 460 loss: 0.000522273243
Iter: 461 loss: 0.000522245595
Iter: 462 loss: 0.000522446062
Iter: 463 loss: 0.00052224315
Iter: 464 loss: 0.000522221555
Iter: 465 loss: 0.000522332091
Iter: 466 loss: 0.000522217655
Iter: 467 loss: 0.000522198679
Iter: 468 loss: 0.000522192451
Iter: 469 loss: 0.000522181392
Iter: 470 loss: 0.000522156595
Iter: 471 loss: 0.00052218989
Iter: 472 loss: 0.000522144837
Iter: 473 loss: 0.000522119284
Iter: 474 loss: 0.000522297283
Iter: 475 loss: 0.000522117247
Iter: 476 loss: 0.000522094953
Iter: 477 loss: 0.000522153452
Iter: 478 loss: 0.00052208791
Iter: 479 loss: 0.000522068
Iter: 480 loss: 0.000522145303
Iter: 481 loss: 0.000522063347
Iter: 482 loss: 0.000522044196
Iter: 483 loss: 0.000522048
Iter: 484 loss: 0.000522029586
Iter: 485 loss: 0.000522007642
Iter: 486 loss: 0.000522116781
Iter: 487 loss: 0.000522003567
Iter: 488 loss: 0.000521985115
Iter: 489 loss: 0.000522054266
Iter: 490 loss: 0.000521980284
Iter: 491 loss: 0.000521963113
Iter: 492 loss: 0.000522034883
Iter: 493 loss: 0.000521959388
Iter: 494 loss: 0.000521945127
Iter: 495 loss: 0.000521954
Iter: 496 loss: 0.000521935464
Iter: 497 loss: 0.000521919399
Iter: 498 loss: 0.000521994429
Iter: 499 loss: 0.000521916547
Iter: 500 loss: 0.000521900482
Iter: 501 loss: 0.000522
Iter: 502 loss: 0.000521898735
Iter: 503 loss: 0.000521886453
Iter: 504 loss: 0.000521886104
Iter: 505 loss: 0.0005218765
Iter: 506 loss: 0.000521860609
Iter: 507 loss: 0.000521883368
Iter: 508 loss: 0.000521852809
Iter: 509 loss: 0.000521837
Iter: 510 loss: 0.00052191643
Iter: 511 loss: 0.000521834474
Iter: 512 loss: 0.000521818816
Iter: 513 loss: 0.000521864044
Iter: 514 loss: 0.000521814392
Iter: 515 loss: 0.000521800714
Iter: 516 loss: 0.000521864
Iter: 517 loss: 0.000521797861
Iter: 518 loss: 0.000521786162
Iter: 519 loss: 0.000521798618
Iter: 520 loss: 0.000521779642
Iter: 521 loss: 0.00052176608
Iter: 522 loss: 0.000521789829
Iter: 523 loss: 0.000521759794
Iter: 524 loss: 0.000521746348
Iter: 525 loss: 0.000521811715
Iter: 526 loss: 0.000521744485
Iter: 527 loss: 0.000521731854
Iter: 528 loss: 0.000521785056
Iter: 529 loss: 0.000521729526
Iter: 530 loss: 0.000521718932
Iter: 531 loss: 0.000521728187
Iter: 532 loss: 0.000521712762
Iter: 533 loss: 0.000521701179
Iter: 534 loss: 0.000521754788
Iter: 535 loss: 0.000521699316
Iter: 536 loss: 0.000521688606
Iter: 537 loss: 0.000521753449
Iter: 538 loss: 0.000521687674
Iter: 539 loss: 0.000521679234
Iter: 540 loss: 0.000521687325
Iter: 541 loss: 0.000521674869
Iter: 542 loss: 0.000521665788
Iter: 543 loss: 0.000521668699
Iter: 544 loss: 0.000521659618
Iter: 545 loss: 0.000521648326
Iter: 546 loss: 0.000521688082
Iter: 547 loss: 0.000521645648
Iter: 548 loss: 0.000521635578
Iter: 549 loss: 0.000521682145
Iter: 550 loss: 0.000521634
Iter: 551 loss: 0.000521624752
Iter: 552 loss: 0.000521663
Iter: 553 loss: 0.000521623
Iter: 554 loss: 0.000521615148
Iter: 555 loss: 0.000521624112
Iter: 556 loss: 0.000521611073
Iter: 557 loss: 0.000521602342
Iter: 558 loss: 0.000521619
Iter: 559 loss: 0.000521598384
Iter: 560 loss: 0.00052159
Iter: 561 loss: 0.000521636859
Iter: 562 loss: 0.000521588721
Iter: 563 loss: 0.000521581504
Iter: 564 loss: 0.000521596754
Iter: 565 loss: 0.000521578535
Iter: 566 loss: 0.00052157091
Iter: 567 loss: 0.000521606533
Iter: 568 loss: 0.000521569862
Iter: 569 loss: 0.000521563285
Iter: 570 loss: 0.000521568756
Iter: 571 loss: 0.000521559792
Iter: 572 loss: 0.000521552865
Iter: 573 loss: 0.000521622133
Iter: 574 loss: 0.000521552691
Iter: 575 loss: 0.000521546812
Iter: 576 loss: 0.000521546695
Iter: 577 loss: 0.000521542388
Iter: 578 loss: 0.000521535869
Iter: 579 loss: 0.000521544134
Iter: 580 loss: 0.000521532493
Iter: 581 loss: 0.000521525566
Iter: 582 loss: 0.000521546928
Iter: 583 loss: 0.000521523529
Iter: 584 loss: 0.000521517
Iter: 585 loss: 0.000521554
Iter: 586 loss: 0.000521516
Iter: 587 loss: 0.000521510374
Iter: 588 loss: 0.000521533
Iter: 589 loss: 0.000521509442
Iter: 590 loss: 0.000521504204
Iter: 591 loss: 0.000521508511
Iter: 592 loss: 0.000521501235
Iter: 593 loss: 0.000521495705
Iter: 594 loss: 0.000521515089
Iter: 595 loss: 0.00052149425
Iter: 596 loss: 0.000521488604
Iter: 597 loss: 0.000521497859
Iter: 598 loss: 0.000521486392
Iter: 599 loss: 0.000521480397
Iter: 600 loss: 0.000521512877
Iter: 601 loss: 0.000521479698
Iter: 602 loss: 0.000521475275
Iter: 603 loss: 0.000521488
Iter: 604 loss: 0.000521473761
Iter: 605 loss: 0.000521469279
Iter: 606 loss: 0.000521478301
Iter: 607 loss: 0.000521467358
Iter: 608 loss: 0.000521463167
Iter: 609 loss: 0.000521502923
Iter: 610 loss: 0.000521463226
Iter: 611 loss: 0.00052145985
Iter: 612 loss: 0.000521459151
Iter: 613 loss: 0.000521457521
Iter: 614 loss: 0.000521453563
Iter: 615 loss: 0.000521457521
Iter: 616 loss: 0.000521451235
Iter: 617 loss: 0.000521446578
Iter: 618 loss: 0.000521463342
Iter: 619 loss: 0.000521445472
Iter: 620 loss: 0.000521441398
Iter: 621 loss: 0.000521453621
Iter: 622 loss: 0.000521440175
Iter: 623 loss: 0.000521436217
Iter: 624 loss: 0.000521457754
Iter: 625 loss: 0.000521436
Iter: 626 loss: 0.000521432376
Iter: 627 loss: 0.000521440059
Iter: 628 loss: 0.000521431444
Iter: 629 loss: 0.000521428
Iter: 630 loss: 0.000521429116
Iter: 631 loss: 0.000521425274
Iter: 632 loss: 0.000521421898
Iter: 633 loss: 0.000521438371
Iter: 634 loss: 0.000521421083
Iter: 635 loss: 0.000521417591
Iter: 636 loss: 0.000521433
Iter: 637 loss: 0.000521416951
Iter: 638 loss: 0.000521414098
Iter: 639 loss: 0.000521423295
Iter: 640 loss: 0.000521412876
Iter: 641 loss: 0.000521410198
Iter: 642 loss: 0.000521419803
Iter: 643 loss: 0.000521409791
Iter: 644 loss: 0.000521407
Iter: 645 loss: 0.000521416601
Iter: 646 loss: 0.00052140624
Iter: 647 loss: 0.000521403796
Iter: 648 loss: 0.000521406531
Iter: 649 loss: 0.000521402224
Iter: 650 loss: 0.000521399779
Iter: 651 loss: 0.000521404785
Iter: 652 loss: 0.000521398673
Iter: 653 loss: 0.000521395588
Iter: 654 loss: 0.000521400245
Iter: 655 loss: 0.000521394424
Iter: 656 loss: 0.000521391863
Iter: 657 loss: 0.000521400711
Iter: 658 loss: 0.000521390932
Iter: 659 loss: 0.000521388487
Iter: 660 loss: 0.000521405833
Iter: 661 loss: 0.000521388138
Iter: 662 loss: 0.00052138645
Iter: 663 loss: 0.000521391223
Iter: 664 loss: 0.000521385635
Iter: 665 loss: 0.000521383365
Iter: 666 loss: 0.000521383947
Iter: 667 loss: 0.000521381968
Iter: 668 loss: 0.000521379523
Iter: 669 loss: 0.000521394075
Iter: 670 loss: 0.000521379174
Iter: 671 loss: 0.000521377195
Iter: 672 loss: 0.000521381909
Iter: 673 loss: 0.000521376496
Iter: 674 loss: 0.000521374226
Iter: 675 loss: 0.000521385693
Iter: 676 loss: 0.000521374517
Iter: 677 loss: 0.000521372771
Iter: 678 loss: 0.000521375332
Iter: 679 loss: 0.000521371781
Iter: 680 loss: 0.000521370152
Iter: 681 loss: 0.000521380745
Iter: 682 loss: 0.00052137
Iter: 683 loss: 0.00052136858
Iter: 684 loss: 0.000521368871
Iter: 685 loss: 0.000521367707
Iter: 686 loss: 0.000521365844
Iter: 687 loss: 0.00052136858
Iter: 688 loss: 0.00052136468
Iter: 689 loss: 0.00052136305
Iter: 690 loss: 0.00052136695
Iter: 691 loss: 0.000521362235
Iter: 692 loss: 0.000521360373
Iter: 693 loss: 0.000521366426
Iter: 694 loss: 0.000521359849
Iter: 695 loss: 0.000521358335
Iter: 696 loss: 0.000521368929
Iter: 697 loss: 0.000521358277
Iter: 698 loss: 0.000521356938
Iter: 699 loss: 0.000521361
Iter: 700 loss: 0.000521356531
Iter: 701 loss: 0.000521354959
Iter: 702 loss: 0.000521355774
Iter: 703 loss: 0.000521354144
Iter: 704 loss: 0.000521352398
Iter: 705 loss: 0.000521357055
Iter: 706 loss: 0.000521352
Iter: 707 loss: 0.00052135071
Iter: 708 loss: 0.000521356938
Iter: 709 loss: 0.000521350536
Iter: 710 loss: 0.000521349371
Iter: 711 loss: 0.000521356
Iter: 712 loss: 0.000521348964
Iter: 713 loss: 0.000521348
Iter: 714 loss: 0.000521349488
Iter: 715 loss: 0.000521347392
Iter: 716 loss: 0.000521346403
Iter: 717 loss: 0.000521353562
Iter: 718 loss: 0.000521346228
Iter: 719 loss: 0.00052134518
Iter: 720 loss: 0.000521344948
Iter: 721 loss: 0.000521344831
Iter: 722 loss: 0.000521343551
Iter: 723 loss: 0.000521346577
Iter: 724 loss: 0.000521342969
Iter: 725 loss: 0.000521342154
Iter: 726 loss: 0.000521344889
Iter: 727 loss: 0.000521341281
Iter: 728 loss: 0.000521340233
Iter: 729 loss: 0.000521344424
Iter: 730 loss: 0.000521340175
Iter: 731 loss: 0.000521338894
Iter: 732 loss: 0.000521341921
Iter: 733 loss: 0.000521338778
Iter: 734 loss: 0.000521337497
Iter: 735 loss: 0.000521344249
Iter: 736 loss: 0.00052133773
Iter: 737 loss: 0.000521336915
Iter: 738 loss: 0.000521336275
Iter: 739 loss: 0.000521335867
Iter: 740 loss: 0.000521335
Iter: 741 loss: 0.000521339
Iter: 742 loss: 0.000521334587
Iter: 743 loss: 0.000521333772
Iter: 744 loss: 0.000521337148
Iter: 745 loss: 0.000521333423
Iter: 746 loss: 0.000521332724
Iter: 747 loss: 0.000521338545
Iter: 748 loss: 0.000521332375
Iter: 749 loss: 0.000521331734
Iter: 750 loss: 0.000521332433
Iter: 751 loss: 0.000521331793
Iter: 752 loss: 0.000521330803
Iter: 753 loss: 0.000521336391
Iter: 754 loss: 0.000521331
Iter: 755 loss: 0.000521330221
Iter: 756 loss: 0.000521329814
Iter: 757 loss: 0.000521329581
Iter: 758 loss: 0.000521328766
Iter: 759 loss: 0.000521331385
Iter: 760 loss: 0.0005213283
Iter: 761 loss: 0.000521327718
Iter: 762 loss: 0.000521329639
Iter: 763 loss: 0.000521327369
Iter: 764 loss: 0.000521326903
Iter: 765 loss: 0.000521328475
Iter: 766 loss: 0.000521326787
Iter: 767 loss: 0.000521325739
Iter: 768 loss: 0.000521329697
Iter: 769 loss: 0.000521325564
Iter: 770 loss: 0.000521324633
Iter: 771 loss: 0.000521327369
Iter: 772 loss: 0.000521325099
Iter: 773 loss: 0.000521324226
Iter: 774 loss: 0.000521325448
Iter: 775 loss: 0.00052132376
Iter: 776 loss: 0.000521323469
Iter: 777 loss: 0.000521323411
Iter: 778 loss: 0.000521322479
Iter: 779 loss: 0.000521321781
Iter: 780 loss: 0.000521326787
Iter: 781 loss: 0.00052132213
Iter: 782 loss: 0.000521321781
Iter: 783 loss: 0.000521323702
Iter: 784 loss: 0.000521321781
Iter: 785 loss: 0.000521321141
Iter: 786 loss: 0.00052132213
Iter: 787 loss: 0.000521320966
Iter: 788 loss: 0.000521320442
Iter: 789 loss: 0.000521321432
Iter: 790 loss: 0.000521320617
Iter: 791 loss: 0.000521319686
Iter: 792 loss: 0.000521320326
Iter: 793 loss: 0.000521319394
Iter: 794 loss: 0.000521319
Iter: 795 loss: 0.000521320035
Iter: 796 loss: 0.000521318521
Iter: 797 loss: 0.000521318289
Iter: 798 loss: 0.000521319103
Iter: 799 loss: 0.000521317706
Iter: 800 loss: 0.00052131759
Iter: 801 loss: 0.000521319045
Iter: 802 loss: 0.000521317183
Iter: 803 loss: 0.000521316892
Iter: 804 loss: 0.00052131986
Iter: 805 loss: 0.000521317183
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.2/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.6
+ date
Tue Oct 27 21:06:05 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.6
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.6/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.2/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 0 --alpha 1.6 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.6/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f94187510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f941b1ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f940fa620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f940fa6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f9411f598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f940da950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f940dac80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f9408c400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f9408c730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f94049e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f94049598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f94049d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f807ec6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f8074c840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80773488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f807738c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f807142f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80714d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f806f1c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80691510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80691378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80691b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f8066e730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f8066ef28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80620488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f805d49d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80620a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f941b17b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f8053d7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f8053d620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f8053dc80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f8053d9d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f805392f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f804fc6a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f80539378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f4f804fc840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0195260607
Iter: 2 loss: 0.0158660151
Iter: 3 loss: 0.0291338228
Iter: 4 loss: 0.0144849308
Iter: 5 loss: 0.0100522
Iter: 6 loss: 0.00991722755
Iter: 7 loss: 0.00757902488
Iter: 8 loss: 0.0139774941
Iter: 9 loss: 0.00691869808
Iter: 10 loss: 0.00530970935
Iter: 11 loss: 0.021717079
Iter: 12 loss: 0.00529199
Iter: 13 loss: 0.00456791185
Iter: 14 loss: 0.00469876872
Iter: 15 loss: 0.00404078793
Iter: 16 loss: 0.00335288933
Iter: 17 loss: 0.00712637603
Iter: 18 loss: 0.00323240366
Iter: 19 loss: 0.00275394041
Iter: 20 loss: 0.00423710607
Iter: 21 loss: 0.00260345801
Iter: 22 loss: 0.00226339558
Iter: 23 loss: 0.00543474033
Iter: 24 loss: 0.00224446366
Iter: 25 loss: 0.00202331808
Iter: 26 loss: 0.00256330962
Iter: 27 loss: 0.00194689783
Iter: 28 loss: 0.00177210965
Iter: 29 loss: 0.00282655237
Iter: 30 loss: 0.0017453949
Iter: 31 loss: 0.00162222655
Iter: 32 loss: 0.00228789542
Iter: 33 loss: 0.00160607509
Iter: 34 loss: 0.00151648617
Iter: 35 loss: 0.00155019364
Iter: 36 loss: 0.00145367137
Iter: 37 loss: 0.00137501862
Iter: 38 loss: 0.00166152453
Iter: 39 loss: 0.00135520799
Iter: 40 loss: 0.00128581258
Iter: 41 loss: 0.00167886575
Iter: 42 loss: 0.00127535174
Iter: 43 loss: 0.00122697977
Iter: 44 loss: 0.00127258745
Iter: 45 loss: 0.00119939097
Iter: 46 loss: 0.0011577541
Iter: 47 loss: 0.00174525846
Iter: 48 loss: 0.00115740695
Iter: 49 loss: 0.00112365885
Iter: 50 loss: 0.00131188077
Iter: 51 loss: 0.00111932191
Iter: 52 loss: 0.0010969697
Iter: 53 loss: 0.00107283797
Iter: 54 loss: 0.00106895226
Iter: 55 loss: 0.00103884
Iter: 56 loss: 0.00109626295
Iter: 57 loss: 0.00102642516
Iter: 58 loss: 0.000996692
Iter: 59 loss: 0.00118229969
Iter: 60 loss: 0.000992914429
Iter: 61 loss: 0.000970977242
Iter: 62 loss: 0.00102937245
Iter: 63 loss: 0.000963684404
Iter: 64 loss: 0.000941738312
Iter: 65 loss: 0.00100432325
Iter: 66 loss: 0.00093476841
Iter: 67 loss: 0.00091590971
Iter: 68 loss: 0.000946563
Iter: 69 loss: 0.000907205278
Iter: 70 loss: 0.000888503739
Iter: 71 loss: 0.000937015284
Iter: 72 loss: 0.00088216638
Iter: 73 loss: 0.000866409275
Iter: 74 loss: 0.000971568341
Iter: 75 loss: 0.000864681613
Iter: 76 loss: 0.000853308826
Iter: 77 loss: 0.000916666875
Iter: 78 loss: 0.000851820223
Iter: 79 loss: 0.000841852278
Iter: 80 loss: 0.000866187329
Iter: 81 loss: 0.000838280888
Iter: 82 loss: 0.000830696139
Iter: 83 loss: 0.000918841455
Iter: 84 loss: 0.000830603531
Iter: 85 loss: 0.000823979266
Iter: 86 loss: 0.000831846206
Iter: 87 loss: 0.000820428832
Iter: 88 loss: 0.000813667895
Iter: 89 loss: 0.000820184592
Iter: 90 loss: 0.000809809426
Iter: 91 loss: 0.000802101567
Iter: 92 loss: 0.000807922333
Iter: 93 loss: 0.00079741783
Iter: 94 loss: 0.000789171667
Iter: 95 loss: 0.000826238305
Iter: 96 loss: 0.000787512341
Iter: 97 loss: 0.00078036834
Iter: 98 loss: 0.000801152433
Iter: 99 loss: 0.00077817234
Iter: 100 loss: 0.00077160896
Iter: 101 loss: 0.000800229434
Iter: 102 loss: 0.000770243
Iter: 103 loss: 0.000764194294
Iter: 104 loss: 0.000773393782
Iter: 105 loss: 0.000761319767
Iter: 106 loss: 0.000755135901
Iter: 107 loss: 0.000773058156
Iter: 108 loss: 0.000753206725
Iter: 109 loss: 0.000747538928
Iter: 110 loss: 0.00076290837
Iter: 111 loss: 0.00074567413
Iter: 112 loss: 0.000740069256
Iter: 113 loss: 0.000757511356
Iter: 114 loss: 0.000738424482
Iter: 115 loss: 0.000734367117
Iter: 116 loss: 0.000780588889
Iter: 117 loss: 0.000734309957
Iter: 118 loss: 0.00073048682
Iter: 119 loss: 0.000744971039
Iter: 120 loss: 0.000729549909
Iter: 121 loss: 0.00072665792
Iter: 122 loss: 0.000729530817
Iter: 123 loss: 0.000725029735
Iter: 124 loss: 0.000721651246
Iter: 125 loss: 0.000721261487
Iter: 126 loss: 0.000718829571
Iter: 127 loss: 0.000714643626
Iter: 128 loss: 0.000722883851
Iter: 129 loss: 0.000712913927
Iter: 130 loss: 0.000708687294
Iter: 131 loss: 0.000738472212
Iter: 132 loss: 0.000708316104
Iter: 133 loss: 0.000704930164
Iter: 134 loss: 0.000710199
Iter: 135 loss: 0.000703338301
Iter: 136 loss: 0.000700064702
Iter: 137 loss: 0.000709168
Iter: 138 loss: 0.000699009164
Iter: 139 loss: 0.000695759722
Iter: 140 loss: 0.000708678155
Iter: 141 loss: 0.000695018
Iter: 142 loss: 0.000692156784
Iter: 143 loss: 0.000699315104
Iter: 144 loss: 0.000691163237
Iter: 145 loss: 0.000688227708
Iter: 146 loss: 0.000695042661
Iter: 147 loss: 0.000687130494
Iter: 148 loss: 0.000684360391
Iter: 149 loss: 0.000690830755
Iter: 150 loss: 0.000683350663
Iter: 151 loss: 0.000681797683
Iter: 152 loss: 0.000681686681
Iter: 153 loss: 0.000680166413
Iter: 154 loss: 0.000680644123
Iter: 155 loss: 0.000679083052
Iter: 156 loss: 0.000677295262
Iter: 157 loss: 0.00067774381
Iter: 158 loss: 0.000675992284
Iter: 159 loss: 0.000673890696
Iter: 160 loss: 0.000679239398
Iter: 161 loss: 0.000673164497
Iter: 162 loss: 0.000671119138
Iter: 163 loss: 0.00067800167
Iter: 164 loss: 0.000670561334
Iter: 165 loss: 0.000668668537
Iter: 166 loss: 0.000670667156
Iter: 167 loss: 0.000667624758
Iter: 168 loss: 0.000665601692
Iter: 169 loss: 0.000674764451
Iter: 170 loss: 0.000665210537
Iter: 171 loss: 0.000663400628
Iter: 172 loss: 0.000665128231
Iter: 173 loss: 0.00066236587
Iter: 174 loss: 0.000660607242
Iter: 175 loss: 0.000681252568
Iter: 176 loss: 0.000660584425
Iter: 177 loss: 0.000659302517
Iter: 178 loss: 0.00065986
Iter: 179 loss: 0.000658425153
Iter: 180 loss: 0.000656889635
Iter: 181 loss: 0.000660193735
Iter: 182 loss: 0.000656293123
Iter: 183 loss: 0.000654949807
Iter: 184 loss: 0.000663014245
Iter: 185 loss: 0.000654776115
Iter: 186 loss: 0.000653784315
Iter: 187 loss: 0.000653783209
Iter: 188 loss: 0.000653112773
Iter: 189 loss: 0.000652272254
Iter: 190 loss: 0.000652204209
Iter: 191 loss: 0.000651113805
Iter: 192 loss: 0.000653543219
Iter: 193 loss: 0.000650698144
Iter: 194 loss: 0.000649605645
Iter: 195 loss: 0.000651987502
Iter: 196 loss: 0.000649182708
Iter: 197 loss: 0.000648087
Iter: 198 loss: 0.000651396578
Iter: 199 loss: 0.000647759298
Iter: 200 loss: 0.000646712724
Iter: 201 loss: 0.000649437075
Iter: 202 loss: 0.000646355969
Iter: 203 loss: 0.000645335182
Iter: 204 loss: 0.000648031244
Iter: 205 loss: 0.000644991698
Iter: 206 loss: 0.000643945765
Iter: 207 loss: 0.0006471136
Iter: 208 loss: 0.000643634703
Iter: 209 loss: 0.000642678584
Iter: 210 loss: 0.000645049033
Iter: 211 loss: 0.000642339757
Iter: 212 loss: 0.000641429913
Iter: 213 loss: 0.000644048152
Iter: 214 loss: 0.000641146326
Iter: 215 loss: 0.00064027292
Iter: 216 loss: 0.000643048
Iter: 217 loss: 0.00064002187
Iter: 218 loss: 0.000639301259
Iter: 219 loss: 0.000645635591
Iter: 220 loss: 0.000639265869
Iter: 221 loss: 0.000638653466
Iter: 222 loss: 0.000642438768
Iter: 223 loss: 0.0006385796
Iter: 224 loss: 0.000638089725
Iter: 225 loss: 0.000638001424
Iter: 226 loss: 0.000637670164
Iter: 227 loss: 0.000637068704
Iter: 228 loss: 0.000636765
Iter: 229 loss: 0.000636482611
Iter: 230 loss: 0.000635601464
Iter: 231 loss: 0.000638045254
Iter: 232 loss: 0.000635318051
Iter: 233 loss: 0.000634582
Iter: 234 loss: 0.000639827107
Iter: 235 loss: 0.000634516589
Iter: 236 loss: 0.000633914955
Iter: 237 loss: 0.000635849196
Iter: 238 loss: 0.000633743592
Iter: 239 loss: 0.000633149059
Iter: 240 loss: 0.000634093
Iter: 241 loss: 0.000632873387
Iter: 242 loss: 0.000632231706
Iter: 243 loss: 0.000634639873
Iter: 244 loss: 0.000632076175
Iter: 245 loss: 0.000631528965
Iter: 246 loss: 0.00063194
Iter: 247 loss: 0.000631194329
Iter: 248 loss: 0.000630522263
Iter: 249 loss: 0.00063391705
Iter: 250 loss: 0.000630411319
Iter: 251 loss: 0.000629874237
Iter: 252 loss: 0.000631460396
Iter: 253 loss: 0.000629710848
Iter: 254 loss: 0.000629349262
Iter: 255 loss: 0.000629342918
Iter: 256 loss: 0.000629040296
Iter: 257 loss: 0.000629120274
Iter: 258 loss: 0.000628820446
Iter: 259 loss: 0.0006284439
Iter: 260 loss: 0.000628435228
Iter: 261 loss: 0.000628140522
Iter: 262 loss: 0.000627681438
Iter: 263 loss: 0.00062857155
Iter: 264 loss: 0.000627490284
Iter: 265 loss: 0.000627052
Iter: 266 loss: 0.000628741458
Iter: 267 loss: 0.000626949
Iter: 268 loss: 0.000626515248
Iter: 269 loss: 0.000627734466
Iter: 270 loss: 0.000626376597
Iter: 271 loss: 0.000625952438
Iter: 272 loss: 0.000626800233
Iter: 273 loss: 0.000625779154
Iter: 274 loss: 0.000625361048
Iter: 275 loss: 0.000626478693
Iter: 276 loss: 0.000625222514
Iter: 277 loss: 0.000624811859
Iter: 278 loss: 0.000625198707
Iter: 279 loss: 0.000624577166
Iter: 280 loss: 0.000624160282
Iter: 281 loss: 0.000628273468
Iter: 282 loss: 0.000624145963
Iter: 283 loss: 0.000623820524
Iter: 284 loss: 0.000624398
Iter: 285 loss: 0.000623678206
Iter: 286 loss: 0.000623354863
Iter: 287 loss: 0.000624805223
Iter: 288 loss: 0.000623292057
Iter: 289 loss: 0.00062301557
Iter: 290 loss: 0.000625999121
Iter: 291 loss: 0.000623009517
Iter: 292 loss: 0.000622789375
Iter: 293 loss: 0.000622910331
Iter: 294 loss: 0.00062264438
Iter: 295 loss: 0.000622432097
Iter: 296 loss: 0.000622127205
Iter: 297 loss: 0.00062211731
Iter: 298 loss: 0.000621760963
Iter: 299 loss: 0.000624196371
Iter: 300 loss: 0.000621726329
Iter: 301 loss: 0.000621433603
Iter: 302 loss: 0.000622251595
Iter: 303 loss: 0.000621340179
Iter: 304 loss: 0.00062105892
Iter: 305 loss: 0.000621962477
Iter: 306 loss: 0.00062097935
Iter: 307 loss: 0.000620710372
Iter: 308 loss: 0.000621439423
Iter: 309 loss: 0.000620622071
Iter: 310 loss: 0.00062036654
Iter: 311 loss: 0.000620656181
Iter: 312 loss: 0.000620228879
Iter: 313 loss: 0.000619960541
Iter: 314 loss: 0.000620892737
Iter: 315 loss: 0.000619889819
Iter: 316 loss: 0.000619640225
Iter: 317 loss: 0.000621324871
Iter: 318 loss: 0.000619615079
Iter: 319 loss: 0.0006194124
Iter: 320 loss: 0.0006197326
Iter: 321 loss: 0.000619317289
Iter: 322 loss: 0.000619132246
Iter: 323 loss: 0.000620931096
Iter: 324 loss: 0.000619125436
Iter: 325 loss: 0.000618962338
Iter: 326 loss: 0.000619742554
Iter: 327 loss: 0.000618932885
Iter: 328 loss: 0.000618811
Iter: 329 loss: 0.000618659426
Iter: 330 loss: 0.000618646503
Iter: 331 loss: 0.000618451042
Iter: 332 loss: 0.000618950173
Iter: 333 loss: 0.000618383754
Iter: 334 loss: 0.000618194928
Iter: 335 loss: 0.00061856932
Iter: 336 loss: 0.000618117105
Iter: 337 loss: 0.000617920829
Iter: 338 loss: 0.000618818682
Iter: 339 loss: 0.000617883285
Iter: 340 loss: 0.000617707265
Iter: 341 loss: 0.000618275721
Iter: 342 loss: 0.000617657555
Iter: 343 loss: 0.000617492711
Iter: 344 loss: 0.000617825717
Iter: 345 loss: 0.000617425365
Iter: 346 loss: 0.000617263373
Iter: 347 loss: 0.000617472688
Iter: 348 loss: 0.000617180602
Iter: 349 loss: 0.000617024954
Iter: 350 loss: 0.000618518796
Iter: 351 loss: 0.000617019134
Iter: 352 loss: 0.000616895733
Iter: 353 loss: 0.000616935373
Iter: 354 loss: 0.00061680784
Iter: 355 loss: 0.000616646255
Iter: 356 loss: 0.000617304584
Iter: 357 loss: 0.000616610865
Iter: 358 loss: 0.000616522
Iter: 359 loss: 0.000616519537
Iter: 360 loss: 0.000616434845
Iter: 361 loss: 0.000616380479
Iter: 362 loss: 0.000616347301
Iter: 363 loss: 0.000616242818
Iter: 364 loss: 0.000616230362
Iter: 365 loss: 0.00061615539
Iter: 366 loss: 0.00061601412
Iter: 367 loss: 0.000616684323
Iter: 368 loss: 0.000615988509
Iter: 369 loss: 0.000615869125
Iter: 370 loss: 0.000616239849
Iter: 371 loss: 0.00061583356
Iter: 372 loss: 0.000615718076
Iter: 373 loss: 0.000615903642
Iter: 374 loss: 0.000615664059
Iter: 375 loss: 0.00061553769
Iter: 376 loss: 0.000615922036
Iter: 377 loss: 0.000615499564
Iter: 378 loss: 0.000615380937
Iter: 379 loss: 0.000615535537
Iter: 380 loss: 0.000615320052
Iter: 381 loss: 0.000615196652
Iter: 382 loss: 0.000615696539
Iter: 383 loss: 0.000615169294
Iter: 384 loss: 0.000615062949
Iter: 385 loss: 0.000615440658
Iter: 386 loss: 0.000615035184
Iter: 387 loss: 0.000614929944
Iter: 388 loss: 0.000615363824
Iter: 389 loss: 0.000614907593
Iter: 390 loss: 0.000614819932
Iter: 391 loss: 0.000615082448
Iter: 392 loss: 0.000614793622
Iter: 393 loss: 0.00061471638
Iter: 394 loss: 0.000615920348
Iter: 395 loss: 0.000614716206
Iter: 396 loss: 0.000614668
Iter: 397 loss: 0.000614572724
Iter: 398 loss: 0.00061646977
Iter: 399 loss: 0.000614571676
Iter: 400 loss: 0.000614479824
Iter: 401 loss: 0.000614913413
Iter: 402 loss: 0.000614462886
Iter: 403 loss: 0.000614378077
Iter: 404 loss: 0.000614508812
Iter: 405 loss: 0.000614338322
Iter: 406 loss: 0.000614248565
Iter: 407 loss: 0.000614699267
Iter: 408 loss: 0.000614233548
Iter: 409 loss: 0.000614158809
Iter: 410 loss: 0.000614228193
Iter: 411 loss: 0.000614115386
Iter: 412 loss: 0.000614032208
Iter: 413 loss: 0.000614318298
Iter: 414 loss: 0.000614010263
Iter: 415 loss: 0.000613931217
Iter: 416 loss: 0.000614182092
Iter: 417 loss: 0.00061390904
Iter: 418 loss: 0.000613836397
Iter: 419 loss: 0.000614015502
Iter: 420 loss: 0.000613810553
Iter: 421 loss: 0.00061374309
Iter: 422 loss: 0.000614153338
Iter: 423 loss: 0.000613734708
Iter: 424 loss: 0.000613673823
Iter: 425 loss: 0.000613695651
Iter: 426 loss: 0.000613632146
Iter: 427 loss: 0.00061358104
Iter: 428 loss: 0.00061432668
Iter: 429 loss: 0.000613581331
Iter: 430 loss: 0.00061352679
Iter: 431 loss: 0.000613641459
Iter: 432 loss: 0.000613505719
Iter: 433 loss: 0.00061346608
Iter: 434 loss: 0.000613446406
Iter: 435 loss: 0.000613427837
Iter: 436 loss: 0.000613367185
Iter: 437 loss: 0.000613464
Iter: 438 loss: 0.000613339245
Iter: 439 loss: 0.000613278244
Iter: 440 loss: 0.000613636686
Iter: 441 loss: 0.000613270327
Iter: 442 loss: 0.000613221142
Iter: 443 loss: 0.000613229524
Iter: 444 loss: 0.000613183889
Iter: 445 loss: 0.000613123761
Iter: 446 loss: 0.00061341963
Iter: 447 loss: 0.000613113167
Iter: 448 loss: 0.000613060489
Iter: 449 loss: 0.000613242853
Iter: 450 loss: 0.000613046577
Iter: 451 loss: 0.000612997101
Iter: 452 loss: 0.000613122
Iter: 453 loss: 0.000612979406
Iter: 454 loss: 0.000612928881
Iter: 455 loss: 0.000613103854
Iter: 456 loss: 0.000612915901
Iter: 457 loss: 0.000612868695
Iter: 458 loss: 0.000612944481
Iter: 459 loss: 0.000612847391
Iter: 460 loss: 0.000612802221
Iter: 461 loss: 0.000612958334
Iter: 462 loss: 0.00061279058
Iter: 463 loss: 0.000612764503
Iter: 464 loss: 0.00061276264
Iter: 465 loss: 0.000612738368
Iter: 466 loss: 0.000612713862
Iter: 467 loss: 0.000612709904
Iter: 468 loss: 0.00061267626
Iter: 469 loss: 0.000612684176
Iter: 470 loss: 0.000612652046
Iter: 471 loss: 0.000612613
Iter: 472 loss: 0.000612765201
Iter: 473 loss: 0.000612603384
Iter: 474 loss: 0.000612564618
Iter: 475 loss: 0.000612718519
Iter: 476 loss: 0.000612555887
Iter: 477 loss: 0.000612521544
Iter: 478 loss: 0.000612541859
Iter: 479 loss: 0.0006124996
Iter: 480 loss: 0.000612463919
Iter: 481 loss: 0.000612652279
Iter: 482 loss: 0.000612458214
Iter: 483 loss: 0.00061242457
Iter: 484 loss: 0.000612513395
Iter: 485 loss: 0.000612412172
Iter: 486 loss: 0.00061237847
Iter: 487 loss: 0.000612450473
Iter: 488 loss: 0.000612365897
Iter: 489 loss: 0.000612333417
Iter: 490 loss: 0.000612453674
Iter: 491 loss: 0.000612325966
Iter: 492 loss: 0.000612295349
Iter: 493 loss: 0.000612353906
Iter: 494 loss: 0.000612282194
Iter: 495 loss: 0.000612255477
Iter: 496 loss: 0.000612462754
Iter: 497 loss: 0.000612254
Iter: 498 loss: 0.000612229866
Iter: 499 loss: 0.000612396747
Iter: 500 loss: 0.000612227246
Iter: 501 loss: 0.000612209318
Iter: 502 loss: 0.000612202
Iter: 503 loss: 0.000612192671
Iter: 504 loss: 0.000612168806
Iter: 505 loss: 0.000612193369
Iter: 506 loss: 0.000612155418
Iter: 507 loss: 0.000612127827
Iter: 508 loss: 0.000612207688
Iter: 509 loss: 0.000612118864
Iter: 510 loss: 0.000612092321
Iter: 511 loss: 0.000612113392
Iter: 512 loss: 0.000612076605
Iter: 513 loss: 0.000612048665
Iter: 514 loss: 0.000612168922
Iter: 515 loss: 0.000612042262
Iter: 516 loss: 0.000612015778
Iter: 517 loss: 0.000612081552
Iter: 518 loss: 0.000612006756
Iter: 519 loss: 0.000611981202
Iter: 520 loss: 0.000612115429
Iter: 521 loss: 0.00061197707
Iter: 522 loss: 0.000611953787
Iter: 523 loss: 0.000611989817
Iter: 524 loss: 0.000611942611
Iter: 525 loss: 0.000611918513
Iter: 526 loss: 0.000612000644
Iter: 527 loss: 0.000611911702
Iter: 528 loss: 0.000611892319
Iter: 529 loss: 0.000611968
Iter: 530 loss: 0.000611887313
Iter: 531 loss: 0.000611869968
Iter: 532 loss: 0.00061203714
Iter: 533 loss: 0.000611869735
Iter: 534 loss: 0.000611852622
Iter: 535 loss: 0.000611887721
Iter: 536 loss: 0.000611846335
Iter: 537 loss: 0.000611832365
Iter: 538 loss: 0.000611826428
Iter: 539 loss: 0.000611819443
Iter: 540 loss: 0.000611799827
Iter: 541 loss: 0.000611853553
Iter: 542 loss: 0.000611793133
Iter: 543 loss: 0.000611774216
Iter: 544 loss: 0.000611806288
Iter: 545 loss: 0.000611765601
Iter: 546 loss: 0.000611745811
Iter: 547 loss: 0.000611788768
Iter: 548 loss: 0.000611738302
Iter: 549 loss: 0.000611718569
Iter: 550 loss: 0.000611795112
Iter: 551 loss: 0.000611713738
Iter: 552 loss: 0.000611696159
Iter: 553 loss: 0.000611778
Iter: 554 loss: 0.000611693
Iter: 555 loss: 0.000611676078
Iter: 556 loss: 0.0006117007
Iter: 557 loss: 0.000611667871
Iter: 558 loss: 0.000611650641
Iter: 559 loss: 0.000611681375
Iter: 560 loss: 0.000611643656
Iter: 561 loss: 0.000611625554
Iter: 562 loss: 0.000611689291
Iter: 563 loss: 0.000611620781
Iter: 564 loss: 0.000611604773
Iter: 565 loss: 0.000611667
Iter: 566 loss: 0.000611600874
Iter: 567 loss: 0.000611590804
Iter: 568 loss: 0.000611590338
Iter: 569 loss: 0.000611583295
Iter: 570 loss: 0.000611575437
Iter: 571 loss: 0.000611574214
Iter: 572 loss: 0.000611561525
Iter: 573 loss: 0.000611571362
Iter: 574 loss: 0.000611554598
Iter: 575 loss: 0.000611541618
Iter: 576 loss: 0.00061157014
Iter: 577 loss: 0.000611536
Iter: 578 loss: 0.000611522
Iter: 579 loss: 0.000611581083
Iter: 580 loss: 0.000611519
Iter: 581 loss: 0.000611507217
Iter: 582 loss: 0.000611532945
Iter: 583 loss: 0.00061150227
Iter: 584 loss: 0.000611491385
Iter: 585 loss: 0.000611538941
Iter: 586 loss: 0.000611488242
Iter: 587 loss: 0.000611477531
Iter: 588 loss: 0.000611498253
Iter: 589 loss: 0.000611472293
Iter: 590 loss: 0.000611461175
Iter: 591 loss: 0.000611470256
Iter: 592 loss: 0.000611454365
Iter: 593 loss: 0.000611441443
Iter: 594 loss: 0.000611490454
Iter: 595 loss: 0.00061143795
Iter: 596 loss: 0.000611426192
Iter: 597 loss: 0.000611472467
Iter: 598 loss: 0.000611423631
Iter: 599 loss: 0.000611415948
Iter: 600 loss: 0.000611523632
Iter: 601 loss: 0.000611416297
Iter: 602 loss: 0.000611408555
Iter: 603 loss: 0.000611430733
Iter: 604 loss: 0.00061140646
Iter: 605 loss: 0.000611400697
Iter: 606 loss: 0.000611396506
Iter: 607 loss: 0.000611394411
Iter: 608 loss: 0.000611385156
Iter: 609 loss: 0.00061140547
Iter: 610 loss: 0.000611381372
Iter: 611 loss: 0.000611372758
Iter: 612 loss: 0.000611389172
Iter: 613 loss: 0.000611369207
Iter: 614 loss: 0.000611360243
Iter: 615 loss: 0.000611392315
Iter: 616 loss: 0.00061135774
Iter: 617 loss: 0.000611348427
Iter: 618 loss: 0.000611367868
Iter: 619 loss: 0.000611345051
Iter: 620 loss: 0.000611336902
Iter: 621 loss: 0.000611369382
Iter: 622 loss: 0.00061133469
Iter: 623 loss: 0.000611326075
Iter: 624 loss: 0.000611340569
Iter: 625 loss: 0.000611322117
Iter: 626 loss: 0.000611314084
Iter: 627 loss: 0.000611338124
Iter: 628 loss: 0.000611311116
Iter: 629 loss: 0.0006113032
Iter: 630 loss: 0.000611334457
Iter: 631 loss: 0.00061130122
Iter: 632 loss: 0.000611294527
Iter: 633 loss: 0.000611318857
Iter: 634 loss: 0.000611292606
Iter: 635 loss: 0.00061128661
Iter: 636 loss: 0.000611322816
Iter: 637 loss: 0.000611285679
Iter: 638 loss: 0.00061128
Iter: 639 loss: 0.000611327647
Iter: 640 loss: 0.000611279509
Iter: 641 loss: 0.000611276308
Iter: 642 loss: 0.000611268799
Iter: 643 loss: 0.000611367752
Iter: 644 loss: 0.000611267867
Iter: 645 loss: 0.000611259486
Iter: 646 loss: 0.000611286261
Iter: 647 loss: 0.00061125739
Iter: 648 loss: 0.000611249707
Iter: 649 loss: 0.00061128661
Iter: 650 loss: 0.000611248368
Iter: 651 loss: 0.000611241907
Iter: 652 loss: 0.000611261057
Iter: 653 loss: 0.000611239579
Iter: 654 loss: 0.000611233525
Iter: 655 loss: 0.000611252501
Iter: 656 loss: 0.000611231779
Iter: 657 loss: 0.000611225259
Iter: 658 loss: 0.000611249241
Iter: 659 loss: 0.000611224386
Iter: 660 loss: 0.000611219206
Iter: 661 loss: 0.000611225958
Iter: 662 loss: 0.000611216237
Iter: 663 loss: 0.000611210475
Iter: 664 loss: 0.000611236552
Iter: 665 loss: 0.000611209311
Iter: 666 loss: 0.00061120349
Iter: 667 loss: 0.000611212337
Iter: 668 loss: 0.000611201162
Iter: 669 loss: 0.000611196
Iter: 670 loss: 0.000611237308
Iter: 671 loss: 0.000611196039
Iter: 672 loss: 0.00061119243
Iter: 673 loss: 0.000611224
Iter: 674 loss: 0.000611192314
Iter: 675 loss: 0.000611188705
Iter: 676 loss: 0.000611188589
Iter: 677 loss: 0.000611185853
Iter: 678 loss: 0.000611182651
Iter: 679 loss: 0.000611180323
Iter: 680 loss: 0.000611178577
Iter: 681 loss: 0.000611173688
Iter: 682 loss: 0.000611195806
Iter: 683 loss: 0.000611172058
Iter: 684 loss: 0.000611168
Iter: 685 loss: 0.000611191674
Iter: 686 loss: 0.000611167226
Iter: 687 loss: 0.000611163152
Iter: 688 loss: 0.000611166528
Iter: 689 loss: 0.000611160416
Iter: 690 loss: 0.000611156225
Iter: 691 loss: 0.000611169031
Iter: 692 loss: 0.000611154479
Iter: 693 loss: 0.000611150288
Iter: 694 loss: 0.000611161347
Iter: 695 loss: 0.000611148891
Iter: 696 loss: 0.000611144234
Iter: 697 loss: 0.000611158379
Iter: 698 loss: 0.000611142779
Iter: 699 loss: 0.000611138472
Iter: 700 loss: 0.000611151685
Iter: 701 loss: 0.000611137133
Iter: 702 loss: 0.000611133641
Iter: 703 loss: 0.000611148425
Iter: 704 loss: 0.000611132535
Iter: 705 loss: 0.000611129391
Iter: 706 loss: 0.000611151336
Iter: 707 loss: 0.000611128926
Iter: 708 loss: 0.000611126074
Iter: 709 loss: 0.000611149182
Iter: 710 loss: 0.000611126132
Iter: 711 loss: 0.000611124211
Iter: 712 loss: 0.000611122057
Iter: 713 loss: 0.000611121359
Iter: 714 loss: 0.00061111839
Iter: 715 loss: 0.000611121359
Iter: 716 loss: 0.000611116877
Iter: 717 loss: 0.000611113268
Iter: 718 loss: 0.000611126481
Iter: 719 loss: 0.000611112
Iter: 720 loss: 0.000611108728
Iter: 721 loss: 0.000611121883
Iter: 722 loss: 0.000611108437
Iter: 723 loss: 0.000611105235
Iter: 724 loss: 0.000611107331
Iter: 725 loss: 0.00061110314
Iter: 726 loss: 0.000611099938
Iter: 727 loss: 0.000611114083
Iter: 728 loss: 0.000611099123
Iter: 729 loss: 0.000611096271
Iter: 730 loss: 0.000611102558
Iter: 731 loss: 0.000611095107
Iter: 732 loss: 0.000611091848
Iter: 733 loss: 0.000611107447
Iter: 734 loss: 0.000611091324
Iter: 735 loss: 0.000611088122
Iter: 736 loss: 0.000611095573
Iter: 737 loss: 0.00061108754
Iter: 738 loss: 0.000611084863
Iter: 739 loss: 0.000611091265
Iter: 740 loss: 0.000611084
Iter: 741 loss: 0.00061108236
Iter: 742 loss: 0.000611082301
Iter: 743 loss: 0.000611080613
Iter: 744 loss: 0.000611081196
Iter: 745 loss: 0.000611079624
Iter: 746 loss: 0.000611077296
Iter: 747 loss: 0.00061107683
Iter: 748 loss: 0.000611076073
Iter: 749 loss: 0.000611073046
Iter: 750 loss: 0.000611078693
Iter: 751 loss: 0.000611072057
Iter: 752 loss: 0.000611070194
Iter: 753 loss: 0.000611082185
Iter: 754 loss: 0.000611070078
Iter: 755 loss: 0.000611067633
Iter: 756 loss: 0.000611071
Iter: 757 loss: 0.000611066702
Iter: 758 loss: 0.000611064723
Iter: 759 loss: 0.000611068448
Iter: 760 loss: 0.000611063384
Iter: 761 loss: 0.000611061347
Iter: 762 loss: 0.000611068797
Iter: 763 loss: 0.000611061114
Iter: 764 loss: 0.000611058669
Iter: 765 loss: 0.000611064374
Iter: 766 loss: 0.000611058262
Iter: 767 loss: 0.000611055875
Iter: 768 loss: 0.000611065072
Iter: 769 loss: 0.000611055584
Iter: 770 loss: 0.00061105378
Iter: 771 loss: 0.000611055293
Iter: 772 loss: 0.000611052266
Iter: 773 loss: 0.000611050928
Iter: 774 loss: 0.000611058786
Iter: 775 loss: 0.000611050637
Iter: 776 loss: 0.000611048774
Iter: 777 loss: 0.000611048774
Iter: 778 loss: 0.000611048
Iter: 779 loss: 0.000611046737
Iter: 780 loss: 0.000611047
Iter: 781 loss: 0.000611044583
Iter: 782 loss: 0.000611047726
Iter: 783 loss: 0.000611043884
Iter: 784 loss: 0.000611042604
Iter: 785 loss: 0.000611048599
Iter: 786 loss: 0.000611042
Iter: 787 loss: 0.000611040276
Iter: 788 loss: 0.000611046678
Iter: 789 loss: 0.000611039926
Iter: 790 loss: 0.000611038413
Iter: 791 loss: 0.000611039344
Iter: 792 loss: 0.000611037714
Iter: 793 loss: 0.000611036085
Iter: 794 loss: 0.000611042837
Iter: 795 loss: 0.000611035386
Iter: 796 loss: 0.000611034
Iter: 797 loss: 0.000611037714
Iter: 798 loss: 0.000611033174
Iter: 799 loss: 0.000611031719
Iter: 800 loss: 0.000611041
Iter: 801 loss: 0.000611031894
Iter: 802 loss: 0.000611030147
Iter: 803 loss: 0.000611032301
Iter: 804 loss: 0.000611029915
Iter: 805 loss: 0.000611028576
Iter: 806 loss: 0.000611030147
Iter: 807 loss: 0.000611027819
Iter: 808 loss: 0.000611026655
Iter: 809 loss: 0.00061102683
Iter: 810 loss: 0.000611025724
Iter: 811 loss: 0.00061102974
Iter: 812 loss: 0.000611025607
Iter: 813 loss: 0.000611024676
Iter: 814 loss: 0.000611024443
Iter: 815 loss: 0.000611024
Iter: 816 loss: 0.000611023046
Iter: 817 loss: 0.00061102421
Iter: 818 loss: 0.000611022231
Iter: 819 loss: 0.000611020892
Iter: 820 loss: 0.000611024909
Iter: 821 loss: 0.000611020485
Iter: 822 loss: 0.00061101967
Iter: 823 loss: 0.000611020718
Iter: 824 loss: 0.000611019204
Iter: 825 loss: 0.000611017691
Iter: 826 loss: 0.000611024909
Iter: 827 loss: 0.000611017924
Iter: 828 loss: 0.00061101676
Iter: 829 loss: 0.000611018
Iter: 830 loss: 0.000611015712
Iter: 831 loss: 0.000611014839
Iter: 832 loss: 0.000611019845
Iter: 833 loss: 0.000611014548
Iter: 834 loss: 0.0006110135
Iter: 835 loss: 0.000611017458
Iter: 836 loss: 0.000611013209
Iter: 837 loss: 0.000611012336
Iter: 838 loss: 0.000611012394
Iter: 839 loss: 0.000611012045
Iter: 840 loss: 0.000611010764
Iter: 841 loss: 0.000611015188
Iter: 842 loss: 0.000611010473
Iter: 843 loss: 0.000611009891
Iter: 844 loss: 0.000611009833
Iter: 845 loss: 0.000611009425
Iter: 846 loss: 0.000611008902
Iter: 847 loss: 0.000611008611
Iter: 848 loss: 0.00061100797
Iter: 849 loss: 0.000611008611
Iter: 850 loss: 0.000611007446
Iter: 851 loss: 0.000611006515
Iter: 852 loss: 0.000611008494
Iter: 853 loss: 0.000611005933
Iter: 854 loss: 0.000611005351
Iter: 855 loss: 0.000611007621
Iter: 856 loss: 0.000611004885
Iter: 857 loss: 0.00061100407
Iter: 858 loss: 0.000611006282
Iter: 859 loss: 0.000611003896
Iter: 860 loss: 0.000611003139
Iter: 861 loss: 0.000611005584
Iter: 862 loss: 0.000611002441
Iter: 863 loss: 0.000611002091
Iter: 864 loss: 0.000611004
Iter: 865 loss: 0.000611001626
Iter: 866 loss: 0.000611000694
Iter: 867 loss: 0.000611003255
Iter: 868 loss: 0.000611000927
Iter: 869 loss: 0.000611000229
Iter: 870 loss: 0.000611002091
Iter: 871 loss: 0.000610999763
Iter: 872 loss: 0.000610998715
Iter: 873 loss: 0.000611000112
Iter: 874 loss: 0.000610998366
Iter: 875 loss: 0.0006109979
Iter: 876 loss: 0.000611002906
Iter: 877 loss: 0.000610997784
Iter: 878 loss: 0.00061099726
Iter: 879 loss: 0.00061100407
Iter: 880 loss: 0.000610997085
Iter: 881 loss: 0.000610997
Iter: 882 loss: 0.00061099662
Iter: 883 loss: 0.000610996736
Iter: 884 loss: 0.000610996038
Iter: 885 loss: 0.000610996562
Iter: 886 loss: 0.000610995921
Iter: 887 loss: 0.000610994932
Iter: 888 loss: 0.000610995106
Iter: 889 loss: 0.000610994815
Iter: 890 loss: 0.000610994059
Iter: 891 loss: 0.000610996271
Iter: 892 loss: 0.000610993593
Iter: 893 loss: 0.000610992953
Iter: 894 loss: 0.000610996387
Iter: 895 loss: 0.000610992895
Iter: 896 loss: 0.00061099272
Iter: 897 loss: 0.000610993884
Iter: 898 loss: 0.000610992312
Iter: 899 loss: 0.000610991381
Iter: 900 loss: 0.000610993
Iter: 901 loss: 0.000610991148
Iter: 902 loss: 0.000610990799
Iter: 903 loss: 0.000610991963
Iter: 904 loss: 0.000610990566
Iter: 905 loss: 0.00061099
Iter: 906 loss: 0.000610993127
Iter: 907 loss: 0.000610990101
Iter: 908 loss: 0.000610989053
Iter: 909 loss: 0.000610989868
Iter: 910 loss: 0.000610989169
Iter: 911 loss: 0.000610988936
Iter: 912 loss: 0.00061098882
Iter: 913 loss: 0.000610988762
Iter: 914 loss: 0.000610989227
Iter: 915 loss: 0.000610987889
Iter: 916 loss: 0.000610988
Iter: 917 loss: 0.00061098818
Iter: 918 loss: 0.000610987656
Iter: 919 loss: 0.000610987
Iter: 920 loss: 0.000610987365
Iter: 921 loss: 0.000610987074
Iter: 922 loss: 0.000610986142
Iter: 923 loss: 0.000610988
Iter: 924 loss: 0.000610986375
Iter: 925 loss: 0.00061098591
Iter: 926 loss: 0.000610986608
Iter: 927 loss: 0.000610985793
Iter: 928 loss: 0.000610985269
Iter: 929 loss: 0.000610987307
Iter: 930 loss: 0.000610985036
Iter: 931 loss: 0.000610984687
Iter: 932 loss: 0.000610986724
Iter: 933 loss: 0.000610984745
Iter: 934 loss: 0.000610984222
Iter: 935 loss: 0.000610984629
Iter: 936 loss: 0.000610984163
Iter: 937 loss: 0.000610983581
Iter: 938 loss: 0.000610985502
Iter: 939 loss: 0.000610983465
Iter: 940 loss: 0.000610983174
Iter: 941 loss: 0.000610985095
Iter: 942 loss: 0.000610983116
Iter: 943 loss: 0.000610982825
Iter: 944 loss: 0.000610983523
Iter: 945 loss: 0.000610982068
Iter: 946 loss: 0.000610982068
Iter: 947 loss: 0.000610982184
Iter: 948 loss: 0.000610981893
Iter: 949 loss: 0.000610982068
Iter: 950 loss: 0.000610981602
Iter: 951 loss: 0.000610981602
Iter: 952 loss: 0.000610981253
Iter: 953 loss: 0.000610981369
Iter: 954 loss: 0.000610980904
Iter: 955 loss: 0.000610981835
Iter: 956 loss: 0.000610980787
Iter: 957 loss: 0.000610980554
Iter: 958 loss: 0.000610981951
Iter: 959 loss: 0.000610980322
Iter: 960 loss: 0.000610980205
Iter: 961 loss: 0.000610981602
Iter: 962 loss: 0.000610980089
Iter: 963 loss: 0.00061097974
Iter: 964 loss: 0.000610980554
Iter: 965 loss: 0.00061098
Iter: 966 loss: 0.00061097939
Iter: 967 loss: 0.000610979681
Iter: 968 loss: 0.000610978925
Iter: 969 loss: 0.000610978925
Iter: 970 loss: 0.000610978808
Iter: 971 loss: 0.000610978692
Iter: 972 loss: 0.000610978343
Iter: 973 loss: 0.000610980263
Iter: 974 loss: 0.00061097811
Iter: 975 loss: 0.000610977644
Iter: 976 loss: 0.000610979
Iter: 977 loss: 0.000610977644
Iter: 978 loss: 0.000610977528
Iter: 979 loss: 0.000610979623
Iter: 980 loss: 0.000610977761
Iter: 981 loss: 0.000610977295
Iter: 982 loss: 0.000610979914
Iter: 983 loss: 0.000610977528
Iter: 984 loss: 0.000610977295
Iter: 985 loss: 0.000610976887
Iter: 986 loss: 0.000610976713
Iter: 987 loss: 0.000610976596
Iter: 988 loss: 0.000610977411
Iter: 989 loss: 0.000610976713
/home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /home/mrdouglas/Manifold/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
++ basename experiments.final/script70
+ '[' -r STOP.script70 ']'
+ MODEL=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.6/k4
+ for phi in 0 0.4 0.8 1.2 1.6 2 2.4 2.8 3
+ OUTDIR=/home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi2
+ date
Tue Oct 27 21:19:28 EDT 2020
+ mkdir -p /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi2
+ '[' -r /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi2/k4 ']'
+ python biholoNN_train.py --seed 1234 --n_pairs 2000 --load_model /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi1.6/k4 --OuterProductNN_k 4 --optimizer lbfgs --function f2 --psi 0 --alpha 2 --save_dir /home/mrdouglas/Manifold/experiments.final/output70/f2_psi0_phi2/ --save_name k4 --max_epochs 2000 --loss_func weighted_MSE
Processing model: k4
WARNING:tensorflow:5 out of the last 5 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695596510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:6 out of the last 6 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66955a1d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:7 out of the last 7 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695588598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:8 out of the last 8 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695588950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:9 out of the last 9 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695532620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:10 out of the last 10 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f669798cd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66954929d8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66954922f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695492ae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695470488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695470b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695420048> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695420d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66953e36a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66953a7488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66953c5a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695350400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f669538b730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66953317b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695331268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f669533d378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f669529c7b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695309f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695309ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695264488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695264d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66952c3b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66951cf158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66951cfa60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f669520d268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695199d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f66951c5f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695163598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695163ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695199ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
WARNING:tensorflow:11 out of the last 11 calls to <function Hypersurface.num_FS_volume_form_tf at 0x7f6695163268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
Iter: 1 loss: 0.0129259974
Iter: 2 loss: 0.0097427
Iter: 3 loss: 6588.5625
Iter: 4 loss: 0.0246207453
Iter: 5 loss: 0.0115778781
Iter: 6 loss: 0.00831938256
Iter: 7 loss: 0.00799969
Iter: 8 loss: 0.00657310756
Iter: 9 loss: 0.0147069097
Iter: 10 loss: 0.00628266437
Iter: 11 loss: 0.00464728149
Iter: 12 loss: 0.0186813362
Iter: 13 loss: 0.00458211266
Iter: 14 loss: 0.00373221771
Iter: 15 loss: 0.00894505717
Iter: 16 loss: 0.00370680401
Iter: 17 loss: 0.00334311463
Iter: 18 loss: 0.00334679848
Iter: 19 loss: 0.00301849516
Iter: 20 loss: 0.00275798142
Iter: 21 loss: 0.00272832974
Iter: 22 loss: 0.00253881514
Iter: 23 loss: 0.00214262633
Iter: 24 loss: 0.00704566902
Iter: 25 loss: 0.00213856017
Iter: 26 loss: 0.00187870651
Iter: 27 loss: 0.00321217813
Iter: 28 loss: 0.00184006989
Iter: 29 loss: 0.0017317622
Iter: 30 loss: 0.00167721929
Iter: 31 loss: 0.00162225193
Iter: 32 loss: 0.00153881288
Iter: 33 loss: 0.00158106734
Iter: 34 loss: 0.00148573588
Iter: 35 loss: 0.00141085673
Iter: 36 loss: 0.00141030946
Iter: 37 loss: 0.00134947442
Iter: 38 loss: 0.00127707771
Iter: 39 loss: 0.0014609152
Iter: 40 loss: 0.00125046074
Iter: 41 loss: 0.00117704761
Iter: 42 loss: 0.00166411407
Iter: 43 loss: 0.0011699521
Iter: 44 loss: 0.00111909211
Iter: 45 loss: 0.00130336953
Iter: 46 loss: 0.00110571936
Iter: 47 loss: 0.00105962472
Iter: 48 loss: 0.00116856757
Iter: 49 loss: 0.0010427665
Iter: 50 loss: 0.00100067072
Iter: 51 loss: 0.00114657101
Iter: 52 loss: 0.000989129883
Iter: 53 loss: 0.000957654906
Iter: 54 loss: 0.00111125642
Iter: 55 loss: 0.000952116679
Iter: 56 loss: 0.000928104506
Iter: 57 loss: 0.00117854669
Iter: 58 loss: 0.000927476445
Iter: 59 loss: 0.000909386901
Iter: 60 loss: 0.000973622315
Iter: 61 loss: 0.000904789311
Iter: 62 loss: 0.000890120165
Iter: 63 loss: 0.000935951073
Iter: 64 loss: 0.000885673799
Iter: 65 loss: 0.000870877644
Iter: 66 loss: 0.00104186707
Iter: 67 loss: 0.000870713731
Iter: 68 loss: 0.000862559769
Iter: 69 loss: 0.000853799342
Iter: 70 loss: 0.000852355151
Iter: 71 loss: 0.000838588574
Iter: 72 loss: 0.000875491183
Iter: 73 loss: 0.000834079576
Iter: 74 loss: 0.000820714049
Iter: 75 loss: 0.000836042629
Iter: 76 loss: 0.000813557883
Iter: 77 loss: 0.000801214832
Iter: 78 loss: 0.00085252733
Iter: 79 loss: 0.000798487687
Iter: 80 loss: 0.000785708893
Iter: 81 loss: 0.000812718528
Iter: 82 loss: 0.000780674047
Iter: 83 loss: 0.000768823666
Iter: 84 loss: 0.000786590273
Iter: 85 loss: 0.000763151911
Iter: 86 loss: 0.000751516491
Iter: 87 loss: 0.000802250521
Iter: 88 loss: 0.000749200233
Iter: 89 loss: 0.000741127471
Iter: 90 loss: 0.000807941076
Iter: 91 loss: 0.000740597839
Iter: 92 loss: 0.00073445926
Iter: 93 loss: 0.000772203319
Iter: 94 loss: 0.000733711408
Iter: 95 loss: 0.000728633371
Iter: 96 loss: 0.000742311706
Iter: 97 loss: 0.000726927188
Iter: 98 loss: 0.000722796249
Iter: 99 loss: 0.000762463897
Iter: 100 loss: 0.000722662895
Iter: 101 loss: 0.000718942843
Iter: 102 loss: 0.000717100571
Iter: 103 loss: 0.000715310103
Iter: 104 loss: 0.000710586552
Iter: 105 loss: 0.00071120949
Iter: 106 loss: 0.000706994
Iter: 107 loss: 0.000700872624
Iter: 108 loss: 0.00072514615
Iter: 109 loss: 0.000699474418
Iter: 110 loss: 0.0006934884
Iter: 111 loss: 0.000706631748
Iter: 112 loss: 0.000691176159
Iter: 113 loss: 0.000685632345
Iter: 114 loss: 0.000693560753
Iter: 115 loss: 0.000682900718
Iter: 116 loss: 0.000677718257
Iter: 117 loss: 0.00070186879
Iter: 118 loss: 0.000676739786
Iter: 119 loss: 0.000671946618
Iter: 120 loss: 0.000687665772
Iter: 121 loss: 0.000670632697
Iter: 122 loss: 0.000666495704
Iter: 123 loss: 0.000677526463
Iter: 124 loss: 0.000665103667
Iter: 125 loss: 0.000661621627
Iter: 126 loss: 0.000685261912
Iter: 127 loss: 0.000661276397
Iter: 128 loss: 0.000658107921
Iter: 129 loss: 0.000672278111
Iter: 130 loss: 0.000657478231
Iter: 131 loss: 0.000655038806
Iter: 132 loss: 0.000666927779
Iter: 133 loss: 0.000654631876
Iter: 134 loss: 0.000652066607
Iter: 135 loss: 0.000656656688
Iter: 136 loss: 0.000650933129
Iter: 137 loss: 0.000648793299
Iter: 138 loss: 0.000647642766
Iter: 139 loss: 0.000646686356
Iter: 140 loss: 0.000643378182
Iter: 141 loss: 0.00065147545
Iter: 142 loss: 0.000642192317
Iter: 143 loss: 0.000638972153
Iter: 144 loss: 0.000648867572
Iter: 145 loss: 0.000638020108
Iter: 146 loss: 0.000635162054
Iter: 147 loss: 0.000647142529
Iter: 148 loss: 0.000634557509
Iter: 149 loss: 0.000631958479
Iter: 150 loss: 0.000638550555
Iter: 151 loss: 0.000631053466
Iter: 152 loss: 0.000628688
Iter: 153 loss: 0.000629856077
Iter: 154 loss: 0.000627109664
Iter: 155 loss: 0.000624523964
Iter: 156 loss: 0.000633890857
Iter: 157 loss: 0.000623868429
Iter: 158 loss: 0.00062162173
Iter: 159 loss: 0.000642003
Iter: 160 loss: 0.000621519168
Iter: 161 loss: 0.000619749888
Iter: 162 loss: 0.000625650107
Iter: 163 loss: 0.000619265425
Iter: 164 loss: 0.000617648591
Iter: 165 loss: 0.000630162
Iter: 166 loss: 0.000617534271
Iter: 167 loss: 0.00061636942
Iter: 168 loss: 0.000620236038
Iter: 169 loss: 0.000616043282
Iter: 170 loss: 0.000614888151
Iter: 171 loss: 0.000613467884
Iter: 172 loss: 0.000613342272
Iter: 173 loss: 0.000611527474
Iter: 174 loss: 0.000615861558
Iter: 175 loss: 0.000610864663
Iter: 176 loss: 0.00060907111
Iter: 177 loss: 0.000618139864
Iter: 178 loss: 0.000608776347
Iter: 179 loss: 0.000607310445
Iter: 180 loss: 0.000609244162
Iter: 181 loss: 0.000606567075
Iter: 182 loss: 0.000604991335
Iter: 183 loss: 0.000612764037
Iter: 184 loss: 0.000604718458
Iter: 185 loss: 0.000603336259
Iter: 186 loss: 0.000605391571
Iter: 187 loss: 0.000602673332
Iter: 188 loss: 0.000601262436
Iter: 189 loss: 0.000602635322
Iter: 190 loss: 0.000600458763
Iter: 191 loss: 0.000598878483
Iter: 192 loss: 0.000608036644
Iter: 193 loss: 0.000598670333
Iter: 194 loss: 0.000597488368
Iter: 195 loss: 0.000605335343
Iter: 196 loss: 0.000597367296
Iter: 197 loss: 0.000596386963
Iter: 198 loss: 0.000604604953
Iter: 199 loss: 0.000596332073
Iter: 200 loss: 0.000595671067
Iter: 201 loss: 0.000597894541
Iter: 202 loss: 0.000595489051
Iter: 203 loss: 0.000594782759
Iter: 204 loss: 0.0005939494
Iter: 205 loss: 0.000593859528
Iter: 206 loss: 0.000592722674
Iter: 207 loss: 0.000596504891
Iter: 208 loss: 0.000592406141
Iter: 209 loss: 0.000591371
Iter: 210 loss: 0.000592355384
Iter: 211 loss: 0.000590780692
Iter: 212 loss: 0.000589631614
Iter: 213 loss: 0.00059399422
Iter: 214 loss: 0.000589356758
Iter: 215 loss: 0.000588313327
Iter: 216 loss: 0.000593878096
Iter: 217 loss: 0.000588153955
Iter: 218 loss: 0.000587269256
Iter: 219 loss: 0.000588153198
Iter: 220 loss: 0.000586773036
Iter: 221 loss: 0.000585807953
Iter: 222 loss: 0.00058764295
Iter: 223 loss: 0.000585401722
Iter: 224 loss: 0.000584393507
Iter: 225 loss: 0.000588636263
Iter: 226 loss: 0.000584179303
Iter: 227 loss: 0.000583258166
Iter: 228 loss: 0.00058634067
Iter: 229 loss: 0.000583005429
Iter: 230 loss: 0.00058238674
Iter: 231 loss: 0.000591412652
Iter: 232 loss: 0.000582386157
Iter: 233 loss: 0.000581844186
Iter: 234 loss: 0.000583551708
Iter: 235 loss: 0.000581685861
Iter: 236 loss: 0.000581215776
Iter: 237 loss: 0.000581486151
Iter: 238 loss: 0.000580910943
Iter: 239 loss: 0.000580298656
Iter: 240 loss: 0.000580129563
Iter: 241 loss: 0.000579752959
Iter: 242 loss: 0.000579016807
Iter: 243 loss: 0.000579811691
Iter: 244 loss: 0.000578613719
Iter: 245 loss: 0.000577839965
Iter: 246 loss: 0.000582935056
Iter: 247 loss: 0.000577758532
Iter: 248 loss: 0.000577097293
Iter: 249 loss: 0.000579547
Iter: 250 loss: 0.000576934777
Iter: 251 loss: 0.000576348393
Iter: 252 loss: 0.000577622
Iter: 253 loss: 0.000576121733
Iter: 254 loss: 0.000575527549
Iter: 255 loss: 0.000576588674
Iter: 256 loss: 0.000575267652
Iter: 257 loss: 0.000574655
Iter: 258 loss: 0.000576432
Iter: 259 loss: 0.000574464793
Iter: 260 loss: 0.000573843776
Iter: 261 loss: 0.00057604193
Iter: 262 loss: 0.000573683355
Iter: 263 loss: 0.000573200872
Iter: 264 loss: 0.000576059101
Iter: 265 loss: 0.000573140336
Iter: 266 loss: 0.000572732184
Iter: 267 loss: 0.000577713421
Iter: 268 loss: 0.000572727527
Iter: 269 loss: 0.000572474091
Iter: 270 loss: 0.000572300632
Iter: 271 loss: 0.000572208664
Iter: 272 loss: 0.000571784563
Iter: 273 loss: 0.000572169665
Iter: 274 loss: 0.000571537181
Iter: 275 loss: 0.000571085664
Iter: 276 loss: 0.000570884324
Iter: 277 loss: 0.00057065615
Iter: 278 loss: 0.000570074073
Iter: 279 loss: 0.000573640107
Iter: 280 loss: 0.000570003642
Iter: 281 loss: 0.000569512486
Iter: 282 loss: 0.000572260935
Iter: 283 loss: 0.000569442811
Iter: 284 loss: 0.000569048
Iter: 285 loss: 0.000569828087
Iter: 286 loss: 0.000568886404
Iter: 287 loss: 0.000568466552
Iter: 288 loss: 0.000569285243
Iter: 289 loss: 0.000568291871
Iter: 290 loss: 0.000567881856
Iter: 291 loss: 0.000569128548
Iter: 292 loss: 0.000567759678
Iter: 293 loss: 0.000567376497
Iter: 294 loss: 0.000568769639
Iter: 295 loss: 0.00056728092
Iter: 296 loss: 0.000566934934
Iter: 297 loss: 0.000568059157
Iter: 298 loss: 0.000566838309
Iter: 299 loss: 0.000566640461
Iter: 300 loss: 0.000566620263
Iter: 301 loss: 0.000566466828
Iter: 302 loss: 0.00056625274
Iter: 303 loss: 0.000566243893
Iter: 304 loss: 0.000565934402
Iter: 305 loss: 0.000566458504
Iter: 306 loss: 0.00056579482
Iter: 307 loss: 0.000565484515
Iter: 308 loss: 0.000565503957
Iter: 309 loss: 0.000565241557
Iter: 310 loss: 0.000564859714
Iter: 311 loss: 0.000565833645
Iter: 312 loss: 0.000564728398
Iter: 313 loss: 0.000564381713
Iter: 314 loss: 0.000567065785
Iter: 315 loss: 0.000564356742
Iter: 316 loss: 0.000564071932
Iter: 317 loss: 0.000564594753
Iter: 318 loss: 0.000563949
Iter: 319 loss: 0.000563639042
Iter: 320 loss: 0.00056436169
Iter: 321 loss: 0.000563524431
Iter: 322 loss: 0.000563239097
Iter: 323 loss: 0.000564170768
Iter: 324 loss: 0.000563159585
Iter: 325 loss: 0.000562873611
Iter: 326 loss: 0.000563374197
Iter: 327 loss: 0.000562747475
Iter: 328 loss: 0.000562472676
Iter: 329 loss: 0.000563514594
Iter: 330 loss: 0.000562407193
Iter: 331 loss: 0.000562275527
Iter: 332 loss: 0.000562253874
Iter: 333 loss: 0.000562126865
Iter: 334 loss: 0.000562034606
Iter: 335 loss: 0.000561990659
Iter: 336 loss: 0.000561803812
Iter: 337 loss: 0.000562027155
Iter: 338 loss: 0.000561705558
Iter: 339 loss: 0.000561492459
Iter: 340 loss: 0.000561711611
Iter: 341 loss: 0.00056137424
Iter: 342 loss: 0.000561145
Iter: 343 loss: 0.000561310677
Iter: 344 loss: 0.000561003166
Iter: 345 loss: 0.000560750777
Iter: 346 loss: 0.000562204688
Iter: 347 loss: 0.00056071626
Iter: 348 loss: 0.000560483779
Iter: 349 loss: 0.000561301
Iter: 350 loss: 0.000560424058
Iter: 351 loss: 0.000560214627
Iter: 352 loss: 0.000560641638
Iter: 353 loss: 0.000560130575
Iter: 354 loss: 0.000559924054
Iter: 355 loss: 0.000560885412
Iter: 356 loss: 0.000559886
Iter: 357 loss: 0.000559697393
Iter: 358 loss: 0.000559750944
Iter: 359 loss: 0.000559561187
Iter: 360 loss: 0.000559337786
Iter: 361 loss: 0.000559955253
Iter: 362 loss: 0.0005592659
Iter: 363 loss: 0.000559176551
Iter: 364 loss: 0.000559146458
Iter: 365 loss: 0.000559034757
Iter: 366 loss: 0.000559041
Iter: 367 loss: 0.000558947388
Iter: 368 loss: 0.000558815664
Iter: 369 loss: 0.000558884931
Iter: 370 loss: 0.000558727595
Iter: 371 loss: 0.000558567932
Iter: 372 loss: 0.000558899483
Iter: 373 loss: 0.000558504311
Iter: 374 loss: 0.000558344531
Iter: 375 loss: 0.000558337895
Iter: 376 loss: 0.000558214844
Iter: 377 loss: 0.000558009953
Iter: 378 loss: 0.000558781438
Iter: 379 loss: 0.00055796036
Iter: 380 loss: 0.000557775667
Iter: 381 loss: 0.000559048727
Iter: 382 loss: 0.000557758205
Iter: 383 loss: 0.000557606923
Iter: 384 loss: 0.000557770545
Iter: 385 loss: 0.00055752456
Iter: 386 loss: 0.000557363848
Iter: 387 loss: 0.000558166066
Iter: 388 loss: 0.000557337189
Iter: 389 loss: 0.000557190564
Iter: 390 loss: 0.000557378167
Iter: 391 loss: 0.000557115651
Iter: 392 loss: 0.000556964776
Iter: 393 loss: 0.000557134044
Iter: 394 loss: 0.000556883053
Iter: 395 loss: 0.000556806044
Iter: 396 loss: 0.000556790095
Iter: 397 loss: 0.000556698244
Iter: 398 loss: 0.000556849467
Iter: 399 loss: 0.000556656043
Iter: 400 loss: 0.00055657106
Iter: 401 loss: 0.000556546031
Iter: 402 loss: 0.000556495157
Iter: 403 loss: 0.000556377694
Iter: 404 loss: 0.000556663843
Iter: 405 loss: 0.000556335435
Iter: 406 loss: 0.000556220068
Iter: 407 loss: 0.000556289102
Iter: 408 loss: 0.000556145911
Iter: 409 loss: 0.00055600924
Iter: 410 loss: 0.000556321931
Iter: 411 loss: 0.00055595825
Iter: 412 loss: 0.000555826642
Iter: 413 loss: 0.000556651677
Iter: 414 loss: 0.000555811683
Iter: 415 loss: 0.000555700215
Iter: 416 loss: 0.000555849052
Iter: 417 loss: 0.000555644394
Iter: 418 loss: 0.000555533
Iter: 419 loss: 0.000556217856
Iter: 420 loss: 0.000555520179
Iter: 421 loss: 0.000555419712
Iter: 422 loss: 0.000555537641
Iter: 423 loss: 0.000555366394
Iter: 424 loss: 0.00055525807
Iter: 425 loss: 0.000555303588
Iter: 426 loss: 0.000555183156
Iter: 427 loss: 0.000555102248
Iter: 428 loss: 0.000555100502
Iter: 429 loss: 0.000555019884
Iter: 430 loss: 0.000555417559
Iter: 431 loss: 0.000555005157
Iter: 432 loss: 0.000554950559
Iter: 433 loss: 0.000554914644
Iter: 434 loss: 0.00055489369
Iter: 435 loss: 0.000554814411
Iter: 436 loss: 0.000554993865
Iter: 437 loss: 0.0005547849
Iter: 438 loss: 0.000554700557
Iter: 439 loss: 0.000554744853
Iter: 440 loss: 0.000554644852
Iter: 441 loss: 0.000554546481
Iter: 442 loss: 0.000554774422
Iter: 443 loss: 0.000554510043
Iter: 444 loss: 0.000554412429
Iter: 445 loss: 0.000554831
Iter: 446 loss: 0.000554391707
Iter: 447 loss: 0.000554299331
Iter: 448 loss: 0.000554547587
Iter: 449 loss: 0.000554268481
Iter: 450 loss: 0.000554185594
Iter: 451 loss: 0.000554489321
Iter: 452 loss: 0.000554165104
Iter: 453 loss: 0.000554082915
Iter: 454 loss: 0.000554350554
Iter: 455 loss: 0.000554060098
Iter: 456 loss: 0.000553985126
Iter: 457 loss: 0.000553994672
Iter: 458 loss: 0.000553928083
Iter: 459 loss: 0.000553842343
Iter: 460 loss: 0.000554436701
Iter: 461 loss: 0.000553834194
Iter: 462 loss: 0.000553784077
Iter: 463 loss: 0.000553780934
Iter: 464 loss: 0.00055374729
Iter: 465 loss: 0.000553691352
Iter: 466 loss: 0.000553691294
Iter: 467 loss: 0.000553628313
Iter: 468 loss: 0.000553786522
Iter: 469 loss: 0.000553606893
Iter: 470 loss: 0.000553540653
Iter: 471 loss: 0.000553617137
Iter: 472 loss: 0.00055350503
Iter: 473 loss: 0.000553434365
Iter: 474 loss: 0.000553632388
Iter: 475 loss: 0.000553411315
Iter: 476 loss: 0.000553335762
Iter: 477 loss: 0.000553441
Iter: 478 loss: 0.00055329781
Iter: 479 loss: 0.000553218764
Iter: 480 loss: 0.000553436461
Iter: 481 loss: 0.00055319292
Iter: 482 loss: 0.000553119928
Iter: 483 loss: 0.000553493504
Iter: 484 loss: 0.000553108
Iter: 485 loss: 0.000553045888
Iter: 486 loss: 0.00055329327
Iter: 487 loss: 0.000553031685
Iter: 488 loss: 0.000552972
Iter: 489 loss: 0.000553048507
Iter: 490 loss: 0.000552941812
Iter: 491 loss: 0.000552876387
Iter: 492 loss: 0.000552964339
Iter: 493 loss: 0.00055284414
Iter: 494 loss: 0.000552824116
Iter: 495 loss: 0.000552809914
Iter: 496 loss: 0.000552775
Iter: 497 loss: 0.0005527389
Iter: 498 loss: 0.000552732265
Iter: 499 loss: 0.000552686863
Iter: 500 loss: 0.000552732381
Iter: 501 loss: 0.000552661
Iter: 502 loss: 0.000552607467
Iter: 503 loss: 0.000552699377
Iter: 504 loss: 0.000552583835
Iter: 505 loss: 0.000552529702
Iter: 506 loss: 0.000552753569
Iter: 507 loss: 0.000552517246
Iter: 508 loss: 0.000552465208
Iter: 509 loss: 0.00055253657
Iter: 510 loss: 0.000552438665
Iter: 511 loss: 0.000552387268
Iter: 512 loss: 0.000552423415
Iter: 513 loss: 0.000552355195
Iter: 514 loss: 0.000552297337
Iter: 515 loss: 0.000552723068
Iter: 516 loss: 0.00055229268
Iter: 517 loss: 0.000552243728
Iter: 518 loss: 0.000552337384
Iter: 519 loss: 0.000552222773
Iter: 520 loss: 0.000552172423
Iter: 521 loss: 0.00055235636
Iter: 522 loss: 0.000552159734
Iter: 523 loss: 0.000552111538
Iter: 524 loss: 0.000552239129
Iter: 525 loss: 0.00055209623
Iter: 526 loss: 0.000552049954
Iter: 527 loss: 0.000552233076
Iter: 528 loss: 0.000552039477
Iter: 529 loss: 0.000552014
Iter: 530 loss: 0.000552012
Iter: 531 loss: 0.000551990583
Iter: 532 loss: 0.000551951409
Iter: 533 loss: 0.000552844489
Iter: 534 loss: 0.000551950769
Iter: 535 loss: 0.000551911362
Iter: 536 loss: 0.000551906764
Iter: 537 loss: 0.000551878591
Iter: 538 loss: 0.000551826379
Iter: 539 loss: 0.000552068057
Iter: 540 loss: 0.000551817
Iter: 541 loss: 0.000551773934
Iter: 542 loss: 0.000552015088
Iter: 543 loss: 0.000551768
Iter: 544 loss: 0.000551729812
Iter: 545 loss: 0.000551775855
Iter: 546 loss: 0.000551709847
Iter: 547 loss: 0.00055166753
Iter: 548 loss: 0.000551838544
Iter: 549 loss: 0.000551657868
Iter: 550 loss: 0.000551620964
Iter: 551 loss: 0.000551663223
Iter: 552 loss: 0.000551600708
Iter: 553 loss: 0.00055155647
Iter: 554 loss: 0.000551664503
Iter: 555 loss: 0.000551540055
Iter: 556 loss: 0.000551499892
Iter: 557 loss: 0.000551620149
Iter: 558 loss: 0.000551487203
Iter: 559 loss: 0.000551450299
Iter: 560 loss: 0.000551673
Iter: 561 loss: 0.000551445759
Iter: 562 loss: 0.000551425619
Iter: 563 loss: 0.000551425386
Iter: 564 loss: 0.000551404664
Iter: 565 loss: 0.000551396864
Iter: 566 loss: 0.000551385514
Iter: 567 loss: 0.00055136357
Iter: 568 loss: 0.000551335281
Iter: 569 loss: 0.000551333127
Iter: 570 loss: 0.000551300938
Iter: 571 loss: 0.000551582198
Iter: 572 loss: 0.000551299192
Iter: 573 loss: 0.000551272
Iter: 574 loss: 0.000551332952
Iter: 575 loss: 0.000551261473
Iter: 576 loss: 0.000551234407
Iter: 577 loss: 0.000551266829
Iter: 578 loss: 0.00055122
Iter: 579 loss: 0.000551188423
Iter: 580 loss: 0.000551299891
Iter: 581 loss: 0.000551180274
Iter: 582 loss: 0.000551150879
Iter: 583 loss: 0.000551232893
Iter: 584 loss: 0.000551141682
Iter: 585 loss: 0.000551113277
Iter: 586 loss: 0.000551197096
Iter: 587 loss: 0.000551105244
Iter: 588 loss: 0.000551078236
Iter: 589 loss: 0.000551121426
Iter: 590 loss: 0.000551065779
Iter: 591 loss: 0.000551037607
Iter: 592 loss: 0.000551153033
Iter: 593 loss: 0.000551031495
Iter: 594 loss: 0.00055100763
Iter: 595 loss: 0.000551150064
Iter: 596 loss: 0.000551005069
Iter: 597 loss: 0.000550985627
Iter: 598 loss: 0.000551260542
Iter: 599 loss: 0.000550985162
Iter: 600 loss: 0.000550976139
Iter: 601 loss: 0.000550950819
Iter: 602 loss: 0.000551127072
Iter: 603 loss: 0.000550945
Iter: 604 loss: 0.000550917175
Iter: 605 loss: 0.000551067875
Iter: 606 loss: 0.000550912926
Iter: 607 loss: 0.000550888304
Iter: 608 loss: 0.000550970144
Iter: 609 loss: 0.000550882
Iter: 610 loss: 0.000550858676
Iter: 611 loss: 0.000550911471
Iter: 612 loss: 0.000550849945
Iter: 613 loss: 0.000550827535
Iter: 614 loss: 0.000550953962
Iter: 615 loss: 0.000550824101
Iter: 616 loss: 0.000550805
Iter: 617 loss: 0.000550814671
Iter: 618 loss: 0.000550792261
Iter: 619 loss: 0.000550769269
Iter: 620 loss: 0.000550823868
Iter: 621 loss: 0.000550760422
Iter: 622 loss: 0.0005507397
Iter: 623 loss: 0.000550812576
Iter: 624 loss: 0.00055073417
Iter: 625 loss: 0.00055071339
Iter: 626 loss: 0.000550804485
Iter: 627 loss: 0.000550709199
Iter: 628 loss: 0.000550691562
Iter: 629 loss: 0.000550730096
Iter: 630 loss: 0.00055068417
Iter: 631 loss: 0.000550677127
Iter: 632 loss: 0.000550674391
Iter: 633 loss: 0.000550666125
Iter: 634 loss: 0.000550646917
Iter: 635 loss: 0.000550839351
Iter: 636 loss: 0.000550644647
Iter: 637 loss: 0.000550626079
Iter: 638 loss: 0.000550693308
Iter: 639 loss: 0.000550620724
Iter: 640 loss: 0.000550603145
Iter: 641 loss: 0.00055061793
Iter: 642 loss: 0.000550591969
Iter: 643 loss: 0.000550570607
Iter: 644 loss: 0.000550673
Iter: 645 loss: 0.000550567289
Iter: 646 loss: 0.000550549245
Iter: 647 loss: 0.000550626486
Iter: 648 loss: 0.000550546
Iter: 649 loss: 0.000550529512
Iter: 650 loss: 0.000550570549
Iter: 651 loss: 0.000550524
Iter: 652 loss: 0.00055050815
Iter: 653 loss: 0.000550522818
Iter: 654 loss: 0.000550499535
Iter: 655 loss: 0.000550481724
Iter: 656 loss: 0.000550506753
Iter: 657 loss: 0.000550473167
Iter: 658 loss: 0.000550454482
Iter: 659 loss: 0.000550581724
Iter: 660 loss: 0.000550451863
Iter: 661 loss: 0.000550435216
Iter: 662 loss: 0.000550469675
Iter: 663 loss: 0.000550428289
Iter: 664 loss: 0.000550422119
Iter: 665 loss: 0.000550419383
Iter: 666 loss: 0.000550411642
Iter: 667 loss: 0.000550397963
Iter: 668 loss: 0.000550397788
Iter: 669 loss: 0.000550385739
Iter: 670 loss: 0.000550389232
Iter: 671 loss: 0.000550377183
Iter: 672 loss: 0.00055036135
Iter: 673 loss: 0.000550414
Iter: 674 loss: 0.000550356868
Iter: 675 loss: 0.000550342083
Iter: 676 loss: 0.000550380093
Iter: 677 loss: 0.000550337369
Iter: 678 loss: 0.000550323166
Iter: 679 loss: 0.000550373457
Iter: 680 loss: 0.000550319615
Iter: 681 loss: 0.000550305936
Iter: 682 loss: 0.000550370722
Iter: 683 loss: 0.000550303375
Iter: 684 loss: 0.000550292199
Iter: 685 loss: 0.000550296274
Iter: 686 loss: 0.000550284
Iter: 687 loss: 0.000550270895
Iter: 688 loss: 0.000550301047
Iter: 689 loss: 0.000550265773
Iter: 690 loss: 0.00055025192
Iter: 691 loss: 0.000550311699
Iter: 692 loss: 0.000550248718
Iter: 693 loss: 0.000550236728
Iter: 694 loss: 0.000550275377
Iter: 695 loss: 0.00055023306
Iter: 696 loss: 0.000550225493
Iter: 697 loss: 0.000550225493
Iter: 698 loss: 0.000550217461
Iter: 699 loss: 0.000550229917
Iter: 700 loss: 0.000550213561
Iter: 701 loss: 0.000550207333
Iter: 702 loss: 0.000550200464
Iter: 703 loss: 0.000550199416
Iter: 704 loss: 0.000550188823
Iter: 705 loss: 0.000550213503
Iter: 706 loss: 0.000550184865
Iter: 707 loss: 0.000550174387
Iter: 708 loss: 0.000550204364
Iter: 709 loss: 0.000550171128
Iter: 710 loss: 0.000550160068
Iter: 711 loss: 0.000550177356
Iter: 712 loss: 0.000550154713
Iter: 713 loss: 0.000550145225
Iter: 714 loss: 0.00055023306
Iter: 715 loss: 0.000550144701
Iter: 716 loss: 0.000550135446
Iter: 717 loss: 0.000550140452
Iter: 718 loss: 0.000550129218
Iter: 719 loss: 0.000550119323
Iter: 720 loss: 0.000550127705
Iter: 721 loss: 0.000550113269
Iter: 722 loss: 0.000550102617
Iter: 723 loss: 0.000550157041
Iter: 724 loss: 0.00055010058
Iter: 725 loss: 0.000550091092
Iter: 726 loss: 0.000550129567
Iter: 727 loss: 0.000550088647
Iter: 728 loss: 0.000550080324
Iter: 729 loss: 0.000550120138
Iter: 730 loss: 0.000550078694
Iter: 731 loss: 0.000550071243
Iter: 732 loss: 0.000550172292
Iter: 733 loss: 0.000550071476
Iter: 734 loss: 0.000550067576
Iter: 735 loss: 0.000550060067
Iter: 736 loss: 0.000550177821
Iter: 737 loss: 0.000550059718
Iter: 738 loss: 0.000550050172
Iter: 739 loss: 0.000550072698
Iter: 740 loss: 0.000550046912
Iter: 741 loss: 0.000550038065
Iter: 742 loss: 0.000550057623
Iter: 743 loss: 0.000550034689
Iter: 744 loss: 0.000550025492
Iter: 745 loss: 0.000550053897
Iter: 746 loss: 0.000550022407
Iter: 747 loss: 0.000550014433
Iter: 748 loss: 0.000550052093
Iter: 749 loss: 0.000550012686
Iter: 750 loss: 0.000550004595
Iter: 751 loss: 0.000550028693
Iter: 752 loss: 0.000550002558
Iter: 753 loss: 0.000549995224
Iter: 754 loss: 0.00055
Iter: 755 loss: 0.000549990917
Iter: 756 loss: 0.000549982535
Iter: 757 loss: 0.000550003489
Iter: 758 loss: 0.000549979741
Iter: 759 loss: 0.000549971184
Iter: 760 loss: 0.000550000812
Iter: 761 loss: 0.00054996839
Iter: 762 loss: 0.000549961464
Iter: 763 loss: 0.000550003722
Iter: 764 loss: 0.000549960765
Iter: 765 loss: 0.000549956691
Iter: 766 loss: 0.000549956341
Iter: 767 loss: 0.000549953547
Iter: 768 loss: 0.000549946679
Iter: 769 loss: 0.000550035038
Iter: 770 loss: 0.000549945864
Iter: 771 loss: 0.000549939577
Iter: 772 loss: 0.000549953082
Iter: 773 loss: 0.0005499369
Iter: 774 loss: 0.000549929915
Iter: 775 loss: 0.000549955817
Iter: 776 loss: 0.000549927878
Iter: 777 loss: 0.000549920951
Iter: 778 loss: 0.000549932825
Iter: 779 loss: 0.00054991775
Iter: 780 loss: 0.000549911521
Iter: 781 loss: 0.00054992456
Iter: 782 loss: 0.000549909542
Iter: 783 loss: 0.00054990279
Iter: 784 loss: 0.000549970136
Iter: 785 loss: 0.000549902616
Iter: 786 loss: 0.000549898075
Iter: 787 loss: 0.000549896737
Iter: 788 loss: 0.000549894117
Iter: 789 loss: 0.000549887773
Iter: 790 loss: 0.000549908495
Iter: 791 loss: 0.00054988591
Iter: 792 loss: 0.000549880497
Iter: 793 loss: 0.00054989662
Iter: 794 loss: 0.000549878401
Iter: 795 loss: 0.000549872871
Iter: 796 loss: 0.000549891847
Iter: 797 loss: 0.000549871533
Iter: 798 loss: 0.000549869263
Iter: 799 loss: 0.000549869
Iter: 800 loss: 0.000549866061
Iter: 801 loss: 0.000549863
Iter: 802 loss: 0.000549862627
Iter: 803 loss: 0.000549858902
Iter: 804 loss: 0.000549857388
Iter: 805 loss: 0.000549855409
Iter: 806 loss: 0.000549849763
Iter: 807 loss: 0.00054987258
Iter: 808 loss: 0.000549849065
Iter: 809 loss: 0.000549844
Iter: 810 loss: 0.000549857446
Iter: 811 loss: 0.000549842604
Iter: 812 loss: 0.000549837307
Iter: 813 loss: 0.000549839053
Iter: 814 loss: 0.000549834105
Iter: 815 loss: 0.000549829507
Iter: 816 loss: 0.000549892837
Iter: 817 loss: 0.00054982939
Iter: 818 loss: 0.000549825607
Iter: 819 loss: 0.000549829507
Iter: 820 loss: 0.000549823279
Iter: 821 loss: 0.00054981932
Iter: 822 loss: 0.000549824559
Iter: 823 loss: 0.00054981705
Iter: 824 loss: 0.000549812277
Iter: 825 loss: 0.000549825607
Iter: 826 loss: 0.000549810706
Iter: 827 loss: 0.000549805874
Iter: 828 loss: 0.000549824908
Iter: 829 loss: 0.000549805118
Iter: 830 loss: 0.000549802382
Iter: 831 loss: 0.000549845281
Iter: 832 loss: 0.000549802673
Iter: 833 loss: 0.000549799064
Iter: 834 loss: 0.00054980407
Iter: 835 loss: 0.000549798133
Iter: 836 loss: 0.000549795106
Iter: 837 loss: 0.000549791264
Iter: 838 loss: 0.000549791672
Iter: 839 loss: 0.000549787132
Iter: 840 loss: 0.000549808261
Iter: 841 loss: 0.000549786
Iter: 842 loss: 0.000549782882
Iter: 843 loss: 0.00054979563
Iter: 844 loss: 0.000549781369
Iter: 845 loss: 0.000549777935
Iter: 846 loss: 0.000549782533
Iter: 847 loss: 0.000549776
Iter: 848 loss: 0.000549772638
Iter: 849 loss: 0.000549791555
Iter: 850 loss: 0.000549771648
Iter: 851 loss: 0.00054976868
Iter: 852 loss: 0.000549779
Iter: 853 loss: 0.000549767632
Iter: 854 loss: 0.000549764
Iter: 855 loss: 0.000549770659
Iter: 856 loss: 0.000549763
Iter: 857 loss: 0.000549759832
Iter: 858 loss: 0.000549763325
Iter: 859 loss: 0.000549758202
Iter: 860 loss: 0.000549754244
Iter: 861 loss: 0.000549769844
Iter: 862 loss: 0.000549753895
Iter: 863 loss: 0.000549750577
Iter: 864 loss: 0.000549764722
Iter: 865 loss: 0.000549750228
Iter: 866 loss: 0.000549747841
Iter: 867 loss: 0.000549747609
Iter: 868 loss: 0.000549746735
Iter: 869 loss: 0.000549743418
Iter: 870 loss: 0.000549763325
Iter: 871 loss: 0.000549742603
Iter: 872 loss: 0.00054973911
Iter: 873 loss: 0.000549747841
Iter: 874 loss: 0.000549738063
Iter: 875 loss: 0.000549734512
Iter: 876 loss: 0.000549759541
Iter: 877 loss: 0.000549734512
Iter: 878 loss: 0.000549731427
Iter: 879 loss: 0.000549733173
Iter: 880 loss: 0.000549729913
Iter: 881 loss: 0.000549727236
Iter: 882 loss: 0.000549738
Iter: 883 loss: 0.000549726072
Iter: 884 loss: 0.000549722754
Iter: 885 loss: 0.000549738412
Iter: 886 loss: 0.000549722521
Iter: 887 loss: 0.000549720309
Iter: 888 loss: 0.000549725723
Iter: 889 loss: 0.00054971897
Iter: 890 loss: 0.000549716584
Iter: 891 loss: 0.000549720135
Iter: 892 loss: 0.000549714954
Iter: 893 loss: 0.000549712
Iter: 894 loss: 0.000549719669
Iter: 895 loss: 0.000549711287
Iter: 896 loss: 0.000549708493
Iter: 897 loss: 0.000549720833
Iter: 898 loss: 0.000549707795
Iter: 899 loss: 0.000549707271
Iter: 900 loss: 0.00054970663
Iter: 901 loss: 0.000549705757
Iter: 902 loss: 0.000549703138
Iter: 903 loss: 0.000549724908
Iter: 904 loss: 0.000549702381
Iter: 905 loss: 0.000549700402
Iter: 906 loss: 0.000549704768
Iter: 907 loss: 0.000549699296
Iter: 908 loss: 0.000549696735
Iter: 909 loss: 0.000549705524
Iter: 910 loss: 0.000549696153
Iter: 911 loss: 0.000549693475
Iter: 912 loss: 0.000549704186
Iter: 913 loss: 0.000549692777
Iter: 914 loss: 0.000549690682
Iter: 915 loss: 0.000549694174
Iter: 916 loss: 0.00054968975
Iter: 917 loss: 0.000549687073
Iter: 918 loss: 0.000549694407
Iter: 919 loss: 0.00054968684
Iter: 920 loss: 0.000549684453
Iter: 921 loss: 0.00054969918
Iter: 922 loss: 0.000549683929
Iter: 923 loss: 0.00054968195
Iter: 924 loss: 0.000549681892
Iter: 925 loss: 0.000549680786
Iter: 926 loss: 0.000549678516
Iter: 927 loss: 0.000549690158
Iter: 928 loss: 0.000549678
Iter: 929 loss: 0.000549675897
Iter: 930 loss: 0.000549681892
Iter: 931 loss: 0.000549675664
Iter: 932 loss: 0.000549674383
Iter: 933 loss: 0.0005496745
Iter: 934 loss: 0.000549673277
Iter: 935 loss: 0.00054967124
Iter: 936 loss: 0.000549671357
Iter: 937 loss: 0.000549669145
Iter: 938 loss: 0.00054967
Iter: 939 loss: 0.000549668213
Iter: 940 loss: 0.000549665827
Iter: 941 loss: 0.000549673685
Iter: 942 loss: 0.000549665594
Iter: 943 loss: 0.000549663033
Iter: 944 loss: 0.000549672171
Iter: 945 loss: 0.000549663324
Iter: 946 loss: 0.00054966117
Iter: 947 loss: 0.000549665536
Iter: 948 loss: 0.000549661
Iter: 949 loss: 0.000549659075
Iter: 950 loss: 0.000549662393
Iter: 951 loss: 0.000549657852
Iter: 952 loss: 0.000549656514
Iter: 953 loss: 0.000549666409
Iter: 954 loss: 0.000549656
Iter: 955 loss: 0.00054965436
Iter: 956 loss: 0.000549657212
Iter: 957 loss: 0.00054965372
Iter: 958 loss: 0.000549652148
Iter: 959 loss: 0.000549656106
Iter: 960 loss: 0.000549651799
Iter: 961 loss: 0.000549649762
Iter: 962 loss: 0.000549653778
Iter: 963 loss: 0.000549649179
Iter: 964 loss: 0.000549647841
Iter: 965 loss: 0.000549660297
Iter: 966 loss: 0.000549647724
Iter: 967 loss: 0.000549646327
Iter: 968 loss: 0.000549653894
Iter: 969 loss: 0.000549646094
Iter: 970 loss: 0.000549645105
Iter: 971 loss: 0.000549643766
Iter: 972 loss: 0.000549664721
Iter: 973 loss: 0.000549643883
Iter: 974 loss: 0.000549641787
Iter: 975 loss: 0.000549648074
Iter: 976 loss: 0.000549641321
Iter: 977 loss: 0.000549639692
Iter: 978 loss: 0.000549646851
Iter: 979 loss: 0.000549639575
Iter: 980 loss: 0.000549637887
Iter: 981 loss: 0.000549641962
Iter: 982 loss: 0.000549637363
Iter: 983 loss: 0.000549635559
Iter: 984 loss: 0.000549639459
Iter: 985 loss: 0.000549635501
Iter: 986 loss: 0.00054963422
Iter: 987 loss: 0.000549642369
Iter: 988 loss: 0.000549633522
Iter: 989 loss: 0.000549632881
Iter: 990 loss: 0.000549634336
Iter: 991 loss: 0.000549631892
Iter: 992 loss: 0.00054963096
Iter: 993 loss: 0.000549635442
Iter: 994 loss: 0.000549630611
Iter: 995 loss: 0.000549629214
Iter: 996 loss: 0.000549631251
Iter: 997 loss: 0.000549628749
Iter: 998 loss: 0.000549627526
Iter: 999 loss: 0.000549632881
Iter: 1000 loss: 0.000549627235
Iter: 1001 loss: 0.000549626187
Iter: 1002 loss: 0.00054962642
Iter: 1003 loss: 0.000549626071
Iter: 1004 loss: 0.000549625
Iter: 1005 loss: 0.000549636083
Iter: 1006 loss: 0.000549624441
Iter: 1007 loss: 0.000549623452
Iter: 1008 loss: 0.000549625081
Iter: 1009 loss: 0.00054962252
Iter: 1010 loss: 0.000549621123
Iter: 1011 loss: 0.000549625489
Iter: 1012 loss: 0.000549620949
Iter: 1013 loss: 0.000549619435
Iter: 1014 loss: 0.000549627235
Iter: 1015 loss: 0.000549619144
Iter: 1016 loss: 0.000549618271
Iter: 1017 loss: 0.00054961862
Iter: 1018 loss: 0.000549617107
Iter: 1019 loss: 0.000549615768
Iter: 1020 loss: 0.000549626129
Iter: 1021 loss: 0.000549615943
Iter: 1022 loss: 0.000549614779
Iter: 1023 loss: 0.00054961635
Iter: 1024 loss: 0.000549614604
Iter: 1025 loss: 0.000549612858
Iter: 1026 loss: 0.000549615594
Iter: 1027 loss: 0.000549612916
Iter: 1028 loss: 0.000549612
Iter: 1029 loss: 0.000549615652
Iter: 1030 loss: 0.000549611519
Iter: 1031 loss: 0.000549610355
Iter: 1032 loss: 0.000549612218
Iter: 1033 loss: 0.00054961
Iter: 1034 loss: 0.000549609889
Iter: 1035 loss: 0.00054960954
Iter: 1036 loss: 0.000549608958
Iter: 1037 loss: 0.000549607794
Iter: 1038 loss: 0.000549621531
Iter: 1039 loss: 0.000549608143
Iter: 1040 loss: 0.000549607212
Iter: 1041 loss: 0.000549608609
Iter: 1042 loss: 0.000549606746
Iter: 1043 loss: 0.000549605815
Iter: 1044 loss: 0.000549608085
Iter: 1045 loss: 0.000549605291
